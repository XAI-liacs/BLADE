{"id": "a1236766-1ad3-400a-8528-4b8b7eb992c8", "fitness": 0.5592739660847712, "name": "DACS", "description": "DACS is a compact CMA‑ES–style heuristic that maintains a search mean m, an estimated covariance C and a global step size sigma, sampling a small Gaussian population N(m, sigma^2 C) each iteration and updating the mean by weighted recombination of the top half. Initialization uses uniform sampling across the provided bounds to pick an initial mean, sets C to a diagonal matrix scaled by the bounds (range/4) and sigma to 0.25·mean(range), while the population size is chosen adaptively (lambda = max(8, 4 + 3·log(dim))) but capped by the budget. Covariance is updated with a rank‑mu style weighted covariance of selected, normalized steps with a relatively conservative learning rate c_cov=0.2 (and numerical safeguards: Cholesky with diagonal jitter and eigen correction), and samples are clamped to bounds. Step‑size adapts via a smoothed success‑rate (approximate 1/5th rule) using an exponential update (sigma_adapt_rate=0.2, success_target=0.2), and prolonged stagnation (scaled to budget) triggers an opportunistic restart that inflates sigma, recenters m around the best with jitter, and resets C to a moderate isotropic matrix.", "code": "import numpy as np\n\nclass DACS:\n    \"\"\"\n    Directional Adaptive Covariance Search (DACS)\n\n    Simplified covariance-adapting evolutionary strategy:\n      - Maintain a mean and a covariance estimate of promising directions (like a compact CMA-ES).\n      - Sample a small population each iteration from N(mean, sigma^2 C).\n      - Update mean by weighted recombination of the best half; update C by weighted rank-mu update.\n      - Adapt sigma via a smoothed success-rule (approximate 1/5th rule).\n      - When stagnation is detected, perform an opportunistic restart: inflate sigma and reinitialize covariance locally.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        # user can override some tuning parameters by assigning attributes after creation if desired\n        self.pop_base = None  # if None, will be set adaptively\n        self.cov_update = 0.2  # learning rate for covariance update (c_cov)\n        self.sigma_adapt_rate = 0.2  # factor controlling step-size adaptation speed\n        self.stagnation_threshold = max(5, int(0.05 * self.budget))  # iterations without improvement to consider stagnation\n\n    def __call__(self, func):\n        rng = np.random.RandomState()  # local RNG\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        # support scalar bounds or per-dim\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n\n        # safeguard bounds\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # adaptive population size: moderate small pop to allow many iterations\n        if self.pop_base is None:\n            self.lambda_ = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            self.lambda_ = int(self.pop_base)\n        self.lambda_ = min(self.lambda_, max(2, self.budget))  # cannot exceed budget\n\n        # initial batch: uniform sampling\n        evals = 0\n        batch0 = min(self.lambda_, self.budget - evals)\n        X = rng.uniform(lb, ub, size=(batch0, self.dim))\n        f_vals = np.array([func(x) for x in X])\n        evals += batch0\n\n        # track best\n        best_idx = np.argmin(f_vals)\n        f_best = f_vals[best_idx]\n        x_best = X[best_idx].copy()\n\n        # initialize mean as weighted mean of top-half of initial samples\n        mu = max(1, batch0 // 2)\n        order = np.argsort(f_vals)\n        elites = X[order[:mu]]\n        weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n        weights = np.maximum(weights, 0.0)\n        weights = weights / np.sum(weights)\n        m = (weights.reshape(-1, 1) * elites).sum(axis=0)\n\n        # initial covariance: scale identity according to bounds (covering half-range)\n        bounds_scale = (ub - lb)\n        # use variance of uniform in [lb,ub] ~ (range^2)/12, but take moderate initial variance\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = 0.25 * np.mean(bounds_scale)  # global step size\n        sigma = max(sigma, 1e-8)\n\n        # strategy state\n        c_cov = float(self.cov_update)\n        p_succ = 0.2  # smoothed success rate estimate\n        success_target = 0.2\n        stagn_count = 0\n        iter_count = 0\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            # determine batch size for this iteration\n            remaining = self.budget - evals\n            lam = min(self.lambda_, remaining)\n            mu = max(1, lam // 2)\n\n            # recompute weights for current mu\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # ensure C is SPD by adding tiny diagonal if needed\n            eps = 1e-12 * np.maximum(np.diag(C), 1.0)\n            try:\n                A = np.linalg.cholesky(C + np.diag(eps))\n            except np.linalg.LinAlgError:\n                # fallback: use eigen decomposition to make SPD\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals))  # columns scaled\n                A = A.T  # so that A^T A = C\n            # Sample lam candidates from N(m, sigma^2 C)\n            Z = rng.normal(size=(lam, self.dim))\n            # transform: Y = Z @ (chol.T) -> Y has covariance C\n            Y = Z @ (A.T)\n            Xcand = m + sigma * Y\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates, one by one to not exceed budget\n            fc = np.empty(lam, dtype=float)\n            for i in range(lam):\n                fc[i] = func(Xcand[i])\n            evals += lam\n\n            # update best\n            gen_best_idx = np.argmin(fc)\n            gen_best_f = fc[gen_best_idx]\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # select elites and update mean\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # compute weighted covariance of selected steps (in normalized coordinates)\n            # deltas = (X_mu - m) / sigma\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            # weighted covariance: sum_i w_i * delta_i * delta_i^T\n            # constructs matrix of shape (dim, dim)\n            # use broadcasting for efficiency\n            W = weights.reshape(-1, 1)  # (mu,1)\n            weighted_cov = (deltas * W).T @ deltas  # shape (dim, dim)\n\n            # update covariance\n            C = (1.0 - c_cov) * C + c_cov * weighted_cov\n\n            # update mean\n            y_w = (m_new - m) / (sigma + 1e-20)\n            m = m_new\n\n            # step-size adaptation via smoothed success rate (approx 1/5th rule)\n            p_succ = 0.9 * p_succ + 0.1 * float(improved)\n            # adapt sigma: small exponential update\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - success_target))\n            # keep sigma in reasonable bounds relative to search space\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n            # opportunistic restart if stagnation for many iterations\n            if stagn_count * lam >= self.stagnation_threshold and evals < self.budget:\n                # inflate sigma and re-center around best with small jitter\n                stagn_count = 0\n                # if best is at boundary, we nudge inward; otherwise random jitter proportional to sigma\n                jitter = 0.5 * sigma * (1.0 + 0.5 * rng.rand(self.dim))\n                m = x_best + (rng.randn(self.dim) * jitter)\n                # clamp to bounds\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset covariance to isotropic moderate\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                sigma = max(sigma, 0.5 * np.mean(bounds_scale))\n                # small safeguard: if budget small, avoid too many restarts\n                continue\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DACS scored 0.559 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "39dd17d5-d2bd-44ed-a9be-de68e6ffa0d6", "operator": null, "metadata": {"aucs": [0.21511716670905867, 0.3162719234146186, 0.4314896378038282, 0.9773434843204531, 0.5107441971128337, 0.966305590282676, 0.2951855368552184, 0.5501894692706565, 0.958259768798472, 0.37183288627989586]}, "task_prompt": ""}
{"id": "4774ee81-1693-48fc-b906-4e1c3dd40998", "fitness": 0.5295735336054557, "name": "AdaptiveDiffPatternSearch", "description": "1) Hybrid approach: the algorithm combines a global Adaptive Differential Evolution backbone with periodic, cheap Hooke–Jeeves-style coordinate pattern searches for exploitation, where local refinement is triggered every local_period generations or when gens_since_improve ≥ local_stagn_gen to balance exploration and exploitation.  \n2) Population and DE mechanics: it initializes a small quasi-uniform population by per-dimension stratification plus jitter (pop ≈ max(12, 4+3·log(dim))) to allow many generations, uses current-to-pbest/1 mutation and binomial crossover, and selects p-best candidates via p_frac to bias toward good solutions.  \n3) Self-adaptation and constraints: F and CR are adapted jDE-style per individual with probabilities tau1 and tau2 and clipped to [F_min,F_max], while out-of-bounds vectors are handled by a reflect-then-clamp rule and all evaluations are strictly budget-aware (sequential counting and early exits).  \n4) Local-search and robustness tricks: the coordinate search uses an initial_step_frac scaled by the bounds with step_shrink and min_step stopping criteria, includes opportunistic extra probes, injects any local improvement by replacing the worst individual, and when stagnating performs mild restart nudges (random jitter around the global best) to regain diversity.", "code": "import numpy as np\n\nclass AdaptiveDiffPatternSearch:\n    \"\"\"\n    Adaptive Differential Evolution with periodic coordinate pattern search refinement.\n\n    Main ideas:\n    - Maintain a small population sampled quasi-uniformly in bounds.\n    - Use a jDE-like self-adaptive scheme for F and CR per individual.\n    - Mutation: current-to-pbest/1 (balances greediness and diversity).\n    - Crossover: binomial.\n    - Bound handling: simple reflection then clamp.\n    - Periodically (or on stagnation) perform a cheap Hooke-Jeeves-style coordinate search\n      centered on the current best solution to exploit promising regions.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        # Tunable options (user may override)\n        self.pop_base = None  # if None, will be set adaptively\n        self.p_frac = 0.2     # fraction for p-best selection\n        self.tau1 = 0.1       # prob to adapt F\n        self.tau2 = 0.1       # prob to adapt CR\n        self.F_min = 0.1\n        self.F_max = 0.9\n        self.local_period = 20           # generations between local refinements\n        self.local_stagn_gen = 30        # gens without improvement to trigger local search\n        self.initial_step_frac = 0.25    # initial step relative to bounds for pattern search\n        self.min_step_frac = 1e-4        # minimum step relative to bounds\n        self.step_shrink = 0.5\n\n    def __call__(self, func):\n        rng = np.random.RandomState()  # local RNG for reproducibility isolation\n\n        # bounds handling similar to given example\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size (smallish to allow many generations)\n        if self.pop_base is None:\n            pop = max(12, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))  # cannot exceed budget\n\n        evals = 0\n\n        # initialize population quasi-uniformly: stratified random (simple)\n        X = np.empty((pop, self.dim), dtype=float)\n        # stratify per-dimension\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n\n        # jitter a bit to break determinism\n        X += (rng.rand(pop, self.dim) - 0.5) * (0.5 * (ub - lb) / max(1.0, self.dim))\n        # clamp\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # Evaluate initial population (sequentially to respect budget)\n        f = np.empty(pop, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        # If budget exhausted during init, return best seen\n        if evals >= self.budget:\n            best_idx = np.argmin(f[:i+1])\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # initialize F and CR arrays (self-adaptive per-individual)\n        F = np.clip(0.5 + 0.1 * rng.randn(pop), self.F_min, self.F_max)\n        CR = np.clip(rng.rand(pop), 0.0, 1.0)\n\n        # track best\n        best_idx = np.argmin(f)\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        # small helper functions\n        def reflect_bounds(x):\n            # reflect once and then clamp (simple, inexpensive)\n            x_ref = x.copy()\n            low = lb\n            high = ub\n            below = x_ref < low\n            if np.any(below):\n                x_ref[below] = low[below] + (low[below] - x_ref[below])\n            above = x_ref > high\n            if np.any(above):\n                x_ref[above] = high[above] - (x_ref[above] - high[above])\n            # final clamp\n            x_ref = np.minimum(np.maximum(x_ref, low), high)\n            return x_ref\n\n        pnum_min = max(2, int(np.ceil(self.p_frac * pop)))\n\n        # main DE loop, generation by generation\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # recompute ranking once per generation\n            order = np.argsort(f)\n            # ensure p-best pool\n            p_pool = order[:max(pnum_min, 2)]\n\n            # iterate individuals in random order to avoid biases\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                # self-adapt F and CR (jDE-style)\n                if rng.rand() < self.tau1:\n                    F[ii] = np.clip(0.5 * (1.0 + 0.5 * rng.randn()), self.F_min, self.F_max)\n                if rng.rand() < self.tau2:\n                    CR[ii] = rng.rand()\n\n                # pick p-best\n                pbest_idx = rng.choice(p_pool)\n                # pick r1,r2 distinct from each other and ii and pbest\n                idxs_pool = list(range(pop))\n                for rem in sorted({ii, pbest_idx}, reverse=True):\n                    try:\n                        idxs_pool.remove(rem)\n                    except ValueError:\n                        pass\n                if len(idxs_pool) < 2:\n                    # fallback: use any distinct indices\n                    candidates = [j for j in range(pop) if j not in (ii, pbest_idx)]\n                    if len(candidates) < 2:\n                        r1, r2 = ii, ii\n                    else:\n                        r1, r2 = rng.choice(candidates, size=2, replace=False)\n                else:\n                    r1, r2 = rng.choice(idxs_pool, size=2, replace=False)\n\n                xi = X[ii]\n                xp = X[pbest_idx]\n                xr1 = X[r1]\n                xr2 = X[r2]\n                # current-to-pbest/1\n                vi = xi + F[ii] * (xp - xi) + F[ii] * (xr1 - xr2)\n                # crossover binomial\n                jrand = rng.randint(self.dim)\n                cross_mask = rng.rand(self.dim) < CR[ii]\n                cross_mask[jrand] = True\n                trial = np.where(cross_mask, vi, xi)\n                # reflect/clamp bounds\n                trial = reflect_bounds(trial)\n\n                # evaluate trial if budget allows\n                if evals >= self.budget:\n                    break\n                fv = float(func(trial))\n                evals += 1\n\n                # selection\n                if fv <= f[ii]:\n                    X[ii] = trial\n                    f[ii] = fv\n                    # success can be used for some variants (we keep simple)\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = trial.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                # otherwise keep parent\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # periodic or stagnation-triggered local search\n            if gen % self.local_period == 0 or gens_since_improve >= self.local_stagn_gen:\n                # Hooke-Jeeves style coordinate search around x_best\n                # limited by remaining budget\n                remaining = self.budget - evals\n                if remaining <= 0:\n                    break\n\n                # initial step relative to bounds\n                range_mean = np.mean(ub - lb)\n                step = max(1e-12, self.initial_step_frac * range_mean)\n                min_step = max(1e-12, self.min_step_frac * range_mean)\n\n                # if no improvement for many gens, increase initial step to escape\n                if gens_since_improve >= self.local_stagn_gen:\n                    step *= 2.0\n\n                local_improved = False\n                # copy best into a working point\n                x_work = x_best.copy()\n                f_work = f_best\n\n                # outer loop of step reductions\n                while step >= min_step and (self.budget - evals) > 0:\n                    moved = False\n                    # coordinate probes\n                    for d in range(self.dim):\n                        if evals >= self.budget:\n                            break\n                        # try plus\n                        x_try = x_work.copy()\n                        x_try[d] = x_try[d] + step\n                        # clamp\n                        if x_try[d] > ub[d]:\n                            x_try[d] = ub[d]\n                        if np.all(x_try == x_work):\n                            # try negative if plus not possible\n                            x_try[d] = x_work[d] - step\n                            if x_try[d] < lb[d]:\n                                x_try[d] = lb[d]\n                        # evaluate\n                        fv = float(func(x_try))\n                        evals += 1\n                        if fv < f_work:\n                            x_work = x_try\n                            f_work = fv\n                            moved = True\n                            local_improved = True\n                            # update global population best as well\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = x_try.copy()\n                                gens_since_improve = 0\n                            # small opportunistic exploitation: try same direction further once\n                            # (one extra probe if budget permits)\n                            if evals < self.budget:\n                                x_try2 = x_work.copy()\n                                step2 = step\n                                x_try2[d] = np.minimum(np.maximum(x_try2[d] + step2, lb[d]), ub[d])\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < f_work:\n                                    x_work = x_try2\n                                    f_work = fv2\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = x_try2.copy()\n                                        gens_since_improve = 0\n                        else:\n                            # try minus direction if plus failed and we didn't already try minus\n                            if evals >= self.budget:\n                                break\n                            x_try = x_work.copy()\n                            x_try[d] = x_work[d] - step\n                            if x_try[d] < lb[d]:\n                                x_try[d] = lb[d]\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                x_work = x_try\n                                f_work = fv\n                                moved = True\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_try.copy()\n                                    gens_since_improve = 0\n\n                    if not moved:\n                        step *= self.step_shrink\n                    # if we moved, continue with same step to possibly continue descent\n                    # stop if budget exhausted\n                    if evals >= self.budget:\n                        break\n\n                # if local improved, inject the point into population replacing worst individual\n                if local_improved:\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_work.copy()\n                    f[worst_idx] = f_work\n                    # also update best if needed (done above)\n                    gens_since_improve = 0\n                else:\n                    # if local search didn't improve and we were stagnating, perform a mild restart move:\n                    if gens_since_improve >= self.local_stagn_gen:\n                        # nudge half of population around global best\n                        for k in range(pop // 2):\n                            jitter = (rng.randn(self.dim) * (0.05 * (ub - lb)))\n                            newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                            if evals >= self.budget:\n                                break\n                            fv = float(func(newx))\n                            evals += 1\n                            # replace some worst\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = newx\n                            f[worst_idx] = fv\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = newx.copy()\n                                gens_since_improve = 0\n\n            # update best info from population to be safe\n            bi = np.argmin(f)\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finished due to budget exhaustion or loop exit\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDiffPatternSearch scored 0.530 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "39dd17d5-d2bd-44ed-a9be-de68e6ffa0d6", "operator": null, "metadata": {"aucs": [0.17325648468436206, 0.18755084631826624, 0.7152509912683902, 0.9909522581264832, 0.7546853419260309, 0.8692959416830887, 0.31491666547448083, 0.5790867223468815, 0.5259506437180285, 0.18478944050854518]}, "task_prompt": ""}
{"id": "188a3a49-ae94-4c3e-b458-f640f8fc578c", "fitness": 0.5289987714794334, "name": "APLS", "description": "APLS maintains a small elite archive of the best points found and uses it both as centers for focused refinements and for jittered restarts, with archive size and initial sampling chosen adaptively to the dimension and budget. It alternates heavy‑tailed global jumps (Cauchy‑like, per‑dim scaling by avg_span and clipped to avoid extremes) to escape basins with Hooke‑Jeeves‑style local pattern searches (coordinate exploratory moves, pattern_factor extension, and step shrink by shrink) for intensive exploitation. The algorithm is budget‑aware via an eval wrapper that clips to bounds and never exceeds self.budget, and it adaptively allocates small local budgets (local_budget_frac, max_local_budget) and slowly reduces global jump scale as attempts progress. Additional diversifiers include occasional uniform injections, jittered restarts around the current best, and a feedback rule that increases global jump probability when the archive becomes too clustered.", "code": "import numpy as np\n\nclass APLS:\n    \"\"\"\n    Adaptive Pattern-Levy Search (APLS)\n\n    Main ideas:\n    - Maintain a small elite archive of best points found so far.\n    - Alternate between heavy-tailed global jumps (Cauchy/Levy-like) to escape basins\n      and intensive local pattern searches (Hooke-Jeeves style) for exploitation.\n    - Local searches use shrinking coordinate steps and pattern moves; successful\n      outcomes update the archive. Restarts are drawn from elite points with jitter.\n    - Budget-aware: never exceeds self.budget evaluations.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 init_samples=None,\n                 archive_size=None,\n                 global_jump_prob=0.25,\n                 local_budget_frac=0.03,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.init_samples = init_samples  # if None, chosen adaptively\n        self.archive_size = archive_size  # if None, chosen adaptively\n        self.global_jump_prob = float(global_jump_prob)\n        self.local_budget_frac = float(local_budget_frac)  # fraction of budget to spend per local search attempt (soft)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n        # parse bounds (func.bounds.lb/ub may be scalar or arrays)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # search-space scales\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        # adaptive defaults\n        if self.init_samples is None:\n            init_samples = max(12, min(60, 6 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, self.budget)\n        if self.archive_size is None:\n            archive_k = max(3, min(10, init_samples // 3))\n        else:\n            archive_k = int(self.archive_size)\n        # budget counters\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        # elite archive: list of tuples (f, x)\n        archive = []\n\n        def eval_and_record(x):\n            # wrapper to evaluate x (clipped) and update best/archive; respects budget\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None  # cannot evaluate\n            x = np.asarray(x, dtype=float)\n            # clip to bounds\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            # update best\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # insert into archive if good\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        # initial sampling (space-filling uniform)\n        for i in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # fallback: if archive empty (shouldn't be), seed with randoms\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # parameters for local search\n        max_local_budget = max(5, int(self.local_budget_frac * self.budget))\n        # local step shrink factor and pattern factor\n        shrink = 0.6\n        pattern_factor = 1.5\n        tol = 1e-8\n\n        # quick function to propose a global heavy-tailed step (Cauchy-like)\n        def global_jump_from(x_center, scale):\n            # Cauchy heavy-tailed steps in direction scaled per-dim by span\n            # produce a random direction and random Cauchy step length\n            direction = rng.randn(self.dim)\n            direction /= (np.linalg.norm(direction) + 1e-12)\n            # standard Cauchy for heavy tails\n            step_length = rng.standard_cauchy()\n            # clip extreme draws to avoid numerical issues but keep heavy tails\n            step_length = np.clip(step_length, -1e3, 1e3)\n            # per-dim scaling: scale * average span, but also allow anisotropy\n            step = direction * (float(scale) * avg_span * (0.5 + 0.5 * rng.rand()))\n            return x_center + step_length * step\n\n        # Hooke-Jeeves inspired local search around a start point\n        def local_search(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            # initial local step: proportional to bounds but not huge\n            step0 = 0.5 * avg_span * (0.5 + rng.rand() * 0.5)\n            steps = np.full(self.dim, step0, dtype=float)\n            local_evals = 0\n            # limit iterations so we don't overconsume\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_evals < local_budget and iters < iter_limit and np.any(steps > (1e-12)):\n                iters += 1\n                improved = False\n                x_probe = base.copy()\n                x_probe_f = base_f\n                # exploratory moves along each coordinate\n                for i in range(self.dim):\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    # try positive\n                    xp = x_probe.copy()\n                    xp[i] += steps[i]\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res = eval_and_record(xp)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < x_probe_f:\n                        x_probe = xp.copy()\n                        x_probe_f = fp\n                        improved = True\n                        continue  # next coordinate continues from improved probe\n                    # try negative\n                    xn = x_probe.copy()\n                    xn[i] -= steps[i]\n                    xn = np.minimum(np.maximum(xn, lb), ub)\n                    res = eval_and_record(xn)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < x_probe_f:\n                        x_probe = xn.copy()\n                        x_probe_f = fn\n                        improved = True\n                # pattern move if exploratory improved\n                if improved and local_evals < local_budget and evals < self.budget:\n                    # pattern: move further in direction from base -> probe\n                    direction = x_probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_and_record(xp)\n                        local_evals += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < x_probe_f:\n                                # accept pattern point as new base\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                # accept exploratory probe\n                                base = x_probe.copy()\n                                base_f = x_probe_f\n                        else:\n                            # budget exhausted\n                            base = x_probe.copy()\n                            base_f = x_probe_f\n                    else:\n                        base = x_probe.copy()\n                        base_f = x_probe_f\n                else:\n                    # no improvement: shrink steps\n                    steps *= shrink\n                # safety break if budget used\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # Main loop: alternate global jumps and local searches until budget exhausted\n        # We'll perform adaptive number of attempts depending on remaining budget\n        attempt = 0\n        # dynamic global scale: shrink slowly as we progress\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            # dynamic local budget allocation: don't take more than a fraction and leave room for future attempts\n            alloc_local = min(max_local_budget, max(2, int(0.02 * self.budget)))\n            alloc_local = min(alloc_local, remaining - 1) if remaining > 1 else 0\n\n            # decide whether to do a global jump or local refine\n            if rng.rand() < self.global_jump_prob and len(archive) > 0:\n                # global jump from an elite point (best or random elite)\n                if rng.rand() < 0.7:\n                    center = archive[0][1]  # best\n                else:\n                    idx = rng.randint(0, len(archive))\n                    center = archive[idx][1]\n                # scale reduces slowly with attempts to focus later\n                scale = max(0.05, 1.0 - 0.02 * attempt)\n                cand = global_jump_from(center, scale)\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n                # if candidate is promising, perform a small local search around it\n                if alloc_local > 0 and f_cand <= (archive[0][0] if len(archive)>0 else np.inf) * 1.1:\n                    # slightly increase local budget for promising points\n                    local_alloc = min(remaining - 1, alloc_local * 3)\n                    local_alloc = max(1, local_alloc)\n                    local_budget = local_alloc\n                    f_after, x_after = local_search(cand, f_cand, local_budget)\n                    # continue to next attempt\n            else:\n                # local refine from a chosen start: choose best or a random archive member, or random restart\n                choose = rng.rand()\n                if choose < 0.6 and len(archive) > 0:\n                    start_f, start_x = archive[0]\n                elif choose < 0.9 and len(archive) > 1:\n                    idx = rng.randint(0, len(archive))\n                    start_f, start_x = archive[idx]\n                else:\n                    # random restart with jitter around best or uniform if no best\n                    if x_best is not None:\n                        jitter = 0.2 * avg_span * rng.randn(self.dim)\n                        start_x = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                        # evaluate start_x\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                    else:\n                        start_x = rng.uniform(lb, ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n\n                # local budget: adapt to remaining budget\n                local_budget = min(alloc_local, max(2, int(0.05 * remaining)))\n                # perform local search (Hooke-Jeeves like)\n                f_after, x_after = local_search(start_x, start_f, local_budget)\n\n            # occasional tiny diversification if archive is too clustered: inject new uniform samples\n            if (attempt % 17) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # break if budget is exhausted\n            if evals >= self.budget:\n                break\n\n            # slight adaptive adjustments: if no improvement for many attempts, increase global jump rate\n            if len(archive) >= 2:\n                # measure diversity\n                if np.linalg.norm(archive[0][1] - archive[-1][1]) < 1e-6 + 0.01 * avg_span:\n                    # increase chance of global jumps to escape\n                    self.global_jump_prob = min(0.6, self.global_jump_prob + 0.02)\n                else:\n                    self.global_jump_prob = max(0.05, self.global_jump_prob * 0.995)\n\n        # finish\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm APLS scored 0.529 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "39dd17d5-d2bd-44ed-a9be-de68e6ffa0d6", "operator": null, "metadata": {"aucs": [0.11234799489261804, 0.17138230146366495, 0.9750720888635214, 0.9898577029653752, 0.3406518952142299, 0.9848810094329066, 0.2798701775521071, 0.2959843053104807, 0.9852862859852469, 0.15465395311418295]}, "task_prompt": ""}
{"id": "51281bd0-71d4-4c04-ae61-5338826a446f", "fitness": 0.10738184730364235, "name": "MCAS", "description": "MCAS maintains a Gaussian search distribution parameterized by a mean m, a covariance C, a directional momentum vector v and a coordinate-wise scale s_diag, samples antithetic pairs (plus one extra if odd) and clips candidates to per-dimension bounds while respecting the evaluation budget. Covariance learning is a mixture of rank‑mu weighted covariance (c_cov≈0.18) and a rank‑one outer product from the momentum (c1≈0.06) with numerical SPD fixes/Cholesky for stable sampling. Per-coordinate adaptation uses an EMA of squared normalized steps (s_diag_beta≈0.6) and momentum smoothing (mom_beta≈0.8) to bias extra perturbations along consistently successful directions, while sigma is multiplicatively adapted via a smoothed success rate (target≈0.2, adapt rate≈0.25). The algorithm also uses a modest dimension‑dependent population, antithetic variance reduction, initial isotropic scaling based on bounds, and opportunistic trust‑region style restarts when stagnation (stagnation_frac≈0.04) is detected.", "code": "import numpy as np\n\nclass MCAS:\n    \"\"\"\n    Momentum-Covariance Adaptive Sampler (MCAS)\n\n    Main ideas:\n    - Maintain mean m, covariance estimate C, a directional momentum vector v and\n      a coordinate-wise scaling s_diag. Sampling uses antithetic pairs and an\n      extra directional perturbation along v to bias search towards consistently\n      successful directions.\n    - Covariance updated via a mixture of rank-mu weighted covariance and a\n      rank-one momentum outer product. Coordinate-wise scale adapts with EMA of\n      squared normalized steps.\n    - Step-size adapts with a smoothed success-rate (approx 1/5-th rule).\n    - Opportunistic trust-region style restarts when stagnation is detected:\n      re-center, inflate sigma and reset covariance isotropically.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10):\n        self.budget = int(budget)\n        self.dim = int(dim)\n\n        # Tunable hyperparameters (can be modified externally)\n        self.pop_base = None              # adaptive base population\n        self.cov_update = 0.18            # rank-mu learning rate\n        self.rank1 = 0.06                 # rank-one learning rate for momentum outer product\n        self.mom_beta = 0.8               # momentum smoothing for directional vector v\n        self.s_diag_beta = 0.6            # EMA factor for coordinate-wise scale\n        self.sigma_adapt_rate = 0.25      # speed for sigma multiplicative update\n        self.success_target = 0.2         # target success probability for sigma adaptation\n        self.stagnation_frac = 0.04       # fraction of budget to consider stagnation\n        self.min_sigma = 1e-12\n        self.max_sigma_scale = 2.0\n\n    def __call__(self, func):\n        rng = np.random.RandomState()  # local RNG for reproducibility isolation\n\n        # bounds support (scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # adapt population size moderately to dimension\n        if self.pop_base is None:\n            # ensure modest base for low budget regimes\n            lam0 = max(6, int(3 + 2 * np.log(max(2, self.dim))))\n        else:\n            lam0 = int(self.pop_base)\n        lam0 = min(lam0, max(2, self.budget))\n\n        # initial sampling (one small batch)\n        evals = 0\n        batch0 = min(lam0, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(batch0, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += batch0\n\n        best_idx = np.argmin(f0)\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize mean as weighted average of top half of initial samples\n        mu0 = max(1, batch0 // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 = w0 / np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance: moderate isotropic aligned to bounds\n        bounds_scale = (ub - lb)\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.18 * np.mean(bounds_scale))\n\n        # additional state: directional momentum and coordinate-wise scales\n        v = np.zeros(self.dim, dtype=float)         # directional momentum vector in normalized coords\n        s_diag = np.ones(self.dim, dtype=float)     # coordinate-wise scaling (multiplies normalized samples)\n        p_succ = 0.2                                # smoothed success rate\n        stagn_iter = 0\n        iter_count = 0\n        stagnation_threshold = max(5, int(self.stagnation_frac * self.budget))\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam = min(lam0, remaining)\n            # ensure lam at least 2 (for antithetic pairing) if budget allows\n            lam = max(2 if remaining >= 2 else 1, lam)\n\n            mu = max(1, lam // 2)\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n            W = weights.reshape(-1, 1)\n\n            # ensure C is SPD; small jitter added to diagonal\n            eps_diag = 1e-12 * np.maximum(np.diag(C), 1.0)\n            try:\n                A = np.linalg.cholesky(C + np.diag(eps_diag))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T  # A such that A^T A = C\n\n            # Antithetic sampling pattern:\n            half = lam // 2\n            # draw Gaussian for positive half\n            Zpos = rng.normal(size=(half, self.dim))\n            # create mirrored negatives\n            Z = np.vstack([Zpos, -Zpos])\n            if lam % 2 == 1:\n                # add one extra sample\n                Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n\n            # transform to correlated space: Y has covariance C\n            Y = Z @ A.T  # shape (lam, dim)\n\n            # directional perturbation: add a scalar multiplier along normalized v\n            v_norm = v.copy()\n            vlen = np.linalg.norm(v_norm) + 1e-20\n            if vlen > 0:\n                v_unit = v_norm / vlen\n            else:\n                v_unit = np.zeros_like(v_norm)\n            # direction strength scales with magnitude of v and current sigma\n            dir_strength = 0.8 * (vlen / (1.0 + vlen))  # in [0,0.8)\n            # draw scalar coefficients for each sample\n            s_scalar = rng.normal(scale=dir_strength, size=(Y.shape[0], 1))\n            Y = Y + (s_scalar * v_unit.reshape(1, -1))\n\n            # apply coordinate-wise scaling (multiplicative)\n            Y = Y * s_diag.reshape(1, -1)\n\n            Xcand = m + sigma * Y\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates (one-by-one with budget guard)\n            lam_actual = Xcand.shape[0]\n            fc = np.full(lam_actual, np.inf, dtype=float)\n            for i in range(lam_actual):\n                if evals >= self.budget:\n                    break\n                fc[i] = func(Xcand[i])\n                evals += 1\n\n            # if some slots not evaluated (due to budget), truncate arrays accordingly\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                lam_actual = fc.shape[0]\n                if lam_actual == 0:\n                    break  # budget exhausted\n\n            # update global best\n            gen_best_idx = np.argmin(fc)\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_iter = 0\n            else:\n                stagn_iter += 1\n\n            # select elites and compute new mean\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            # If fewer elites than weights (happens if lam_actual < mu), adjust\n            if X_mu.shape[0] != weights.shape[0]:\n                mu_eff = X_mu.shape[0]\n                w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                w_eff = np.maximum(w_eff, 0.0)\n                if np.sum(w_eff) <= 0:\n                    w_eff = np.ones_like(w_eff)\n                w_eff = w_eff / np.sum(w_eff)\n                W_eff = w_eff.reshape(-1, 1)\n                m_new = (W_eff * X_mu).sum(axis=0)\n            else:\n                m_new = (W * X_mu).sum(axis=0)\n\n            # normalized deltas in sample coordinates (y = (x - m) / sigma)\n            deltas = (X_mu - m) / (sigma + 1e-20)  # shape (mu, dim)\n\n            # weighted covariance in normalized coords\n            # covariance estimate from elites\n            if deltas.shape[0] > 0:\n                if deltas.shape[0] != weights.shape[0]:\n                    # recompute small set weights if required\n                    mu_eff = deltas.shape[0]\n                    w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if np.sum(w_eff) <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff = w_eff / np.sum(w_eff)\n                    Wd = w_eff.reshape(-1, 1)\n                    weighted_cov = (deltas * Wd).T @ deltas\n                    delta_mean = (Wd * deltas).sum(axis=0)\n                else:\n                    weighted_cov = (deltas * W).T @ deltas\n                    delta_mean = (W * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # update directional momentum v in normalized coordinates\n            v = self.mom_beta * v + (1.0 - self.mom_beta) * delta_mean\n\n            # rank-one outer product from momentum (stabilize scale)\n            rank_one = np.outer(v, v)\n\n            # covariance update: mixture of old covariance, weighted_cov and rank-one momentum\n            c_cov = float(self.cov_update)\n            c1 = float(self.rank1)\n            C = (1.0 - c_cov - c1) * C + c_cov * weighted_cov + c1 * rank_one\n            # ensure symmetry and SPD\n            C = 0.5 * (C + C.T) + np.diag(np.maximum(np.diag(C), 1e-18))\n\n            # coordinate-wise scale update (EMA of squared normalized steps)\n            # measure across elites; if none, use small decay\n            if deltas.shape[0] > 0:\n                stat = np.mean(deltas ** 2, axis=0)\n            else:\n                stat = 1e-6 * np.ones(self.dim)\n            s_diag = (self.s_diag_beta * s_diag +\n                      (1.0 - self.s_diag_beta) * np.sqrt(stat + 1e-20))\n            # clip s_diag to reasonable range\n            s_diag = np.clip(s_diag, 0.2, 5.0)\n\n            # update mean\n            m = m_new.copy()\n\n            # step-size adaptation using smoothed success-rate\n            p_succ = 0.85 * p_succ + 0.15 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, self.min_sigma, self.max_sigma_scale * np.max(bounds_scale))\n\n            # opportunistic trust-region-style restart if stagnation\n            if stagn_iter >= stagnation_threshold and evals < self.budget:\n                stagn_iter = 0\n                # if best is promising, restart around best with random jitter; otherwise random global restart\n                if np.isfinite(f_best):\n                    jitter_scale = max(0.5 * sigma, 0.08 * np.mean(bounds_scale))\n                    m = x_best + rng.randn(self.dim) * jitter_scale\n                else:\n                    m = rng.uniform(lb, ub, size=self.dim)\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset covariance isotropic but slightly narrower (trust-region)\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                # inflate sigma to encourage exploration\n                sigma = max(sigma * 1.8, 0.5 * np.mean(bounds_scale))\n                # reset momentum and coordinate scales partially\n                v = np.zeros_like(v)\n                s_diag = np.ones_like(s_diag)\n                # continue to next iteration (don't count more evaluations here)\n                continue\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MCAS scored 0.107 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a1236766-1ad3-400a-8528-4b8b7eb992c8", "operator": null, "metadata": {"aucs": [0.03595355407991219, 0.0720168640544343, 0.16977111970105951, 0.12067889859316394, 0.08835680778127086, 0.14142126546440792, 0.13541762716657846, 0.1039903104056582, 0.10375568403642155, 0.1024563417535167]}, "task_prompt": ""}
{"id": "cebdb775-6824-4b44-af56-7c5277130528", "fitness": 0.16340025182814139, "name": "AMES", "description": "Adaptive Mirrored Evolution Strategy that uses mirrored (antithetic) pair sampling to get variance-efficient, gradient-free samples and a small-to-moderate population (lam = max(12, 6+2*sqrt(dim))) for robust sampling. Covariance is updated by a mix of a relatively strong rank‑1 path term (c1=0.12) and a smaller rank‑mu term (cmu=0.06) with an evolution path p accumulated using a dimension‑aware smoothing factor, while linear decreasing recombination weights and a narrower initial covariance/sigma (init_scale = bounds/6, sigma = 0.15*mean(bounds)) bias early local exploitation. Step‑size is adapted aggressively (alpha_sigma=0.7) toward a desired normalized spread (diversity_target=0.30) by measuring the RMS of normalized population steps, increasing sigma when the population collapses. Robustness measures include per‑iteration Cholesky/eigen SPD corrections to keep C positive definite and an opportunistic restart on stagnation that inflates sigma, re-centers around the best solution with jitter, and reinitializes C to promote exploration.", "code": "import numpy as np\n\nclass AMES:\n    \"\"\"\n    Adaptive Mirrored Evolution Strategy (AMES)\n\n    Key ideas:\n     - Use mirrored-pair sampling to get high-efficiency gradient-free samples.\n     - Maintain a covariance estimate updated by a rank-1 evolution path (c1) and a rank-mu weighted update (cmu).\n     - Adapt global step-size sigma using the population's normalized spread (not a simple success-count).\n     - Conservative learning rates and occasional eigen/cholesky correction to keep C SPD.\n     - Opportunistic restart on prolonged stagnation (different reinitialization equations than DACS).\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 c1=0.12, cmu=0.06,         # covariance learning rates (different from DACS's single c_cov)\n                 alpha_sigma=0.7,          # step-size adaptation strength (different equation)\n                 diversity_target=0.30,    # desired normalized spread (controls sigma updates)\n                 stagnation_ratio=0.02,    # fraction of budget indicating stagnation\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.c1 = float(c1)\n        self.cmu = float(cmu)\n        self.alpha_sigma = float(alpha_sigma)\n        self.diversity_target = float(diversity_target)\n        self.stagnation_ratio = float(stagnation_ratio)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds support (Many Affine BBOB uses [-5,5] typically)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size: favor somewhat larger than DACS but still moderate\n        if self.pop_base is None:\n            lam = max(12, int(6 + 2 * np.sqrt(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # initial sampling (uniform)\n        evals = 0\n        first_batch = min(lam, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(first_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += first_batch\n\n        best_idx = np.argmin(f0)\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize mean using top-half weighted recombination (different weighting scale)\n        mu = max(1, first_batch // 2)\n        order = np.argsort(f0)\n        elites = X0[order[:mu]]\n        # different weighting formula: linear decreasing then normalized (not log-weights)\n        weights = np.linspace(mu, 1, mu)\n        weights = np.maximum(weights, 1e-12)\n        weights = weights / np.sum(weights)\n        m = (weights.reshape(-1, 1) * elites).sum(axis=0)\n\n        # covariance and sigma initializations (different scales from DACS)\n        bounds_scale = (ub - lb)\n        # prefer smaller initial covariance to encourage local exploitation\n        init_scale = (bounds_scale / 6.0)  # narrower than DACS's /4\n        C = np.diag((init_scale ** 2).clip(min=1e-12))\n        sigma = 0.15 * np.mean(bounds_scale)  # different base step-size (smaller than DACS)\n\n        # strategy state\n        c1 = float(self.c1)\n        cmu = float(self.cmu)\n        alpha_sigma = float(self.alpha_sigma)\n        diversity_target = float(self.diversity_target)\n        stagn_limit = max(10, int(self.stagnation_ratio * self.budget))\n        stagn_count = 0\n\n        # evolution path (for rank-1 update)\n        p = np.zeros(self.dim, dtype=float)\n\n        # prepare recombination weights for general lam (linear decreasing)\n        def recombination_weights(mu_local):\n            w = np.linspace(mu_local, 1, mu_local)\n            w = np.maximum(w, 0.0)\n            w = w / np.sum(w)\n            return w\n\n        # main loop\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu_iter = max(1, lam_iter // 2)\n            weights = recombination_weights(mu_iter)\n\n            # ensure C is SPD with small jitter; prefer eigen-correction every iteration to avoid breakdown\n            eps = 1e-12 * np.maximum(np.diag(C), 1.0)\n            try:\n                A = np.linalg.cholesky(C + np.diag(eps))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n\n            # mirrored sampling: generate lam_iter samples, using pairs +/- for efficiency\n            half = lam_iter // 2\n            odd = (lam_iter % 2) != 0\n            Z = rng.normal(size=(half, self.dim))\n            Y_half = Z @ A.T  # each row has covariance C\n            Xcand_list = []\n            Z_list = []\n            for y in Y_half:\n                Xcand_list.append(m + sigma * y)\n                Xcand_list.append(m - sigma * y)\n                Z_list.append(y)\n                Z_list.append(-y)\n            if odd:\n                z = rng.normal(size=self.dim)\n                yc = z @ A.T\n                Xcand_list.append(m + sigma * yc)\n                Z_list.append(yc)\n            Xcand = np.vstack(Xcand_list)[:lam_iter]\n            Zmat = np.vstack(Z_list)[:lam_iter]\n\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates one by one\n            fc = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                fc[i] = func(Xcand[i])\n            evals += lam_iter\n\n            # update best\n            gen_best_idx = np.argmin(fc)\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # select elites and compute weighted mean in original coordinates\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu_iter]]\n            Z_mu = Zmat[order[:mu_iter]]  # corresponding normalized steps (A-transformed)\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # compute normalized steps y_i = (X_i - m) / sigma  (note: using old m)\n            y_steps = (X_mu - m) / (sigma + 1e-20)  # shape (mu_iter, dim)\n            # weighted rank-mu covariance in normalized coordinates\n            W = weights.reshape(-1, 1)\n            cov_mu = (W * y_steps).T @ y_steps  # shape (dim, dim)\n\n            # evolution path update (rank-1), using weighted mean step in normalized coords\n            y_w = ( (weights.reshape(-1,1) * y_steps).sum(axis=0) )\n            # compute effective mu for scaling\n            mu_eff = (np.sum(weights))**2 / np.sum(weights**2)\n            # update p with a different smoothing than DACS: accumulate with sqrt factor\n            c_p = 2.0 / (self.dim + 2.0)  # a dimension-aware small factor\n            p = (1.0 - c_p) * p + np.sqrt(c_p * (2.0 - c_p) * mu_eff) * y_w\n\n            # covariance update: mix (1-c1-cmu)*C + c1*p p^T + cmu*cov_mu\n            coef_fix = max(0.0, 1.0 - c1 - cmu)\n            C = coef_fix * C + c1 * np.outer(p, p) + cmu * cov_mu\n\n            # update mean\n            m = m_new\n\n            # step-size adaptation using normalized population spread (novel eqn)\n            # compute normalized RMS length of y's (should be ~sqrt(dim) for good spread; normalize by sqrt(dim))\n            y_all = (Xcand - m) / (sigma + 1e-20)\n            norm_rms = np.sqrt(np.mean(np.sum(y_all**2, axis=1)) / max(1.0, float(self.dim)))\n            # adjust sigma towards diversity_target: increase if population collapsed (norm_rms < target)\n            sigma *= np.exp(alpha_sigma * (diversity_target - norm_rms))\n            # keep sigma sensible relative to bounds\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n            # occasional SPD safeguard: eigen-correct if necessary\n            if np.any(np.isnan(C)) or np.any(np.isinf(C)):\n                C = np.diag(((bounds_scale / 8.0) ** 2).clip(min=1e-12))\n            # ensure positive definiteness by eigen clipping if needed\n            try:\n                _ = np.linalg.cholesky(C + np.eye(self.dim) * 1e-16)\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                C = (vecs * vals) @ vecs.T\n\n            # opportunistic restart (different rules & reinit scales than DACS)\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # inflate sigma substantially and reinitialize C smaller (promote exploration)\n                sigma *= 3.0\n                # re-center near best with moderate jitter proportional to sigma\n                jitter = sigma * (0.25 + 0.5 * rng.rand(self.dim))\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((bounds_scale / 12.0) ** 2).clip(min=1e-12))\n                p = np.zeros_like(p)\n                # avoid too large sigma relative to bounds\n                sigma = min(sigma, 1.0 * np.max(bounds_scale))\n                continue\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AMES scored 0.163 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a1236766-1ad3-400a-8528-4b8b7eb992c8", "operator": null, "metadata": {"aucs": [0.11229732125393477, 0.16216085105818245, 0.22364306261692402, 0.2889327185056302, 0.10786023210569695, 0.13263902656374438, 0.17350716878742345, 0.17921539919005836, 0.1298752522713873, 0.12387148592843222]}, "task_prompt": ""}
{"id": "7956008c-efb9-4476-b683-ba91bcce8d93", "fitness": 0.67866965889269, "name": "ADES", "description": "ADES keeps a search center m, an adaptive trust radius rho and a learned covariance C, plus a small archive of evaluated points for covariance learning and a linear surrogate; the center is initialized from a modest uniform batch and updated by weighted recombination of top candidates. Candidate generation mixes directed moves along top eigenvectors of C (both signs), Gaussian samples from N(m, (rho^2)C), an occasional gradient-exploitation step from a ridge linear fit on recent archive points, and local uniform jitter to fill remaining slots. Adaptation uses trust-region style rho expansion (rho_expand=1.2) on center improvement and shrinkage (rho_shrink=0.66) on failure, a rank-mu style covariance update blended with a small rank-1 successful-step term and a moderate covariance learning rate (cov_lr≈0.22), plus soft acceptance (m smoothed toward m_new) and numerical safeguards (Cholesky/eigendecomposition and eigenvalue clipping). Robustness features include adaptive population size, archive sizing proportional to dim, bounds clipping, SPD enforcement, and opportunistic restarts when stagnation or rho collapse is detected.", "code": "import numpy as np\n\nclass ADES:\n    \"\"\"\n    Adaptive Directional Ensemble Search (ADES)\n\n    Main ideas:\n      - Maintain a center m, an adaptive trust radius rho, and a learned covariance C.\n      - Each iteration generate a small ensemble mixing:\n         * proposals along principal/eigen directions of C (both signs),\n         * Gaussian proposals drawn from N(m, rho^2 C),\n         * an occasional gradient-exploitation proposal from a ridge-fit linear model on recent points.\n      - Update m by weighted recombination of top candidates, and update C via a rank-mu style update\n        using the normalized steps (w.r.t. rho). Accept or shrink/expand rho based on whether the center\n        is improved by the best candidate (trust-region style).\n      - Maintain a small archive for covariance learning and for fitting a linear surrogate (to estimate a gradient).\n      - Opportunistic restart if stagnation or rho becomes too small.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,           # if None adaptively chosen\n                 cov_lr=0.22,             # covariance learning rate\n                 rho_init_frac=0.25,      # initial trust radius fraction of bound range\n                 rho_shrink=0.66,         # shrink factor on failure\n                 rho_expand=1.2,          # expand factor on success\n                 success_target=0.2,      # relative target success rate for minor self-adaptation (unused heavy)\n                 archive_size_factor=6,   # how many points to keep for surrogate/cov updates (~ factor * dim)\n                 stagn_thresh_ratio=0.05, # fraction of budget before restart trigger (relative)\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.cov_lr = float(cov_lr)\n        self.rho_init_frac = float(rho_init_frac)\n        self.rho_shrink = float(rho_shrink)\n        self.rho_expand = float(rho_expand)\n        self.success_target = float(success_target)\n        self.archive_size_factor = int(archive_size_factor)\n        self.stagn_thresh_ratio = float(stagn_thresh_ratio)\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds handling (allow scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        max_bound = np.max(bounds_scale)\n\n        # adaptive population base if not given\n        if self.pop_base is None:\n            lambda_ = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lambda_ = int(self.pop_base)\n        lambda_ = min(lambda_, max(2, self.budget))\n\n        # bookkeeping\n        evals = 0\n        archive_capacity = max(self.dim * self.archive_size_factor, 4 * self.dim, 20)\n\n        # initial sampling: modest uniform batch to initialize mean and covariance\n        init_batch = min(lambda_ * 2, max(2, self.budget // 20), self.budget)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize center m as weighted mean of top half of initial samples\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w = np.maximum(w, 0.0)\n        w /= np.sum(w)\n        m = (w.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial trust radius and covariance\n        rho = float(self.rho_init_frac * np.mean(bounds_scale))\n        rho = max(rho, 1e-8)\n        # initial covariance moderate isotropic but allow per-dim scaling:\n        C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n\n        # archive of evaluated points (for surrogate and covariance smoothing)\n        X_hist = list(X0)\n        f_hist = list(f0)\n\n        # stagnation and counters\n        stagn_iters = 0\n        stagn_thresh = max(5, int(self.stagn_thresh_ratio * self.budget))\n        iter_count = 0\n\n        # helper to ensure SPD chol\n        def chol_spd(mat):\n            eps = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam = min(lambda_, remaining)\n            mu = max(1, lam // 2)\n\n            # recompute weighted recombination weights for mu\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # Compute principal directions from C (eigenvectors)\n            try:\n                vals, vecs = np.linalg.eigh(C)\n            except np.linalg.LinAlgError:\n                vals = np.ones(self.dim)\n                vecs = np.eye(self.dim)\n            # sort by descending eigenvalue\n            idxs = np.argsort(-vals)\n            vals = vals[idxs]\n            vecs = vecs[:, idxs]\n\n            # prepare candidate generation:\n            candidates = []\n            # 1) directional proposals along top eigenvectors (both signs)\n            n_dir = min(max(1, lam // 4), self.dim)\n            for k in range(n_dir):\n                v = vecs[:, k]\n                # random amplitude along direction scaled by rho and eigenscale\n                scale = (1.0 + 0.6 * rng.rand()) * rho * (np.sqrt(max(vals[k], 1e-12)) / (np.sqrt(np.mean(vals)) + 1e-12))\n                candidates.append(m + scale * v)\n                if len(candidates) >= lam:\n                    break\n                candidates.append(m - scale * v)\n                if len(candidates) >= lam:\n                    break\n\n            # 2) Gaussian proposals using C scaled to rho (i.e., draw z ~ N(0,C) then multiply by rho)\n            if len(candidates) < lam:\n                # compute Cholesky of C (for sampling)\n                A = chol_spd(C)\n                n_gauss = lam - len(candidates) - 1  # reserve 1 slot for gradient exploitation candidate\n                if n_gauss < 0:\n                    n_gauss = 0\n                if n_gauss > 0:\n                    Z = rng.normal(size=(n_gauss, self.dim))\n                    Y = Z @ (A.T)  # Y has covariance C\n                    Xg = m + rho * Y\n                    candidates.extend(list(Xg))\n            # 3) gradient exploitation candidate (if enough history)\n            grad_candidate_generated = False\n            if len(candidates) < lam:\n                grad_candidate = None\n                # require at least dim+2 points in archive for a meaningful linear fit\n                if len(f_hist) >= min(self.dim + 2, 8):\n                    # build regression matrix using recent archive (centered)\n                    # use most recent up to archive_capacity points\n                    n_fit = min(len(X_hist), archive_capacity)\n                    X_fit = np.asarray(X_hist[-n_fit:])  # (n_fit, dim)\n                    f_fit = np.asarray(f_hist[-n_fit:])\n                    # center coordinates w.r.t current center m\n                    Xc = X_fit - m\n                    # target is change in objective (we fit linear f(x) ~ f(m) + g^T (x-m))\n                    fm_est = np.interp(0.0, [0.0, 1.0], [0.0, 0.0])  # placeholder, we will use y = f - f_center\n                    # pick f_center as the best known center evaluation if available in archive else approximate by mean\n                    # find a point in archive closest to m\n                    dists = np.sum((X_fit - m)**2, axis=1)\n                    idx_closest = int(np.argmin(dists))\n                    f_center = f_fit[idx_closest]\n                    y = f_fit - f_center\n                    # ridge regularized linear solve: beta = (Xc^T Xc + lambda I)^-1 Xc^T y\n                    lam_reg = 1e-6 * (1.0 + np.var(y))\n                    XT_X = Xc.T @ Xc\n                    reg = lam_reg * np.eye(self.dim)\n                    try:\n                        beta = np.linalg.solve(XT_X + reg, Xc.T @ y)\n                        g = beta  # approximate gradient pointing to increase in f\n                        # take a step opposite to gradient\n                        gnorm = np.linalg.norm(g)\n                        if gnorm > 0:\n                            step_scale = rho * (0.8 + 0.6 * rng.rand())\n                            grad_candidate = m - (step_scale * (g / (gnorm + 1e-20)))\n                        else:\n                            grad_candidate = None\n                    except np.linalg.LinAlgError:\n                        grad_candidate = None\n                if grad_candidate is not None:\n                    candidates.append(grad_candidate)\n                    grad_candidate_generated = True\n\n            # Fill remaining slots with uniform random within a small box around m to encourage local exploration\n            while len(candidates) < lam:\n                box = np.clip(rho * 0.5, 1e-12, np.max(bounds_scale))\n                cand = m + rng.uniform(-box, box, size=self.dim)\n                candidates.append(cand)\n\n            # finalize candidates and clip to bounds\n            Xcand = np.asarray(candidates[:lam])\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates (one by one to ensure never exceeding budget)\n            fc = np.empty(Xcand.shape[0], dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    # fill rest with inf and break\n                    fc[i:] = np.inf\n                    break\n                fc[i] = func(Xcand[i])\n                evals += 1\n                # update best on the fly to allow early knowledge\n                if fc[i] < f_best:\n                    f_best = float(fc[i])\n                    x_best = Xcand[i].copy()\n                    stagn_iters = 0\n            else:\n                # if loop finished normally, no special handling\n                pass\n\n            # store evaluated points into archive (trim to capacity)\n            for xi, fi in zip(Xcand, fc):\n                X_hist.append(xi.copy())\n                f_hist.append(float(fi))\n            if len(X_hist) > archive_capacity:\n                excess = len(X_hist) - archive_capacity\n                X_hist = X_hist[excess:]\n                f_hist = f_hist[excess:]\n\n            # determine best candidate of this generation\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            # measure improvement relative to current center value: find nearest archived point to m to approximate f(m)\n            # we try to find an evaluated point equal or very close to m in history; if none, approximate by f_best (conservative)\n            if len(X_hist) > 0:\n                Xh = np.asarray(X_hist)\n                dists = np.sum((Xh - m)**2, axis=1)\n                idx0 = int(np.argmin(dists))\n                f_m_approx = float(f_hist[idx0])\n            else:\n                f_m_approx = f_best\n\n            improved_center = gen_best_f < f_m_approx - 1e-12\n\n            # recompute new center by weighted recombination of top mu candidates (elitist)\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # compute normalized steps (w.r.t. rho) for covariance update\n            deltas = (X_mu - m) / (rho + 1e-20)  # shape (mu, dim)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas  # shape (dim, dim)\n\n            # additional rank-1 update in direction of successful step if any\n            if improved_center:\n                successful_step = (gen_best_x - m) / (rho + 1e-20)\n                # using small weight for direction exploitation\n                dir_cov = np.outer(successful_step, successful_step)\n                C = (1.0 - self.cov_lr) * C + self.cov_lr * (0.75 * weighted_cov + 0.25 * dir_cov)\n            else:\n                # conservative update if no clear center improvement: blend toward isotropic small shrink to limit noise\n                iso = np.diag(((bounds_scale / 12.0) ** 2).clip(min=1e-12))\n                C = (1.0 - 0.5 * self.cov_lr) * C + (0.5 * self.cov_lr) * weighted_cov + (0.5 * self.cov_lr) * iso\n\n            # update center acceptance and rho adaptation (trust-region style)\n            if improved_center:\n                # accept new center and consider expanding trust radius moderately\n                m = m_new\n                rho = min(2.0 * np.max(bounds_scale), rho * self.rho_expand)\n                stagn_iters = 0\n            else:\n                # if no improvement, keep m but shrink rho moderately (be more local)\n                stagn_iters += 1\n                rho = max(1e-8, rho * self.rho_shrink)\n\n            # also apply a small smoothing step for m towards m_new even if not fully accepted (soft acceptance)\n            m = 0.85 * m + 0.15 * m_new\n\n            # clamp center\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # small numerical safeguards for C\n            # ensure symmetry\n            C = 0.5 * (C + C.T)\n            # eigensafety\n            vals, vecs = np.linalg.eigh(C)\n            vals = np.clip(vals, 1e-12, None)\n            C = (vecs * vals) @ vecs.T\n\n            # opportunistic restart if stagnation prolonged or rho collapsed too small\n            if (stagn_iters >= stagn_thresh) or (rho <= 1e-9 * max_bound):\n                # reinitialize around the global best with jitter and reset covariance and rho\n                stagn_iters = 0\n                # jitter magnitude proportional to current bounds and small fraction\n                jitter = 0.5 * np.maximum(rho, 0.05 * np.mean(bounds_scale))\n                m = x_best + jitter * rng.randn(self.dim)\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                rho = max(rho, self.rho_init_frac * np.mean(bounds_scale) * 0.8)\n                # slightly reduce lambda_ when budget small to avoid over-sampling\n                if self.budget < 200:\n                    lambda_ = max(4, lambda_ // 2)\n                continue\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ADES scored 0.679 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a1236766-1ad3-400a-8528-4b8b7eb992c8", "operator": null, "metadata": {"aucs": [0.270481123369372, 0.4276891415233621, 0.963385114211606, 0.9804027261795689, 0.7130454351869648, 0.9824953667679923, 0.3167728889493401, 0.961483301253673, 0.9790222470949717, 0.19191924439005026]}, "task_prompt": ""}
{"id": "23fe7331-5fec-4d4d-a554-9168a2971557", "fitness": 0.7416028020198373, "name": "AEDS", "description": "AEDS is an adaptive ensemble directional search that keeps a compact diagonal/full covariance estimate and a directional evolution path (p_c) to combine a conservative rank-mu covariance estimate with a rank‑one path term, using log‑biased recombination weights and a Cholesky (with eigenfallback) for robust sampling. Population size is set slightly large and growing with sqrt(dim), initial sigma is a modest 0.2·mean(bounds) with a tight diagonal initial C ((bounds/6)^2), and sigma is adapted multiplicatively by a smoothed success-rate p_succ (alpha=0.15) scaled down by sqrt(dim) to slow step changes. Covariance updates blend old and new information heavily (cov_memory=0.75) with a relatively small rank‑one learning rate (c_cov=0.12) and a slow path_decay (0.9) to retain momentum while preventing runaway, plus tiny jittering for numerical stability. Conservative restarts detect stagnation (stagnation_frac→threshold) and respond by shrinking sigma, re-centering near the best, resetting to a smaller isotropic C, and modestly increasing population to diversify search.", "code": "import numpy as np\n\nclass AEDS:\n    \"\"\"\n    Adaptive Ensemble Directional Search (AEDS)\n\n    Main idea (one-liner):\n      Maintain a compact covariance estimate and a directional memory (evolution path),\n      sample a small ensemble each iteration, update mean by weighted recombination,\n      update covariance using both a rank-mu estimate and a path (rank-one) term,\n      adapt step-size by a smoothed success-rate rule scaled by dimension,\n      and perform conservative restarts that slightly reduce sigma and reinitialize covariance.\n\n    Main tunable parameters (exposed as attributes; differences versus the given DACS):\n      - pop_base / lambda_: base/adaptive population size (here scaled ~ sqrt(dim), different constant)\n      - c_cov: covariance learning rate (default 0.12, more conservative than 0.2)\n      - sigma_adapt_rate: speed of multiplicative sigma updates (default 0.3)\n      - success_target: target success rate (default 0.25)\n      - stagnation_frac: fraction of budget to consider stagnation (default 0.08, different scale)\n      - cov_memory: blending weight for old covariance vs new rank-mu (default 0.75)\n      - path_decay: decay for evolution-path accumulation (default 0.9)\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 c_cov=0.12,\n                 sigma_adapt_rate=0.3,\n                 success_target=0.25,\n                 stagnation_frac=0.08,\n                 cov_memory=0.75,\n                 path_decay=0.9,\n                 random_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.c_cov = float(c_cov)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.success_target = float(success_target)\n        self.stagnation_frac = float(stagnation_frac)\n        self.cov_memory = float(cov_memory)\n        self.path_decay = float(path_decay)\n        self.random_seed = random_seed\n\n        # derived / safe defaults\n        self.stagnation_threshold = max(5, int(self.stagnation_frac * max(1, self.budget)))\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.random_seed)\n\n        # bounds handling (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size heuristic (different scaling than DACS)\n        if self.pop_base is None:\n            # slightly larger base for higher-dimensional tasks but growing like sqrt(dim)\n            self.lambda_ = max(6, int(6 + 4 * np.sqrt(max(1, self.dim))))\n        else:\n            self.lambda_ = int(self.pop_base)\n        self.lambda_ = min(self.lambda_, max(2, self.budget))\n\n        # initial sampling to bootstrap mean and best\n        evals = 0\n        init_batch = min(self.lambda_, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        best_idx = np.argmin(f0)\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # weighted initial mean from top half (but with slightly different log-weights)\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        weights0 = np.log(np.arange(mu0, 0, -1) + 0.6)  # reversed-ish log emphasis\n        weights0 = np.maximum(weights0, 0.0)\n        weights0 = weights0 / np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance: diagonal but smaller than DACS (tighter initial search)\n        bounds_scale = (ub - lb)\n        C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n\n        # initial sigma: modest fraction of bounds (different constant)\n        sigma = 0.2 * np.mean(bounds_scale)\n        sigma = max(sigma, 1e-12)\n\n        # algorithm state\n        p_succ = 0.2  # smoothed success estimate (start near target)\n        stagn_count = 0\n        iter_count = 0\n\n        # evolution path (directional memory) to add a rank-one contribution to covariance\n        p_c = np.zeros(self.dim, dtype=float)\n        # small regularizer for numeric stability\n        min_diag = 1e-12\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n\n            remaining = self.budget - evals\n            lam = min(self.lambda_, remaining)\n            mu = max(1, lam // 2)\n\n            # recompute weights (rank-mu) - slightly different shape to bias top\n            ranks = np.arange(1, mu + 1)\n            weights = np.log(mu + 0.5) - np.log(ranks + 0.2)\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # ensure SPD via jittered Cholesky; fallback eigen correction\n            eps = 1e-12 * np.maximum(np.diag(C), 1.0)\n            try:\n                A = np.linalg.cholesky(C + np.diag(eps))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, min_diag, None)\n                A = (vecs * np.sqrt(vals)).T\n\n            # sample lam candidates\n            Z = rng.normal(size=(lam, self.dim))\n            Y = Z @ (A.T)          # Y ~ N(0, C)\n            Xcand = m + sigma * Y\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate (one by one)\n            fc = np.empty(lam, dtype=float)\n            for i in range(lam):\n                fc[i] = float(func(Xcand[i]))\n            evals += lam\n\n            # generation best and global best update\n            gen_best_idx = np.argmin(fc)\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # recombine to get new mean\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized steps (in sigma-units)\n            deltas = (X_mu - m) / (sigma + 1e-20)   # shape (mu, dim)\n\n            # weighted covariance estimate (rank-mu)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas  # (dim, dim)\n\n            # update evolution path p_c (directional momentum) using the weighted mean step\n            y_w = (m_new - m) / (sigma + 1e-20)\n            # small normalization to avoid runaway\n            p_c = self.path_decay * p_c + (1.0 - self.path_decay) * y_w\n\n            # combine rank-mu and path (rank-one) into covariance update\n            rank_one = np.outer(p_c, p_c)\n            # blend: keep some memory of previous C (cov_memory) and mix new rank-mu and rank-one\n            C_new = (self.cov_memory * C +\n                     (1.0 - self.cov_memory) * ((1.0 - self.c_cov) * weighted_cov + self.c_cov * rank_one))\n            # ensure symmetry\n            C = 0.5 * (C_new + C_new.T)\n            # tiny diagonal safeguard\n            diagC = np.diag(C)\n            jitter = 1e-12 * np.maximum(diagC, 1.0)\n            C += np.diag(jitter)\n\n            # accept the new mean\n            m = m_new\n\n            # success smoothing and sigma adaptation\n            # smoother alpha chosen lower than 0.2 (so changes are neither too fast nor too slow)\n            alpha = 0.15\n            p_succ = (1.0 - alpha) * p_succ + alpha * float(improved)\n\n            # sigma update scaled by sqrt(dim) (different equation from DACS)\n            dim_scale = 1.0 + 0.5 * np.sqrt(max(1, self.dim))\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target) / dim_scale)\n\n            # clamp sigma within sensible bounds relative to problem size\n            max_sigma = 2.0 * np.max(bounds_scale)\n            sigma = float(np.clip(sigma, 1e-12, max_sigma))\n\n            # opportunistic conservative restart (different behavior from DACS):\n            # if stagnating for many iterations, do a conservative shrink and reinit covariance locally\n            if stagn_count * lam >= self.stagnation_threshold and evals < self.budget:\n                stagn_count = 0\n                # reduce sigma moderately (shrink towards more local search)\n                sigma *= (0.4 + 0.6 * rng.rand())  # between 0.4 and 1.0 multiplier\n                # re-center mean near the best but keep one random component\n                jitter = 0.05 * bounds_scale * (0.5 + rng.rand(self.dim))\n                m = x_best + (rng.randn(self.dim) * jitter)\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset covariance to a smaller isotropic matrix (more local)\n                C = np.diag(((bounds_scale / 8.0) ** 2).clip(min=min_diag))\n                # slightly increase population for next rounds to diversify (but not beyond budget)\n                self.lambda_ = min(self.lambda_ + 2, max(2, self.budget))\n                # continue loop\n                continue\n\n        # done; store results\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AEDS scored 0.742 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a1236766-1ad3-400a-8528-4b8b7eb992c8", "operator": null, "metadata": {"aucs": [0.2519846985235499, 0.17727541479073594, 0.9352441878636011, 0.9800894512010374, 0.9558200564345248, 0.9625699222904927, 0.319240200639032, 0.9271634551688678, 0.9547156697840858, 0.9519249635024448]}, "task_prompt": ""}
{"id": "ad00285c-2740-4894-bdf7-843cbde9ae5f", "fitness": 0.8117159468043381, "name": "HybridCMADE", "description": "HybridCMADE fuses a CMA-like state (mean m, covariance C, global step sigma) with DE-style differential proposals drawn from an elite archive — each generation samples roughly half Gaussian candidates from N(m, sigma^2 C) and half archive-driven differential/crossover trials (F_de=0.8, CR=0.9), using an adaptive population size lam = max(8, 4+3·log(dim)) and archive_size = min(40, max(5, 4·dim)).  \nThe mean is updated by rank-weighted recombination (log-based weights), covariance is adapted from the selected deltas with a relatively aggressive learning rate cov_lr=0.25 plus floor/blending regularization to prevent collapse, and chol_safe/eigendecomposition fallback guarantees numerical stability.  \nStep-size sigma uses a smoothed success-rate controller (p_succ → success_target=0.2) with sigma_adapt_rate=0.25 (a 1/5th-like rule), and all proposals are clamped to the provided bounds.  \nTo escape stagnation the method performs occasional heavy-tailed Lévy/Cauchy jumps (levy_prob=0.25) anchored on archive elites or opportunistic restarts centered on the best, while practical safeguards include uniform initial seeding, bounds-scaled isotropic initial covariance/sigma, budget-aware sampling, and archive maintenance.", "code": "import numpy as np\n\nclass HybridCMADE:\n    \"\"\"\n    HybridCMADE: Hybrid directional CMA-style + Differential proposals with adaptive Lévy escapes.\n    \n    Main ideas:\n      - Maintain mean m, covariance C and global step sigma (CMA-like).\n      - Each iteration sample a small population: half from N(m, sigma^2 C), half from DE-style differential proposals\n        built from an elite archive of good solutions (best + differences).\n      - Weighted recombination (rank-mu) updates the mean; covariance updated from the mixture of selected steps.\n      - Step-size adapts via a smoothed success rate; occasional Lévy/Cauchy jumps and opportunistic restarts on stagnation.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        # tunable knobs (safe defaults)\n        self.pop_base = None  # if None, adaptively chosen\n        self.cov_lr = 0.25    # covariance learning rate (more aggressive than very conservative)\n        self.sigma_adapt_rate = 0.25\n        self.success_target = 0.2\n        self.archive_size = min(40, max(5, 4 * self.dim))  # elite archive pool\n        self.stagnation_iters = max(10, int(0.05 * self.budget))  # iterations without improvement to trigger jump/restart\n        self.levy_prob = 0.25  # probability to try a Lévy-style jump when stagnating\n        self.F_de = 0.8  # differential weight for DE-style proposals\n        self.CR = 0.9    # crossover probability for DE proposals\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # adaptive population size\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # initial uniform sampling to seed archive and initial mean\n        evals = 0\n        init_batch = min(lam, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        # best-known\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # build archive (list of tuples f,x), keep sorted ascending\n        archive_X = X0.copy()\n        archive_f = f0.copy()\n        # if fewer than archive_size, we'll grow it; otherwise we'll keep top-k\n        def archive_add(x, fx):\n            nonlocal archive_X, archive_f\n            if len(archive_f) < self.archive_size:\n                archive_X = np.vstack([archive_X, x.reshape(1, -1)])\n                archive_f = np.concatenate([archive_f, np.array([fx])])\n            else:\n                worst_idx = int(np.argmax(archive_f))\n                if fx < archive_f[worst_idx]:\n                    archive_X[worst_idx] = x\n                    archive_f[worst_idx] = fx\n            # keep arrays aligned but no full sort every time to save cost; sorting when needed\n\n        # initialize mean as weighted mean of top-half initial samples if possible\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        weights0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        weights0 = np.maximum(weights0, 0.0)\n        weights0 = weights0 / np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance: moderate isotropic scaled by bounds\n        bounds_scale = (ub - lb)\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = 0.25 * np.mean(bounds_scale)\n        sigma = max(sigma, 1e-8)\n\n        # strategy state\n        p_succ = self.success_target  # smoothed success estimate\n        stagn_iters = 0\n        iter_count = 0\n\n        # helper: safe cholesky/eig to obtain A s.t. A^T A = C\n        def chol_safe(Cmat):\n            eps = 1e-12 * np.maximum(np.diag(Cmat), 1.0)\n            try:\n                A = np.linalg.cholesky(Cmat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(Cmat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        # main loop: each iteration produce lam candidates (or fewer when nearing budget)\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu = max(1, lam_iter // 2)\n            # recompute weights\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # compute cholesky-like transform for covariance sampling\n            A = chol_safe(C)\n\n            # compose candidate pool: half Gaussian, half DE-style (if archive has enough)\n            n_gauss = lam_iter // 2\n            n_de = lam_iter - n_gauss\n\n            Xcand = np.empty((lam_iter, self.dim), dtype=float)\n            # 1) Gaussian proposals\n            if n_gauss > 0:\n                Z = rng.normal(size=(n_gauss, self.dim))\n                Y = Z @ (A.T)  # shape (n_gauss, dim)\n                Xg = m + sigma * Y\n                # clamp\n                Xg = np.minimum(np.maximum(Xg, lb), ub)\n                Xcand[:n_gauss] = Xg\n\n            # 2) Differential proposals from archive-driven DE (directed long-range moves)\n            if n_de > 0:\n                # ensure archive arrays exist and provide indices\n                if len(archive_f) < 3:\n                    # fallback to Gaussian\n                    Zd = rng.normal(size=(n_de, self.dim))\n                    Yd = Zd @ (A.T)\n                    Xd = m + sigma * Yd\n                    Xd = np.minimum(np.maximum(Xd, lb), ub)\n                    Xcand[n_gauss:] = Xd\n                else:\n                    # pick DE parents from archive uniformly\n                    # derive base vector from a random elite (biased towards best)\n                    # sort archive occasionally if needed\n                    idx_sort = np.argsort(archive_f)\n                    sorted_X = archive_X[idx_sort]\n                    sorted_f = archive_f[idx_sort]\n                    # mixture: choose base as best with prob, else random elite\n                    for i in range(n_de):\n                        # base selection (biased)\n                        if rng.rand() < 0.6:\n                            base = sorted_X[0]\n                        else:\n                            base = sorted_X[rng.randint(len(sorted_X))]\n                        # pick two other distincts\n                        idxs = rng.choice(len(sorted_X), size=2, replace=False)\n                        x1 = sorted_X[idxs[0]]\n                        x2 = sorted_X[idxs[1]]\n                        # differential vector\n                        diff = self.F_de * (x1 - x2)\n                        # crossover with target = base or m\n                        if rng.rand() < 0.5:\n                            target = base\n                        else:\n                            target = m\n                        # propose\n                        trial = target + diff\n                        # small Gaussian perturbation scaled by sigma to add exploration\n                        trial += rng.normal(scale=0.5 * sigma, size=self.dim)\n                        # crossover mask\n                        mask = rng.rand(self.dim) < self.CR\n                        if not np.any(mask):\n                            mask[rng.randint(self.dim)] = True\n                        # combine with target to honor crossover\n                        trial = np.where(mask, trial, target)\n                        # clamp\n                        trial = np.minimum(np.maximum(trial, lb), ub)\n                        Xcand[n_gauss + i] = trial\n\n            # evaluate candidates\n            f_cand = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                f_cand[i] = func(Xcand[i])\n            evals += lam_iter\n\n            # update archive with all candidates\n            for i in range(lam_iter):\n                archive_add(Xcand[i].copy(), float(f_cand[i]))\n\n            # find generation best\n            gen_best_idx = int(np.argmin(f_cand))\n            gen_best_f = float(f_cand[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n                stagn_iters = 0\n            else:\n                stagn_iters += 1\n\n            # selection: take top-mu of the candidate set\n            order = np.argsort(f_cand)\n            X_mu = Xcand[order[:mu]]\n\n            # compute new mean by weighted recombination\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # compute deltas (normalized by sigma) from both Gaussian proposals and DE proposals relative to old mean\n            # Using all selected elites to update covariance; this mixes information from DE steps too.\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas  # shape (dim, dim)\n\n            # extra regularization: add small isotropic floor scaled by bounds\n            floor = np.diag(((bounds_scale / 20.0) ** 2).clip(min=1e-12))\n\n            # update covariance with learning rate, include floor\n            C = (1.0 - self.cov_lr) * C + self.cov_lr * weighted_cov + 1e-12 * np.eye(self.dim)\n            # blend with floor to avoid collapse\n            C = 0.98 * C + 0.02 * floor\n\n            # update mean\n            m = m_new.copy()\n\n            # step-size adaptation via smoothed success-rate (approx 1/5th rule)\n            p_succ = 0.9 * p_succ + 0.1 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            # keep sigma in reasonable bounds\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n            # opportunistic Lévy-like jumps / restarts on stagnation\n            if stagn_iters >= self.stagnation_iters and evals < self.budget:\n                # with some probability perform a Lévy/Cauchy jump to escape\n                if rng.rand() < self.levy_prob:\n                    # pick an anchor from the top of archive (best or random elite)\n                    idx_sort = np.argsort(archive_f)\n                    anchor = archive_X[idx_sort[rng.randint(min(len(idx_sort), max(3, self.dim)))]]\n                    # Cauchy/Lévy style heavy-tailed jump: use standard Cauchy (t-distribution with df=1)\n                    # magnitude scaled by search-range and current sigma\n                    cauchy_scale = max(np.mean(bounds_scale) * 0.5, sigma * 5.0)\n                    jump = rng.standard_cauchy(size=self.dim) * cauchy_scale\n                    x_jump = anchor + jump\n                    x_jump = np.minimum(np.maximum(x_jump, lb), ub)\n                    # evaluate one candidate at jump\n                    fj = func(x_jump)\n                    evals += 1\n                    archive_add(x_jump.copy(), float(fj))\n                    if fj < f_best:\n                        f_best = float(fj)\n                        x_best = x_jump.copy()\n                        stagn_iters = 0\n                        # reset mean near new best and inflate sigma moderately\n                        m = x_jump.copy()\n                        sigma = max(sigma, 0.5 * np.mean(bounds_scale))\n                        # reset covariance to moderate isotropic\n                        C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                    else:\n                        # if jump didn't help, nudge mean toward best and inflate sigma slightly\n                        m = 0.7 * m + 0.3 * x_best\n                        sigma = min(2.0 * np.max(bounds_scale), sigma * 1.5)\n                else:\n                    # opportunistic restart: re-center around best with small jitter and reset covariance moderately\n                    m = x_best + rng.normal(scale=0.05 * np.maximum(bounds_scale, 1.0), size=self.dim)\n                    m = np.minimum(np.maximum(m, lb), ub)\n                    C = np.diag(((bounds_scale / 8.0) ** 2).clip(min=1e-12))\n                    sigma = max(sigma, 0.3 * np.mean(bounds_scale))\n                stagn_iters = 0  # reset after action\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridCMADE scored 0.812 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a1236766-1ad3-400a-8528-4b8b7eb992c8", "operator": null, "metadata": {"aucs": [0.3037212072744624, 0.9414328615100104, 0.9123196015336315, 0.9708925681524905, 0.9223964602645582, 0.9346378551165797, 0.34237897583542387, 0.9173517506627371, 0.9368173887427644, 0.9352107989507236]}, "task_prompt": ""}
{"id": "d69d92c9-8b06-4d06-bd45-db0cc1d62d31", "fitness": 0.5359824264157056, "name": "LevyDEPatternSearch", "description": "The method couples a compact current-to-pbest/1 Differential Evolution with jDE-style per-individual adaptation (F, CR with tau1=tau2=0.12 and F clipped to [0.05,0.95]) and a small population chosen as max(12, 4+3*log(dim)) to be budget-efficient. A small elite archive (3–8 members) seeds heavy‑tailed, Cauchy-like Levy/global jumps (global_jump_prob≈0.22) and the jump probability is adapted from archive diversity; diversity is also supported by quasi‑uniform stratified initialization and occasional uniform injections. Budget-aware machinery enforces a strict eval counter with bound reflection+clamp, and periodic or stagnation-triggered Hooke–Jeeves coordinate pattern local searches (initial_step_frac≈0.18, pattern_factor=1.5, shrink=0.6, local_budget_frac≈0.04) to intensify promising regions. Improvements are injected by replacing worst individuals, archive-guided local refinements are applied when a jump is promising, and several tunables (local_period=18, local_stagn_gen=28, archive size, etc.) steer the global–local balance for robust continuous optimization on BBOB-like tasks.", "code": "import numpy as np\n\nclass LevyDEPatternSearch:\n    \"\"\"\n    Levy-guided Differential Evolution with periodic Hooke-Jeeves refinements.\n\n    Main features:\n    - Compact current-to-pbest/1 DE with jDE-style F and CR adaptation per individual.\n    - Maintain small elite archive of best solutions; archive seeds Levy (Cauchy-like) global jumps.\n    - Periodic, budget-limited Hooke-Jeeves coordinate pattern searches around the best/archive members.\n    - Budget-aware eval wrapper, bound reflection+clamp, archive-driven adaptive global-jump probability,\n      and occasional uniform injections to maintain diversity.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # Tunables (sensible defaults)\n        self.p_frac = 0.2            # fraction for p-best pool\n        self.tau1 = 0.12             # prob to adapt F (jDE)\n        self.tau2 = 0.12             # prob to adapt CR (jDE)\n        self.F_min = 0.05\n        self.F_max = 0.95\n\n        self.local_period = 18       # generations between local refinements\n        self.local_stagn_gen = 28    # gens without improvement to trigger more aggressive local search\n        self.local_budget_frac = 0.04  # fraction of budget to spend on a local search call (soft)\n        self.pattern_factor = 1.5\n        self.shrink = 0.6\n        self.min_step_frac = 1e-5\n        self.initial_step_frac = 0.18\n\n        self.global_jump_prob = 0.22\n        self.archive_size = None     # auto-chosen based on pop/init_samples\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds handling (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # population size (small compact population)\n        pop = max(12, int(4 + 3 * np.log(max(2, self.dim))))\n        pop = min(pop, max(2, self.budget))\n        # archive size adaptive\n        if self.archive_size is None:\n            archive_k = max(3, min(8, pop // 2))\n        else:\n            archive_k = int(self.archive_size)\n\n        # budget counter and eval wrapper\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of tuples (f, x) sorted\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # clip to bounds\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = float(func(x))\n            evals += 1\n            # update best\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # archive maintenance\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # quasi-uniform initialization (stratified per-dim) like No.3\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter small\n        X += (rng.rand(pop, self.dim) - 0.5) * (0.5 * span / max(1.0, self.dim))\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            res = eval_and_record(X[i])\n            if res is None:\n                break\n            f[i], X[i] = res\n\n        # ensure we have at least one point\n        if x_best is None:\n            # sample uniformly a bit\n            while evals < self.budget:\n                x0 = rng.uniform(lb, ub)\n                res = eval_and_record(x0)\n                if res is None:\n                    break\n                break\n\n        # jDE-style F and CR initialization\n        F = np.clip(0.6 + 0.1 * rng.randn(pop), self.F_min, self.F_max)\n        CR = np.clip(rng.rand(pop), 0.0, 1.0)\n\n        # strategy state\n        gen = 0\n        gens_since_improve = 0\n        pnum_min = max(2, int(np.ceil(self.p_frac * pop)))\n\n        def reflect_bounds(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # heavy-tailed global jump (Cauchy-like directional)\n        def global_jump_from(x_center, scale):\n            direction = rng.randn(self.dim)\n            direction /= (np.linalg.norm(direction) + 1e-12)\n            step_length = rng.standard_cauchy()\n            step_length = np.clip(step_length, -1e3, 1e3)\n            step = direction * (float(scale) * avg_span * (0.4 + 0.6 * rng.rand()))\n            return x_center + step_length * step\n\n        # Hooke-Jeeves style local search (coordinate pattern) with strict local_budget\n        def local_search(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            # initial step scaled to bounds\n            step0 = max(1e-12, self.initial_step_frac * avg_span * (0.8 + 0.4 * rng.rand()))\n            steps = np.full(self.dim, step0, dtype=float)\n            local_evals = 0\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_evals < local_budget and iters < iter_limit and np.any(steps > (self.min_step_frac * avg_span)):\n                iters += 1\n                improved = False\n                x_probe = base.copy()\n                x_probe_f = base_f\n                for i in range(self.dim):\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    # plus\n                    xp = x_probe.copy()\n                    xp[i] = np.minimum(xp[i] + steps[i], ub[i])\n                    res = eval_and_record(xp)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < x_probe_f:\n                        x_probe = xp.copy()\n                        x_probe_f = fp\n                        improved = True\n                        continue\n                    # minus\n                    xn = x_probe.copy()\n                    xn[i] = np.maximum(xn[i] - steps[i], lb[i])\n                    res = eval_and_record(xn)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < x_probe_f:\n                        x_probe = xn.copy()\n                        x_probe_f = fn\n                        improved = True\n                # pattern move\n                if improved and local_evals < local_budget and evals < self.budget:\n                    direction = x_probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + self.pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_and_record(xp)\n                        local_evals += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < x_probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = x_probe.copy()\n                                base_f = x_probe_f\n                        else:\n                            base = x_probe.copy()\n                            base_f = x_probe_f\n                    else:\n                        base = x_probe.copy()\n                        base_f = x_probe_f\n                else:\n                    steps *= self.shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # Main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n            # ranking and p-best pool\n            order = np.argsort(f)\n            p_pool = order[:max(pnum_min, 2)]\n\n            # iterate individuals in random order\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n                # jDE adaptation\n                if rng.rand() < self.tau1:\n                    F[ii] = np.clip(0.4 + 0.4 * rng.rand(), self.F_min, self.F_max)\n                if rng.rand() < self.tau2:\n                    CR[ii] = rng.rand()\n\n                # choose p-best\n                pbest_idx = rng.choice(p_pool)\n                # pick r1,r2 distinct\n                pool = [j for j in range(pop) if j not in (ii, pbest_idx)]\n                if len(pool) < 2:\n                    r1 = r2 = ii\n                else:\n                    r1, r2 = rng.choice(pool, size=2, replace=False)\n\n                xi = X[ii].copy()\n                xp = X[pbest_idx].copy()\n                xr1 = X[r1].copy()\n                xr2 = X[r2].copy()\n\n                vi = xi + F[ii] * (xp - xi) + F[ii] * (xr1 - xr2)\n                # binomial crossover\n                jrand = rng.randint(self.dim)\n                mask = (rng.rand(self.dim) < CR[ii])\n                mask[jrand] = True\n                trial = np.where(mask, vi, xi)\n                trial = reflect_bounds(trial)\n\n                if evals >= self.budget:\n                    break\n                res = eval_and_record(trial)\n                if res is None:\n                    break\n                fv, trial = res\n                if fv <= f[ii]:\n                    X[ii] = trial\n                    f[ii] = fv\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = trial.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # Occasionally perform an archive-guided Levy jump (global exploration)\n            if len(archive) > 0 and rng.rand() < self.global_jump_prob:\n                # choose center from archive (prefer best)\n                center = archive[0][1] if rng.rand() < 0.75 else archive[rng.randint(0, len(archive))][1]\n                scale = max(0.06, 1.0 - 0.015 * gen)\n                cand = global_jump_from(center, scale)\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is not None:\n                    f_cand, cand = res\n                    # if promising, apply a small focused local search\n                    threshold = archive[0][0] * 1.08 if len(archive) > 0 else np.inf\n                    if f_cand <= threshold and evals < self.budget:\n                        local_alloc = min(int(self.local_budget_frac * self.budget) * 3, self.budget - evals)\n                        local_alloc = max(1, local_alloc)\n                        f_after, x_after = local_search(cand, f_cand, local_alloc)\n                        # inject improvement into population replacing worst\n                        if f_after < np.max(f):\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = x_after.copy()\n                            f[worst_idx] = f_after\n\n            # Periodic or stagnation-triggered local search around best\n            remaining = self.budget - evals\n            if remaining > 0 and (gen % self.local_period == 0 or gens_since_improve >= self.local_stagn_gen):\n                alloc = int(max(1, min(int(self.local_budget_frac * self.budget), remaining)))\n                # if stagnating, expand local budget\n                if gens_since_improve >= self.local_stagn_gen:\n                    alloc = min(remaining, alloc * 3)\n                f_after, x_after = local_search(x_best, f_best, alloc)\n                if f_after < f_best:\n                    # inject to population by replacing worst\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_after.copy()\n                    f[worst_idx] = f_after\n                    f_best = f_after\n                    x_best = x_after.copy()\n                    gens_since_improve = 0\n                else:\n                    # mild jitter nudges if still stagnating\n                    if gens_since_improve >= self.local_stagn_gen:\n                        nudges = min(pop // 2, max(1, int((gens_since_improve - self.local_stagn_gen + 1))))\n                        for k in range(nudges):\n                            if evals >= self.budget:\n                                break\n                            jitter = rng.randn(self.dim) * (0.04 * span)\n                            newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                            res = eval_and_record(newx)\n                            if res is None:\n                                break\n                            fv, newx = res\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = newx.copy()\n                            f[worst_idx] = fv\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = newx.copy()\n                                gens_since_improve = 0\n\n            # occasional uniform injection to keep diversity\n            if (gen % 23) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                res = eval_and_record(xu)\n                if res is not None:\n                    fu, xu = res\n                    # replace a random bad individual\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = xu.copy()\n                    f[worst_idx] = fu\n                    if fu < f_best:\n                        f_best = fu\n                        x_best = xu.copy()\n                        gens_since_improve = 0\n\n            # update archive from current population (keep best few)\n            # insert current best\n            if x_best is not None:\n                # ensure best recorded\n                if len(archive) < archive_k or f_best < archive[-1][0]:\n                    archive.append((float(f_best), x_best.copy()))\n                    archive.sort(key=lambda t: t[0])\n                    if len(archive) > archive_k:\n                        archive.pop()\n            # adapt global_jump_prob based on archive diversity\n            if len(archive) >= 2:\n                diversity = np.linalg.norm(archive[0][1] - archive[-1][1])\n                if diversity < 0.01 * avg_span + 1e-9:\n                    self.global_jump_prob = min(0.65, self.global_jump_prob + 0.03)\n                else:\n                    self.global_jump_prob = max(0.05, self.global_jump_prob * 0.996)\n\n            # ensure best tracked from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm LevyDEPatternSearch scored 0.536 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a1236766-1ad3-400a-8528-4b8b7eb992c8", "operator": null, "metadata": {"aucs": [0.13393380739527716, 0.2262101922622477, 0.7125244323361077, 0.9923648637628677, 0.8107696154245012, 0.8188478641532595, 0.30406460854393225, 0.5417852796787368, 0.6667855699565219, 0.15253803064360416]}, "task_prompt": ""}
{"id": "98b5d309-59bb-49ef-9442-6831b47dfff9", "fitness": 0.3619096042098535, "name": "AOP_TRLE", "description": "The algorithm uses a small population with mirrored‑opposition seeding for broad initial coverage and per‑individual trust radii (init_radius_frac, min_radius_frac) that mildly expand (radius_expand≈1.12) on success and shrink (radius_shrink≈0.88) on failure to balance local search and diversification. A diverse operator pool (directional diff‑to‑best, isotropic gaussian_local, elite recombination, heavy‑tailed Lévy/Cauchy jumps) is chosen probabilistically via adaptive credits (op_credit with decay≈0.9) so effective operators are favored over time. Bounds are handled by a reflect‑then‑clamp rule, successful moves trigger opportunistic extra steps, and periodic localized refinement around the current best (local_period, progressive sigma shrink) plus soft restarts (nudging half the population when stagnating) provide intensified exploitation and escape from stagnation. Strict budget accounting and parameter choices (moderate levy_scale_frac, small pop heuristic) aim for a robust exploration–exploitation balance across varying BBOB problems.", "code": "import numpy as np\n\nclass AOP_TRLE:\n    \"\"\"\n    Adaptive Operator Pool with Trust Regions and Lévy Escapes.\n\n    Main ideas:\n    - Small population initialized with mirrored-opposition seeding for coverage.\n    - Maintain per-individual trust radius that expands on success and shrinks on failure.\n    - A pool of diverse operators (directional diff-to-best, Gaussian local, elite recombination,\n      and heavy-tailed Lévy/Cauchy jumps). Operator selection probabilities adapt via credit assignment.\n    - Periodic localized Gaussian sampling (trust-region style) around current best for exploitation.\n    - Mild nudges (soft restarts) when stagnation is detected.\n    - Strict budget accounting and reflect-then-clamp bound handling.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 p_frac=0.2,\n                 local_period=25,\n                 local_stagn_gen=35,\n                 init_radius_frac=0.25,\n                 min_radius_frac=1e-5,\n                 radius_expand=1.12,\n                 radius_shrink=0.88,\n                 op_credit_decay=0.9,\n                 levy_scale_frac=0.5):\n        self.budget = int(budget)\n        self.dim = int(dim)\n\n        # user-tunable\n        self.pop_base = pop_base\n        self.p_frac = p_frac\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.init_radius_frac = float(init_radius_frac)\n        self.min_radius_frac = float(min_radius_frac)\n        self.radius_expand = float(radius_expand)\n        self.radius_shrink = float(radius_shrink)\n        self.op_credit_decay = float(op_credit_decay)\n        self.levy_scale_frac = float(levy_scale_frac)\n\n    def __call__(self, func):\n        rng = np.random.RandomState()  # local RNG\n\n        # Bounds from func (BBOB standard typically -5..5, but we use provided)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, float(lb), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, float(ub), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size: slightly different heuristic than original\n        if self.pop_base is None:\n            pop = max(12, int(5 + 2 * np.log(max(2, self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # mirrored-opposition initialization for broader coverage:\n        half = (pop + 1) // 2\n        X = np.empty((pop, self.dim), dtype=float)\n        # sample half uniformly, mirror them around center (lb+ub)/2\n        center = 0.5 * (lb + ub)\n        for i in range(half):\n            u = rng.rand(self.dim)\n            X[i] = lb + u * (ub - lb)\n            # mirrored point\n            j = i + half\n            if j < pop:\n                X[j] = 2.0 * center - X[i]\n        # jitter small random noise to break symmetry\n        X += (rng.randn(pop, self.dim) * 1e-3 * (ub - lb))\n        # clamp strictly\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # Evaluate initial population sequentially\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        # If budget exhausted already, return best\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-individual trust radii (scalar per individual, relative to mean range)\n        range_mean = float(np.mean(ub - lb))\n        init_radius = max(1e-12, self.init_radius_frac * range_mean)\n        min_radius = max(1e-12, self.min_radius_frac * range_mean)\n        radius = np.full(pop, init_radius, dtype=float)\n\n        # operator pool and their credit counters (success-weight)\n        # operators are indexed 0..3: diff_to_best, gaussian_local, elite_recomb, levy_jump\n        n_ops = 4\n        op_credit = np.ones(n_ops, dtype=float)  # initial neutral credit\n        # selection probabilities\n        def op_probabilities():\n            # softmax-ish but stable: normalize credits to probabilities\n            tot = np.sum(op_credit)\n            if tot <= 0:\n                return np.full_like(op_credit, 1.0 / len(op_credit))\n            return op_credit / tot\n\n        # helper: reflect once then clamp\n        def reflect_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # helper to draw Cauchy (heavy tailed) scaled vector\n        def cauchy_step(scale):\n            # standard Cauchy sampling via inverse CDF of uniform\n            # but numpy provides standard_cauchy\n            return rng.standard_cauchy(self.dim) * scale\n\n        # helper to pick elite indices\n        def elite_pool_indices():\n            k = max(2, int(np.ceil(self.p_frac * pop)))\n            return np.argsort(f)[:k]\n\n        # track best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        # bookkeeping for operator stats within a generation\n        op_success_counts = np.zeros(n_ops, dtype=float)\n        op_try_counts = np.zeros(n_ops, dtype=float)\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # recompute order and elites\n            order = np.argsort(f)\n            elites = order[:max(2, int(np.ceil(self.p_frac * pop)))]\n            # per-gen reset try counts (we accumulate successes for credit update afterwards)\n            op_try_counts[:] = 0.0\n            op_success_counts[:] = 0.0\n\n            # iterate individuals in random order\n            idxs = rng.permutation(pop)\n            probs = op_probabilities()\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fi = float(f[ii])\n\n                # operator selection\n                op_idx = rng.choice(n_ops, p=probs)\n                op_try_counts[op_idx] += 1.0\n\n                # operator implementations\n                trial = None\n\n                # 0: diff_to_best: directional move toward best with two-diff perturbation\n                if op_idx == 0:\n                    # pick two distinct others\n                    others = [j for j in range(pop) if j != ii]\n                    if len(others) >= 2:\n                        a, b = rng.choice(others, size=2, replace=False)\n                    else:\n                        a = b = ii\n                    beta = 0.8 * rng.rand() + 0.1  # scale [0.1,0.9]\n                    trial = xi + beta * (x_best - xi) + beta * (X[a] - X[b])\n\n                # 1: gaussian_local: isotropic Gaussian around xi scaled by radius\n                elif op_idx == 1:\n                    scale = radius[ii]\n                    trial = xi + rng.randn(self.dim) * (scale * (0.5 + rng.rand()))\n\n                # 2: elite_recomb: recombine with random elite member + small gaussian\n                elif op_idx == 2:\n                    elite_idx = int(rng.choice(elites))\n                    alpha = 0.5 * (1.0 + rng.rand())  # [0.5,1.0]\n                    trial = xi + alpha * (X[elite_idx] - xi) + rng.randn(self.dim) * 0.2 * radius[ii]\n\n                # 3: levy_jump: heavy-tail jump from current best (escape)\n                elif op_idx == 3:\n                    scale = self.levy_scale_frac * radius[ii]\n                    # occasional jump centered on best to help escape\n                    center = x_best if rng.rand() < 0.7 else xi\n                    trial = center + cauchy_step(scale)\n\n                # ensure we have a candidate\n                if trial is None:\n                    trial = xi.copy()\n\n                # reflect and clamp\n                trial = reflect_clamp(trial)\n\n                # opportunistic quick budget check\n                if evals >= self.budget:\n                    break\n\n                # evaluate trial\n                fv = float(func(trial))\n                evals += 1\n\n                # selection and trust radius adaptation\n                if fv <= fi:\n                    # success, accept\n                    X[ii] = trial\n                    f[ii] = fv\n                    # expand trust radius slightly\n                    radius[ii] = min(np.maximum(radius[ii] * self.radius_expand, min_radius), range_mean)\n                    op_success_counts[op_idx] += 1.0\n                    # directional exploitation: attempt a small step further in successful direction\n                    disp = trial - xi\n                    if np.any(np.isfinite(disp)) and np.linalg.norm(disp) > 0 and evals < self.budget:\n                        # take a fraction step further (opportunistic)\n                        extra_frac = 0.7 * rng.rand() + 0.1\n                        extra = trial + extra_frac * disp\n                        extra = reflect_clamp(extra)\n                        fv2 = float(func(extra))\n                        evals += 1\n                        if fv2 < f[ii]:\n                            X[ii] = extra\n                            f[ii] = fv2\n                            # expand radius again\n                            radius[ii] = min(radius[ii] * (1.0 + 0.05 * extra_frac), range_mean)\n                    # update global best if improved\n                    if f[ii] < f_best:\n                        f_best = float(f[ii])\n                        x_best = X[ii].copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # failure: shrink radius a bit\n                    radius[ii] = max(radius[ii] * self.radius_shrink, min_radius)\n\n                # early stop if budget used up\n                if evals >= self.budget:\n                    break\n\n            # end individuals loop\n\n            # credit update: exponentially decay old credits and add new successes\n            op_credit = self.op_credit_update(op_credit if hasattr(self, 'op_credit') else np.ones(n_ops),\n                                              op_success_counts, self.op_credit_decay)\n            # store for next iteration\n            self.op_credit = op_credit.copy()\n\n            # if no improvement this generation, increase stagnation counter\n            if not improved_in_gen:\n                gens_since_improve += 1\n            else:\n                gens_since_improve = 0\n\n            # periodic local refinement around the best\n            if gen % self.local_period == 0 or gens_since_improve >= self.local_stagn_gen:\n                # limited budget local sampling: progressive Gaussian sampling with shrinking sigma\n                remaining = self.budget - evals\n                if remaining <= 0:\n                    break\n\n                local_sigma = max(min_radius, 0.6 * radius.mean())  # start sigma\n                local_shrink = 0.5\n                local_iters = 0\n                local_improved = False\n                # progressively shrink sigma\n                while local_sigma >= min_radius and evals < self.budget and local_iters < 6:\n                    # number of samples proportional to dim but limited by budget\n                    n_samples = min(8 + self.dim, (self.budget - evals))\n                    for s in range(int(n_samples)):\n                        if evals >= self.budget:\n                            break\n                        candidate = x_best + rng.randn(self.dim) * local_sigma\n                        candidate = reflect_clamp(candidate)\n                        fv = float(func(candidate))\n                        evals += 1\n                        if fv < f_best:\n                            f_best = fv\n                            x_best = candidate.copy()\n                            local_improved = True\n                            # inject into population replacing worst\n                            worst = int(np.argmax(f))\n                            X[worst] = candidate.copy()\n                            f[worst] = fv\n                            gens_since_improve = 0\n                            # update radii of replaced individual\n                            radius[worst] = max(radius[worst] * 0.8, min_radius)\n                            # small opportunistic continue with same sigma\n                            if evals >= self.budget:\n                                break\n                    if local_improved:\n                        # if improved, try a few more samples at same sigma to exploit\n                        local_improved = False  # reset flag for next shrink stage\n                        # do a shorter additional sampling\n                        extra = min(4, self.budget - evals)\n                        for _ in range(int(extra)):\n                            if evals >= self.budget:\n                                break\n                            candidate = x_best + rng.randn(self.dim) * local_sigma * 0.6\n                            candidate = reflect_clamp(candidate)\n                            fv = float(func(candidate))\n                            evals += 1\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = candidate.copy()\n                                worst = int(np.argmax(f))\n                                X[worst] = candidate.copy()\n                                f[worst] = fv\n                                gens_since_improve = 0\n                    # shrink sigma for next round\n                    local_sigma *= local_shrink\n                    local_iters += 1\n\n                # if still stagnating after local attempts, do soft restarts (nudge half population)\n                if gens_since_improve >= self.local_stagn_gen:\n                    n_nudge = pop // 2\n                    for k in range(n_nudge):\n                        if evals >= self.budget:\n                            break\n                        idx_replace = np.argmax(f)\n                        jitter_scale = 0.08 * (ub - lb) * (1.0 + rng.rand(self.dim))\n                        candidate = x_best + rng.randn(self.dim) * jitter_scale\n                        candidate = reflect_clamp(candidate)\n                        fv = float(func(candidate))\n                        evals += 1\n                        X[idx_replace] = candidate\n                        f[idx_replace] = fv\n                        radius[idx_replace] = init_radius\n                        if fv < f_best:\n                            f_best = fv\n                            x_best = candidate.copy()\n                            gens_since_improve = 0\n\n            # safety update: reflect best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt\n\n    # helper method to update op_credit: decay old and add successes (keeps attribute-free update)\n    def op_credit_update(self, old_credit, success_counts, decay):\n        # decay old credit, add successes with small smoothing\n        new = old_credit * decay + success_counts * (1.0 - decay)\n        # ensure positivity (small floor)\n        new = np.maximum(new, 1e-8)\n        return new", "configspace": "", "generation": 0, "feedback": "The algorithm AOP_TRLE scored 0.362 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "4774ee81-1693-48fc-b906-4e1c3dd40998", "operator": null, "metadata": {"aucs": [0.18483734370649385, 0.1773710765353257, 0.5288259351537352, 0.6241865305953782, 0.2678988705187837, 0.7650622568972044, 0.21554560008054624, 0.4048074713474412, 0.2780089542100046, 0.17255200305362206]}, "task_prompt": ""}
{"id": "140086d9-7241-4560-a19e-2703a518521f", "fitness": 0.42402841828441395, "name": "DiagonalAdaptiveEvolution", "description": "The algorithm is a population-based heuristic that uses per-individual isotropic Gaussian mutations (sigma per individual, initially sigma_init_frac=0.3·range) combined with a strong pull toward the population mean (alpha_mean=0.7), per-coordinate mixing (individual mix_prob), Latin-like stratified initialization and reflect/clamp bounds handling to ensure diverse but biased sampling. Sigmas adapt via a windowed success history (window_len=12) with conservative decrease/increase multipliers (decrease_factor=0.92, increase_factor=1.07) and rare random sigma resets (tau_sigma_reset=0.05); mix_prob is also jittered occasionally to vary exploration/exploitation. Exploration enhancements include occasional opposition sampling (opposition_prob=0.15), opportunistic evaluation ordering, and a stagnation-driven mild restart that re-samples half the population around the best point, all while strictly counting evaluations to respect the budget. Local refinement is handled by frequent randomized coordinate-descent around the global best (local_period=10) with shrinking step sizes (local_init_frac=0.10, local_shrink=0.6) to exploit promising regions and inject improvements back into the population.", "code": "import numpy as np\n\nclass DiagonalAdaptiveEvolution:\n    \"\"\"\n    Diagonal-adaptive evolution:\n    - Population of individuals mutated by isotropic Gaussians with per-individual sigma.\n    - Each candidate is pulled partly towards the population mean (alpha_mean) to bias search.\n    - Per-individual sigma adapts with a success-based 1/5-like rule (windowed success rate).\n    - Occasional opposition sampling (evaluate mirrored point) for extra exploration.\n    - Periodic randomized coordinate-descent local search around the global best with shrinking steps.\n    - Budget-aware: never calls func more than self.budget times (evaluations counted sequentially).\n    -------------------------------------------------------------------------\n    Main tunable parameters (different from the provided algorithm):\n      - pop_base: default = max(20, int(6*sqrt(dim))) (larger than original small-pop)\n      - alpha_mean: 0.7 (pull towards mean)\n      - sigma_init_frac: 0.3 (initial sigma relative to search-range mean)\n      - sigma_min_frac: 1e-5, sigma_max_frac: 1.5 (clamping range)\n      - window_len: 12 (success-history length for adapt rule)\n      - decrease_factor: 0.92, increase_factor: 1.07 (sigma adaptation multipliers)\n      - tau_sigma_reset: 0.05 (rare chance to reinitialize sigma)\n      - local_period: 10 (more frequent local refinement)\n      - local_stagn_gen: 50 (stagnation threshold)\n      - local_init_frac: 0.10 (initial local step relative to range mean)\n      - local_shrink: 0.6, local_min_frac: 1e-5\n    -------------------------------------------------------------------------\n    This algorithm is designed as a novel heuristic alternative to classic DE+pattern hybrids.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 alpha_mean=0.7,\n                 sigma_init_frac=0.3,\n                 sigma_min_frac=1e-5,\n                 sigma_max_frac=1.5,\n                 window_len=12,\n                 decrease_factor=0.92,\n                 increase_factor=1.07,\n                 tau_sigma_reset=0.05,\n                 opposition_prob=0.15,\n                 local_period=10,\n                 local_stagn_gen=50,\n                 local_init_frac=0.10,\n                 local_shrink=0.6,\n                 local_min_frac=1e-5,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n\n        # Population sizing (different from provided algorithm)\n        self.pop_base = pop_base\n        self.alpha_mean = float(alpha_mean)\n\n        # sigma adaptation parameters\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.sigma_min_frac = float(sigma_min_frac)\n        self.sigma_max_frac = float(sigma_max_frac)\n        self.window_len = int(window_len)\n        self.decrease_factor = float(decrease_factor)\n        self.increase_factor = float(increase_factor)\n        self.tau_sigma_reset = float(tau_sigma_reset)\n        self.opposition_prob = float(opposition_prob)\n\n        # local search params\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.local_init_frac = float(local_init_frac)\n        self.local_shrink = float(local_shrink)\n        self.local_min_frac = float(local_min_frac)\n\n        # RNG (isolated)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # Bounds (Many-BBOB uses [-5,5], but read from func.bounds)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        range_vec = ub - lb\n        range_mean = float(np.mean(range_vec))\n        eps = 1e-12\n\n        # population size: choose moderate population to allow meaningful statistics\n        if self.pop_base is None:\n            pop = max(20, int(6 * np.sqrt(max(1, self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))  # cannot exceed budget\n\n        evals = 0\n\n        # Latin-like stratified initialization (per-dimension stratification)\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter a little to avoid ties\n        jitter_scale = 0.25 * range_mean / max(1.0, self.dim)\n        X += (rng.rand(pop, self.dim) - 0.5) * jitter_scale\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially (budget-aware)\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            fx = float(func(X[i]))\n            f[i] = fx\n            evals += 1\n\n        # if budget exhausted during init, return best so far\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-individual sigma (isotropic), CR-like mixing probability\n        sigma = np.full(pop, max(eps, self.sigma_init_frac * range_mean), dtype=float)\n        sigma_min = max(eps, self.sigma_min_frac * range_mean)\n        sigma_max = max(eps, self.sigma_max_frac * range_mean)\n        mix_prob = np.clip(0.2 + 0.2 * rng.rand(pop), 0.05, 0.9)\n\n        # success history for windowed adaptation\n        win = max(1, self.window_len)\n        success_hist = np.zeros((pop, win), dtype=np.int8)\n        hist_pos = 0\n\n        # tracking best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        def reflect_and_clamp(x):\n            # reflect once then clamp (cheap)\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        # main generation loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # compute mean of population (for mean-pull)\n            pop_mean = np.mean(X, axis=0)\n\n            # shuffle order\n            order = rng.permutation(pop)\n            # reset current generation success flags (we update hist at end of gen by writing one column)\n            gen_success = np.zeros(pop, dtype=np.int8)\n\n            for ii in order:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n\n                # occasional sigma reset for exploration\n                if rng.rand() < self.tau_sigma_reset:\n                    sigma[ii] = rng.rand() * (sigma_max - sigma_min) + sigma_min\n\n                # generate perturbation: pull towards mean plus gaussian noise\n                pull = self.alpha_mean * (pop_mean - xi)\n                gauss = rng.randn(self.dim) * sigma[ii]\n\n                trial = xi + pull + gauss\n\n                # mixing (like crossover): randomly keep some parent coords\n                mask = rng.rand(self.dim) < mix_prob[ii]\n                if not np.any(mask):\n                    # ensure at least one changed coordinate\n                    mask[rng.randint(self.dim)] = True\n                trial = np.where(mask, trial, xi)\n\n                # reflect/clamp\n                trial = reflect_and_clamp(trial)\n\n                # opposition sampling: with some probability evaluate mirrored point too\n                candidate_points = [trial]\n                if rng.rand() < self.opposition_prob:\n                    opp = lb + ub - trial\n                    # small jitter to avoid exact symmetry\n                    opp += (rng.randn(self.dim) * 0.01 * range_mean)\n                    opp = reflect_and_clamp(opp)\n                    candidate_points.append(opp)\n\n                # evaluate candidates in order, pick best (opportunistic; stop if budget exhausted)\n                best_local_x = None\n                best_local_f = np.inf\n                for xcand in candidate_points:\n                    if evals >= self.budget:\n                        break\n                    fv = float(func(xcand))\n                    evals += 1\n                    if fv < best_local_f:\n                        best_local_f = fv\n                        best_local_x = xcand.copy()\n\n                # selection: replace if better\n                if best_local_f <= f[ii]:\n                    X[ii] = best_local_x\n                    f[ii] = best_local_f\n                    gen_success[ii] = 1\n                    # update global best if needed\n                    if best_local_f < f_best:\n                        f_best = best_local_f\n                        x_best = best_local_x.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    gen_success[ii] = 0\n\n            # update success history circularly\n            success_hist[:, hist_pos] = gen_success\n            hist_pos = (hist_pos + 1) % win\n\n            # adapt sigma per individual based on windowed success rate\n            success_rate = np.sum(success_hist, axis=1) / float(win)\n            # if rate high -> reduce sigma (zoom in), else increase\n            for i in range(pop):\n                if success_rate[i] > 0.25:\n                    sigma[i] = max(sigma_min, sigma[i] * self.decrease_factor)\n                elif success_rate[i] < 0.15:\n                    sigma[i] = min(sigma_max, sigma[i] * self.increase_factor)\n                # occasionally jitter mix_prob a bit\n                if rng.rand() < 0.02:\n                    mix_prob[i] = np.clip(mix_prob[i] + (rng.randn() * 0.05), 0.01, 0.95)\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # Periodic or stagnation-driven local refinement: randomized coordinate descent\n            if gen % self.local_period == 0 or gens_since_improve >= self.local_stagn_gen:\n                remaining = self.budget - evals\n                if remaining <= 0:\n                    break\n\n                # local search parameters based on range_mean\n                step = max(eps, self.local_init_frac * range_mean)\n                min_step = max(eps, self.local_min_frac * range_mean)\n\n                # if heavily stagnating, start a larger step\n                if gens_since_improve >= self.local_stagn_gen:\n                    step *= 2.0\n\n                local_improved = False\n                x_work = x_best.copy()\n                f_work = f_best\n\n                # randomized coordinate order each local invocation to avoid bias\n                while step >= min_step and (self.budget - evals) > 0:\n                    moved = False\n                    dims_order = list(range(self.dim))\n                    rng.shuffle(dims_order)\n                    for d in dims_order:\n                        if evals >= self.budget:\n                            break\n                        # try a positive step\n                        x_try = x_work.copy()\n                        x_try[d] = min(ub[d], x_try[d] + step)\n                        if np.allclose(x_try, x_work):\n                            # if no change possible, try negative\n                            x_try[d] = max(lb[d], x_work[d] - step)\n                        # evaluate\n                        fv = float(func(x_try))\n                        evals += 1\n                        if fv < f_work:\n                            x_work = x_try.copy()\n                            f_work = fv\n                            moved = True\n                            local_improved = True\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = x_work.copy()\n                                gens_since_improve = 0\n                            # opportunistic extra along same direction (once)\n                            if evals < self.budget:\n                                x_try2 = x_work.copy()\n                                x_try2[d] = np.minimum(np.maximum(x_try2[d] + step, lb[d]), ub[d])\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < f_work:\n                                    x_work = x_try2.copy()\n                                    f_work = fv2\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = x_try2.copy()\n                                        gens_since_improve = 0\n                        else:\n                            # try opposite direction if not already tried\n                            if evals >= self.budget:\n                                break\n                            x_try = x_work.copy()\n                            x_try[d] = max(lb[d], x_work[d] - step)\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                x_work = x_try.copy()\n                                f_work = fv\n                                moved = True\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_try.copy()\n                                    gens_since_improve = 0\n\n                    if not moved:\n                        step *= self.local_shrink\n                    # loop continues until step too small or budget exhausted\n\n                # If local search found improvement, inject it into population (replace worst)\n                if local_improved:\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_work.copy()\n                    f[worst_idx] = f_work\n                    gens_since_improve = 0\n                else:\n                    # If local search failed and we are stagnating, perform mild restart: re-sample half population around best\n                    if gens_since_improve >= self.local_stagn_gen:\n                        half = pop // 2\n                        for k in range(half):\n                            if evals >= self.budget:\n                                break\n                            # Gaussian jitter around best, scale by average sigma\n                            avg_sigma = max(np.mean(sigma), sigma_min)\n                            jitter = rng.randn(self.dim) * (0.2 * range_mean)\n                            newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                            fv = float(func(newx))\n                            evals += 1\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = newx\n                            f[worst_idx] = fv\n                            sigma[worst_idx] = max(sigma_min, min(sigma_max, 0.5 * avg_sigma))\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = newx.copy()\n                                gens_since_improve = 0\n\n            # ensure we sync best from population (safe check)\n            current_best_idx = int(np.argmin(f))\n            if f[current_best_idx] < f_best:\n                f_best = float(f[current_best_idx])\n                x_best = X[current_best_idx].copy()\n                gens_since_improve = 0\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DiagonalAdaptiveEvolution scored 0.424 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "4774ee81-1693-48fc-b906-4e1c3dd40998", "operator": null, "metadata": {"aucs": [0.11171722977842513, 0.163736757540765, 0.6724696308958562, 0.9899308356595653, 0.2795493989982508, 0.853309202633815, 0.2759007316882862, 0.4384586983211475, 0.29341029978859345, 0.16180139753943512]}, "task_prompt": ""}
{"id": "93890e17-e490-4bd2-83de-00a7a8d5b2b0", "fitness": 0.2848117488763983, "name": "LevyPCAGuidedSearch", "description": "1) Hybrid operator mix and small cooperative population: the algorithm uses a modest, dimension-aware population (LHS-like init, pop ≈ 6+2√dim with caps) and probabilistically applies three complementary global moves — Lévy/Cauchy heavy-tailed jumps (p_levy=0.25) for long exploration, a stronger DE-style directed recombination (p_de=0.5) for guided crossover/exploitation, and PCA-projected sampling (p_pca=0.25) to exploit correlated directions — while per-individual log-normal adaptive scales sigma (tau_sigma=0.12, sigma_init=0.1) control step sizes relative to domain_scale.  \n2) Archive + PCA guidance: a bounded elite archive (kept to ≈4*pop) stores good samples and builds PCA via cheap power iterations (6–12 iters) to extract principal directions; PCA moves sample along dominant eigenvectors centered on elites and normalize steps by domain_scale for scale invariance.  \n3) Local directed exploitation and guarded line search: periodically (local_period=25) or on stagnation (stagn_threshold=30) the algorithm performs low-cost centered finite-difference along the top PCA direction, uses a guarded backtracking line-search with limited extra probes (max_dir_probes=6) to accept conservative improvements, and injects improvements by replacing worst individuals.  \n4) Robust, budget-aware mechanics and bounds handling: every eval is strictly counted and can trigger early stop, population/steps are scaled to the problem box, out-of-bounds are handled by reflect-then-clamp, Cauchy tails are truncated to avoid infinities, and mild diversification nudges are applied when stagnating.", "code": "import numpy as np\n\nclass LevyPCAGuidedSearch:\n    \"\"\"\n    Lévy-PCA Guided Search (novel heuristic)\n    - Small cooperative population with per-individual step scales.\n    - Global moves: mixture of Lévy flights (heavy-tailed jumps), DE-style directed recombination,\n      and PCA-projected sampling using the elite archive.\n    - Local directed exploitation: low-cost directional derivative estimates along PCA directions\n      and guarded backtracking steps (very few extra evals).\n    - Budget-aware, reflect-then-clamp bounds handling, and replacement of worst individuals by improvements.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 p_levy=0.25,      # probability to perform Lévy jump for an individual\n                 p_de=0.5,         # probability to use DE-like recombination\n                 p_pca=0.25,       # probability to sample along PCA direction\n                 tau_sigma=0.12,   # prob to adapt per-individual scale\n                 sigma_init=0.1,   # initial relative scale (fraction of domain)\n                 elite_frac=0.25,  # fraction used to build PCA\n                 local_period=25,  # generations between PCA-model local exploitations\n                 stagn_threshold=30, # gens without improvement to force exploitation\n                 max_dir_probes=6  # max extra evals in directional local step\n                 ):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.p_levy = float(p_levy)\n        self.p_de = float(p_de)\n        self.p_pca = float(p_pca)\n        self.tau_sigma = float(tau_sigma)\n        self.sigma_init = float(sigma_init)\n        self.elite_frac = float(elite_frac)\n        self.local_period = int(local_period)\n        self.stagn_threshold = int(stagn_threshold)\n        self.max_dir_probes = int(max_dir_probes)\n\n    def __call__(self, func):\n        rng = np.random.RandomState()  # isolated RNG\n\n        # Determine bounds: prefer func.bounds if available, else [-5,5]^dim\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # adaptive small population: slightly different formula than prior art\n        if self.pop_base is None:\n            pop = max(8, int(np.ceil(6 + 2.0 * np.sqrt(self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        # helper: reflect-then-clamp bounds\n        def reflect_clamp(x):\n            x = np.asarray(x, dtype=float).copy()\n            low = lb\n            high = ub\n            # reflect once\n            below = x < low\n            if np.any(below):\n                x[below] = low[below] + (low[below] - x[below])\n            above = x > high\n            if np.any(above):\n                x[above] = high[above] - (x[above] - high[above])\n            # final clamp\n            np.minimum(np.maximum(x, low), high, out=x)\n            return x\n\n        # small Lévy-like step generator (Cauchy-ish heavy tail but scaled)\n        def levy_step(scale, size):\n            # Use symmetric Cauchy for heavy tails; scale ~ domain * scale\n            # Avoid infinite values by truncating extreme samples\n            s = np.tan(np.pi * (rng.rand(*size) - 0.5))  # standard Cauchy via tan(pi*(u-0.5))\n            # truncate extreme tails\n            s = np.clip(s, -1e3, 1e3)\n            return scale * s\n\n        # initialize population via Latin-hypercube-like stratification\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / float(pop)\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter to break structure\n        X += (rng.rand(pop, self.dim) - 0.5) * 0.5 * (ub - lb) / max(1.0, self.dim)\n        # clamp\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        f = np.full(pop, np.inf, dtype=float)\n        evals = 0\n\n        # Evaluate initial population sequentially\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        if evals >= self.budget:\n            best_idx = int(np.nanargmin(f))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-individual scale (relative to domain size)\n        domain_scale = ub - lb\n        sigma = np.full(pop, self.sigma_init, dtype=float)\n\n        # keep an elite archive (small) to build PCA\n        archive_X = X.copy()\n        archive_f = f.copy()\n\n        # tracking\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n        gen = 0\n        gens_since_improve = 0\n\n        # helper to update archive with new candidate\n        def archive_add(x_new, f_new):\n            nonlocal archive_X, archive_f\n            archive_X = np.vstack([archive_X, x_new[np.newaxis, :]])\n            archive_f = np.concatenate([archive_f, np.array([f_new], dtype=float)])\n            # keep archive limited in size: say 4*pop\n            max_archive = max(4 * pop, pop + 10)\n            if archive_X.shape[0] > max_archive:\n                # keep best ones\n                order = np.argsort(archive_f)\n                keep = order[:max_archive]\n                archive_X = archive_X[keep]\n                archive_f = archive_f[keep]\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # build ranking\n            order = np.argsort(f)\n            elite_count = max(2, int(np.ceil(self.elite_frac * pop)))\n            elite_idx = order[:elite_count]\n\n            # perform one generation: produce candidate for each individual\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                x_i = X[ii].copy()\n                f_i = float(f[ii])\n\n                # adapt sigma occasionally (log-normal multiplicative)\n                if rng.rand() < self.tau_sigma:\n                    sigma[ii] *= np.exp(0.1 * rng.randn())\n                    sigma[ii] = np.clip(sigma[ii], 1e-6, 2.0)\n\n                # decide operator\n                r = rng.rand()\n                candidate = None\n\n                # 1) Lévy jump\n                if r < self.p_levy:\n                    # Lévy around current or around best with small prob\n                    center = x_i if rng.rand() < 0.7 else x_best\n                    step_scale = sigma[ii] * np.mean(domain_scale)\n                    # generate heavy-tailed vector with coordinate scaling\n                    step = levy_step(step_scale, (self.dim,))\n                    # damp step on each coordinate by domain scale\n                    step = step * (domain_scale / np.mean(domain_scale))\n                    candidate = reflect_clamp(center + step)\n\n                else:\n                    # 2) DE-like recombination (guided)\n                    if r < self.p_levy + self.p_de:\n                        # current-to-pbest/rand with adaptive mixing\n                        p = max(1, int(np.ceil(0.2 * pop)))\n                        pbest = X[rng.choice(order[:p])]\n                        # pick two others\n                        choices = [j for j in range(pop) if j != ii]\n                        if len(choices) >= 2:\n                            r1, r2 = rng.choice(choices, size=2, replace=False)\n                        else:\n                            r1 = r2 = ii\n                        v = x_i + 0.8 * (pbest - x_i) + 0.6 * (X[r1] - X[r2])\n                        # add small Gaussian noise proportional to sigma[ii]\n                        v = v + (rng.randn(self.dim) * sigma[ii] * domain_scale)\n                        candidate = reflect_clamp(v)\n\n                    else:\n                        # 3) PCA-projected sampling: sample along principal component of archive elites\n                        # Build PCA direction from archive or elite set\n                        if archive_X.shape[0] >= 3:\n                            # use best part of archive\n                            a_order = np.argsort(archive_f)\n                            topk = min(max(3, elite_count), archive_X.shape[0])\n                            Z = archive_X[a_order[:topk]] - np.mean(archive_X[a_order[:topk]], axis=0)\n                            # Covariance and principal eigenvector via power method (cheap)\n                            C = np.dot(Z.T, Z) / max(1.0, Z.shape[0])\n                            # power iteration for principal eigenvector\n                            v = rng.randn(self.dim)\n                            for _ in range(6):\n                                v = np.dot(C, v)\n                                norm = np.linalg.norm(v)\n                                if norm == 0:\n                                    break\n                                v /= norm\n                            pc = v\n                        else:\n                            # fallback random direction\n                            pc = rng.randn(self.dim)\n                            pc /= np.linalg.norm(pc)\n\n                        # sample along direction centered at a random elite\n                        center = X[rng.choice(elite_idx)]\n                        length = sigma[ii] * np.mean(domain_scale) * (1.0 + rng.rand() * 2.0)\n                        step = (rng.randn() * length) * pc\n                        candidate = reflect_clamp(center + step)\n\n                # evaluate candidate (if we have budget)\n                if candidate is None:\n                    candidate = x_i.copy()\n                if evals >= self.budget:\n                    break\n                f_cand = float(func(candidate))\n                evals += 1\n\n                # selection: replace if better\n                if f_cand < f_i:\n                    X[ii] = candidate\n                    f[ii] = f_cand\n                    archive_add(candidate, f_cand)\n                    if f_cand < f_best:\n                        f_best = f_cand\n                        x_best = candidate.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # Periodic low-cost PCA-directed local exploitation (few evals)\n            # We estimate directional derivative on top PCA directions and try guarded steps\n            if (gen % self.local_period == 0) or (gens_since_improve >= self.stagn_threshold):\n                if evals >= self.budget:\n                    break\n\n                # Build PCA from current archive or elite population\n                try:\n                    use_data = archive_X if archive_X.shape[0] >= 4 else X[order[:max(4, elite_count)]]\n                    # center\n                    M = np.mean(use_data, axis=0)\n                    Z = use_data - M\n                    # covariance\n                    C = np.dot(Z.T, Z) / max(1.0, Z.shape[0])\n                    # principal eigenvector via power iterations\n                    v = rng.randn(self.dim)\n                    for _ in range(12):\n                        v = np.dot(C, v)\n                        nrm = np.linalg.norm(v)\n                        if nrm == 0:\n                            break\n                        v /= nrm\n                    pc1 = v / (np.linalg.norm(v) + 1e-16)\n                except Exception:\n                    pc1 = rng.randn(self.dim)\n                    pc1 /= np.linalg.norm(pc1)\n\n                # perform up to max_dir_probes directional probes starting from x_best\n                # compute small epsilon for finite diff proportional to sigma of best (estimate)\n                eps = max(1e-8, 1e-3 * np.linalg.norm(domain_scale) * np.median(sigma))\n                probes_done = 0\n                # centered two-sided finite difference along pc1 (cost 2 evals)\n                if evals + 2 <= self.budget:\n                    x_fwd = reflect_clamp(x_best + eps * pc1)\n                    x_bwd = reflect_clamp(x_best - eps * pc1)\n                    f_fwd = float(func(x_fwd)); evals += 1\n                    f_bwd = float(func(x_bwd)); evals += 1\n                    probes_done += 2\n                    # central derivative estimate\n                    deriv = (f_fwd - f_bwd) / (2.0 * eps)\n                    # propose a step in negative derivative direction (line search with guarded backtracking)\n                    if abs(deriv) > 1e-12:\n                        # initial step length scaled to domain and local curvature heuristic\n                        step0 = (1.0 / (1.0 + abs(deriv))) * np.mean(domain_scale) * 0.2\n                        # try decreasing factors alpha\n                        alphas = [1.0, 0.5, 0.25, 0.125]\n                        improved_local = False\n                        best_local_x = x_best.copy()\n                        best_local_f = f_best\n                        for a in alphas:\n                            if probes_done >= self.max_dir_probes or evals >= self.budget:\n                                break\n                            step = -np.sign(deriv) * a * step0\n                            x_try = reflect_clamp(x_best + step * pc1)\n                            f_try = float(func(x_try)); evals += 1\n                            probes_done += 1\n                            if f_try < best_local_f:\n                                best_local_f = f_try\n                                best_local_x = x_try.copy()\n                                improved_local = True\n                                # small opportunistic extension: try one more forward in same direction\n                                if probes_done < self.max_dir_probes and evals < self.budget:\n                                    x_try2 = reflect_clamp(x_try + step * pc1)\n                                    f_try2 = float(func(x_try2)); evals += 1\n                                    probes_done += 1\n                                    if f_try2 < best_local_f:\n                                        best_local_f = f_try2\n                                        best_local_x = x_try2.copy()\n                                break  # keep first improving alpha (conservative)\n                        if improved_local:\n                            # inject into population replacing worst\n                            worst = int(np.argmax(f))\n                            X[worst] = best_local_x.copy()\n                            f[worst] = best_local_f\n                            archive_add(best_local_x, best_local_f)\n                            if best_local_f < f_best:\n                                f_best = best_local_f\n                                x_best = best_local_x.copy()\n                                gens_since_improve = 0\n                                improved_in_gen = True\n\n                # If still stagnating strongly, perform mild population diversification near best\n                if (not improved_in_gen) and (gens_since_improve >= self.stagn_threshold):\n                    # nudge a fraction of population around x_best with small Gaussian jitter\n                    nudge_count = max(1, pop // 3)\n                    for k in range(nudge_count):\n                        if evals >= self.budget:\n                            break\n                        jitter = 0.06 * (domain_scale) * rng.randn(self.dim)\n                        x_new = reflect_clamp(x_best + jitter)\n                        f_new = float(func(x_new)); evals += 1\n                        # replace a random worse-than-median individual\n                        med = np.median(f)\n                        candidates = np.where(f > med)[0]\n                        if candidates.size == 0:\n                            replace_idx = int(np.argmax(f))\n                        else:\n                            replace_idx = int(rng.choice(candidates))\n                        X[replace_idx] = x_new\n                        f[replace_idx] = f_new\n                        archive_add(x_new, f_new)\n                        if f_new < f_best:\n                            f_best = f_new\n                            x_best = x_new.copy()\n                            gens_since_improve = 0\n                            improved_in_gen = True\n\n            # ensure best is synced with population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n            # terminate early if budget exhausted\n            if evals >= self.budget:\n                break\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm LevyPCAGuidedSearch scored 0.285 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "4774ee81-1693-48fc-b906-4e1c3dd40998", "operator": null, "metadata": {"aucs": [0.1589734646902543, 0.1591990389874991, 0.3625090078827312, 0.5552381442000831, 0.2447766327694435, 0.35881092722288055, 0.2517031632421777, 0.3199689450035966, 0.2720278436257032, 0.16491032113961435]}, "task_prompt": ""}
{"id": "dd291d53-01ec-4a34-9cd6-09226201dd4e", "fitness": 0.4193371448168743, "name": "DirectionalAdaptiveSearch", "description": "The algorithm is a small-population, DE-style search that trades population size (pop = max(8, 2*sqrt(dim)+4) capped by budget) for many generations and uses a centroid-directed mutation (xi + F*(centroid-xi) + F*(xr1-xr2)) to bias search toward promising regions while retaining differential diversity. It adapts step parameters with a SHADE-like memory (H default 10) where F is sampled from a Cauchy around mem_F and CR from a normal around mem_CR, and successful Fi/CR updates use a weighted Lehmer mean/arithmetic mean with a conservative 0.9/0.1 memory smoothing. Exploration is boosted by rare Lévy-like jumps (≈3% chance, heavy‑tailed scale), periodic opportunistic doubling line probes (every local_period=25, with initial_step_frac=0.2 and min_step_frac=1e-4) and a stagnation-triggered half-population reseed (stagnation_restart=45) around the best. Initialization is quasi-uniform per-dimension stratification plus jitter, bounds are handled by reflect-then-clamp, and improvements are injected by replacing worst individuals and synchronizing a global best.", "code": "import numpy as np\n\nclass DirectionalAdaptiveSearch:\n    \"\"\"\n    Directional Adaptive Search with Lévy-like jumps and SHADE-style memory (DAS-LJ).\n\n    Main ideas:\n    - Small, quasi-uniform population to allow many generations.\n    - SHADE-like memory for F and CR (Lehmer mean update) to adapt step sizes over time.\n    - Mutation uses a centroid-directed component plus differential information:\n        mutant = xi + F * (centroid - xi) + F * (xr1 - xr2)\n      (centroid encourages convergence to promising region while differential term keeps diversity).\n    - Binomial crossover.\n    - Simple reflect-then-clamp bound handling.\n    - Periodic cheap random-direction line probing (opportunistic doubling search) around the best.\n    - On long stagnation, mild half-population re-seeding around the best to regain diversity.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, pop_base=None,\n                 H=10, p_frac=0.2, initial_step_frac=0.2, min_step_frac=1e-4,\n                 local_period=25, stagnation_restart=45, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        # memory length for SHADE-like adaptation\n        self.H = int(H)\n        self.p_frac = float(p_frac)\n        # local probing parameters\n        self.initial_step_frac = float(initial_step_frac)\n        self.min_step_frac = float(min_step_frac)\n        self.local_period = int(local_period)\n        self.stagnation_restart = int(stagnation_restart)\n        # RNG seed (optional)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        # local RNG\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size (different heuristic than the provided algorithm)\n        if self.pop_base is None:\n            pop = max(8, int(2 * np.sqrt(max(1, self.dim)) + 4))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))  # cannot exceed budget\n\n        evals = 0\n\n        # initialize population quasi-uniformly (simple per-dim stratification)\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter slightly\n        X += (rng.rand(pop, self.dim) - 0.5) * (0.4 * (ub - lb) / max(1.0, self.dim))\n        # clamp\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.empty(pop, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        # if budget exhausted during init\n        if evals >= self.budget:\n            best_idx = np.argmin(f[:i + 1])\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # SHADE-like memory for F and CR\n        H = max(1, int(self.H))\n        mem_F = np.full(H, 0.5, dtype=float)\n        mem_CR = np.full(H, 0.5, dtype=float)\n        mem_pos = 0\n\n        # per-individual parameters (for book-keeping; will be sampled each trial)\n        F_pop = np.clip(0.5 + 0.1 * rng.randn(pop), 0.05, 0.95)\n        CR_pop = np.clip(rng.rand(pop), 0.0, 1.0)\n\n        # best tracking\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        def reflect_clamp(x):\n            # reflect once then clamp\n            xr = x.copy()\n            low = lb\n            high = ub\n            below = xr < low\n            if np.any(below):\n                xr[below] = low[below] + (low[below] - xr[below])\n            above = xr > high\n            if np.any(above):\n                xr[above] = high[above] - (xr[above] - high[above])\n            xr = np.minimum(np.maximum(xr, low), high)\n            return xr\n\n        pnum_min = max(2, int(np.ceil(self.p_frac * pop)))\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # ranking\n            order = np.argsort(f)\n            # centroid of top p\n            p_pool = order[:max(pnum_min, 2)]\n            centroid = np.mean(X[p_pool], axis=0)\n\n            # prepare success lists for memory update\n            succ_F = []\n            succ_CR = []\n            succ_w = []  # weights for Lehmer mean update (use improvement magnitude based weights)\n\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                # sample a memory index and sample F and CR from memory (SHADE style)\n                mem_idx = rng.randint(H)\n                # sample F from Cauchy around mem_F[mem_idx]\n                # fallback to uniform if numerical issues\n                attempts = 0\n                Fi = None\n                while attempts < 5:\n                    Fi = mem_F[mem_idx] + 0.1 * rng.standard_cauchy()\n                    if Fi > 1e-6:\n                        break\n                    attempts += 1\n                if Fi is None or not np.isfinite(Fi):\n                    Fi = 0.5\n                Fi = float(np.clip(Fi, 0.01, 1.0))\n\n                # sample CR from normal around mem_CR[mem_idx]\n                CRi = float(np.clip(mem_CR[mem_idx] + 0.1 * rng.randn(), 0.0, 1.0))\n\n                F_pop[ii] = Fi\n                CR_pop[ii] = CRi\n\n                # select r1, r2 distinct from ii\n                pool = [j for j in range(pop) if j != ii]\n                if len(pool) >= 2:\n                    r1, r2 = rng.choice(pool, size=2, replace=False)\n                elif len(pool) == 1:\n                    r1 = pool[0]; r2 = pool[0]\n                else:\n                    r1 = r2 = ii\n\n                xi = X[ii]\n                xr1 = X[r1]\n                xr2 = X[r2]\n\n                # mutation: centroid-directed + differential term (different equation from provided alg)\n                vi = xi + Fi * (centroid - xi) + Fi * (xr1 - xr2)\n\n                # occasional Lévy-like random jump (very small probability) to escape local traps\n                if rng.rand() < 0.03:\n                    # approximate heavy-tailed jump by scaled normal with random large scale\n                    scale = (ub - lb) * (0.05 + 2.0 * (rng.rand() ** -0.7))  # heavy tail surrogate\n                    vi = xi + rng.randn(self.dim) * scale\n\n                # crossover (binomial)\n                jrand = rng.randint(self.dim)\n                mask = rng.rand(self.dim) < CRi\n                mask[jrand] = True\n                trial = np.where(mask, vi, xi)\n\n                # bound handling\n                trial = reflect_clamp(trial)\n\n                # evaluate if budget allows\n                if evals >= self.budget:\n                    break\n                fv = float(func(trial))\n                evals += 1\n\n                # selection\n                if fv <= f[ii]:\n                    # success: replace\n                    X[ii] = trial\n                    f[ii] = fv\n                    # record success params and weight\n                    succ_F.append(Fi)\n                    succ_CR.append(CRi)\n                    # weight proportional to improvement magnitude\n                    w = max(1e-12, abs(f[ii] - fv))  # f[ii] already updated but original parent value unknown; approximate using f[ii] as current\n                    succ_w.append(w)\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = trial.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # SHADE-like memory update if there were successes\n            if len(succ_F) > 0:\n                succ_F = np.asarray(succ_F)\n                succ_CR = np.asarray(succ_CR)\n                succ_w = np.asarray(succ_w)\n                # Lehmer mean for F\n                if np.sum(succ_w) > 0:\n                    w = succ_w / np.sum(succ_w)\n                else:\n                    w = np.ones_like(succ_w) / len(succ_w)\n                # Lehmer mean\n                numer = np.sum(w * (succ_F ** 2))\n                denom = np.sum(w * succ_F) + 1e-12\n                new_mF = numer / denom\n                # arithmetic mean for CR (weighted)\n                new_mCR = np.sum(w * succ_CR)\n                # store into memory circularly (use mem_pos)\n                mem_F[mem_pos] = 0.9 * mem_F[mem_pos] + 0.1 * float(np.clip(new_mF, 1e-3, 1.0))\n                mem_CR[mem_pos] = 0.9 * mem_CR[mem_pos] + 0.1 * float(np.clip(new_mCR, 0.0, 1.0))\n                mem_pos = (mem_pos + 1) % H\n\n            # Periodic or stagnation-triggered local random-direction probing\n            if (gen % self.local_period == 0) or (gens_since_improve >= self.stagnation_restart):\n                remaining = self.budget - evals\n                if remaining > 0:\n                    range_mean = np.mean(ub - lb)\n                    step0 = max(1e-12, self.initial_step_frac * range_mean)\n                    min_step = max(1e-12, self.min_step_frac * range_mean)\n                    if gens_since_improve >= self.stagnation_restart:\n                        step0 *= 2.0  # try bigger steps if stagnating\n\n                    local_improved = False\n                    x_work = x_best.copy()\n                    f_work = f_best\n\n                    # probe a few random directions (cheap)\n                    n_dirs = min(4, self.dim)\n                    for di in range(n_dirs):\n                        if evals >= self.budget:\n                            break\n                        # random direction normalized\n                        dvec = rng.randn(self.dim)\n                        dn = np.linalg.norm(dvec)\n                        if dn == 0.0:\n                            continue\n                        dvec /= dn\n\n                        step = step0\n                        # opportunistic doubling line search along dvec\n                        while step >= min_step and (self.budget - evals) > 0:\n                            # try positive\n                            x_try = x_work + dvec * step\n                            x_try = np.minimum(np.maximum(x_try, lb), ub)\n                            # skip if identical\n                            if np.allclose(x_try, x_work):\n                                # try negative\n                                x_try = x_work - dvec * step\n                                x_try = np.minimum(np.maximum(x_try, lb), ub)\n                                if np.allclose(x_try, x_work):\n                                    break\n                            # evaluate\n                            if evals >= self.budget:\n                                break\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                # accept and try doubling\n                                x_work = x_try\n                                f_work = fv\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_try.copy()\n                                    gens_since_improve = 0\n                                # attempt to double step opportunistically\n                                step *= 2.0\n                                # continue along this direction while budget remains\n                                if evals >= self.budget:\n                                    break\n                            else:\n                                # try opposite direction once\n                                x_try2 = x_work - dvec * step\n                                x_try2 = np.minimum(np.maximum(x_try2, lb), ub)\n                                if np.allclose(x_try2, x_work):\n                                    # no move possible, reduce step\n                                    step *= 0.5\n                                    continue\n                                if evals >= self.budget:\n                                    break\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < f_work:\n                                    x_work = x_try2\n                                    f_work = fv2\n                                    local_improved = True\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = x_try2.copy()\n                                        gens_since_improve = 0\n                                    step *= 2.0\n                                    if evals >= self.budget:\n                                        break\n                                else:\n                                    # reduce step\n                                    step *= 0.5\n\n                    # inject local improvement into population replacing worst\n                    if local_improved:\n                        worst_idx = int(np.argmax(f))\n                        X[worst_idx] = x_work.copy()\n                        f[worst_idx] = f_work\n                        gens_since_improve = 0\n                    else:\n                        # if stagnating and no improvement, reseed half of population around best\n                        if gens_since_improve >= self.stagnation_restart:\n                            half = pop // 2\n                            for k in range(half):\n                                if evals >= self.budget:\n                                    break\n                                jitter = rng.randn(self.dim) * (0.06 * (ub - lb))\n                                newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                                fv = float(func(newx))\n                                evals += 1\n                                worst_idx = int(np.argmax(f))\n                                X[worst_idx] = newx\n                                f[worst_idx] = fv\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = newx.copy()\n                                    gens_since_improve = 0\n\n            # conservative synchronization of best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DirectionalAdaptiveSearch scored 0.419 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "4774ee81-1693-48fc-b906-4e1c3dd40998", "operator": null, "metadata": {"aucs": [0.1393448098084069, 0.1716889333052265, 0.8493878043940839, 0.9074759130886679, 0.24781876510804313, 0.7618938993317697, 0.29685149707062597, 0.34707093898920094, 0.25855537955470764, 0.21328350751801028]}, "task_prompt": ""}
{"id": "bb3480f9-49d6-486a-8da6-7beaf8ccece9", "fitness": 0.4125159641900761, "name": "AdaptiveDE_DirectionalLocalSearch", "description": "The algorithm combines a compact, quasi‑uniform stratified initialization with jDE-style self-adaptive F and CR per individual and a small population (pop = max(12, 4+3·log dim)) to keep evaluations efficient. It uses a hybrid mutation scheme dominated by current-to-pbest/1 (exploitation) with a small probability of rand/1 (exploration, strategy_mix_prob=0.1) and a modest adaptation rate (tau1,tau2=0.1) and F range (0.05–0.9). Successful trial step vectors are kept in a short history (success_hist_len=12) and an SVD-derived principal direction is used to drive budget‑aware directional line searches plus opportunistic extra probes and anisotropic coordinate (Hooke–Jeeves-like) moves with geometric step shrinking, all using reflect-then-clamp bounds handling. Local improvements are injected by replacing the worst individual, and prolonged stagnation triggers mild jittered restarts of half the population; key timing parameters (local_period=18, local_stagn_gen=28, initial_step_frac=0.2) bias the method toward periodic, budget‑conscious local refinement.", "code": "import numpy as np\n\nclass AdaptiveDE_DirectionalLocalSearch:\n    \"\"\"\n    AdaptiveDE-DirectionalLocalSearch (ADE-DLS)\n\n    - Small quasi-uniform initial population (per-dimension stratification + jitter).\n    - jDE-style self-adaptive F and CR per individual.\n    - Current-to-pbest/1 primary mutation, with occasional rand/1 exploration (strategy mixing).\n    - Maintain a short history of successful step vectors; compute principal direction (SVD) to guide\n      cheap directional line-search probes and anisotropic coordinate probes periodically.\n    - Opportunistic extra probes, reflect-then-clamp bounds handling, inject local improvements\n      by replacing worst individual, and mild jitter restarts on stagnation.\n    - Fully budget-aware (never exceeds self.budget calls to func).\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 p_frac=0.2,\n                 tau1=0.1, tau2=0.1,\n                 F_min=0.05, F_max=0.9,\n                 local_period=18, local_stagn_gen=28,\n                 initial_step_frac=0.20, min_step_frac=1e-5, step_shrink=0.5,\n                 strategy_mix_prob=0.1, success_hist_len=12):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.p_frac = float(p_frac)\n        self.tau1 = float(tau1)\n        self.tau2 = float(tau2)\n        self.F_min = float(F_min)\n        self.F_max = float(F_max)\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.initial_step_frac = float(initial_step_frac)\n        self.min_step_frac = float(min_step_frac)\n        self.step_shrink = float(step_shrink)\n        self.strategy_mix_prob = float(strategy_mix_prob)\n        self.success_hist_len = int(success_hist_len)\n\n    def __call__(self, func):\n        rng = np.random.RandomState()\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size\n        pop = max(12, int(4 + 3 * np.log(max(2, self.dim))))\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # initialize population quasi-uniformly\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter to break ties\n        jitter_scale = 0.5 * (ub - lb) / max(1.0, self.dim)\n        X += (rng.rand(pop, self.dim) - 0.5) * jitter_scale\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.empty(pop, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        if evals >= self.budget:\n            best_idx = np.argmin(f[:i+1])\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-individual F and CR (jDE init)\n        F = np.clip(0.5 + 0.1 * rng.randn(pop), self.F_min, self.F_max)\n        CR = np.clip(rng.rand(pop), 0.0, 1.0)\n\n        # tracking\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n        gen = 0\n        gens_since_improve = 0\n\n        # history of successful step vectors (x_new - x_old), limited length\n        success_steps = []\n\n        def reflect_then_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        pnum_min = max(2, int(np.ceil(self.p_frac * pop)))\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            order = np.argsort(f)\n            p_pool = order[:max(pnum_min, 2)]\n\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                # adapt F and CR jDE-style\n                if rng.rand() < self.tau1:\n                    F[ii] = np.clip(0.5 * (1.0 + 0.5 * rng.randn()), self.F_min, self.F_max)\n                if rng.rand() < self.tau2:\n                    CR[ii] = rng.rand()\n\n                # strategy mixing: mostly current-to-pbest/1, with small prob rand/1\n                if rng.rand() < self.strategy_mix_prob:\n                    # rand/1\n                    idxs_pool = [j for j in range(pop) if j != ii]\n                    if len(idxs_pool) < 3:\n                        r1 = r2 = r3 = ii\n                    else:\n                        r1, r2, r3 = rng.choice(idxs_pool, size=3, replace=False)\n                    vi = X[r1] + F[ii] * (X[r2] - X[r3])\n                else:\n                    # current-to-pbest/1\n                    pbest_idx = int(rng.choice(p_pool))\n                    idxs_pool = [j for j in range(pop) if j not in (ii, pbest_idx)]\n                    if len(idxs_pool) < 2:\n                        r1 = r2 = ii\n                    else:\n                        r1, r2 = rng.choice(idxs_pool, size=2, replace=False)\n                    xi = X[ii]\n                    xp = X[pbest_idx]\n                    xr1 = X[r1]\n                    xr2 = X[r2]\n                    vi = xi + F[ii] * (xp - xi) + F[ii] * (xr1 - xr2)\n\n                # binomial crossover\n                jrand = rng.randint(self.dim)\n                mask = rng.rand(self.dim) < CR[ii]\n                mask[jrand] = True\n                trial = np.where(mask, vi, X[ii])\n                trial = reflect_then_clamp(trial)\n\n                if evals >= self.budget:\n                    break\n                fv = float(func(trial))\n                evals += 1\n\n                # selection\n                if fv <= f[ii]:\n                    # store successful step vector\n                    step_vec = trial - X[ii]\n                    if np.linalg.norm(step_vec) > 0:\n                        success_steps.append(step_vec.copy())\n                        if len(success_steps) > self.success_hist_len:\n                            success_steps.pop(0)\n                    X[ii] = trial\n                    f[ii] = fv\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = trial.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # periodic or stagnation-triggered local directional search + anisotropic coordinate probes\n            do_local = (gen % self.local_period == 0) or (gens_since_improve >= self.local_stagn_gen)\n            if do_local and (evals < self.budget):\n                remaining = self.budget - evals\n                if remaining <= 0:\n                    break\n\n                range_mean = np.mean(ub - lb)\n                step = max(1e-12, self.initial_step_frac * range_mean)\n                min_step = max(1e-12, self.min_step_frac * range_mean)\n                if gens_since_improve >= self.local_stagn_gen:\n                    step *= 2.0\n\n                local_improved = False\n                x_work = x_best.copy()\n                f_work = f_best\n\n                # compute principal direction from success_steps if available\n                principal_dir = None\n                if len(success_steps) >= 2:\n                    S = np.vstack(success_steps)\n                    try:\n                        # center rows\n                        S_centered = S - S.mean(axis=0, keepdims=True)\n                        # compute first right-singular vector\n                        u, svals, vh = np.linalg.svd(S_centered, full_matrices=False)\n                        principal_dir = vh[0]\n                        # normalize\n                        nrm = np.linalg.norm(principal_dir)\n                        if nrm > 0:\n                            principal_dir = principal_dir / nrm\n                        else:\n                            principal_dir = None\n                    except Exception:\n                        principal_dir = None\n\n                # directional line-search using principal direction then coordinate probes\n                while step >= min_step and (self.budget - evals) > 0:\n                    moved = False\n\n                    # first try principal direction if available\n                    if principal_dir is not None and (self.budget - evals) > 0:\n                        for sign in (+1.0, -1.0):\n                            if evals >= self.budget:\n                                break\n                            x_try = x_work + sign * step * principal_dir\n                            x_try = reflect_then_clamp(x_try)\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                # opportunistic further probe in same direction\n                                if evals < self.budget:\n                                    x_try2 = x_try + sign * step * principal_dir\n                                    x_try2 = reflect_then_clamp(x_try2)\n                                    fv2 = float(func(x_try2))\n                                    evals += 1\n                                    if fv2 < fv:\n                                        x_try, fv = x_try2, fv2\n                                # accept\n                                step_vec = x_try - x_work\n                                if np.linalg.norm(step_vec) > 0:\n                                    success_steps.append(step_vec.copy())\n                                    if len(success_steps) > self.success_hist_len:\n                                        success_steps.pop(0)\n                                x_work = x_try\n                                f_work = fv\n                                moved = True\n                                local_improved = True\n                                if f_work < f_best:\n                                    f_best = f_work\n                                    x_best = x_work.copy()\n                                    gens_since_improve = 0\n                                break\n\n                    # then anisotropic coordinate probes (Hooke-Jeeves style but with per-dim scaling)\n                    if (self.budget - evals) <= 0:\n                        break\n                    for d in range(self.dim):\n                        if evals >= self.budget:\n                            break\n                        # plus direction\n                        x_try = x_work.copy()\n                        x_try[d] = x_try[d] + step\n                        x_try = reflect_then_clamp(x_try)\n                        if np.allclose(x_try, x_work):\n                            # try minus\n                            x_try = x_work.copy()\n                            x_try[d] = x_try[d] - step\n                            x_try = reflect_then_clamp(x_try)\n                        fv = float(func(x_try))\n                        evals += 1\n                        if fv < f_work:\n                            # opportunistic extra probe further in same sense\n                            if evals < self.budget:\n                                x_try2 = x_try.copy()\n                                x_try2[d] = x_try2[d] + np.sign(x_try[d] - x_work[d]) * step\n                                x_try2 = reflect_then_clamp(x_try2)\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < fv:\n                                    x_try, fv = x_try2, fv2\n                            step_vec = x_try - x_work\n                            if np.linalg.norm(step_vec) > 0:\n                                success_steps.append(step_vec.copy())\n                                if len(success_steps) > self.success_hist_len:\n                                    success_steps.pop(0)\n                            x_work = x_try\n                            f_work = fv\n                            moved = True\n                            local_improved = True\n                            if f_work < f_best:\n                                f_best = f_work\n                                x_best = x_work.copy()\n                                gens_since_improve = 0\n\n                    if not moved:\n                        step *= self.step_shrink\n                    # continue while step >= min_step\n\n                # inject local improvement into population\n                if local_improved:\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_work.copy()\n                    f[worst_idx] = f_work\n                    # update best variables already done\n                    gens_since_improve = 0\n                else:\n                    # stagnation nudges: jitter half of population around best\n                    if gens_since_improve >= self.local_stagn_gen:\n                        half = max(1, pop // 2)\n                        for k in range(half):\n                            if evals >= self.budget:\n                                break\n                            jitter = rng.randn(self.dim) * (0.06 * (ub - lb))\n                            newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                            fv = float(func(newx))\n                            evals += 1\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = newx\n                            f[worst_idx] = fv\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = newx.copy()\n                                gens_since_improve = 0\n\n            # sync best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finish\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDE_DirectionalLocalSearch scored 0.413 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "4774ee81-1693-48fc-b906-4e1c3dd40998", "operator": null, "metadata": {"aucs": [0.10599108451740524, 0.16850952304177103, 0.46318592438325334, 0.4362940305259786, 0.45993217570816514, 0.7210358946673526, 0.3086125585508962, 0.45484234944749513, 0.8173837194009101, 0.18937238165753345]}, "task_prompt": ""}
{"id": "25ef7321-3c58-4469-96c5-fb81ab07c8f5", "fitness": 0.4624568049548068, "name": "MCAPS", "description": "MCAPS is a hybrid global–local heuristic that blends antithetic, covariance-adaptive Gaussian sampling with a small rank‑one momentum term and per‑coordinate scaling to bias search directions and reduce variance (antithetic pairs, cov_lr≈0.18, rank1≈0.06, mom_beta≈0.8, s_diag_beta≈0.6). It adapts overall step-size sigma by a success‑rate rule (sigma_adapt_rate≈0.25, success_target≈0.2; initial sigma=0.18·range) and maintains an archive for occasional differential‑style injections (de_inject_prob≈0.12) to inject global diversity. Periodic or stagnation‑triggered Hooke–Jeeves coordinate pattern search (initial_step_frac≈0.18, step_shrink=0.5, min_step_frac=1e‑4) provides deterministic local refinement and opportunistic extra probes, while reflect‑then‑clamp boundary handling, SPD corrections (chol and eigen fixes), jittered nudges/restarts, and strict immediate best updates ensure robustness under a tight evaluation budget.", "code": "import numpy as np\n\nclass MCAPS:\n    \"\"\"\n    Momentum-Covariance Adaptive Pattern Search (MCAPS)\n\n    One-line: Antithetic momentum-covariance sampling (directional bias + per-coordinate scaling)\n    combined with periodic Hooke-Jeeves coordinate pattern local refinement and occasional\n    differential-style injections for robust global-local balance under strict budget control.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 cov_lr=0.18,      # rank-mu learning rate\n                 rank1=0.06,       # rank-one momentum weight\n                 mom_beta=0.8,\n                 s_diag_beta=0.6,\n                 sigma_adapt_rate=0.25,\n                 success_target=0.2,\n                 local_period=25,\n                 local_stagn_gen=30,\n                 initial_step_frac=0.18,\n                 step_shrink=0.5,\n                 min_step_frac=1e-4,\n                 de_inject_prob=0.12,\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.cov_lr = float(cov_lr)\n        self.rank1 = float(rank1)\n        self.mom_beta = float(mom_beta)\n        self.s_diag_beta = float(s_diag_beta)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.success_target = float(success_target)\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.initial_step_frac = float(initial_step_frac)\n        self.step_shrink = float(step_shrink)\n        self.min_step_frac = float(min_step_frac)\n        self.de_inject_prob = float(de_inject_prob)\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds handling\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        range_mean = float(np.mean(bounds_scale))\n        max_bound = float(np.max(bounds_scale))\n\n        # population base (antithetic requires pairs)\n        if self.pop_base is None:\n            lam0 = max(6, int(3 + 2 * np.log(max(2, self.dim))))\n        else:\n            lam0 = int(self.pop_base)\n        lam0 = min(lam0, max(2, self.budget))\n        # ensure even where possible for antithetic pairing\n        if lam0 % 2 == 1 and lam0 > 2:\n            lam0 -= 1\n\n        evals = 0\n\n        # initial uniform batch to seed mean, covariance, archive\n        init_batch = min(max(2, lam0), self.budget)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.empty(init_batch, dtype=float)\n        for i in range(init_batch):\n            f0[i] = float(func(X0[i]))\n            evals += 1\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize mean m from weighted top-half\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 /= np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance and sigma (narrower to encourage refinement early)\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.18 * range_mean)\n\n        # momentum, per-coordinate scaling, success smoothing\n        v = np.zeros(self.dim, dtype=float)\n        s_diag = np.ones(self.dim, dtype=float)\n        p_succ = float(self.success_target)\n\n        # simple archive for DE injections\n        archive_X = [x.copy() for x in X0]\n        archive_f = [float(fi) for fi in f0]\n        archive_capacity = max(4 * self.dim, 20)\n\n        stagn_gens = 0\n        gen = 0\n\n        # helpers\n        def chol_spd(mat):\n            eps = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        def reflect_then_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(lam0, remaining)\n            # ensure at least 2 for antithetic if budget allows\n            if remaining >= 2:\n                lam = max(2, lam if lam % 2 == 0 else lam - 1)\n            else:\n                lam = 1\n\n            mu = max(1, lam // 2)\n            # recompute weights\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n            W = weights.reshape(-1, 1)\n\n            # get SPD factor\n            A = chol_spd(C)\n\n            # antithetic Gaussian sampling\n            half = lam // 2\n            Zpos = rng.normal(size=(half, self.dim))\n            Z = np.vstack([Zpos, -Zpos])\n            if lam % 2 == 1:\n                Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n\n            Y = Z @ A.T  # correlated perturbations\n            # directional perturbation along momentum (normalized)\n            vlen = np.linalg.norm(v) + 1e-20\n            if vlen > 0:\n                v_unit = v / vlen\n                dir_strength = 0.8 * (vlen / (1.0 + vlen))\n                s_scalar = rng.normal(scale=dir_strength, size=(Y.shape[0], 1))\n                Y = Y + s_scalar * v_unit.reshape(1, -1)\n            # apply coordinate-wise scaling\n            Y = Y * s_diag.reshape(1, -1)\n\n            Xcand = m + sigma * Y\n            # optional DE-style injection: replace a random candidate with a differential-like trial\n            if (len(archive_X) >= 3) and (rng.rand() < self.de_inject_prob) and (lam >= 1):\n                # build a DE-like candidate using two archive diffs and biased base\n                idxs = rng.choice(len(archive_X), size=3, replace=False)\n                base = archive_X[idxs[0]]\n                x1 = archive_X[idxs[1]]\n                x2 = archive_X[idxs[2]]\n                F = 0.8\n                trial = base + F * (x1 - x2)\n                # small Gaussian/local perturbation\n                trial += rng.normal(scale=0.25 * sigma, size=self.dim)\n                trial = reflect_then_clamp(trial)\n                # pick a slot to replace (random)\n                rep = rng.randint(Xcand.shape[0])\n                Xcand[rep] = trial\n\n            # clamp candidates\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates sequentially\n            fc = np.full(Xcand.shape[0], np.inf, dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                xi = Xcand[i]\n                # cheap reflect/clamp safety (already clamped)\n                fv = float(func(xi))\n                fc[i] = fv\n                evals += 1\n                # update running best immediately\n                if fv < f_best:\n                    f_best = fv\n                    x_best = xi.copy()\n                    stagn_gens = 0\n            # truncate if budget exhausted mid-batch\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                if Xcand.shape[0] == 0:\n                    break\n\n            # append to archive and trim\n            for xi, fi in zip(Xcand, fc):\n                archive_X.append(xi.copy())\n                archive_f.append(float(fi))\n            if len(archive_X) > archive_capacity:\n                excess = len(archive_X) - archive_capacity\n                archive_X = archive_X[excess:]\n                archive_f = archive_f[excess:]\n\n            # determine generation best and whether improved\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                # already handled above, but keep flag\n                improved = True\n                stagn_gens = 0\n            else:\n                # If best in this generation equals global best (from early updates), set improved accordingly\n                if gen_best_f < f_best + 1e-20:\n                    improved = False\n                stagn_gens += 1\n\n            # selection: top-mu\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            # compute normalized deltas (in sample coordinates)\n            deltas = (X_mu - m) / (sigma + 1e-20)  # shape (mu, dim)\n\n            if deltas.shape[0] > 0:\n                # weighted covariance in normalized coordinates\n                if deltas.shape[0] != weights.shape[0]:\n                    mu_eff = deltas.shape[0]\n                    w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if np.sum(w_eff) <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff /= np.sum(w_eff)\n                    Wd = w_eff.reshape(-1, 1)\n                    weighted_cov = (deltas * Wd).T @ deltas\n                    delta_mean = (Wd * deltas).sum(axis=0)\n                else:\n                    weighted_cov = (deltas * W).T @ deltas\n                    delta_mean = (W * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # update momentum in normalized coords\n            v = self.mom_beta * v + (1.0 - self.mom_beta) * delta_mean\n            # rank-one momentum outer\n            rank_one = np.outer(v, v)\n\n            # covariance update: mixture of old, weighted_cov and rank-one\n            c_cov = float(self.cov_lr)\n            c1 = float(self.rank1)\n            # ensure coefficients not exceeding 1\n            other = max(0.0, 1.0 - c_cov - c1)\n            C = other * C + c_cov * weighted_cov + c1 * rank_one\n            # symmetry and small diag jitter\n            C = 0.5 * (C + C.T) + np.diag(np.maximum(np.diag(C), 1e-18))\n\n            # update per-coordinate scaling (EMA of sqrt of squared normalized deltas)\n            if deltas.shape[0] > 0:\n                stat = np.mean(deltas ** 2, axis=0)\n            else:\n                stat = 1e-6 * np.ones(self.dim)\n            s_diag = (self.s_diag_beta * s_diag +\n                      (1.0 - self.s_diag_beta) * np.sqrt(stat + 1e-20))\n            s_diag = np.clip(s_diag, 0.2, 5.0)\n\n            # update mean\n            if X_mu.shape[0] > 0:\n                m_new = (weights.reshape(-1, 1) * X_mu[:weights.shape[0]]).sum(axis=0)\n            else:\n                m_new = m.copy()\n            m = np.minimum(np.maximum(m_new, lb), ub)\n\n            # success-based sigma adaptation\n            p_succ = 0.85 * p_succ + 0.15 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, 1e-12, 2.0 * max_bound)\n\n            # periodic or stagnation-triggered local Hooke-Jeeves coordinate pattern search\n            if (gen % self.local_period == 0) or (stagn_gens >= self.local_stagn_gen):\n                remaining_loc = self.budget - evals\n                if remaining_loc <= 0:\n                    break\n\n                step = max(1e-12, self.initial_step_frac * range_mean)\n                min_step = max(1e-12, self.min_step_frac * range_mean)\n                # if stagnating, increase step a bit to escape basin\n                if stagn_gens >= self.local_stagn_gen:\n                    step *= 2.0\n\n                local_improved = False\n                x_work = x_best.copy()\n                f_work = f_best\n\n                while step >= min_step and (self.budget - evals) > 0:\n                    moved = False\n                    for d in range(self.dim):\n                        if evals >= self.budget:\n                            break\n                        # try positive direction\n                        x_try = x_work.copy()\n                        x_try[d] = x_try[d] + step\n                        if x_try[d] > ub[d]:\n                            x_try[d] = ub[d]\n                        if np.all(x_try == x_work):\n                            # try negative if plus not possible\n                            x_try[d] = x_work[d] - step\n                            if x_try[d] < lb[d]:\n                                x_try[d] = lb[d]\n                        x_try = reflect_then_clamp(x_try)\n                        # evaluate\n                        fv = float(func(x_try))\n                        evals += 1\n                        if fv < f_work:\n                            x_work = x_try\n                            f_work = fv\n                            moved = True\n                            local_improved = True\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = x_try.copy()\n                                stagn_gens = 0\n                            # opportunistic extra probe further in same direction\n                            if evals < self.budget:\n                                x_try2 = x_work.copy()\n                                x_try2[d] = np.minimum(np.maximum(x_try2[d] + step, lb[d]), ub[d])\n                                x_try2 = reflect_then_clamp(x_try2)\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < f_work:\n                                    x_work = x_try2\n                                    f_work = fv2\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = x_try2.copy()\n                                        stagn_gens = 0\n                        else:\n                            # try minus direction if plus didn't improve\n                            if evals >= self.budget:\n                                break\n                            x_try = x_work.copy()\n                            x_try[d] = x_work[d] - step\n                            if x_try[d] < lb[d]:\n                                x_try[d] = lb[d]\n                            x_try = reflect_then_clamp(x_try)\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                x_work = x_try\n                                f_work = fv\n                                moved = True\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_try.copy()\n                                    stagn_gens = 0\n                    if not moved:\n                        step *= self.step_shrink\n                    if evals >= self.budget:\n                        break\n\n                # inject improvement into archive/population\n                if local_improved:\n                    # replace worst in archive\n                    if len(archive_f) > 0:\n                        worst_idx = int(np.argmax(archive_f))\n                        archive_X[worst_idx] = x_work.copy()\n                        archive_f[worst_idx] = float(f_work)\n                    else:\n                        archive_X.append(x_work.copy())\n                        archive_f.append(float(f_work))\n                    # update mean gently toward local improvement\n                    m = 0.9 * m + 0.1 * x_work\n                    # update covariance to reflect local step (small rank-1)\n                    s = (x_work - m) / (sigma + 1e-20)\n                    C = 0.98 * C + 0.02 * np.outer(s, s)\n                    # ensure SPD\n                    vals, vecs = np.linalg.eigh(C)\n                    vals = np.clip(vals, 1e-12, None)\n                    C = (vecs * vals) @ vecs.T\n                    stagn_gens = 0\n                else:\n                    # mild restart nudges if stagnating\n                    if stagn_gens >= self.local_stagn_gen:\n                        nudge_pop = max(1, lam0 // 3)\n                        for k in range(nudge_pop):\n                            if evals >= self.budget:\n                                break\n                            jitter = rng.randn(self.dim) * (0.05 * bounds_scale)\n                            newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                            fv = float(func(newx))\n                            evals += 1\n                            # replace some worst archive\n                            if len(archive_f) > 0:\n                                worst_idx = int(np.argmax(archive_f))\n                                archive_X[worst_idx] = newx.copy()\n                                archive_f[worst_idx] = float(fv)\n                            else:\n                                archive_X.append(newx.copy())\n                                archive_f.append(float(fv))\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = newx.copy()\n                                stagn_gens = 0\n\n            # opportunistic archive maintenance / restart if rho collapse equivalent (sigma too small)\n            if sigma <= 1e-9 * max_bound or stagn_gens > max(3, self.local_stagn_gen * 3):\n                # jitter center around best, reset covariance modestly\n                m = x_best + rng.randn(self.dim) * (0.05 * bounds_scale)\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                sigma = max(sigma, 0.12 * range_mean)\n                v = np.zeros_like(v)\n                s_diag = np.ones_like(s_diag)\n                stagn_gens = 0\n\n            # safety SPD correction each iteration\n            try:\n                _ = np.linalg.cholesky(C + np.eye(self.dim) * 1e-16)\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                C = (vecs * vals) @ vecs.T\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MCAPS scored 0.462 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "4774ee81-1693-48fc-b906-4e1c3dd40998", "operator": null, "metadata": {"aucs": [0.14603555356689046, 0.14835371164442268, 0.5799523025124361, 0.9497967653208161, 0.6482999578569428, 0.7043807966377673, 0.2709246088773639, 0.37917231672285046, 0.6660627500360081, 0.13158928637257017]}, "task_prompt": ""}
{"id": "190f07d3-62a5-43e2-82e1-78ebbbad2370", "fitness": 0.4512217286648402, "name": "FAMS", "description": "FAMS maintains a compact sorted archive of best points and a small population of probes (each with position, value, local radius, age and a momentum vector) initialized from random sampling (init_samples = max(12, min(60, 6*dim))) and tuned archive/probe sizes (archive_k in [4,12], probe_count up to archive_k). Local search is done by multi-scale directional 1D parabolic probing along random orthonormal directions (QR, up to k=3) using symmetric evaluations at -step and +step plus a parabola fit to estimate a minimizer; radii adapt on success (expand ×1.25, cap 2.0*avg_span) and failure (shrink ×0.65), with small local polish (0.3*r) after improvements and momentum-based extrapolation (mom updated with 0.6/0.4 smoothing, extrapolate with alpha=0.8). Global exploration uses PCA-guided low-rank jumps from the archive (top eigenvector, step length drawn from a heavy-tailed Cauchy scaled by sqrt(eigval) and avg_span, clamped) plus occasional uniform/jitter injections (every ~7, 23, 41 attempts) and probe replacement/pruning to maintain diversity. The algorithm is budget-aware (eval_and_record enforces self.budget and clips to bounds), selects probes via softmax over -f with an adaptive temperature (sel_temp in [0.3,5.0]), and uses many pragmatic safeguards (clamping extrapolation t in [-2,2], minimal radii, numerical regularization) for robust continuous optimization.", "code": "import numpy as np\n\nclass FAMS:\n    \"\"\"\n    Fractal Adaptive Multi-Scale Search (FAMS)\n\n    Main ideas:\n    - Maintain a compact archive of best-found points and a set of \"probes\"\n      (each probe keeps position, value, local radius and momentum).\n    - Perform multi-scale directional 1D parabolic probes on random low-dim\n      subspaces (orthonormal directions) around a probe; fit a parabola from\n      evaluations at -step, 0, +step to estimate a 1D minimizer along the line.\n    - Adaptive radius per probe: expand on success, contract on failure.\n    - Momentum-based extrapolation: when a probe accumulates a consistent\n      improvement direction, try extrapolation.\n    - Low-rank PCA-guided global jumps from archive top eigenvectors with\n      heavy-tailed scaling to escape basins.\n    - Budget-respecting evaluation wrapper that clips to bounds and never\n      performs evaluations beyond self.budget.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10,\n                 rng_seed=None,\n                 init_samples=None,\n                 archive_size=None,\n                 probe_count=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.probe_count = probe_count\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds (func.bounds.lb/ub may be scalar or arrays)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive defaults\n        if self.init_samples is None:\n            init_samples = max(12, min(60, 6 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, self.budget)\n\n        if self.archive_size is None:\n            archive_k = max(4, min(12, init_samples // 3))\n        else:\n            archive_k = int(self.archive_size)\n\n        if self.probe_count is None:\n            probe_count = max(2, min(12, archive_k))\n        else:\n            probe_count = int(self.probe_count)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        # archive: list of (f, x)\n        archive = []\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            # update best\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # insert into archive (keep sorted)\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        # initial sampling\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one point\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # initialize probes from archive top entries (or random if insufficient)\n        probes = []\n        for i in range(min(probe_count, len(archive))):\n            f0, x0 = archive[i]\n            probe = {\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': max(0.08 * avg_span, 0.25 * avg_span * (0.9 ** i)),  # radius\n                'mom': np.zeros(self.dim, dtype=float),\n                'age': 0\n            }\n            probes.append(probe)\n        # if not enough probes, create from random archive samples\n        while len(probes) < probe_count and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            res = eval_and_record(x0)\n            if res is None:\n                break\n            f0, x0 = res\n            probes.append({\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': 0.25 * avg_span,\n                'mom': np.zeros(self.dim, dtype=float),\n                'age': 0\n            })\n\n        # selection temperature for probe choice (lower -> pick best more often)\n        sel_temp = 1.0\n\n        attempt = 0\n        stagnation_counter = 0\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n\n            # select a probe by softmax over -f (favor smaller f)\n            fs = np.array([p['f'] for p in probes], dtype=float)\n            # prevent overflow: shift\n            z = -fs / max(1e-9, sel_temp)\n            probs = np.exp(z - np.max(z))\n            probs /= probs.sum()\n            idx = rng.choice(len(probes), p=probs)\n            probe = probes[idx]\n            x0 = probe['x'].copy()\n            f0 = probe['f']\n            r0 = probe['r']\n\n            improved = False\n            # choose subspace dimension k: small to keep cheap fitting\n            k = min(self.dim, max(1, int(max(1, np.ceil(np.sqrt(self.dim)) // 1))))\n            k = min(k, 3)  # limit to at most 3 directions for speed on high-dim\n\n            # build random orthonormal directions (k columns)\n            A = rng.randn(self.dim, k)\n            # QR for orthonormal columns\n            try:\n                Q, _ = np.linalg.qr(A)\n            except Exception:\n                Q = A / (np.linalg.norm(A, axis=0, keepdims=True) + 1e-12)\n            directions = [Q[:, j] for j in range(k)]\n\n            # directional parabolic probing\n            for d in directions:\n                if evals >= self.budget:\n                    break\n                # step magnitude is probe radius times random factor in [0.6,1.4]\n                s = r0 * (0.6 + 0.8 * rng.rand())\n                step = d * s\n                # symmetric evaluations at -step and +step; also use center value f0\n                x_minus = np.minimum(np.maximum(x0 - step, lb), ub)\n                res_minus = eval_and_record(x_minus)\n                if res_minus is None:\n                    break\n                f_minus, x_minus = res_minus\n\n                x_plus = np.minimum(np.maximum(x0 + step, lb), ub)\n                res_plus = eval_and_record(x_plus)\n                if res_plus is None:\n                    break\n                f_plus, x_plus = res_plus\n\n                # attempt parabolic minimizer along the line parameter t (t in units of step)\n                denom = (f_minus + f_plus - 2.0 * f0)\n                x_candidate = None\n                f_candidate = None\n                if abs(denom) > 1e-12:\n                    t_star = 0.5 * (f_minus - f_plus) / denom\n                    # clamp t_star to reasonable range [-2, 2] to avoid wild extrapolation\n                    t_star = float(np.clip(t_star, -2.0, 2.0))\n                    x_parab = x0 + t_star * step\n                    x_parab = np.minimum(np.maximum(x_parab, lb), ub)\n                    res_parab = eval_and_record(x_parab)\n                    if res_parab is not None:\n                        f_parab, x_parab = res_parab\n                        x_candidate = x_parab\n                        f_candidate = f_parab\n                # consider best among center (already known), plus/minus, parab if available\n                # we have f_minus and f_plus already integrated into archive via eval_and_record\n                # find the best observed on-line for this direction\n                # gather tuples (f, x) for candidates\n                cand_list = []\n                cand_list.append((f_minus, x_minus))\n                cand_list.append((f_plus, x_plus))\n                if x_candidate is not None:\n                    cand_list.append((f_candidate, x_candidate))\n                # also include current center (x0,f0)\n                cand_list.append((f0, x0))\n                cand_list.sort(key=lambda t: t[0])\n                best_dir_f, best_dir_x = cand_list[0]\n                if best_dir_f < probe['f'] - 1e-12:\n                    # improvement\n                    old_x = probe['x'].copy()\n                    probe['x'] = best_dir_x.copy()\n                    probe['f'] = float(best_dir_f)\n                    # update momentum (exponential smoothing)\n                    move = probe['x'] - old_x\n                    probe['mom'] = 0.6 * probe['mom'] + 0.4 * move\n                    # expand radius moderately\n                    probe['r'] = min(max(1e-6, probe['r'] * 1.25), 2.0 * avg_span)\n                    probe['age'] = 0\n                    improved = True\n                    stagnation_counter = 0\n                else:\n                    # failure in this direction -> shrink radius a bit\n                    probe['r'] = max(1e-8, probe['r'] * 0.65)\n                    probe['age'] += 1\n                    stagnation_counter += 1\n\n                # small budget safety break\n                if evals >= self.budget:\n                    break\n\n            # momentum extrapolation: try a small step along momentum if consistent\n            if evals < self.budget and np.linalg.norm(probe['mom']) > 1e-8:\n                alpha = 0.8  # fraction of momentum to try\n                xm = probe['x'] + alpha * probe['mom']\n                xm = np.minimum(np.maximum(xm, lb), ub)\n                res_m = eval_and_record(xm)\n                if res_m is not None:\n                    fm, xm = res_m\n                    if fm < probe['f'] - 1e-12:\n                        # accept extrapolation and expand radius slightly\n                        probe['x'] = xm.copy()\n                        probe['f'] = float(fm)\n                        probe['r'] = min(probe['r'] * 1.3, 2.0 * avg_span)\n                        probe['mom'] = 0.8 * probe['mom']  # damp\n                        improved = True\n                        stagnation_counter = 0\n                    else:\n                        # damp momentum if bad\n                        probe['mom'] *= 0.5\n\n            # if this probe improved a lot, try a small local refine using reduced radius\n            if improved and evals < self.budget:\n                # quick local polish: 2-direction small steps\n                small_r = max(1e-8, 0.3 * probe['r'])\n                # take two random orthonormal directions\n                A2 = rng.randn(self.dim, min(2, self.dim))\n                try:\n                    Q2, _ = np.linalg.qr(A2)\n                except Exception:\n                    Q2 = A2 / (np.linalg.norm(A2, axis=0, keepdims=True) + 1e-12)\n                for j in range(Q2.shape[1]):\n                    if evals >= self.budget:\n                        break\n                    d = Q2[:, j]\n                    xp = probe['x'] + d * small_r\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res_p = eval_and_record(xp)\n                    if res_p is None:\n                        break\n                    fp, xp = res_p\n                    if fp < probe['f']:\n                        probe['x'] = xp.copy()\n                        probe['f'] = float(fp)\n\n            # maintain probes list size: occasionally inject new probes around best archive points\n            if attempt % 7 == 0 and len(probes) < probe_count and len(archive) > 0 and evals < self.budget:\n                # jitter around best\n                base = archive[0][1]\n                jitter = 0.15 * avg_span * rng.randn(self.dim)\n                new_x = np.minimum(np.maximum(base + jitter, lb), ub)\n                res_new = eval_and_record(new_x)\n                if res_new is not None:\n                    fnew, new_x = res_new\n                    probes.append({\n                        'x': new_x.copy(),\n                        'f': float(fnew),\n                        'r': 0.25 * avg_span,\n                        'mom': np.zeros(self.dim, dtype=float),\n                        'age': 0\n                    })\n\n            # PCA-guided low-rank global jump when stagnating or occasionally\n            if (stagnation_counter > 40 and len(archive) >= 3) or (attempt % 23 == 0 and len(archive) >= 3):\n                # compute covariance of top archive points\n                pts = np.vstack([t[1] for t in archive])\n                mean = np.mean(pts, axis=0)\n                Xc = pts - mean\n                # small regularization to avoid numerical issues\n                C = (Xc.T @ Xc) / max(1.0, pts.shape[0])\n                try:\n                    eigvals, eigvecs = np.linalg.eigh(C)\n                    # pick top eigenvector\n                    idx_top = np.argsort(eigvals)[-1]\n                    v = eigvecs[:, idx_top]\n                    lam = max(1e-8, float(eigvals[idx_top]))\n                except Exception:\n                    # fallback to random direction\n                    v = rng.randn(self.dim)\n                    v = v / (np.linalg.norm(v) + 1e-12)\n                    lam = 1.0\n                # heavy-tailed length (Cauchy) scaled by sqrt(eigval) and avg_span\n                step_len = rng.standard_cauchy() * (np.sqrt(lam) + 0.2) * 0.8 * avg_span\n                # clip step to reasonable magnitude\n                step_len = float(np.clip(step_len, -5.0 * avg_span, 5.0 * avg_span))\n                x_jump = mean + step_len * v\n                x_jump = np.minimum(np.maximum(x_jump, lb), ub)\n                res_jump = eval_and_record(x_jump)\n                if res_jump is not None:\n                    fj, x_jump = res_jump\n                    # if good, replace worst probe or add new probe\n                    if fj < max([p['f'] for p in probes]):\n                        # replace the worst probe\n                        worst_idx = int(np.argmax([p['f'] for p in probes]))\n                        probes[worst_idx] = {\n                            'x': x_jump.copy(),\n                            'f': float(fj),\n                            'r': 0.3 * avg_span,\n                            'mom': np.zeros(self.dim, dtype=float),\n                            'age': 0\n                        }\n                    else:\n                        # small chance to append new exploratory probe\n                        if rng.rand() < 0.2 and len(probes) < 2 * probe_count:\n                            probes.append({\n                                'x': x_jump.copy(),\n                                'f': float(fj),\n                                'r': 0.3 * avg_span,\n                                'mom': np.zeros(self.dim, dtype=float),\n                                'age': 0\n                            })\n                stagnation_counter = 0  # reset after jump attempt\n\n            # prune probes that are old and poor\n            if len(probes) > probe_count:\n                # sort by f and keep best probe_count\n                probes.sort(key=lambda p: p['f'])\n                probes = probes[:probe_count]\n\n            # adaptive selection temperature: increase when diverse improvements, decrease when stagnating\n            if stagnation_counter > 30:\n                sel_temp = min(5.0, sel_temp * 1.05)\n            else:\n                sel_temp = max(0.3, sel_temp * 0.995)\n\n            # occasional uniform injection to maintain exploration\n            if attempt % 41 == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # safety: if archive best improved recently, reduce sel_temp to focus\n            if len(archive) > 0:\n                # no extra action, main loop continues\n\n                pass\n\n            # end while loop condition will check evals\n\n        # finish: ensure best is recorded\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm FAMS scored 0.451 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "188a3a49-ae94-4c3e-b458-f640f8fc578c", "operator": null, "metadata": {"aucs": [0.12202301675596183, 0.1541433839347769, 0.5249178634492349, 0.861784196557727, 0.2893224190533048, 0.8264440063828349, 0.2613224541573964, 0.4301361338374067, 0.8961367836799308, 0.14598702883982784]}, "task_prompt": ""}
{"id": "22fdb245-00ef-4d24-9240-afb45392d5d6", "fitness": 0.45220433093631823, "name": "ADSS", "description": "The algorithm mixes budget-aware global exploration and local exploitation by starting with adaptive uniform sampling (init_samples capped by budget) and keeping a small elite archive that scales ~sqrt(dim). Global moves use directional heavy‑tailed Student‑t jumps (df=3) with anisotropic per‑dimension scaling derived from an archive-based diversity metric (fallback scales like 0.2·span or min 0.03·span), a decaying global step scale, occasional uniform injections and jittered restarts to maintain exploration. Exploitation is a randomized Hooke–Jeeves coordinate local search seeded from archive/best points with per‑dim steps initialized from diversity, aggressive shrink (0.618), pattern extension (factor 2.0), and a differential recombination operator (recomb_gamma=0.8) to create diverse candidates. Everything is budget‑conscious and adaptive: local budget fractions, a smooth tanh‑based p_global depending on no_improve_since, and slow adjustments to the base global probability, with strict clipping to bounds and archive maintenance.", "code": "import numpy as np\n\nclass ADSS:\n    \"\"\"\n    Adaptive Directional Student-t Search (ADSS)\n\n    Main algorithm parameters (identification):\n    - budget: total allowed function evaluations\n    - dim: problem dimensionality\n    - init_samples: number of initial uniform samples (if None chosen adaptively)\n    - archive_size: number of elite points to keep (if None chosen adaptively)\n    - global_base_prob: baseline probability to attempt a global (heavy-tailed) move\n    - local_frac: fraction of budget recommended for a single local search attempt\n    - student_df: degrees of freedom for Student-t global jumps (heavier than Gaussian but milder than Cauchy)\n    - shrink: shrink factor used in local search (uses golden-ratio-ish 0.618)\n    - pattern_factor: extension multiplier for pattern move (uses 2.0 here)\n    - recomb_gamma: differential recombination multiplier (used for archive recombination)\n\n    Differences vs. the provided APLS:\n    - initial sampling count, archive sizing, and local/global budget split are computed with different formulas\n    - global jumps use Student-t(df=3) directional scaling with per-dimension diversity-based scales (not pure Cauchy)\n    - local search shrink uses ~0.618 and pattern_factor 2.0 (different numerical values)\n    - includes explicit differential recombination operator for diversification\n    - adaptive global probability is controlled via a smooth tanh-based rule (different update equation)\n    \"\"\"\n    def __init__(self, budget=10000, dim=10,\n                 init_samples=None,\n                 archive_size=None,\n                 global_base_prob=0.18,\n                 local_frac=0.05,\n                 student_df=3,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.global_base_prob = float(global_base_prob)\n        self.local_frac = float(local_frac)\n        self.student_df = float(student_df)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds (support scalar or array)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive defaults (different formulas than APLS)\n        if self.init_samples is None:\n            # slightly more initial exploration for moderate dims, capped by budget\n            init_samples = int(min(max(8, 8 * self.dim), max(10, self.budget // 8), 250))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, self.budget)\n\n        if self.archive_size is None:\n            # archive scales with sqrt(dim), clipped\n            archive_k = int(max(3, min(12, int(np.ceil(np.sqrt(self.dim) * 1.5)))))\n        else:\n            archive_k = int(self.archive_size)\n\n        # bookkeeping\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x)\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # clip\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # maintain sorted archive\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        # initial uniform samples\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one archive member\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # local search parameters (different shrink/pattern)\n        shrink = 0.618  # golden-ratio-ish shrink (different from 0.6)\n        pattern_factor = 2.0  # more aggressive pattern extension\n        recomb_gamma = 0.8  # differential recombination multiplier\n        tol = 1e-10\n\n        # helper: compute per-dim diversity scale from archive or global span\n        def diversity_scale():\n            if len(archive) >= 2:\n                pts = np.vstack([t[1] for t in archive])\n                std = np.std(pts, axis=0)\n                # avoid too small scales; combine with global span baseline\n                return np.maximum(std, 0.03 * span)\n            else:\n                return 0.2 * span  # fallback scale\n\n        # propose a global jump (Student-t directionally scaled)\n        def global_jump_from(x_center, scale):\n            # direction: isotropic random direction\n            direction = rng.randn(self.dim)\n            nrm = np.linalg.norm(direction) + 1e-12\n            direction /= nrm\n            # Student-t draw per step length (df small => heavy tails)\n            t_draw = rng.standard_t(self.student_df)\n            # per-dim scaling derived from diversity\n            dscale = diversity_scale()\n            # combine scale factor with average span but allow anisotropy\n            step = direction * (float(scale) * (0.25 * avg_span) * (1.0 + 0.8 * rng.rand()))\n            # project anisotropy by multiplying by normalized dscale ratio\n            anis = (dscale / (np.mean(dscale) + 1e-12))\n            step = step * anis\n            return x_center + t_draw * step\n\n        # differential recombination from archive\n        def recombine_from_archive():\n            if len(archive) >= 2:\n                i, j = rng.choice(len(archive), size=2, replace=False)\n                x1 = archive[i][1]\n                x2 = archive[j][1]\n                # differential-like step plus small student t noise\n                diff = x1 - x2\n                child = x1 + recomb_gamma * diff + 0.05 * avg_span * rng.standard_t(self.student_df, size=self.dim)\n                return np.minimum(np.maximum(child, lb), ub)\n            else:\n                return rng.uniform(lb, ub)\n\n        # Hooke-Jeeves style local search (different sequence/shrink)\n        def local_search(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            # initialize steps based on diversity and span (different equation than APLS)\n            dscale = diversity_scale()\n            # use a per-dim initial step that is clipped to reasonable fraction\n            steps = np.minimum(0.5 * dscale, 0.4 * avg_span)\n            local_evals = 0\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_evals < local_budget and iters < iter_limit and np.any(steps > tol):\n                iters += 1\n                improved = False\n                probe = base.copy()\n                probe_f = base_f\n                # explore coordinates in randomized order (different from always 0..dim-1)\n                order = rng.permutation(self.dim)\n                for idx in order:\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    # positive direction\n                    xp = probe.copy()\n                    xp[idx] += steps[idx]\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res = eval_and_record(xp)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < probe_f:\n                        probe = xp.copy()\n                        probe_f = fp\n                        improved = True\n                        continue\n                    # negative direction\n                    xn = probe.copy()\n                    xn[idx] -= steps[idx]\n                    xn = np.minimum(np.maximum(xn, lb), ub)\n                    res = eval_and_record(xn)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < probe_f:\n                        probe = xn.copy()\n                        probe_f = fn\n                        improved = True\n                # pattern extension if got improvement\n                if improved and local_evals < local_budget and evals < self.budget:\n                    direction = probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_and_record(xp)\n                        local_evals += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = probe.copy()\n                                base_f = probe_f\n                        else:\n                            base = probe.copy()\n                            base_f = probe_f\n                    else:\n                        base = probe.copy()\n                        base_f = probe_f\n                else:\n                    # shrink more aggressively if no improvement\n                    steps *= shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # main loop\n        attempt = 0\n        no_improve_since = 0\n        # dynamic global probability will be modulated from base by tanh of no_improve_since\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            # allocate local budgets differently: proportional to remaining but clipped\n            max_local_budget = max(3, int(self.local_frac * self.budget))\n            alloc_local = min(max_local_budget, max(2, int(0.03 * remaining)))\n            alloc_local = min(alloc_local, remaining - 1) if remaining > 1 else 0\n\n            # adapt global jump probability smoothly\n            p_global = min(0.9, max(0.03, self.global_base_prob * (1.0 + 0.5 * np.tanh((no_improve_since - 5) / 4.0))))\n\n            do_global = (rng.rand() < p_global)\n\n            if do_global and len(archive) > 0:\n                # choose center: often best, sometimes random elite\n                if rng.rand() < 0.75:\n                    center = archive[0][1]\n                else:\n                    idx = rng.randint(0, len(archive))\n                    center = archive[idx][1]\n                # scale reduces with attempts more gently (different equation)\n                scale = max(0.07, 1.0 / (1.0 + 0.015 * attempt))\n                cand = global_jump_from(center, scale)\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n\n                # if candidate improved global best, reset no_improve counter\n                if f_cand < f_best:\n                    no_improve_since = 0\n                else:\n                    no_improve_since += 1\n\n                # if promising, do a local search (different local budget formula)\n                threshold = (archive[0][0] if len(archive) > 0 else np.inf)\n                if alloc_local > 0 and f_cand <= threshold * (1.08 + 0.02 * rng.rand()):\n                    local_alloc = min(remaining - 1, int(alloc_local * (1 + rng.rand())))\n                    local_alloc = max(1, local_alloc)\n                    f_after, x_after = local_search(cand, f_cand, local_alloc)\n                    if f_after < f_best:\n                        no_improve_since = 0\n                    else:\n                        no_improve_since += 1\n                else:\n                    # occasionally attempt differential recombination instead of local search\n                    if rng.rand() < 0.12 and evals < self.budget:\n                        child = recombine_from_archive()\n                        res = eval_and_record(child)\n                        if res is None:\n                            break\n                        fc, child = res\n                        if fc < f_best:\n                            no_improve_since = 0\n                        else:\n                            no_improve_since += 1\n\n            else:\n                # local refinement or restart\n                choose = rng.rand()\n                if choose < 0.6 and len(archive) > 0:\n                    start_f, start_x = archive[0]\n                elif choose < 0.9 and len(archive) > 1:\n                    idx = rng.randint(0, len(archive))\n                    start_f, start_x = archive[idx]\n                else:\n                    # jittered restart around best with anisotropic noise\n                    if x_best is not None:\n                        dscale = diversity_scale()\n                        jitter = rng.normal(scale=0.15 * dscale)\n                        start_x = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                    else:\n                        start_x = rng.uniform(lb, ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n\n                # local budget adapted to remaining budget (different fraction)\n                local_budget = min(alloc_local, max(2, int(0.06 * remaining)))\n                f_after, x_after = local_search(start_x, start_f, local_budget)\n                if f_after < f_best:\n                    no_improve_since = 0\n                else:\n                    no_improve_since += 1\n\n            # occasional uniform injection to maintain exploration (different period)\n            if (attempt % 23) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # gentle decay or increase of the base probability depending on recent progress\n            if no_improve_since > 8:\n                self.global_base_prob = min(0.85, self.global_base_prob + 0.03)\n            else:\n                self.global_base_prob = max(0.03, self.global_base_prob * 0.995)\n\n            if evals >= self.budget:\n                break\n\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ADSS scored 0.452 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "188a3a49-ae94-4c3e-b458-f640f8fc578c", "operator": null, "metadata": {"aucs": [0.0707483811603814, 0.15430531275166504, 0.9716517321333956, 0.40265940033947933, 0.629472218561901, 0.9883510706569597, 0.25622142231024003, 0.24155840870050715, 0.6642952723539169, 0.14278009039473516]}, "task_prompt": ""}
{"id": "ac212fd4-0f41-40e1-896a-e9fab802db4f", "fitness": 0.2378882545252607, "name": "AMDS", "description": "AMDS is a hybrid, budget-aware heuristic that mixes low-rank subspace modeling (p_model=0.45), mirrored directional derivative probes (p_directional=0.35) and global heavy‑tailed restarts/injections (p_global=0.20) to balance local exploitation and global diversification. The low-rank model builds an orthonormal random subspace, fits a cheap least-squares linear surrogate on samples within a trust radius (sigma = trust_radius) to obtain a subspace gradient which is lifted to full space and used for a normalized step. The mirrored directional mode uses central differences from x ± delta*v (delta ≈ (0.6–1.4)·trust_radius) with directions seeded from elite archive differences and random vectors, accumulates a gradient estimate and steps opposite its direction; both modes adapt the trust radius (expand_factor=1.25, shrink_factor=0.6) on success/failure. The algorithm maintains a small elite archive (archive_k), biases center selection toward elites while performing occasional Cauchy-like anisotropic jumps, uniform injections and local polishing, and enforces strict per-run budget caps so func() is never called beyond self.budget.", "code": "import numpy as np\n\nclass AMDS:\n    \"\"\"\n    Adaptive Multi-scale Directional Search (AMDS)\n\n    Main ideas / novelty:\n    - Use mirrored directional probes (x +/- delta*v) to estimate directional derivatives\n      and assemble a gradient estimate in a small subspace (no analytic gradients).\n    - Build cheap low-rank linear models in randomly chosen subspaces (least squares)\n      to propose multi-dimensional steps inside a trust-region.\n    - Adaptive trust-radius per attempt: expands after success, shrinks after failure.\n    - Maintain a small elite archive; sample centers from elites (best-first) or jittered restarts.\n    - Global diversification via heavy-tailed (Cauchy-mixed) orthogonalized jumps and uniform injections.\n    - Budget-aware: never calls func() more than self.budget. Works with variable dim and box bounds.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, init_samples=None, archive_size=None, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # parse bounds (allow scalar or arrays)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        diag_span = np.maximum(span, 1e-12)\n\n        # adaptive defaults\n        if self.init_samples is None:\n            init_samples = max(10, min(60, 4 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, self.budget // 2)  # reserve budget\n        if self.archive_size is None:\n            archive_k = max(3, min(12, init_samples // 3))\n        else:\n            archive_k = int(self.archive_size)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x)\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # insert into archive\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        # Initial space-filling samples\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # If nothing evaluated (unlikely), do one eval\n        if len(archive) == 0 and evals < self.budget:\n            eval_and_record(rng.uniform(lb, ub))\n\n        # Control parameters\n        trust_radius = 0.25 * avg_span  # global initial trust radius\n        trust_min = 1e-6 * avg_span\n        trust_max = 1.5 * avg_span\n        expand_factor = 1.25\n        shrink_factor = 0.6\n\n        # probabilities (adaptive)\n        p_model = 0.45  # low-rank model in subspace\n        p_directional = 0.35  # mirrored directional derivative exploitation\n        p_global = 0.20  # global heavy-tailed restart\n\n        attempt = 0\n\n        # utility: draw heavy-tailed scalar (bounded)\n        def heavy_tail_scalar():\n            s = rng.standard_cauchy()\n            return float(np.clip(s, -1e2, 1e2))\n\n        # utility: orthonormal basis of k vectors in R^dim\n        def random_subspace(k):\n            Y = rng.randn(self.dim, k)\n            # QR\n            Q, _ = np.linalg.qr(Y)\n            return Q[:, :k]\n\n        # main loop\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            # choose center\n            if len(archive) > 0 and rng.rand() < 0.7:\n                # bias to best but sometimes pick a slightly worse elite\n                if rng.rand() < 0.75:\n                    center = archive[0][1].copy()\n                    center_f = archive[0][0]\n                else:\n                    idx = min(len(archive) - 1, rng.randint(0, len(archive)))\n                    center_f, center = archive[idx]\n                    center = center.copy()\n            else:\n                # random restart or jitter around best\n                if x_best is not None and rng.rand() < 0.6:\n                    jitter = (0.15 * avg_span) * rng.randn(self.dim)\n                    center = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                    res = eval_and_record(center)\n                    if res is None:\n                        break\n                    center_f, center = res\n                else:\n                    center = rng.uniform(lb, ub)\n                    res = eval_and_record(center)\n                    if res is None:\n                        break\n                    center_f, center = res\n\n            # cap the local budget for this attempt (leave room for future)\n            # mirrored probes cost 2 evals per direction; model building cost s evals.\n            max_local = min(remaining - 1, max(4, int(0.03 * self.budget)))\n            if max_local <= 0:\n                break\n\n            op = rng.rand()\n            success = False\n\n            # 1) Low-rank subspace model step\n            if op < p_model and max_local >= 4:\n                # choose subspace dimension k (1..min(4, dim))\n                k = min(self.dim, max(1, int(min(4, max(1, self.dim // 4)))))\n                k = max(1, int(rng.choice([1, min(2, k), k]) ))\n                U = random_subspace(k)  # dim x k\n                # choose sample radius (within trust)\n                sigma = trust_radius\n                # build small design: sample z coords in [-1,1] scaled by sigma\n                s = min(max_local, 2 + 2 * k)  # ensure > k for LS\n                Z = (rng.uniform(-1.0, 1.0, size=(s, k))).astype(float)\n                Xs = center.reshape(1, -1) + (Z @ (sigma * U.T)).reshape(s, self.dim)\n                # ensure bounds\n                for i in range(s):\n                    Xs[i] = np.minimum(np.maximum(Xs[i], lb), ub)\n                # evaluate planned design points as budget allows\n                fvals = []\n                evaled = 0\n                for i in range(s):\n                    if evals >= self.budget:\n                        break\n                    res = eval_and_record(Xs[i])\n                    if res is None:\n                        break\n                    fi, xi = res\n                    fvals.append(fi)\n                    evaled += 1\n                if len(fvals) < max(1, k):\n                    # nothing to do\n                    continue\n                fvals = np.asarray(fvals, dtype=float)\n                # center baseline estimate: optionally include center point if not included\n                # Solve linear model: f(z) ≈ a + g_sub^T z  (in subspace coordinates)\n                # Build design matrix with columns [1, Z]\n                Z_used = Z[: len(fvals), :]\n                A = np.concatenate([np.ones((len(fvals), 1)), Z_used], axis=1)\n                # solve least squares\n                try:\n                    sol, *_ = np.linalg.lstsq(A, fvals, rcond=None)\n                    a = sol[0]\n                    g_sub = sol[1:]\n                    # build full-space gradient approx\n                    g_full = (U @ g_sub).astype(float)\n                    # propose step - move opposite to gradient estimate\n                    step_scale = sigma * (1.0 + 0.5 * heavy_tail_scalar() * 0.1)  # small heavy-tail mix\n                    proposed = center - step_scale * g_full / (np.linalg.norm(g_full) + 1e-12)\n                    proposed = np.minimum(np.maximum(proposed, lb), ub)\n                    res = eval_and_record(proposed)\n                    if res is None:\n                        break\n                    fprop, xprop = res\n                    if fprop < center_f:\n                        # success: expand trust\n                        trust_radius = min(trust_max, trust_radius * expand_factor)\n                        success = True\n                    else:\n                        # failure: shrink trust\n                        trust_radius = max(trust_min, trust_radius * shrink_factor)\n                        success = False\n                except Exception:\n                    # fallback: skip\n                    trust_radius = max(trust_min, trust_radius * shrink_factor)\n                    success = False\n\n            # 2) Mirrored directional exploitation (gradient-free directional derivatives)\n            elif op < p_model + p_directional and max_local >= 2:\n                # choose number of directions d (1..min(dim, 4)), each uses 2 evals (mirrored)\n                d = min(self.dim, max(1, int(1 + rng.randint(0, min(3, self.dim - 1)))))\n                d = min(d, max(1, max_local // 2))\n                # build directions: prefer archive differences to capture promising landscape directions\n                directions = []\n                if len(archive) >= 2 and rng.rand() < 0.7:\n                    # differences between elites\n                    for i in range(min(d, len(archive)-1)):\n                        v = archive[i+1][1] - archive[0][1]\n                        if np.linalg.norm(v) > 0:\n                            directions.append(v / (np.linalg.norm(v) + 1e-12))\n                # fill remaining with random directions\n                while len(directions) < d:\n                    v = rng.randn(self.dim)\n                    v = v / (np.linalg.norm(v) + 1e-12)\n                    directions.append(v)\n                # mirrored probes\n                grad_est = np.zeros(self.dim, dtype=float)\n                used = 0\n                for v in directions:\n                    if evals + 2 > self.budget:\n                        break\n                    delta = trust_radius * (0.6 + 0.8 * rng.rand())  # in (0.6..1.4)*trust\n                    xp = center + delta * v\n                    xn = center - delta * v\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    xn = np.minimum(np.maximum(xn, lb), ub)\n                    res1 = eval_and_record(xp)\n                    if res1 is None:\n                        break\n                    res2 = eval_and_record(xn)\n                    if res2 is None:\n                        break\n                    fp, _ = res1\n                    fn, _ = res2\n                    # central difference directional derivative\n                    ddir = (fp - fn) / (2.0 * delta)\n                    # accumulate gradient estimate (note sign: derivative of f along v)\n                    grad_est += ddir * v\n                    used += 2\n                if used == 0:\n                    # nothing done\n                    continue\n                # propose step along -grad_est with adaptive step length\n                gnorm = np.linalg.norm(grad_est)\n                if gnorm < 1e-12:\n                    # small derivatives -> small random search in trust region\n                    step = trust_radius * rng.randn(self.dim) * 0.3\n                else:\n                    step = - (trust_radius * 0.9) * grad_est / gnorm\n                proposed = center + step\n                proposed = np.minimum(np.maximum(proposed, lb), ub)\n                res = eval_and_record(proposed)\n                if res is None:\n                    break\n                fprop, xprop = res\n                if fprop < center_f:\n                    trust_radius = min(trust_max, trust_radius * expand_factor)\n                    success = True\n                else:\n                    trust_radius = max(trust_min, trust_radius * shrink_factor)\n                    success = False\n\n            # 3) Global heavy-tailed restart / diversification\n            else:\n                # propose a heavy-tailed move from an elite center or uniform\n                if len(archive) > 0 and rng.rand() < 0.75:\n                    base = archive[0][1] if rng.rand() < 0.85 else archive[rng.randint(0, len(archive))][1]\n                else:\n                    base = rng.uniform(lb, ub)\n                # choose jump: mix of Cauchy-scaled average-span and archive covariance\n                c = heavy_tail_scalar()\n                anis = (0.2 + 0.8 * rng.rand()) * diag_span  # per-dim scaling\n                jump = c * (0.6 + 0.8 * rng.rand()) * anis * rng.randn(self.dim)\n                proposed = base + jump\n                proposed = np.minimum(np.maximum(proposed, lb), ub)\n                res = eval_and_record(proposed)\n                if res is None:\n                    break\n                fprop, xprop = res\n                # if promising do a tiny local polish (1-3 evals)\n                if fprop < (archive[0][0] if len(archive) > 0 else np.inf) * 1.05 and evals < self.budget:\n                    local_try = min(3, self.budget - evals)\n                    # small gaussian polish\n                    for _ in range(local_try):\n                        y = xprop + 0.12 * avg_span * rng.randn(self.dim)\n                        y = np.minimum(np.maximum(y, lb), ub)\n                        res = eval_and_record(y)\n                        if res is None:\n                            break\n                        fy, yx = res\n                        if fy < fprop:\n                            fprop, xprop = fy, yx\n                    # adjust trust radius based on improvement\n                if fprop < center_f:\n                    trust_radius = min(trust_max, trust_radius * expand_factor)\n                    success = True\n                else:\n                    trust_radius = max(trust_min, trust_radius * shrink_factor)\n                    success = False\n\n            # occasional uniform injection to maintain exploration\n            if attempt % 23 == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # adaptive probability nudging: if many failures, encourage global moves\n            if attempt % 11 == 0:\n                if len(archive) >= 2:\n                    spread = np.linalg.norm(archive[0][1] - archive[-1][1])\n                    if spread < 0.02 * avg_span:\n                        # archive clustered -> more global\n                        p_global = min(0.6, p_global + 0.05)\n                        p_model = max(0.15, p_model - 0.02)\n                        p_directional = max(0.15, p_directional - 0.02)\n                    else:\n                        # slowly decay global\n                        p_global = max(0.05, p_global * 0.98)\n                        p_model = min(0.7, p_model * 1.01)\n                        p_directional = min(0.7, p_directional * 1.01)\n                # re-normalize to sum 1\n                ssum = p_model + p_directional + p_global\n                p_model /= ssum; p_directional /= ssum; p_global /= ssum\n\n            # stop if budget nearly exhausted\n            if evals >= self.budget:\n                break\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AMDS scored 0.238 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "188a3a49-ae94-4c3e-b458-f640f8fc578c", "operator": null, "metadata": {"aucs": [0.11033950435607698, 0.14938011100774917, 0.304865076945667, 0.4052972056048618, 0.20552510887013942, 0.32682682949722697, 0.2358714523444434, 0.26694641082880666, 0.22531980084234748, 0.14851104495528833]}, "task_prompt": ""}
{"id": "a6c97156-5eb7-4d59-985a-d24a554c7ddb", "fitness": 0.20036018052340593, "name": "ADRS", "description": "ADRS maintains a small elite archive (init_samples default ≈4*dim, archive_size 4–12) that is updated on every evaluation and used as the basis for most decisions. It builds search directions from the archive with a PCA-like principal direction routine (archive_principal_direction) and biases directional searches toward cand − best when promising, while global proposals use anisotropic Gaussian sampling scaled by per-dimension archive variances. Local refinement is a budget-aware 1D directional line-search that aggressively expands on improvement (s *= 1.8) and otherwise shrinks (shrink = 0.7), with per-line budgets controlled by line_budget_frac (default ~0.045) and strict clipping/budget checks in eval_and_record. Diversification comes from occasional isotropic Gaussian bursts (burst_prob ~0.04), random injections and an adaptive mix between global and local moves controlled by global_prob (default 0.35) and slowly decaying step sizes (global_step ≈0.5·avg_span, local_step ≈0.35·avg_span, step_decay 0.96).", "code": "import numpy as np\n\nclass ADRS:\n    \"\"\"\n    Adaptive Directional Restart Search (ADRS)\n\n    Short description:\n    - Maintain a small elite archive of best points.\n    - Build preferred search directions from archive (PCA-like) and use those\n      for budget-aware 1D directional searches (line-expansion + shrink).\n    - Use anisotropic global sampling (Gaussian scaled by archive variances)\n      to explore, and occasional isotropic Gaussian bursts for diversification.\n    - Adaptive step sizes decay slowly; local line budgets are a fraction of total budget.\n    - All evaluations are clipped to bounds and strictly budget-aware.\n\n    Main parameters (tunable):\n    - init_samples: initial uniform samples (default ~4*dim, clipped to budget)\n    - archive_size: number of elites kept (default 6..12 depending on dim)\n    - global_prob: probability to perform a global anisotropic sample on each attempt\n    - burst_prob: probability to do an isotropic gaussian burst (diversifier)\n    - line_budget_frac: fraction of budget allowed for a single directional (line) search\n    - step_decay: multiplicative decay applied to global/local step after each attempt\n    - shrink: shrink factor used during line-search when no progress\n    \"\"\"\n    def __init__(self, budget=10000, dim=10,\n                 init_samples=None,\n                 archive_size=None,\n                 global_prob=0.35,\n                 burst_prob=0.04,\n                 line_budget_frac=0.045,\n                 step_decay=0.96,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.global_prob = float(global_prob)\n        self.burst_prob = float(burst_prob)\n        self.line_budget_frac = float(line_budget_frac)\n        self.step_decay = float(step_decay)\n        self.shrink = 0.7\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive defaults\n        if self.init_samples is None:\n            init_samples = max(8, min(40, 4 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, self.budget)\n\n        if self.archive_size is None:\n            archive_k = max(4, min(12, init_samples // 2))\n        else:\n            archive_k = int(self.archive_size)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of tuples (f, x), sorted by f\n\n        def update_archive(fv, xv):\n            nonlocal archive\n            # insert sorted\n            if len(archive) < archive_k or fv < archive[-1][0]:\n                archive.append((float(fv), xv.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # clip to bounds\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            update_archive(float(f), x)\n            return float(f), x\n\n        # initial uniform sampling\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # fallback if empty archive\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # initial step lengths (large but not extreme)\n        global_step = 0.5 * avg_span  # used for anisotropic global proposals\n        local_step = 0.35 * avg_span  # used for directional line-search initial step\n\n        # helper: build directional distribution from archive (PCA-like)\n        def archive_principal_direction():\n            # if archive has few items, return random unit vector\n            if len(archive) <= 1:\n                v = rng.randn(self.dim)\n                v /= max(1e-12, np.linalg.norm(v))\n                return v\n            # build matrix of deviations from best (or mean)\n            points = np.stack([a[1] for a in archive], axis=0)\n            center = points.mean(axis=0)\n            M = points - center\n            # small regularization\n            cov = (M.T @ M) / max(1, M.shape[0]) + 1e-8 * np.eye(self.dim)\n            # power iteration to get leading eigenvector (cheap)\n            b = rng.randn(self.dim)\n            for _ in range(6):\n                b = cov @ b\n                nrm = np.linalg.norm(b)\n                if nrm == 0:\n                    b = rng.randn(self.dim)\n                else:\n                    b /= nrm\n            return b\n\n        # directional 1D line search (budget-aware): expand along +dir/-dir, then zoom by shrinking\n        def directional_line_search(x0, f0, direction, budget_for_line, start_step):\n            nonlocal evals, f_best, x_best\n            if budget_for_line <= 0 or evals >= self.budget:\n                return f0, x0\n            d = np.asarray(direction, dtype=float)\n            nrm = np.linalg.norm(d)\n            if nrm == 0:\n                d = rng.randn(self.dim)\n                d /= np.linalg.norm(d)\n            else:\n                d = d / nrm\n\n            # try center, +s, -s\n            s = float(start_step)\n            best_x = x0.copy()\n            best_f = float(f0)\n\n            # ensure we don't evaluate a point we already have in x0 (we already know f0)\n            remaining = min(budget_for_line, self.budget - evals)\n            # attempt loop\n            iter_count = 0\n            while remaining > 0 and s > 1e-12:\n                iter_count += 1\n                # probe +s\n                if remaining <= 0:\n                    break\n                xp = np.minimum(np.maximum(x0 + s * d, lb), ub)\n                res = eval_and_record(xp)\n                remaining = min(budget_for_line, self.budget - evals)\n                if res is None:\n                    break\n                fp, xp = res\n                if fp < best_f:\n                    best_f = fp\n                    best_x = xp.copy()\n                    # try to expand further in same direction (aggressive)\n                    s *= 1.8\n                    # continue with same x0 updated to xp (we focus search around improvement)\n                    x0, f0 = best_x.copy(), best_f\n                    remaining = min(budget_for_line, self.budget - evals)\n                    continue\n                # probe -s\n                if remaining <= 0:\n                    break\n                xn = np.minimum(np.maximum(x0 - s * d, lb), ub)\n                res = eval_and_record(xn)\n                remaining = min(budget_for_line, self.budget - evals)\n                if res is None:\n                    break\n                fn, xn = res\n                if fn < best_f:\n                    best_f = fn\n                    best_x = xn.copy()\n                    s *= 1.8\n                    x0, f0 = best_x.copy(), best_f\n                    remaining = min(budget_for_line, self.budget - evals)\n                    continue\n                # if neither side improved, shrink step\n                s *= self.shrink\n                remaining = min(budget_for_line, self.budget - evals)\n            return best_f, best_x\n\n        attempt = 0\n        # main loop\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            # allocate a small line budget (respect remaining)\n            alloc_line = min(max(3, int(self.line_budget_frac * self.budget)), remaining - 1) if remaining > 1 else 0\n\n            # occasionally perform a Gaussian burst diversification\n            if rng.rand() < self.burst_prob:\n                burst_scale = 0.6 * avg_span * max(0.1, 1.0 - attempt * 0.01)\n                x_burst = np.minimum(np.maximum((x_best if x_best is not None else rng.uniform(lb, ub)) + burst_scale * rng.randn(self.dim), lb), ub)\n                res = eval_and_record(x_burst)\n                if res is None:\n                    break\n                # small local polish if promising\n                fb, xb = res\n                if alloc_line > 0 and fb < (archive[0][0] if len(archive) > 0 else np.inf) * 1.05:\n                    directional_line_search(xb, fb, rng.randn(self.dim), min(alloc_line, remaining - 1), local_step * 0.6)\n                # decay steps\n                global_step *= self.step_decay\n                local_step *= self.step_decay\n                continue\n\n            # choose between global anisotropic sampling and local directional search\n            if rng.rand() < self.global_prob:\n                # global anisotropic sample using archive variance as per-dim scale\n                if len(archive) >= 2:\n                    pts = np.stack([a[1] for a in archive], axis=0)\n                    per_dim_var = np.var(pts, axis=0) + 1e-8\n                else:\n                    per_dim_var = (0.3 * avg_span) ** 2 * np.ones(self.dim)\n                # sample anisotropic Gaussian\n                scale_diag = np.sqrt(per_dim_var) * (0.8 + 0.4 * rng.rand(self.dim))\n                cand = (archive[0][1] if len(archive) > 0 and rng.rand() < 0.6 else rng.uniform(lb, ub)).copy()\n                cand += (rng.randn(self.dim) * scale_diag) * (global_step / (0.5 * avg_span))\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                fc, xc = res\n                # if promising, do a directed line-search along principal archive direction\n                if alloc_line > 0 and fc <= (archive[0][0] if len(archive) > 0 else np.inf) * 1.12:\n                    direction = archive_principal_direction()\n                    # bias direction towards cand - best\n                    if x_best is not None:\n                        bias = xc - x_best\n                        if np.linalg.norm(bias) > 1e-12:\n                            direction = 0.6 * (bias / np.linalg.norm(bias)) + 0.4 * direction\n                            direction /= max(1e-12, np.linalg.norm(direction))\n                    line_budget = min(alloc_line, remaining - 1)\n                    directional_line_search(xc, fc, direction, line_budget, local_step)\n            else:\n                # local directional refinement from best or a random elite\n                if len(archive) > 0 and rng.rand() < 0.75:\n                    start_f, start_x = archive[0]\n                elif len(archive) > 1:\n                    idx = rng.randint(0, len(archive))\n                    start_f, start_x = archive[idx]\n                else:\n                    # random start\n                    start_x = rng.uniform(lb, ub)\n                    res = eval_and_record(start_x)\n                    if res is None:\n                        break\n                    start_f, start_x = res\n\n                # get a direction from archive PCA with some randomization\n                direction = archive_principal_direction()\n                if rng.rand() < 0.35:\n                    # random orthogonal perturbation to escape ridges\n                    direction += 0.3 * rng.randn(self.dim)\n                # set per-line budget (keep at least 1 eval for other strategies)\n                line_budget = min(alloc_line, max(2, int(0.06 * remaining)))\n                directional_line_search(start_x, start_f, direction, line_budget, local_step)\n\n            # small random injection occasionally\n            if (attempt % 13) == 0 and evals < self.budget:\n                xr = rng.uniform(lb, ub)\n                eval_and_record(xr)\n\n            # adapt probabilities and steps slowly\n            # if archive collapsed (low diversity), increase global_prob to escape\n            if len(archive) >= 2:\n                div = np.linalg.norm(archive[0][1] - archive[-1][1])\n                if div < 0.01 * avg_span:\n                    self.global_prob = min(0.85, self.global_prob + 0.03)\n                else:\n                    self.global_prob = max(0.05, self.global_prob * 0.995)\n            global_step *= self.step_decay\n            local_step *= self.step_decay\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ADRS scored 0.200 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "188a3a49-ae94-4c3e-b458-f640f8fc578c", "operator": null, "metadata": {"aucs": [0.06135924580990071, 0.16166620456011715, 0.24500122977765937, 0.3494777198592669, 0.1506318482677964, 0.393055649145835, 0.1773276958611788, 0.1934216527798318, 0.15715009656461054, 0.11451046260786246]}, "task_prompt": ""}
{"id": "b6db7a7e-9699-49c0-ad02-a3fdafec2752", "fitness": 0.4553637487959322, "name": "EliteDifferentialPatternSearch", "description": "EDPS keeps a small sorted elite archive (size chosen from init samples, budget-aware) and generates candidates via three complementary operators: DE-style differential recombination (best-biased with jitter), anisotropic heavy-tailed Cauchy jumps from elites, and a Hooke–Jeeves-like local pattern search with per-dimension adaptive steps (base_step = 0.25·span, expand=1.3, shrink=0.6, pattern_factor=1.5). Initialization is space-filling and budget-aware (init_samples = min(6·dim, budget/4); archive_k in [3..12]) and occasional uniform injections (inject_period=17) maintain diversity. The algorithm adaptively biases operator probabilities and the differential scale F based on measured elite spread (clustered elites increase global moves and F), while Cauchy jump scale decays as budget is consumed and differential F_loc increases when elites are close to encourage exploration. A small local-budget fraction (local_budget_frac≈0.03) is reserved for coordinate-wise randomized exploratory refinements and pattern extensions, and every evaluation is clipped to bounds and recorded to update the archive and steering decisions.", "code": "import numpy as np\n\nclass EliteDifferentialPatternSearch:\n    \"\"\"\n    Elite-Differential Pattern Search (EDPS)\n\n    Main ideas:\n    - Keep a small elite archive of best points.\n    - Propose candidates via (1) differential recombination among elites,\n      (2) heavy-tailed Cauchy jumps from elites, or (3) local pattern searches.\n    - Local searches are Hooke-Jeeves-like with per-dimension adaptive step sizes.\n    - Budget-aware wrapper ensures we never call func more than self.budget.\n    - Occasional uniform injections maintain diversity; adaptive rates react to archive clustering.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 init_samples=None, archive_size=None,\n                 local_budget_frac=0.03, F=0.8, cr=0.9):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.local_budget_frac = float(local_budget_frac)\n        self.F = float(F)   # differential scale\n        self.cr = float(cr) # crossover probability (not heavily used but kept)\n        # will set results after run\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive initial sampling and archive size\n        if self.init_samples is None:\n            init_samples = max(12, min(60, 6 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, max(1, self.budget // 4))\n\n        if self.archive_size is None:\n            archive_k = max(3, min(12, init_samples // 3))\n        else:\n            archive_k = int(self.archive_size)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of tuples (f, x)\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            f = float(f)\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # maintain sorted archive\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # initial sampling (space-filling uniform)\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # fallback ensure at least one point\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # initial per-dim step sizes for local search (proportional to span)\n        base_step = 0.25 * span  # somewhat large initial step\n        base_step = np.maximum(base_step, 1e-8)\n\n        # parameters\n        shrink = 0.6\n        expand = 1.3\n        pattern_factor = 1.5\n\n        # adaptive probabilities\n        p_diff = 0.42\n        p_cauchy = 0.28\n        p_local = 0.28  # leftover for local\n        # occasional injection every N attempts\n        inject_period = 17\n\n        attempt = 0\n\n        def global_cauchy_jump(center, scale_factor):\n            # produce heavy-tailed displacement with per-dim anisotropy from span\n            direction = rng.randn(self.dim)\n            norm = np.linalg.norm(direction) + 1e-12\n            direction /= norm\n            # Cauchy scalar\n            step_len = rng.standard_cauchy()\n            step_len = np.clip(step_len, -1e3, 1e3)\n            # anisotropic scaling\n            anis = 0.5 + 0.5 * rng.rand()\n            step = direction * (scale_factor * avg_span * anis)\n            return center + step_len * step\n\n        def differential_recombination():\n            # produce candidate from archive differences (DE-like)\n            if len(archive) < 3:\n                return rng.uniform(lb, ub)\n            # choose a (best-biased), b, c distinct\n            idxs = list(range(len(archive)))\n            a_idx = 0 if rng.rand() < 0.7 else rng.randint(0, len(archive))\n            idxs.remove(a_idx)\n            b_idx = rng.choice(idxs)\n            idxs.remove(b_idx)\n            c_idx = rng.choice(idxs)\n            a = archive[a_idx][1]\n            b = archive[b_idx][1]\n            c = archive[c_idx][1]\n            diff = b - c\n            # adapt F slightly based on diversity (larger F if elites clustered)\n            elite_spread = np.linalg.norm(archive[0][1] - archive[-1][1]) + 1e-12\n            F_loc = self.F * (1.0 + 0.5 * np.exp(-elite_spread / (avg_span + 1e-12)))\n            cand = a + F_loc * diff\n            # add small gaussian jitter scaled by per-dim span\n            cand += 0.05 * (rng.randn(self.dim) * span)\n            return cand\n\n        def local_search(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            steps = base_step.copy()\n            local_used = 0\n            # limit iterations so we don't exceed budget\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_used < local_budget and iters < iter_limit and np.any(steps > 1e-12):\n                iters += 1\n                improved = False\n                x_probe = base.copy()\n                x_probe_f = base_f\n                # exploratory moves along coordinates (random order for robustness)\n                order = list(range(self.dim))\n                rng.shuffle(order)\n                for i in order:\n                    if local_used >= local_budget or evals >= self.budget:\n                        break\n                    # positive\n                    xp = x_probe.copy()\n                    xp[i] += steps[i]\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res = eval_and_record(xp)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < x_probe_f:\n                        x_probe = xp.copy()\n                        x_probe_f = fp\n                        improved = True\n                        # increase this coordinate step a little\n                        steps[i] *= expand\n                        continue\n                    # negative\n                    xn = x_probe.copy()\n                    xn[i] -= steps[i]\n                    xn = np.minimum(np.maximum(xn, lb), ub)\n                    res = eval_and_record(xn)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < x_probe_f:\n                        x_probe = xn.copy()\n                        x_probe_f = fn\n                        improved = True\n                        steps[i] *= expand\n                # pattern / extension\n                if improved and local_used < local_budget and evals < self.budget:\n                    direction = x_probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_and_record(xp)\n                        local_used += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < x_probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = x_probe.copy()\n                                base_f = x_probe_f\n                        else:\n                            base = x_probe.copy()\n                            base_f = x_probe_f\n                    else:\n                        base = x_probe.copy()\n                        base_f = x_probe_f\n                else:\n                    # shrink steps\n                    steps *= shrink\n                # safety\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # Main loop\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            # dynamic local allocation\n            alloc_local = min(max(3, int(self.local_budget_frac * self.budget)), remaining - 1) if remaining > 1 else 0\n\n            # adjust probabilities slightly based on diversity\n            if len(archive) >= 2:\n                spread = np.linalg.norm(archive[0][1] - archive[-1][1])\n            else:\n                spread = avg_span\n            # if archive clustered, favor global moves\n            p_diff_local = p_diff * (0.9 + 0.2 * (spread / (avg_span + 1e-12)))\n            p_cauchy_local = p_cauchy * (1.1 - 0.5 * (spread / (avg_span + 1e-12)))\n            # normalize to keep sum <= 0.95 for some local fraction\n            s = p_diff_local + p_cauchy_local\n            if s > 0.95:\n                p_diff_local *= 0.95 / s\n                p_cauchy_local *= 0.95 / s\n            r = rng.rand()\n            done_local_search = False\n\n            if r < p_diff_local and len(archive) >= 3:\n                # differential recombination proposal\n                cand = differential_recombination()\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n                # small local refine if promising\n                threshold = archive[0][0] * 1.05 if len(archive) > 0 else np.inf\n                if alloc_local > 0 and f_cand <= threshold:\n                    local_budget = min(remaining - 1, max(2, alloc_local))\n                    f_after, x_after = local_search(cand, f_cand, local_budget)\n                    done_local_search = True\n            elif r < p_diff_local + p_cauchy_local and len(archive) > 0:\n                # heavy-tailed Cauchy jump from an elite\n                if rng.rand() < 0.75:\n                    center = archive[0][1]\n                else:\n                    idx = rng.randint(0, len(archive))\n                    center = archive[idx][1]\n                # scale decreases as budget used to focus\n                scale = max(0.03, 1.0 - (evals / max(1, self.budget)) * 0.9)\n                cand = global_cauchy_jump(center, scale)\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n                # if promising, do local refine\n                if alloc_local > 0 and f_cand <= (archive[0][0] if len(archive)>0 else np.inf) * 1.1:\n                    local_budget = min(remaining - 1, max(2, 3 * alloc_local))\n                    f_after, x_after = local_search(cand, f_cand, local_budget)\n                    done_local_search = True\n            else:\n                # local refinement or jittered restart\n                choice = rng.rand()\n                if len(archive) > 0 and choice < 0.65:\n                    start_f, start_x = archive[0]\n                elif len(archive) > 1 and choice < 0.92:\n                    idx = rng.randint(0, len(archive))\n                    start_f, start_x = archive[idx]\n                else:\n                    # jittered restart around best or uniform if no best\n                    if x_best is not None:\n                        jitter = 0.12 * avg_span * rng.randn(self.dim)\n                        start_x = x_best + jitter\n                        start_x = np.minimum(np.maximum(start_x, lb), ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                    else:\n                        start_x = rng.uniform(lb, ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                # local budget\n                local_budget = min(alloc_local, max(2, int(0.04 * remaining)))\n                if local_budget > 0:\n                    f_after, x_after = local_search(start_x, start_f, local_budget)\n                    done_local_search = True\n\n            # occasional uniform injection to maintain diversity\n            if (attempt % inject_period) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # small adaptive adjustments: if archive gets too clustered, increase global jump emphasis\n            if len(archive) >= 2:\n                cluster_norm = np.linalg.norm(archive[0][1] - archive[-1][1])\n                if cluster_norm < 1e-8 + 0.02 * avg_span:\n                    # increase global randomness a bit by increasing F and biasing to cauchy proposals\n                    self.F = min(1.6, self.F * 1.03)\n                else:\n                    self.F = max(0.6, self.F * 0.999)\n\n            # break if budget used\n            if evals >= self.budget:\n                break\n\n        # finish\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EliteDifferentialPatternSearch scored 0.455 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "188a3a49-ae94-4c3e-b458-f640f8fc578c", "operator": null, "metadata": {"aucs": [0.10405169603591424, 0.1562161321771106, 0.9104346694791896, 0.9887043890591071, 0.30703517373545186, 0.9827203896178983, 0.2444389840399004, 0.3724913099359176, 0.3327285583484203, 0.15481618553041177]}, "task_prompt": ""}
{"id": "a1972bb9-6405-4e8b-a83a-27fbcf95e68b", "fitness": 0.40644140267899076, "name": "OPCMA_TR", "description": "The algorithm couples a compact CMA-like core (mean m, covariance C, step-size sigma) with robust numerical safeguards (chol_safe, SPD enforcement) and a covariance floor/blend to avoid collapse (C blend ~0.985/0.015 with a span-scaled floor); sigma is adapted by a smoothed 1/5th-like rule (sigma_adapt_rate ≈ 0.22, success_target 0.2). Sampling mixes Gaussian CMA proposals (about half) with an adaptive operator pool (diff-to-mean, gaussian-local, elite-mix, levy jump) that produces the other half; operators are selected by soft credits that decay (decay 0.9) and are increased by empirical successes, and operator selection probabilities are normalized with a small floor. Per-individual trust radii (init ~0.12·mean_range) steer local proposals and are expanded/shrunk (trust_expand 1.12, trust_shrink 0.88) based on operator outcomes, while an archive of elites (size ~4·dim clipped) supports elite recombination and credit baselines (median/archive used for success tests). Initialization emphasizes diversity (mirrored-opposition sampling, small-pop tuned as 4+3·log(dim)), boundaries use reflect/clamp, and stagnation handling includes heavy-tailed/Levy escapes (levy_prob 0.2), isotropic re-seeding, and re-centering to robustly recover from local collapse.", "code": "import numpy as np\n\nclass OPCMA_TR:\n    \"\"\"\n    Operator-Pooled Compact CMA with Trust Radii (OPCMA_TR)\n\n    Main ideas (one-line): compact CMA-like mean/covariance/sigma core drives Gaussian sampling and covariance learning,\n    while an adaptive operator pool plus per-individual trust radii supply diverse proposals; operators are credited\n    by success and sigma is adapted via a smoothed 1/5th-like rule, with covariance-safe updates and stagnation restarts.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n\n        # strategy knobs (tunable)\n        self.pop_base = None                # if None, adaptively chosen\n        self.cov_lr = 0.2                   # covariance learning rate (rank-mu blend)\n        self.sigma_adapt_rate = 0.22        # speed of sigma adaptation\n        self.success_target = 0.2           # target success rate for 1/5th-like rule\n        self.trust_init_frac = 0.12         # initial trust radius fraction of mean range\n        self.trust_expand = 1.12\n        self.trust_shrink = 0.88\n        self.archive_size = max(6, min(40, 4 * self.dim))\n        self.stagnation_limit = max(8, int(0.03 * self.budget))\n        self.levy_prob = 0.20\n        self.min_sigma = 1e-12\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds support scalar or per-dim\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        mean_range = float(np.mean(span))\n\n        # adaptive small population\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # mirrored-opposition-ish initialization for diversity: sample half and mirror\n        pop = max(12, lam)\n        pop = min(pop, max(2, self.budget))\n        half = (pop + 1) // 2\n        X = np.empty((pop, self.dim), dtype=float)\n        center = 0.5 * (lb + ub)\n        for i in range(half):\n            u = rng.rand(self.dim)\n            X[i] = lb + u * (ub - lb)\n            j = i + half\n            if j < pop:\n                X[j] = 2.0 * center - X[i]\n        X += rng.randn(pop, self.dim) * 1e-6  # tiny jitter\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        evals = 0\n        # evaluate initial subset up to lam to get a starting mean\n        initial_batch = min(pop, max(4, lam))\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(initial_batch):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        # if budget exhausted during init\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:initial_batch]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # initialize mean from top-half of initial evaluated\n        valid_idx = np.where(np.isfinite(f))[0]\n        if valid_idx.size == 0:\n            m = 0.5 * (lb + ub)\n        else:\n            mu0 = max(1, len(valid_idx) // 2)\n            order0 = np.argsort(f[valid_idx])\n            elites0 = X[valid_idx][order0[:mu0]]\n            weights0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n            weights0 = np.maximum(weights0, 0.0)\n            weights0 = weights0 / np.sum(weights0)\n            m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance: moderate isotropic scaled to bounds\n        C = np.diag(((span / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(self.min_sigma, 0.25 * mean_range)\n\n        # per-individual trust radii (for operator-local proposals)\n        init_radius = max(1e-12, self.trust_init_frac * mean_range)\n        radius = np.full(pop, init_radius, dtype=float)\n\n        # operator pool: 0=diff-to-mean,1=gaussian_local,2=elite_mix,3=levy_jump\n        n_ops = 4\n        op_credit = np.ones(n_ops, dtype=float)\n\n        # archive of elites\n        archive_X = []\n        archive_f = []\n\n        # state variables\n        p_succ = self.success_target\n        stagn_no_improve = 0\n        f_best = np.inf\n        x_best = None\n\n        # helper functions\n        def chol_safe(Cmat):\n            eps = 1e-12 * np.maximum(np.diag(Cmat), 1.0)\n            try:\n                A = np.linalg.cholesky(Cmat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(Cmat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        def reflect_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        def op_probabilities():\n            tot = np.sum(op_credit)\n            if tot <= 0:\n                return np.full(n_ops, 1.0 / n_ops)\n            probs = op_credit / tot\n            # add tiny floor and renormalize\n            probs = np.maximum(probs, 1e-6)\n            probs = probs / np.sum(probs)\n            return probs\n\n        def archive_add(x, fx):\n            nonlocal archive_X, archive_f\n            if len(archive_f) < self.archive_size:\n                archive_X.append(x.copy())\n                archive_f.append(float(fx))\n            else:\n                worst = int(np.argmax(archive_f))\n                if fx < archive_f[worst]:\n                    archive_X[worst] = x.copy()\n                    archive_f[worst] = float(fx)\n            # maintain sorted order lazily when needed\n\n        # incorporate initial evaluated points into archive/best\n        for i in range(initial_batch):\n            if np.isfinite(f[i]):\n                archive_add(X[i], f[i])\n                if f[i] < f_best:\n                    f_best = float(f[i])\n                    x_best = X[i].copy()\n\n        # main loop: keep producing mixed candidate sets until budget exhausted\n        iter_count = 0\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu = max(1, lam_iter // 2)\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # prepare SPD transform for Gaussian proposals\n            A = chol_safe(C)\n\n            # decide mix: half Gaussian around m, half operator-driven (or fallback)\n            n_gauss = lam_iter // 2\n            n_ops_prop = lam_iter - n_gauss\n\n            Xcand = np.empty((lam_iter, self.dim), dtype=float)\n            cand_origin = np.array([''] * lam_iter)  # tag origins for crediting\n\n            # Gaussian proposals\n            if n_gauss > 0:\n                Z = rng.normal(size=(n_gauss, self.dim))\n                Y = Z @ (A.T)\n                Xg = m + sigma * Y\n                Xg = np.minimum(np.maximum(Xg, lb), ub)\n                Xcand[:n_gauss] = Xg\n                cand_origin[:n_gauss] = 'gauss'\n\n            # operator-driven proposals\n            probs = op_probabilities()\n            elites_idx = np.argsort(np.array(archive_f) if len(archive_f)>0 else np.array([np.inf]))[:max(2, min(len(archive_f), mu))]\n            for i in range(n_ops_prop):\n                idx = n_gauss + i\n                # choose operator by current probs\n                op = rng.choice(n_ops, p=probs)\n                cand_origin[idx] = f'op{op}'\n                # pick a base individual for trust radius & directional info\n                base_i = rng.randint(0, pop)\n                xi = X[base_i].copy()\n                # operator implementations\n                if op == 0:\n                    # diff-to-mean directional: pull towards mean + differential between two randoms\n                    others = [j for j in range(pop) if j != base_i]\n                    if len(others) >= 2:\n                        a, b = rng.choice(others, size=2, replace=False)\n                    elif len(others) == 1:\n                        a = b = others[0]\n                    else:\n                        a = b = base_i\n                    beta = 0.6 * rng.rand() + 0.2\n                    trial = xi + beta * (m - xi) + beta * (X[a] - X[b])\n                elif op == 1:\n                    # gaussian local around xi scaled by its trust radius\n                    scale = max(1e-12, radius[base_i])\n                    trial = xi + rng.randn(self.dim) * (scale * (0.4 + 0.6 * rng.rand()))\n                elif op == 2:\n                    # elite mix: recombine with an archive member if available, else with mean\n                    if len(archive_X) >= 1:\n                        elite = archive_X[rng.randint(len(archive_X))]\n                    else:\n                        elite = m\n                    alpha = 0.4 + 0.6 * rng.rand()\n                    trial = xi + alpha * (elite - xi) + rng.randn(self.dim) * 0.15 * radius[base_i]\n                else:\n                    # levy-like heavy-tailed from best or xi\n                    center = x_best if (x_best is not None and rng.rand() < 0.8) else xi\n                    scale = 0.6 * mean_range * (0.5 + rng.rand())\n                    jump = rng.standard_cauchy(self.dim) * (scale * 0.6)\n                    trial = center + jump\n\n                # reflect/clamp and assign\n                trial = reflect_clamp(trial)\n                Xcand[idx] = trial\n\n            # evaluate candidates sequentially, ensure not to exceed budget\n            f_cand = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                if evals >= self.budget:\n                    # mark remaining as inf\n                    f_cand[i:] = np.inf\n                    break\n                x_try = Xcand[i]\n                fval = float(func(x_try))\n                f_cand[i] = fval\n                evals += 1\n                # update global archive and best\n                archive_add(x_try, fval)\n                if fval < f_best or x_best is None:\n                    f_best = float(fval)\n                    x_best = x_try.copy()\n\n            # selection: pick top-mu from current candidate batch\n            order = np.argsort(f_cand)\n            X_mu = Xcand[order[:mu]]\n            f_mu = f_cand[order[:mu]]\n\n            # compute weighted new mean and normalized deltas\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas  # shape (dim,dim)\n\n            # covariance update with floor and blend\n            floor = np.diag(((span / 30.0) ** 2).clip(min=1e-12))\n            C = (1.0 - self.cov_lr) * C + self.cov_lr * weighted_cov + 1e-12 * np.eye(self.dim)\n            # blend with floor to avoid collapse\n            C = 0.985 * C + 0.015 * floor\n\n            # update mean\n            y_w = (m_new - m) / (sigma + 1e-20)\n            m = m_new.copy()\n\n            # evaluate improvement of batch relative to previous best to count successes\n            gen_improved = np.any(f_cand < f_best)  # but f_best was updated above; detect if any candidate improved archive before update:\n            # instead, count successes per candidate vs median or previous mean value: we'll consider a success when candidate improved global best at time of its evaluation\n            # compute successes by comparing f_mu to previous best prior to this generation (approx).\n            # For crediting operators, we mark success if candidate improved the best at its time of eval (we updated f_best already), so we credit those origins.\n            # We'll approximate by crediting origins for any candidate whose f equals new global best (rare) or was in top-mu with improvement over median stored f.\n            # Simpler and safe: credit operator if candidate's f <= median of previous archive_f (if archive non-empty).\n            prev_archive_median = np.median(np.array(archive_f)) if len(archive_f) > 0 else np.median(f_cand)\n            op_try = np.zeros(n_ops, dtype=float)\n            op_succ = np.zeros(n_ops, dtype=float)\n            for i in range(lam_iter):\n                origin = cand_origin[i]\n                if origin == '':\n                    continue\n                if origin.startswith('op'):\n                    op_idx = int(origin[2:])\n                elif origin == 'gauss':\n                    op_idx = 1  # count gaussian core as operator 1 for crediting\n                else:\n                    op_idx = 1\n                op_try[op_idx] += 1.0\n                if f_cand[i] <= prev_archive_median or f_cand[i] <= f_best:\n                    op_succ[op_idx] += 1.0\n\n            # update operator credits (decay + add successes)\n            decay = 0.9\n            op_credit = op_credit * decay + op_succ * (1.0 - decay)\n            op_credit = np.maximum(op_credit, 1e-8)\n\n            # step-size adaptation via smoothed success-rate (approx 1/5th rule)\n            # p_succ estimated from fraction of candidates that improved the run best during this batch\n            # because f_best might already be updated, estimate success_frac as proportion of candidates better than median archived before this generation\n            succ_frac = np.sum(f_cand < prev_archive_median) / max(1, np.sum(np.isfinite(f_cand)))\n            p_succ = 0.9 * p_succ + 0.1 * succ_frac\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = float(np.clip(sigma, self.min_sigma, 2.0 * np.max(span)))\n\n            # adapt trust radii: expand for individuals that produced improving proposals, shrink otherwise\n            # map candidate origins back to base indices is not tracked; instead expand globally small fraction if op_succ nonzero\n            if np.sum(op_succ) > 0:\n                # expand a random subset proportional to successes\n                n_expand = min(pop, int(1 + np.sum(op_succ)))\n                for jj in rng.choice(pop, size=n_expand, replace=False):\n                    radius[jj] = min(radius[jj] * self.trust_expand, mean_range)\n            else:\n                # shrink a few\n                for jj in rng.choice(pop, size=min(pop, 2), replace=False):\n                    radius[jj] = max(radius[jj] * self.trust_shrink, 1e-12)\n\n            # opportunistic restart / levy escapes on stagnation\n            # detect stagnation if many iterations without meaningful sigma growth or best not improving\n            if iter_count % 5 == 0:\n                # compute small diversity measure from eigenvalues\n                vals = np.clip(np.linalg.eigvalsh(C), 1e-16, None)\n                diversity = np.sqrt(np.max(vals))\n                if diversity < 1e-9 or stagn_no_improve * lam_iter >= self.stagnation_limit:\n                    # perform heavy-tailed jump anchored on best or random archive member\n                    if len(archive_X) > 0 and rng.rand() < self.levy_prob:\n                        anchor = archive_X[rng.randint(len(archive_X))]\n                        jump = rng.standard_cauchy(self.dim) * (0.6 * mean_range)\n                        x_jump = anchor + jump\n                        x_jump = np.minimum(np.maximum(x_jump, lb), ub)\n                        if evals < self.budget:\n                            fj = float(func(x_jump))\n                            evals += 1\n                            archive_add(x_jump, fj)\n                            if fj < f_best:\n                                f_best = fj\n                                x_best = x_jump.copy()\n                                # re-center mean and inflate sigma\n                                m = x_jump.copy()\n                                sigma = max(sigma, 0.4 * mean_range)\n                                C = np.diag(((span / 6.0) ** 2).clip(min=1e-12))\n                                stagn_no_improve = 0\n                            else:\n                                # mild nudge of mean toward best\n                                if x_best is not None:\n                                    m = 0.7 * m + 0.3 * x_best\n                                sigma = min(2.0 * np.max(span), sigma * 1.6)\n                    else:\n                        # isotropic re-seed around current best with jitter\n                        if x_best is not None:\n                            jitter = rng.randn(self.dim) * (0.08 * mean_range)\n                            m = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                        else:\n                            m = np.minimum(np.maximum(center + rng.randn(self.dim) * 0.3 * mean_range, lb), ub)\n                        C = np.diag(((span / 5.0) ** 2).clip(min=1e-12))\n                        sigma = max(sigma, 0.25 * mean_range)\n                        # slightly diversify radii\n                        radius *= 0.9\n                        stagn_no_improve = 0\n\n            # update stagn counter: count as no-improve if best hasn't changed recently\n            # (we updated f_best earlier when evaluating candidates; we track improvement via stagn_no_improve)\n            # If any candidate in batch improved, reset stagn; else increment\n            if np.any(f_cand < f_best):\n                stagn_no_improve = 0\n            else:\n                stagn_no_improve += 1\n\n            # safety SPD enforcement on C every few iterations\n            if iter_count % 11 == 0:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-16, None)\n                C = (vecs * vals) @ vecs.T\n\n            # loop continues until budget exhausted\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm OPCMA_TR scored 0.406 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "188a3a49-ae94-4c3e-b458-f640f8fc578c", "operator": null, "metadata": {"aucs": [0.1791478301391919, 0.2812051793344442, 0.4688601765942422, 0.8715105766916491, 0.40791356154057623, 0.5582647607069411, 0.2782696046003992, 0.40873219009585027, 0.4380877167494468, 0.17242243033716664]}, "task_prompt": ""}
{"id": "2811fe3d-dd7e-43cc-b4a9-d12e24b3df30", "fitness": 0.6479648967112452, "name": "AdaptiveSubspaceModelDE", "description": "The algorithm is a hybrid, population-based optimizer that keeps an evaluated-point archive (size scaled with dimension, seeded by an initial uniform batch) and operates inside -5..5 bounds with budget-aware pruning and population sizing (lambda ~ 4+3.5 log(dim), clipped to budget). It fits a lightweight quadratic surrogate in a dominant PCA subspace of elites to compute a predicted minimizer and generates \"model-guided\" proposals around that point. To maintain exploration it mixes subspace-weighted Gaussian sampling (CMA-like using a learned covariance), DE-style differential proposals (F_de=0.85, CR=0.9), and model proposals, while adaptively allocating resources between model vs diversity with a simple bandit-like success history (p_model) based on recent top-mu performance. Global adaptation uses rank-mu weighted covariance updates (cov_lr≈0.22), smoothed success-rule step-size adaptation (sigma_adapt_rate≈0.25, success_target≈0.2), and stagnation escapes via occasional heavy-tailed Cauchy jumps or opportunistic re-seeding.", "code": "import numpy as np\n\nclass AdaptiveSubspaceModelDE:\n    \"\"\"\n    AdaptiveSubspaceModelDE (ASMDE)\n\n    Main ideas:\n      - Maintain an archive of evaluated points and a global mean m, covariance C, and step sigma.\n      - Each iteration allocates proposals between: (A) model-guided minimizer candidates computed\n        from a lightweight quadratic surrogate in a PCA subspace, (B) subspace-CMA-style Gaussian\n        sampling along dominant eigenvectors, and (C) DE-style differential proposals from the archive.\n      - A small bandit/adaptive controller adjusts the fraction of model vs. diversity sampling by\n        tracking recent per-strategy success.\n      - Covariance and step-size are adapted using rank-mu style updates and a smoothed success-rule.\n      - Occasional heavy-tailed Cauchy (Lévy-like) escapes and opportunistic re-seeding when stagnating.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, seed=None, pop_base=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.pop_base = pop_base\n\n        # algorithm knobs\n        self.cov_lr = 0.22\n        self.sigma_adapt_rate = 0.25\n        self.success_target = 0.2\n        self.max_archive = min(60, max(12, 6 * self.dim))\n        self.init_archive = min(self.max_archive, max(12, 3 * self.dim))\n        self.stagnation_iters = max(12, int(0.06 * self.budget))\n        self.levy_prob = 0.2\n        self.F_de = 0.85\n        self.CR = 0.9\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds (Many BBOB uses -5..5 but use func.bounds if present)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = -5.0 * np.ones(self.dim)\n            ub = 5.0 * np.ones(self.dim)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        bounds_scale = ub - lb\n        center_bounds = 0.5 * (lb + ub)\n\n        # adaptive population size\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3.5 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # helpers\n        def clamp(x):\n            return np.minimum(np.maximum(x, lb), ub)\n\n        def chol_safe(Cmat):\n            eps = 1e-12 * np.maximum(np.diag(Cmat), 1.0)\n            try:\n                return np.linalg.cholesky(Cmat + np.diag(eps))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(Cmat)\n                vals = np.clip(vals, 1e-12, None)\n                return (vecs * np.sqrt(vals)).T\n\n        # initial uniform sampling to seed archive\n        evals = 0\n        init_batch = min(self.init_archive, max(4, self.dim + 2, lam * 2), self.budget)\n        X_init = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f_init = np.array([func(x) for x in X_init])\n        evals += init_batch\n\n        # archive (store as arrays)\n        archive_X = X_init.copy()\n        archive_f = f_init.copy()\n\n        def prune_archive():\n            nonlocal archive_X, archive_f\n            if len(archive_f) > self.max_archive:\n                order = np.argsort(archive_f)\n                keep = order[: self.max_archive]\n                archive_X = archive_X[keep].copy()\n                archive_f = archive_f[keep].copy()\n\n        def archive_add(x, fx):\n            nonlocal archive_X, archive_f\n            x = np.asarray(x, dtype=float).reshape(1, -1)\n            fx = float(fx)\n            if archive_f.size == 0:\n                archive_X = x.copy()\n                archive_f = np.array([fx], dtype=float)\n            else:\n                if archive_X.shape[0] < self.max_archive:\n                    archive_X = np.vstack([archive_X, x])\n                    archive_f = np.concatenate([archive_f, np.array([fx])])\n                else:\n                    worst = int(np.argmax(archive_f))\n                    if fx < archive_f[worst]:\n                        archive_X[worst] = x\n                        archive_f[worst] = fx\n            # keep them unsorted until prune or needed\n            if archive_f.size > 2 * self.max_archive:\n                prune_archive()\n\n        # best-known\n        best_idx = int(np.argmin(archive_f))\n        f_best = float(archive_f[best_idx])\n        x_best = archive_X[best_idx].copy()\n\n        # initial mean & covariance & sigma\n        # mean: weighted average of top-half of initial samples\n        m = x_best.copy()\n        # moderate isotropic covariance scaled by bounds\n        C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n        sigma = 0.18 * np.mean(bounds_scale)\n        sigma = max(sigma, 1e-8)\n\n        # strategy state\n        p_succ = self.success_target\n        stagn_iters = 0\n        iter_count = 0\n\n        # controller: probability of using model-guided proposals\n        p_model = 0.5\n        model_window = 10\n        success_history_model = []\n        success_history_div = []\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu = max(1, lam_iter // 2)\n            # rank-mu log weights\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # ensure archive sorted when needed\n            order_arch = np.argsort(archive_f)\n            X_sorted = archive_X[order_arch]\n            f_sorted = archive_f[order_arch]\n\n            # compute PCA on top elites to get dominant subspace\n            top_pca = min(len(f_sorted), max(4, 3 * self.dim // 2))\n            elites_for_pca = X_sorted[:top_pca] if top_pca > 0 else archive_X.copy()\n            if elites_for_pca.shape[0] >= 2:\n                # covariance of elites (centered at mean m)\n                Xm = elites_for_pca - m.reshape(1, -1)\n                S = np.cov(Xm, rowvar=False, bias=True)\n                # safe eigen-decomposition\n                vals, vecs = np.linalg.eigh(S + 1e-12 * np.eye(self.dim))\n                # order descending\n                idx_desc = np.argsort(vals)[::-1]\n                vals = vals[idx_desc]\n                vecs = vecs[:, idx_desc]\n            else:\n                vals = np.ones(self.dim)\n                vecs = np.eye(self.dim)\n\n            # choose subspace dimension (at least 1)\n            k_sub = max(1, min(self.dim, int(max(1, round(self.dim / 3.0)))))\n            V = vecs[:, :k_sub].copy()\n            eigvals = vals[:k_sub].copy()\n            eigvals = np.maximum(eigvals, 1e-12)\n\n            # surrogate fit in subspace (lightweight quadratic)\n            use_model = False\n            x_model_center = None\n            # build training set projected into subspace\n            n_have = X_sorted.shape[0]\n            # assemble points (use top K or all)\n            n_train = min(n_have, max(2 * (1 + k_sub + k_sub * (k_sub + 1) // 2), 5 * k_sub))\n            train_X = X_sorted[:n_train]\n            train_y = f_sorted[:n_train]\n            # project to subspace coords y = V^T (x - m)\n            Ys = (train_X - m.reshape(1, -1)) @ V  # shape (n_train, k_sub)\n\n            # build quadratic basis phi(y) = [1, y_i, y_j*y_k (j<=k)]\n            def build_phi_row(y):\n                elems = [1.0]\n                elems.extend(y.tolist())\n                # quadratic upper-triangular\n                for i in range(len(y)):\n                    for j in range(i, len(y)):\n                        elems.append(float(y[i] * y[j]))\n                return np.array(elems, dtype=float)\n\n            phi_sample = np.vstack([build_phi_row(Ys[i]) for i in range(Ys.shape[0])])\n            # check if interpolation is possible: need more equations than features or apply ridge\n            feats = phi_sample.shape[1]\n            if train_X.shape[0] >= max(3, feats // 2):\n                # weighted ridge regression (emphasize better points)\n                # weights by inverse rank-based exponential\n                ranks = np.argsort(np.argsort(train_y))\n                # better points get higher weight\n                sample_weights = np.exp(-0.5 * ranks / max(1, (n_train - 1)))\n                Wmat = np.sqrt(sample_weights).reshape(-1, 1)\n                A = (phi_sample * Wmat).T @ (phi_sample * Wmat)\n                b = (phi_sample * Wmat).T @ (train_y.reshape(-1, 1) * Wmat).reshape(-1)\n                # regularize\n                reg = 1e-6 * (np.trace(A) + 1.0)\n                A += reg * np.eye(A.shape[0])\n                try:\n                    coeff = np.linalg.solve(A, b)\n                    # extract linear and quadratic parts\n                    c0 = coeff[0]\n                    b_lin = coeff[1:1 + k_sub]\n                    q_coeffs = coeff[1 + k_sub:]\n                    # reconstruct symmetric S matrix in subspace such that\n                    # model(y) = c0 + b_lin^T y + sum_{i<=j} q_{ij} y_i y_j\n                    # define matrix S where S_ii = q_ii, S_ij = 0.5*q_ij for i!=j\n                    Ssub = np.zeros((k_sub, k_sub), dtype=float)\n                    idx = 0\n                    for i in range(k_sub):\n                        for j in range(i, k_sub):\n                            if i == j:\n                                Ssub[i, i] = q_coeffs[idx]\n                            else:\n                                Ssub[i, j] = 0.5 * q_coeffs[idx]\n                                Ssub[j, i] = Ssub[i, j]\n                            idx += 1\n                    # compute minimizer in subspace: solve 2*Ssub*y + b_lin = 0 -> y = -0.5 Ssub^{-1} b_lin\n                    # regularize Ssub\n                    Sreg = Ssub.copy()\n                    # ensure symmetric\n                    Sreg = 0.5 * (Sreg + Sreg.T)\n                    Sreg += 1e-8 * np.eye(k_sub)\n                    try:\n                        y_star = -0.5 * np.linalg.solve(Sreg, b_lin)\n                    except np.linalg.LinAlgError:\n                        # fallback to pseudo-inverse\n                        y_star = -0.5 * np.linalg.pinv(Sreg) @ b_lin\n                    x_pred = m + V @ y_star\n                    x_pred = clamp(x_pred)\n                    x_model_center = x_pred\n                    use_model = True\n                except np.linalg.LinAlgError:\n                    use_model = False\n            else:\n                use_model = False\n\n            # decide counts\n            # adaptively allocate fraction to model proposals\n            n_model = int(np.round(p_model * lam_iter))\n            # ensure at least one\n            n_model = max(0, min(lam_iter - 2, n_model))\n            n_gauss = max(1, lam_iter // 3)\n            n_de = lam_iter - n_model - n_gauss\n            if n_de < 0:\n                n_de = 0\n                if n_gauss + n_model > lam_iter:\n                    n_gauss = max(1, lam_iter - n_model)\n\n            Xcand = np.empty((lam_iter, self.dim), dtype=float)\n            cand_source = [''] * lam_iter\n            idx_c = 0\n\n            # 1) model-guided proposals (around x_model_center), if available, else fallback to subspace Gaussian\n            model_success = 0\n            if n_model > 0:\n                for i in range(n_model):\n                    if use_model and rng.rand() < 0.95:\n                        # propose around predicted minimizer with small noise proportional to sigma and subspace eigenvalues\n                        scale = sigma * (0.6 + 0.8 * rng.rand())\n                        perturb = (V @ (rng.normal(scale=np.sqrt(eigvals)) * rng.normal(scale=0.6, size=k_sub)))\n                        xprop = x_model_center + scale * perturb\n                    else:\n                        # fallback: sample in dominant subspace\n                        z = rng.normal(size=k_sub)\n                        # scale by eigenvalues sqrt\n                        z = z * np.sqrt(eigvals)\n                        xprop = m + V @ (z * (sigma / (np.mean(bounds_scale) + 1e-12)))\n                    xprop = clamp(xprop)\n                    Xcand[idx_c] = xprop\n                    cand_source[idx_c] = 'model'\n                    idx_c += 1\n\n            # 2) subspace-CMA Gaussian sampling along dominant eigenvectors (captures anisotropy)\n            if n_gauss > 0:\n                A = chol_safe(C)\n                for i in range(n_gauss):\n                    # sample in full space but scale along dominant directions\n                    z = rng.normal(size=self.dim)\n                    # give extra weight to dominant axes\n                    z[:k_sub] *= 1.0 + 0.5\n                    y = z @ (A.T)\n                    xg = m + sigma * y\n                    xg = clamp(xg)\n                    Xcand[idx_c] = xg\n                    cand_source[idx_c] = 'gauss'\n                    idx_c += 1\n\n            # 3) DE-style differential proposals from archive\n            if n_de > 0:\n                # ensure at least 3 archive members\n                n_avail = len(archive_f)\n                for i in range(n_de):\n                    if n_avail >= 3:\n                        idxs = rng.choice(n_avail, 3, replace=False)\n                        base = archive_X[idxs[0]]\n                        a = archive_X[idxs[1]]\n                        b = archive_X[idxs[2]]\n                        diff = self.F_de * (a - b)\n                        trial = base + diff\n                        # apply crossover with either base or mean bias\n                        if rng.rand() < 0.5:\n                            target = base\n                        else:\n                            target = m\n                        mask = rng.rand(self.dim) < self.CR\n                        if not mask.any():\n                            mask[rng.randint(self.dim)] = True\n                        trial = np.where(mask, trial, target)\n                        # small Gaussian nudge scaled by sigma\n                        trial += rng.normal(scale=0.35 * sigma, size=self.dim)\n                    else:\n                        # fallback gaussian\n                        z = rng.normal(size=self.dim)\n                        trial = m + sigma * (chol_safe(C).T @ z)\n                    trial = clamp(trial)\n                    Xcand[idx_c] = trial\n                    cand_source[idx_c] = 'de'\n                    idx_c += 1\n\n            # If we underfilled due to numeric rounding, fill with gaussians\n            while idx_c < lam_iter:\n                z = rng.normal(size=self.dim)\n                Xcand[idx_c] = clamp(m + sigma * (chol_safe(C).T @ z))\n                cand_source[idx_c] = 'gauss'\n                idx_c += 1\n\n            # Evaluate candidates but enforce budget exactness\n            f_cand = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                if evals >= self.budget:\n                    # mark remaining as very bad (won't be used)\n                    f_cand[i] = np.inf\n                    continue\n                xi = Xcand[i]\n                fi = float(func(xi))\n                f_cand[i] = fi\n                evals += 1\n                # immediate archive add\n                archive_add(xi.copy(), fi)\n\n            # generation best\n            gen_best_idx = int(np.argmin(f_cand))\n            gen_best_f = float(f_cand[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            # update global best\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n                stagn_iters = 0\n            else:\n                stagn_iters += 1\n\n            # compute per-source success (did any model candidate enter top mu or beat previous best?)\n            order_gen = np.argsort(f_cand)\n            top_mu_idx = set(order_gen[:mu].tolist())\n            # model success: fraction of model proposals that are in top mu or improved global\n            model_in_top = sum(1 for idx in range(lam_iter) if cand_source[idx] == 'model' and idx in top_mu_idx)\n            div_in_top = sum(1 for idx in range(lam_iter) if cand_source[idx] != 'model' and idx in top_mu_idx)\n            success_history_model.append(model_in_top / max(1, n_model))\n            success_history_div.append(div_in_top / max(1, lam_iter - n_model))\n            # keep history windowed\n            if len(success_history_model) > model_window:\n                success_history_model.pop(0)\n            if len(success_history_div) > model_window:\n                success_history_div.pop(0)\n\n            # adaptive allocation between model/diversity\n            avg_model_succ = np.mean(success_history_model) if len(success_history_model) > 0 else 0.0\n            avg_div_succ = np.mean(success_history_div) if len(success_history_div) > 0 else 0.0\n            # update p_model towards better performing arm\n            if (avg_model_succ + avg_div_succ) > 0:\n                target_p = 0.5 + 0.4 * (avg_model_succ - avg_div_succ)\n            else:\n                target_p = 0.5\n            p_model = 0.9 * p_model + 0.1 * np.clip(target_p, 0.05, 0.95)\n\n            # selection: pick top-mu candidates to update mean and covariance\n            X_mu = Xcand[order_gen[:mu]]\n\n            # recombination to update mean\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # compute deltas for covariance update\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas  # dim x dim\n\n            # floor for covariance to avoid collapse\n            floor = np.diag(((bounds_scale / 30.0) ** 2).clip(min=1e-12))\n\n            # update covariance with lr and small blending\n            C = (1.0 - self.cov_lr) * C + self.cov_lr * weighted_cov + 1e-12 * np.eye(self.dim)\n            C = 0.985 * C + 0.015 * floor\n\n            # update mean\n            m = m_new.copy()\n\n            # step-size adaptation: smoothed success-rate\n            p_succ = 0.88 * p_succ + 0.12 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n            # stagnation handling: Lévy escapes or re-seed\n            if stagn_iters >= self.stagnation_iters and evals < self.budget:\n                if rng.rand() < self.levy_prob:\n                    # heavy-tailed jump anchored on a good elite\n                    idx_choice = rng.randint(min(len(archive_f), max(3, self.dim)))\n                    anchor = X_sorted[idx_choice]\n                    cauchy_scale = max(0.3 * np.mean(bounds_scale), sigma * 6.0)\n                    jump = rng.standard_cauchy(size=self.dim) * cauchy_scale\n                    x_jump = clamp(anchor + jump)\n                    if evals < self.budget:\n                        fj = float(func(x_jump))\n                        evals += 1\n                        archive_add(x_jump.copy(), fj)\n                        if fj < f_best:\n                            f_best = fj\n                            x_best = x_jump.copy()\n                            stagn_iters = 0\n                            m = x_jump.copy()\n                            sigma = max(sigma, 0.6 * np.mean(bounds_scale))\n                            C = np.diag(((bounds_scale / 8.0) ** 2).clip(min=1e-12))\n                        else:\n                            # nudge mean towards best\n                            m = 0.6 * m + 0.4 * x_best\n                            sigma = min(2.0 * np.max(bounds_scale), sigma * 1.7)\n                else:\n                    # opportunistic re-seeding: sample a small batch uniformly and insert best into archive\n                    n_seed = min(3 + self.dim // 4, max(2, self.budget - evals))\n                    for _ in range(n_seed):\n                        if evals >= self.budget:\n                            break\n                        xr = rng.uniform(lb, ub, size=self.dim)\n                        fr = float(func(xr))\n                        evals += 1\n                        archive_add(xr.copy(), fr)\n                        if fr < f_best:\n                            f_best = fr\n                            x_best = xr.copy()\n                            m = xr.copy()\n                    # moderate reset of covariance and enlarge sigma\n                    C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                    sigma = max(sigma, 0.35 * np.mean(bounds_scale))\n                stagn_iters = 0\n\n            # small budget-aware pruning\n            prune_archive()\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSubspaceModelDE scored 0.648 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ad00285c-2740-4894-bdf7-843cbde9ae5f", "operator": null, "metadata": {"aucs": [0.2663005336819525, 0.21257795903855692, 0.7419716061427302, 0.9449102364510679, 0.8865381020472243, 0.8994087992514442, 0.5940833981152154, 0.8502965956503518, 0.8932698912604027, 0.19029184547350653]}, "task_prompt": ""}
{"id": "396683fe-ad29-4f0c-b4bb-bd141f4a9657", "fitness": 0.8368902145110958, "name": "MirrorAdaptiveDECovInject", "description": "Hybridizes mirrored Gaussian sampling and adaptive Differential Evolution (rand/1/bin) under a learned covariance: mirrored pairs around a weighted exponential-rank mean reduce variance while an eigendecomposed covariance (updated with a relatively slow cov_lr=0.10) shapes proposals. DE trials use adaptive per-trial F sampled from a heavy-tailed Cauchy (centered at F_base=0.6) and CR from a normal (CR_base=0.9), with archive-biased selection and a larger archive_size to preserve diversity. Step-size sigma adapts softly (sigma_adapt_rate=0.15) toward a slightly higher success target (0.25), and eigenvalue clamping / condition-number limits plus covariance injection keep the search numerically stable. On stagnation the algorithm rarely (levy_prob=0.10) performs heavy-tailed multivariate‑t probes or eigen-inflation and mild restarts to escape local traps, while all sampling and updates respect problem bounds.", "code": "import numpy as np\n\nclass MirrorAdaptiveDECovInject:\n    \"\"\"\n    MirrorAdaptiveDECovInject:\n    - Hybrid of mirrored Gaussian sampling and adaptive Differential Evolution (rand/1/bin).\n    - Maintains a covariance matrix to shape Gaussian proposals and updates it from selected elites.\n    - Uses exponential rank weights (different from log-weights in the reference).\n    - Adaptive F and CR per trial (sampled from heavy-tailed / normal priors).\n    - Eigenvalue clamping + covariance injection instead of plain floor blend; opportunistic eigen-inflation\n      / small multivariate-t probes on stagnation (different equations and parameter settings).\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None, pop_base=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        # Algorithmic knobs (deliberately different choices from the provided HybridCMADE)\n        self.pop_base = pop_base  # if None, computed below (uses sqrt scaling instead of log)\n        self.cov_lr = 0.10               # slower covariance learning than reference's 0.25\n        self.sigma_adapt_rate = 0.15     # milder step-size adaptation\n        self.success_target = 0.25       # slightly higher target success rate\n        self.archive_size = min(50, max(5, 6 * self.dim))  # larger archive scaling\n        self.stagnation_iters = max(15, int(0.03 * self.budget))  # different stagnation trigger\n        self.levy_prob = 0.10            # rarer heavy-tailed probes\n        self.F_base = 0.6                # base differential weight\n        self.CR_base = 0.9               # base crossover prob\n        self.max_eig_ratio = 1e6         # maximal condition number allowed\n        self.min_eig_scale = 1e-12       # absolute minimum eigenvalue floor\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds (Many BBOB uses [-5,5], but honor func bounds)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        bounds_scale = (ub - lb)\n\n        # adaptive population size (different from original log formula)\n        if self.pop_base is None:\n            lam = max(8, int(6 + 2.0 * np.sqrt(max(1, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        evals = 0\n        # initial uniform seeding (consume up to lam evaluations)\n        init_n = min(lam, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(init_n, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_n\n\n        # best-known\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # archive (store as arrays)\n        archive_X = X0.copy()\n        archive_f = f0.copy()\n\n        def archive_add(x, fx):\n            nonlocal archive_X, archive_f\n            if len(archive_f) < self.archive_size:\n                archive_X = np.vstack([archive_X, x.reshape(1, -1)])\n                archive_f = np.concatenate([archive_f, np.array([fx])])\n            else:\n                worst_idx = int(np.argmax(archive_f))\n                if fx < archive_f[worst_idx]:\n                    archive_X[worst_idx] = x\n                    archive_f[worst_idx] = fx\n\n        # initialize mean by exponential rank-weighted average of the top half\n        mu0 = max(1, init_n // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        # exponential weights (different equation)\n        ranks = np.arange(mu0)\n        weights0 = np.exp(-ranks / max(1.0, mu0 / 3.0))\n        weights0 = weights0 / weights0.sum()\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance: isotropic scaled relative to bounds but different divisor\n        C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-16))\n        sigma = 0.20 * np.mean(bounds_scale)\n        sigma = max(sigma, 1e-12)\n\n        # strategy state\n        p_succ = self.success_target\n        stagn_iters = 0\n        iter_count = 0\n\n        # helper: safe decomposition to get transform A with A^T A = C\n        def chol_like(Cmat):\n            # prefer eigh and form sqrt(V D V^T) to allow rectangular A\n            vals, vecs = np.linalg.eigh(Cmat)\n            vals_clipped = np.clip(vals, self.min_eig_scale, None)\n            # enforce condition limit\n            if vals_clipped.max() / vals_clipped.min() > self.max_eig_ratio:\n                # rescale largest eigenvalues to maintain condition number\n                max_allowed = vals_clipped.min() * self.max_eig_ratio\n                vals_clipped = np.minimum(vals_clipped, max_allowed)\n            A = (vecs * np.sqrt(vals_clipped)).T  # A @ A.T = Cmat, A^T @ A = ...\n            return A\n\n        # main loop: generate up to lam candidates per generation\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu = max(1, lam_iter // 2)\n\n            # recompute exponential rank weights (different equation)\n            ranks = np.arange(mu)\n            weights = np.exp(-ranks / max(1.0, mu / 3.0))\n            weights = weights / np.sum(weights)\n\n            A = chol_like(C)\n\n            # candidate composition: half mirrored Gaussian, half adaptive DE\n            n_gauss = lam_iter // 2\n            n_de = lam_iter - n_gauss\n            Xcand = np.empty((lam_iter, self.dim), dtype=float)\n\n            # 1) mirrored Gaussian proposals: produce pairs (x, 2m - x) for variance reduction\n            if n_gauss > 0:\n                # generate n_gauss/2 unique normals and mirror them; if odd handle last separately\n                Z = rng.normal(size=(n_gauss, self.dim))\n                Y = Z @ (A.T)\n                Xg = m + sigma * Y\n                # mirrored\n                Xg_mirror = 2.0 * m - Xg\n                # mix sequence Xg and mirrors to fill n_gauss slots\n                for i in range(n_gauss):\n                    if i < len(Xg):\n                        cand = Xg[i]\n                    else:\n                        cand = Xg_mirror[i - len(Xg)]\n                    # clamp\n                    Xcand[i] = np.minimum(np.maximum(cand, lb), ub)\n\n            # 2) adaptive DE rand/1/bin proposals using archive\n            if n_de > 0:\n                # ensure sorted archive for selection bias towards elites\n                if len(archive_f) >= 3:\n                    idx_sort = np.argsort(archive_f)\n                    sorted_X = archive_X[idx_sort]\n                    sorted_f = archive_f[idx_sort]\n                else:\n                    sorted_X = archive_X\n                    sorted_f = archive_f\n\n                for i in range(n_de):\n                    # sample F from Cauchy centered at base, heavy-tailed but clipped\n                    F = rng.standard_cauchy() * 0.1 + self.F_base\n                    F = float(np.clip(F, 0.2, 1.0))\n                    # sample CR from normal near base\n                    CR = float(np.clip(rng.normal(loc=self.CR_base, scale=0.15), 0.0, 1.0))\n\n                    if len(sorted_X) < 3:\n                        # fallback gaussian\n                        z = rng.normal(size=self.dim)\n                        y = z @ (A.T)\n                        trial = m + sigma * y\n                    else:\n                        # pick three distinct indices for rand/1\n                        idxs = rng.choice(len(sorted_X), size=3, replace=False)\n                        xr = sorted_X[idxs[0]]\n                        xa = sorted_X[idxs[1]]\n                        xb = sorted_X[idxs[2]]\n                        mutant = xr + F * (xa - xb)\n                        # target vector chosen randomly between m and a random elite (introduce diversity)\n                        if rng.rand() < 0.5:\n                            target = m\n                        else:\n                            target = sorted_X[rng.randint(len(sorted_X))]\n                        # binomial crossover\n                        mask = rng.rand(self.dim) < CR\n                        if not np.any(mask):\n                            mask[rng.randint(self.dim)] = True\n                        trial = np.where(mask, mutant, target)\n                        # small Gaussian jitter scaled by sigma and relative to bounds\n                        trial += rng.normal(scale=0.3 * sigma, size=self.dim)\n\n                    # clamp\n                    Xcand[n_gauss + i] = np.minimum(np.maximum(trial, lb), ub)\n\n            # evaluate candidates (respect budget)\n            f_cand = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                if evals >= self.budget:\n                    # Should not happen as lam_iter chosen <= remaining, but guard anyway\n                    f_cand[i] = np.inf\n                    continue\n                f_cand[i] = float(func(Xcand[i]))\n            evals += lam_iter\n\n            # update archive\n            for i in range(lam_iter):\n                archive_add(Xcand[i].copy(), float(f_cand[i]))\n\n            # generation best\n            gen_best_idx = int(np.argmin(f_cand))\n            gen_best_f = float(f_cand[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n                stagn_iters = 0\n            else:\n                stagn_iters += 1\n\n            # selection: choose top-mu candidates\n            order = np.argsort(f_cand)\n            X_mu = Xcand[order[:mu]]\n\n            # recompute weighted mean (exponential rank weights)\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # deltas normalized by sigma for covariance update\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas  # (dim x dim)\n\n            # include small rank-one update from mean shift\n            mean_shift = ((m_new - m) / max(sigma, 1e-20)).reshape(-1, 1)\n            rank_one = (mean_shift @ mean_shift.T) * 0.5\n\n            # covariance update with injection term (different blend than reference)\n            C = (1.0 - self.cov_lr) * C + self.cov_lr * (weighted_cov + 0.5 * rank_one)\n\n            # eigen-regularize: clamp eigenvalues to reasonable range relative to bounds_scale\n            vals, vecs = np.linalg.eigh(C)\n            # set minimum eigenvalue relative to typical squared scale of bounds\n            min_eig = max(self.min_eig_scale, (np.mean(bounds_scale) * 1e-3) ** 2)\n            vals_clipped = np.clip(vals, min_eig, None)\n            # enforce max condition number\n            max_allowed = vals_clipped.min() * self.max_eig_ratio\n            vals_clipped = np.minimum(vals_clipped, max_allowed)\n            C = (vecs * vals_clipped) @ vecs.T\n\n            # update mean\n            m = m_new.copy()\n\n            # step-size adaptation via smoothed success-rate but with different smoothing\n            p_succ = 0.85 * p_succ + 0.15 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            # clip sigma to sensible bounds (bounded by domain size)\n            sigma = float(np.clip(sigma, 1e-12, 1.5 * np.max(bounds_scale)))\n\n            # stagnation handling: covariance injection or small multivariate-t probes\n            if stagn_iters >= self.stagnation_iters and evals < self.budget:\n                if rng.rand() < self.levy_prob:\n                    # heavy-tailed multivariate-t probe centered at one of the top elites\n                    idx_sort = np.argsort(archive_f)\n                    topK = min(len(idx_sort), max(3, self.dim))\n                    anchor = archive_X[idx_sort[rng.randint(topK)]]\n                    # multivariate t-like by sampling normal and dividing by sqrt(gamma)\n                    # gamma drawn from chi2 with df small to create heavy tails\n                    df = 2.0\n                    gamma = max(1e-8, rng.chisquare(df))\n                    z = rng.normal(size=self.dim)\n                    scale = max(0.4 * np.mean(bounds_scale), sigma * 3.0)\n                    jump = z / np.sqrt(gamma / df) * scale\n                    x_jump = anchor + jump\n                    x_jump = np.minimum(np.maximum(x_jump, lb), ub)\n                    fj = float(func(x_jump))\n                    evals += 1\n                    archive_add(x_jump.copy(), fj)\n                    if fj < f_best:\n                        f_best = fj\n                        x_best = x_jump.copy()\n                        stagn_iters = 0\n                        m = x_jump.copy()\n                        sigma = max(sigma, 0.4 * np.mean(bounds_scale))\n                        C = np.diag(((bounds_scale / 5.0) ** 2).clip(min=1e-16))\n                    else:\n                        # perform eigen-inflation: increase small eigenvalues moderately to encourage new directions\n                        vals, vecs = np.linalg.eigh(C)\n                        vals = np.maximum(vals, min_eig)\n                        inflation = 1.5\n                        vals = vals * inflation\n                        C = (vecs * vals) @ vecs.T\n                        # nudge mean slightly toward the best\n                        m = 0.85 * m + 0.15 * x_best\n                        sigma = min(1.5 * np.max(bounds_scale), sigma * 1.4)\n                else:\n                    # milder restart around the best with small Gaussian jitter (not full reinitialization)\n                    jitter = rng.normal(scale=0.08 * np.maximum(bounds_scale, 1.0), size=self.dim)\n                    m = x_best + jitter\n                    m = np.minimum(np.maximum(m, lb), ub)\n                    C = np.diag(((bounds_scale / 7.0) ** 2).clip(min=1e-16))\n                    sigma = max(sigma, 0.25 * np.mean(bounds_scale))\n                stagn_iters = 0\n                p_succ = self.success_target  # reset smoothed success estimate\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MirrorAdaptiveDECovInject scored 0.837 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ad00285c-2740-4894-bdf7-843cbde9ae5f", "operator": null, "metadata": {"aucs": [0.47300416260066824, 0.6238677356342714, 0.9029142496152635, 0.9650200021339553, 0.9257517102557562, 0.9357207553435835, 0.7955137354389289, 0.901434392868441, 0.9202952522322716, 0.9253801489878187]}, "task_prompt": ""}
{"id": "68f4d867-4eba-4317-a2c0-8dd7d1cf302b", "fitness": 0.501118089561456, "name": "AdaptiveSubspaceEnsemble", "description": "The design centers on an adaptive-trust-region search: maintain a center m and a radius rho (initialized as 0.25*avg_range, clipped) plus an elite archive (capacity max(40,6*dim)) seeded by an initial uniform batch (init_batch = ~2*lam) to provide history for PCA and elite differences. Candidate generation is an ensemble mixing low-rank PCA Gaussian moves (subspace rank pca_rank = min(6,dim//4)), directional probes drawn from a small directional memory (mem_size ∈ [4,12]) and elite differences with mirroring (mirror_prob=0.4), opposition moves (opposition_prob=0.15), occasional Cauchy heavy-tailed escapes (cauchy_prob=0.08), and isotropic jitter — with ~60% of population devoted to subspace sampling. Updates use a softmax-like weighted recombination of the top mu candidates to form m_new, normalized successful step directions are inserted into Dmem (orthonormalized to avoid degeneracy), and rho is multiplicatively adapted via a smoothed success rate (rho_adapt=0.3, success_target=0.25) with occasional opportunistic recenters toward the archive best. Practical safeguards include variance flooring for subspace variances, clamping to bounds, jitter to avoid stagnation, random PCA fallback, and population scaling lam = max(8, 4+3*log(dim)) to balance exploration and budget.", "code": "import numpy as np\n\nclass AdaptiveSubspaceEnsemble:\n    \"\"\"\n    AdaptiveSubspaceEnsemble (ASE)\n\n    Main ideas:\n      - Maintain a center m and a trust radius rho (a step-size-like trust region).\n      - Keep an elite archive and a small directional memory of previously successful step directions.\n      - Each iteration sample a modest ensemble of candidates by mixing:\n          * low-rank subspace Gaussian sampling (PCA of elites),\n          * directional line-like probes using directional memory and elite differences (with mirrored partners),\n          * opposition-based candidate(s) (reflect center against bounds midpoint),\n          * occasional Cauchy heavy-tailed escape.\n      - Update center by weighted recombination of the best candidates (softmax/rank-inspired),\n        update directional memory with normalized successful steps, and adapt rho with a simple success-rate controller.\n      - Uses low-rank covariance in the subspace for efficient exploration in higher dims and robust fallbacks.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None, pop_base=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.pop_base = pop_base  # optional override for population size\n        # Tunables\n        self.mem_size = max(4, min(12, 2 * (self.dim // 2)))  # memory of successful directions\n        self.pca_rank = max(1, min(6, self.dim // 4))         # subspace rank to use\n        self.rho_init = 1.0                                   # initial trust radius (interpreted relative to bounds)\n        self.success_target = 0.25\n        self.rho_adapt = 0.3     # rate controlling multiplicative adaptation of rho\n        self.cauchy_prob = 0.08  # occasional heavy-tailed jump probability\n        self.opposition_prob = 0.15\n        self.mirror_prob = 0.4\n        self.min_rho = 1e-6\n        self.max_rho_scale = 3.0  # multiplies mean(bounds_range)\n        self.seeded = seed is not None\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n        # bounds (assume func.bounds available)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        bounds_scale = (ub - lb)\n        avg_range = float(np.mean(bounds_scale))\n\n        # adaptive population\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n        # keep iteration-pop not exceeding budget later\n\n        # initial seeding: evaluate a modest initial batch uniformly across bounds\n        evals = 0\n        init_batch = min(lam * 2, self.budget)  # a slightly larger initial archive\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # archive: keep X and f; we'll maintain unsorted arrays but sort when needed\n        archive_X = X0.copy()\n        archive_f = f0.copy()\n        archive_cap = max(40, 6 * self.dim)  # keep a reasonably sized archive for PCA\n\n        def archive_add(x, fx):\n            nonlocal archive_X, archive_f\n            if archive_f.size < archive_cap:\n                archive_X = np.vstack([archive_X, x.reshape(1, -1)])\n                archive_f = np.concatenate([archive_f, np.array([fx])])\n            else:\n                # replace worst if better\n                worst_idx = int(np.argmax(archive_f))\n                if fx < archive_f[worst_idx]:\n                    archive_X[worst_idx] = x\n                    archive_f[worst_idx] = fx\n\n        # directional memory: normalized directions from successful moves\n        Dmem = np.zeros((self.dim, 0), dtype=float)  # columns are directions\n        max_mem = self.mem_size\n\n        # initialize center as weighted mean of top half of initial points (soft log-weights)\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(archive_f)\n        elites0 = archive_X[order0[:mu0]]\n        weights0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        weights0 = np.maximum(weights0, 0.0)\n        if weights0.sum() <= 0:\n            weights0 = np.ones_like(weights0)\n        weights0 = weights0 / weights0.sum()\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial trust radius rho scaled to bounds\n        rho = self.rho_init * (0.25 * avg_range)\n        rho = float(np.clip(rho, self.min_rho, self.max_rho_scale * avg_range))\n\n        # success tracking for rho adaptation\n        p_succ = self.success_target\n\n        # helper: build low-rank subspace basis via PCA of top elites\n        def compute_subspace(k):\n            if archive_f.size < max(3, k + 1):\n                # no reliable PCA -> random orthonormal subspace\n                Q = np.linalg.qr(rng.normal(size=(self.dim, k)))[0][:, :k]\n                return Q\n            idx = np.argsort(archive_f)[:min(archive_f.size, 4 * k)]\n            X = archive_X[idx]\n            Xc = X - X.mean(axis=0)\n            # small regularization\n            cov = (Xc.T @ Xc) / max(1, Xc.shape[0] - 1)\n            try:\n                vals, vecs = np.linalg.eigh(cov)\n                order = np.argsort(vals)[::-1]\n                vecs = vecs[:, order]\n                # If k > number of positive eigenvalues, pad with random orthonormal vectors\n                if vecs.shape[1] < k:\n                    extra = np.linalg.qr(rng.normal(size=(self.dim, k - vecs.shape[1])))[0]\n                    basis = np.hstack([vecs, extra])\n                else:\n                    basis = vecs[:, :k]\n                return basis\n            except np.linalg.LinAlgError:\n                # fallback\n                Q = np.linalg.qr(rng.normal(size=(self.dim, k)))[0][:, :k]\n                return Q\n\n        # main loop\n        iter_count = 0\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            # dynamic division of candidates: subspace dominated with some directional and a few exploratives\n            n_sub = max(1, int(0.6 * lam_iter))\n            n_dir = max(0, lam_iter - n_sub - 1)  # leave one slot for opposition/heavy\n            n_misc = lam_iter - n_sub - n_dir\n\n            # build subspace\n            k = min(self.pca_rank, self.dim)\n            B = compute_subspace(k)  # dim x k\n\n            # approximate diagonal variances in subspace from projected elite spread\n            if archive_X.shape[0] > k:\n                proj = (archive_X - archive_X.mean(axis=0)) @ B  # N x k\n                var_proj = np.var(proj, axis=0, ddof=0)\n                # floor variances\n                var_proj = np.maximum(var_proj, (0.01 * rho) ** 2)\n            else:\n                var_proj = (rho ** 2) * np.ones(k)\n\n            # candidate pool\n            Xcand = np.empty((lam_iter, self.dim), dtype=float)\n            ci = 0\n\n            # 1) Subspace Gaussian proposals (low-rank)\n            if n_sub > 0:\n                # sample coefficients in subspace with independent variances var_proj\n                Z = rng.normal(size=(n_sub, k)) * np.sqrt(var_proj.reshape(1, -1))\n                Xs = m.reshape(1, -1) + Z.dot(B.T)  # (n_sub, dim)\n                # small isotropic jitter\n                jitter = rng.normal(scale=0.03 * rho, size=(n_sub, self.dim))\n                Xs += jitter\n                # clamp\n                Xs = np.minimum(np.maximum(Xs, lb), ub)\n                Xcand[ci:ci + n_sub] = Xs\n                ci += n_sub\n\n            # 2) Directional probes using Dmem or elite differences\n            if n_dir > 0:\n                # prepare a pool of directions: prefer memory, else form differences from archive elites\n                dir_pool = []\n                if Dmem.shape[1] > 0:\n                    for j in range(Dmem.shape[1]):\n                        dir_pool.append(Dmem[:, j].copy())\n                # augment from elite differences\n                if archive_X.shape[0] >= 2:\n                    idxs = np.argsort(archive_f)[:min(6, archive_f.size)]\n                    topX = archive_X[idxs]\n                    for a in range(len(topX)):\n                        for b in range(a + 1, len(topX)):\n                            d = topX[a] - topX[b]\n                            nd = d / (np.linalg.norm(d) + 1e-12)\n                            dir_pool.append(nd)\n                if len(dir_pool) == 0:\n                    # fallback to random directions\n                    dir_pool = [rng.normal(size=self.dim) for _ in range(max(4, n_dir))]\n                # sample directional probes\n                for j in range(n_dir):\n                    d = dir_pool[rng.randint(len(dir_pool))].copy()\n                    d = d / (np.linalg.norm(d) + 1e-12)\n                    # sample step length log-uniform in [rho*0.05, rho*2]\n                    a_low = np.log(max(1e-8, 0.05 * rho))\n                    a_high = np.log(max(a_low + 1e-12, 2.0 * rho))\n                    alpha = float(np.exp(rng.uniform(a_low, a_high)))\n                    trial = m + alpha * d\n                    # with some probability mirror (opposite along d)\n                    if rng.rand() < self.mirror_prob:\n                        trial_mirror = m - alpha * d\n                        # include mirror if space allows\n                        if ci < lam_iter:\n                            Xcand[ci] = np.minimum(np.maximum(trial_mirror, lb), ub)\n                            ci += 1\n                            if ci >= lam_iter:\n                                break\n                    if ci < lam_iter:\n                        Xcand[ci] = np.minimum(np.maximum(trial, lb), ub)\n                        ci += 1\n                    if ci >= lam_iter:\n                        break\n\n            # 3) Misc: opposition, random global, occasional heavy-tailed\n            # opposition candidate: reflect center across bounds midpoint\n            if ci < lam_iter and rng.rand() < self.opposition_prob:\n                mid = (lb + ub) / 2.0\n                opp = np.minimum(np.maximum(2.0 * mid - m, lb), ub)\n                Xcand[ci] = opp\n                ci += 1\n\n            # remaining slots: isotropic random around center (small)\n            while ci < lam_iter:\n                # occasional heavy-tailed global escape\n                if rng.rand() < self.cauchy_prob:\n                    scale = max(0.5 * avg_range, rho * 4.0)\n                    jump = rng.standard_cauchy(size=self.dim) * scale\n                    trial = m + jump\n                else:\n                    trial = m + rng.normal(scale=0.6 * rho, size=self.dim)\n                trial = np.minimum(np.maximum(trial, lb), ub)\n                Xcand[ci] = trial\n                ci += 1\n\n            # Evaluate candidates (respect budget)\n            f_cand = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                if evals >= self.budget:\n                    # safety check — shouldn't normally happen because lam_iter <= remaining\n                    f_cand = f_cand[:i].copy()\n                    Xcand = Xcand[:i].copy()\n                    lam_iter = i\n                    break\n                f_cand[i] = float(func(Xcand[i]))\n                evals += 1\n\n            # Update archive with all candidates\n            for i in range(lam_iter):\n                archive_add(Xcand[i].copy(), float(f_cand[i]))\n\n            # track generation best\n            if lam_iter == 0:\n                break\n            gen_best_idx = int(np.argmin(f_cand))\n            gen_best_f = float(f_cand[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n\n            # selection: top mu (we'll use mu = max(1, lam_iter//4))\n            mu = max(1, lam_iter // 4)\n            order = np.argsort(f_cand)\n            X_mu = Xcand[order[:mu]]\n            f_mu = f_cand[order[:mu]]\n\n            # recombination: softmax weights over negative objective (prefer smaller f)\n            # rescale f_mu to stabilize exponentials\n            fmin = np.min(f_mu)\n            fshift = f_mu - fmin\n            temp = max(1e-8, np.std(fshift)) if f_mu.size > 1 else 1.0\n            logits = -fshift / (temp + 1e-12)\n            expw = np.exp(logits - np.max(logits))\n            weights = expw / (expw.sum() + 1e-20)\n\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # compute successful steps relative to old center and update Dmem\n            steps = (X_mu - m).copy()\n            # consider only steps that improved relative to center\n            keep_steps = []\n            for j in range(X_mu.shape[0]):\n                if f_mu[j] < np.mean(archive_f) or np.linalg.norm(steps[j]) > 1e-12:\n                    # heuristics: keep steps that are meaningful\n                    s = steps[j]\n                    nrm = np.linalg.norm(s)\n                    if nrm > 1e-12:\n                        keep_steps.append(s / nrm)\n            # update Dmem by inserting new normalized successful directions\n            if keep_steps:\n                for s in keep_steps:\n                    if Dmem.shape[1] < max_mem:\n                        Dmem = np.hstack([Dmem, s.reshape(-1, 1)])\n                    else:\n                        # replace a random older memory with small probability, or replace worst by diversity measure\n                        ridx = rng.randint(Dmem.shape[1])\n                        Dmem[:, ridx] = s\n\n                # orthonormalize memory columns to avoid degeneracy\n                if Dmem.shape[1] > 1:\n                    Q, _ = np.linalg.qr(Dmem)\n                    Dmem = Q[:, :Dmem.shape[1]]\n\n            # update center with momentum-like blending to avoid abrupt jumps\n            m = 0.85 * m + 0.15 * m_new\n\n            # adapt rho using short-term success estimate (smoothed)\n            p_succ = 0.9 * p_succ + 0.1 * float(improved)\n            # multiplicative adaptation: if p_succ>target increase rho, else decrease\n            adapt_factor = np.exp(self.rho_adapt * (p_succ - self.success_target))\n            rho = float(np.clip(rho * adapt_factor, self.min_rho, self.max_rho_scale * avg_range))\n\n            # occasional opportunistic recenter if stagnation: if no improvement for many iterations, nudge toward best\n            if iter_count % 25 == 0 and not improved:\n                # nudge center towards best in archive top element\n                idx_sort = np.argsort(archive_f)\n                anchor = archive_X[idx_sort[0]]\n                m = 0.5 * m + 0.5 * anchor\n                # slightly inflate rho\n                rho = float(min(self.max_rho_scale * avg_range, rho * 1.2))\n\n            # ensure center stays within bounds\n            m = np.minimum(np.maximum(m, lb), ub)\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSubspaceEnsemble scored 0.501 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ad00285c-2740-4894-bdf7-843cbde9ae5f", "operator": null, "metadata": {"aucs": [0.14145927285863902, 0.1795840650737185, 0.8958263377482601, 0.19066870542180292, 0.9405867231905128, 0.9555070596832048, 0.23323112339574248, 0.9246169105910971, 0.3191422389549171, 0.23055845869666514]}, "task_prompt": ""}
{"id": "dbae8772-209e-4368-a357-29d9b3adfbbb", "fitness": 0.6713156945474534, "name": "DADCS", "description": "The algorithm mixes three complementary search engines — diagonal Gaussian sampling, archive-driven differential-evolution proposals, and axis/directional moves — with a conservative population sizing (lam ≈ 3√dim) and a relatively large archive (min(80, 8·dim)) to retain diverse history for DE and restarts. It maintains a per-dimension diagonal covariance C_diag (fast floor enforcement and gentle cov_lr=0.10) and a global step-size sigma that is multiplicatively adapted from a smoothed success-rate (sigma_adapt_rate=0.70, success_target=0.25), enabling separate learning of directionality and scale. Candidates are recombined with polynomial-weighted averages over the top ~30% (mu) to update the mean and diagonal variances, while a small directional memory stores successful normalized moves to bias future axis-like proposals. Stagnation triggers occasional heavy-tailed Cauchy jumps anchored to archive members (levy_prob=0.15) or mild restarts around the best, providing escape from local optima and preserving long-range exploration.", "code": "import numpy as np\n\nclass DADCS:\n    \"\"\"\n    Diagonal Adaptive Differential-Covariance Search (DADCS).\n\n    Main idea (one-line): Combine archive-driven differential proposals and diagonal\n    adaptive covariance sampling with per-dimension variance learning, softer step-size\n    control, and occasional heavy-tailed escapes.\n\n    Key algorithmic parameters (tunable, intentionally different from HybridCMADE):\n      - lam: population size ~ max(10, ceil(3 * sqrt(dim))) (smaller growth with dim)\n      - archive_size: min(80, max(8, 8*dim)) (larger archive)\n      - cov_lr: 0.10 (slower / gentler diagonal variance learning vs 0.25)\n      - sigma_adapt_rate: 0.70 (faster multiplicative response to success-rate deviations)\n      - success_target: 0.25 (different success target)\n      - F_de: 0.6, CR: 0.7 (DE constants changed)\n      - levy_prob: 0.15 (less frequent heavy-tailed escapes)\n      - stagnation_iters: max(15, int(0.03*budget)) (different stagnation trigger)\n      - Uses diagonal covariance C_diag (per-dim variances) rather than full matrix\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n\n        # Tunable knobs (different defaults than the provided HybridCMADE)\n        self.lam_base = None  # if None compute via sqrt rule\n        self.cov_lr = 0.10\n        self.sigma_adapt_rate = 0.70\n        self.success_target = 0.25\n        self.archive_size = min(80, max(8, 8 * self.dim))\n        self.stagnation_iters = max(15, int(0.03 * self.budget))\n        self.levy_prob = 0.15\n        self.F_de = 0.6\n        self.CR = 0.7\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds handling\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        # population size: different functional form (sqrt scaling)\n        if self.lam_base is None:\n            lam = max(10, int(np.ceil(3.0 * np.sqrt(max(1, self.dim)))))\n        else:\n            lam = int(self.lam_base)\n        lam = min(lam, max(2, self.budget))\n\n        # initial seeding\n        evals = 0\n        init_batch = min(lam, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        # best-known\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # archive arrays (simple unsorted store with replacement of worst)\n        archive_X = X0.copy()\n        archive_f = f0.copy()\n\n        def archive_add(x, fx):\n            nonlocal archive_X, archive_f\n            if len(archive_f) < self.archive_size:\n                archive_X = np.vstack([archive_X, x.reshape(1, -1)])\n                archive_f = np.concatenate([archive_f, np.array([fx])])\n            else:\n                worst_idx = int(np.argmax(archive_f))\n                if fx < archive_f[worst_idx]:\n                    archive_X[worst_idx] = x\n                    archive_f[worst_idx] = fx\n\n        # initialize mean as average of top-half (robust)\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        m = elites0.mean(axis=0)\n\n        # diagonal covariance and step-size initialization (different scales)\n        C_diag = ((bounds_scale / 6.0) ** 2).clip(min=1e-12)  # per-dim variance\n        sigma = 0.20 * np.mean(bounds_scale)\n        sigma = max(sigma, 1e-12)\n\n        # state variables\n        p_succ = self.success_target\n        stagn_iters = 0\n        iter_count = 0\n\n        # direction memory (successful normalized directions)\n        direction_memory = []\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n\n            # selection size mu (different fraction)\n            mu = max(2, int(np.ceil(0.30 * lam_iter)))\n            # weight shape: heavier weight on best, smooth polynomial decay\n            idxs = np.arange(mu, 0, -1, dtype=float)\n            weights = idxs ** 1.2\n            weights = weights / np.sum(weights)\n\n            # candidate composition: fractions different from HybridCMADE\n            n_gauss = int(np.floor(0.40 * lam_iter))\n            n_de = int(np.floor(0.50 * lam_iter))\n            n_axis = lam_iter - (n_gauss + n_de)  # small remainder for directional moves\n\n            Xcand = np.empty((lam_iter, self.dim), dtype=float)\n\n            # 1) Gaussian samples with diagonal covariance\n            if n_gauss > 0:\n                Z = rng.normal(size=(n_gauss, self.dim))\n                # per-dim std\n                stds = np.sqrt(C_diag)\n                Y = Z * (stds.reshape(1, -1))  # shape (n_gauss, dim)\n                Xg = m.reshape(1, -1) + sigma * Y\n                Xg = np.minimum(np.maximum(Xg, lb), ub)\n                Xcand[:n_gauss] = Xg\n\n            # 2) DE-style proposals driven by archive (rand/1/bin around archive / mean)\n            if n_de > 0:\n                if len(archive_f) < 3:\n                    # fallback to Gaussian if archive too small\n                    Zd = rng.normal(size=(n_de, self.dim))\n                    stds = np.sqrt(C_diag)\n                    Yd = Zd * stds.reshape(1, -1)\n                    Xd = m.reshape(1, -1) + sigma * Yd\n                    Xd = np.minimum(np.maximum(Xd, lb), ub)\n                    Xcand[n_gauss:n_gauss + n_de] = Xd\n                else:\n                    # sort archive (occasional full sort is ok here)\n                    idx_sort = np.argsort(archive_f)\n                    sorted_X = archive_X[idx_sort]\n                    # build DE candidates\n                    for i in range(n_de):\n                        # choose base either best elite or current mean (mix)\n                        if rng.rand() < 0.55:\n                            base = sorted_X[0]\n                        else:\n                            base = m\n                        # pick three distinct indices for differential vector\n                        ids = rng.choice(len(sorted_X), size=3, replace=False)\n                        r1, r2, r3 = sorted_X[ids[0]], sorted_X[ids[1]], sorted_X[ids[2]]\n                        trial = r1 + self.F_de * (r2 - r3)\n                        # binomial crossover with base as target\n                        mask = rng.rand(self.dim) < self.CR\n                        if not np.any(mask):\n                            mask[rng.randint(self.dim)] = True\n                        trial = np.where(mask, trial, base)\n                        # add small gaussian jitter scaled by per-dim stds\n                        jitter = rng.normal(scale=0.3 * sigma * np.sqrt(C_diag))\n                        trial = trial + jitter\n                        trial = np.minimum(np.maximum(trial, lb), ub)\n                        Xcand[n_gauss + i] = trial\n\n            # 3) Axis/directional proposals from archive differences / direction memory\n            if n_axis > 0:\n                for i in range(n_axis):\n                    if len(direction_memory) > 0 and rng.rand() < 0.6:\n                        # pick stored direction\n                        dir_vec = direction_memory[rng.randint(len(direction_memory))]\n                        step = dir_vec * (sigma * (0.8 + rng.rand() * 2.0))  # variable scaling\n                        trial = m + step\n                    elif len(archive_f) >= 2:\n                        # create long-range diff from two elites\n                        ids = rng.choice(len(archive_X), size=2, replace=False)\n                        diff = archive_X[ids[0]] - archive_X[ids[1]]\n                        norm = np.linalg.norm(diff) + 1e-12\n                        dir_vec = diff / norm\n                        step = dir_vec * (rng.normal() * max(0.5 * np.mean(bounds_scale), sigma * 2.0))\n                        trial = (m + step)\n                    else:\n                        # random gaussian fallback\n                        trial = m + rng.normal(scale=sigma * np.sqrt(C_diag))\n                    trial = np.minimum(np.maximum(trial, lb), ub)\n                    Xcand[n_gauss + n_de + i] = trial\n\n            # evaluate candidates (sequentially)\n            f_cand = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                # ensure we never exceed budget (lam_iter was set to remaining so safe)\n                f_cand[i] = func(Xcand[i])\n            evals += lam_iter\n\n            # add to archive\n            for i in range(lam_iter):\n                archive_add(Xcand[i].copy(), float(f_cand[i]))\n\n            # generation best\n            gen_best_idx = int(np.argmin(f_cand))\n            gen_best_f = float(f_cand[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n                stagn_iters = 0\n            else:\n                stagn_iters += 1\n\n            # selection: pick top-mu\n            order = np.argsort(f_cand)\n            X_mu = Xcand[order[:mu]]\n\n            # recombine to new mean with polynomial weights\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # compute deltas and update diagonal covariance (variances)\n            deltas = X_mu - m  # shape (mu, dim)\n            weighted_var = (weights.reshape(-1, 1) * (deltas ** 2)).sum(axis=0)\n            # update C_diag as running average of squared displacements\n            C_diag = (1.0 - self.cov_lr) * C_diag + self.cov_lr * weighted_var\n            # enforce floor to maintain exploration (bounds scaled)\n            floor = ((bounds_scale / 30.0) ** 2).clip(min=1e-12)\n            C_diag = 0.985 * C_diag + 0.015 * floor\n\n            # update mean\n            m = m_new.copy()\n\n            # update direction memory with normalized successful moves (store few)\n            if improved:\n                # store direction from previous mean to new best (if not trivial)\n                move = (x_best - m)\n                nm = np.linalg.norm(move)\n                if nm > 1e-12:\n                    dirn = move / nm\n                    direction_memory.append(dirn)\n                    if len(direction_memory) > 2 * self.dim:\n                        # keep memory bounded\n                        direction_memory = direction_memory[-(2 * self.dim):]\n\n            # step-size adaptation via smoothed success rate (different smoothing)\n            p_succ = 0.8 * p_succ + 0.2 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, 1e-12, 3.0 * np.max(bounds_scale))\n\n            # occasional heavy-tailed jump or mild restart on stagnation\n            if stagn_iters >= self.stagnation_iters and evals < self.budget:\n                if rng.rand() < self.levy_prob:\n                    # heavy-tailed jump anchored to a good archive member\n                    idx_sort = np.argsort(archive_f)\n                    anchor = archive_X[idx_sort[rng.randint(min(len(idx_sort), max(3, self.dim)))]]\n                    cauchy_scale = max(np.mean(bounds_scale) * 0.4, sigma * 4.0)\n                    jump = rng.standard_cauchy(size=self.dim) * cauchy_scale\n                    x_jump = anchor + jump\n                    x_jump = np.minimum(np.maximum(x_jump, lb), ub)\n                    fj = func(x_jump)\n                    evals += 1\n                    archive_add(x_jump.copy(), float(fj))\n                    if fj < f_best:\n                        f_best = float(fj)\n                        x_best = x_jump.copy()\n                        stagn_iters = 0\n                        # center around the jumped solution but keep some history\n                        m = 0.6 * m + 0.4 * x_jump\n                        sigma = max(sigma, 0.6 * np.mean(bounds_scale))\n                        C_diag = ((bounds_scale / 8.0) ** 2).clip(min=1e-12)\n                    else:\n                        # nudge mean towards best and slightly grow sigma\n                        m = 0.8 * m + 0.2 * x_best\n                        sigma = min(3.0 * np.max(bounds_scale), sigma * 1.4)\n                else:\n                    # mild restart around best with small jitter\n                    jitter = rng.normal(scale=0.06 * np.maximum(bounds_scale, 1.0), size=self.dim)\n                    m = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                    C_diag = ((bounds_scale / 10.0) ** 2).clip(min=1e-12)\n                    sigma = max(sigma, 0.25 * np.mean(bounds_scale))\n                stagn_iters = 0  # reset after escape attempt\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DADCS scored 0.671 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ad00285c-2740-4894-bdf7-843cbde9ae5f", "operator": null, "metadata": {"aucs": [0.26105565030422706, 0.18373516924822642, 0.935787240425331, 0.9711040437042844, 0.9588944410918493, 0.9646683909045811, 0.30464155572984664, 0.9543607439000192, 0.9469223530314744, 0.23198735713469465]}, "task_prompt": ""}
{"id": "6e9a40c0-64e9-4293-8c37-4288eb9ff7c2", "fitness": 0.8088871309430363, "name": "DualScaleArchiveCMADE", "description": "This is a hybrid, budget-aware continuous optimizer that combines CMA-like rank-weighted recombination and covariance/sigma adaptation (weights from top-μ, cov_lr ≈ 0.22, sigma adapted via a smoothed success-rate p_succ toward target 0.2, chol_safe and a covariance floor/blend to avoid collapse). Sampling is dual-scale: mirrored Gaussian pairs around the mean for low-variance, variance-reduced exploitation, DE-style archive-driven long-range proposals (F_de≈0.8, CR≈0.9 plus Gaussian jitter and binomial crossover) for exploration, and smaller local Gaussians for fine exploitation, with population composition chosen per iteration. A bounded, size-scaling archive (archive_size ∝ dim) is maintained by replacing the worst entry, and is used both to seed DE moves and to anchor occasional heavy-tailed Cauchy “levy” escapes (levy_prob≈0.22); stagnation triggers cause budget-aware opportunistic restarts via a BIPOP-like pop_multiplier and mean jitter. Practical safeguards ensure robustness and budget compliance: bounds clipping, chol_safe eigen fallback, covariance regularization/flooring, sequential budget-tracked evaluations, and population sizing tied to budget and dimension.", "code": "import numpy as np\n\nclass DualScaleArchiveCMADE:\n    \"\"\"\n    DualScaleArchiveCMADE\n\n    A hybrid continuous optimizer combining:\n      - CMA-like mean/covariance/sigma adaptation (rank-weighted updates)\n      - Dual-scale sampling: mirrored local Gaussians for low-variance exploitation and archive-driven differential moves for long-range exploration\n      - Archive maintenance, smoothed success-rate sigma adaptation, Levy-style escapes and budget-aware opportunistic restarts\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n\n        # Tunables (sensible defaults)\n        self.pop_base = None\n        self.cov_lr = 0.22\n        self.sigma_adapt_rate = 0.22\n        self.success_target = 0.2\n        self.archive_size = min(60, max(6, 6 * self.dim))\n        self.levy_prob = 0.22\n        self.F_de = 0.8\n        self.CR = 0.9\n\n        # stagnation triggers (in iterations)\n        self.stagn_iter_trigger = max(8, int(0.05 * self.budget))\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # adaptive base population size\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # initial uniform sampling to seed archive and initial mean\n        evals = 0\n        init_batch = min(lam, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # archive arrays\n        archive_X = X0.copy()\n        archive_f = f0.copy()\n\n        def archive_add(x, fx):\n            nonlocal archive_X, archive_f\n            fx = float(fx)\n            if len(archive_f) < self.archive_size:\n                archive_X = np.vstack([archive_X, x.reshape(1, -1)])\n                archive_f = np.concatenate([archive_f, np.array([fx])])\n            else:\n                worst = int(np.argmax(archive_f))\n                if fx < archive_f[worst]:\n                    archive_X[worst] = x\n                    archive_f[worst] = fx\n\n        # init mean as weighted recombination of top-half\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        weights0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        weights0 = np.maximum(weights0, 0.0)\n        weights0 = weights0 / np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # covariance and sigma initial (bounds-scaled)\n        bounds_scale = (ub - lb)\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.25 * np.mean(bounds_scale))\n\n        # state\n        p_succ = self.success_target\n        stagn_iters = 0\n        iter_count = 0\n\n        # helper: safe factor A such that A^T A = C\n        def chol_safe(Cmat):\n            eps = 1e-12 * np.maximum(np.diag(Cmat), 1.0)\n            try:\n                return np.linalg.cholesky(Cmat + np.diag(eps))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(Cmat)\n                vals = np.clip(vals, 1e-12, None)\n                return (vecs * np.sqrt(vals)).T\n\n        # dynamic population multiplier for restarts (BIPOP-like)\n        pop_multiplier = 1\n        max_pop_multiplier = max(4, int(self.budget / max(50, self.dim)))\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(max(2, int(round(lam * pop_multiplier))), remaining)\n            mu = max(1, lam_iter // 2)\n\n            # recompute weights for mu\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # compute transform\n            A = chol_safe(C)\n\n            # mixing: half mirrored Gaussian local, some DE proposals, some small local exploitation\n            n_gauss = lam_iter // 2\n            # mirrored sampling uses pairs: generate half the number of unique normals and mirror them\n            # remaining slots: DE proposals (archive-driven) and small local Gaussians\n            n_remaining = lam_iter - n_gauss\n            n_de = int(0.6 * n_remaining)\n            n_local = n_remaining - n_de\n\n            Xcand = np.empty((lam_iter, self.dim), dtype=float)\n            idx = 0\n\n            # 1) mirrored Gaussian proposals (reduce estimator variance)\n            if n_gauss > 0:\n                # number of unique normals\n                n_unique = (n_gauss + 1) // 2\n                Z = rng.normal(size=(n_unique, self.dim))\n                Y = Z @ (A.T)\n                # scaled proposals\n                for i in range(n_unique):\n                    if idx < lam_iter:\n                        Xcand[idx] = np.minimum(np.maximum(m + sigma * Y[i], lb), ub)\n                        idx += 1\n                    if idx < lam_iter:\n                        Xcand[idx] = np.minimum(np.maximum(m - sigma * Y[i], lb), ub)\n                        idx += 1\n\n            # 2) DE-style proposals from archive (long-range)\n            if n_de > 0:\n                # ensure archive available\n                if len(archive_f) < 3:\n                    # fallback to Gaussian small perturbations\n                    Zd = rng.normal(size=(n_de, self.dim))\n                    Yd = Zd @ (A.T)\n                    for i in range(n_de):\n                        if idx >= lam_iter: break\n                        Xcand[idx] = np.minimum(np.maximum(m + 0.9 * sigma * Yd[i], lb), ub)\n                        idx += 1\n                else:\n                    # sort archive to bias towards good elites sometimes\n                    idx_sort = np.argsort(archive_f)\n                    sorted_X = archive_X[idx_sort]\n                    n_arch = len(sorted_X)\n                    for i in range(n_de):\n                        if idx >= lam_iter: break\n                        # pick base: either best or random elite\n                        if rng.rand() < 0.6:\n                            base = sorted_X[0]\n                        else:\n                            base = sorted_X[rng.randint(n_arch)]\n                        # pick two distinct others\n                        a, b = rng.choice(n_arch, size=2, replace=False)\n                        x1 = sorted_X[a]\n                        x2 = sorted_X[b]\n                        diff = self.F_de * (x1 - x2)\n                        # mix with mean or base\n                        target = base if rng.rand() < 0.5 else m\n                        trial = target + diff\n                        # small gaussian perturbation to keep stochasticity\n                        trial += rng.normal(scale=0.4 * sigma, size=self.dim)\n                        # binomial crossover with target\n                        mask = (rng.rand(self.dim) < self.CR)\n                        if not np.any(mask):\n                            mask[rng.randint(self.dim)] = True\n                        trial = np.where(mask, trial, target)\n                        trial = np.minimum(np.maximum(trial, lb), ub)\n                        Xcand[idx] = trial\n                        idx += 1\n\n            # 3) small-local Gaussian exploitation (smaller sigma)\n            if n_local > 0:\n                small_sigma = max(1e-12, 0.4 * sigma)\n                Zl = rng.normal(size=(n_local, self.dim))\n                Yl = Zl @ (A.T)\n                for i in range(n_local):\n                    if idx >= lam_iter: break\n                    Xcand[idx] = np.minimum(np.maximum(m + small_sigma * Yl[i], lb), ub)\n                    idx += 1\n\n            # Safety: if any slots left (rounding), fill with small Gaussian around m\n            while idx < lam_iter:\n                z = rng.normal(size=self.dim)\n                y = z @ (A.T)\n                Xcand[idx] = np.minimum(np.maximum(m + 0.8 * sigma * y, lb), ub)\n                idx += 1\n\n            # Evaluate candidates (sequentially)\n            f_cand = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                f_cand[i] = func(Xcand[i])\n            evals += lam_iter\n\n            # update archive with candidates\n            for i in range(lam_iter):\n                archive_add(Xcand[i].copy(), float(f_cand[i]))\n\n            # generation best\n            gen_best_idx = int(np.argmin(f_cand))\n            gen_best_f = float(f_cand[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n                stagn_iters = 0\n            else:\n                stagn_iters += 1\n\n            # selection of elites and recombination\n            order = np.argsort(f_cand)\n            X_mu = Xcand[order[:mu]]\n\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # deltas normalized by sigma (avoid division by zero)\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas\n\n            # covariance floor to prevent collapse\n            floor = np.diag(((bounds_scale / 20.0) ** 2).clip(min=1e-12))\n\n            # Update covariance with learning rate, regularize and blend with floor\n            C = (1.0 - self.cov_lr) * C + self.cov_lr * weighted_cov + 1e-14 * np.eye(self.dim)\n            # Blend with floor lightly\n            C = 0.985 * C + 0.015 * floor\n\n            # ensure symmetry\n            C = 0.5 * (C + C.T)\n\n            # update mean\n            m = m_new.copy()\n\n            # step-size adaptation (smoothed success rate)\n            p_succ = 0.9 * p_succ + 0.1 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n            # stagnation responses\n            if stagn_iters >= self.stagn_iter_trigger and evals < self.budget:\n                # try heavy-tailed escape with some probability\n                if rng.rand() < self.levy_prob and len(archive_f) > 0 and evals < self.budget:\n                    # pick anchor from top of archive (bias to best)\n                    idx_sort = np.argsort(archive_f)\n                    anchor_idx = idx_sort[rng.randint(min(len(idx_sort), max(3, self.dim)))]\n                    anchor = archive_X[anchor_idx]\n                    # cauchy jump scaled by range and sigma\n                    cauchy_scale = max(np.mean(bounds_scale) * 0.5, sigma * 6.0)\n                    jump = rng.standard_cauchy(size=self.dim) * cauchy_scale\n                    x_jump = np.minimum(np.maximum(anchor + jump, lb), ub)\n                    # evaluate (if budget permits)\n                    if evals < self.budget:\n                        fj = func(x_jump)\n                        evals += 1\n                        archive_add(x_jump.copy(), float(fj))\n                        if fj < f_best:\n                            f_best = float(fj)\n                            x_best = x_jump.copy()\n                            stagn_iters = 0\n                            # reset mean near new best and refresh C/sigma\n                            m = x_jump.copy()\n                            sigma = max(sigma, 0.45 * np.mean(bounds_scale))\n                            C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                        else:\n                            # nudge mean toward best and inflate sigma a bit\n                            m = 0.75 * m + 0.25 * x_best\n                            sigma = min(2.0 * np.max(bounds_scale), sigma * 1.4)\n                else:\n                    # opportunistic restart: increase population occasionally (multi-population restart)\n                    stagn_iters = 0\n                    pop_multiplier = min(max_pop_multiplier, pop_multiplier * 1.6)\n                    # reposition mean around best with jitter inversely proportional to pop_multiplier\n                    jitter_scale = 0.6 * np.mean(bounds_scale) / max(1.0, pop_multiplier)\n                    m = np.minimum(np.maximum(x_best + rng.normal(scale=jitter_scale, size=self.dim), lb), ub)\n                    # reset sigma and covariance moderately\n                    sigma = max(sigma, 0.35 * np.mean(bounds_scale))\n                    C = np.diag(((bounds_scale / (4.0 + pop_multiplier)) ** 2).clip(min=1e-12))\n\n            # moderate population shrink when progress is good\n            if improved and pop_multiplier > 1:\n                pop_multiplier = max(1, pop_multiplier * 0.85)\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DualScaleArchiveCMADE scored 0.809 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ad00285c-2740-4894-bdf7-843cbde9ae5f", "operator": null, "metadata": {"aucs": [0.31386583133501655, 0.9300059117027197, 0.9065910007309571, 0.9704708635084373, 0.936875804343425, 0.9471548667649219, 0.3082128140576117, 0.9178874151346217, 0.9370841488171634, 0.9207226530354886]}, "task_prompt": ""}
{"id": "733c54d6-7567-4b8b-a4c2-286bbe7c5adc", "fitness": 0.5476254407873283, "name": "SubspaceMirroredHybrid", "description": "The design is a hybrid global/local search that mixes CMA-like Gaussian sampling (antithetic when possible) with archive-driven DE-style trial vectors (lam ≈ max(8, 4+3log dim), F_de=0.8, CR=0.9), all respecting box bounds and a strict budget via a single eval wrapper. For exploitation it performs targeted local moves: occasional low-rank linear surrogates fitted in random subspaces (least-squares to estimate a subspace gradient) and mirrored central-difference directional probes around archive-biased centers, both governed by an adaptive trust_radius. Global adaptation uses a weighted-selection covariance update (cov_lr=0.22) and smoothed success-rate sigma adaptation (sigma_adapt_rate=0.22, success_target=0.2) with expansion/shrink factors to control step sizes. Robustness/exploration is enforced by an elite archive (size min(40, max(5,4*dim))), heavy-tailed Cauchy/Lévy restarts (levy_prob=0.25), occasional uniform injections, and SPD/correction safeguards for the covariance.", "code": "import numpy as np\n\nclass SubspaceMirroredHybrid:\n    \"\"\"\n    Subspace-Mirrored Hybrid CMA-DE\n\n    One-line: Hybrid CMA-like + DE mixture augmented with occasional\n    low-rank linear surrogate steps and mirrored directional derivative probes\n    around elite archive points, using an adaptive trust radius and heavy-tailed restarts.\n\n    Key features:\n    - Gaussian proposals from N(m, sigma^2 C) + archive-driven DE proposals (half/half).\n    - Occasional low-rank subspace linear model (least-squares) to estimate a subspace gradient.\n    - Mirrored directional central-difference probes to build gradient estimates cheaply.\n    - Adaptive trust radius (expand/shrink) and sigma adaptation via success smoothing.\n    - Elite archive used to bias centers for local surrogate/probe steps.\n    - Heavy-tailed (Cauchy) restarts/injections on stagnation.\n    - Strict budget-aware evaluation wrapper.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n\n        # algorithm knobs\n        self.pop_base = None\n        self.cov_lr = 0.22\n        self.sigma_adapt_rate = 0.22\n        self.success_target = 0.2\n        self.levy_prob = 0.25\n        self.F_de = 0.8\n        self.CR = 0.9\n\n        # frequencies for model/directional actions\n        self.p_model = 0.33\n        self.p_directional = 0.33\n        self.p_global = 0.34\n\n        # trust radius adaptation\n        self.trust_expand = 1.25\n        self.trust_shrink = 0.6\n        self.trust_min_frac = 1e-6\n        self.trust_max_frac = 1.5\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        max_span = float(np.max(span))\n        diag_span = np.maximum(span, 1e-12)\n\n        # population size\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # archive settings\n        archive_size = min(40, max(5, 4 * self.dim))\n        archive = []  # list of (f, x) sorted ascending\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n\n        # helper to evaluate safely\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = float(func(x))\n            evals += 1\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # maintain archive\n            if len(archive) < archive_size or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_size:\n                    archive.pop()\n            return f, x\n\n        # initial seeding: uniform samples to fill some archive and initialize mean\n        init_batch = min(lam, max(10, int(2 * self.dim)))\n        for _ in range(init_batch):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one point\n        if len(archive) == 0 and evals < self.budget:\n            eval_and_record(rng.uniform(lb, ub))\n\n        # initialize mean m, covariance C, sigma\n        if len(archive) > 0:\n            m = np.copy(archive[0][1])\n        else:\n            m = rng.uniform(lb, ub)\n\n        bounds_scale = (ub - lb)\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.20 * np.mean(bounds_scale))\n\n        # trust radius (relative to avg_span)\n        trust_radius = 0.2 * avg_span\n        trust_min = self.trust_min_frac * avg_span\n        trust_max = self.trust_max_frac * avg_span\n\n        p_succ = self.success_target\n        stagn_iters = 0\n        iter_count = 0\n\n        # helpers\n        def chol_safe(mat):\n            eps = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, 1e-12, None)\n                return (vecs * np.sqrt(vals)).T\n\n        def heavy_tail_scalar():\n            s = rng.standard_cauchy()\n            return float(np.clip(s, -1e2, 1e2))\n\n        def random_subspace(k):\n            Y = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(Y)\n            return Q[:, :k]\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu = max(1, lam_iter // 2)\n\n            # occasionally perform a targeted surrogate/directional move instead of full population\n            op = rng.rand()\n            local_success = False\n\n            # choose center biased to best archive\n            if len(archive) > 0 and rng.rand() < 0.75:\n                # pick best or near-best\n                if rng.rand() < 0.8:\n                    center_f, center = archive[0]\n                    center = center.copy()\n                else:\n                    idx = min(len(archive)-1, rng.randint(0, len(archive)))\n                    center_f, center = archive[idx]\n                    center = center.copy()\n            else:\n                # jitter around best or sample uniform\n                if x_best is not None and rng.rand() < 0.6:\n                    jitter = 0.12 * avg_span * rng.randn(self.dim)\n                    center = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                    res = eval_and_record(center)\n                    if res is None:\n                        break\n                    center_f, center = res\n                else:\n                    center = rng.uniform(lb, ub)\n                    res = eval_and_record(center)\n                    if res is None:\n                        break\n                    center_f, center = res\n\n            # cap local budget for surrogate/probe (leave room)\n            max_local = max(2, min(remaining - 1, int(0.05 * self.budget)))\n\n            # 1) Low-rank linear surrogate in subspace\n            if op < self.p_model and max_local >= 4:\n                # choose small subspace dimension\n                k = min(4, max(1, self.dim // 4))\n                k = max(1, int(rng.choice([1, min(2, k), k])))\n                U = random_subspace(k)  # dim x k\n                sigma_loc = min(trust_radius, 0.75 * trust_max)\n                # design points in subspace coords\n                s = min(max_local, max(4, 2 * k + 2))\n                Z = rng.uniform(-1.0, 1.0, size=(s, k))\n                Xs = np.asarray([np.minimum(np.maximum(center + (sigma_loc * (Z[i] @ U.T)), lb), ub) for i in range(s)])\n                fvals = []\n                actual = 0\n                for i in range(s):\n                    if evals >= self.budget:\n                        break\n                    res = eval_and_record(Xs[i])\n                    if res is None:\n                        break\n                    fi, xi = res\n                    fvals.append(fi)\n                    actual += 1\n                if len(fvals) >= k + 1:\n                    fvals = np.asarray(fvals, dtype=float)\n                    Z_used = Z[:len(fvals), :]\n                    A_mat = np.concatenate([np.ones((len(fvals), 1)), Z_used], axis=1)\n                    try:\n                        sol, *_ = np.linalg.lstsq(A_mat, fvals, rcond=None)\n                        g_sub = sol[1:]\n                        g_full = (U @ g_sub).astype(float)\n                        gnorm = np.linalg.norm(g_full)\n                        step_scale = sigma_loc * (0.9 + 0.4 * heavy_tail_scalar() * 0.01)\n                        if gnorm < 1e-12:\n                            prop = center + step_scale * rng.randn(self.dim) * 0.5\n                        else:\n                            prop = center - step_scale * g_full / gnorm\n                        prop = np.minimum(np.maximum(prop, lb), ub)\n                        res = eval_and_record(prop)\n                        if res is None:\n                            break\n                        fprop, xprop = res\n                        if fprop < center_f:\n                            trust_radius = min(trust_max, trust_radius * self.trust_expand)\n                            local_success = True\n                        else:\n                            trust_radius = max(trust_min, trust_radius * self.trust_shrink)\n                            local_success = False\n                    except Exception:\n                        trust_radius = max(trust_min, trust_radius * self.trust_shrink)\n                        local_success = False\n                else:\n                    # insufficient data, fall back to small random local try\n                    if evals < self.budget:\n                        y = center + 0.6 * trust_radius * rng.randn(self.dim)\n                        res = eval_and_record(y)\n                        if res is None:\n                            break\n                # continue to next iteration\n                continue\n\n            # 2) Mirrored directional probing exploitation\n            elif op < self.p_model + self.p_directional and max_local >= 2:\n                d = min(self.dim, max(1, int(1 + rng.randint(0, min(3, self.dim - 1)))))\n                d = min(d, max(1, max_local // 2))\n                directions = []\n                if len(archive) >= 2 and rng.rand() < 0.7:\n                    for i in range(min(d, len(archive)-1)):\n                        v = archive[i+1][1] - archive[0][1]\n                        if np.linalg.norm(v) > 0:\n                            directions.append(v / (np.linalg.norm(v) + 1e-12))\n                while len(directions) < d:\n                    v = rng.randn(self.dim)\n                    v = v / (np.linalg.norm(v) + 1e-12)\n                    directions.append(v)\n                grad_est = np.zeros(self.dim, dtype=float)\n                used = 0\n                for v in directions:\n                    if evals + 2 > self.budget:\n                        break\n                    delta = trust_radius * (0.6 + 0.8 * rng.rand())\n                    xp = np.minimum(np.maximum(center + delta * v, lb), ub)\n                    xn = np.minimum(np.maximum(center - delta * v, lb), ub)\n                    res1 = eval_and_record(xp)\n                    if res1 is None:\n                        break\n                    res2 = eval_and_record(xn)\n                    if res2 is None:\n                        break\n                    fp, _ = res1; fn, _ = res2\n                    ddir = (fp - fn) / (2.0 * delta)\n                    grad_est += ddir * v\n                    used += 2\n                if used == 0:\n                    continue\n                gnorm = np.linalg.norm(grad_est)\n                if gnorm < 1e-12:\n                    step = 0.6 * trust_radius * rng.randn(self.dim)\n                else:\n                    step = - (trust_radius * 0.9) * grad_est / gnorm\n                proposed = np.minimum(np.maximum(center + step, lb), ub)\n                res = eval_and_record(proposed)\n                if res is None:\n                    break\n                fprop, xprop = res\n                if fprop < center_f:\n                    trust_radius = min(trust_max, trust_radius * self.trust_expand)\n                    local_success = True\n                else:\n                    trust_radius = max(trust_min, trust_radius * self.trust_shrink)\n                    local_success = False\n                continue\n\n            # 3) Global mixed CMA/DE population step (default)\n            else:\n                # compose population half Gaussian half DE-style\n                A = chol_safe(C)\n                n_gauss = lam_iter // 2\n                n_de = lam_iter - n_gauss\n                Xcand = np.empty((lam_iter, self.dim), dtype=float)\n\n                # Gaussian proposals (antithetic if even)\n                if n_gauss > 0:\n                    half = n_gauss // 2\n                    if half > 0:\n                        Zpos = rng.normal(size=(half, self.dim))\n                        Z = np.vstack([Zpos, -Zpos])\n                        if n_gauss % 2 == 1:\n                            Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n                        Y = Z @ A.T\n                    else:\n                        Z = rng.normal(size=(n_gauss, self.dim))\n                        Y = Z @ A.T\n                    Xg = m + sigma * Y\n                    Xg = np.minimum(np.maximum(Xg, lb), ub)\n                    Xcand[:n_gauss] = Xg\n\n                # DE-style proposals from archive\n                if n_de > 0:\n                    if len(archive) < 3:\n                        Zd = rng.normal(size=(n_de, self.dim))\n                        Yd = Zd @ A.T\n                        Xd = m + sigma * Yd\n                        Xd = np.minimum(np.maximum(Xd, lb), ub)\n                        Xcand[n_gauss:] = Xd\n                    else:\n                        # sort archive occasionally\n                        idx_sort = np.argsort([t[0] for t in archive])\n                        sorted_X = np.vstack([archive[i][1] for i in idx_sort])\n                        for i in range(n_de):\n                            if rng.rand() < 0.6:\n                                base = sorted_X[0]\n                            else:\n                                base = sorted_X[rng.randint(len(sorted_X))]\n                            # pick two distinct\n                            ids = rng.choice(len(sorted_X), size=2, replace=False)\n                            x1 = sorted_X[ids[0]]; x2 = sorted_X[ids[1]]\n                            trial = base + self.F_de * (x1 - x2)\n                            trial += rng.normal(scale=0.5 * sigma, size=self.dim)\n                            mask = rng.rand(self.dim) < self.CR\n                            if not np.any(mask):\n                                mask[rng.randint(self.dim)] = True\n                            target = m if rng.rand() < 0.5 else base\n                            trial = np.where(mask, trial, target)\n                            trial = np.minimum(np.maximum(trial, lb), ub)\n                            Xcand[n_gauss + i] = trial\n\n                # evaluate candidates one by one budget-aware\n                f_cand = np.full(Xcand.shape[0], np.inf, dtype=float)\n                for i in range(Xcand.shape[0]):\n                    if evals >= self.budget:\n                        break\n                    xi = Xcand[i]\n                    res = eval_and_record(xi)\n                    if res is None:\n                        break\n                    fi, xi = res\n                    f_cand[i] = fi\n\n                # trim invalids if budget ended mid-batch\n                valid = np.isfinite(f_cand)\n                if not np.all(valid):\n                    Xcand = Xcand[valid]\n                    f_cand = f_cand[valid]\n                    if Xcand.shape[0] == 0:\n                        break\n\n                # update archive already handled in eval_and_record\n                gen_best_idx = int(np.argmin(f_cand))\n                gen_best_f = float(f_cand[gen_best_idx])\n                gen_best_x = Xcand[gen_best_idx].copy()\n\n                improved = False\n                if gen_best_f < f_best:\n                    f_best = gen_best_f\n                    x_best = gen_best_x.copy()\n                    improved = True\n                    stagn_iters = 0\n                else:\n                    stagn_iters += 1\n\n                # selection top-mu\n                order = np.argsort(f_cand)\n                X_mu = Xcand[order[:mu]]\n\n                # update mean\n                weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n                weights = np.maximum(weights, 0.0)\n                if np.sum(weights) <= 0:\n                    weights = np.ones_like(weights)\n                weights /= np.sum(weights)\n                m_new = (weights.reshape(-1, 1) * X_mu[:weights.shape[0]]).sum(axis=0)\n\n                # deltas and weighted covariance in normalized coords\n                deltas = (X_mu - m) / (sigma + 1e-20)\n                W = weights.reshape(-1, 1)\n                weighted_cov = (deltas * W).T @ deltas if deltas.shape[0] > 0 else np.zeros((self.dim, self.dim))\n\n                # update covariance with learning rate and small floor\n                C = (1.0 - self.cov_lr) * C + self.cov_lr * weighted_cov + 1e-12 * np.eye(self.dim)\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                C = (vecs * vals) @ vecs.T  # ensure PD\n\n                # update mean\n                m = np.minimum(np.maximum(m_new, lb), ub)\n\n                # sigma adaptation via smoothed success-rate\n                p_succ = 0.9 * p_succ + 0.1 * float(improved)\n                sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n                sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n                # adapt trust radius slowly when global iter improves\n                if improved:\n                    trust_radius = min(trust_max, trust_radius * self.trust_expand)\n                else:\n                    trust_radius = max(trust_min, trust_radius * self.trust_shrink)\n\n            # occasional uniform injection to keep exploration\n            if iter_count % 29 == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # Opportunistic heavy-tailed Lévy jump on stagnation\n            if stagn_iters > max(10, int(0.02 * self.budget)) and evals < self.budget:\n                stagn_iters = 0\n                if rng.rand() < self.levy_prob:\n                    # anchor from archive\n                    if len(archive) > 0:\n                        anchor = archive[rng.randint(0, len(archive))][1]\n                    else:\n                        anchor = m\n                    c_scale = max(0.5 * avg_span, 5.0 * sigma)\n                    jump = rng.standard_cauchy(size=self.dim) * c_scale\n                    x_jump = np.minimum(np.maximum(anchor + jump, lb), ub)\n                    res = eval_and_record(x_jump)\n                    if res is None:\n                        break\n                    fj, xj = res\n                    if fj < f_best:\n                        f_best = fj; x_best = xj.copy()\n                        # re-center and inflate sigma & trust radius a bit\n                        m = xj.copy()\n                        sigma = max(sigma, 0.5 * avg_span)\n                        trust_radius = max(trust_radius, 0.4 * avg_span)\n                        # reset covariance moderately\n                        C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n\n            # safety SPD correction each main iteration\n            try:\n                _ = np.linalg.cholesky(C + np.eye(self.dim) * 1e-16)\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                C = (vecs * vals) @ vecs.T\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SubspaceMirroredHybrid scored 0.548 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ad00285c-2740-4894-bdf7-843cbde9ae5f", "operator": null, "metadata": {"aucs": [0.19848844848332725, 0.15802691097570454, 0.9166851328319285, 0.9668579695694859, 0.2812736773400166, 0.9502035569945452, 0.27165292722933565, 0.5896556173166977, 0.9450917566220692, 0.19831841051017296]}, "task_prompt": ""}
{"id": "c3c30e9e-1d2a-4bee-927b-7dbe5764f4e3", "fitness": 0.24339355728668335, "name": "LASS", "description": "LASS mixes global heavy-tailed escapes (Cauchy jumps, cauchy_prob≈0.18) with adaptive Gaussian exploration that is biased into a learned low-rank subspace (recent normalized successful displacements are SVD'd to produce U, sub_bias grows with history) and occasional DE‑style recombination from an archive (de_inject_prob≈0.12) to promote diversity. The algorithm maintains a weighted-elite mean (CMA-like weights), an EMA momentum on normalized mean displacements (momentum_beta≈0.85), and a success-rate controlled sigma (sigma_init scaled by problem range, adapt_rate≈0.3, success_target≈0.2) to adapt step sizes. Bound handling is via reflection-then-clamp, and candidate lengths use gamma-shaped scaling or normalized Gaussian directions to balance local vs. global moves while trimming extreme Cauchy outliers. Periodically it runs rotated-local refinements (simplex when dim small, otherwise rotated coordinate pattern) using a small local_budget_frac, keeps a bounded archive with replacement of poor entries, and performs jittered restarts when sigma collapses or stagnation is detected.", "code": "import numpy as np\n\nclass LASS:\n    \"\"\"\n    Levy-driven Adaptive Subspace Search (LASS)\n\n    One-line: Combine heavy-tailed (Cauchy) jumps for global escapes, adaptive Gaussian\n    exploration biased into a learnt low-rank subspace of past successful displacements,\n    and periodic rotated-local-simplex refinements + archive-based recombination.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop=20,\n                 subspace_k=None,         # dimensionality of learnt subspace\n                 momentum_beta=0.85,      # EMA for mean momentum\n                 sigma_init=0.2,          # initial step scale relative to bounds range\n                 adapt_rate=0.3,          # sigma adaptation strength\n                 success_target=0.2,      # target success rate for sigma adaptation\n                 cauchy_prob=0.18,        # probability to take a heavy-tailed (Cauchy) jump\n                 de_inject_prob=0.12,     # archive recombination probability\n                 local_period=30,         # gens between local refinements\n                 local_budget_frac=0.06,  # fraction of remaining budget for local refinement\n                 archive_capacity=None,\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop = max(4, int(pop))\n        self.subspace_k = subspace_k if subspace_k is not None else max(1, min(self.dim, 4))\n        self.momentum_beta = float(momentum_beta)\n        self.sigma_init = float(sigma_init)\n        self.adapt_rate = float(adapt_rate)\n        self.success_target = float(success_target)\n        self.cauchy_prob = float(cauchy_prob)\n        self.de_inject_prob = float(de_inject_prob)\n        self.local_period = int(local_period)\n        self.local_budget_frac = float(local_budget_frac)\n        self.archive_capacity = archive_capacity\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # read bounds, allow scalar bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = ub - lb\n        range_mean = float(np.mean(bounds_scale))\n        max_bound = float(np.max(bounds_scale))\n\n        # population size cannot exceed budget\n        pop = min(self.pop, max(2, self.budget))\n        if pop % 2 == 1 and pop > 2:\n            pop -= 1\n\n        # archive capacity\n        if self.archive_capacity is None:\n            archive_capacity = max(4 * self.dim, 30)\n        else:\n            archive_capacity = int(self.archive_capacity)\n\n        evals = 0\n\n        # initial population: uniform sampling to seed archive and statistics\n        init_pop = min(pop, max(2, self.budget))\n        X = rng.uniform(lb, ub, size=(init_pop, self.dim))\n        fvals = np.empty(init_pop, dtype=float)\n        for i in range(init_pop):\n            if evals >= self.budget:\n                break\n            fvals[i] = float(func(X[i]))\n            evals += 1\n\n        # record best\n        best_idx = int(np.argmin(fvals[:init_pop]))\n        f_best = float(fvals[best_idx])\n        x_best = X[best_idx].copy()\n\n        # initialize mean from weighted elites (top half)\n        mu0 = max(1, init_pop // 2)\n        order0 = np.argsort(fvals[:init_pop])\n        elites0 = X[order0[:mu0]]\n        # log-weights (like CMA-style)\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 /= np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # adaptive parameters\n        sigma = max(1e-12, self.sigma_init * range_mean)\n        p_succ = float(self.success_target)  # EMA of success\n        v = np.zeros(self.dim, dtype=float)  # momentum in normalized coordinates\n\n        # archive: store diverse solutions for recombination\n        archive_X = [X[i].copy() for i in range(init_pop)]\n        archive_f = [float(fvals[i]) for i in range(init_pop)]\n\n        # subspace of recent successful displacement vectors (normalized)\n        recent_deltas = []  # list of arrays (dim,)\n        k = max(1, min(self.subspace_k, self.dim))\n\n        gen = 0\n        stagn_gens = 0\n\n        def reflect_then_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # utility to compute orthonormal basis U from recent deltas\n        def compute_subspace(recent_list, kk):\n            if len(recent_list) == 0:\n                return np.zeros((self.dim, 0))\n            M = np.vstack(recent_list)  # (t, dim)\n            # center rows (they are already zero-mean typically), perform SVD for basis\n            try:\n                U, S, Vt = np.linalg.svd(M, full_matrices=False)\n                # Vt.shape = (rank, dim), take top kk rows -> basis vectors are Vt[:kk].T\n                kk_eff = min(kk, Vt.shape[0])\n                basis = Vt[:kk_eff].T  # (dim, kk_eff)\n                # orthonormal columns\n                return basis\n            except np.linalg.LinAlgError:\n                return np.zeros((self.dim, 0))\n\n        # main loop: generate batches until budget used\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            # batch size adaptively chosen but not more than remaining\n            lam = min(pop, remaining)\n            # sample candidate offsets\n            # compute subspace basis\n            U = compute_subspace(recent_deltas, k)  # (dim, k_eff)\n            k_eff = U.shape[1]\n\n            # bias strength into subspace increases as we learn more\n            sub_bias = 0.2 + 0.6 * min(1.0, len(recent_deltas) / float(max(4, k)))\n            # create candidate matrix\n            Xcand = np.zeros((lam, self.dim), dtype=float)\n            for i in range(lam):\n                # choose whether heavy-tailed jump\n                if rng.rand() < self.cauchy_prob:\n                    # Cauchy step (heavy-tailed) scaled by sigma, along random direction\n                    step_len = np.abs(rng.standard_cauchy())  # may be large\n                    # limit outliers moderately\n                    step_len = np.clip(step_len, 0.0, 50.0)\n                    dir_vec = rng.normal(size=self.dim)\n                    dir_vec /= (np.linalg.norm(dir_vec) + 1e-20)\n                    delta = dir_vec * (sigma * step_len)\n                else:\n                    # Gaussian step partially in learnt subspace\n                    if k_eff > 0 and rng.rand() < sub_bias:\n                        # sample coefficients for subspace\n                        coeff = rng.normal(scale=1.0, size=k_eff)\n                        subpart = U @ coeff  # (dim,)\n                        # orth complement small isotropic noise\n                        perp = rng.normal(scale=0.6, size=self.dim)\n                        # remove projection on U from perp\n                        if k_eff < self.dim:\n                            proj = (U @ (U.T @ perp))\n                            perp = perp - proj\n                        perp *= 0.6\n                        delta = subpart + perp\n                        # normalize and scale\n                        delta /= (np.linalg.norm(delta) + 1e-20)\n                        delta = delta * sigma * rng.gamma(shape=1.5, scale=1.0)  # gamma-shaped length\n                    else:\n                        # plain Gaussian exploration around mean\n                        z = rng.normal(size=self.dim)\n                        z /= (np.linalg.norm(z) + 1e-20)\n                        delta = z * sigma * rng.normal(loc=1.0, scale=0.6)\n                # occasionally inject a DE-like recombinant\n                if (len(archive_X) >= 3) and (rng.rand() < self.de_inject_prob):\n                    idxs = rng.choice(len(archive_X), size=3, replace=False)\n                    base = archive_X[idxs[0]]\n                    diff = archive_X[idxs[1]] - archive_X[idxs[2]]\n                    F = 0.75 * rng.rand()\n                    trial = base + F * diff + 0.3 * delta\n                    trial = reflect_then_clamp(trial)\n                    Xcand[i] = trial\n                else:\n                    Xcand[i] = m + delta\n\n            # clamp candidates into bounds with reflection\n            for i in range(Xcand.shape[0]):\n                Xcand[i] = reflect_then_clamp(Xcand[i])\n\n            # evaluate candidates sequentially\n            fc = np.full(Xcand.shape[0], np.inf, dtype=float)\n            improved_any = False\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                xi = Xcand[i]\n                fv = float(func(xi))\n                fc[i] = fv\n                evals += 1\n                # immediate update of global best\n                if fv < f_best:\n                    f_best = fv\n                    x_best = xi.copy()\n                    improved_any = True\n                    stagn_gens = 0\n\n            # trim if budget exhausted mid-batch\n            valid_mask = np.isfinite(fc)\n            if not np.all(valid_mask):\n                Xcand = Xcand[valid_mask]\n                fc = fc[valid_mask]\n                if Xcand.shape[0] == 0:\n                    break\n\n            # add to archive (preserve best variety)\n            for xi, fi in zip(Xcand, fc):\n                archive_X.append(xi.copy())\n                archive_f.append(float(fi))\n            if len(archive_X) > archive_capacity:\n                # remove worst older entries\n                # keep the best half and recent portion\n                idxs_keep = np.argsort(archive_f)[:archive_capacity]\n                archive_X = [archive_X[i] for i in idxs_keep]\n                archive_f = [archive_f[i] for i in idxs_keep]\n\n            # determine generation best relative to mean to record successes\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            # compute elite set for mean update (top half)\n            lam_eff = Xcand.shape[0]\n            mu = max(1, lam_eff // 2)\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            # compute weighted mean update\n            w = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            w = np.maximum(w, 0.0)\n            if np.sum(w) <= 0:\n                w = np.ones_like(w)\n            w = w / np.sum(w)\n            m_new = (w.reshape(-1, 1) * X_mu[:w.shape[0]]).sum(axis=0)\n            # record displacement for momentum / subspace learning\n            delta_m = (m_new - m) / (sigma + 1e-20)\n            # update momentum (EMA)\n            v = self.momentum_beta * v + (1.0 - self.momentum_beta) * delta_m\n\n            # If at least one elite is strictly better than previous mean (relative to best), consider success\n            gen_improved = (gen_best_f < f_best + 1e-20) and (gen_best_f < np.min(archive_f) + 1e-20 or improved_any)\n\n            # update sigma via success-rate rule (smoothed)\n            success_here = float(np.any(fc < f_best))\n            p_succ = 0.85 * p_succ + 0.15 * (success_here > 0)\n            sigma *= np.exp(self.adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, 1e-12, 2.0 * max_bound)\n\n            # store successful displacement(s) into recent_deltas\n            # successful = those that improved over current mean position m (we use improvement over m if known)\n            for xi, fi in zip(Xcand, fc):\n                # define success relative to current mean's projection: if candidate is among elites or better than current best, log delta\n                if fi <= gen_best_f + 1e-12 or fi < f_best + 1e-12:\n                    d = (xi - m) / (np.linalg.norm(xi - m) + 1e-20)\n                    recent_deltas.append(d)\n            # keep limited history\n            max_hist = max(4, 4 * k)\n            if len(recent_deltas) > max_hist:\n                recent_deltas = recent_deltas[-max_hist:]\n\n            # update mean gently (momentum-influenced)\n            # Use convex combination to avoid abrupt jumps\n            m = 0.85 * m + 0.15 * m_new\n            m = reflect_then_clamp(m)\n\n            # stagnation accounting\n            if improved_any:\n                stagn_gens = 0\n            else:\n                stagn_gens += 1\n\n            # periodic rotated simplex local refinement when budget permits\n            if (gen % self.local_period == 0) and (self.budget - evals > 0):\n                # allocate small local budget proportional to remaining budget\n                loc_budget = max(1, int(self.local_budget_frac * max(1, self.budget - evals)))\n                # if dim is small-ish, attempt a rotated Nelder-Mead-like simplex; otherwise do rotated coordinate pattern\n                if self.dim <= 20 and loc_budget >= (self.dim + 1):\n                    # build simplex around best using low-rank rotation by U (if available)\n                    simplex = np.zeros((self.dim + 1, self.dim))\n                    simplex[0] = x_best.copy()\n                    scale = max(1e-12, 0.05 * range_mean)\n                    for i in range(1, self.dim + 1):\n                        e = np.zeros(self.dim)\n                        # use U to rotate if available\n                        if U.shape[1] >= 1:\n                            # select a basis column cyclically\n                            col = U[:, (i - 1) % U.shape[1]]\n                            e = col\n                        else:\n                            e[i - 1] = 1.0\n                        simplex[i] = reflect_then_clamp(simplex[0] + scale * e)\n                    # evaluate simplex points\n                    fs = np.empty(self.dim + 1)\n                    for i in range(self.dim + 1):\n                        if evals >= self.budget or i >= loc_budget:\n                            fs[i:] = np.inf\n                            break\n                        fs[i] = float(func(simplex[i]))\n                        evals += 1\n                        if fs[i] < f_best:\n                            f_best = fs[i]\n                            x_best = simplex[i].copy()\n                            stagn_gens = 0\n                    # simple adaptive procedure: try reflecting worst across centroid\n                    # find worst\n                    if np.isfinite(fs).any():\n                        worst = int(np.argmax(fs))\n                        best_idx_local = int(np.argmin(fs))\n                        centroid = np.mean(np.delete(simplex, worst, axis=0), axis=0)\n                        reflected = reflect_then_clamp(centroid + (centroid - simplex[worst]))\n                        if evals < self.budget:\n                            fr = float(func(reflected))\n                            evals += 1\n                            if fr < fs[best_idx_local]:\n                                # accept reflection replacing worst and maybe shrink/logical moves\n                                simplex[worst] = reflected\n                                if fr < f_best:\n                                    f_best = fr\n                                    x_best = reflected.copy()\n                                    stagn_gens = 0\n                else:\n                    # rotated coordinate pattern: use U to define order of explored coordinates\n                    step = max(1e-12, 0.06 * range_mean)\n                    local_evals = 0\n                    x_work = x_best.copy()\n                    f_work = f_best\n                    # obtain a rotation matrix R: columns are U then random orthonormal complement\n                    if U.shape[1] > 0:\n                        # orthonormalize complement\n                        Q = U.copy()\n                        # if less than dim, fill with random orthonormal complement\n                        if Q.shape[1] < self.dim:\n                            # Gram-Schmidt against Q for random vectors\n                            comp = []\n                            trials = 0\n                            while Q.shape[1] + len(comp) < self.dim and trials < 5 * self.dim:\n                                v_rand = rng.normal(size=self.dim)\n                                # orthogonalize against Q and existing comp\n                                for qv in [*Q.T, *comp]:\n                                    v_rand -= np.dot(v_rand, qv) * qv\n                                nrm = np.linalg.norm(v_rand)\n                                if nrm > 1e-8:\n                                    comp.append(v_rand / nrm)\n                                trials += 1\n                            if len(comp) > 0:\n                                Q = np.column_stack([Q, np.column_stack(comp)])\n                        R = Q if Q.shape[1] == self.dim else np.eye(self.dim)\n                    else:\n                        R = np.eye(self.dim)\n                    # iterate small coordinate probes\n                    while local_evals < loc_budget and evals < self.budget:\n                        moved = False\n                        for idx_col in range(self.dim):\n                            if evals >= self.budget or local_evals >= loc_budget:\n                                break\n                            # direction in original space\n                            col_vec = R[:, idx_col % R.shape[1]]\n                            # try plus\n                            xt = reflect_then_clamp(x_work + step * col_vec)\n                            fv = float(func(xt))\n                            evals += 1\n                            local_evals += 1\n                            if fv < f_work:\n                                x_work = xt\n                                f_work = fv\n                                moved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = xt.copy()\n                                    stagn_gens = 0\n                                continue\n                            # try minus\n                            xt = reflect_then_clamp(x_work - step * col_vec)\n                            fv = float(func(xt))\n                            evals += 1\n                            local_evals += 1\n                            if fv < f_work:\n                                x_work = xt\n                                f_work = fv\n                                moved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = xt.copy()\n                                    stagn_gens = 0\n                        if not moved:\n                            step *= 0.5\n                            if step < 1e-10 * range_mean:\n                                break\n                    # inject local improvements into archive\n                    if f_work < np.max(archive_f):\n                        worst_idx = int(np.argmax(archive_f))\n                        archive_X[worst_idx] = x_work.copy()\n                        archive_f[worst_idx] = float(f_work)\n                        if f_work < f_best:\n                            f_best = f_work\n                            x_best = x_work.copy()\n                            stagn_gens = 0\n\n            # opportunistic restart nudges if sigma collapses or prolonged stagnation\n            if sigma < 1e-12 * max_bound or stagn_gens > max(6, 3 * self.local_period):\n                # jitter center around best, modest reinitialization\n                jitter = rng.normal(scale=0.05 * bounds_scale, size=self.dim)\n                m = reflect_then_clamp(x_best + jitter)\n                sigma = max(sigma, 0.12 * range_mean)\n                v = np.zeros_like(v)\n                recent_deltas = []\n                stagn_gens = 0\n\n            # ensure not exceeding budget (loop head handles breaks)\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm LASS scored 0.243 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "25ef7321-3c58-4469-96c5-fb81ab07c8f5", "operator": null, "metadata": {"aucs": [0.14460688128460808, 0.16825848900404816, 0.38795236191927585, 0.38069288566741477, 0.20709700343215665, 0.24048499095209186, 0.2512649888024069, 0.30318571396622485, 0.20441061184522424, 0.1459816459933817]}, "task_prompt": ""}
{"id": "72fa7282-40ae-4b1d-b292-e6ac152bb19f", "fitness": 0.22836363321426506, "name": "LADS", "description": "LADS blends ADAM-style directional learning with light-weight evolutionary tricks: it maintains first/second moment estimates (m1, m2) with high momentum (beta1=0.85) and faster RMS adaptation (beta2=0.70) and uses bias-corrected adjusted directions to update a center m, while a per-coordinate RMS scale s_diag (RMSprop-inspired, clipped to [0.05,6]) modulates sampling anisotropy. Global step-size sigma is initialized relative to the search range (sigma0=0.25*mean_range) and adapted multiplicatively (inc=1.10 on success, dec=0.95 on failure) so steps change gently; lr=0.15 controls how center updates translate into movement (m += lr * adjusted * sigma). Exploration/exploitation is diversified via a small population per generation with top-mu selection, an archive used for occasional DE-style injections (de_prob=0.12, archive_capacity ~max(4*dim,30)), rare heavy-tailed Levy jumps (levy_prob=0.06), and reflective/clamping bounds handling to keep candidates feasible. Periodic coordinate-local refinement (every local_period=22 generations, up to local_steps=6) provides targeted hill-climbing around the best, and aggressive stagnation checks trigger restarts and archive-guided nudges to escape traps.", "code": "import numpy as np\n\nclass LADS:\n    \"\"\"\n    Layered Adaptive Directional Search (LADS)\n\n    One-line: ADAM-style directional adaptation + per-coordinate RMS scaling,\n    multiplicative sigma adaptation, Levy jumps and DE-style archive injections,\n    plus occasional coordinate-local refinement.\n\n    Main algorithm parameters (tunable):\n      - pop_base: base population size used each generation (default auto, ~4+)\n      - lr: learning rate for mean updates (plays role similar to c_mu)\n      - beta1, beta2: EMA coefficients for first and second moments (ADAM-like)\n      - sigma0: initial global scale (fraction of search-range)\n      - inc, dec: multiplicative factors to increase/decrease sigma on success/failure\n      - de_prob: probability to perform a differential-style injection from archive\n      - levy_prob: probability to perform a heavy-tailed jump (Cauchy) to escape basins\n      - local_period: generations between coordinate local searches\n      - local_steps: maximum coordinate steps per local search cycle\n      - archive_capacity: number of archived points stored for DE injections\n      - seed: RNG seed for reproducibility\n\n    Differences vs MCAPS:\n      - Uses ADAM-like first/second moment adaptation (m1, m2) instead of full covariance.\n      - Sigma adaptation is multiplicative (inc/dec) rather than success-rate exponential rule.\n      - Per-coordinate scaling uses RMS accumulators inspired by RMSprop/ADAM.\n      - Occasional Levy (Cauchy) jumps and tunable DE injection factor randomized.\n      - Simpler low-memory approach (O(dim) rather than O(dim^2)), suitable for higher dims.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 lr=0.15,         # learning rate for mean-step (scaled by sigma)\n                 beta1=0.85,      # momentum (first moment)\n                 beta2=0.70,      # RMS smoothing (second moment)\n                 sigma0=0.25,     # initial sigma fraction of search-range\n                 inc=1.10,        # sigma increase factor on success\n                 dec=0.95,        # sigma decrease factor on non-success\n                 de_prob=0.12,    # archive DE-style injection probability\n                 levy_prob=0.06,  # heavy-tailed jump probability\n                 local_period=22, # how often to perform local coordinate refinement\n                 local_steps=6,   # max coordinate tries per local pass\n                 archive_capacity=None,\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.lr = float(lr)\n        self.beta1 = float(beta1)\n        self.beta2 = float(beta2)\n        self.sigma0 = float(sigma0)\n        self.inc = float(inc)\n        self.dec = float(dec)\n        self.de_prob = float(de_prob)\n        self.levy_prob = float(levy_prob)\n        self.local_period = int(local_period)\n        self.local_steps = int(local_steps)\n        self.archive_capacity = archive_capacity\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds handling (BBOB: typically [-5,5])\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        range_mean = float(np.mean(bounds_scale))\n        max_bound = float(np.max(bounds_scale))\n\n        # population base (non-antithetic by design)\n        if self.pop_base is None:\n            lam0 = max(4, int(4 + np.log(max(2, self.dim))))\n        else:\n            lam0 = int(self.pop_base)\n        lam0 = min(lam0, max(1, self.budget))\n\n        evals = 0\n\n        # initial sampling: small uniform batch to seed center and archive\n        init_batch = min(max(2, lam0), self.budget)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.empty(init_batch, dtype=float)\n        for i in range(init_batch):\n            f0[i] = float(func(X0[i]))\n            evals += 1\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize center m as weighted average of top half (simple)\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.ones(mu0) / mu0\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # ADAM-like moment accumulators (in normalized sample coordinates)\n        m1 = np.zeros(self.dim, dtype=float)   # first moment\n        m2 = np.zeros(self.dim, dtype=float)   # second moment (RMS)\n        eps = 1e-8\n\n        # per-coordinate RMS scale (starts neutral)\n        s_diag = np.ones(self.dim, dtype=float)\n\n        # initial sigma (global step)\n        sigma = max(1e-12, self.sigma0 * range_mean)\n\n        # simple archive for DE injections\n        archive_X = [x.copy() for x in X0]\n        archive_f = [float(fi) for fi in f0]\n        if self.archive_capacity is None:\n            archive_capacity = max(4 * self.dim, 30)\n        else:\n            archive_capacity = int(self.archive_capacity)\n\n        gen = 0\n        stagn = 0\n\n        # helpers\n        def reflect_then_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # main loop: generate populations until budget exhausted\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(lam0, remaining)\n            lam = max(1, int(lam))\n\n            # choose mu (top-fraction selection)\n            mu = max(1, lam // 3)\n            weights = np.ones(mu) / mu\n\n            # sample candidate perturbations: normal but scaled by per-dim RMS\n            Z = rng.normal(size=(lam, self.dim))\n            # scale by per-dim s_diag (RMS) and by a minor isotropic jitter\n            Y = Z * (s_diag.reshape(1, -1) + 0.05)  # shape (lam, dim)\n\n            # directional bias from first moment (ADAM-like) but normalized\n            m1_norm = np.linalg.norm(m1) + 1e-20\n            if m1_norm > 0:\n                dir_unit = m1 / m1_norm\n                # direction strength proportional to sqrt of m2 (to favor stable directions)\n                dir_strength = 0.6 * (np.sqrt(np.mean(m2)) / (1.0 + np.sqrt(np.mean(m2))))\n                Y += rng.normal(scale=dir_strength, size=(lam, 1)) * dir_unit.reshape(1, -1)\n\n            # propose candidates\n            Xcand = m.reshape(1, -1) + sigma * Y\n\n            # occasional DE-style injection from archive\n            if (len(archive_X) >= 3) and (rng.rand() < self.de_prob):\n                idxs = rng.choice(len(archive_X), size=3, replace=False)\n                base = archive_X[idxs[0]].copy()\n                x1 = archive_X[idxs[1]]\n                x2 = archive_X[idxs[2]]\n                # random factor F in [0.4, 1.0]\n                F = 0.4 + 0.6 * rng.rand()\n                trial = base + F * (x1 - x2)\n                # small local perturbation\n                trial += rng.normal(scale=0.2 * sigma, size=self.dim)\n                trial = reflect_then_clamp(trial)\n                rep = rng.randint(0, Xcand.shape[0])\n                Xcand[rep] = trial\n\n            # occasional Levy/Cauchy heavy-tail jump to escape\n            if rng.rand() < self.levy_prob:\n                jump = np.tan((rng.rand(self.dim) - 0.5) * np.pi) * (0.5 * sigma)\n                x_jump = m + jump\n                x_jump = reflect_then_clamp(x_jump)\n                # replace a random candidate\n                rep = rng.randint(0, Xcand.shape[0])\n                Xcand[rep] = x_jump\n\n            # clamp candidates into bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates sequentially (stop if budget exhausted)\n            fc = np.full(Xcand.shape[0], np.inf, dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                xi = Xcand[i]\n                fv = float(func(xi))\n                fc[i] = fv\n                evals += 1\n                # immediate update of global best\n                if fv < f_best:\n                    f_best = fv\n                    x_best = xi.copy()\n                    stagn = 0\n\n            # drop any un-evaluated candidates if budget cut mid-batch\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                if Xcand.shape[0] == 0:\n                    break\n\n            # add to archive, maintain capacity\n            for xi, fi in zip(Xcand, fc):\n                archive_X.append(xi.copy())\n                archive_f.append(float(fi))\n            if len(archive_X) > archive_capacity:\n                # remove worst oldest entries to keep capacity (mix age+quality)\n                # simple trim: remove oldest excess\n                excess = len(archive_X) - archive_capacity\n                archive_X = archive_X[excess:]\n                archive_f = archive_f[excess:]\n\n            # determine generation best\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                # Already handled immediate update, but mark improved flag\n                improved = True\n                stagn = 0\n            else:\n                # if any candidate improved relative to previous center?\n                # consider improvement if gen_best better than f at center approximated by evaluating m (we may not have it)\n                # use simple criterion: improvement if gen_best strictly better than historical best seen in archive median\n                improved = gen_best_f < np.median(archive_f) if len(archive_f) > 0 else False\n                if not improved:\n                    stagn += 1\n\n            # selection: top-mu candidates for \"gradient\" surrogate\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            # normalized deltas\n            if X_mu.shape[0] > 0:\n                deltas = (X_mu - m) / (sigma + 1e-20)  # shape (mu, dim)\n                delta_mean = deltas.mean(axis=0)\n            else:\n                deltas = np.zeros((0, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # ADAM-like updates using delta_mean as surrogate \"gradient\"\n            m1 = self.beta1 * m1 + (1.0 - self.beta1) * delta_mean\n            m2 = self.beta2 * m2 + (1.0 - self.beta2) * (delta_mean ** 2)\n            # bias correction (optional but helps early iter)\n            t = gen\n            m1_hat = m1 / (1.0 - self.beta1 ** t)\n            m2_hat = m2 / (1.0 - self.beta2 ** t)\n            # compute adjusted direction\n            adjusted = m1_hat / (np.sqrt(m2_hat) + eps)\n\n            # update center m with learning rate scaled by sigma (so step sizes are relative)\n            step_vec = self.lr * adjusted\n            m = m + step_vec * sigma\n            m = reflect_then_clamp(m)\n\n            # update per-coordinate RMS scale s_diag (RMSprop-like)\n            s_diag = np.sqrt(0.9 * (s_diag ** 2) + 0.1 * (delta_mean ** 2) + 1e-12)\n            # clip to reasonable bounds to avoid degeneracy\n            s_diag = np.clip(s_diag, 0.05, 6.0)\n\n            # multiplicative sigma adaptation\n            if improved:\n                sigma *= self.inc\n            else:\n                sigma *= self.dec\n            # ensure sigma within safe bounds\n            sigma = np.clip(sigma, 1e-12, 1.5 * max_bound)\n\n            # periodic coordinate-local refinement (simple coordinate descent)\n            if (gen % self.local_period == 0) and (evals < self.budget):\n                # small local search around current best\n                local_step = max(1e-12, 0.12 * range_mean * (sigma / (self.sigma0 * range_mean + 1e-20)))\n                local_improved = False\n                x_work = x_best.copy()\n                f_work = f_best\n\n                # attempt limited coordinate moves\n                for ls in range(self.local_steps):\n                    moved = False\n                    for d in range(self.dim):\n                        if evals >= self.budget:\n                            break\n                        # try plus\n                        x_try = x_work.copy()\n                        x_try[d] = np.minimum(x_try[d] + local_step, ub[d])\n                        x_try = reflect_then_clamp(x_try)\n                        fv = float(func(x_try))\n                        evals += 1\n                        if fv < f_work:\n                            x_work = x_try\n                            f_work = fv\n                            moved = True\n                            local_improved = True\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = x_try.copy()\n                                stagn = 0\n                            # opportunistic extra probe\n                            if evals < self.budget:\n                                x_try2 = x_work.copy()\n                                x_try2[d] = np.minimum(x_try2[d] + local_step, ub[d])\n                                x_try2 = reflect_then_clamp(x_try2)\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < f_work:\n                                    x_work = x_try2\n                                    f_work = fv2\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = x_try2.copy()\n                                        stagn = 0\n                        else:\n                            # try minus\n                            if evals >= self.budget:\n                                break\n                            x_try = x_work.copy()\n                            x_try[d] = np.maximum(x_try[d] - local_step, lb[d])\n                            x_try = reflect_then_clamp(x_try)\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                x_work = x_try\n                                f_work = fv\n                                moved = True\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_try.copy()\n                                    stagn = 0\n                    if not moved:\n                        local_step *= 0.6  # shrink local step if no progress\n                    if local_step < 1e-9:\n                        break\n\n                if local_improved:\n                    # inject into archive and gently bias center\n                    archive_X.append(x_work.copy())\n                    archive_f.append(float(f_work))\n                    if len(archive_X) > archive_capacity:\n                        excess = len(archive_X) - archive_capacity\n                        archive_X = archive_X[excess:]\n                        archive_f = archive_f[excess:]\n                    # bias center toward local improvement but conservatively\n                    m = 0.92 * m + 0.08 * x_work\n                    stagn = 0\n                else:\n                    # mild random nudges if prolonged stagnation\n                    if stagn > (3 * self.local_period):\n                        nudge = rng.normal(scale=0.03 * bounds_scale)\n                        m = reflect_then_clamp(m + nudge)\n                        stagn = 0\n\n            # restart if sigma collapsed or extreme stagnation\n            if sigma < 1e-11 * max_bound or stagn > max(50, 5 * self.local_period):\n                m = x_best + rng.normal(scale=0.06 * bounds_scale)\n                m = reflect_then_clamp(m)\n                sigma = max(sigma, 0.12 * range_mean)\n                m1 = np.zeros_like(m1)\n                m2 = np.zeros_like(m2)\n                s_diag = np.ones_like(s_diag)\n                stagn = 0\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm LADS scored 0.228 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "25ef7321-3c58-4469-96c5-fb81ab07c8f5", "operator": null, "metadata": {"aucs": [0.10719897610453843, 0.15978212646195122, 0.297024577847386, 0.3305566874090492, 0.22749366789533665, 0.2869216013807926, 0.2139562566208979, 0.26908555851156823, 0.23742214027868647, 0.15419473963244423]}, "task_prompt": ""}
{"id": "0558fbb3-5375-4f47-91ef-5431ae462b40", "fitness": 0.23112122793532536, "name": "SRE_Bandit", "description": "The algorithm adaptively samples in low-dimensional subspaces (PCA when available, otherwise random orthonormal bases) chosen by a lightweight softmax bandit over subspace sizes, using antithetic Gaussian draws with a small momentum-projected bias and per-basis scaling to shape directions. It maintains a trust-region radius (init_trust_frac=0.18, min_trust small) and per-dimension adaptive scales (EMA of squared elite deltas) while updating a conservative center via weighted elite means and keeping an archive (default capacity ≈ 4*dim) that can inject DE-style differential trials (de_inject_prob=0.15). Performance feedback updates the bandit (reward = count of center-improving candidates) and trust (increase/decrease factors 1.25/0.7 against success_target=0.2), with opportunistic directional extrapolation on batch improvements and mild restarts/jitter when stagnation or tiny trust occurs. Overall the design balances global exploration (random subspaces, bandit diversity, archive) and local refinement (trust-region, per-dimension scaling, momentum, extrapolation) with lightweight, robust heuristics suitable for bounded continuous optimization.", "code": "import numpy as np\n\nclass SRE_Bandit:\n    \"\"\"\n    Subspace Rotational Evolution with Bandit Subspace Selection (SRE-Bandit)\n\n    Main idea (one-liner):\n    Adaptively sample in small random/PCA-rotated subspaces whose dimension is chosen\n    by a lightweight multi-armed bandit; combine trust-region scaling, per-coordinate\n    scaling statistics, archive-based differential injections, and opportunistic\n    directional extrapolation to balance global exploration and local refinement.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 seed=None,\n                 pop_base=None,\n                 max_subspace=4,\n                 bandit_tau=0.2,\n                 success_target=0.2,\n                 trust_increase=1.25,\n                 trust_decrease=0.7,\n                 init_trust_frac=0.18,\n                 min_trust_frac=1e-4,\n                 de_inject_prob=0.15,\n                 archive_capacity=None,\n                 mem_moves=30):\n        # required\n        self.budget = int(budget)\n        self.dim = int(dim)\n\n        # randomness\n        self.seed = seed\n\n        # sampling / population\n        self.pop_base = pop_base\n        self.max_subspace = max(1, min(max_subspace, self.dim))\n        self.bandit_tau = float(bandit_tau)  # exploration temperature for subspace MAB\n        self.success_target = float(success_target)\n        self.trust_increase = float(trust_increase)\n        self.trust_decrease = float(trust_decrease)\n        self.init_trust_frac = float(init_trust_frac)\n        self.min_trust_frac = float(min_trust_frac)\n        self.de_inject_prob = float(de_inject_prob)\n        self.mem_moves = int(mem_moves)\n\n        if archive_capacity is None:\n            self.archive_capacity = max(20, 4 * self.dim)\n        else:\n            self.archive_capacity = int(archive_capacity)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds: try to use func.bounds if provided, else assume [-5,5]\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n            if lb.size == 1:\n                lb = np.full(self.dim, lb.item(), dtype=float)\n            if ub.size == 1:\n                ub = np.full(self.dim, ub.item(), dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = ub - lb\n        range_mean = float(np.mean(bounds_scale))\n        max_bound = float(np.max(bounds_scale))\n\n        # population per batch\n        if self.pop_base is None:\n            lam0 = max(6, 2 * min(12, self.dim + 2))\n        else:\n            lam0 = int(self.pop_base)\n        lam0 = min(lam0, max(2, self.budget))\n        if lam0 % 2 == 1 and lam0 > 2:\n            lam0 -= 1\n\n        evals = 0\n\n        # initialize center and best by a small Latin-hypercube-like initial set\n        n_init = min(max(2, lam0), self.budget)\n        X0 = rng.uniform(lb, ub, size=(n_init, self.dim))\n        f0 = np.full(n_init, np.inf, dtype=float)\n        for i in range(n_init):\n            f0[i] = float(func(X0[i]))\n            evals += 1\n\n        best_idx = int(np.argmin(f0))\n        x_best = X0[best_idx].copy()\n        f_best = float(f0[best_idx])\n\n        # initial center (use weighted elite mean)\n        mu0 = max(1, n_init // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 /= np.sum(w0)\n        x_center = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n        x_center = np.minimum(np.maximum(x_center, lb), ub)\n\n        # trust-region radius (global scale)\n        trust = max(1e-12, self.init_trust_frac * range_mean)\n        min_trust = max(1e-12, self.min_trust_frac * range_mean)\n        max_trust = 0.5 * max_bound\n\n        # per-dimension scale statistic (like AdaGrad), momentum & small memory of moves\n        scales = np.ones(self.dim, dtype=float)\n        momentum = np.zeros(self.dim, dtype=float)\n        recent_moves = []  # list of deltas (normalized by range_mean)\n        move_mem = self.mem_moves\n\n        # archive for DE-style candidates\n        archive_X = [x.copy() for x in X0]\n        archive_f = [float(fi) for fi in f0]\n\n        # bandit statistics for subspace sizes 1..K\n        K = min(self.max_subspace, self.dim)\n        bandit_counts = np.ones(K, dtype=float)  # pseudo-counts\n        bandit_rewards = np.ones(K, dtype=float) * 1e-6  # cumulative successes\n\n        # stagnation tracking\n        stagn = 0\n        stagn_limit = max(10, 5 * K)\n\n        # helper: reflect then clamp like in original, but with symmetrical reflection\n        def reflect_then_clamp(x):\n            x_ref = x.copy()\n            low = x_ref < lb\n            if np.any(low):\n                x_ref[low] = lb[low] + (lb[low] - x_ref[low])\n            high = x_ref > ub\n            if np.any(high):\n                x_ref[high] = ub[high] - (x_ref[high] - ub[high])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # helper: build an orthonormal basis for a k-dim subspace\n        def build_subspace_basis(k):\n            # try to use PCA on recent_moves to extract dominant directions\n            if len(recent_moves) >= max(2, k):\n                M = np.vstack(recent_moves)  # rows are recent moves\n                # center\n                M -= M.mean(axis=0)\n                try:\n                    u, svals, vt = np.linalg.svd(M, full_matrices=False)\n                    basis = vt[:k]  # top-k right singular vectors (shape k x dim)\n                    # random rotational mixing: slightly rotate basis with random Givens-like perturbations\n                    if rng.rand() < 0.3:\n                        P = np.eye(self.dim)\n                        # apply small random orthogonal mixing on top-k portion\n                        R = np.eye(k) + 0.05 * rng.randn(k, k)\n                        # orthonormalize R via QR\n                        Q, _ = np.linalg.qr(R)\n                        basis = (Q @ basis).reshape(k, self.dim)\n                except np.linalg.LinAlgError:\n                    basis = None\n            else:\n                basis = None\n\n            if basis is None:\n                # random orthonormal basis: sample k random vectors and orthonormalize\n                R = rng.randn(k, self.dim)\n                # QR on transposed to obtain orthonormal rows\n                try:\n                    q, _ = np.linalg.qr(R.T)\n                    basis = q.T[:k]\n                except np.linalg.LinAlgError:\n                    # fallback: normalized random vectors\n                    basis = R / (np.linalg.norm(R, axis=1, keepdims=True) + 1e-20)\n            return basis  # shape (k, dim)\n\n        # main loop: generate batches until budget exhausted\n        gen = 0\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(lam0, remaining)\n            # ensure even for antithetic pairs if possible\n            if remaining >= 2:\n                lam = max(2, lam if lam % 2 == 0 else lam - 1)\n            else:\n                lam = 1\n\n            # pick subspace dimension k via softmax of bandit expected reward per count\n            avg_rewards = bandit_rewards / bandit_counts\n            # add small exploration noise via temperature\n            logits = avg_rewards / max(self.bandit_tau, 1e-12)\n            probs = np.exp(logits - np.max(logits))\n            probs /= np.sum(probs)\n            # sample an index (1..K) according to probs\n            k_idx = rng.choice(len(probs), p=probs)\n            k = k_idx + 1  # actual subspace dimension\n\n            # build basis B (k x dim)\n            B = build_subspace_basis(k)  # rows are basis vectors\n            # ensure orthonormality: rows should be orthonormal\n            # (build_subspace_basis tries to ensure that)\n\n            # sample in k-dim subspace: antithetic pairing\n            half = lam // 2\n            Zpos = rng.normal(size=(half, k))\n            Z = np.vstack([Zpos, -Zpos])\n            if lam % 2 == 1:\n                Z = np.vstack([Z, rng.normal(size=(1, k))])\n\n            # scale subspace coordinates by per-dimension scales projected to subspace\n            # compute per-basis scaling as sqrt of average squared coefficients of basis rows weighted by scales\n            per_basis_scale = np.sqrt((B ** 2) @ (scales ** 2) + 1e-20)  # shape (k,)\n            # randomized directional bias using momentum projected into subspace\n            momentum_proj = B @ momentum  # shape (k,)\n            mlen = np.linalg.norm(momentum_proj) + 1e-20\n            if mlen > 0:\n                bias_strength = 0.6 * (mlen / (1.0 + mlen))\n                bias_samples = rng.normal(loc=0.0, scale=bias_strength, size=(Z.shape[0], 1)) * \\\n                               (momentum_proj.reshape(1, -1) / mlen)\n                Z = Z + bias_samples  # add a small projection-bias in subspace coords\n\n            # map to full dimension: directions = (Z * per_basis_scale) @ B  (Z shape n x k; B k x dim)\n            Z_scaled = Z * per_basis_scale.reshape(1, -1)\n            directions = Z_scaled @ B  # shape (lam, dim)\n\n            # normalize directions to unit length per-sample to make trust scale meaningful\n            norms = np.linalg.norm(directions, axis=1, keepdims=True) + 1e-20\n            directions = directions / norms\n\n            # candidate generation\n            Xcand = x_center.reshape(1, -1) + (trust * directions)\n            # archive DE injection: replace a random candidate with archive-diff trial\n            if (len(archive_X) >= 3) and (rng.rand() < self.de_inject_prob):\n                idxs = rng.choice(len(archive_X), size=3, replace=False)\n                base = archive_X[idxs[0]]\n                x1 = archive_X[idxs[1]]\n                x2 = archive_X[idxs[2]]\n                F = 0.7 + 0.3 * rng.rand()\n                trial = base + F * (x1 - x2)\n                trial += rng.normal(scale=0.2 * trust, size=self.dim)  # local jitter\n                trial = reflect_then_clamp(trial)\n                rep = rng.randint(Xcand.shape[0])\n                Xcand[rep] = trial\n\n            # clamp candidates (safety)\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates sequentially and update best immediately\n            fc = np.full(Xcand.shape[0], np.inf, dtype=float)\n            batch_improvements = 0\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                xi = Xcand[i]\n                fv = float(func(xi))\n                fc[i] = fv\n                evals += 1\n                # immediate best update\n                if fv < f_best:\n                    f_best = fv\n                    x_best = xi.copy()\n                    stagn = 0\n                    batch_improvements += 1\n                # also count as improvement relative to center (for trust adaptation)\n                # we'll check later\n            # if budget exhausted mid-batch, truncate arrays\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                if Xcand.shape[0] == 0:\n                    break\n\n            # archive maintenance\n            for xi, fi in zip(Xcand, fc):\n                archive_X.append(xi.copy())\n                archive_f.append(float(fi))\n            if len(archive_X) > self.archive_capacity:\n                excess = len(archive_X) - self.archive_capacity\n                # discard worst oldest (simple strategy)\n                # keep the best archive_capacity by fitness (stable-ish)\n                order = np.argsort(archive_f)\n                keep_idx = order[:self.archive_capacity]\n                archive_X = [archive_X[ii] for ii in keep_idx]\n                archive_f = [archive_f[ii] for ii in keep_idx]\n\n            # selection: compute improvements relative to center evaluation (we may not have it)\n            # Evaluate center if not evaluated recently: approximate by best candidate if center hasn't been evaluated\n            # For trust update, compare number of candidates that beat current center-f proxy.\n            # We'll keep a stored center_f; if not present, set center_f = f_best (conservative)\n            if not hasattr(self, \"_center_f\"):\n                center_f = f_best\n            else:\n                center_f = float(self._center_f)\n\n            # compute how many candidates improved on center_f\n            center_improvements = int(np.sum(fc < center_f))\n            success_frac = center_improvements / max(1, Xcand.shape[0])\n\n            # update center: move toward the top-mu weighted mean of candidates\n            mu = max(1, Xcand.shape[0] // 2)\n            order = np.argsort(fc)\n            elites = Xcand[order[:mu]]\n            w = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            w = np.maximum(w, 0.0)\n            if np.sum(w) <= 0:\n                w = np.ones_like(w)\n            w = w / np.sum(w)\n            new_center = (w.reshape(-1, 1) * elites[:w.shape[0]]).sum(axis=0)\n            # move center conservatively (mix)\n            mix_rate = 0.2\n            x_center_old = x_center.copy()\n            x_center = np.minimum(np.maximum((1.0 - mix_rate) * x_center + mix_rate * new_center, lb), ub)\n            # store center f as best candidate's fitness if center moved or keep previous\n            self._center_f = float(min(center_f, np.min(fc)))\n\n            # update per-dimension scales using EMA of squared deltas from elites (normalized)\n            deltas = (elites - x_center_old) / (range_mean + 1e-20)  # normalized by problem scale\n            if deltas.shape[0] > 0:\n                stat = np.mean(deltas ** 2, axis=0)\n            else:\n                stat = 1e-6 * np.ones(self.dim)\n            scales = 0.85 * scales + 0.15 * np.sqrt(stat + 1e-20)\n            scales = np.clip(scales, 0.1, 10.0)\n\n            # update momentum as EMA of center displacement (normalized)\n            disp = (x_center - x_center_old) / (range_mean + 1e-20)\n            momentum = 0.8 * momentum + 0.2 * disp\n\n            # update recent_moves memory with successful directions (from center or from best)\n            # record normalized direction from old center to each improving candidate\n            improving_idxs = np.where(fc < center_f)[0]\n            for idx in improving_idxs:\n                d = (Xcand[idx] - x_center_old) / (range_mean + 1e-20)\n                recent_moves.append(d)\n            # also include the best candidate delta\n            best_local_idx = int(np.argmin(fc))\n            best_delta = (Xcand[best_local_idx] - x_center_old) / (range_mean + 1e-20)\n            recent_moves.append(best_delta)\n            # trim memory\n            if len(recent_moves) > move_mem:\n                recent_moves = recent_moves[-move_mem:]\n\n            # trust-region adaptation using success fraction vs target\n            if success_frac > self.success_target:\n                trust = min(max_trust, trust * self.trust_increase)\n            else:\n                trust = max(min_trust, trust * self.trust_decrease)\n\n            # bandit update: reward the chosen arm k by count of improvements (clipped)\n            reward = float(center_improvements)\n            bandit_rewards[k_idx] += reward\n            bandit_counts[k_idx] += 1.0\n\n            # stagnation: if no global improvement in a while, increase stagn counter\n            if batch_improvements == 0:\n                stagn += 1\n            else:\n                stagn = 0\n\n            # opportunistic directional extrapolation: if the best candidate in batch improved global best,\n            # attempt a few extrapolation steps along that direction (aggressive local search)\n            if fc.size > 0:\n                batch_best_idx = int(np.argmin(fc))\n                batch_best_x = Xcand[batch_best_idx].copy()\n                batch_best_f = float(fc[batch_best_idx])\n                if batch_best_f < f_best:  # actually this case already handled earlier, but keep robust\n                    # perform up to 3 extrapolations with increasing step multipliers, stopping on no improvement\n                    dir_vec = batch_best_x - x_center_old\n                    dir_norm = np.linalg.norm(dir_vec) + 1e-20\n                    dir_unit = dir_vec / dir_norm\n                    multipliers = [1.2, 1.6, 2.4]\n                    for alpha in multipliers:\n                        if evals >= self.budget:\n                            break\n                        probe = batch_best_x + alpha * trust * dir_unit\n                        probe = reflect_then_clamp(probe)\n                        fv = float(func(probe))\n                        evals += 1\n                        # insert into archive\n                        archive_X.append(probe.copy()); archive_f.append(float(fv))\n                        if fv < f_best:\n                            f_best = fv\n                            x_best = probe.copy()\n                            stagn = 0\n                        if fv < batch_best_f:\n                            # continue extrapolating from this better point\n                            batch_best_x = probe.copy()\n                            batch_best_f = fv\n                        else:\n                            # stop extrapolation if didn't improve\n                            break\n                        # maintain archive cap\n                        if len(archive_X) > self.archive_capacity:\n                            # keep best entries\n                            order = np.argsort(archive_f)\n                            keep_idx = order[:self.archive_capacity]\n                            archive_X = [archive_X[ii] for ii in keep_idx]\n                            archive_f = [archive_f[ii] for ii in keep_idx]\n\n            # periodic mild restart if stagnation persists\n            if (stagn > stagn_limit) or (trust <= min_trust * 1.01):\n                # jitter-around best\n                nudge = max(1, lam0 // 3)\n                for _ in range(nudge):\n                    if evals >= self.budget:\n                        break\n                    jitter = rng.randn(self.dim) * (0.08 * bounds_scale)\n                    newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                    fv = float(func(newx))\n                    evals += 1\n                    archive_X.append(newx.copy()); archive_f.append(float(fv))\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = newx.copy()\n                        stagn = 0\n                # if still stagnating, randomize center moderately\n                x_center = np.minimum(np.maximum(x_best + rng.randn(self.dim) * (0.05 * bounds_scale), lb), ub)\n                self._center_f = float(f_best)\n                trust = max(trust, 0.12 * range_mean)\n                momentum = np.zeros_like(momentum)\n                recent_moves = []\n\n            # final safety clamp on trust\n            trust = np.clip(trust, min_trust, max_trust)\n\n        # finalize outputs\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SRE_Bandit scored 0.231 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "25ef7321-3c58-4469-96c5-fb81ab07c8f5", "operator": null, "metadata": {"aucs": [0.11880642786791518, 0.22533428006841738, 0.2984977518191779, 0.2945811691938217, 0.22385481467841772, 0.28873050013920054, 0.2247159709003006, 0.26452491541332257, 0.21939609523878012, 0.1527703540339005]}, "task_prompt": ""}
{"id": "6f9693a1-e97e-40a3-8f90-9e441b58cf70", "fitness": 0.40769201495406576, "name": "ACORN", "description": "ACORN combines adaptive covariance exploration with momentum and per-coordinate scaling: a modest cov_lr and stronger rank-one weight bias the covariance update while a faster-decaying momentum (mom_beta) and an EMA on per-coordinate scales (s_diag_beta) steer directional search and anisotropic steps. Sampling and diversity are enforced by antithetic draws from a robust SPD-factorized C, occasional opposition-based reflections, and frequent DE-style injections from a bounded archive (strong differential factor and reflect_then_clamp to respect [-5,5]). Local exploitation is handled by periodic or stagnation-triggered shuffled coordinate pattern search with step shrinking, opportunistic directional extensions and jitter nudges near the best; successful local finds are injected back into the archive and gently pull the mean and covariance. Control mechanisms include smoothed success-ratio sigma adaptation, conservative mean mixing to retain exploration, SPD safety fixes, archive trimming for diversity, and opportunistic restarts when sigma collapses or stagnation persists.", "code": "import numpy as np\n\nclass ACORN:\n    \"\"\"\n    ACORN: Adaptive COVariance + Opposing-RefleNction neighborhood search\n\n    Main ideas / main parameters (differences vs MCAPS):\n      - cov_lr (covariance learning rate): 0.08  (smaller, smoother covariance updates)\n      - rank1 (rank-one momentum weight):     0.12  (stronger rank-one bias than MCAPS)\n      - mom_beta (momentum decay):            0.6   (faster reacting momentum)\n      - s_diag_beta (per-coordinate EMA):     0.8   (slower changes to coordinate scaling)\n      - sigma_adapt_rate:                     0.12  (gentler step-size adaptation)\n      - success_target:                       0.25  (slightly higher success ratio)\n      - de_inject_prob:                       0.25  (more frequent differential-style diversity)\n      - local_period:                         15    (more frequent local refinement)\n      - local_stagn_gen:                      20\n      - initial_step_frac:                    0.12  (smaller local step fraction)\n      - step_shrink:                          0.6\n      - min_step_frac:                        1e-5\n      - pop_base default:                     ~max(6, 4 + dim//2) (larger base population)\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 cov_lr=0.08, rank1=0.12,\n                 mom_beta=0.6, s_diag_beta=0.8,\n                 sigma_adapt_rate=0.12, success_target=0.25,\n                 local_period=15, local_stagn_gen=20,\n                 initial_step_frac=0.12, step_shrink=0.6, min_step_frac=1e-5,\n                 de_inject_prob=0.25,\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.cov_lr = float(cov_lr)\n        self.rank1 = float(rank1)\n        self.mom_beta = float(mom_beta)\n        self.s_diag_beta = float(s_diag_beta)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.success_target = float(success_target)\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.initial_step_frac = float(initial_step_frac)\n        self.step_shrink = float(step_shrink)\n        self.min_step_frac = float(min_step_frac)\n        self.de_inject_prob = float(de_inject_prob)\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds (Many BBOB uses [-5,5], but read from func if present)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        range_mean = float(np.mean(bounds_scale))\n        max_bound = float(np.max(bounds_scale))\n\n        # population base (ensure even for antithetic)\n        if self.pop_base is None:\n            lam0 = max(6, 4 + self.dim // 2)\n        else:\n            lam0 = int(self.pop_base)\n        lam0 = min(lam0, max(2, self.budget))\n        if lam0 % 2 == 1 and lam0 > 2:\n            lam0 -= 1\n\n        evals = 0\n\n        # initial uniform samples (seed archive & mean)\n        init_batch = min(max(4, lam0), self.budget)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.empty(init_batch, dtype=float)\n        for i in range(init_batch):\n            f0[i] = float(func(X0[i]))\n            evals += 1\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize mean from top-half\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 /= np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance: modestly wide but conservative\n        C = np.diag(((bounds_scale / 5.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-10, 0.12 * range_mean)  # different initial sigma than MCAPS\n\n        # momentum and per-coordinate scaling\n        v = np.zeros(self.dim, dtype=float)\n        s_diag = np.ones(self.dim, dtype=float)\n        p_succ = float(self.success_target)\n\n        # archive for DE-style injections and opposition\n        archive_X = [x.copy() for x in X0]\n        archive_f = [float(fi) for fi in f0]\n        archive_capacity = max(6 * self.dim, 30)\n\n        gen = 0\n        stagn_gens = 0\n\n        def chol_spd(mat):\n            # robust SPD factorization with tiny diag stabilizer\n            eps = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        def reflect_then_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(lam0, remaining)\n            if remaining >= 2:\n                lam = max(2, lam if lam % 2 == 0 else lam - 1)\n            else:\n                lam = 1\n\n            mu = max(1, lam // 2)\n            # recompute ranking weights\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights /= np.sum(weights)\n            W = weights.reshape(-1, 1)\n\n            A = chol_spd(C)\n\n            # antithetic sampling\n            half = lam // 2\n            Zpos = rng.normal(size=(half, self.dim))\n            Z = np.vstack([Zpos, -Zpos])\n            if lam % 2 == 1:\n                Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n\n            Y = Z @ A.T\n\n            # momentum-driven directional bias (different scaling)\n            vlen = np.linalg.norm(v) + 1e-20\n            if vlen > 0:\n                v_unit = v / vlen\n                dir_strength = 0.6 * (vlen / (1.0 + 0.5 * vlen))\n                s_scalar = rng.normal(scale=dir_strength, size=(Y.shape[0], 1))\n                Y += s_scalar * v_unit.reshape(1, -1)\n\n            # per-coordinate scaling\n            Y = Y * s_diag.reshape(1, -1)\n\n            Xcand = m + sigma * Y\n\n            # Opposition-based extra candidate (create opposite for a fraction)\n            if lam >= 2:\n                if rng.rand() < 0.12:\n                    # compute opposite of a random candidate w.r.t. mean\n                    idx_opp = rng.randint(Xcand.shape[0])\n                    x = Xcand[idx_opp]\n                    opp = m - (x - m)\n                    opp = reflect_then_clamp(opp)\n                    # replace a random slot with opposite\n                    rep = rng.randint(Xcand.shape[0])\n                    Xcand[rep] = opp\n\n            # DE-style injection (more frequent)\n            if (len(archive_X) >= 3) and (rng.rand() < self.de_inject_prob) and (lam >= 1):\n                idxs = rng.choice(len(archive_X), size=3, replace=False)\n                base = archive_X[idxs[0]]\n                x1 = archive_X[idxs[1]]\n                x2 = archive_X[idxs[2]]\n                F = 0.9  # stronger differential factor\n                trial = base + F * (x1 - x2)\n                # apply smaller local gaussian than MCAPS\n                trial += rng.normal(scale=0.18 * sigma, size=self.dim)\n                trial = reflect_then_clamp(trial)\n                rep = rng.randint(Xcand.shape[0])\n                Xcand[rep] = trial\n\n            # clamp candidates\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate in randomized order to diversify immediate updates\n            order_eval = np.arange(Xcand.shape[0])\n            rng.shuffle(order_eval)\n            fc = np.full(Xcand.shape[0], np.inf, dtype=float)\n            for j in order_eval:\n                if evals >= self.budget:\n                    break\n                xj = Xcand[j]\n                fj = float(func(xj))\n                fc[j] = fj\n                evals += 1\n                if fj < f_best:\n                    f_best = fj\n                    x_best = xj.copy()\n                    stagn_gens = 0\n\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                if Xcand.shape[0] == 0:\n                    break\n\n            # archive maintenance\n            for xi, fi in zip(Xcand, fc):\n                archive_X.append(xi.copy())\n                archive_f.append(float(fi))\n            if len(archive_X) > archive_capacity:\n                excess = len(archive_X) - archive_capacity\n                # drop worst/excess earliest entries to keep diversity\n                # keep best ones preferentially\n                idx_sorted = np.argsort(archive_f)\n                keep = idx_sorted[:archive_capacity]\n                archive_X = [archive_X[i] for i in keep]\n                archive_f = [archive_f[i] for i in keep]\n\n            # generation best\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                improved = True\n                stagn_gens = 0\n            else:\n                # if nothing better than global best, increase stagn counter\n                stagn_gens += 1\n\n            # selection top-mu\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n\n            # normalized deltas\n            deltas = (X_mu - m) / (sigma + 1e-20)\n\n            if deltas.shape[0] > 0:\n                if deltas.shape[0] != weights.shape[0]:\n                    mu_eff = deltas.shape[0]\n                    w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if np.sum(w_eff) <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff /= np.sum(w_eff)\n                    Wd = w_eff.reshape(-1, 1)\n                    weighted_cov = (deltas * Wd).T @ deltas\n                    delta_mean = (Wd * deltas).sum(axis=0)\n                else:\n                    weighted_cov = (deltas * W).T @ deltas\n                    delta_mean = (W * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # momentum update (normalized coords)\n            v = self.mom_beta * v + (1.0 - self.mom_beta) * delta_mean\n            rank_one = np.outer(v, v)\n\n            # covariance update with slightly different mixing\n            c_cov = float(self.cov_lr)\n            c1 = float(self.rank1)\n            other = max(0.0, 1.0 - c_cov - c1)\n            C = other * C + c_cov * weighted_cov + c1 * rank_one\n            C = 0.5 * (C + C.T) + np.diag(np.maximum(np.diag(C), 1e-18))\n\n            # per-coordinate scaling EMA (use squared stat then sqrt)\n            if deltas.shape[0] > 0:\n                stat = np.mean(deltas ** 2, axis=0)\n            else:\n                stat = 1e-8 * np.ones(self.dim)\n            s_diag = (self.s_diag_beta * s_diag +\n                      (1.0 - self.s_diag_beta) * np.sqrt(stat + 1e-20))\n            s_diag = np.clip(s_diag, 0.15, 6.0)\n\n            # update mean gently biased toward elites and occasional best\n            if X_mu.shape[0] > 0:\n                take = min(weights.shape[0], X_mu.shape[0])\n                m_new = (weights[:take].reshape(-1, 1) * X_mu[:take]).sum(axis=0)\n                # mix with previous mean to retain exploration\n                m = 0.85 * m + 0.15 * m_new\n            else:\n                m = m.copy()\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # sigma adaptation via smoothed success ratio (gentler)\n            p_succ = 0.9 * p_succ + 0.1 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, 1e-12, 2.5 * max_bound)\n\n            # periodic or stagnation local pattern search (shuffled coordinate order)\n            if (gen % self.local_period == 0) or (stagn_gens >= self.local_stagn_gen):\n                remaining_loc = self.budget - evals\n                if remaining_loc <= 0:\n                    break\n\n                step = max(1e-12, self.initial_step_frac * range_mean)\n                min_step = max(1e-12, self.min_step_frac * range_mean)\n                if stagn_gens >= self.local_stagn_gen:\n                    step *= 1.8\n\n                local_improved = False\n                x_work = x_best.copy()\n                f_work = f_best\n\n                # shuffle coordinate order to avoid systematic bias\n                coord_order = list(range(self.dim))\n                rng.shuffle(coord_order)\n\n                while step >= min_step and (self.budget - evals) > 0:\n                    moved = False\n                    for d in coord_order:\n                        if evals >= self.budget:\n                            break\n                        # try positive direction\n                        x_try = x_work.copy()\n                        x_try[d] += step\n                        if x_try[d] > ub[d]:\n                            x_try[d] = ub[d]\n                        x_try = reflect_then_clamp(x_try)\n                        fv = float(func(x_try))\n                        evals += 1\n                        if fv < f_work:\n                            x_work = x_try\n                            f_work = fv\n                            moved = True\n                            local_improved = True\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = x_try.copy()\n                                stagn_gens = 0\n                            # opportunistic extension in same dir\n                            if evals < self.budget:\n                                x_try2 = x_work.copy()\n                                x_try2[d] = np.minimum(x_try2[d] + step, ub[d])\n                                x_try2 = reflect_then_clamp(x_try2)\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < f_work:\n                                    x_work = x_try2\n                                    f_work = fv2\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = x_try2.copy()\n                                        stagn_gens = 0\n                        else:\n                            # negative direction\n                            if evals >= self.budget:\n                                break\n                            x_try = x_work.copy()\n                            x_try[d] -= step\n                            if x_try[d] < lb[d]:\n                                x_try[d] = lb[d]\n                            x_try = reflect_then_clamp(x_try)\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                x_work = x_try\n                                f_work = fv\n                                moved = True\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_try.copy()\n                                    stagn_gens = 0\n                    if not moved:\n                        step *= self.step_shrink\n                    if evals >= self.budget:\n                        break\n\n                # inject local improvement\n                if local_improved:\n                    # replace worst archive entry or append\n                    if len(archive_f) > 0:\n                        worst_idx = int(np.argmax(archive_f))\n                        archive_X[worst_idx] = x_work.copy()\n                        archive_f[worst_idx] = float(f_work)\n                    else:\n                        archive_X.append(x_work.copy())\n                        archive_f.append(float(f_work))\n                    # move mean slightly toward local improvement\n                    m = 0.92 * m + 0.08 * x_work\n                    s = (x_work - m) / (sigma + 1e-20)\n                    C = 0.985 * C + 0.015 * np.outer(s, s)\n                    # SPD correction\n                    vals, vecs = np.linalg.eigh(C)\n                    vals = np.clip(vals, 1e-12, None)\n                    C = (vecs * vals) @ vecs.T\n                    stagn_gens = 0\n                else:\n                    # if stagnating, generate targeted nudges near best\n                    if stagn_gens >= self.local_stagn_gen:\n                        nudges = max(1, lam0 // 4)\n                        for k in range(nudges):\n                            if evals >= self.budget:\n                                break\n                            jitter = rng.randn(self.dim) * (0.04 * bounds_scale)\n                            newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                            fv = float(func(newx))\n                            evals += 1\n                            if len(archive_f) > 0:\n                                worst_idx = int(np.argmax(archive_f))\n                                archive_X[worst_idx] = newx.copy()\n                                archive_f[worst_idx] = float(fv)\n                            else:\n                                archive_X.append(newx.copy())\n                                archive_f.append(float(fv))\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = newx.copy()\n                                stagn_gens = 0\n\n            # opportunistic restart if sigma collapsed or persistent stagnation\n            if sigma <= 5e-10 * max_bound or stagn_gens > max(4, self.local_stagn_gen * 3):\n                m = x_best + rng.randn(self.dim) * (0.035 * bounds_scale)\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((bounds_scale / 7.0) ** 2).clip(min=1e-12))\n                sigma = max(sigma, 0.08 * range_mean)\n                v = np.zeros_like(v)\n                s_diag = np.ones_like(s_diag)\n                stagn_gens = 0\n\n            # SPD safety\n            try:\n                _ = np.linalg.cholesky(C + np.eye(self.dim) * 1e-16)\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                C = (vecs * vals) @ vecs.T\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ACORN scored 0.408 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "25ef7321-3c58-4469-96c5-fb81ab07c8f5", "operator": null, "metadata": {"aucs": [0.07546974755265967, 0.14794549647095379, 0.6819093990212128, 0.9683388866638473, 0.3363886261543263, 0.8463971557868144, 0.2462431257355966, 0.393474821102063, 0.2518993394423654, 0.12885355161081868]}, "task_prompt": ""}
{"id": "774c4bc0-7c5c-4a00-a4a7-553a11fc95bb", "fitness": 0.3751919718012475, "name": "AMCD_HJ", "description": "The algorithm combines antithetic mirrored sampling from a learned multivariate Gaussian (stratified quasi-uniform initialization, Cholesky/SPD fixes) with covariance adaptation (cov_lr≈0.18) and a small rank‑one momentum component (rank1≈0.06, mom_beta≈0.82) so the search distribution both tracks successful directions and retains inertia. Per‑coordinate EMA scaling (s_diag, s_diag_beta≈0.6) and a success‑rate driven sigma update (sigma_adapt_rate≈0.25, success_target≈0.2) adapt step lengths robustly across dimensions. Diversity and escape are maintained by an archive plus occasional DE‑style injections (de_inject_prob≈0.12) and mild global jitter or restart when sigma collapses, while periodic or stagnation‑triggered Hooke–Jeeves coordinate pattern searches (local_period, local_stagn_gen, initial_step_frac) provide deterministic local refinement. Practical robustness features include reflect‑then‑clamp boundary handling, bounded population sizing, archive trimming, and repeated SPD corrections to keep the covariance numerically well‑conditioned.", "code": "import numpy as np\n\nclass AMCD_HJ:\n    \"\"\"\n    AMCD-HJ: Antithetic Momentum-Covariance with DE injections and periodic Hooke-Jeeves local refinement.\n\n    One-line: Antithetic covariance-adaptive sampling + small momentum and per-coordinate scaling,\n    success-rate sigma adaptation, archive-driven differential injections, and periodic Hooke-Jeeves\n    coordinate refinement around the best, with reflect-then-clamp bounds and SPD fixes.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop_base=None,\n                 cov_lr=0.18,       # covariance learning rate (like rank-mu)\n                 rank1=0.06,        # rank-one momentum weight\n                 mom_beta=0.82,     # momentum EMA\n                 s_diag_beta=0.6,   # per-coordinate EMA\n                 sigma_adapt_rate=0.25,\n                 success_target=0.2,\n                 de_inject_prob=0.12,\n                 local_period=22,\n                 local_stagn_gen=28,\n                 initial_step_frac=0.18,\n                 step_shrink=0.5,\n                 min_step_frac=1e-4):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.pop_base = pop_base\n        # adaptation params\n        self.cov_lr = float(cov_lr)\n        self.rank1 = float(rank1)\n        self.mom_beta = float(mom_beta)\n        self.s_diag_beta = float(s_diag_beta)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.success_target = float(success_target)\n        self.de_inject_prob = float(de_inject_prob)\n        # local search\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.initial_step_frac = float(initial_step_frac)\n        self.step_shrink = float(step_shrink)\n        self.min_step_frac = float(min_step_frac)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        range_mean = float(np.mean(bounds_scale))\n        max_bound = float(np.max(bounds_scale))\n\n        # antithetic batch base\n        if self.pop_base is None:\n            lam0 = max(6, int(3 + 2 * np.log(max(2, self.dim))))\n        else:\n            lam0 = int(self.pop_base)\n        lam0 = min(lam0, max(2, self.budget))\n        if lam0 % 2 == 1 and lam0 > 2:\n            lam0 -= 1\n\n        evals = 0\n\n        # Stratified quasi-uniform init (small jitter)\n        init_n = min(lam0, max(2, self.budget))\n        X0 = np.empty((init_n, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(init_n)\n            strata = (np.arange(init_n) + 0.5) / init_n\n            X0[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter a bit\n        jitter_scale = 0.25 * bounds_scale / max(1.0, self.dim)\n        X0 += (rng.rand(init_n, self.dim) - 0.5) * jitter_scale.reshape(1, -1)\n        X0 = np.minimum(np.maximum(X0, lb), ub)\n\n        f0 = np.full(init_n, np.inf, dtype=float)\n        for i in range(init_n):\n            if evals >= self.budget:\n                break\n            f0[i] = float(func(X0[i]))\n            evals += 1\n\n        # if budget exhausted during init, return best seen\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f0[:i+1]))\n            self.f_opt = float(f0[best_idx])\n            self.x_opt = X0[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # archive seeded with initial samples\n        archive_X = [X0[i].copy() for i in range(init_n)]\n        archive_f = [float(f0[i]) for i in range(init_n)]\n        archive_capacity = max(4 * self.dim, 20)\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initial mean from elites\n        mu0 = max(1, init_n // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 /= np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance & sigma (conservative)\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.18 * range_mean)\n\n        # momentum, per-coordinate scaling, success smoothing\n        v = np.zeros(self.dim, dtype=float)\n        s_diag = np.ones(self.dim, dtype=float)\n        p_succ = float(self.success_target)\n\n        stagn_gens = 0\n        gen = 0\n\n        def chol_spd(mat):\n            eps = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        def reflect_then_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(lam0, remaining)\n            if remaining >= 2:\n                lam = max(2, lam if lam % 2 == 0 else lam - 1)\n            else:\n                lam = 1\n\n            mu = max(1, lam // 2)\n            # recompute weights\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n            W = weights.reshape(-1, 1)\n\n            # SPD factor\n            A = chol_spd(C)\n\n            # antithetic sampling\n            half = lam // 2\n            Zpos = rng.normal(size=(half, self.dim))\n            Z = np.vstack([Zpos, -Zpos])\n            if lam % 2 == 1:\n                Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n\n            Y = Z @ A.T\n            # directional momentum injection (normalized)\n            vlen = np.linalg.norm(v) + 1e-20\n            if vlen > 0:\n                v_unit = v / vlen\n                dir_strength = 0.8 * (vlen / (1.0 + vlen))\n                s_scalar = rng.normal(scale=dir_strength, size=(Y.shape[0], 1))\n                Y = Y + s_scalar * v_unit.reshape(1, -1)\n            # per-coordinate scaling\n            Y = Y * s_diag.reshape(1, -1)\n\n            Xcand = m + sigma * Y\n\n            # occasional DE-style injection into the candidate set for structured diversity\n            if (len(archive_X) >= 3) and (rng.rand() < self.de_inject_prob) and (Xcand.shape[0] >= 1):\n                # build a DE-like trial from archive entries\n                idxs = rng.choice(len(archive_X), size=min(3, len(archive_X)), replace=False)\n                if len(idxs) == 3:\n                    base = archive_X[idxs[0]]\n                    x1 = archive_X[idxs[1]]\n                    x2 = archive_X[idxs[2]]\n                    F = 0.8\n                    trial = base + F * (x1 - x2)\n                    # localized gaussian perturbation to mix scales\n                    trial += rng.normal(scale=0.2 * sigma, size=self.dim)\n                    trial = reflect_then_clamp(trial)\n                    rep = rng.randint(Xcand.shape[0])\n                    Xcand[rep] = trial\n\n            # clamp candidates\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate sequentially\n            fc = np.full(Xcand.shape[0], np.inf, dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                xi = Xcand[i]\n                fv = float(func(xi))\n                fc[i] = fv\n                evals += 1\n                if fv < f_best:\n                    f_best = fv\n                    x_best = xi.copy()\n                    stagn_gens = 0\n\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                if Xcand.shape[0] == 0:\n                    break\n\n            # archive maintenance\n            for xi, fi in zip(Xcand, fc):\n                archive_X.append(xi.copy())\n                archive_f.append(float(fi))\n            if len(archive_X) > archive_capacity:\n                # keep most recent entries (simple)\n                excess = len(archive_X) - archive_capacity\n                archive_X = archive_X[excess:]\n                archive_f = archive_f[excess:]\n\n            # generation best\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            fc_mu = fc[order[:mu]]\n            gen_best_f = float(np.min(fc)) if fc.size > 0 else np.inf\n            improved = gen_best_f < f_best - 1e-20  # strict improvement\n            if improved:\n                stagn_gens = 0\n            else:\n                stagn_gens += 1\n\n            # compute normalized deltas\n            if X_mu.shape[0] > 0:\n                deltas = (X_mu - m) / (sigma + 1e-20)\n                # weighted covariance in normalized coords\n                if deltas.shape[0] != weights.shape[0]:\n                    mu_eff = deltas.shape[0]\n                    w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if np.sum(w_eff) <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff /= np.sum(w_eff)\n                    Wd = w_eff.reshape(-1, 1)\n                    weighted_cov = (deltas * Wd).T @ deltas\n                    delta_mean = (Wd * deltas).sum(axis=0)\n                else:\n                    weighted_cov = (deltas * W).T @ deltas\n                    delta_mean = (W * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # momentum update (normalized coords)\n            v = self.mom_beta * v + (1.0 - self.mom_beta) * delta_mean\n            rank_one = np.outer(v, v)\n\n            # covariance update\n            c_cov = float(self.cov_lr)\n            c1 = float(self.rank1)\n            other = max(0.0, 1.0 - c_cov - c1)\n            C = other * C + c_cov * weighted_cov + c1 * rank_one\n            C = 0.5 * (C + C.T) + np.diag(np.maximum(np.diag(C), 1e-18))\n\n            # per-coordinate scaling update (EMA of sqrt stat)\n            if X_mu.shape[0] > 0:\n                stat = np.mean(deltas ** 2, axis=0)\n            else:\n                stat = 1e-6 * np.ones(self.dim)\n            s_diag = (self.s_diag_beta * s_diag +\n                      (1.0 - self.s_diag_beta) * np.sqrt(stat + 1e-20))\n            s_diag = np.clip(s_diag, 0.2, 5.0)\n\n            # mean update (weighted)\n            if X_mu.shape[0] > 0:\n                m_new = (weights.reshape(-1, 1) * X_mu[:weights.shape[0]]).sum(axis=0)\n                m = np.minimum(np.maximum(m_new, lb), ub)\n\n            # success-based sigma adaptation\n            p_succ = 0.85 * p_succ + 0.15 * float(np.any(fc < f_best))\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, 1e-12, 2.0 * max_bound)\n\n            # periodic or stagnation-triggered Hooke-Jeeves coordinate pattern search\n            if (gen % self.local_period == 0) or (stagn_gens >= self.local_stagn_gen):\n                remaining_loc = self.budget - evals\n                if remaining_loc > 0:\n                    step = max(1e-12, self.initial_step_frac * range_mean)\n                    min_step = max(1e-12, self.min_step_frac * range_mean)\n                    if stagn_gens >= self.local_stagn_gen:\n                        step *= 2.0\n                    local_improved = False\n                    x_work = x_best.copy()\n                    f_work = f_best\n                    while step >= min_step and (self.budget - evals) > 0:\n                        moved = False\n                        for d in range(self.dim):\n                            if evals >= self.budget:\n                                break\n                            # positive probe\n                            x_try = x_work.copy()\n                            x_try[d] = x_try[d] + step\n                            if x_try[d] > ub[d]:\n                                x_try[d] = ub[d]\n                            if np.all(x_try == x_work):\n                                x_try[d] = x_work[d] - step\n                                if x_try[d] < lb[d]:\n                                    x_try[d] = lb[d]\n                            x_try = reflect_then_clamp(x_try)\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                x_work = x_try\n                                f_work = fv\n                                moved = True\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_try.copy()\n                                    stagn_gens = 0\n                                # opportunistic extra probe further\n                                if evals < self.budget:\n                                    x_try2 = x_work.copy()\n                                    x_try2[d] = np.minimum(np.maximum(x_try2[d] + step, lb[d]), ub[d])\n                                    x_try2 = reflect_then_clamp(x_try2)\n                                    fv2 = float(func(x_try2))\n                                    evals += 1\n                                    if fv2 < f_work:\n                                        x_work = x_try2\n                                        f_work = fv2\n                                        if fv2 < f_best:\n                                            f_best = fv2\n                                            x_best = x_try2.copy()\n                                            stagn_gens = 0\n                            else:\n                                # try minus if plus didn't help\n                                if evals >= self.budget:\n                                    break\n                                x_try = x_work.copy()\n                                x_try[d] = x_work[d] - step\n                                if x_try[d] < lb[d]:\n                                    x_try[d] = lb[d]\n                                x_try = reflect_then_clamp(x_try)\n                                fv = float(func(x_try))\n                                evals += 1\n                                if fv < f_work:\n                                    x_work = x_try\n                                    f_work = fv\n                                    moved = True\n                                    local_improved = True\n                                    if fv < f_best:\n                                        f_best = fv\n                                        x_best = x_try.copy()\n                                        stagn_gens = 0\n                        if not moved:\n                            step *= self.step_shrink\n                        if evals >= self.budget:\n                            break\n\n                    if local_improved:\n                        # inject into archive and nudge mean/cov\n                        if len(archive_f) > 0:\n                            worst_idx = int(np.argmax(archive_f))\n                            archive_X[worst_idx] = x_work.copy()\n                            archive_f[worst_idx] = float(f_work)\n                        else:\n                            archive_X.append(x_work.copy())\n                            archive_f.append(float(f_work))\n                        # gentle shift of mean and small covariance rank-1\n                        m = 0.92 * m + 0.08 * x_work\n                        s = (x_work - m) / (sigma + 1e-20)\n                        C = 0.98 * C + 0.02 * np.outer(s, s)\n                        # SPD fix\n                        vals, vecs = np.linalg.eigh(C)\n                        vals = np.clip(vals, 1e-12, None)\n                        C = (vecs * vals) @ vecs.T\n                        stagn_gens = 0\n                    else:\n                        # mild nudges around best when stagnating\n                        if stagn_gens >= self.local_stagn_gen:\n                            nudge_pop = max(1, lam0 // 3)\n                            for k in range(nudge_pop):\n                                if evals >= self.budget:\n                                    break\n                                jitter = rng.randn(self.dim) * (0.05 * bounds_scale)\n                                newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                                fv = float(func(newx))\n                                evals += 1\n                                if len(archive_f) > 0:\n                                    worst_idx = int(np.argmax(archive_f))\n                                    archive_X[worst_idx] = newx.copy()\n                                    archive_f[worst_idx] = float(fv)\n                                else:\n                                    archive_X.append(newx.copy())\n                                    archive_f.append(float(fv))\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = newx.copy()\n                                    stagn_gens = 0\n\n            # sigma collapse or long stagnation -> mild global jitter restart\n            if sigma <= 1e-9 * max_bound or stagn_gens > max(5, self.local_stagn_gen * 3):\n                m = x_best + rng.randn(self.dim) * (0.05 * bounds_scale)\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                sigma = max(sigma, 0.12 * range_mean)\n                v = np.zeros_like(v)\n                s_diag = np.ones_like(s_diag)\n                stagn_gens = 0\n\n            # ensure SPD\n            try:\n                _ = np.linalg.cholesky(C + np.eye(self.dim) * 1e-16)\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                C = (vecs * vals) @ vecs.T\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AMCD_HJ scored 0.375 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "25ef7321-3c58-4469-96c5-fb81ab07c8f5", "operator": null, "metadata": {"aucs": [0.08438156758638138, 0.13842712129348433, 0.48394124999871635, 0.9895183060670228, 0.2939356084330379, 0.7194893189300862, 0.24118701842155454, 0.4346915360008967, 0.25105522091533217, 0.1152927703659622]}, "task_prompt": ""}
{"id": "87d9ad08-ab7d-4a3c-932f-3a90f774324b", "fitness": 0.14728097396773676, "name": "AM_DACS", "description": "The design is a compact CMA-style iterative search that maintains a mean m, a global step-size sigma and a full covariance C while using mirrored (antithetic) pair sampling to halve sampling variance and a small, budget-aware population (lam ≈ max(10, 6+2√dim) but capped by budget). Covariance learning mixes a rank‑1 update from an evolution path p and a rank‑mu weighted covariance (c1=0.12, cmu=0.06) with linear decreasing recombination weights and an effective-parent-size mu_eff; the evolution path uses c_p = 2/(dim+2) to be dimension-aware. Step-size is adapted by comparing normalized RMS population spread to a diversity_target (0.30) with a multiplicative update controlled by alpha_sigma (0.6), and sigma/C are initialized narrowly (sigma=0.15·avg_span, diag(C)∝(span/6)^2) to encourage early exploitation. Robustness measures include SPD safeguards (Cholesky fallback to eigen decomposition, eigen clipping at 1e-12), bounds clamping for candidates, and an opportunistic stagnation restart (stagn_limit ≈ max(10, 0.02·budget)) that recenters the mean near the best, inflates sigma and shrinks C.", "code": "import numpy as np\n\nclass AM_DACS:\n    \"\"\"\n    Adaptive Mirrored Directional Adaptive Covariance Search (AM-DACS)\n\n    - Compact CMA-style loop (mean m, covariance C, global sigma) like DACS.\n    - Use mirrored (antithetic) pair sampling for variance-efficient populations.\n    - Covariance update mixes a rank-1 evolution path and a rank-mu weighted covariance (c1, cmu).\n    - Step-size sigma adapted via measured normalized population spread toward a target (diversity_target).\n    - Robust SPD safeguards (Cholesky + eigen clipping) and opportunistic restart on stagnation.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # covariance learning rates (inspired by AMES)\n        self.c1 = 0.12\n        self.cmu = 0.06\n\n        # step-size adaptation\n        self.alpha_sigma = 0.6\n        self.diversity_target = 0.30\n\n        # population sizing preference (compact but >8)\n        self.pop_base = None\n\n        # stagnation control (fraction of budget)\n        self.stagnation_ratio = 0.02\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds (support scalar or per-dim)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        avg_span = float(np.mean(bounds_scale))\n\n        # adaptive population (mirrored pairs efficient)\n        if self.pop_base is None:\n            lam = max(10, int(6 + 2 * np.sqrt(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # initial uniform sampling to populate first generation\n        evals = 0\n        first_batch = min(lam, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(first_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += first_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize mean from top-half (robust small-pop recombination)\n        mu = max(1, first_batch // 2)\n        order = np.argsort(f0)\n        elites = X0[order[:mu]]\n        # linear decreasing weights (normalized)\n        weights = np.linspace(mu, 1, mu)\n        weights = np.maximum(weights, 1e-12)\n        weights = weights / np.sum(weights)\n        m = (weights.reshape(-1,1) * elites).sum(axis=0)\n\n        # initialize covariance and sigma (narrower to encourage exploitation early)\n        init_scale = bounds_scale / 6.0\n        C = np.diag((init_scale ** 2).clip(min=1e-12))\n        sigma = 0.15 * avg_span\n\n        # evolution path and other state\n        p = np.zeros(self.dim, dtype=float)\n        c1 = float(self.c1)\n        cmu = float(self.cmu)\n        alpha_sigma = float(self.alpha_sigma)\n        diversity_target = float(self.diversity_target)\n        stagn_limit = max(10, int(self.stagnation_ratio * self.budget))\n        stagn_count = 0\n\n        # helper: ensure SPD and return factor A such that A^T A = C\n        def chol_or_eig(Cmat):\n            # small regularization based on diagonal\n            eps = 1e-12 * np.maximum(np.diag(Cmat), 1.0)\n            try:\n                A = np.linalg.cholesky(Cmat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(Cmat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        # recombination weights factory (linear decreasing)\n        def recombination_weights(mu_local):\n            w = np.linspace(mu_local, 1, mu_local)\n            w = np.maximum(w, 0.0)\n            w = w / np.sum(w)\n            return w\n\n        # main loop\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu_iter = max(1, lam_iter // 2)\n            weights = recombination_weights(mu_iter)\n\n            # ensure SPD and get A\n            A = chol_or_eig(C)\n\n            # mirrored sampling: generate half normal draws and reflect\n            half = lam_iter // 2\n            odd = (lam_iter % 2) != 0\n            Z = rng.normal(size=(half, self.dim))\n            Y_half = Z @ A.T  # each row has covariance C\n            Xcand_list = []\n            Z_list = []\n            for y in Y_half:\n                Xcand_list.append(m + sigma * y)\n                Xcand_list.append(m - sigma * y)\n                Z_list.append(y)\n                Z_list.append(-y)\n            if odd:\n                z = rng.normal(size=self.dim)\n                yc = z @ A.T\n                Xcand_list.append(m + sigma * yc)\n                Z_list.append(yc)\n            Xcand = np.vstack(Xcand_list)[:lam_iter]\n            Zmat = np.vstack(Z_list)[:lam_iter]\n\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate sequentially (budget-respecting)\n            fc = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                fc[i] = func(Xcand[i])\n            evals += lam_iter\n\n            # update best\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # select elites and recompute mean\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu_iter]]\n            m_new = (weights.reshape(-1,1) * X_mu).sum(axis=0)\n\n            # normalized steps in candidate coords (using old m)\n            y_steps = (X_mu - m) / (sigma + 1e-20)  # shape (mu_iter, dim)\n            W = weights.reshape(-1,1)\n            cov_mu = (W * y_steps).T @ y_steps\n\n            # update evolution path (dimension-aware cp)\n            mu_eff = (np.sum(weights))**2 / (np.sum(weights**2) + 1e-20)\n            c_p = 2.0 / (self.dim + 2.0)\n            y_w = (weights.reshape(-1,1) * y_steps).sum(axis=0)\n            p = (1.0 - c_p) * p + np.sqrt(c_p * (2.0 - c_p) * mu_eff) * y_w\n\n            # covariance update\n            coef_fix = max(0.0, 1.0 - c1 - cmu)\n            C = coef_fix * C + c1 * np.outer(p, p) + cmu * cov_mu\n\n            # update mean\n            m = m_new\n\n            # step-size adaptation based on normalized RMS spread (encourages population diversity)\n            y_all = (Xcand - m) / (sigma + 1e-20)\n            norm_rms = np.sqrt(np.mean(np.sum(y_all**2, axis=1)) / max(1.0, float(self.dim)))\n            sigma *= np.exp(alpha_sigma * (diversity_target - norm_rms))\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n            # numeric safeguards for C\n            if np.any(np.isnan(C)) or np.any(np.isinf(C)):\n                C = np.diag(((bounds_scale / 8.0) ** 2).clip(min=1e-12))\n            try:\n                _ = np.linalg.cholesky(C + np.eye(self.dim) * 1e-16)\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                C = (vecs * vals) @ vecs.T\n\n            # opportunistic restart on stagnation: re-center near best, inflate sigma, shrink C\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                sigma = min(sigma * 3.0, 1.0 * np.max(bounds_scale))\n                jitter = sigma * (0.2 + 0.6 * rng.rand(self.dim))\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((bounds_scale / 12.0) ** 2).clip(min=1e-12))\n                p = np.zeros_like(p)\n                continue\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AM_DACS scored 0.147 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "25ef7321-3c58-4469-96c5-fb81ab07c8f5", "operator": null, "metadata": {"aucs": [0.11316481798000677, 0.16738531381394628, 0.1746941548633194, 0.12651480856319963, 0.10476003281067969, 0.15370983874735744, 0.20843903136078734, 0.13885999329278276, 0.16363061006041413, 0.12165113818487416]}, "task_prompt": ""}
{"id": "f46a96a2-6832-440f-806f-6bc7b27e5c62", "fitness": "-inf", "name": "PCA_Levy_Repel_SubspaceSearch", "description": "The algorithm maintains a small sorted elite archive and computes its centroid, covariance and principal components to drive low-dimensional exploitation while always clamping candidates to the problem bounds and strictly counting evaluations against the budget. It uses an adaptive ensemble of four operators — Mantegna-style Lévy flights for heavy-tailed global jumps (levy_alpha≈1.5), PCA-guided subspace sampling for focused search, repulsive reinitialization to promote diversity when elites cluster, and focused 1‑D quadratic refinements along top principal axes — with occasional uniform injections to preserve exploration. Operator selection is governed by softmax sampling and online credit-assignment (exponential recency decay and learning rate) where rewards are proportional to improvement over a baseline, and scales (global/local) decay adaptively with remaining budget to shift from exploration to exploitation. Additional design choices include budget-aware initial sample sizing and archive sizing, anisotropic scaling using eigenvalues/avg span, small orthogonal noise for escape, and multiple local refinement heuristics (subspace samples and quadratic axis fits).", "code": "import numpy as np\n\nclass PCA_Levy_Repel_SubspaceSearch:\n    \"\"\"\n    PCA-guided Multi-scale Lévy & Repulsive Subspace Search (PLRSS)\n\n    Main ideas:\n    - Maintain a small elite archive.\n    - Use an adaptive ensemble of operators:\n        1) Mantegna-style Lévy flights (heavy-tailed global jumps).\n        2) PCA-guided subspace sampling around elite centroid (low-dimensional exploitation).\n        3) Repulsive reinitialization to push samples away from clustered elites.\n        4) Quadratic 1D subspace refinements along principal axes (local model-based steps).\n    - Operator selection by online credit assignment (reward-weighted).\n    - Budget-aware multi-scale step adaptation: global scales decay with budget, local scales adapt from elite covariance.\n    - Strictly never calls func more than budget times.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 init_samples=None, archive_size=None,\n                 levy_alpha=1.5, min_scale=0.02):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.levy_alpha = float(levy_alpha)\n        self.min_scale = float(min_scale)\n\n        # results placeholders\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds parsing (Many BBOB uses [-5,5], but read from func.bounds)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        center_box = 0.5 * (lb + ub)\n\n        # initial sample counts\n        if self.init_samples is None:\n            init_samples = max(12, min(60, 6 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, max(1, self.budget // 4))\n\n        if self.archive_size is None:\n            archive_k = max(3, min(12, init_samples // 3))\n        else:\n            archive_k = int(self.archive_size)\n\n        evals = 0\n        archive = []  # sorted list of tuples (f, x)\n        f_best = np.inf\n        x_best = None\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            f = float(f)\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # maintain sorted archive\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # initial sampling - space-filling random\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # helper: compute centroid & principal components of archive\n        def archive_stats(n_components=None):\n            if len(archive) == 0:\n                return center_box.copy(), np.eye(self.dim), np.ones(self.dim) * 1e-12\n            X = np.vstack([t[1] for t in archive])\n            centroid = np.mean(X, axis=0)\n            # covariance with small regularization\n            cov = np.cov(X.T) if X.shape[0] > 1 else np.eye(self.dim) * (1e-6 + 0.01 * span**2)\n            cov = cov + np.eye(self.dim) * 1e-12\n            # eigendecomposition\n            vals, vecs = np.linalg.eigh(cov)\n            # sort descending\n            idx = np.argsort(vals)[::-1]\n            vals = vals[idx]\n            vecs = vecs[:, idx]\n            if n_components is None:\n                return centroid, vecs, vals\n            else:\n                return centroid, vecs[:, :n_components], vals[:n_components]\n\n        # Mantegna's algorithm for symmetric Levy stable steps (alpha in (0,2))\n        def mantenga_levy(alpha, size):\n            # returns vector of length \"size\" with iid symmetric Levy(alpha)\n            # Implementation following Mantegna (1994) for 1D; we extend by generating independent components\n            # but scale each component by same distribution to get heavy tail directionality.\n            sigma_u = (np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) /\n                       (np.math.gamma((1 + alpha) / 2) * alpha * 2 ** ((alpha - 1) / 2))) ** (1 / alpha)\n            u = rng.normal(0, sigma_u, size=size)\n            v = rng.normal(0, 1.0, size=size)\n            step = u / (np.abs(v) ** (1.0 / alpha) + 1e-16)\n            return step\n\n        # Operators: we'll manage 4 operators with adaptive weights\n        n_ops = 4\n        op_weights = np.ones(n_ops, dtype=float)  # adaptive credit\n        op_decay = 0.85  # weight decay for older credits\n        learning_rate = 0.7  # how strongly to incorporate reward\n\n        # scales and parameters\n        global_scale_initial = 1.0\n        local_scale_initial = 0.2\n        min_scale = self.min_scale\n\n        attempt = 0\n\n        # main loop\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            # budget-aware global scale decays as more evals are consumed\n            t = evals / max(1, self.budget)\n            global_scale = max(min_scale, global_scale_initial * (1.0 - 0.9 * t ** 1.2))\n            local_scale = max(min_scale * 0.1, local_scale_initial * (1.0 - t))\n\n            # get centroid & PC structure\n            centroid, pcs_all, eigvals_all = archive_stats()\n            # choose subspace dimensionality adaptively (1..dim)\n            sub_k = max(1, min(self.dim, int(1 + np.round(0.5 * np.sum(eigvals_all > (np.mean(eigvals_all) * 0.1))))))\n            cent_sub, pcs_sub, eig_sub = archive_stats(n_components=sub_k)\n\n            # sample operator index proportionally to softmax of weights\n            probs = np.exp(op_weights - np.max(op_weights))\n            probs = probs / (np.sum(probs) + 1e-16)\n            op = rng.choice(n_ops, p=probs)\n\n            # helper to record reward and update weight\n            def record_reward(op_idx, reward):\n                nonlocal op_weights\n                # reward >= 0 expected; do exponential recency weighted update\n                op_weights[op_idx] = op_weights[op_idx] * op_decay + learning_rate * reward\n\n            # store baseline f to compute reward\n            baseline = archive[0][0] if len(archive) > 0 else f_best\n\n            # OP 0: Mantegna Lévy flight around a chosen center (global heavy-tailed)\n            if op == 0:\n                # choose center biased to best\n                if len(archive) > 0 and rng.rand() < 0.8:\n                    center = archive[0][1]\n                else:\n                    center = rng.uniform(lb, ub)\n                # direction: scaled Mantegna vector\n                step_vec = mantenga_levy(self.levy_alpha, self.dim)\n                # anisotropic scaling using span and eigen-structure\n                anis = 0.4 + 0.6 * rng.rand()\n                cand = center + global_scale * anis * avg_span * step_vec\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, x_cand = res\n                # reward proportional to improvement relative to baseline with budget-normalization\n                reward = max(0.0, (baseline - f_cand) / (abs(baseline) + 1e-12))\n                record_reward(0, reward)\n\n                # if promising, do a light PCA-subspace refinement\n                if f_cand <= baseline * 0.99 and remaining > 3:\n                    # small subspace sampling\n                    n_sub = min(3 + self.dim // 6, remaining - 1)\n                    best_local = (f_cand, x_cand)\n                    for _ in range(n_sub):\n                        z = rng.normal(0, 1.0, size=sub_k) * np.sqrt(eig_sub + 1e-12)\n                        candidate = cent_sub + local_scale * z @ pcs_sub.T\n                        candidate += 0.01 * avg_span * rng.randn(self.dim)  # small orth noise\n                        candidate = np.minimum(np.maximum(candidate, lb), ub)\n                        res = eval_and_record(candidate)\n                        if res is None:\n                            break\n                        ftmp, xtmp = res\n                        if ftmp < best_local[0]:\n                            best_local = (ftmp, xtmp)\n                    # reward update for the extra exploitation\n                    record_reward(0, max(0.0, (baseline - best_local[0]) / (abs(baseline) + 1e-12)))\n\n            # OP 1: PCA-guided Subspace Sampling (exploit along principal directions)\n            elif op == 1:\n                # choose center as centroid of archive or best with some prob\n                if len(archive) > 0 and rng.rand() < 0.6:\n                    center = archive[0][1]\n                else:\n                    center = centroid\n                # sample coefficients in low-dimensional subspace (pcs_sub)\n                coeffs = rng.normal(0, 1.0, size=sub_k) * np.sqrt(eig_sub + 1e-12)\n                candidate = center + local_scale * coeffs @ pcs_sub.T\n                # add small orthogonal noise to explore outside subspace\n                orth_noise = 0.02 * avg_span * rng.randn(self.dim)\n                candidate = candidate + orth_noise\n                candidate = np.minimum(np.maximum(candidate, lb), ub)\n                res = eval_and_record(candidate)\n                if res is None:\n                    break\n                f_cand, x_cand = res\n                reward = max(0.0, (baseline - f_cand) / (abs(baseline) + 1e-12))\n                record_reward(1, reward)\n\n                # if moderately promising, do 1-step quadratic axis refinement\n                if f_cand <= baseline * 1.02 and remaining > 4:\n                    best_local = (f_cand, x_cand)\n                    # for a couple principal axes\n                    axes_try = min(sub_k, max(1, int(np.ceil(sub_k * 0.6))))\n                    idxs = list(range(sub_k))\n                    rng.shuffle(idxs)\n                    for i in idxs[:axes_try]:\n                        axis = pcs_sub[:, i]\n                        s = max(1e-6, 0.8 * local_scale * np.sqrt(eig_sub[i] + 1e-12) * avg_span)\n                        # evaluate at -s,0,+s along axis from center x_cand\n                        p0 = x_cand\n                        p_plus = np.minimum(np.maximum(p0 + s * axis, lb), ub)\n                        res_plus = eval_and_record(p_plus)\n                        if res_plus is None:\n                            break\n                        f_plus, _ = res_plus\n                        p_minus = np.minimum(np.maximum(p0 - s * axis, lb), ub)\n                        res_minus = eval_and_record(p_minus)\n                        if res_minus is None:\n                            break\n                        f_minus, _ = res_minus\n                        # quadratic minimizer along axis (t in [-1.5,1.5] * s)\n                        denom = (f_plus + f_minus - 2.0 * f_cand)\n                        if abs(denom) > 1e-12:\n                            t_star = -s * (f_plus - f_minus) / (2.0 * denom)\n                            t_star = np.clip(t_star, -1.5 * s, 1.5 * s)\n                            p_star = np.minimum(np.maximum(p0 + t_star * axis, lb), ub)\n                            res_star = eval_and_record(p_star)\n                            if res_star is None:\n                                break\n                            f_star, x_star = res_star\n                            if f_star < best_local[0]:\n                                best_local = (f_star, x_star)\n                    record_reward(1, max(0.0, (baseline - best_local[0]) / (abs(baseline) + 1e-12)))\n\n            # OP 2: Repulsive Reinitialization (promote diversity when elites cluster)\n            elif op == 2:\n                # compute pairwise spread\n                if len(archive) > 1:\n                    spread = np.linalg.norm(archive[0][1] - archive[-1][1])\n                else:\n                    spread = avg_span\n                # choose a base point (best or uniform) and push away from centroid\n                if len(archive) > 0 and rng.rand() < 0.8:\n                    base = archive[0][1]\n                else:\n                    base = rng.uniform(lb, ub)\n                centroid_all = centroid\n                vec = base - centroid_all\n                dist = np.linalg.norm(vec) + 1e-12\n                # repulsion magnitude ~ (target - dist) / (1 + dist) scaled by global_scale\n                target = 0.2 * avg_span + 0.5 * spread\n                repel_strength = np.tanh((target - dist) / (target + 1e-12))  # [-1,1]\n                # random rotation around base to diversify\n                random_rot = rng.randn(self.dim)\n                random_rot /= (np.linalg.norm(random_rot) + 1e-12)\n                # compose candidate\n                cand = base + (repel_strength * 1.2) * (dist + 1e-6) * random_rot * global_scale * avg_span * 0.5\n                # occasional full uniform injection\n                if rng.rand() < 0.12:\n                    cand = rng.uniform(lb, ub)\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, x_cand = res\n                reward = max(0.0, (baseline - f_cand) / (abs(baseline) + 1e-12))\n                record_reward(2, reward)\n\n                # if not improved and archive very clustered, try opposite direction\n                if reward == 0.0 and dist < 1e-6 + 0.02 * avg_span and remaining > 3:\n                    opposite = base - (random_rot * global_scale * avg_span * (0.6 + rng.rand()))\n                    opposite = np.minimum(np.maximum(opposite, lb), ub)\n                    res2 = eval_and_record(opposite)\n                    if res2 is None:\n                        break\n                    f2, x2 = res2\n                    record_reward(2, max(0.0, (baseline - f2) / (abs(baseline) + 1e-12)))\n\n            # OP 3: Focused subspace \"polish\" starting at best (local model-driven pattern)\n            else:\n                if len(archive) > 0:\n                    start_x = archive[0][1].copy()\n                    start_f = archive[0][0]\n                else:\n                    start_x = rng.uniform(lb, ub)\n                    temp = eval_and_record(start_x)\n                    if temp is None:\n                        break\n                    start_f, start_x = temp\n                # perform a small number of 1D quadratic refinements along top PCs\n                best_local = (start_f, start_x.copy())\n                axes = min(sub_k, max(1, int(1 + np.round(sub_k * 0.5))))\n                idxs = list(range(sub_k))\n                rng.shuffle(idxs)\n                for i in idxs[:axes]:\n                    if evals >= self.budget:\n                        break\n                    axis = pcs_sub[:, i]\n                    # adapt step from eigenvalue\n                    s = max(1e-6, 0.6 * local_scale * np.sqrt(eig_sub[i] + 1e-12) * avg_span)\n                    p0 = best_local[1]\n                    # evaluate at -s,+s (we already have f at center maybe)\n                    p_plus = np.minimum(np.maximum(p0 + s * axis, lb), ub)\n                    res_plus = eval_and_record(p_plus)\n                    if res_plus is None:\n                        break\n                    f_plus, _ = res_plus\n                    p_minus = np.minimum(np.maximum(p0 - s * axis, lb), ub)\n                    res_minus = eval_and_record(p_minus)\n                    if res_minus is None:\n                        break\n                    f_minus, _ = res_minus\n                    # quadratic minimizer\n                    denom = (f_plus + f_minus - 2.0 * best_local[0])\n                    if abs(denom) > 1e-12:\n                        t_star = -s * (f_plus - f_minus) / (2.0 * denom)\n                        t_star = np.clip(t_star, -1.5 * s, 1.5 * s)\n                        p_star = np.minimum(np.maximum(p0 + t_star * axis, lb), ub)\n                        res_star = eval_and_record(p_star)\n                        if res_star is None:\n                            break\n                        f_star, x_star = res_star\n                        if f_star < best_local[0]:\n                            best_local = (f_star, x_star)\n                # reward relative to start\n                reward = max(0.0, (start_f - best_local[0]) / (abs(start_f) + 1e-12))\n                record_reward(3, reward)\n\n            # occasional uniform injection to preserve global exploration (budget-aware)\n            if (attempt % (13 + self.dim % 7)) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # slight normalization / stabilization of op_weights to avoid numerical blowup\n            if np.any(np.isnan(op_weights)) or np.any(op_weights > 1e9):\n                op_weights = np.ones_like(op_weights)\n\n            # early stop if perfect zero found\n            if f_best == 0.0:\n                break\n\n        # finalize results\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'math'. Did you mean: 'emath'?", "error": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'math'. Did you mean: 'emath'?", "parent_ids": "b6db7a7e-9699-49c0-ad02-a3fdafec2752", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "9214814f-75d2-4ab2-9a98-575a28bee8f7", "fitness": 0.4728509695319845, "name": "HALTS", "description": "HALTS is a hybrid search that keeps a small sorted elite archive and mixes three proposal operators — covariance-guided Gaussian sampling (p_cov=0.40), Lévy-like heavy‑tailed jumps (p_levy=0.35, levy_alpha=1.2) and an adaptive trust‑region local search (p_local=0.25) — favoring slightly global moves while still reserving local refinement. Initialization and archive sizing are budget‑aware (init_samples = min(8*dim, budget//4), archive_k ~ init_samples/4) and occasional uniform injections (inject_period=23) preserve diversity. Local search is a coordinate exploratory + pattern method using a conservative base step (base_step = 0.15*span), mild expansion (1.2) and strong shrinkage (0.5), with a small fraction of the budget reserved for focused local refinements (local_budget_frac=0.05). Operator mixing and proposal scales adapt to population spread via a median pairwise distance (diversity_factor) and slowly adjusted cov_scale, so the algorithm increases exploration when elites cluster and tightens search as progress is made.", "code": "import numpy as np\n\nclass HALTS:\n    \"\"\"\n    Hybrid Adaptive Lévy-Trust-Region Search (HALTS)\n\n    - Maintains a small elite archive.\n    - Proposes candidates using:\n        1) Covariance-guided Gaussian sampling around elites (informed global moves).\n        2) Pareto/Lévy-like heavy-tailed jumps from elites (exploratory jumps).\n        3) Adaptive trust-region local search (coordinate explorations + pattern steps).\n    - Adaptive operator mixing based on median pairwise elite distance (diversity).\n    - Budget-aware initial sampling and local-budget reservation.\n    - All evaluations clipped to bounds and recorded; never exceeds budget.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 init_samples=None, archive_size=None,\n                 local_budget_frac=0.05, cov_scale=0.6, levy_alpha=1.2):\n        \"\"\"\n        Parameters:\n        - budget: total allowed function evaluations.\n        - dim: problem dimensionality.\n        - rng_seed: optional RNG seed.\n        - init_samples: optional override of initial sampling count.\n        - archive_size: optional override of elite archive size.\n        - local_budget_frac: fraction of total budget reserved for local searches (relative policy).\n        - cov_scale: base scale multiplier for covariance-guided proposals.\n        - levy_alpha: tail index for Pareto-like heavy jumps (1 < alpha <= 3 typical; smaller = heavier tail).\n        \"\"\"\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.local_budget_frac = float(local_budget_frac)\n        self.cov_scale = float(cov_scale)\n        self.levy_alpha = float(levy_alpha)\n\n        # results\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds (support scalar or vector)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial sampling and archive size (different from original)\n        if self.init_samples is None:\n            init_samples = max(8, min(8 * self.dim, self.budget // 5))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, max(1, self.budget // 4))\n\n        if self.archive_size is None:\n            archive_k = max(4, min(16, max(3, init_samples // 4)))\n        else:\n            archive_k = int(self.archive_size)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # sorted list of (f, x)\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            f = float(f)\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # maintain sorted archive\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # initial space-filling sampling (uniform)\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one point\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # trust-region / local-search parameters (different from provided)\n        base_step = 0.15 * span  # smaller base step than original\n        base_step = np.maximum(base_step, 1e-10)\n        expand = 1.2      # milder expansion\n        shrink = 0.5      # stronger shrinkage\n        pattern_factor = 1.2\n\n        # operator base probabilities (will adapt)\n        p_cov = 0.40     # covariance-guided global Gaussian\n        p_levy = 0.35    # heavy-tailed Pareto jumps\n        p_local = 0.25   # trust-region local search\n        inject_period = 23  # occasional uniform injection\n\n        attempt = 0\n\n        def median_pairwise_dist(points):\n            # compute median pairwise distance; if <2 points return large value to avoid bias\n            if len(points) < 2:\n                return avg_span\n            pts = np.stack(points, axis=0)\n            # for efficiency, sample if too many\n            n = pts.shape[0]\n            if n > 50:\n                idx = rng.choice(n, 50, replace=False)\n                pts = pts[idx]\n                n = pts.shape[0]\n            diffs = []\n            for i in range(n):\n                for j in range(i + 1, n):\n                    diffs.append(np.linalg.norm(pts[i] - pts[j]))\n            if len(diffs) == 0:\n                return avg_span\n            return float(np.median(diffs))\n\n        def cov_guided_sample(scale_factor):\n            # create Gaussian proposal using diagonal covariance estimated from elites,\n            # with small PCA-like stretching if available.\n            if len(archive) == 0:\n                return rng.uniform(lb, ub)\n            elites = np.stack([t[1] for t in archive], axis=0)\n            # diagonal variances\n            var = np.var(elites, axis=0, ddof=0)\n            # if variance is tiny, fallback to span-based\n            var = np.maximum(var, (0.02 * span) ** 2)\n            cov_diag = var * (self.cov_scale * scale_factor) ** 2\n            step = rng.randn(self.dim) * np.sqrt(cov_diag)\n            # center around a weighted elite mean, biased to best\n            weights = np.linspace(1.0, 0.3, num=len(archive)) if len(archive) > 1 else np.array([1.0])\n            weights = weights / weights.sum()\n            center = np.sum(np.stack([w * a[1] for w, a in zip(weights, archive)], axis=0), axis=0)\n            return center + step\n\n        def levy_pareto_jump(center, scale):\n            # Pareto-like (heavy tail) radial magnitude * random direction\n            # sample Pareto with tail alpha: s = (U)^(-1/alpha) - 1\n            u = rng.rand(self.dim)\n            # avoid extremely large outliers by clipping U away from 0\n            u = np.clip(u, 1e-6, 1.0)\n            # generate independent pareto-like magnitudes\n            mag = (u ** (-1.0 / self.levy_alpha) - 1.0)\n            # allow anisotropy: scale each dimension by span\n            anis = 0.5 + 0.5 * rng.rand(self.dim)\n            direction = rng.randn(self.dim)\n            norm = np.linalg.norm(direction) + 1e-12\n            direction /= norm\n            step = direction * (mag.mean() * scale * avg_span * anis)\n            return center + step\n\n        def trust_region_local_search(x_start, f_start, local_budget):\n            # coordinate exploratory search with pattern, using base_step, expand/shrink, pattern factor\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            steps = base_step.copy()\n            used = 0\n            # limit iterations to avoid overuse\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while used < local_budget and iters < iter_limit and np.any(steps > 1e-12):\n                iters += 1\n                improved = False\n                probe = base.copy()\n                probe_f = base_f\n                order = list(range(self.dim))\n                rng.shuffle(order)\n                for i in order:\n                    if used >= local_budget or evals >= self.budget:\n                        break\n                    # + direction\n                    xp = probe.copy()\n                    xp[i] += steps[i]\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res = eval_and_record(xp)\n                    used += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < probe_f:\n                        probe = xp.copy()\n                        probe_f = fp\n                        improved = True\n                        steps[i] *= expand\n                        continue\n                    # - direction\n                    xn = probe.copy()\n                    xn[i] -= steps[i]\n                    xn = np.minimum(np.maximum(xn, lb), ub)\n                    res = eval_and_record(xn)\n                    used += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < probe_f:\n                        probe = xn.copy()\n                        probe_f = fn\n                        improved = True\n                        steps[i] *= expand\n                # pattern extension\n                if improved and used < local_budget and evals < self.budget:\n                    direction = probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_and_record(xp)\n                        used += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = probe.copy()\n                                base_f = probe_f\n                        else:\n                            base = probe.copy()\n                            base_f = probe_f\n                    else:\n                        base = probe.copy()\n                        base_f = probe_f\n                else:\n                    steps *= shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # Main loop\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n\n            # dynamic local allocation (policy differs from original)\n            alloc_local = min(max(4, int(self.local_budget_frac * self.budget)), max(1, remaining - 1))\n\n            # measure diversity via median pairwise distance\n            if len(archive) >= 2:\n                median_dist = median_pairwise_dist([t[1] for t in archive])\n            else:\n                median_dist = avg_span\n\n            # adapt operator probabilities: more exploration if clustered (small median_dist)\n            diversity_factor = median_dist / (avg_span + 1e-12)  # in [~0, ~1]\n            # if diversity low, increase levy jumps and cov scale, else favor local refinement\n            p_levy_local = p_levy * (1.0 + (0.8 - diversity_factor) * 0.8)\n            p_cov_local = p_cov * (0.9 + diversity_factor * 0.4)\n            # normalize so sum <= 0.95 and local gets remainder\n            s = p_levy_local + p_cov_local\n            if s > 0.95:\n                p_levy_local *= 0.95 / s\n                p_cov_local *= 0.95 / s\n            p_local_local = 1.0 - (p_levy_local + p_cov_local)\n            # slight jitter to prevent determinism\n            r = rng.rand()\n\n            done_local = False\n\n            # operator: covariance-guided Gaussian\n            if r < p_cov_local:\n                # scale shrinks with progress to focus search\n                progress = evals / max(1, self.budget)\n                scale = max(0.06, 1.0 - progress * 0.92)  # differ from original\n                cand = cov_guided_sample(scale)\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n                # if promising, allocate a small local search\n                threshold = archive[0][0] * (1.03 if len(archive) > 0 else 1.0)\n                if alloc_local > 0 and f_cand <= threshold:\n                    local_budget = min(remaining - 1, max(3, alloc_local))\n                    f_after, x_after = trust_region_local_search(cand, f_cand, local_budget)\n                    done_local = True\n\n            # operator: heavy-tailed levy-like jumps\n            elif r < p_cov_local + p_levy_local:\n                # choose center: mostly best, sometimes random elite\n                if rng.rand() < 0.8 or len(archive) == 1:\n                    center = archive[0][1]\n                else:\n                    idx = rng.randint(0, len(archive))\n                    center = archive[idx][1]\n                progress = evals / max(1, self.budget)\n                # scale decays but keeps some baseline\n                scale = max(0.04, 0.6 * (1.0 - progress))\n                cand = levy_pareto_jump(center, scale)\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n                # if very promising, do an extended local search\n                if alloc_local > 0 and f_cand <= (archive[0][0] if len(archive) > 0 else np.inf) * 1.08:\n                    local_budget = min(remaining - 1, max(4, 4 * alloc_local))\n                    f_after, x_after = trust_region_local_search(cand, f_cand, local_budget)\n                    done_local = True\n\n            # operator: local trust-region refinement or jittered sampling\n            else:\n                choice = rng.rand()\n                if len(archive) > 0 and choice < 0.7:\n                    start_f, start_x = archive[0]\n                elif len(archive) > 1 and choice < 0.95:\n                    idx = rng.randint(0, len(archive))\n                    start_f, start_x = archive[idx]\n                else:\n                    # jitter around best or uniform\n                    if x_best is not None:\n                        jitter = 0.08 * avg_span * rng.randn(self.dim)\n                        start_x = x_best + jitter\n                        start_x = np.minimum(np.maximum(start_x, lb), ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                    else:\n                        start_x = rng.uniform(lb, ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                local_budget = min(alloc_local, max(3, int(0.06 * remaining)))\n                if local_budget > 0:\n                    f_after, x_after = trust_region_local_search(start_x, start_f, local_budget)\n                    done_local = True\n\n            # occasional uniform injection to maintain diversity\n            if (attempt % inject_period) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # adaptive adjustments: adjust cov_scale slightly based on clustering\n            if len(archive) >= 2:\n                med = median_pairwise_dist([t[1] for t in archive])\n                if med < 1e-8 + 0.03 * avg_span:\n                    # increase exploration a bit\n                    self.cov_scale = min(1.6, self.cov_scale * 1.04)\n                else:\n                    self.cov_scale = max(0.2, self.cov_scale * 0.997)\n\n            if evals >= self.budget:\n                break\n\n        # finish: ensure result set\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HALTS scored 0.473 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b6db7a7e-9699-49c0-ad02-a3fdafec2752", "operator": null, "metadata": {"aucs": [0.11615870509166037, 0.15229995155151332, 0.9674551945835971, 0.9881666854298556, 0.24875234875110863, 0.989147818028823, 0.3229307123454922, 0.5274703871293035, 0.2834727865430199, 0.13265510586547125]}, "task_prompt": ""}
{"id": "d5bd3b15-24b1-4a27-9ff3-678aa6fc3d46", "fitness": 0.34597244319295806, "name": "AdaptiveDirectionalBanditSearch", "description": "The algorithm maintains a small sorted elite archive and uses a bandit-style softmax over four complementary operators (anisotropic Levy-axis jumps, mirror reflections from worst-to-best, Gaussian sampling around a weighted elite mean, and a lightweight linear-model descent) so different global/local search behaviors are balanced. Operator utilities are updated with exponential recency (success_exp=0.9) and sampled via a low initial softmax temperature (operator_temp=0.2) with occasional uniform exploration (3%), while an adaptive trust radius (trust_init=0.5, shrinks on failures, grows modestly on successes within [trust_min, trust_max]) controls step magnitudes and local refinement intensities. Directional information is cheaply estimated from the archive via a power-iteration principal axis and a least-squares linear gradient to produce directed proposals without extra evaluations, and occasional uniform injections (injection_period=23) prevent loss of coverage. Budget-awareness is enforced everywhere (never exceeding self.budget), candidates are clipped to bounds, and small local refinements and jitter terms (e.g. 0.12*trust*avg_span local steps, tiny Gaussian jitter) help escape flat traps and polish promising solutions.", "code": "import numpy as np\n\nclass AdaptiveDirectionalBanditSearch:\n    \"\"\"\n    Adaptive Directional Bandit Search (ADBS)\n\n    Key ideas:\n    - Keep a small sorted archive of evaluated elites.\n    - Use a bandit-style softmax over several complementary operators:\n        * principal-axis Levy jumps (anisotropic, heavy-tailed)\n        * mirror-reflection moves across best/worst\n        * Gaussian bandit moves around a weighted elite mean\n        * lightweight linear-model (finite-diff) descent step using archive info\n    - Maintain operator utilities updated by observed improvements (reward = f_before - f_after).\n    - Estimate a principal direction from elites (power iteration) and a local linear gradient\n      from differences (pseudo-inverse) to suggest directed steps without extra evaluations.\n    - Adaptive trust radius controls step magnitudes; success increases it, failure shrinks it.\n    - Budget-aware: never call func more than self.budget; all proposals are clipped to bounds.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 archive_size=None, init_samples=None,\n                 trust_init=0.5, trust_min=1e-4, trust_max=3.0,\n                 operator_temp=0.2, injection_period=23):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.archive_size = archive_size\n        self.init_samples = init_samples\n        self.trust_init = float(trust_init)\n        self.trust_min = float(trust_min)\n        self.trust_max = float(trust_max)\n        self.operator_temp = float(operator_temp)  # softmax temperature\n        self.injection_period = int(injection_period)\n\n        # outputs\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds (BBOB typical [-5,5] but use func.bounds if present)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # init sample counts and archive size\n        if self.init_samples is None:\n            init_samples = max(8, min(60, 4 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, max(1, self.budget // 6))\n\n        if self.archive_size is None:\n            archive_k = max(3, min(12, init_samples // 2))\n        else:\n            archive_k = int(self.archive_size)\n\n        # internal state\n        evals = 0\n        archive = []  # list of (f, x) sorted ascending by f\n        best_history = []\n\n        # operator definitions\n        operators = ['levy_axis', 'mirror', 'gauss_bandit', 'lin_model']\n        n_ops = len(operators)\n        # utilities / scores for bandit selection (exponential recency)\n        utilities = np.ones(n_ops, dtype=float)\n        op_counts = np.ones(n_ops, dtype=float)  # for stabilizing\n        success_exp = 0.9  # decay for utilities\n\n        # trust radius for model steps / general step scaling (in units of avg_span)\n        trust = float(self.trust_init)\n\n        # evaluation wrapper\n        f_best = np.inf\n        x_best = None\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            f = float(f)\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # insert into sorted archive\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # initial space-filling sampling (uniform)\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # fallback ensure at least one point\n        if len(archive) == 0 and evals < self.budget:\n            eval_and_record(rng.uniform(lb, ub))\n\n        # helper: principal axis estimation (power iteration on covariance of elites)\n        def estimate_principal_axis(k_use=6, n_iters=8):\n            if len(archive) < 2:\n                # fallback to random unit vector\n                v = rng.randn(self.dim)\n                v /= (np.linalg.norm(v) + 1e-12)\n                return v\n            k = min(k_use, len(archive))\n            pts = np.vstack([archive[i][1] for i in range(k)])\n            center = pts.mean(axis=0)\n            X = pts - center\n            # small regularization\n            C = (X.T @ X) / max(1.0, X.shape[0]) + 1e-8 * np.eye(self.dim)\n            # power iteration\n            v = rng.randn(self.dim)\n            v /= np.linalg.norm(v) + 1e-12\n            for _ in range(n_iters):\n                v = C @ v\n                nrm = np.linalg.norm(v) + 1e-12\n                v /= nrm\n            return v\n\n        # helper: lightweight linear gradient estimate around best using archive differences\n        def estimate_linear_gradient(k_use=None):\n            if len(archive) < 2:\n                return None\n            if k_use is None:\n                k_use = min(len(archive) - 1, 2 * self.dim)\n            # take k_use nearest to best (excluding best itself)\n            pts = np.vstack([p[1] for p in archive])\n            fs = np.array([p[0] for p in archive])\n            best_idx = 0\n            best_x = pts[best_idx].copy()\n            best_f = fs[best_idx]\n            if pts.shape[0] == 1:\n                return None\n            others = pts[1:k_use+1] if pts.shape[0] > 1 else np.empty((0, self.dim))\n            ff = fs[1:k_use+1] if pts.shape[0] > 1 else np.empty((0,))\n            if others.shape[0] == 0:\n                return None\n            D = others - best_x  # rows: samples\n            b = ff - best_f\n            # we approximate linear model b ≈ D * g\n            # solve least squares: g = pinv(D) @ b\n            try:\n                g = np.linalg.lstsq(D, b, rcond=None)[0]\n            except Exception:\n                # fallback\n                return None\n            if np.linalg.norm(g) < 1e-12:\n                return None\n            return g\n\n        # operator implementations (they only propose points using archive + RNG)\n        def op_levy_axis():\n            # heavy-tailed jump along principal axis + small orthogonal noise\n            axis = estimate_principal_axis(k_use= min(len(archive), 8))\n            center = archive[0][1] if len(archive) > 0 else rng.uniform(lb, ub)\n            # sample scalar Cauchy, clipped for safety\n            s = rng.standard_cauchy()\n            s = np.clip(s, -250.0, 250.0)\n            # scale proportional to trust and avg_span\n            scale = trust * avg_span * (0.8 + 0.8 * rng.rand())\n            # anisotropic: axis component scaled by larger factor\n            axis_part = axis * (1.5 * scale) * s\n            orth = rng.randn(self.dim)\n            # project out axis to keep orthogonal component small\n            orth -= np.dot(orth, axis) * axis\n            orth /= (np.linalg.norm(orth) + 1e-12)\n            orth_part = orth * (0.2 * scale) * rng.randn()\n            return center + axis_part + orth_part\n\n        def op_mirror():\n            # reflect from worst towards best with stochasticity\n            if len(archive) == 0:\n                return rng.uniform(lb, ub)\n            best = archive[0][1]\n            worst = archive[-1][1] if len(archive) > 1 else rng.uniform(lb, ub)\n            alpha = 0.6 + 0.8 * rng.rand()  # reflection strength\n            noise = 0.08 * avg_span * rng.randn(self.dim)\n            cand = best + alpha * (best - worst) + noise * (1.0 + 0.5 * rng.rand())\n            # occasional \"undershoot\" (move partly towards random elite)\n            if rng.rand() < 0.2 and len(archive) > 1:\n                idx = rng.randint(1, len(archive))\n                cand = 0.5 * (cand + archive[idx][1])\n            return cand\n\n        def op_gauss_bandit():\n            # sample around a weighted mean of elites with covariance derived from elites\n            if len(archive) == 0:\n                return rng.uniform(lb, ub)\n            k = min(len(archive), 6)\n            weights = np.array([np.exp(-i / max(1.0, k/2.0)) for i in range(k)], dtype=float)\n            weights /= weights.sum()\n            pts = np.vstack([archive[i][1] for i in range(k)])\n            mean = (weights[:, None] * pts).sum(axis=0)\n            # covariance approx from pts\n            X = pts - mean\n            cov = (X.T @ (X * weights[:, None])) + 1e-6 * np.eye(self.dim)\n            # sample Gaussian with some inflation by trust\n            L = np.linalg.cholesky(cov + 1e-8 * np.eye(self.dim))\n            z = L @ (rng.randn(self.dim) * (0.6 + 0.8 * trust))\n            return mean + z\n\n        def op_lin_model():\n            # create a candidate by taking a gradient-like step from best using archive information\n            if len(archive) == 0:\n                return rng.uniform(lb, ub)\n            g = estimate_linear_gradient()\n            center = archive[0][1]\n            if g is None:\n                # fallback to small gaussian around best\n                return center + 0.2 * avg_span * rng.randn(self.dim)\n            # normalized direction\n            ng = g / (np.linalg.norm(g) + 1e-12)\n            # step length scaled by trust and estimated linear curvature proxy:\n            # curvature proxy: mean of directional second differences along D rows\n            # we don't compute true curvature, just moderate the step length\n            step_mag = trust * avg_span * (0.6 + 0.8 * rng.rand())\n            cand = center - step_mag * ng\n            # add small isotropic jitter to escape flat traps\n            cand += 0.03 * avg_span * rng.randn(self.dim)\n            return cand\n\n        op_funcs = {\n            'levy_axis': op_levy_axis,\n            'mirror': op_mirror,\n            'gauss_bandit': op_gauss_bandit,\n            'lin_model': op_lin_model\n        }\n\n        # main loop\n        attempt = 0\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n\n            # occasionally inject uniform random sample to keep coverage\n            if (attempt % self.injection_period) == 0 and evals < self.budget:\n                eval_and_record(rng.uniform(lb, ub))\n\n            # select operator via softmax of utilities\n            logits = utilities / (self.operator_temp + 1e-12)\n            # numeric softmax\n            maxl = np.max(logits)\n            probs = np.exp(logits - maxl)\n            probs /= probs.sum()\n            op_idx = rng.choice(n_ops, p=probs)\n            op_name = operators[op_idx]\n            # exploration epsilon: small chance choose uniform\n            if rng.rand() < 0.03:\n                cand = rng.uniform(lb, ub)\n            else:\n                cand = op_funcs[op_name]()\n\n            # clip to bounds\n            cand = np.minimum(np.maximum(cand, lb), ub)\n\n            # remember previous best to compute reward\n            prev_best = f_best\n\n            # evaluate candidate\n            res = eval_and_record(cand)\n            if res is None:\n                break\n            f_new, x_new = res\n\n            # compute reward (improvement)\n            reward = max(0.0, prev_best - f_new)\n\n            # update operator utility with exponential recency weighting\n            utilities[op_idx] = success_exp * utilities[op_idx] + (1.0 - success_exp) * (reward + 1e-8)\n            op_counts[op_idx] += 1.0\n\n            # adapt trust based on success (if improvement relative to previous best)\n            if f_new < prev_best - 1e-12:\n                # success: enlarge trust moderately\n                trust = min(self.trust_max, trust * (1.02 + 0.02 * (reward / (abs(prev_best) + 1e-12))))\n            else:\n                # failure: shrink trust\n                trust = max(self.trust_min, trust * 0.94)\n\n            # additional local attempt: if candidate was promising (within a factor), do a short refinement\n            do_local = False\n            if f_new < prev_best * 1.02 and remaining > 2:\n                do_local = True\n            if do_local:\n                # propose small local gaussian around x_new scaled by trust\n                local_steps = min(3, remaining - 1)\n                base = x_new.copy()\n                base_f = f_new\n                for _ in range(local_steps):\n                    xp = base + 0.12 * trust * avg_span * rng.randn(self.dim)\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res2 = eval_and_record(xp)\n                    if res2 is None:\n                        break\n                    fp, xp = res2\n                    if fp < base_f:\n                        base = xp.copy()\n                        base_f = fp\n                        # reward the operator that led here\n                        utilities[op_idx] += 0.5 * (prev_best - fp)\n                # end small local loop\n\n            # update best_history for diagnostics / direction estimation\n            if x_best is not None:\n                best_history.append((evals, f_best))\n\n            # light adaptive temperature adjustment: if utilities concentrate, increase temp to explore\n            if np.std(utilities) < 1e-6:\n                self.operator_temp = max(0.05, self.operator_temp * 0.98)\n            else:\n                # nudge temperature slightly towards exploration when stagnating (no improvement for many evals)\n                if len(best_history) > 50:\n                    if best_history[-1][1] >= best_history[0][1] - 1e-12:\n                        self.operator_temp = min(1.0, self.operator_temp * 1.02)\n\n            # stop early if perfect zero reached (BBOB functions often have known minima but we don't assume)\n            if f_best <= 1e-12:\n                break\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDirectionalBanditSearch scored 0.346 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b6db7a7e-9699-49c0-ad02-a3fdafec2752", "operator": null, "metadata": {"aucs": [0.10621245248396183, 0.16061742932715128, 0.5963013044019685, 0.7655376170982691, 0.26572416690681055, 0.6889277240373604, 0.22419762244819574, 0.2844503887699694, 0.22434900920543577, 0.14340671725045817]}, "task_prompt": ""}
{"id": "36c4a1b1-3014-45c8-b983-d0aa5ce97039", "fitness": "-inf", "name": "EnsembleLevyCovarianceSearch", "description": "The algorithm is an ensemble-driven, budget-aware search that builds and maintains a sorted elite archive from a slightly enlarged initial space-filling sample (init_samples up to budget/3) to estimate diagonal covariances and guide sampling while always clipping to given bounds. It mixes three complementary operators with tuned weights (p_rand=0.45 favoring DE/rand-1 style recombination with a moderate F_init=0.6 and small Gaussian perturbation, p_levy=0.35 using Mantegna Lévy flights with beta≈1.5, anisotropic scaling and progress-dependent step decay, and p_local=0.20 sampling from a covariance-biased multivariate normal around a convex combination of the best and centroid). Promising candidates trigger a coordinate-wise local refinement (base_step = 0.15·span, milder expansion=1.2 and stronger shrink=0.5, pattern extension factor 1.3) with a reserved local_budget_frac (0.04) so local search is careful and budget-controlled. Adaptive mechanisms include operator-weight rebalancing based on elite diversity (favoring Lévy when elites collapse), modest self-adaptation of F, periodic uniform injections (inject_period=23) to restore diversity, and aggressive budget accounting to never exceed the evaluation limit.", "code": "import numpy as np\nimport math\n\nclass EnsembleLevyCovarianceSearch:\n    \"\"\"\n    Ensemble Levy–Covariance Search (ELCS)\n\n    Main configurable parameters (set in __init__, with defaults):\n    - budget: total function evaluations allowed\n    - dim: problem dimensionality\n    - rng_seed: random seed\n    - init_samples: initial space-filling samples (default chosen budget-aware)\n    - archive_size: number of elites to keep (default chosen from init samples)\n    - F_init: initial differential scale for rand-1 recombination (default 0.6)\n    - cr: (not heavily used) crossover probability\n    - levy_beta: stability parameter for Mantegna Levy flights (1 < beta <= 2)\n    - local_budget_frac: fraction of total budget to reserve for local refinements\n    - inject_period: how often to inject uniform samples to keep diversity\n    \"\"\"\n\n    def __init__(self,\n                 budget=10000,\n                 dim=10,\n                 rng_seed=None,\n                 init_samples=None,\n                 archive_size=None,\n                 F_init=0.6,\n                 cr=0.9,\n                 levy_beta=1.5,\n                 local_budget_frac=0.04,\n                 inject_period=23):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.F = float(F_init)\n        self.cr = float(cr)\n        self.levy_beta = float(levy_beta)\n        self.local_budget_frac = float(local_budget_frac)\n        self.inject_period = int(inject_period)\n\n        # will be set after run\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds (func.bounds.lb/ub might be scalar or arrays)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial sampling choices (different from original EDPS)\n        if self.init_samples is None:\n            # slightly larger initial sampling to build robust covariance estimate\n            init_samples = max(12, min(8 * self.dim, self.budget // 3))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, max(1, self.budget // 3))\n\n        # archive size chosen from init samples, different range\n        if self.archive_size is None:\n            archive_k = max(4, min(20, max(3, init_samples // 4)))\n        else:\n            archive_k = int(self.archive_size)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of tuples (f, x)\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # clip to bounds\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            f = float(f)\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # maintain sorted archive (ascending by f)\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # --- Initialization (space-filling random uniform) ---\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one evaluated point\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # initial local step sizes, different constants than EDPS\n        base_step = 0.15 * span  # smaller than EDPS's 0.25\n        base_step = np.maximum(base_step, 1e-9)\n        expand = 1.2    # milder expansion\n        shrink = 0.5    # stronger shrink\n        pattern_factor = 1.3\n\n        # operator base probabilities (different emphasis)\n        p_rand = 0.45   # rand-1 differential recombination\n        p_levy = 0.35   # Levy flights\n        p_local = 0.20  # local covariance-guided refinements\n\n        attempt = 0\n\n        # Precompute constants for Mantegna Levy\n        beta = max(1.01, min(2.0, self.levy_beta))\n        # sigma for numerator\n        num = math.gamma(1 + beta) * math.sin(math.pi * beta / 2.0)\n        den = math.gamma((1 + beta) / 2.0) * beta * (2 ** ((beta - 1) / 2.0))\n        sigma_u = (num / den) ** (1.0 / beta)\n\n        def mantegna_levy_step(scale):\n            # returns a vector levy step (dimension self.dim)\n            # component-wise Mantegna: u ~ N(0, sigma_u^2), v ~ N(0,1) => step = u / |v|^(1/beta)\n            u = rng.normal(0, sigma_u, size=self.dim)\n            v = rng.normal(0, 1.0, size=self.dim)\n            step = u / (np.abs(v) ** (1.0 / beta) + 1e-12)\n            return step * scale\n\n        def rand1_diff_candidate():\n            # DE/rand/1 style recombination but center biases towards random elite subset average\n            if len(archive) < 3:\n                return rng.uniform(lb, ub)\n            # pick three distinct indices among archive (uniform)\n            idxs = rng.choice(len(archive), size=3, replace=False)\n            x1 = archive[idxs[0]][1]\n            x2 = archive[idxs[1]][1]\n            x3 = archive[idxs[2]][1]\n            cand = x1 + self.F * (x2 - x3)\n            # add small gaussian with covariance from archive diagonal variances\n            if len(archive) >= 2:\n                arr = np.vstack([a[1] for a in archive])\n                diagvar = np.var(arr, axis=0) + 1e-12\n                cand += 0.03 * rng.randn(self.dim) * np.sqrt(diagvar)\n            else:\n                cand += 0.03 * rng.randn(self.dim) * span\n            return cand\n\n        def levy_candidate():\n            # Levy flight centered at a selected elite (mostly best)\n            if len(archive) == 0:\n                center = rng.uniform(lb, ub)\n            else:\n                if rng.rand() < 0.8:\n                    center = archive[0][1]\n                else:\n                    center = archive[rng.randint(0, len(archive))][1]\n            # scale decays with progress (different decay than EDPS)\n            progress = evals / max(1, self.budget)\n            scale = max(0.02, 1.0 - progress * 0.95)\n            # anisotropy by per-dim span and small random factor\n            anis = (0.5 + rng.rand(self.dim) * 0.8)\n            step = mantegna_levy_step(scale * avg_span) * anis\n            return center + step\n\n        def covariance_guided_candidate():\n            # sample from multivariate normal with diagonal covariance estimated from archive,\n            # mean biased to a convex combination of best and archive centroid\n            if len(archive) == 0:\n                return rng.uniform(lb, ub)\n            arr = np.vstack([a[1] for a in archive])\n            centroid = np.mean(arr, axis=0)\n            mean = 0.7 * archive[0][1] + 0.3 * centroid\n            diagvar = np.var(arr, axis=0) + 1e-12\n            scale = 0.12 + 0.6 * (1.0 - (evals / max(1, self.budget)))  # larger early, smaller later\n            cand = mean + scale * rng.randn(self.dim) * np.sqrt(diagvar + 1e-12)\n            return cand\n\n        def local_coordinate_refine(x_start, f_start, local_budget):\n            # coordinate-wise randomized refinement with pattern extension (smaller steps than EDPS)\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            steps = base_step.copy()\n            local_used = 0\n            # allow several passes but respect local_budget\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_used < local_budget and iters < iter_limit and np.any(steps > 1e-13):\n                iters += 1\n                improved = False\n                x_probe = base.copy()\n                x_probe_f = base_f\n                order = list(range(self.dim))\n                rng.shuffle(order)\n                for i in order:\n                    if local_used >= local_budget or evals >= self.budget:\n                        break\n                    # try positive direction\n                    xp = x_probe.copy()\n                    xp[i] += steps[i]\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res = eval_and_record(xp)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < x_probe_f:\n                        x_probe = xp.copy()\n                        x_probe_f = fp\n                        steps[i] *= expand\n                        improved = True\n                        continue\n                    # try negative direction\n                    xn = x_probe.copy()\n                    xn[i] -= steps[i]\n                    xn = np.minimum(np.maximum(xn, lb), ub)\n                    res = eval_and_record(xn)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < x_probe_f:\n                        x_probe = xn.copy()\n                        x_probe_f = fn\n                        steps[i] *= expand\n                        improved = True\n                # pattern extension (milder)\n                if improved and local_used < local_budget and evals < self.budget:\n                    direction = x_probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_and_record(xp)\n                        local_used += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < x_probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = x_probe.copy()\n                                base_f = x_probe_f\n                        else:\n                            base = x_probe.copy()\n                            base_f = x_probe_f\n                    else:\n                        base = x_probe.copy()\n                        base_f = x_probe_f\n                else:\n                    steps *= shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # Helper: estimate diversity among elites (mean pairwise dist or max-min)\n        def elite_diversity():\n            if len(archive) <= 1:\n                return avg_span\n            arr = np.vstack([a[1] for a in archive])\n            # use average pairwise L2 distance (downscaled)\n            # to be efficient, compute pairwise via broadcasting for moderate archive_k\n            diffs = arr[None, :, :] - arr[:, None, :]\n            dists = np.sqrt(np.sum(diffs ** 2, axis=2))\n            # take upper triangle mean\n            n = arr.shape[0]\n            if n <= 1:\n                return avg_span\n            iu = np.triu_indices(n, k=1)\n            mean_pair = np.mean(dists[iu])\n            return mean_pair\n\n        # Main loop\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            # dynamic local allocation, reserved fraction\n            alloc_local = min(max(2, int(self.local_budget_frac * self.budget)), remaining - 1) if remaining > 1 else 0\n\n            # adapt operator weights using diversity (different rule than EDPS)\n            div = elite_diversity()\n            # if diversity low -> favor Levy (big jumps) and increase F\n            norm_div = div / (avg_span + 1e-12)\n            p_levy_adj = p_levy * (1.0 + 0.9 * (1.0 - min(1.0, norm_div)))\n            p_rand_adj = p_rand * (0.9 + 0.4 * min(1.0, norm_div))\n            # keep local modest but slightly larger when diversity medium\n            p_local_adj = p_local * (1.0 + 0.3 * (0.5 - abs(0.5 - min(1.0, norm_div))))\n            # normalize to 1\n            s = p_levy_adj + p_rand_adj + p_local_adj\n            p_levy_adj /= s\n            p_rand_adj /= s\n            p_local_adj /= s\n\n            r = rng.rand()\n            done_local_search = False\n\n            # choose operator\n            if r < p_rand_adj:\n                cand = rand1_diff_candidate()\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n                # if promising relative improvement, refine locally\n                if alloc_local > 0 and f_cand <= (archive[0][0] * 0.995 if archive else np.inf):\n                    local_budget = min(remaining - 1, max(2, alloc_local))\n                    f_after, x_after = local_coordinate_refine(cand, f_cand, local_budget)\n                    done_local_search = True\n            elif r < p_rand_adj + p_levy_adj:\n                cand = levy_candidate()\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n                # larger local refinement if significantly better or sometimes by chance\n                cond = (alloc_local > 0 and (f_cand <= (archive[0][0] * 1.02 if archive else np.inf)))\n                if cond:\n                    local_budget = min(remaining - 1, max(3, 4 * alloc_local))\n                    f_after, x_after = local_coordinate_refine(cand, f_cand, local_budget)\n                    done_local_search = True\n            else:\n                cand = covariance_guided_candidate()\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n                # always allow a small local probe after covariance sampling if budget permits\n                if alloc_local > 0:\n                    local_budget = min(remaining - 1, max(2, int(0.6 * alloc_local)))\n                    f_after, x_after = local_coordinate_refine(cand, f_cand, local_budget)\n                    done_local_search = True\n\n            # occasional uniform injection to keep diversity (different period than EDPS)\n            if (attempt % self.inject_period) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # adaptive F adjustment (different dynamics)\n            if len(archive) >= 2:\n                div_now = elite_diversity()\n                if div_now < 0.03 * avg_span:\n                    # elites collapsed -> increase F moderately\n                    self.F = min(1.2, self.F * 1.04)\n                else:\n                    # otherwise slowly decay towards baseline\n                    self.F = max(0.4, self.F * 0.995)\n\n            # stop if budget used\n            if evals >= self.budget:\n                break\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 131, in __call__, the following error occurred:\nNameError: name 'math' is not defined\nOn line: num = math.gamma(1 + beta) * math.sin(math.pi * beta / 2.0)", "error": "In the code, line 131, in __call__, the following error occurred:\nNameError: name 'math' is not defined\nOn line: num = math.gamma(1 + beta) * math.sin(math.pi * beta / 2.0)", "parent_ids": "b6db7a7e-9699-49c0-ad02-a3fdafec2752", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "aa6387f9-fdf1-4563-8d77-cdfb5274162a", "fitness": 0.47196126773397645, "name": "AEPD", "description": "The algorithm is an adaptive ensemble around a small elite archive: it keeps the best-k solutions (archive_size ~ 3–12) from an initial space-filling sampling (init_samples = min(max(12,6*dim), budget/4)) and uses a recency-weighted credit scheme (decay=0.9) to select among four complementary operators. Operators are designed and tuned for different scales: a best‑biased differential recombination (base_F=0.8) with F adapted by archive spread, anisotropic heavy‑tailed Cauchy jumps whose step scale decays as budget is used (min scale ≈0.03), and a Gaussian local exploiter (base_gauss_scale=0.06) that also shrinks over time. Intensive local refinement is provided by a Hooke–Jeeves–style per‑dimension pattern search using base_step = 0.18*span with shrink=0.6, expand=1.3 and pattern_factor=1.5, and a small budget fraction for local searches (local_budget_frac≈0.03). The design is budget‑aware and safe (strict eval counting, bound clipping), occasionally injects uniform restarts (every 17 attempts), and nudges operator scores based on measured improvement and archive clustering to balance global exploration and local exploitation.", "code": "import numpy as np\n\nclass AEPD:\n    \"\"\"\n    Adaptive Ensemble Pattern-Differential (AEPD)\n\n    - Maintains a small elite archive.\n    - Uses 4 complementary operators:\n        * differential recombination (best-biased)\n        * anisotropic heavy-tailed Cauchy jumps\n        * Gaussian exploitation around elites\n        * Hooke-Jeeves-like per-dimension local pattern search\n    - Operator selection uses a recency-weighted credit/score scheme (adaptive bandit-like).\n    - Adapts differential scale F and Cauchy scale from measured archive spread.\n    - Budget-aware: never exceeds self.budget and clips to bounds.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 init_samples=None, archive_size=None, local_budget_frac=0.03):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.local_budget_frac = float(local_budget_frac)\n\n        # Result placeholders\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds (support scalar or array)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive init samples & archive size\n        if self.init_samples is None:\n            init_samples = max(12, min(60, 6 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, max(1, self.budget // 4))\n\n        if self.archive_size is None:\n            archive_k = max(3, min(12, init_samples // 3))\n        else:\n            archive_k = int(self.archive_size)\n\n        # budget & recorders\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of tuples (f, x)\n\n        # operator credit tracking (recency-weighted)\n        op_names = ['diff', 'cauchy', 'gauss', 'local']\n        op_score = {op: 1e-6 for op in op_names}  # smoothed score (higher -> more selected)\n        op_count = {op: 0 for op in op_names}\n        decay = 0.9  # recency weight for score updates\n\n        # baseline params\n        base_F = 0.8\n        base_gauss_scale = 0.06  # fraction of span\n        inject_period = 17\n\n        # local search base step (per-dim), will be scaled adaptively\n        base_step = 0.18 * span\n        base_step = np.maximum(base_step, 1e-8)\n\n        # local search params\n        shrink = 0.6\n        expand = 1.3\n        pattern_factor = 1.5\n        tol = 1e-12\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            f = float(f)\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # archive maintenance\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # initial space-filling sampling\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one point\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # helper: measure elite spread (Euclidean between best and worst in archive)\n        def archive_spread():\n            if len(archive) >= 2:\n                return np.linalg.norm(archive[0][1] - archive[-1][1])\n            else:\n                return np.linalg.norm(span)\n\n        # operators\n        def differential_recombination():\n            # return candidate and number of function evaluations performed by this operator (0 here; evals done externally)\n            if len(archive) < 3:\n                return rng.uniform(lb, ub)\n            # select indices: a (best-biased), b, c distinct\n            idxs = list(range(len(archive)))\n            a_idx = 0 if rng.rand() < 0.75 else rng.randint(0, len(archive))\n            idxs.remove(a_idx)\n            b_idx = rng.choice(idxs)\n            idxs.remove(b_idx)\n            c_idx = rng.choice(idxs)\n            a = archive[a_idx][1]\n            b = archive[b_idx][1]\n            c = archive[c_idx][1]\n            # adapt F using archive spread (more F if clustered)\n            spread = archive_spread()\n            F_loc = base_F * (1.0 + 0.6 * np.exp(-spread / (avg_span + 1e-12)))\n            cand = a + F_loc * (b - c)\n            # small jitter scaled by per-dim span\n            cand += 0.03 * (rng.randn(self.dim) * span)\n            return cand\n\n        def cauchy_jump():\n            # pick a center (best-biased)\n            if len(archive) == 0:\n                center = rng.uniform(lb, ub)\n            else:\n                center = archive[0][1] if rng.rand() < 0.75 else archive[rng.randint(0, len(archive))][1]\n            # scale decays as budget used\n            frac_used = evals / max(1, self.budget)\n            scale = max(0.03, 1.0 - 0.9 * frac_used)\n            # direction & anisotropy\n            direction = rng.randn(self.dim)\n            direction /= (np.linalg.norm(direction) + 1e-12)\n            anis = 0.4 + 0.6 * rng.rand()\n            step = direction * (scale * avg_span * anis)\n            # heavy-tailed length\n            length = rng.standard_cauchy()\n            length = np.clip(length, -1e3, 1e3)\n            cand = center + length * step\n            return cand\n\n        def gauss_exploit():\n            if len(archive) == 0:\n                center = rng.uniform(lb, ub)\n            else:\n                # bias to best but occasionally another elite\n                center = archive[0][1] if rng.rand() < 0.8 else archive[rng.randint(0, len(archive))][1]\n            # small gaussian perturbation proportional to span (exploitation)\n            scale = base_gauss_scale * (1.0 - evals / max(1, self.budget) * 0.8)\n            cand = center + rng.randn(self.dim) * (scale * span)\n            return cand\n\n        def local_pattern_search(x_start, f_start, local_budget):\n            # Hooke-Jeeves-like per-dim adaptive search; returns (best_f, best_x, evals_used)\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start, 0\n            base = np.asarray(x_start, dtype=float).copy()\n            base_f = float(f_start)\n            steps = base_step.copy()\n            used = 0\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while used < local_budget and iters < iter_limit and np.any(steps > tol):\n                iters += 1\n                improved = False\n                probe = base.copy()\n                probe_f = base_f\n                order = list(range(self.dim))\n                rng.shuffle(order)\n                for i in order:\n                    if used >= local_budget or evals >= self.budget:\n                        break\n                    # positive trial\n                    xp = probe.copy()\n                    xp[i] += steps[i]\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res = eval_and_record(xp)\n                    used += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < probe_f:\n                        probe = xp.copy()\n                        probe_f = fp\n                        improved = True\n                        steps[i] *= expand\n                        continue\n                    # negative trial\n                    xn = probe.copy()\n                    xn[i] -= steps[i]\n                    xn = np.minimum(np.maximum(xn, lb), ub)\n                    res = eval_and_record(xn)\n                    used += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < probe_f:\n                        probe = xn.copy()\n                        probe_f = fn\n                        improved = True\n                        steps[i] *= expand\n                # pattern move if improved\n                if improved and used < local_budget and evals < self.budget:\n                    direction = probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_and_record(xp)\n                        used += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = probe.copy()\n                                base_f = probe_f\n                        else:\n                            base = probe.copy()\n                            base_f = probe_f\n                    else:\n                        base = probe.copy()\n                        base_f = probe_f\n                else:\n                    steps *= shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base, used\n\n        # main loop: adaptive operator selection via op_score\n        attempt = 0\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            # dynamic allocation of local budget for promising cases\n            max_local_alloc = min(max(3, int(self.local_budget_frac * self.budget)), max(1, remaining - 1))\n            # compute selection probabilities (softmax-like but simple proportional)\n            scores = np.array([op_score[op] for op in op_names])\n            # add small exploration floor\n            scores = scores + 1e-6\n            probs = scores / np.sum(scores)\n            # choose operator\n            r = rng.rand()\n            cum = 0.0\n            choice = op_names[-1]\n            for i, p in enumerate(probs):\n                cum += p\n                if r < cum:\n                    choice = op_names[i]\n                    break\n\n            # baseline f before operator\n            f_before = f_best\n            x_before = x_best.copy() if x_best is not None else None\n\n            used_by_op = 0\n            best_f_after = f_before\n            best_x_after = x_before.copy() if x_before is not None else None\n\n            if choice == 'diff':\n                cand = differential_recombination()\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, x_cand = res\n                best_f_after = f_cand\n                best_x_after = x_cand.copy()\n                used_by_op = 1\n                # small local refinement if promising\n                threshold = (archive[0][0] * 1.05) if len(archive) > 0 else np.inf\n                if max_local_alloc > 0 and f_cand <= threshold and remaining > 2:\n                    local_budget = min(remaining - 1, int(3 * max_local_alloc))\n                    f_loc, x_loc, used_loc = local_pattern_search(x_cand, f_cand, local_budget)\n                    used_by_op += used_loc\n                    if f_loc < best_f_after:\n                        best_f_after = f_loc\n                        best_x_after = x_loc.copy()\n\n            elif choice == 'cauchy':\n                cand = cauchy_jump()\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, x_cand = res\n                best_f_after = f_cand\n                best_x_after = x_cand.copy()\n                used_by_op = 1\n                # local refine if promising\n                threshold = (archive[0][0] * 1.12) if len(archive) > 0 else np.inf\n                if max_local_alloc > 0 and f_cand <= threshold and remaining > 2:\n                    local_budget = min(remaining - 1, int(3 * max_local_alloc))\n                    f_loc, x_loc, used_loc = local_pattern_search(x_cand, f_cand, local_budget)\n                    used_by_op += used_loc\n                    if f_loc < best_f_after:\n                        best_f_after = f_loc\n                        best_x_after = x_loc.copy()\n\n            elif choice == 'gauss':\n                cand = gauss_exploit()\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, x_cand = res\n                best_f_after = f_cand\n                best_x_after = x_cand.copy()\n                used_by_op = 1\n                # tiny local polish sometimes\n                if max_local_alloc > 0 and rng.rand() < 0.25 and remaining > 2:\n                    local_budget = min(remaining - 1, int(1 * max_local_alloc))\n                    f_loc, x_loc, used_loc = local_pattern_search(x_cand, f_cand, local_budget)\n                    used_by_op += used_loc\n                    if f_loc < best_f_after:\n                        best_f_after = f_loc\n                        best_x_after = x_loc.copy()\n\n            else:  # local\n                # choose start: best, random elite, or jittered restart\n                choice_local = rng.rand()\n                if len(archive) > 0 and choice_local < 0.66:\n                    start_f, start_x = archive[0]\n                elif len(archive) > 1 and choice_local < 0.95:\n                    idx = rng.randint(0, len(archive))\n                    start_f, start_x = archive[idx]\n                else:\n                    if x_best is not None and rng.rand() < 0.9:\n                        jitter = 0.12 * avg_span * rng.randn(self.dim)\n                        start_x = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                    else:\n                        start_x = rng.uniform(lb, ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                # allocate local budget\n                local_budget = min(max_local_alloc, max(2, int(0.05 * remaining)))\n                f_loc, x_loc, used_loc = local_pattern_search(start_x, start_f, local_budget)\n                used_by_op = used_loc\n                best_f_after = f_loc\n                best_x_after = x_loc.copy()\n\n            # compute observed improvement for this operator (positive = improvement)\n            improv = max(0.0, f_before - best_f_after)\n            # update op_score recency-weighted\n            op_score[choice] = decay * op_score[choice] + (1.0 - decay) * (improv + 1e-8)\n            op_count[choice] += 1\n\n            # occasional uniform injection\n            if (attempt % inject_period) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # if archive is too clustered, boost Cauchy & diff scores a bit\n            spread = archive_spread()\n            if spread < 0.02 * avg_span:\n                # encourage global exploration\n                op_score['cauchy'] *= 1.02\n                op_score['diff'] *= 1.01\n            else:\n                # slightly decay aggressive bias\n                for op in op_names:\n                    op_score[op] *= 0.9995\n\n            # safety break if budget exhausted\n            if evals >= self.budget:\n                break\n\n        # finish\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AEPD scored 0.472 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b6db7a7e-9699-49c0-ad02-a3fdafec2752", "operator": null, "metadata": {"aucs": [0.11701560113954834, 0.1488639912085683, 0.9750805540865966, 0.9903849750819269, 0.24693682451032395, 0.985877373708313, 0.22093560581909022, 0.5742866834932953, 0.29119550668756766, 0.16903556160453492]}, "task_prompt": ""}
{"id": "a8c09e6a-b14f-48a4-ad48-92f109ec22d1", "fitness": 0.4004289602281698, "name": "AMES_TR", "description": "AMES-TR combines mirrored/antithetic sampling and an elite-weighted mean to generate efficient, variance-reduced candidate directions while keeping a moderate population size (lam ~ max(12, 6+2√dim)).  \nEach candidate is processed by an adaptive operator pool (gaussian_local, trust_local, elite_recomb, levy_escape) whose success-driven credits (decay ~0.9) bias future choices, and every population slot maintains a per-slot trust radius (init ~0.15·range, expand 1.15, shrink 0.85) to focus local search or enable escapes.  \nGlobal structure borrows CMA-style covariance learning with conservative learning rates (c1=0.12, cmu=0.06) plus a rank‑1 evolution path and an RMS-based sigma adaptation (target diversity 0.30, alpha_sigma 0.6) for robust step-size control, with SPD corrections for C and reflect-then-clamp bound handling.  \nPractical resilience comes from an archive/elite recombination, opportunistic extrapolation after successful replacements, periodic local polishing, and soft restarts on stagnation to recover global exploration.", "code": "import numpy as np\n\nclass AMES_TR:\n    \"\"\"\n    Adaptive Mirrored Evolution Strategy with Trust-regions and Adaptive Operator Pool (AMES-TR)\n\n    Main ideas:\n    - Mirrored (antithetic) sampling for evaluation efficiency (from AMES).\n    - Per-candidate operator pool (gaussian_local, trust_local, elite_recomb, levy_escape), with adaptive op credits.\n    - Per-candidate trust radius that expands on success and shrinks on failure.\n    - Covariance (C) updated by rank-1 evolution path and rank-mu term; sigma adapted from normalized spread.\n    - Opportunistic extrapolation after successful moves and periodic local polishing around x_best.\n    - Reflect-then-clamp bounds handling, SPD corrections for C, and soft restarts on stagnation.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 init_radius_frac=0.15,\n                 min_radius_frac=1e-6,\n                 radius_expand=1.15,\n                 radius_shrink=0.85,\n                 levy_scale_frac=0.5,\n                 op_credit_decay=0.9,\n                 local_period=30,\n                 stagn_threshold_frac=0.02,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        # trust radius params\n        self.init_radius_frac = float(init_radius_frac)\n        self.min_radius_frac = float(min_radius_frac)\n        self.radius_expand = float(radius_expand)\n        self.radius_shrink = float(radius_shrink)\n        # levy/op pool\n        self.levy_scale_frac = float(levy_scale_frac)\n        self.op_credit_decay = float(op_credit_decay)\n        # local polishing & stagnation\n        self.local_period = int(local_period)\n        self.stagn_threshold_frac = float(stagn_threshold_frac)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds (BBOB: usually -5..5)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        range_mean = float(np.mean(ub - lb))\n        # population size similar to AMES but small-to-moderate\n        if self.pop_base is None:\n            lam = max(12, int(6 + 2 * np.sqrt(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        evals = 0\n\n        # mirrored-opposition initialization for a small initial population\n        half = (lam + 1) // 2\n        X = np.empty((lam, self.dim), dtype=float)\n        center = 0.5 * (lb + ub)\n        for i in range(half):\n            u = rng.rand(self.dim)\n            X[i] = lb + u * (ub - lb)\n            j = i + half\n            if j < lam:\n                X[j] = 2.0 * center - X[i]\n        X += rng.randn(lam, self.dim) * 1e-3 * (ub - lb)\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        f = np.full(lam, np.inf, dtype=float)\n        for i in range(lam):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        # fallback if budget exhausted during init\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-individual trust radii (relative absolute scale)\n        init_radius = max(1e-12, self.init_radius_frac * range_mean)\n        min_radius = max(1e-12, self.min_radius_frac * range_mean)\n        radius = np.full(lam, init_radius, dtype=float)\n\n        # covariance and sigma initializations (conservative)\n        span = ub - lb\n        init_scale = (span / 8.0)\n        C = np.diag((init_scale ** 2).clip(min=1e-12))\n        sigma = 0.15 * np.mean(span)\n\n        # operator pool: 0=gaussian_local,1=trust_local,2=elite_recomb,3=levy_escape\n        n_ops = 4\n        op_credit = np.ones(n_ops, dtype=float)\n        def op_probabilities():\n            s = np.sum(op_credit)\n            if s <= 0:\n                return np.full_like(op_credit, 1.0 / len(op_credit))\n            return op_credit / s\n\n        # helper: reflect then clamp\n        def reflect_clamp(x):\n            x_ref = np.asarray(x, dtype=float).copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # cauchy/levy step generator (coordinate-wise scaled)\n        def cauchy_step(scale):\n            # use standard cauchy scaled; avoid infinities by clipping\n            s = rng.standard_cauchy(self.dim) * scale\n            s = np.clip(s, -1e3 * scale, 1e3 * scale)\n            return s\n\n        # small elite archive (keeps top points)\n        archive_X = X.copy()\n        archive_f = f.copy()\n\n        def archive_add(x_new, f_new):\n            nonlocal archive_X, archive_f\n            archive_X = np.vstack([archive_X, x_new[np.newaxis, :]])\n            archive_f = np.concatenate([archive_f, np.array([f_new], dtype=float)])\n            max_archive = max(4 * lam, lam + 10)\n            if archive_X.shape[0] > max_archive:\n                order = np.argsort(archive_f)\n                keep = order[:max_archive]\n                archive_X = archive_X[keep]\n                archive_f = archive_f[keep]\n\n        # track best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        # evolution path for rank-1 updates\n        p = np.zeros(self.dim, dtype=float)\n\n        gen = 0\n        gens_since_improve = 0\n        stagn_limit = max(5, int(self.stagn_threshold_frac * self.budget))\n\n        # helper to ensure SPD of C\n        def ensure_spd(Cmat):\n            # small jitter then attempt Cholesky, fallback to eigenvalue clipping\n            jitter = 1e-12 * (np.abs(np.diag(Cmat)) + 1.0)\n            try:\n                np.linalg.cholesky(Cmat + np.diag(jitter))\n                return Cmat\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(Cmat)\n                vals = np.clip(vals, 1e-12, None)\n                return (vecs * vals) @ vecs.T\n\n        # op credit updater\n        def update_op_credit(old, succ_counts, decay):\n            new = old * decay + succ_counts * (1.0 - decay) * float(lam)\n            new = np.maximum(new, 1e-8)\n            return new\n\n        # main loop: generate mirrored candidates in batches and apply operators\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # prepare SPD factor A via eig/cholesky\n            try:\n                A = np.linalg.cholesky(C + np.eye(self.dim) * 1e-12)\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n\n            # generate lam candidate directions (mirrored where possible)\n            lam_iter = min(lam, self.budget - evals)  # ensure we don't plan more than budget left\n            half_gen = lam_iter // 2\n            odd = (lam_iter % 2) != 0\n            Ys = []\n            for _ in range(half_gen):\n                z = rng.randn(self.dim)\n                y = z @ A.T\n                Ys.append(y)\n                Ys.append(-y)\n            if odd:\n                z = rng.randn(self.dim)\n                Ys.append(z @ A.T)\n            Ys = np.vstack(Ys)[:lam_iter]\n\n            # operator stats this generation\n            op_try = np.zeros(n_ops, dtype=float)\n            op_succ = np.zeros(n_ops, dtype=float)\n            probs = op_probabilities()\n\n            # produce candidates by applying operator-specific perturbation to mirrored samples around mean m\n            # compute current mean m as weighted mean of top-half of population\n            order_pop = np.argsort(f)\n            mu = max(1, lam // 2)\n            elites = X[order_pop[:mu]]\n            weights = np.linspace(mu, 1, mu)\n            weights = np.maximum(weights, 1e-12)\n            weights = weights / np.sum(weights)\n            m = (weights.reshape(-1, 1) * elites).sum(axis=0)\n\n            candidates = []\n            cand_ops = []\n            parent_idxs = []\n            for i in range(lam_iter):\n                if evals >= self.budget:\n                    break\n                y = Ys[i]\n                # base candidate from mirrored sampling\n                base = m + sigma * y\n                base = reflect_clamp(base)\n\n                # choose operator\n                op = rng.choice(n_ops, p=probs)\n                op_try[op] += 1.0\n\n                cand = base.copy()\n\n                # 0: gaussian_local - small isotropic perturb around base, scaled by radius heuristic\n                if op == 0:\n                    scale = 0.6 * np.mean(radius) * (0.5 + rng.rand())\n                    cand = base + rng.randn(self.dim) * scale\n\n                # 1: trust_local - use per-indexed trust radius (map to some index via i%lam)\n                elif op == 1:\n                    idx = i % lam\n                    r = radius[idx]\n                    cand = base + rng.randn(self.dim) * r\n\n                # 2: elite_recomb - recombine with a random archive/elite point plus small gaussian\n                elif op == 2:\n                    if archive_X.shape[0] > 0:\n                        elite_idx = int(rng.randint(0, archive_X.shape[0]))\n                        alpha = 0.4 + 0.6 * rng.rand()\n                        cand = base + alpha * (archive_X[elite_idx] - base) + rng.randn(self.dim) * 0.15 * np.mean(radius)\n                    else:\n                        cand = base + rng.randn(self.dim) * 0.2 * np.mean(radius)\n\n                # 3: levy_escape - heavy-tailed jump centered on best or base\n                elif op == 3:\n                    center = x_best if rng.rand() < 0.75 else base\n                    scale = self.levy_scale_frac * np.mean(radius) * (1.0 + rng.rand())\n                    cand = center + cauchy_step(scale)\n\n                # reflect/clamp\n                cand = reflect_clamp(cand)\n                candidates.append(cand)\n                cand_ops.append(op)\n                parent_idxs.append(i % lam)\n\n            # evaluate candidates (one by one to allow opportunistic extrapolation)\n            cand_f = []\n            for idx_c, cand in enumerate(candidates):\n                if evals >= self.budget:\n                    break\n                f_c = float(func(cand))\n                evals += 1\n                cand_f.append(f_c)\n\n                # replacement logic: if candidate better than worst in population, replace worst\n                worst_idx = int(np.argmax(f))\n                replaced = False\n                if f_c < f[worst_idx]:\n                    # replace worst\n                    X[worst_idx] = cand.copy()\n                    f[worst_idx] = f_c\n                    archive_add(cand, f_c)\n                    op = cand_ops[idx_c]\n                    op_succ[op] += 1.0\n                    replaced = True\n                    # expand radius of replaced index (we treat replaced slot as a success receiver)\n                    radius[worst_idx] = min(max(radius[worst_idx] * self.radius_expand, min_radius), range_mean)\n                    # opportunistic extrapolation along displacement from m (if space and budget)\n                    if evals < self.budget:\n                        disp = cand - m\n                        if np.linalg.norm(disp) > 1e-12:\n                            extra_frac = 0.5 * rng.rand() + 0.2\n                            extra = cand + extra_frac * disp\n                            extra = reflect_clamp(extra)\n                            if evals < self.budget:\n                                f_extra = float(func(extra)); evals += 1\n                                if f_extra < f[worst_idx]:\n                                    # accept extrapolation into same replaced slot\n                                    X[worst_idx] = extra.copy()\n                                    f[worst_idx] = f_extra\n                                    archive_add(extra, f_extra)\n                                    # further expand radius for that slot\n                                    radius[worst_idx] = min(radius[worst_idx] * (1.0 + 0.04 * extra_frac), range_mean)\n                                    f_c = f_extra  # treat extrapolation as the candidate outcome\n                    # update global best\n                    if f_c < f_best:\n                        f_best = f_c\n                        x_best = X[worst_idx].copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # failure: shrink a corresponding trust radius (use parent slot map)\n                    idx_parent = parent_idxs[idx_c]\n                    radius[idx_parent] = max(radius[idx_parent] * self.radius_shrink, min_radius)\n\n                # small bookkeeping: if not replaced but still better than some median, still update archive\n                if not replaced and f_c < np.median(f):\n                    archive_add(cand, f_c)\n                # early break on budget\n                if evals >= self.budget:\n                    break\n\n            # Update op credits with decay\n            op_credit = update_op_credit(op_credit, op_succ, self.op_credit_decay)\n\n            # selection: recompute best sync with population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                improved_in_gen = True\n                gens_since_improve = 0\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n            else:\n                gens_since_improve = 0\n\n            # Covariance and sigma updates based on current population (like AMES)\n            # select top mu from current population\n            order = np.argsort(f)\n            mu = max(1, lam // 2)\n            X_mu = X[order[:mu]]\n            weights = np.linspace(mu, 1, mu)\n            weights = np.maximum(weights, 1e-12)\n            weights = weights / np.sum(weights)\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized steps y = (X_i - m) / sigma (use old m)\n            y_steps = (X_mu - m_new) / (sigma + 1e-20)\n            W = weights.reshape(-1, 1)\n            cov_mu = (W * y_steps).T @ y_steps\n\n            # evolution path update (rank-1)\n            y_w = (W * y_steps).sum(axis=0)\n            mu_eff = (np.sum(weights))**2 / np.sum(weights**2)\n            c_p = 2.0 / (self.dim + 2.0)\n            p = (1.0 - c_p) * p + np.sqrt(c_p * (2.0 - c_p) * mu_eff) * y_w\n\n            # covariance mixing: keep relative small learning rates to maintain robustness\n            c1 = 0.12\n            cmu = 0.06\n            coef_fix = max(0.0, 1.0 - c1 - cmu)\n            C = coef_fix * C + c1 * np.outer(p, p) + cmu * cov_mu\n            C = ensure_spd(C)\n\n            # sigma adaptation via normalized RMS length heuristic (encourage target spread)\n            y_all = (X - m_new) / (sigma + 1e-20)\n            norm_rms = np.sqrt(np.mean(np.sum(y_all**2, axis=1)) / max(1.0, float(self.dim)))\n            diversity_target = 0.30\n            alpha_sigma = 0.6\n            sigma *= np.exp(alpha_sigma * (diversity_target - norm_rms))\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(span))\n\n            # update mean\n            m = m_new.copy()\n\n            # periodic local polishing around current best\n            if (gen % self.local_period == 0) and (evals < self.budget):\n                local_iters = min(6, (self.budget - evals))\n                local_sigma = max(min_radius, 0.5 * np.mean(radius))\n                for _ in range(local_iters):\n                    if evals >= self.budget:\n                        break\n                    cand = reflect_clamp(x_best + rng.randn(self.dim) * local_sigma)\n                    f_c = float(func(cand)); evals += 1\n                    if f_c < f_best:\n                        f_best = f_c\n                        x_best = cand.copy()\n                        # replace worst\n                        worst_idx = int(np.argmax(f))\n                        X[worst_idx] = cand.copy()\n                        f[worst_idx] = f_c\n                        archive_add(cand, f_c)\n                        radius[worst_idx] = max(radius[worst_idx] * 0.8, min_radius)\n                        gens_since_improve = 0\n\n            # soft restart if stagnating for many gens\n            if gens_since_improve >= stagn_limit and evals < self.budget:\n                gens_since_improve = 0\n                # inflate sigma moderately and re-center m near best with jitter\n                sigma = min(1.5 * sigma, 1.0 * np.max(span))\n                jitter = sigma * (0.1 + 0.4 * rng.rand(self.dim))\n                m = reflect_clamp(x_best + rng.randn(self.dim) * jitter)\n                # reinit covariance to diagonal small\n                C = np.diag(((span / 10.0) ** 2).clip(min=1e-12))\n                # nudge half of population toward new m with small noise\n                n_nudge = max(1, lam // 2)\n                for k in range(n_nudge):\n                    if evals >= self.budget:\n                        break\n                    idx_replace = int(np.argmax(f))\n                    cand = reflect_clamp(m + rng.randn(self.dim) * 0.6 * sigma)\n                    f_c = float(func(cand)); evals += 1\n                    X[idx_replace] = cand.copy()\n                    f[idx_replace] = f_c\n                    radius[idx_replace] = init_radius\n                    archive_add(cand, f_c)\n                    if f_c < f_best:\n                        f_best = f_c\n                        x_best = cand.copy()\n                        gens_since_improve = 0\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AMES_TR scored 0.400 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b6db7a7e-9699-49c0-ad02-a3fdafec2752", "operator": null, "metadata": {"aucs": [0.14966222601545942, 0.15898460426527017, 0.3811613817049433, 0.9658940728186939, 0.6560610396266533, 0.4379359084835729, 0.27817483132483656, 0.4857957258536927, 0.298422718523331, 0.19219709366524573]}, "task_prompt": ""}
{"id": "450c7db0-1e08-4d12-aad4-fb46bfba5f4a", "fitness": 0.6499301223235635, "name": "ASRE", "description": "The algorithm learns a low‑rank \"active\" subspace from an archive of recent normalized steps using SVD/PCA (energy thresholds drive the subspace dimension k and occasional re-randomization), and it stores only steps that beat a smoothed baseline or are top‑k to focus memory on useful directions. Sampling mixes global isotropic noise and subspace-projected noise with alpha ~ Beta(2,4) (so subspace-directed moves are favored), adds occasional differential guidance from archive entries and a persistent momentum bias, then clamps candidates to the problem bounds. Selection uses a softmax‑style recombination (temperature = std of fitnesses) to form the new mean and a momentum vector (rho = 0.82) is updated on normalized mean shifts, while sigma is initialized at 0.28×mean(range) and multiplicatively adapted using a smoothed success rate p_succ (alpha_smooth=0.12, sigma_adapt_rate=0.45) toward target_success=0.25 with dimensional scaling and hard clamping (max_sigma = 2.5×max(range)). Heuristics include population ≈ max(6, 8+2√dim), default sub_dim ≈ √dim, archive capped (~min(200,10·dim or 50)), stagnation detection at ~0.06·budget that triggers conservative \"scale‑shake\" restarts (inflate or shrink sigma, re-center on best, reseed archive) to escape or refine search.", "code": "import numpy as np\n\nclass ASRE:\n    \"\"\"\n    Adaptive Subspace Rotational Evolution (ASRE)\n\n    Main idea (one-liner):\n      Learn a low-rank active subspace from recent normalized steps (archive PCA),\n      sample each generation by mixing global isotropic noise and subspace-directed noise,\n      use softmax-weighted recombination to update the mean, maintain a momentum\n      (directional drift) and adapt sigma by a smoothed success-rate; perform\n      conservative \"scale-shake\" restarts using the best-so-far when stagnation occurs.\n\n    Intended for bounded continuous optimization (e.g., BBOB tasks with bounds [-5,5]).\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_size=None,\n                 sub_dim=None,\n                 archive_size=None,\n                 seed=None,\n                 target_success=0.25):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.rng = np.random.RandomState(seed)\n\n        # population size heuristic\n        if pop_size is None:\n            self.pop_size = max(6, int(8 + 2.0 * np.sqrt(max(1, self.dim))))\n        else:\n            self.pop_size = int(pop_size)\n\n        # subspace dimension (k) initial\n        if sub_dim is None:\n            self.sub_dim = max(1, int(np.sqrt(max(1, self.dim))))\n        else:\n            self.sub_dim = int(min(sub_dim, self.dim))\n\n        # archive for recent normalized steps used to build subspace\n        if archive_size is None:\n            self.archive_size = min(200, max(10 * self.dim, 50))\n        else:\n            self.archive_size = int(archive_size)\n\n        # step-size / success adaptation parameters\n        self.target_success = float(target_success)\n        self.sigma_adapt_rate = 0.45        # multiplier in exponent\n        self.alpha_smooth = 0.12           # smoothing for p_succ\n        self.beta_baseline = 0.20          # smoothing for baseline fitness\n\n        # momentum for mean updates\n        self.momentum_rho = 0.82\n\n        # stagnation detection\n        self.stagnation_limit = max(5, int(0.06 * max(1, self.budget)))\n\n        # storage for results\n        self.f_opt = None\n        self.x_opt = None\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = ub - lb\n        # initial mean sampled uniformly\n        m = rng.uniform(lb, ub)\n        f_m = float(func(m))\n        evals = 1\n\n        f_best = float(f_m)\n        x_best = m.copy()\n\n        # initial sigma: moderate fraction of search width\n        sigma = 0.28 * np.mean(bounds_scale)\n        sigma = max(sigma, 1e-12)\n        max_sigma = 2.5 * np.max(bounds_scale)\n\n        # archive of normalized steps (rows are step vectors in sigma-units)\n        archive_steps = []    # list of (step_vector)\n        archive_vals = []     # corresponding function improvement sign or magnitude\n\n        # PCA subspace basis (dim x k). initialize to random orthonormal basis\n        k = min(self.sub_dim, self.dim)\n        B = np.linalg.qr(rng.normal(size=(self.dim, k)))[0][:, :k]\n\n        # momentum vector (directional drift), in sigma units\n        v = np.zeros(self.dim, dtype=float)\n\n        # smoothed success and baseline fitness\n        p_succ = 0.2\n        baseline = f_m\n\n        stagn_count = 0\n\n        # main loop\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam = min(self.pop_size, remaining)\n            if lam <= 0:\n                break\n\n            # adaptively possibly reduce/increase subspace dimension based on archive energy\n            if len(archive_steps) >= max(4, k):\n                # build matrix S (n x dim)\n                S = np.vstack(archive_steps)\n                # weighted SVD for direction energy (cheap: economy SVD)\n                try:\n                    # compute covariance of S (dim x dim) via S.T @ S if smaller n>dim maybe do SVD\n                    U, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                except np.linalg.LinAlgError:\n                    # fallback: small jitter then QR\n                    S2 = S + 1e-12 * rng.randn(*S.shape)\n                    U, svals, Vt = np.linalg.svd(S2, full_matrices=False)\n                # choose k so that cumulative energy >= 0.80 (but not exceeding self.sub_dim)\n                energy = np.cumsum(svals ** 2)\n                total_energy = energy[-1] if energy.size > 0 else 0.0\n                if total_energy > 0:\n                    frac = energy / total_energy\n                    newk = int(np.searchsorted(frac, 0.80) + 1)\n                    newk = min(max(1, newk), self.dim, max(1, self.sub_dim * 2))\n                    # restrict growth to avoid sudden big jumps\n                    k = min(newk, max(1, k + 1))\n                    B = Vt[:k].T  # (dim x k)\n                else:\n                    # keep B but maybe jitter\n                    B = B\n            else:\n                # if not enough history, keep or re-randomize slightly\n                if len(archive_steps) == 0 and rng.rand() < 0.05:\n                    # re-randomize initial subspace occasionally\n                    B = np.linalg.qr(rng.normal(size=(self.dim, k)))[0][:, :k]\n\n            # generate candidate perturbations:\n            # - mix between global isotropic noise and subspace-projected noise\n            # - add a small momentum bias and occasional differential direction from archive\n            global_noise = rng.normal(size=(lam, self.dim))  # isotropic\n            sub_noise = rng.normal(size=(lam, k))            # low-rank coordinates\n\n            # mixing coefficient: bias towards subspace but keep diversity; randomize per-candidate\n            alpha = rng.beta(2.0, 4.0, size=(lam, 1))  # usually < 0.5 favors subspace\n            # build subspace component: (lam x dim) = (lam x k) @ (k x dim).T\n            sub_component = sub_noise @ (B.T)  # lam x dim\n\n            # differential perturbation from two random archive points (if available)\n            diff_component = np.zeros((lam, self.dim))\n            if len(archive_steps) >= 2:\n                # pick random gaps and scale differences by small factor\n                for i in range(lam):\n                    if rng.rand() < 0.3:  # only some candidates use differential guidance\n                        idx1, idx2 = rng.randint(0, len(archive_steps), size=2)\n                        diff_component[i] = 0.5 * (archive_steps[idx1] - archive_steps[idx2])  # in sigma-units\n\n            # candidate noises\n            Y = alpha * global_noise + (1.0 - alpha) * sub_component + 0.3 * diff_component + 0.12 * v.reshape(1, -1)\n            Xcand = m.reshape(1, -1) + sigma * Y\n\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb.reshape(1, -1)), ub.reshape(1, -1))\n\n            # evaluate sequentially until lam or budget\n            fc = np.empty(lam, dtype=float)\n            for i in range(lam):\n                fc[i] = float(func(Xcand[i]))\n            evals += lam\n\n            # generation stats\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            # update global best\n            improved_any = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved_any = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # softmax-like recombination weights (favor better candidates)\n            # temperature scaled by spread\n            spread = np.std(fc)\n            temp = max(1e-6, spread)\n            # shift for numerical stability\n            vals = np.exp(-(fc - fc.min()) / (temp + 1e-12))\n            weights = vals / (np.sum(vals) + 1e-12)\n            # recombine to get new mean\n            m_new = (weights.reshape(-1, 1) * Xcand).sum(axis=0)\n\n            # approximate fitness of m_new as weighted average\n            f_m_new = float((weights * fc).sum())\n\n            # update momentum (direction in sigma-units)\n            delta_m = (m_new - m) / (sigma + 1e-20)\n            v = self.momentum_rho * v + (1.0 - self.momentum_rho) * delta_m\n\n            # update mean\n            m = m_new\n            f_m = f_m_new\n\n            # update baseline for success metric (baseline is smoothed generation best)\n            baseline = (1.0 - self.beta_baseline) * baseline + self.beta_baseline * gen_best_f\n\n            # success fraction: proportion of candidates that beat baseline\n            success_frac = float(np.sum(fc < baseline) / max(1, lam))\n\n            # smooth success\n            p_succ = (1.0 - self.alpha_smooth) * p_succ + self.alpha_smooth * success_frac\n\n            # sigma adaptation (multiplicative), scaled by sqrt dimension (slowdown)\n            dim_scale = 1.0 + 0.6 * np.sqrt(max(1, self.dim))\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.target_success) / dim_scale)\n            # clamp sigma\n            sigma = float(np.clip(sigma, 1e-12, max_sigma))\n\n            # update archive with normalized steps from top candidates (keep only those that beat baseline or are top-k)\n            # steps are stored in sigma units relative to the mean prior to update (we used m old)\n            # note we used m before updating; compute steps = (Xcand - previous m) / sigma\n            steps = (Xcand - (m - sigma * delta_m)) / (sigma + 1e-20)  # approximate previous m\n            # prefer steps that led to improvement over baseline or are among top\n            keep_mask = (fc < baseline)\n            # ensure at least 1-2 top steps are included\n            topk = max(1, min(len(fc), int(max(1, lam // 4))))\n            top_idx = np.argsort(fc)[:topk]\n            keep_mask[top_idx] = True\n\n            # append and cap archive size\n            for i in range(lam):\n                if keep_mask[i]:\n                    archive_steps.append(steps[i].astype(float))\n                    archive_vals.append(float(fc[i]))\n            # cap\n            if len(archive_steps) > self.archive_size:\n                # remove oldest\n                cut = len(archive_steps) - self.archive_size\n                archive_steps = archive_steps[cut:]\n                archive_vals = archive_vals[cut:]\n\n            # occasionally nudge subspace basis if archive changed\n            if len(archive_steps) >= 3 and rng.rand() < 0.6:\n                # small randomized SVD recomputation for B to reflect new archive\n                S = np.vstack(archive_steps)\n                try:\n                    _, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                except np.linalg.LinAlgError:\n                    S2 = S + 1e-12 * rng.randn(*S.shape)\n                    _, svals, Vt = np.linalg.svd(S2, full_matrices=False)\n                # shrink k toward energy threshold, but keep it bounded\n                if svals.size > 0:\n                    energy = np.cumsum(svals ** 2)\n                    total = energy[-1]\n                    if total > 0:\n                        newk = int(np.searchsorted(energy / total, 0.85) + 1)\n                        newk = min(max(1, newk), self.dim)\n                        k = min(newk, max(1, k + 1))\n                        B = Vt[:k].T\n\n            # stagnation handling: if too many consecutive gens without improvement, do a scale-shake\n            if stagn_count >= self.stagnation_limit and evals < self.budget:\n                stagn_count = 0\n                # two strategies chosen randomly: amplify sigma to escape or localize and re-center near best\n                if rng.rand() < 0.6:\n                    # escape: inflate sigma and randomize mean around best\n                    sigma = min(max_sigma, sigma * (1.8 + 0.8 * rng.rand()))\n                    m = x_best + rng.normal(scale=0.6 * sigma, size=self.dim)\n                    m = np.minimum(np.maximum(m, lb), ub)\n                else:\n                    # localize: shrink sigma, reset some momentum, and re-seed a few archive entries\n                    sigma = max(1e-12, sigma * (0.12 + 0.6 * rng.rand()))\n                    v *= 0.2\n                    # repopulate archive with small perturbations around best\n                    archive_steps = []\n                    archive_vals = []\n                    for _ in range(min(6, self.archive_size)):\n                        s = rng.normal(scale=0.5, size=self.dim)\n                        archive_steps.append(s)\n                        archive_vals.append(f_best + rng.rand())\n                    # rebuild B\n                    B = np.linalg.qr(rng.normal(size=(self.dim, k)))[0][:, :k]\n\n        # done\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ASRE scored 0.650 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "23fe7331-5fec-4d4d-a554-9168a2971557", "operator": null, "metadata": {"aucs": [0.19321383061148056, 0.15559348109072657, 0.7444794936986032, 0.9631283862098831, 0.8325761604601403, 0.818221271848455, 0.3113732367578892, 0.8210602629909263, 0.8210479512862509, 0.8386071482812812]}, "task_prompt": ""}
{"id": "37cf6dfd-317c-4c1c-b588-09007a2a4bad", "fitness": 0.6405257758329379, "name": "DARS", "description": "1) The algorithm maintains a small orthonormal subspace of explicit search directions (k_dirs ≈ min(dim, 2+dim//4) ) and samples candidates by mixing a directional, heavy-tailed component with an isotropic component scaled by a diagonal covariance, normalizing steps so typical norms are ≈√dim.  \n2) Covariance is diagonal-only and updated by a rank-µ weighted squared-step estimator (cov_lr ≈ 0.18) with a decayed evolution path (path_decay ≈ 0.6) folded into the diagonal as a cheap rank-one contribution to capture directional memory.  \n3) Global step-size sigma is adapted by a linear multiplicative rule (sigma_adapt_rate ≈ 0.45) driven by a smoothed success rate target (success_target ≈ 0.28), with clipping and bounds relative to problem scale to avoid extreme changes; population size grows slowly with log(1+dim) for efficiency.  \n4) A conservative restart policy (trigger ≈0.06·budget stagnation) aggressively shrinks sigma, recenters around the best with jitter, re-randomizes directions and tightens diagonal variance to refocus search, and all samples are clamped to the box bounds.", "code": "import numpy as np\n\nclass DARS:\n    \"\"\"\n    Directional Adaptive Restart Search (DARS)\n\n    Main idea (one-liner):\n      Maintain a small orthonormal set of search directions and a diagonal variance model,\n      sample candidates by combining directional and isotropic components, adapt step-size\n      by a linear multiplicative rule driven by a smoothed success rate, update diagonal\n      variance by weighted squared steps and a decayed evolution path, and perform\n      conservative restarts that re-randomize directions and shrink the scale.\n\n    Notes on differences vs the provided AEDS:\n      - population sizing grows with log(1+dim) rather than sqrt(dim)\n      - sigma adaptation uses a linear multiplicative factor (clipped) instead of an exp with dim scaling\n      - covariance is diagonal-only (fast, compact) with a different learning-rate equation\n      - evolution path decays faster and contributes a small diagonal (rank-one-to-diag)\n      - directions are an explicit orthonormal subspace that gets reinitialized on restart\n      - conservative restarts use stronger shrink and immediate direction re-randomization\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 sigma_adapt_rate=0.45,   # linear multiplier rate (different form)\n                 success_target=0.28,\n                 cov_lr=0.18,             # diagonal covariance learning rate (different)\n                 path_decay=0.6,          # faster decay than AEDS\n                 dir_count=None,          # number of maintained directions\n                 random_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.success_target = float(success_target)\n        self.cov_lr = float(cov_lr)\n        self.path_decay = float(path_decay)\n        self.dir_count = dir_count\n        self.random_seed = random_seed\n\n        # stagnation: fraction of budget to trigger conservative restart (different constant)\n        self.stagnation_threshold = max(6, int(0.06 * max(1, self.budget)))\n\n    def _init_directions(self, rng, k):\n        # produce k orthonormal direction vectors in R^dim using QR on a random normal matrix\n        M = rng.normal(size=(self.dim, k))\n        Q, _ = np.linalg.qr(M)\n        return Q[:, :k].copy()\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.random_seed)\n\n        # bounds handling (func.bounds.lb/ub may be scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = ub - lb\n        # population size heuristic: grows slowly with log(1+dim)\n        if self.pop_base is None:\n            lam = max(6, int(4 + 6 * np.log1p(max(1, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        self.lambda_ = min(lam, max(2, self.budget))\n\n        # initial sampling to bootstrap mean and best\n        evals = 0\n        init_batch = min(self.lambda_, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        best_idx = np.argmin(f0)\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initial mean: weighted linear ranks (different shape than log-weights)\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        lin_weights = np.arange(mu0, 0, -1).astype(float)\n        lin_weights = lin_weights / np.sum(lin_weights)\n        m = (lin_weights.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial diagonal covariance (tighter local focus than AEDS)\n        C_diag = ((bounds_scale / 4.0) ** 2).clip(min=1e-12)\n\n        # initial sigma: modest fraction of mean bounds (different constant)\n        sigma = 0.15 * np.mean(bounds_scale)\n        sigma = max(sigma, 1e-12)\n\n        # state\n        p_succ = 0.18\n        stagn_count = 0\n        iter_count = 0\n\n        # evolution path (for direction memory, small)\n        p = np.zeros(self.dim, dtype=float)\n\n        # number of maintained directions\n        if self.dir_count is None:\n            k_dirs = min(self.dim, max(2, 2 + self.dim // 4))\n        else:\n            k_dirs = min(self.dim, int(self.dir_count))\n        directions = self._init_directions(rng, k_dirs)\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam = min(self.lambda_, remaining)\n            mu = max(1, lam // 2)\n\n            # linear rank weights (different from log-biased recombination)\n            ranks = np.arange(mu, 0, -1).astype(float)\n            weights = ranks / np.sum(ranks)\n\n            # produce lam candidates by mixing directional and isotropic components\n            Xcand = np.empty((lam, self.dim), dtype=float)\n            Z_dir_idx = rng.randint(0, directions.shape[1], size=lam)\n            # prepare sqrt diag for isotropic part\n            sqrt_diag = np.sqrt(C_diag)\n\n            for i in range(lam):\n                di = Z_dir_idx[i]\n                # directional scalar with limited heavy-tail: scaled t-like (normal clipped)\n                s_dir = np.tanh(rng.normal(loc=0.0, scale=1.2)) * 2.0\n                dir_vec = directions[:, di] * s_dir\n\n                # isotropic component scaled by sqrt of diagonal cov\n                iso = rng.normal(size=self.dim) * sqrt_diag\n\n                # combine components with fixed mix coefficients (different equation)\n                y = 0.65 * dir_vec + 0.35 * iso\n                # normalize small vectors to avoid tiny steps\n                nrm = np.linalg.norm(y)\n                if nrm > 0:\n                    y = y / (nrm / np.sqrt(self.dim))  # rescale so typical norm ~ sqrt(dim)\n                Xcand[i] = m + sigma * y\n\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate (sequentially)\n            fc = np.empty(lam, dtype=float)\n            for i in range(lam):\n                fc[i] = float(func(Xcand[i]))\n            evals += lam\n\n            # generation best and global best\n            gen_best_idx = np.argmin(fc)\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # recombine to get new mean\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized step vectors (in sigma units)\n            deltas = (X_mu - m) / (sigma + 1e-20)  # (mu, dim)\n\n            # diagonal (rank-mu) estimate: weighted squared deltas\n            weighted_sq = (weights.reshape(-1, 1) * (deltas ** 2)).sum(axis=0)\n            # update diagonal covariance with a different learning rule\n            C_diag = (1.0 - self.cov_lr) * C_diag + self.cov_lr * (weighted_sq + 1e-16)\n\n            # update evolution path (faster decay)\n            y_w = (m_new - m) / (sigma + 1e-20)\n            p = self.path_decay * p + (1.0 - self.path_decay) * y_w\n\n            # small rank-one contribution folded into diagonal (different than full rank-one)\n            C_diag += 0.06 * (p ** 2)\n\n            # ensure positivity and numeric safety\n            C_diag = np.maximum(C_diag, 1e-12)\n\n            # accept new mean\n            m = m_new\n\n            # success smoothing (alpha smaller to smooth more slowly)\n            alpha = 0.12\n            p_succ = (1.0 - alpha) * p_succ + alpha * float(improved)\n\n            # sigma adaptation: linear multiplicative factor (clipped), different equation than AEDS\n            factor = 1.0 + self.sigma_adapt_rate * (p_succ - self.success_target)\n            # clip factor to avoid too large jumps\n            factor = float(np.clip(factor, 0.75, 1.45))\n            sigma *= factor\n\n            # clamp sigma to reasonable bounds relative to problem size\n            max_sigma = 3.0 * np.max(bounds_scale)\n            sigma = float(np.clip(sigma, 1e-12, max_sigma))\n\n            # conservative restart policy: stronger shrink & re-randomize directions\n            if stagn_count * lam >= self.stagnation_threshold and evals < self.budget:\n                stagn_count = 0\n                # shrink sigma significantly to focus locally\n                sigma *= 0.2 + 0.1 * rng.rand()  # roughly between 0.2 and 0.3\n                # re-center mean near best with small jitter\n                jitter_scale = 0.03 * bounds_scale\n                m = x_best + rng.normal(scale=jitter_scale)\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset diagonal covariance to tighter local scale\n                C_diag = ((bounds_scale / 10.0) ** 2).clip(min=1e-12)\n                # reinitialize directions\n                directions = self._init_directions(rng, k_dirs)\n                # modestly increase population to diversify (bounded)\n                self.lambda_ = min(self.lambda_ + 3, max(2, self.budget))\n                # reset some adapt state\n                p_succ = 0.18\n                p.fill(0.0)\n                # continue main loop\n                continue\n\n        # done\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DARS scored 0.641 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "23fe7331-5fec-4d4d-a554-9168a2971557", "operator": null, "metadata": {"aucs": [0.26956574079909, 0.24211893051585187, 0.8925051326676449, 0.9564482495381749, 0.916403341787437, 0.9213560109071368, 0.306155187645195, 0.7300353513168466, 0.9268455990468766, 0.24382421410512545]}, "task_prompt": ""}
{"id": "4014a4c8-344a-4b54-baa4-857d6e1cfdaf", "fitness": 0.28928676297853767, "name": "MSOS", "description": "The MSOS heuristic keeps a lightweight running covariance sketch G and a per-coordinate variance d, extracts a small low-rank subspace U (k_subspace small relative to dim) and maintains two step-size scales (sigma_sub for subspace-directed moves and sigma_diag for anisotropic coordinate moves) to sample a mixture of subspace-directed, coordinate-wise anisotropic and occasional heavy‑tailed Cauchy-like jump candidates (jump_prob ≈ 0.07). New means are formed by log-biased rank‑mu recombination of the best offspring, a normalized rank‑mu covariance is EMA-blended into G (cov_memory=0.85) and d is updated by an EMA of squared steps (diag_memory=0.7) with per-coordinate scaling sqrt(d). The subspace U is refreshed from the top eigenvectors of G every eig_update_every iterations to focus search directions while sigmas are multiplicatively adapted from a smoothed success rate p_succ toward a success_target (≈0.2) with adapt_rate ≈0.25 and different sensitivity for subspace vs diag moves. Practical safeguards include strict bound clamping, sigma clipping relative to bounds, conservative restarts on stagnation (stagnation_frac ≈0.06) that shrink sigmas and re-center near the best, and population sizing that grows mildly with sqrt(dim).", "code": "import numpy as np\n\nclass MSOS:\n    \"\"\"\n    Multi-Scale Orthogonal Search (MSOS)\n\n    Main idea (one-liner):\n      Keep a lightweight running covariance sketch and a diagonal scale,\n      estimate a low-rank informative subspace, sample a mixture of\n      subspace-directed steps, coordinate-wise anisotropic steps and\n      occasional heavy-tailed jumps, adapt two sigmas (subspace & diag)\n      by smoothed success and perform conservative local restarts.\n\n    This implementation is written to respect a strict budget of function\n    evaluations and to work for variable dimension problems (bounds are\n    read from func.bounds.{lb,ub}).\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 k_subspace=None,\n                 cov_memory=0.85,    # memory for running covariance sketch\n                 diag_memory=0.7,    # memory for per-coordinate variance estimator\n                 sigma_diag_init=None,\n                 sigma_sub_init=None,\n                 success_target=0.2,\n                 adapt_rate=0.25,\n                 jump_prob=0.07,\n                 eig_update_every=6,\n                 stagnation_frac=0.06,\n                 random_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.cov_memory = float(cov_memory)\n        self.diag_memory = float(diag_memory)\n        self.success_target = float(success_target)\n        self.adapt_rate = float(adapt_rate)\n        self.jump_prob = float(jump_prob)\n        self.eig_update_every = int(eig_update_every)\n        self.stagnation_frac = float(stagnation_frac)\n        self.random_seed = random_seed\n\n        # subspace rank\n        if k_subspace is None:\n            # keep a small subspace, grows mildly with dim but bounded to limit cost\n            self.k_subspace = max(1, min(6, self.dim // 3))\n        else:\n            self.k_subspace = int(min(k_subspace, self.dim))\n\n        # derived settings\n        if self.pop_base is None:\n            self.lambda_base = max(6, int(6 + 3 * np.sqrt(max(1, self.dim))))\n        else:\n            self.lambda_base = int(self.pop_base)\n        self.lambda_base = min(self.lambda_base, max(2, self.budget))\n\n        self.stagnation_threshold = max(5, int(self.stagnation_frac * max(1, self.budget)))\n\n        # optional sigma inits set later when bounds known\n        self.sigma_diag_init = sigma_diag_init\n        self.sigma_sub_init = sigma_sub_init\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.random_seed)\n\n        # handle bounds (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        bounds_scale = (ub - lb)\n        mean_span = float(np.mean(bounds_scale))\n\n        # initialize population size for iterations\n        self.lambda_ = self.lambda_base\n\n        # bootstrap: sample an initial batch to get a starting mean and best\n        evals = 0\n        init_batch = min(self.lambda_, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # weighted initial mean formed from top half with log-like weights\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(np.arange(mu0, 0, -1) + 0.7)\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones(mu0) / mu0\n        else:\n            w0 = w0 / np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # running covariance sketch (full symmetric matrix) used to extract subspace\n        # initialize to a small isotropic matrix scaled to bounds\n        init_var = ((bounds_scale / 6.0) ** 2).clip(min=1e-12)\n        G = np.diag(init_var).copy()  # running covariance sketch\n\n        # per-coordinate variance estimator (diagonal adapt)\n        d = init_var.copy()\n\n        # sigmas: two scales: diagonal anisotropic sigma and subspace sigma\n        sigma_diag = float(self.sigma_diag_init if self.sigma_diag_init is not None\n                           else 0.18 * mean_span)\n        sigma_sub = float(self.sigma_sub_init if self.sigma_sub_init is not None\n                          else 0.9 * sigma_diag)  # subspace moves are larger initially\n        sigma_diag = max(sigma_diag, 1e-12)\n        sigma_sub = max(sigma_sub, 1e-12)\n\n        # subspace basis (columns are orthonormal)\n        U = np.zeros((self.dim, self.k_subspace), dtype=float)\n        # default initial basis: random orthonormal\n        Q, _ = np.linalg.qr(rng.randn(self.dim, self.k_subspace))\n        U[:, :Q.shape[1]] = Q\n\n        # state for adaptation\n        p_succ = 0.2  # smoothed success ratio\n        stagn_count = 0\n        iter_count = 0\n        last_eig_update = 0\n\n        # small safeguards\n        eps = 1e-12\n        min_diag = 1e-12\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam = min(self.lambda_, remaining)\n            mu = max(1, lam // 2)\n\n            # recompute rank-mu weights (log-biased)\n            ranks = np.arange(1, mu + 1)\n            weights = np.log(mu + 0.6) - np.log(ranks + 0.3)\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones(mu)\n            weights = weights / np.sum(weights)\n\n            # decide mixture counts: subspace, diag, jump\n            # keep some minimum for subspace for low-dim\n            p_jump = min(0.5, max(0.01, self.jump_prob))\n            p_sub = min(0.85, 0.5 + 0.25 * (self.k_subspace / max(1, self.dim)))\n            p_diag = 1.0 - p_jump - p_sub\n            # ensure non-negative\n            if p_diag < 0:\n                p_diag = 0.01\n                p_sub = 1.0 - p_jump - p_diag\n\n            # sample how many of each mode (multinomial)\n            counts = rng.multinomial(lam, [p_sub, p_diag, p_jump])\n            n_sub, n_diag, n_jump = counts.tolist()\n\n            Xcand = np.empty((lam, self.dim), dtype=float)\n            mode_of = np.empty(lam, dtype=int)  # 0=subspace,1=diag,2=jump\n            idx = 0\n\n            sqrt_d = np.sqrt(np.maximum(d, min_diag))\n\n            # subspace-directed samples\n            if n_sub > 0:\n                # sample coefficients in subspace\n                Zk = rng.normal(size=(n_sub, self.k_subspace))\n                # subspace component\n                sub_comp = Zk @ U.T  # (n_sub, dim)\n                # small orthogonal noise scaled by diag sigma\n                ortho_noise = rng.normal(size=(n_sub, self.dim)) * sqrt_d\n                X_sub = m + sigma_sub * sub_comp + sigma_diag * ortho_noise\n                Xcand[idx:idx + n_sub] = X_sub\n                mode_of[idx:idx + n_sub] = 0\n                idx += n_sub\n\n            # diag anisotropic samples (coordinate-wise exploration)\n            if n_diag > 0:\n                Zd = rng.normal(size=(n_diag, self.dim))\n                X_diag = m + sigma_diag * (Zd * sqrt_d)\n                Xcand[idx:idx + n_diag] = X_diag\n                mode_of[idx:idx + n_diag] = 1\n                idx += n_diag\n\n            # jump (heavy-tailed Cauchy-like) samples\n            if n_jump > 0:\n                # use ratio of normals to get Cauchy-like heavy tails\n                Uc = rng.normal(size=(n_jump, self.dim))\n                Vc = rng.normal(size=(n_jump, self.dim))\n                # avoid division by zero\n                Vc[np.abs(Vc) < 1e-6] = 1e-6\n                Cauchy = Uc / Vc\n                # scale jump magnitude relative to bounds and current sigmas\n                jump_scale = 0.6 * mean_span * (0.8 + 0.4 * rng.rand(n_jump)).reshape(-1, 1)\n                X_jump = m + (Cauchy * jump_scale)\n                Xcand[idx:idx + n_jump] = X_jump\n                mode_of[idx:idx + n_jump] = 2\n                idx += n_jump\n\n            # clamp candidates into bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates\n            fc = np.empty(lam, dtype=float)\n            for i in range(lam):\n                fc[i] = float(func(Xcand[i]))\n            evals += lam\n\n            # generation best\n            gen_best_idx_local = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx_local])\n            gen_best_x = Xcand[gen_best_idx_local].copy()\n\n            improved = False\n            # if generation best improves global best, update\n            if gen_best_f < f_best - 1e-15:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # recombine to get new mean m_new using best mu candidates\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized steps using diag sigma for standardization\n            denom = (sigma_diag + eps)\n            deltas = (X_mu - m) / denom  # shape (mu, dim)\n\n            # rank-mu covariance estimate (normalized)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas  # (dim, dim)\n            # ensure symmetry\n            weighted_cov = 0.5 * (weighted_cov + weighted_cov.T)\n\n            # update running covariance sketch G (memory blend)\n            G = self.cov_memory * G + (1.0 - self.cov_memory) * weighted_cov\n\n            # per-coordinate variance update (EMA of squared steps)\n            var_est = np.mean(deltas ** 2, axis=0) if mu > 0 else np.zeros(self.dim)\n            d = self.diag_memory * d + (1.0 - self.diag_memory) * (var_est * (denom ** 2))\n            # keep safe min\n            d = np.maximum(d, min_diag)\n\n            # occasionally update subspace basis by extracting top eigenvectors of G\n            if (iter_count - last_eig_update) >= self.eig_update_every:\n                last_eig_update = iter_count\n                # symmetric correction\n                Gsym = 0.5 * (G + G.T)\n                try:\n                    eigvals, eigvecs = np.linalg.eigh(Gsym)\n                    # pick top k_subspace eigenvectors\n                    top_idx = np.argsort(eigvals)[-self.k_subspace:]\n                    U = eigvecs[:, top_idx]\n                    # orthonormalize columns\n                    U, _ = np.linalg.qr(U)\n                except np.linalg.LinAlgError:\n                    # keep previous U on failure\n                    pass\n\n            # adopt new mean\n            m = m_new\n\n            # success smoothing and dual-sigma adaptation\n            alpha = 0.14  # smoothing factor\n            p_succ = (1.0 - alpha) * p_succ + alpha * float(improved)\n\n            # adapt sigma_diag and sigma_sub differently\n            # larger reaction for subspace sigma if subspace-generated candidate improved\n            # find which mode produced gen_best (one of 0,1,2 mapping to mode_of)\n            mode_of_genbest = int(mode_of[gen_best_idx_local])\n            # factor depending on improvement\n            delta_succ = (p_succ - self.success_target)\n            # update rules (multiplicative)\n            # scale by adapt_rate and dimension scaling for stability\n            dim_scale = 1.0 + 0.3 * np.sqrt(max(1, self.dim))\n            sigma_diag *= np.exp(self.adapt_rate * delta_succ / dim_scale)\n            # subspace adapt: slightly more sensitive if we saw improvements from subspace\n            if mode_of_genbest == 0:\n                sigma_sub *= np.exp(1.3 * self.adapt_rate * delta_succ / dim_scale)\n            else:\n                sigma_sub *= np.exp(0.7 * self.adapt_rate * delta_succ / dim_scale)\n\n            # clamp sigmas to reasonable ranges relative to bounds\n            sigma_diag = float(np.clip(sigma_diag, 1e-12, 3.0 * np.max(bounds_scale)))\n            sigma_sub = float(np.clip(sigma_sub, 1e-12, 4.0 * np.max(bounds_scale)))\n\n            # conservative restart if stagnating too long\n            if stagn_count >= self.stagnation_threshold and evals < self.budget:\n                stagn_count = 0\n                # shrink sigmas to focus local search and perform a guided re-center near best\n                sigma_diag *= (0.25 + 0.6 * rng.rand())\n                sigma_sub *= (0.25 + 0.8 * rng.rand())\n                # re-center mean around best with small noise\n                jitter = 0.03 * bounds_scale * (0.5 + rng.rand(self.dim))\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset diagonal variance to be tighter and keep some fraction of G\n                d = np.maximum(d * 0.4, min_diag)\n                G = np.diag(d) + 0.05 * G  # blend in some sketch info\n                # slightly increase population to encourage diversification\n                self.lambda_ = min(self.lambda_ + 2, max(2, self.budget))\n                # continue loop (do not perform further updates this iteration)\n                continue\n\n        # done: return best found\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MSOS scored 0.289 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "23fe7331-5fec-4d4d-a554-9168a2971557", "operator": null, "metadata": {"aucs": [0.19928078352683076, 0.26602424089178534, 0.3249571161071544, 0.3820781145146558, 0.2638488166234597, 0.3830519729870637, 0.299434511538999, 0.2917137571194436, 0.27997571782830477, 0.20250259864767983]}, "task_prompt": ""}
{"id": "b9f441db-49d8-4b32-a128-01ee67b1316b", "fitness": 0.8090776880819025, "name": "EDCAS", "description": "EDCAS uses antithetic (mirrored) Gaussian sampling around a weighted recombination mean with a modest population size heuristic (lambda ~ 6+6·log1p(dim)) and clamps samples to problem bounds to reduce sampling variance and respect the search box. Covariance learning blends a rank‑mu estimate from normalized elite steps with a rank‑one outer product of an evolution path, but applies conservative mixing (small c_cov and a hard-coded 0.12 memory term), Ledoit‑style shrinkage toward a bounds‑derived diagonal prior, and eigen/jitter regularization to keep C well‑conditioned. Step-size (sigma) is adapted multiplicatively using a smoothed success probability (p_succ) with a tanh/logistic‑like mapping and moderate sensitivity (eta_sigma), while evolution path decay and weights bias updates toward recent successful directions. A conservative stagnation restart recenters the mean near the best, strongly reduces sigma, resets covariance to a localized diagonal, slightly increases population, and preserves numeric safety via floors and symmetrization.", "code": "import numpy as np\n\nclass EDCAS:\n    \"\"\"\n    Ensemble Directional Covariance with Antithetic Sampling (EDCAS)\n\n    Main idea (one-liner):\n      Use mirrored (antithetic) sampling to get low-variance ensemble estimates,\n      maintain a compact covariance estimate using a blend of rank-mu and a\n      directional evolution path, shrink the covariance toward a bounds-based\n      diagonal prior (Ledoit-style), and adapt sigma with a smoothed success-rate\n      in a logistic-like multiplicative rule. Conservative local reinitialization\n      (restart) is applied on stagnation.\n\n    Notes:\n      - __init__(self, budget, dim, ...) must be provided by the evaluator harness.\n      - func.bounds.lb / ub can be scalar or per-dimension arrays.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 c_cov=0.08,             # stronger conservatism for rank-one mixing\n                 shrink_alpha=0.35,      # shrinkage toward diagonal prior (Ledoit-like)\n                 sigma_init_frac=0.15,   # initial sigma as fraction of bounds range\n                 eta_sigma=0.28,         # sigma adaptation sensitivity\n                 success_target=0.30,    # desired success rate for sigma controller\n                 p_succ_alpha=0.18,      # smoothing for success probability\n                 path_base_decay=0.86,   # base decay for evolution path\n                 random_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.c_cov = float(c_cov)\n        self.shrink_alpha = float(shrink_alpha)\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.eta_sigma = float(eta_sigma)\n        self.success_target = float(success_target)\n        self.p_succ_alpha = float(p_succ_alpha)\n        self.path_base_decay = float(path_base_decay)\n        self.random_seed = random_seed\n\n        # stagnation threshold (iterations without improvement)\n        self.stagnation_threshold = max(8, int(max(1, 0.05 * self.budget)))\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.random_seed)\n\n        # bounds handling (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        # safety: if user-provided bounds are degenerate, ensure minimal scale\n        bounds_scale = np.maximum(bounds_scale, 1e-8)\n\n        # population size heuristic: grow gently with log(dim) (different from sqrt)\n        if self.pop_base is None:\n            self.lambda_ = max(6, int(6 + 6.0 * np.log1p(self.dim)))\n        else:\n            self.lambda_ = int(self.pop_base)\n        self.lambda_ = min(self.lambda_, max(2, self.budget))\n\n        # initial batch to bootstrap mean and covariance (small but > dim)\n        init_batch = min(max(self.lambda_ * 2, self.dim + 2), self.budget // 10 + 1)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals = init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # weighted initial mean using exponential rank weights (strong top emphasis)\n        order0 = np.argsort(f0)\n        mu0 = max(1, init_batch // 3)\n        elites0 = X0[order0[:mu0]]\n        ranks = np.arange(mu0)\n        weights0 = np.exp(-ranks / max(1.0, (mu0 / 3.0)))\n        weights0 = weights0 / np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance: diagonal prior based on bounds, tighter than naive uniform\n        prior_var = (bounds_scale / 6.0) ** 2\n        C = np.diag(prior_var.copy())\n\n        # initial sigma relative to bounds\n        sigma = max(1e-12, self.sigma_init_frac * np.mean(bounds_scale))\n\n        # evolution path (directional memory)\n        p_c = np.zeros(self.dim, dtype=float)\n\n        # small numerical floor for eigenvalues\n        min_diag = 1e-16\n\n        # smoothed success probability\n        p_succ = self.success_target\n\n        # stagnation counter (consecutive generations without improvement)\n        stagn_count = 0\n\n        # main loop: respect budget\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam = min(self.lambda_, remaining)\n            # ensure lam is at least 2 to allow mirrored pairs when possible\n            lam = max(1, lam)\n\n            # build rank-mu recombination weights (exponential decay with different scale)\n            mu = max(1, lam // 2)\n            ranks = np.arange(mu)\n            weights = np.exp(-ranks / max(1.0, (mu / 2.0)))\n            weights = weights / np.sum(weights)\n\n            # ensure SPD for C via eigen regularization (robust)\n            try:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, min_diag, None)\n                sqrt_vals = np.sqrt(vals)\n                # B such that B @ B.T = C\n                B = vecs * sqrt_vals.reshape(1, -1)\n            except Exception:\n                # fallback to isotropic small covariance\n                B = np.eye(self.dim) * np.sqrt(np.maximum(np.diag(C), min_diag))\n\n            # Antithetic (mirrored) sampling: use lam//2 pairs\n            Xcand = []\n            to_make = lam\n            npairs = to_make // 2\n            if npairs > 0:\n                Z = rng.normal(size=(npairs, self.dim))\n                Y = Z @ B  # shape (npairs, dim)\n                X_plus = m + sigma * Y\n                X_minus = m - sigma * Y\n                Xcand.extend(X_plus.tolist())\n                Xcand.extend(X_minus.tolist())\n\n            if to_make % 2 == 1:\n                z = rng.normal(size=(self.dim,))\n                y = z @ B\n                Xcand.append((m + sigma * y).tolist())\n\n            Xcand = np.asarray(Xcand, dtype=float)[:lam]\n\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates (one by one to count exactly)\n            fc = np.empty(lam, dtype=float)\n            for i in range(lam):\n                fc[i] = float(func(Xcand[i]))\n            evals += lam\n\n            # generation best and update global best\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # recombine to get new mean\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized steps in sigma units\n            deltas = (X_mu - m) / (sigma + 1e-20)   # shape (mu, dim)\n\n            # weighted covariance estimate (rank-mu)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas  # (dim, dim)\n\n            # adapt path decay slightly based on recent success (more memory if successful)\n            decay = self.path_base_decay + 0.08 * (1.0 if p_succ > self.success_target else 0.0)\n            decay = float(np.clip(decay, 0.6, 0.98))\n\n            # update evolution path p_c\n            y_w = (m_new - m) / (sigma + 1e-20)\n            p_c = decay * p_c + (1.0 - decay) * y_w\n\n            # rank-one from path\n            rank_one = np.outer(p_c, p_c)\n\n            # blend previous covariance with new information (rank-mu + rank-one),\n            # then apply shrinkage toward prior diagonal (Ledoit-like mixing)\n            blend_new = (1.0 - self.c_cov) * weighted_cov + self.c_cov * rank_one\n            C_temp = (1.0 - 0.12) * C + 0.12 * blend_new   # keep more memory of old C (hard-coded 0.12)\n            # Ledoit-style shrink toward prior diagonal (prior_var)\n            shrink_target = np.diag(prior_var)\n            C = (1.0 - self.shrink_alpha) * C_temp + self.shrink_alpha * shrink_target\n\n            # symmetrize and add tiny jitter for numeric stability\n            C = 0.5 * (C + C.T)\n            diagC = np.diag(C)\n            jitter = 1e-14 * np.maximum(diagC, 1.0)\n            C += np.diag(jitter)\n            # ensure positive definiteness floor\n            vals, _ = np.linalg.eigh(C)\n            if np.min(vals) <= 0:\n                C += np.eye(self.dim) * (abs(np.min(vals)) + min_diag)\n\n            # accept new mean\n            m = m_new\n\n            # update smoothed success probability and adapt sigma multiplicatively\n            p_succ = (1.0 - self.p_succ_alpha) * p_succ + self.p_succ_alpha * float(improved)\n            # logistic-like scaling: map success diff through tanh for smoother reaction on extremes\n            delta = p_succ - self.success_target\n            scale = np.exp(self.eta_sigma * np.tanh(2.5 * delta) / (1.0 + 0.25 * np.log1p(self.dim)))\n            sigma *= float(scale)\n\n            # enforce sensible sigma bounds relative to problem scale\n            max_sigma = 2.5 * np.max(bounds_scale)\n            min_sigma = 1e-12\n            sigma = float(np.clip(sigma, min_sigma, max_sigma))\n\n            # conservative local restart on stagnation: re-center near best, shrink sigma strongly,\n            # reset covariance to slightly inflated diagonal prior, and bump population mildly\n            if stagn_count >= self.stagnation_threshold and evals < self.budget:\n                stagn_count = 0\n                # strong shrink of sigma\n                sigma *= (0.18 + 0.22 * rng.rand())  # between 0.18 and 0.4\n                # place mean near best with small randomized offset\n                jitter_scale = 0.06 * bounds_scale * (0.5 + rng.rand(self.dim))\n                m = x_best + rng.randn(self.dim) * jitter_scale\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset covariance to more local isotropic around prior but slightly inflated\n                C = np.diag((prior_var * (0.6 + 0.6 * rng.rand())).clip(min=min_diag))\n                # increase lambda to diversify (but not beyond remaining budget)\n                self.lambda_ = min(self.lambda_ + 1, max(2, self.budget))\n                # small reset of evolution path\n                p_c *= 0.4\n                # continue next generation\n                continue\n\n        # done\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EDCAS scored 0.809 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "23fe7331-5fec-4d4d-a554-9168a2971557", "operator": null, "metadata": {"aucs": [0.3106907058414644, 0.9536210677081981, 0.9073860261424141, 0.9635719934523514, 0.9305643262424019, 0.9412255630776708, 0.32217335828736493, 0.909476958249735, 0.9256955186291635, 0.9263713631882591]}, "task_prompt": ""}
{"id": "5502f328-f796-4807-808a-f18c407df21f", "fitness": 0.7836358982617098, "name": "HAMC", "description": "The HAMC algorithm is a hybrid CMA-style heuristic that blends local covariance-guided search and global isotropic exploration by sampling a tunable fraction (mix, initialized 0.5) of offspring from a learned covariance and the rest from isotropic normal or uniform perturbations, with initial mean set by weighted recombination of elites and a tight diagonal C based on the problem range. Covariance learning combines rank‑mu (weighted sample covariance) and a rank‑one evolution path (p_c) with long memory (cov_memory=0.8, path_decay=0.92) and robustifies C via moderate shrinkage toward its diagonal (cov_shrink=0.3) plus SPD fixes (Cholesky / eigendecomposition fallback and tiny diagonal jitter). Step-size (sigma) is multiplicatively adapted from a smoothed success probability (p_succ) toward a low success_target (0.2) with a relatively strong adaptation rate (sigma_adapt_rate=0.25), while the mix between local/global sampling also drifts with recent success; population size lambda is heuristically set by dim and can grow modestly on stagnation (max_pop_increase=6) to diversify. Conservative mechanisms include bounded sigma and lambda, opportunistic mini-restarts and center jitter around the best solution, clipping to variable bounds, and multiple safeguards (symmetrization, min-diagonal) to keep the algorithm stable across Many-Affine BBOB problems.", "code": "import numpy as np\n\nclass HAMC:\n    \"\"\"\n    Hybrid Adaptive Mixture CMA (HAMC)\n\n    Key ideas combined:\n      - Mixture sampling: a fraction of the population is sampled using the learned covariance (local search),\n        and the rest is sampled isotropically (global exploration).\n      - Covariance is kept robust via shrinkage towards diagonal and includes a rank-one evolution path term.\n      - Sigma is adapted multiplicatively using a smoothed success-rate; population size can grow on stagnation.\n      - Conservative opportunistic restarts re-center near the best and toggle exploration/localization.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, random_seed=None,\n                 pop_base=None,\n                 cov_memory=0.8,    # memory for covariance (how much old C is kept)\n                 c_cov=0.15,        # learning rate blending rank-mu vs rank-one\n                 cov_shrink=0.3,    # shrinkage toward diagonal (robustness)\n                 path_decay=0.92,   # decay for evolution path\n                 mix_init=0.5,      # initial fraction sampled from covariance (rest isotropic)\n                 sigma_adapt_rate=0.25,\n                 success_target=0.2,\n                 stagnation_frac=0.06,\n                 max_pop_increase=6):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.random_seed = random_seed\n        self.pop_base = pop_base\n        self.cov_memory = float(cov_memory)\n        self.c_cov = float(c_cov)\n        self.cov_shrink = float(cov_shrink)\n        self.path_decay = float(path_decay)\n        self.mix = float(mix_init)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.success_target = float(success_target)\n        self.stagnation_frac = float(stagnation_frac)\n        self.max_pop_increase = int(max_pop_increase)\n\n        # derived\n        self.stagnation_threshold = max(5, int(self.stagnation_frac * max(1, self.budget)))\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.random_seed)\n\n        # bounds handling (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        avg_range = float(np.mean(bounds_scale))\n\n        # population size heuristic: base grows moderately with sqrt(dim)\n        if self.pop_base is None:\n            lam = max(8, int(6 + 3 * np.sqrt(max(1, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n        self.lambda_ = lam\n\n        # initial sampling: bootstrap\n        evals = 0\n        init_batch = min(self.lambda_, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([float(func(x)) for x in X0])\n        evals += init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize mean as weighted recombination of top half\n        mu = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu]]\n        weights0 = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1) + 0.2)\n        weights0 = np.maximum(weights0, 0.0)\n        weights0 = weights0 / np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance: tight diagonal to prefer local search initially\n        C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n\n        # evolution path\n        p_c = np.zeros(self.dim, dtype=float)\n\n        # initial sigma\n        sigma = 0.22 * avg_range\n        sigma = max(sigma, 1e-12)\n\n        # state variables\n        p_succ = 0.2\n        stagn_count = 0\n        iter_count = 0\n\n        # helper small constants\n        min_diag = 1e-12\n        max_sigma = 2.0 * np.max(bounds_scale)\n\n        while evals < self.budget:\n            iter_count += 1\n\n            remaining = self.budget - evals\n            lam = min(self.lambda_, remaining)\n            mu = max(1, lam // 2)\n\n            # recalc weights\n            ranks = np.arange(1, mu + 1)\n            weights = np.log(mu + 0.5) - np.log(ranks + 0.2)\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # determine how many to sample from covariance vs isotropic; small dynamic adaptation:\n            # shift mix slightly toward covariance when recent improvements, otherwise favor isotropic\n            mix = float(np.clip(self.mix + 0.15 * (p_succ - self.success_target), 0.2, 0.9))\n            n_cov = int(np.round(mix * lam))\n            n_iso = lam - n_cov\n            # ensure at least one of each type if possible\n            if lam >= 2:\n                n_cov = max(1, min(n_cov, lam - 1))\n                n_iso = lam - n_cov\n\n            # ensure SPD for C\n            eps = 1e-12 * np.maximum(np.diag(C), 1.0)\n            try:\n                A = np.linalg.cholesky(C + np.diag(eps))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, min_diag, None)\n                A = (vecs * np.sqrt(vals)).T  # so that A.T @ A = C\n\n            # sample covariance-driven candidates\n            Xcand = []\n            if n_cov > 0:\n                Z_cov = rng.normal(size=(n_cov, self.dim))\n                Y_cov = Z_cov @ (A.T)   # transforms to have covariance C\n                Xcov = m + sigma * Y_cov\n                Xcov = np.minimum(np.maximum(Xcov, lb), ub)\n                Xcand.append(Xcov)\n\n            # sample isotropic/global candidates (independent, with larger radius occasionally)\n            if n_iso > 0:\n                # occasionally sample some farther out to help escape\n                global_scale = 1.0 + 0.5 * rng.rand() * (0.5 if stagn_count > 0 else 0.0)\n                Z_iso = rng.normal(size=(n_iso, self.dim))\n                Xiso = m + sigma * global_scale * Z_iso\n                Xiso = np.minimum(np.maximum(Xiso, lb), ub)\n                Xcand.append(Xiso)\n\n            if len(Xcand) == 0:\n                break\n            Xcand = np.vstack(Xcand)\n            # If lam > Xcand rows (numerical rounding), pad by random uniform\n            if Xcand.shape[0] < lam:\n                pad = lam - Xcand.shape[0]\n                Xpad = rng.uniform(lb, ub, size=(pad, self.dim))\n                Xcand = np.vstack([Xcand, Xpad])\n\n            # evaluate candidates one-by-one\n            fc = np.empty(Xcand.shape[0], dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    fc = fc[:i]\n                    Xcand = Xcand[:i]\n                    break\n                fc[i] = float(func(Xcand[i]))\n                evals += 1\n\n            if Xcand.shape[0] == 0:\n                break\n\n            # update generation best and global best\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best - 1e-16:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # recombine top mu\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized steps\n            deltas = (X_mu - m) / (sigma + 1e-20)  # shape (mu, dim)\n\n            # rank-mu weighted covariance (in normalized coordinates)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas  # (dim, dim)\n\n            # update evolution path using weighted mean step\n            y_w = (m_new - m) / (sigma + 1e-20)\n            p_c = self.path_decay * p_c + (1.0 - self.path_decay) * y_w\n\n            rank_one = np.outer(p_c, p_c)\n\n            # form new candidate covariance from rank-mu and rank-one\n            C_est = (1.0 - self.c_cov) * weighted_cov + self.c_cov * rank_one\n\n            # shrinkage toward diagonal estimate of current C for robustness\n            diagC = np.diag(np.diag(C))\n            C_new = (self.cov_memory * C + (1.0 - self.cov_memory) * C_est)\n            C = (1.0 - self.cov_shrink) * C_new + self.cov_shrink * diagC\n\n            # ensure symmetry and tiny diagonal jitter\n            C = 0.5 * (C + C.T)\n            diagC = np.diag(C)\n            jitter = 1e-12 * np.maximum(diagC, 1.0)\n            C += np.diag(jitter)\n            # accept new mean\n            m = m_new\n\n            # success smoothing and sigma adaptation (multiplicative)\n            alpha = 0.18\n            p_succ = (1.0 - alpha) * p_succ + alpha * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target) / np.sqrt(max(1, self.dim)))\n            sigma = float(np.clip(sigma, 1e-12, max_sigma))\n\n            # adapt mix slightly (favor covariance when improving)\n            if improved:\n                self.mix = float(np.clip(self.mix * 1.02, 0.2, 0.95))\n            else:\n                self.mix = float(np.clip(self.mix * 0.995, 0.05, 0.95))\n\n            # dynamic population adaptation upon stagnation\n            if stagn_count * lam >= self.stagnation_threshold and evals < self.budget:\n                stagn_count = 0\n                # increase population modestly to diversify (but not beyond budget)\n                self.lambda_ = min(self.lambda_ + rng.randint(1, self.max_pop_increase + 1), max(2, self.budget))\n                # moderately enlarge sigma to explore\n                sigma = min(max_sigma, sigma * (1.2 + 0.6 * rng.rand()))\n                # jitter center around best\n                jitter_scale = 0.25 * sigma\n                m = x_best + rng.randn(self.dim) * jitter_scale\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset covariance to a slightly larger diagonal but keep some memory\n                C = 0.5 * C + 0.5 * np.diag(((bounds_scale / 5.5) ** 2).clip(min=min_diag))\n                # continue main loop\n                continue\n\n            # conservative opportunistic mini-restart if stuck very long\n            if stagn_count * lam >= 3 * self.stagnation_threshold and evals < self.budget:\n                stagn_count = 0\n                # shrink sigma to intensify local search and re-center near best with small jitter\n                sigma *= (0.3 + 0.7 * rng.rand())\n                m = x_best + 0.04 * bounds_scale * rng.randn(self.dim)\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((bounds_scale / 8.0) ** 2).clip(min=min_diag))\n                # slightly reduce population\n                self.lambda_ = max(4, int(0.9 * self.lambda_))\n                continue\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HAMC scored 0.784 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "23fe7331-5fec-4d4d-a554-9168a2971557", "operator": null, "metadata": {"aucs": [0.2969923071377992, 0.812481516615014, 0.7925578592752673, 0.9645269499138275, 0.8910727199354399, 0.8645656600938088, 0.7931305718952929, 0.7841020172444884, 0.825443746098762, 0.8114856344073971]}, "task_prompt": ""}
{"id": "0cc6489f-ca03-463c-99e0-c117ae432a26", "fitness": 0.7778358614792589, "name": "AD_CCS", "description": "The design combines a compact CMA-style search (single mean m, covariance C) with budget-aware population sizing and hybrid sampling: targeted directional moves along top eigenvectors, Gaussian samples shaped by C, a ridge-regression “ridge-gradient” exploitation candidate built from an archive, and uniform jitter to fill remaining slots. It uses weighted recombination of the top μ samples to produce m_new and updates C with a moderate learning rate (c_cov ≈ 0.18) that blends rank-μ information and a rank‑1 term from successful steps, while initial covariance and sigma are scaled to problem bounds (diag((bounds/4)^2), sigma ≈ 0.25·mean_span). Step-size control is smoothed via a success-rate tracker p_succ with a relatively aggressive sigma_adapt_rate ≈ 0.22 toward success_target ≈ 0.20 and multiplicative expand/shrink factors (sigma_expand 1.15, sigma_shrink 0.66), plus a soft-acceptance move (soft_accept 0.85) for stability. Finally, numerical safeguards (SPD enforcement, eigenvalue clipping relative to mean_span), an archive for surrogate fitting and covariance smoothing (archive_factor 6), and budget-aware stagnation restarts (stagn_thresh_frac ≈ 0.03) provide robustness.", "code": "import numpy as np\n\nclass AD_CCS:\n    \"\"\"\n    Adaptive Directional Compact Covariance Search (AD-CCS)\n\n    One-line: Compact CMA-style sampling with eigen-direction moves and occasional ridge-surrogate gradient steps,\n    using weighted recombination, soft acceptance, sigma trust adaptation, SPD safeguards and budget-aware restarts.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        # tuning knobs\n        self.c_cov = 0.18               # covariance learning rate (rank-mu blend)\n        self.sigma_adapt_rate = 0.22    # rate for smoothed sigma adaptation\n        self.success_target = 0.20      # target success for sigma adaptation\n        self.sigma_expand = 1.15        # expand factor on clear center improvement\n        self.sigma_shrink = 0.66        # shrink factor on failure\n        self.soft_accept = 0.85         # keep fraction of old m (soft acceptance)\n        self.archive_factor = 6         # archive size multiplier times dim\n        self.stagn_thresh_frac = 0.03   # fraction of budget to detect stagnation\n        # results\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds handling (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        mean_span = float(np.mean(bounds_scale))\n        max_bound = np.max(bounds_scale)\n\n        # population base like DACS\n        lam = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        lam = min(lam, max(2, self.budget))\n\n        # initial sampling to bootstrap\n        evals = 0\n        init_batch = min(lam * 2, max(2, self.budget // 20), self.budget)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize mean from weighted recombination of top-half\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        w0 /= np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance: diagonal moderate\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = 0.25 * mean_span\n        sigma = max(sigma, 1e-12)\n\n        # archive for surrogate and cov smoothing\n        archive_capacity = max(self.dim * self.archive_factor, 4 * self.dim, 20)\n        X_hist = list(X0)\n        f_hist = list(f0)\n\n        # stagnation counters\n        stagn_iters = 0\n        stagn_thresh = max(5, int(self.stagn_thresh_frac * self.budget))\n        p_succ = 0.2  # smoothed success rate\n\n        # helper to produce SPD sqrt (A s.t. A @ A.T = C)\n        def sqrt_spd(mat):\n            try:\n                vals, vecs = np.linalg.eigh(mat)\n            except np.linalg.LinAlgError:\n                # fallback to small jitter and retry\n                vals, vecs = np.linalg.eigh(mat + 1e-12 * np.eye(self.dim))\n            vals_clipped = np.clip(vals, 1e-14, None)\n            A = (vecs * np.sqrt(vals_clipped)).T\n            return A, vals_clipped, vecs\n\n        # main loop\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu = max(1, lam_iter // 2)\n\n            # recompute weights\n            ranks = np.arange(1, mu + 1)\n            weights = np.log(mu + 0.5) - np.log(ranks)\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # eigendecomposition for directional proposals\n            try:\n                eigvals, eigvecs = np.linalg.eigh(C)\n            except np.linalg.LinAlgError:\n                eigvals = np.ones(self.dim)\n                eigvecs = np.eye(self.dim)\n            idxs = np.argsort(-eigvals)\n            eigvals = eigvals[idxs]\n            eigvecs = eigvecs[:, idxs]\n\n            candidates = []\n            # 1) directional proposals along top eigenvectors (both signs)\n            n_dir = min(max(1, lam_iter // 4), self.dim)\n            for k in range(n_dir):\n                v = eigvecs[:, k]\n                # scale by eigenvalue sqrt and sigma with random amplitude\n                scale = sigma * (0.8 + 0.6 * rng.rand()) * (np.sqrt(max(eigvals[k], 1e-12)) / (np.sqrt(np.mean(eigvals)) + 1e-12))\n                candidates.append(m + scale * v)\n                if len(candidates) >= lam_iter:\n                    break\n                candidates.append(m - scale * v)\n                if len(candidates) >= lam_iter:\n                    break\n\n            # 2) Gaussian proposals shaped by C\n            if len(candidates) < lam_iter:\n                A, _, _ = sqrt_spd(C)\n                n_gauss = lam_iter - len(candidates) - 1  # reserve 1 slot for gradient candidate\n                n_gauss = max(0, n_gauss)\n                if n_gauss > 0:\n                    Z = rng.normal(size=(n_gauss, self.dim))\n                    Y = Z @ (A.T)  # covariance C\n                    Xg = m + sigma * Y\n                    candidates.extend(list(Xg))\n\n            # 3) surrogate ridge-gradient exploitation candidate (if archive sufficient)\n            grad_candidate = None\n            if len(candidates) < lam_iter and len(f_hist) >= min(self.dim + 3, 12):\n                n_fit = min(len(X_hist), archive_capacity)\n                X_fit = np.asarray(X_hist[-n_fit:])\n                f_fit = np.asarray(f_hist[-n_fit:])\n                # find approximate f at m by nearest archived point\n                dists = np.sum((X_fit - m)**2, axis=1)\n                idx_closest = int(np.argmin(dists))\n                f_center = f_fit[idx_closest]\n                Xc = X_fit - m\n                y = f_fit - f_center\n                # ridge regression\n                lam_reg = 1e-6 * (1.0 + np.var(y))\n                XT_X = Xc.T @ Xc\n                reg = lam_reg * np.eye(self.dim)\n                try:\n                    beta = np.linalg.solve(XT_X + reg, Xc.T @ y)\n                    g = beta\n                    gnorm = np.linalg.norm(g)\n                    if gnorm > 0:\n                        step_scale = sigma * (0.7 + 0.6 * rng.rand())\n                        grad_candidate = m - (step_scale * (g / (gnorm + 1e-20)))\n                except np.linalg.LinAlgError:\n                    grad_candidate = None\n            if grad_candidate is not None:\n                candidates.append(grad_candidate)\n\n            # 4) fill remaining with jittered uniform local samples\n            while len(candidates) < lam_iter:\n                box = np.clip(sigma * 0.6, 1e-12, np.max(bounds_scale))\n                cand = m + rng.uniform(-box, box, size=self.dim)\n                candidates.append(cand)\n\n            Xcand = np.asarray(candidates[:lam_iter])\n            # clip to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate sequentially (respect budget)\n            fc = np.empty(Xcand.shape[0], dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    fc[i:] = np.inf\n                    break\n                fc[i] = float(func(Xcand[i]))\n                evals += 1\n                # update global best on the fly\n                if fc[i] < f_best:\n                    f_best = float(fc[i])\n                    x_best = Xcand[i].copy()\n                    stagn_iters = 0\n\n            # add to archive and trim\n            for xi, fi in zip(Xcand, fc):\n                X_hist.append(xi.copy())\n                f_hist.append(float(fi))\n            if len(X_hist) > archive_capacity:\n                excess = len(X_hist) - archive_capacity\n                X_hist = X_hist[excess:]\n                f_hist = f_hist[excess:]\n\n            # generation best and approximate f(m) from archive\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            if len(X_hist) > 0:\n                Xh = np.asarray(X_hist)\n                dists = np.sum((Xh - m)**2, axis=1)\n                idx0 = int(np.argmin(dists))\n                f_m_approx = float(f_hist[idx0])\n            else:\n                f_m_approx = f_best\n\n            improved_center = gen_best_f < f_m_approx - 1e-12\n\n            # recombine top-mu to compute m_new\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized deltas for covariance update\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas\n\n            # small rank-one term from successful step\n            if improved_center:\n                successful_step = (gen_best_x - m) / (sigma + 1e-20)\n                dir_cov = np.outer(successful_step, successful_step)\n                C = (1.0 - self.c_cov) * C + self.c_cov * (0.7 * weighted_cov + 0.3 * dir_cov)\n            else:\n                # conservative blending with small isotropic shrink to avoid noise\n                iso = np.diag(((bounds_scale / 8.0) ** 2).clip(min=1e-12))\n                C = (1.0 - 0.5 * self.c_cov) * C + (0.5 * self.c_cov) * weighted_cov + (0.5 * self.c_cov) * iso\n\n            # soft acceptance and sigma trust adaptation\n            if improved_center:\n                # accept and expand sigma moderately\n                m = m_new.copy()\n                sigma = min(2.0 * max_bound, sigma * self.sigma_expand)\n                stagn_iters = 0\n                succ = 1.0\n            else:\n                # keep m but shrink sigma; soft move toward m_new\n                stagn_iters += 1\n                sigma = max(1e-12, sigma * self.sigma_shrink)\n                succ = 0.0\n\n            # soft acceptance smoothing even if accepted (stability)\n            m = self.soft_accept * m + (1.0 - self.soft_accept) * m_new\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # numeric safeguards on C\n            C = 0.5 * (C + C.T)\n            vals, vecs = np.linalg.eigh(C)\n            # min eigen relative to problem scale\n            min_eig = max(1e-14, (mean_span * 1e-3) ** 2)\n            vals = np.clip(vals, min_eig, None)\n            C = (vecs * vals) @ vecs.T\n\n            # update smoothed success p_succ and multiplicative sigma adjustment\n            alpha = 0.18\n            p_succ = (1.0 - alpha) * p_succ + alpha * succ\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            # clamp sigma\n            sigma = float(np.clip(sigma, 1e-12, 1.5 * max_bound))\n\n            # restart on long stagnation or collapse\n            if (stagn_iters >= stagn_thresh) or (sigma <= 1e-10 * max_bound):\n                stagn_iters = 0\n                # jitter around best\n                jitter = max(0.05 * mean_span, sigma) * rng.randn(self.dim)\n                m = x_best + jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n                sigma = max(sigma, 0.8 * 0.25 * mean_span)\n                # small increase of sampling breadth by temporarily raising lam if budget allows\n                if self.budget < 200:\n                    lam = max(4, lam // 2)\n                continue\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AD_CCS scored 0.778 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "23fe7331-5fec-4d4d-a554-9168a2971557", "operator": null, "metadata": {"aucs": [0.36809837904301146, 0.348490691128329, 0.9574431866294142, 0.9844855083009724, 0.9753965040091758, 0.9763207859239861, 0.32799213755408374, 0.9050702980716587, 0.9745621412785567, 0.9604989828534007]}, "task_prompt": ""}
{"id": "1fb12251-d3e0-4871-bbbc-c8da2c782e40", "fitness": 0.3562519706063608, "name": "AEBH", "description": "1. AEBH maintains a small, sorted elite set (size grows mildly with dimension) and combines global anisotropic heavy‑tailed probes, covariance‑aware recombination, and short directional line‑searches to balance exploration and exploitation under a strict evaluation budget.  \n2. Global probes are elliptical/heavy‑tailed: Student‑t draws (df=4) are scaled per‑dimension by an empirical std with a floor (0.02*span) and elongated along a principal direction estimated from the elites (power iteration), so jumps are both axis‑aware and directionally biased.  \n3. Local refinement uses covariance‑informed recombination and budget‑aware mini line‑searches whose step lengths are tied to per‑dimension scales and avg_span, while acceptance is probabilistic with a decaying temperature (base_temp) that can warm up during stagnation to allow uphill escapes.  \n4. Robustness features include dimension/budget‑aware initial sampling, jittered restarts and occasional uniform injections, adaptive temperature and hard restarts that spawn jittered clusters around the best solution to recover from stagnation.", "code": "import numpy as np\n\nclass AEBH:\n    \"\"\"\n    Adaptive Elliptical Basin Hopping (AEBH)\n\n    Main idea (one line): Maintain a small elite set, build an anisotropic elliptical search\n    operator from elite covariance (low-rank principal direction elongation) and combine it\n    with covariance-aware recombination and short directional line-searches; use a\n    temperature-like acceptance and adaptive restarts to trade exploration/exploitation\n    under a strict evaluation budget.\n\n    Constructor: AEBH(budget, dim, rng_seed=None, elite_size=None, df=4, base_temp=0.5)\n    - budget, dim: required\n    - rng_seed: optional random seed\n    - elite_size: optional number of elites to maintain\n    - df: degrees of freedom for heavy-tailed Student-t draws used in global probes\n    - base_temp: initial temperature used in probabilistic acceptance of uphill moves\n    \"\"\"\n\n    def __init__(self, budget, dim, rng_seed=None, elite_size=None, df=4, base_temp=0.5):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.df = float(df)\n        self.base_temp = float(base_temp)\n        # adaptive default elite size if not provided\n        if elite_size is None:\n            # keep small but grow mildly with dimension\n            self.elite_size = max(3, min(12, int(np.ceil(np.sqrt(self.dim) * 1.8))))\n        else:\n            self.elite_size = int(elite_size)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # handle bounds (func.bounds.lb/ub may be scalar or arrays)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # bookkeeping\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        elites = []  # list of (f, x) kept sorted ascending by f\n\n        # helper to safely evaluate and maintain elites\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, elites\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # clip\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = float(func(x))\n            evals += 1\n            # update global best\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # maintain sorted elites\n            if len(elites) < self.elite_size or f < elites[-1][0]:\n                elites.append((f, x.copy()))\n                elites.sort(key=lambda t: t[0])\n                if len(elites) > self.elite_size:\n                    elites.pop()\n            return f, x\n\n        # initial sampling: a small but dimension-aware batch\n        init_N = int(min(max(8, 6 * self.dim), max(10, self.budget // 10), 200))\n        init_N = min(init_N, self.budget)\n        for _ in range(init_N):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one sample\n        if len(elites) == 0 and evals < self.budget:\n            eval_and_record(rng.uniform(lb, ub))\n\n        # helpers: per-dim scale baseline derived from elites or global span\n        def per_dim_scale():\n            # returns a positive array of scales for each dimension\n            if len(elites) >= 2:\n                pts = np.vstack([t[1] for t in elites])\n                std = np.std(pts, axis=0, ddof=0)\n                # combine empirical std with a small fraction of global span to avoid collapse\n                return np.maximum(std, 0.02 * span)\n            else:\n                # fallback coarse exploration scale\n                return 0.2 * span\n\n        # compute a low-rank directional elongation using principal direction (power iteration)\n        def principal_direction():\n            if len(elites) >= 2:\n                pts = np.vstack([t[1] for t in elites])\n                C = np.cov(pts.T)  # shape (dim, dim)\n                # power iteration for largest eigenvector\n                v = rng.randn(self.dim)\n                v /= (np.linalg.norm(v) + 1e-12)\n                for _ in range(6):\n                    v = C.dot(v)\n                    nrm = np.linalg.norm(v) + 1e-12\n                    v /= nrm\n                return v / (np.linalg.norm(v) + 1e-12)\n            else:\n                # random unit vector\n                v = rng.randn(self.dim)\n                return v / (np.linalg.norm(v) + 1e-12)\n\n        # elliptical (anisotropic) heavy-tailed probe\n        def elliptical_probe(center, scale_factor=1.0, elongation=1.8):\n            # center: numpy array\n            # scale_factor: multiply baseline magnitude\n            # elongation: factor >1 elongates along principal direction\n            dscale = per_dim_scale()\n            pdir = principal_direction()\n            # student-t vector\n            z = rng.standard_t(self.df, size=self.dim)\n            # anisotropic scale per-dim: baseline times scale factor and a random jitter\n            base = dscale * (0.2 * scale_factor * avg_span) * (1.0 + 0.5 * rng.rand())\n            # enhance projection along principal direction\n            proj = np.dot(z, pdir)\n            # make step where components aligned with pdir get elongated\n            anis = 1.0 + (elongation - 1.0) * (proj ** 2)  # amplification ~ squared projection\n            step = z * base * anis\n            cand = center + step\n            return np.minimum(np.maximum(cand, lb), ub)\n\n        # covariance-aware recombination (convex blend + small heavy-tailed noise)\n        def recombine_elites():\n            if len(elites) >= 2:\n                # biased toward best: pick i=best, j=random\n                i = 0\n                j = rng.randint(1, len(elites))\n                x1 = elites[i][1]\n                x2 = elites[j][1]\n                alpha = 0.2 + 0.6 * rng.rand()  # blend weight in [0.2,0.8]\n                child = alpha * x1 + (1 - alpha) * x2\n                # add small anisotropic heavy-tailed perturbation\n                noise = rng.standard_t(self.df, size=self.dim) * (0.06 * per_dim_scale())\n                child = child + noise\n                return np.minimum(np.maximum(child, lb), ub)\n            else:\n                return rng.uniform(lb, ub)\n\n        # directional mini line-search (short, budget-aware)\n        def directional_minisearch(x0, f0, direction, local_budget):\n            # tries progressive shrinking/extension along direction with geometric steps\n            if local_budget <= 0 or evals >= self.budget:\n                return f0, x0\n            dir_norm = direction / (np.linalg.norm(direction) + 1e-12)\n            # initial step length tied to per-dim scale projected onto direction\n            pscale = per_dim_scale()\n            init_step = max(0.02 * avg_span, 0.15 * np.dot(pscale, np.abs(dir_norm)) )\n            step = init_step\n            best_x = x0.copy()\n            best_f = float(f0)\n            calls = 0\n            # allow a small number of probes depending on local_budget and dim\n            max_probes = min(local_budget, 6 + self.dim // 3)\n            while calls < max_probes and evals < self.budget:\n                # try forward and backward\n                for sgn in (+1.0, -1.0):\n                    if evals >= self.budget or calls >= max_probes:\n                        break\n                    cand = best_x + sgn * step * dir_norm\n                    cand = np.minimum(np.maximum(cand, lb), ub)\n                    res = eval_and_record(cand)\n                    calls += 1\n                    if res is None:\n                        break\n                    fc, xc = res\n                    if fc < best_f:\n                        best_f = fc\n                        best_x = xc.copy()\n                        # allow a pattern extension once\n                        ext = best_x + 1.5 * sgn * step * dir_norm\n                        ext = np.minimum(np.maximum(ext, lb), ub)\n                        res2 = eval_and_record(ext)\n                        calls += 1\n                        if res2 is None:\n                            break\n                        fext, xext = res2\n                        if fext < best_f:\n                            best_f = fext\n                            best_x = xext.copy()\n                        # after improvement, keep same step to exploit\n                # if no improvement in both directions, shrink step\n                step *= 0.5\n                if step < 1e-12 * avg_span:\n                    break\n            return best_f, best_x\n\n        # acceptance: probabilistic uphill acceptance with temperature schedule\n        def accept_candidate(fcand, fref, current_evals):\n            # temperature decays slowly with evaluations remaining\n            # avoid zero division\n            frac = float(current_evals) / max(1.0, self.budget)\n            T = self.base_temp * (1.0 - 0.8 * frac) + 1e-12\n            if fcand <= fref:\n                return True\n            else:\n                p = np.exp(-(fcand - fref) / (T * (1.0 + 0.5 * frac)))\n                return rng.rand() < p\n\n        # main loop\n        attempts = 0\n        no_improve_since = 0\n        stagnation_restart_thresh = max(20, int(0.06 * self.budget))\n        # nominal probabilities\n        while evals < self.budget:\n            attempts += 1\n            remaining = self.budget - evals\n\n            # adapt global vs local tendencies: more global when stagnating\n            p_global = min(0.95, 0.35 + 0.55 * (1.0 - np.exp(-no_improve_since / 8.0)))\n            r = rng.rand()\n\n            # pick a center: usually best, sometimes a random elite, occasionally random point\n            if len(elites) > 0:\n                if rng.rand() < 0.8:\n                    center = elites[0][1].copy()\n                    center_f = elites[0][0]\n                else:\n                    idx = rng.randint(0, len(elites))\n                    center_f, center = elites[idx]\n            else:\n                center = rng.uniform(lb, ub)\n                center_f = None\n\n            performed_local = False\n\n            if r < p_global:\n                # Global elliptical probe\n                scale_factor = 0.8 + 2.2 / (1.0 + 0.02 * attempts)  # decays but stays >0.8\n                elongation = 1.2 + 3.0 * (min(1.0, no_improve_since / 20.0))  # elongate more when stuck\n                cand = elliptical_probe(center, scale_factor=scale_factor, elongation=elongation)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                fcand, xcand = res\n\n                # acceptance vs best (probabilistic)\n                if accept_candidate(fcand, f_best, evals):\n                    # update no_improve counter based on improvement over global best\n                    if fcand < f_best:\n                        no_improve_since = 0\n                    else:\n                        no_improve_since += 1\n                else:\n                    no_improve_since += 1\n\n                # if candidate is promising relative to center or elites, do a short directional mini-search\n                threshold = elites[0][0] if len(elites) > 0 else np.inf\n                if remaining > 3 and fcand <= threshold * (1.10 + 0.03 * rng.rand()):\n                    # choose search direction: either principal direction or the vector from center to candidate or a random coordinate\n                    if rng.rand() < 0.5:\n                        direction = (xcand - center)\n                        if np.linalg.norm(direction) < 1e-12:\n                            direction = principal_direction()\n                    elif rng.rand() < 0.8:\n                        direction = principal_direction()\n                    else:\n                        # random coordinate direction\n                        idx = rng.randint(0, self.dim)\n                        direction = np.zeros(self.dim)\n                        direction[idx] = 1.0\n                    # local budget is small and adaptive\n                    local_budget = int(min( max(2, remaining // 15 ), 8 + self.dim // 4 ))\n                    local_budget = max(1, local_budget)\n                    f_after, x_after = directional_minisearch(xcand, fcand, direction, local_budget)\n                    performed_local = True\n                    if f_after < f_best:\n                        no_improve_since = 0\n                    else:\n                        no_improve_since += 1\n\n            else:\n                # local refinement / recombination / jittered restart\n                # decide between recombination, short local search around elite, or jittered sample\n                p_recomb = 0.25\n                p_local = 0.55\n                rs = rng.rand()\n                if rs < p_recomb and len(elites) >= 2:\n                    child = recombine_elites()\n                    res = eval_and_record(child)\n                    if res is None:\n                        break\n                    fc, xc = res\n                    if fc < f_best:\n                        no_improve_since = 0\n                    else:\n                        no_improve_since += 1\n                elif rs < p_recomb + p_local and len(elites) >= 1:\n                    # perform a directional minisearch from a selected elite\n                    if rng.rand() < 0.85:\n                        start_f, start_x = elites[0]\n                    else:\n                        idx = rng.randint(0, len(elites))\n                        start_f, start_x = elites[idx]\n                    # choose direction from local covariance principal or a coordinate\n                    if rng.rand() < 0.6:\n                        direction = principal_direction()\n                    else:\n                        idx = rng.randint(0, self.dim)\n                        direction = np.zeros(self.dim)\n                        direction[idx] = 1.0\n                    local_budget = int(min(max(2, remaining // 20), 6 + self.dim // 5))\n                    f_after, x_after = directional_minisearch(start_x, start_f, direction, local_budget)\n                    performed_local = True\n                    if f_after < f_best:\n                        no_improve_since = 0\n                    else:\n                        no_improve_since += 1\n                else:\n                    # jittered restart around best or uniform random if no best\n                    if x_best is not None and rng.rand() < 0.85:\n                        dscale = per_dim_scale()\n                        jitter = rng.normal(scale=0.12 * dscale)\n                        cand = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                    else:\n                        cand = rng.uniform(lb, ub)\n                    res = eval_and_record(cand)\n                    if res is None:\n                        break\n                    fc, xc = res\n                    if fc < f_best:\n                        no_improve_since = 0\n                    else:\n                        no_improve_since += 1\n\n            # occasional uniform injection (rare)\n            if (attempts % 31) == 0 and evals < self.budget:\n                eval_and_record(rng.uniform(lb, ub))\n\n            # adaptive temperature/base behavior: slightly warm up if long stagnation to allow escapes\n            if no_improve_since > 10:\n                self.base_temp = min(2.0, self.base_temp * 1.05)\n            else:\n                # slowly cool down towards 0.4\n                self.base_temp = max(0.25, self.base_temp * 0.995)\n\n            # hard restart when extreme stagnation for many evals: create small cluster around best\n            if no_improve_since * 5 > stagnation_restart_thresh and evals < self.budget:\n                # spawn k random jittered samples around best to refill elites\n                K = min(self.elite_size * 2, max(3, int(0.07 * (self.budget - evals))))\n                dscale = per_dim_scale()\n                for _ in range(K):\n                    if evals >= self.budget:\n                        break\n                    jitter = rng.normal(scale=0.2 * dscale)\n                    xnew = np.minimum(np.maximum((x_best if x_best is not None else rng.uniform(lb, ub)) + jitter, lb), ub)\n                    eval_and_record(xnew)\n                # reset stagnation counter moderately\n                no_improve_since = 0\n\n            if evals >= self.budget:\n                break\n\n        # finalize best\n        if x_best is None and len(elites) > 0:\n            f_best, x_best = elites[0]\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AEBH scored 0.356 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "22fdb245-00ef-4d24-9240-afb45392d5d6", "operator": null, "metadata": {"aucs": [0.11339174876624925, 0.22747222910147935, 0.4507698605982249, 0.9190543440177759, 0.24252429501583728, 0.5476845834761285, 0.2511375021681548, 0.3764058404931936, 0.2612828116660677, 0.1727964907604974]}, "task_prompt": ""}
{"id": "4b299d0c-037b-4aec-ba35-51973f3553a2", "fitness": 0.4026754121676442, "name": "AMLS", "description": "AMLS maintains a small, log(dim)-scaled elite archive and balances long-range exploration with focused local refinement using a budget-aware controller. Global moves are directional, Lévy-like Student-t jumps (low df ≈1.5) with anisotropic per-dimension scaling derived from archive MAD to respect variable-wise diversity, plus archive-weighted recombination (centroid + differential, recomb_beta≈0.6) for informed variation. Local exploitation is a stochastic coordinate-pattern search seeded from elites with MAD-initialized per-dim steps, pattern-extension (pattern_factor≈1.8) and aggressive shrinkage on stagnation (shrink≈0.55), and it consumes carefully allocated micro-budgets (local_frac≈0.06). Adaptation and robustness come from a logistic rule that increases global-search probability with no-improvement streaks, occasional uniform injections/jittered restarts, and small randomized restarts to avoid premature convergence.", "code": "import numpy as np\n\nclass AMLS:\n    \"\"\"\n    Adaptive Multi-scale Lévy Search (AMLS)\n\n    Main idea:\n    - Maintain a small elite archive of best points (archive size grows slowly with dim).\n    - Perform directional heavy-tailed jumps (Student-t with low df) scaled anisotropically\n      using per-dimension MAD (median absolute deviation) from the archive.\n    - Use an archive-weighted recombination operator to generate diverse candidates.\n    - Apply a budget-aware stochastic coordinate-pattern local search seeded from archive/best\n      points with adaptive per-dimension steps that shrink aggressively on stagnation.\n    - Adapt the global/local decision probability using a logistic-like rule based on\n      consecutive non-improvements. Occasional uniform injections and jittered restarts\n      maintain exploration.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10,\n                 init_samples=None,\n                 archive_size=None,\n                 global_base_prob=0.25,\n                 local_frac=0.06,\n                 student_df=1.5,\n                 shrink=0.55,\n                 pattern_factor=1.8,\n                 recomb_beta=0.6,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.global_base_prob = float(global_base_prob)\n        self.local_frac = float(local_frac)\n        self.student_df = float(student_df)\n        self.shrink = float(shrink)\n        self.pattern_factor = float(pattern_factor)\n        self.recomb_beta = float(recomb_beta)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds handling (support scalar or array)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive defaults (different equations)\n        if self.init_samples is None:\n            # a bit more initial samples in low dims, but bounded by budget\n            init_samples = int(min(max(12, 3 * self.dim), max(10, self.budget // 12), 200))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, self.budget)\n\n        if self.archive_size is None:\n            # archive grows with log(dim) to keep it small for large dims\n            archive_k = int(max(3, min(14, int(2 + 3 * np.log1p(self.dim)))))\n        else:\n            archive_k = int(self.archive_size)\n\n        # bookkeeping\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x), sorted by f ascending\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # clip to bounds\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = float(func(x))\n            evals += 1\n            # update global best\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # maintain archive (sorted)\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # initial uniform sampling\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one sample\n        if len(archive) == 0 and evals < self.budget:\n            eval_and_record(rng.uniform(lb, ub))\n\n        # helper: compute MAD-based per-dim diversity scale (different from std/span)\n        def diversity_scale():\n            # median absolute deviation of archive points or fallback\n            if len(archive) >= 2:\n                pts = np.vstack([t[1] for t in archive])\n                med = np.median(pts, axis=0)\n                mad = np.median(np.abs(pts - med), axis=0)\n                # scale minima and combine with a small fraction of global span\n                base = np.maximum(mad, 0.015 * span)\n                # encourage slightly larger steps when archive is small\n                factor = 1.0 + 0.5 * np.exp(-len(archive) / max(1.0, archive_k))\n                return base * factor + 1e-12\n            else:\n                return np.maximum(0.18 * span, 0.015 * span)\n\n        # Lévy-like global jump (directional Student-t based, different scaling)\n        def levy_jump(center, scale_factor):\n            direction = rng.randn(self.dim)\n            norm = np.linalg.norm(direction) + 1e-12\n            direction /= norm\n            # heavy-tailed length\n            t_draw = rng.standard_t(self.student_df)\n            # anisotropic per-dim scale from MAD\n            dscale = diversity_scale()\n            anis = dscale / (np.mean(dscale) + 1e-12)\n            # global amplitude uses scale_factor * avg_span with randomized multiplier\n            amp = (0.2 * avg_span) * scale_factor * (0.6 + 0.8 * rng.rand())\n            step = direction * amp\n            step = step * anis\n            return center + t_draw * step\n\n        # archive-guided recombination (weighted centroid + differential)\n        def recombine_archive():\n            if len(archive) >= 2:\n                # weights favor better points exponentially\n                fs = np.array([t[0] for t in archive])\n                w = np.exp(- (fs - fs.min()) / (1e-8 + (fs.std() if fs.std() > 0 else 1.0)))\n                w /= w.sum()\n                centroid = np.sum([w[i] * archive[i][1] for i in range(len(archive))], axis=0)\n                # pick two distinct elites and form differential contribution\n                i, j = rng.choice(len(archive), size=2, replace=False)\n                diff = archive[i][1] - archive[j][1]\n                child = centroid + self.recomb_beta * diff + 0.03 * avg_span * rng.standard_t(self.student_df, size=self.dim)\n                return np.minimum(np.maximum(child, lb), ub)\n            else:\n                return rng.uniform(lb, ub)\n\n        # stochastic coordinate-pattern local search (budget-aware)\n        def local_search(x0, f0, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f0, x0\n            base = x0.copy()\n            base_f = float(f0)\n            # initialize per-dim steps from MAD but capped\n            dscale = diversity_scale()\n            steps = np.minimum(0.6 * dscale, 0.45 * avg_span)\n            # small randomization for steps to avoid lock-step\n            steps *= (0.85 + 0.3 * rng.rand(self.dim))\n            local_used = 0\n            iters = 0\n            iter_limit = max(1, int(np.ceil(local_budget / max(1, self.dim))))\n            while local_used < local_budget and iters < iter_limit and np.any(steps > 1e-11):\n                iters += 1\n                improved = False\n                probe = base.copy()\n                probe_f = base_f\n                # randomized subset of coordinates (not necessarily all)\n                kcoords = max(1, int(0.7 * self.dim))\n                coords = rng.choice(self.dim, size=kcoords, replace=False)\n                for idx in coords:\n                    if local_used >= local_budget or evals >= self.budget:\n                        break\n                    # try positive\n                    xp = probe.copy()\n                    xp[idx] = np.clip(xp[idx] + steps[idx], lb[idx], ub[idx])\n                    res = eval_and_record(xp)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < probe_f:\n                        probe = xp.copy()\n                        probe_f = fp\n                        improved = True\n                        continue\n                    # try negative\n                    xn = probe.copy()\n                    xn[idx] = np.clip(xn[idx] - steps[idx], lb[idx], ub[idx])\n                    res = eval_and_record(xn)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < probe_f:\n                        probe = xn.copy()\n                        probe_f = fn\n                        improved = True\n                # pattern extension if improved\n                if improved and np.linalg.norm(probe - base) > 0 and local_used < local_budget:\n                    direction = probe - base\n                    xp = base + self.pattern_factor * direction\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res = eval_and_record(xp)\n                    local_used += 1\n                    if res is not None:\n                        fp, xp = res\n                        if fp < probe_f:\n                            base = xp.copy()\n                            base_f = fp\n                        else:\n                            base = probe.copy()\n                            base_f = probe_f\n                    else:\n                        base = probe.copy()\n                        base_f = probe_f\n                else:\n                    # shrink steps if no improvement\n                    steps *= self.shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # main loop\n        attempt = 0\n        no_improve_since = 0\n        # logistic-style adaptation parameters\n        logistic_k = 0.9\n        logistic_shift = 4.0\n\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n\n            # allocate a small local budget chunk (different equation)\n            max_local = max(3, int(self.local_frac * self.budget))\n            alloc_local = min(max_local, max(2, int(0.04 * remaining)))\n            alloc_local = min(alloc_local, remaining - 1) if remaining > 1 else 0\n\n            # adapt global probability using a logistic-like increase with stagnation\n            p_global = np.clip(self.global_base_prob + \\\n                               (0.9 - self.global_base_prob) / (1.0 + np.exp(- (no_improve_since - logistic_shift) / logistic_k)),\n                               0.02, 0.92)\n\n            do_global = (rng.rand() < p_global)\n\n            if do_global and len(archive) > 0:\n                # center selection: weighted pick among elites (favor best but allow others)\n                if rng.rand() < 0.7:\n                    center = archive[0][1]\n                else:\n                    weights = np.linspace(1.0, 0.3, num=len(archive))\n                    weights = weights / weights.sum()\n                    idx = rng.choice(len(archive), p=weights)\n                    center = archive[idx][1]\n                # scale decays with attempts according to a different formula\n                scale = max(0.06, 1.0 / (1.0 + 0.02 * np.sqrt(attempt)))\n                cand = levy_jump(center, scale)\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n\n                if f_cand < f_best:\n                    no_improve_since = 0\n                else:\n                    no_improve_since += 1\n\n                # if candidate is promising relative to the best elite, attempt local search\n                threshold = archive[0][0] if len(archive) > 0 else np.inf\n                if alloc_local > 0 and f_cand <= threshold * (1.06 + 0.03 * rng.rand()):\n                    local_alloc = min(remaining - 1, max(1, int(alloc_local * (0.8 + rng.rand() * 0.6))))\n                    f_after, x_after = local_search(cand, f_cand, local_alloc)\n                    if f_after < f_best:\n                        no_improve_since = 0\n                    else:\n                        no_improve_since += 1\n                else:\n                    # occasionally recombine instead of local search\n                    if rng.rand() < 0.18 and evals < self.budget:\n                        child = recombine_archive()\n                        res = eval_and_record(child)\n                        if res is None:\n                            break\n                        fc, child = res\n                        if fc < f_best:\n                            no_improve_since = 0\n                        else:\n                            no_improve_since += 1\n            else:\n                # local refinement or jittered restart\n                r = rng.rand()\n                if r < 0.58 and len(archive) > 0:\n                    start_f, start_x = archive[0]\n                elif r < 0.9 and len(archive) > 1:\n                    idx = rng.randint(0, len(archive))\n                    start_f, start_x = archive[idx]\n                else:\n                    # jittered restart around best with MAD anisotropic noise\n                    if x_best is not None:\n                        dscale = diversity_scale()\n                        jitter = rng.normal(scale=0.12 * dscale)\n                        start_x = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                    else:\n                        start_x = rng.uniform(lb, ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n\n                local_budget = min(alloc_local, max(2, int(0.07 * remaining)))\n                f_after, x_after = local_search(start_x, start_f, local_budget)\n                if f_after < f_best:\n                    no_improve_since = 0\n                else:\n                    no_improve_since += 1\n\n            # occasional uniform injection to maintain exploration\n            if (attempt % 19) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # gentle adaptation of base prob: increase if long stagnation, else decay slowly\n            if no_improve_since > 10:\n                self.global_base_prob = min(0.9, self.global_base_prob + 0.035)\n            else:\n                self.global_base_prob = max(0.02, self.global_base_prob * 0.996)\n\n            # small randomized restart if stuck for very long\n            if no_improve_since > 35 and evals + 3 < self.budget:\n                for _ in range(3):\n                    xr = rng.uniform(lb, ub)\n                    eval_and_record(xr)\n                no_improve_since = 0\n\n            if evals >= self.budget:\n                break\n\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AMLS scored 0.403 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "22fdb245-00ef-4d24-9240-afb45392d5d6", "operator": null, "metadata": {"aucs": [0.061313105258682055, 0.16524106885402146, 0.6912139987328872, 0.9924232457851582, 0.3142119476652133, 0.987774828540582, 0.22733407151260154, 0.27178974145949997, 0.1971029217199728, 0.11834919214782325]}, "task_prompt": ""}
{"id": "a49f5e12-24c5-4d72-aa00-214ea649214a", "fitness": 0.34145375097788555, "name": "DLASS", "description": "DLASS is a hybrid global–local heuristic that maintains a small elite archive (size ~ sqrt(dim)) and builds a low-rank PCA/covariance from those elites to generate anisotropic, eigenvalue-scaled search axes for concentrated search in promising subspaces. Global exploration uses heavy-tailed Student-t (Lévy-like) jumps in top principal components and convex recombination of elites (with anisotropic t-noise), while local exploitation uses budget-aware multiplicative directional probes (geometric step increases) along principal directions or improvement vectors to aggressively extend improvements. Several budget- and progress-aware mechanisms steer behavior: initial uniform sampling, clipping to bounds, adaptive archive/PCA regularization, radius_scale and student_df tuning for diversification, adaptive explore probability driven by a no-improvement counter, occasional mirror-jitter restarts, and strict evaluation counting to never exceed the budget.", "code": "import numpy as np\n\nclass DLASS:\n    \"\"\"\n    Directional Lévy Adaptive Subspace Search (DLASS)\n\n    Main ideas:\n    - Maintain a small elite archive (adaptive size ~ sqrt(dim)).\n    - Build a low-rank approximate covariance / principal axes from the archive.\n      Use those principal axes to generate anisotropic, heavy-tailed (Student-t)\n      jumps concentrated in promising low-dimensional subspaces.\n    - Use convex recombination of elites + small Lévy/Student noise for diversification.\n    - For exploitation, perform budget-aware multiplicative directional probes (geometric line steps)\n      along promising directions (principal axes or improvement vectors), extending while improving.\n    - Adaptive probabilities and step radii change slowly with no-improvement counters.\n    - Always clip points to bounds; never exceed budget.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 init_frac=0.08, base_explore_prob=0.22, student_df=1.7):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_frac = float(init_frac)\n        self.base_explore_prob = float(base_explore_prob)\n        self.student_df = float(student_df)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds (support scalar or array)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive initial sampling\n        init_samples = min(max(12, int(self.init_frac * self.budget)), self.budget)\n        init_samples = max(init_samples, min(80, 6 * self.dim))\n\n        # archive size scales ~ sqrt(dim) with bounds\n        archive_k = int(max(3, min(16, int(np.ceil(np.sqrt(self.dim) * 1.7)))))\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x) sorted ascending by f\n\n        # evaluation wrapper (budget-aware)\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = float(func(x))\n            evals += 1\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # insert into archive sorted\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # initial uniform sampling\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one archive member\n        if len(archive) == 0 and evals < self.budget:\n            eval_and_record(rng.uniform(lb, ub))\n\n        # helper: compute principal axes from archive (low-rank PCA)\n        def principal_axes(k=None, shrink_floor=0.02):\n            if k is None:\n                k = min(self.dim, max(1, int(np.ceil(len(archive) / 2))))\n            if len(archive) < 2:\n                # fallback: axis-aligned\n                scales = np.maximum(shrink_floor * span, 0.05 * avg_span)\n                axes = np.eye(self.dim)\n                vals = np.ones(self.dim) * np.mean(scales)\n                return axes, vals\n            pts = np.vstack([t[1] for t in archive])\n            mean = np.mean(pts, axis=0)\n            C = np.cov((pts - mean).T, bias=True)\n            # regularize to avoid singular\n            C += np.diag((0.01 * avg_span) ** 2 * np.ones(self.dim))\n            try:\n                vals, axes = np.linalg.eigh(C)  # vals ascending\n            except np.linalg.LinAlgError:\n                # fallback\n                axes = np.eye(self.dim)\n                vals = np.ones(self.dim) * (0.05 * avg_span) ** 2\n            # sort descending by eigenvalue\n            idx = np.argsort(-vals)\n            vals = np.maximum(vals[idx], (shrink_floor * avg_span) ** 2)\n            axes = axes[:, idx]\n            return axes, vals\n\n        # recombination operator: convex combination of a few elites + small t-noise\n        def recombine_elites():\n            if len(archive) == 0:\n                return rng.uniform(lb, ub)\n            m = min(4, len(archive))\n            idx = rng.choice(len(archive), size=m, replace=False)\n            weights = rng.exponential(scale=1.0, size=m)\n            weights /= np.sum(weights)\n            child = sum(weights[i] * archive[idx[i]][1] for i in range(m))\n            # add anisotropic heavy-tailed noise along principal axes\n            axes, vals = principal_axes(k=min(4, self.dim))\n            coeffs = rng.standard_t(self.student_df, size=axes.shape[1]) * (0.06 * avg_span)\n            noise = axes[:, :coeffs.size].dot(coeffs * np.sqrt(vals[:coeffs.size]) / (avg_span + 1e-12))\n            child = child + noise\n            child = np.minimum(np.maximum(child, lb), ub)\n            return child\n\n        # global subspace Lévy jump: sample in top-r principal components, plus isotropic tail\n        def subspace_levy_jump(center, radius_scale):\n            axes, vals = principal_axes(k=min(self.dim, max(1, int(len(archive) ** 0.5))))\n            r = int(max(1, min(self.dim, axes.shape[1])))\n            # choose random subspace dimension between 1 and r biased to small dims\n            subdim = max(1, int(r * (rng.rand() ** 1.8)))\n            # prepare coefficients heavy-tailed per-axis\n            coeffs = rng.standard_t(self.student_df, size=subdim)\n            axis_scales = np.sqrt(vals[:subdim])\n            step = axes[:, :subdim].dot(coeffs * axis_scales * (radius_scale * 0.25 * avg_span))\n            # small isotropic background\n            iso = rng.standard_t(max(1.0, min(3.0, self.student_df))) * (0.06 * avg_span) * rng.randn(self.dim) / (np.linalg.norm(rng.randn(self.dim)) + 1e-12)\n            cand = center + step + iso\n            return np.minimum(np.maximum(cand, lb), ub)\n\n        # multiplicative directional probe (budget-aware): geometric stepping along direction while improving\n        def directional_probe(x0, f0, direction, max_probes):\n            \"\"\"\n            Start at x0, try steps: step = base * factor^k along 'direction' (direction normalized).\n            Continue while improvement and budget remains, up to max_probes evaluations.\n            Return best found (f, x).\n            \"\"\"\n            nonlocal evals, f_best, x_best\n            if max_probes <= 0 or evals >= self.budget:\n                return f0, x0\n            d = np.asarray(direction, dtype=float)\n            nrm = np.linalg.norm(d) + 1e-12\n            d = d / nrm\n            # base step depends on diversity and avg_span\n            axes, vals = principal_axes()\n            base_step = max(0.01 * avg_span, 0.08 * np.sqrt(np.mean(vals)))  # conservative base\n            factor = 1.8  # multiplicative factor\n            best_f = f0\n            best_x = x0.copy()\n            probes = 0\n            k = 0\n            while probes < max_probes and evals < self.budget:\n                step = base_step * (factor ** k)\n                cand = best_x + step * d\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                probes += 1\n                if res is None:\n                    break\n                fc, xc = res\n                if fc < best_f:\n                    best_f = fc\n                    best_x = xc.copy()\n                    # continue exploring further in same direction (aggressive exploitation)\n                    k += 1\n                    # if we improved a lot, allow a few extra probes\n                    if fc < 0.95 * f0:\n                        max_probes = min(max_probes + 2, 30)\n                else:\n                    # try the opposite direction once\n                    cand2 = best_x - step * d\n                    cand2 = np.minimum(np.maximum(cand2, lb), ub)\n                    res2 = eval_and_record(cand2)\n                    probes += 1\n                    if res2 is None:\n                        break\n                    f2, x2 = res2\n                    if f2 < best_f:\n                        best_f = f2\n                        best_x = x2.copy()\n                        # continue negative direction next iteration\n                        k = 1\n                    else:\n                        # shrink base step and stop\n                        break\n                if probes >= max_probes:\n                    break\n                # safety cap on k to avoid huge steps\n                if k > 8:\n                    break\n            return best_f, best_x\n\n        # main loop variables\n        attempts = 0\n        no_improve = 0\n        explore_prob = float(self.base_explore_prob)\n        # phase schedule: initial exploration bias then move to exploitation\n        while evals < self.budget:\n            attempts += 1\n            remaining = self.budget - evals\n            # adaptive probabilities: increase exploration when stuck\n            p_explore = min(0.95, max(0.03, explore_prob * (1.0 + 0.6 * np.tanh((no_improve - 6) / 3.0))))\n            do_explore = (rng.rand() < p_explore)\n\n            # choose center: best with high probability, else random elite, else random\n            if len(archive) > 0 and rng.rand() < 0.8:\n                center = archive[0][1].copy()\n                center_f = archive[0][0]\n            elif len(archive) > 0:\n                idx = rng.randint(0, len(archive))\n                center = archive[idx][1].copy()\n                center_f = archive[idx][0]\n            else:\n                center = rng.uniform(lb, ub)\n                res = eval_and_record(center)\n                if res is None:\n                    break\n                center_f, center = res\n\n            if do_explore:\n                # exploration: either a subspace Lévy jump or recombination-generated child\n                if rng.rand() < 0.6:\n                    # radius scale decreases gently with attempts, but increases if stuck\n                    radius_scale = max(0.06, 0.9 / (1.0 + 0.012 * attempts))\n                    if no_improve > 7:\n                        radius_scale *= (1.0 + 0.8 * np.tanh((no_improve - 7) / 5.0))\n                    cand = subspace_levy_jump(center, radius_scale)\n                    res = eval_and_record(cand)\n                    if res is None:\n                        break\n                    fc, xc = res\n                else:\n                    child = recombine_elites()\n                    res = eval_and_record(child)\n                    if res is None:\n                        break\n                    fc, xc = res\n\n                # update no_improve\n                if fc < f_best:\n                    no_improve = 0\n                else:\n                    no_improve += 1\n\n                # opportunistic directional probe if candidate is promising relative to elite\n                if len(archive) > 0 and fc <= archive[0][0] * (1.05 + 0.03 * rng.rand()) and remaining > 8:\n                    # direction: from center to candidate\n                    dir_vec = xc - center\n                    # allocate a small budget for local probing\n                    local_budget = min( int(max(3, 0.04 * remaining)), remaining - 1)\n                    f_after, x_after = directional_probe(xc, fc, dir_vec if np.linalg.norm(dir_vec) > 1e-12 else (rng.randn(self.dim)), local_budget)\n                    if f_after < f_best:\n                        no_improve = 0\n                    else:\n                        no_improve += 1\n\n            else:\n                # exploitation: directional probes from best or along principal axes\n                if len(archive) > 0:\n                    if rng.rand() < 0.6:\n                        # probe along principal directions (top eigenvector)\n                        axes, vals = principal_axes(k= min(self.dim, max(1, int(np.ceil(len(archive)/2)))))\n                        top = axes[:, 0]\n                        # choose sign randomly\n                        if rng.rand() < 0.5:\n                            top = -top\n                        local_budget = min(int(max(4, 0.06 * remaining)), remaining - 1)\n                        f_after, x_after = directional_probe(center, center_f, top, local_budget)\n                    else:\n                        # convex recombination + short probe\n                        child = recombine_elites()\n                        res = eval_and_record(child)\n                        if res is None:\n                            break\n                        fc, xc = res\n                        if fc < f_best:\n                            no_improve = 0\n                        else:\n                            no_improve += 1\n                        # quick probe along improvement vector\n                        dir_vec = xc - center\n                        if np.linalg.norm(dir_vec) > 1e-12 and remaining > 6:\n                            local_budget = min(6, remaining - 1)\n                            f_after, x_after = directional_probe(xc, fc, dir_vec, local_budget)\n                            if f_after < f_best:\n                                no_improve = 0\n                            else:\n                                no_improve += 1\n                else:\n                    # fallback random sample\n                    xrand = rng.uniform(lb, ub)\n                    res = eval_and_record(xrand)\n                    if res is None:\n                        break\n                    fr, xr = res\n                    if fr < f_best:\n                        no_improve = 0\n                    else:\n                        no_improve += 1\n\n            # occasional jittered mirror restart to inject diversity (budget-aware)\n            if attempts % 17 == 0 and evals < self.budget:\n                if x_best is not None:\n                    mirror = lb + ub - x_best  # mirror across center\n                    jitter = rng.normal(scale=0.12 * np.maximum(0.01 * avg_span, 0.2 * np.std([t[1] for t in archive], axis=0) if len(archive)>0 else 0.05 * avg_span), size=self.dim)\n                    candidate = np.minimum(np.maximum(mirror + jitter, lb), ub)\n                else:\n                    candidate = rng.uniform(lb, ub)\n                res = eval_and_record(candidate)\n                if res is None:\n                    break\n                fc, xc = res\n                if fc < f_best:\n                    no_improve = 0\n                else:\n                    no_improve += 1\n\n            # gentle adaptation of exploration base prob depending on progress\n            if no_improve > 10:\n                explore_prob = min(0.9, explore_prob + 0.03)\n            else:\n                explore_prob = max(0.02, explore_prob * 0.995)\n\n            # safety: if stuck a long time, force a random injection\n            if no_improve > 30 and evals < self.budget:\n                res = eval_and_record(rng.uniform(lb, ub))\n                if res is None:\n                    break\n                fc, xc = res\n                if fc < f_best:\n                    no_improve = 0\n                else:\n                    no_improve += 1\n\n            if evals >= self.budget:\n                break\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best) if f_best is not None else np.inf\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DLASS scored 0.341 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "22fdb245-00ef-4d24-9240-afb45392d5d6", "operator": null, "metadata": {"aucs": [0.12346315173277844, 0.1580276049595185, 0.46081158416302936, 0.8630552306223, 0.22797162964434203, 0.5278979168009716, 0.24505722655699846, 0.39010175917697, 0.27045281716272584, 0.14769858895922172]}, "task_prompt": ""}
{"id": "e657ab86-ee8f-47e8-bcb7-3e07c3750a80", "fitness": 0.41235314633964765, "name": "ALeCD", "description": "ALeCD combines a small adaptive elite archive (log‑scaled size, initial uniform sampling) with a robust MAD-based diversity estimator to drive anisotropic steps and per-dimension step sizes. Global exploration uses heavy‑tailed Student‑t (levy_df≈1.5) directional jumps plus occasional long axis‑aligned jumps and recombination from the archive (centroid + weighted differences) to generate wide, directional moves. Local exploitation is a coordinate‑wise adaptive search that expands a coordinate step on success and shrinks it on failure, with pattern/extension moves and budget‑aware local allocations. The scheduler is budget‑aware and adaptive: a baseline global move probability (≈0.22) smoothly increases with stagnation (no_improve_since), triggers jittered restarts and occasional broad sampling, and always clips to bounds to respect the search domain.", "code": "import numpy as np\n\nclass ALeCD:\n    \"\"\"\n    Adaptive Lévy-guided Coordinate Descent (ALeCD)\n\n    Main idea:\n      - Use a small elite archive (adaptive size) to estimate per-dimension diversity via MAD.\n      - Global exploration: directionally-scaled heavy-tailed jumps (Student-t with small df,\n        approximating Lévy-like steps) combined with occasional axis-aligned long jumps.\n      - Local exploitation: coordinate-wise adaptive step search (increase on success,\n        shrink on failure) with pattern/extension moves.\n      - Budget-aware initial sampling, archive maintenance and strict eval counting.\n      - Adaptive global/local scheduling based on no_improve_since with a smooth rise in\n        global probability when progress stalls.\n\n    Parameters (constructor):\n      - budget: total allowed function evaluations\n      - dim: problem dimensionality\n      - init_samples: optional number of initial uniform samples (default adaptive)\n      - archive_size: optional archive size (default adaptive)\n      - global_base_prob: baseline probability for global moves (adaptive)\n      - local_frac: suggested fraction of budget to use for single local attempt\n      - levy_df: degrees of freedom for Student-t used for heavy tails (smaller => heavier tails)\n      - shrink_factor: multiplier applied to steps on failure (0<shrink<1)\n      - expand_factor: multiplier applied to a coordinate step on success (>1)\n      - recomb_beta: weight used in recombination from archive\n      - rng_seed: RNG seed for reproducibility\n    \"\"\"\n    def __init__(self, budget=10000, dim=10,\n                 init_samples=None, archive_size=None,\n                 global_base_prob=0.22, local_frac=0.06,\n                 levy_df=1.5, shrink_factor=0.55, expand_factor=1.6,\n                 recomb_beta=0.7, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.global_base_prob = float(global_base_prob)\n        self.local_frac = float(local_frac)\n        self.levy_df = float(levy_df)\n        self.shrink_factor = float(shrink_factor)\n        self.expand_factor = float(expand_factor)\n        self.recomb_beta = float(recomb_beta)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds handling (support scalar or array)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive defaults\n        if self.init_samples is None:\n            # more aggressive initial coverage for moderate dims but budget-aware\n            init_samples = int(min(max(12, 6 * self.dim), max(12, self.budget // 10), 300))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, self.budget)\n\n        if self.archive_size is None:\n            # archive grows slowly with log(dim) to keep overhead low\n            archive_k = int(max(3, min(16, int(np.ceil(2.0 * np.log1p(self.dim)) + 1))))\n        else:\n            archive_k = int(self.archive_size)\n\n        # bookkeeping\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x) sorted by f ascending\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # clip to bounds\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # maintain archive (sorted)\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        # initial uniform sampling\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one archive member\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # helper: MAD-based diversity scale (robust)\n        def diversity_scale():\n            if len(archive) >= 2:\n                pts = np.vstack([t[1] for t in archive])\n                med = np.median(pts, axis=0)\n                mad = np.median(np.abs(pts - med), axis=0)\n                # convert MAD to approx std: multiply by 1.4826\n                approx_std = mad * 1.4826\n                baseline = 0.04 * span  # baseline fraction of span\n                # ensure not too small\n                return np.maximum(approx_std, baseline)\n            else:\n                return 0.06 * span  # fallback\n\n        # global heavy-tailed jump (directional + occasional axis-aligned)\n        def global_jump(center, scale):\n            # choose whether to do isotropic directional step or axis-aligned\n            if rng.rand() < 0.78:\n                direction = rng.randn(self.dim)\n                nrm = np.linalg.norm(direction) + 1e-12\n                direction /= nrm\n                t = rng.standard_t(self.levy_df)\n                dscale = diversity_scale()\n                anis = dscale / (np.mean(dscale) + 1e-12)\n                # combine scale with avg_span and small random multiplier\n                step = direction * (float(scale) * avg_span * (0.18 + 0.9 * rng.rand()))\n                step = step * anis\n                return center + t * step\n            else:\n                # long axis-aligned jump (pick few axes)\n                axes = rng.choice(self.dim, size=max(1, int(0.08 * self.dim)), replace=False)\n                child = center.copy()\n                dscale = diversity_scale()\n                for a in axes:\n                    t = rng.standard_t(self.levy_df)\n                    child[a] += t * (float(scale) * (0.25 * avg_span) * (dscale[a] / (np.mean(dscale) + 1e-12)))\n                return child\n\n        # recombination from archive: centroid + weighted diffs + small noise\n        def recombine():\n            if len(archive) >= 3:\n                pts = np.vstack([t[1] for t in archive])\n                centroid = np.mean(pts, axis=0)\n                i, j = rng.choice(len(archive), size=2, replace=False)\n                diff = archive[i][1] - archive[j][1]\n                child = centroid + self.recomb_beta * diff\n                # small gaussian jitter scaled by MAD\n                child += 0.03 * diversity_scale() * rng.randn(self.dim)\n                return np.minimum(np.maximum(child, lb), ub)\n            elif len(archive) >= 1:\n                # mix best with a random elite\n                if len(archive) >= 2:\n                    j = rng.randint(1, len(archive))\n                    child = (1 - self.recomb_beta) * archive[0][1] + self.recomb_beta * archive[j][1]\n                    child += 0.02 * diversity_scale() * rng.randn(self.dim)\n                    return np.minimum(np.maximum(child, lb), ub)\n                else:\n                    return rng.uniform(lb, ub)\n        \n        # coordinate-wise local search with success-driven step adaptation\n        def coord_local_search(x0, f0, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f0, x0\n            base = x0.copy()\n            base_f = float(f0)\n            # initial steps: use MAD or baseline\n            dscale = diversity_scale()\n            steps = np.minimum(0.6 * dscale, 0.45 * avg_span)\n            # ensure minimal step\n            steps = np.maximum(steps, 1e-8)\n            local_used = 0\n            # iterate until budget used or steps become tiny\n            while local_used < local_budget and np.any(steps > 1e-10) and evals < self.budget:\n                improved_any = False\n                # randomize coordinate order\n                order = rng.permutation(self.dim)\n                for idx in order:\n                    if local_used >= local_budget or evals >= self.budget:\n                        break\n                    # try positive direction\n                    xp = base.copy()\n                    xp[idx] += steps[idx]\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res = eval_and_record(xp)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < base_f:\n                        base = xp.copy()\n                        base_f = fp\n                        improved_any = True\n                        # expand successful step\n                        steps[idx] = min(steps[idx] * self.expand_factor, 0.9 * span[idx])\n                        continue\n                    # try negative direction\n                    xn = base.copy()\n                    xn[idx] -= steps[idx]\n                    xn = np.minimum(np.maximum(xn, lb), ub)\n                    res = eval_and_record(xn)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < base_f:\n                        base = xn.copy()\n                        base_f = fn\n                        improved_any = True\n                        steps[idx] = min(steps[idx] * self.expand_factor, 0.9 * span[idx])\n                        continue\n                    # if neither side improved, shrink this coordinate\n                    steps[idx] *= self.shrink_factor\n                # pattern extension: if a cycle of coordinates improved, try an extrapolation\n                if improved_any and local_used < local_budget and evals < self.budget:\n                    # attempt a modest extension along the net change direction from starting x0\n                    direction = base - x0\n                    if np.linalg.norm(direction) > 1e-12:\n                        ext = base + 1.2 * direction\n                        ext = np.minimum(np.maximum(ext, lb), ub)\n                        res = eval_and_record(ext)\n                        local_used += 1\n                        if res is None:\n                            break\n                        fe, xe = res\n                        if fe < base_f:\n                            base = xe.copy()\n                            base_f = fe\n                # stop earlier if best improved to global tol\n                if f_best <= -1e300:  # unreachable placeholder, kept for symmetry; effectively does nothing\n                    break\n            return base_f, base\n\n        # main loop\n        attempt = 0\n        no_improve_since = 0\n        # parameters for adaptive global probability (smooth rise when stalled)\n        max_global_prob = 0.92\n        rise_tau = 8.0\n\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            # compute local allocation (scaled with remaining)\n            max_local_budget = max(4, int(self.local_frac * self.budget))\n            alloc_local = min(max_local_budget, max(2, int(0.04 * remaining)))\n            alloc_local = min(alloc_local, remaining - 1) if remaining > 1 else 0\n\n            # adaptive global probability: slowly increases as no_improve_since grows (sigmoid-like)\n            frac = 1.0 - np.exp(- (no_improve_since / rise_tau))\n            p_global = float(np.clip(self.global_base_prob + (max_global_prob - self.global_base_prob) * frac, 0.02, max_global_prob))\n\n            if rng.rand() < p_global and len(archive) > 0:\n                # pick center: mostly best, sometimes random archive member\n                if rng.rand() < 0.8:\n                    center = archive[0][1]\n                else:\n                    center = archive[rng.randint(0, len(archive))][1]\n                # scale decays with attempts gently, but stays above a floor\n                scale = max(0.05, 1.0 / (1.0 + 0.01 * attempt))\n                cand = global_jump(center, scale)\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n\n                # update no_improve_since based on global best\n                if f_cand < f_best:\n                    no_improve_since = 0\n                else:\n                    no_improve_since += 1\n\n                # if candidate is reasonably good, attempt local refinement\n                threshold = archive[0][0] if len(archive) > 0 else np.inf\n                if alloc_local > 0 and f_cand <= threshold * (1.10 + 0.03 * rng.rand()):\n                    local_alloc = min(remaining - 1, max(1, int(alloc_local * (1 + 0.8 * rng.rand()))))\n                    f_after, x_after = coord_local_search(cand, f_cand, local_alloc)\n                    if f_after < f_best:\n                        no_improve_since = 0\n                    else:\n                        no_improve_since += 1\n                else:\n                    # occasionally try recombination if global jump wasn't promising\n                    if rng.rand() < 0.18 and evals < self.budget and len(archive) >= 1:\n                        child = recombine()\n                        res = eval_and_record(child)\n                        if res is None:\n                            break\n                        fc, child = res\n                        if fc < f_best:\n                            no_improve_since = 0\n                        else:\n                            no_improve_since += 1\n            else:\n                # local refinement or jittered restart around best\n                r = rng.rand()\n                if r < 0.62 and len(archive) > 0:\n                    start_f, start_x = archive[0]\n                elif r < 0.92 and len(archive) > 1:\n                    idx = rng.randint(0, len(archive))\n                    start_f, start_x = archive[idx]\n                else:\n                    # jittered restart around best using MAD anisotropy\n                    if x_best is not None:\n                        dscale = diversity_scale()\n                        jitter = rng.normal(scale=0.18 * dscale)\n                        start_x = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                    else:\n                        start_x = rng.uniform(lb, ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n\n                # local budget adapted to leftover\n                local_budget = min(alloc_local, max(2, int(0.07 * remaining)))\n                f_after, x_after = coord_local_search(start_x, start_f, local_budget)\n                if f_after < f_best:\n                    no_improve_since = 0\n                else:\n                    no_improve_since += 1\n\n            # occasional uniform injection to maintain coverage\n            if (attempt % 17) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # if stagnation prolonged, do a larger restart (broad sampling)\n            if no_improve_since > 35 and evals < self.budget:\n                # sample several points but stay within budget\n                tries = min(3, self.budget - evals)\n                for _ in range(tries):\n                    xr = rng.uniform(lb - 0.25 * span, ub + 0.25 * span)\n                    xr = np.minimum(np.maximum(xr, lb), ub)\n                    eval_and_record(xr)\n                # gently reset no_improve_since to encourage local searches\n                no_improve_since = int(no_improve_since * 0.5)\n\n            # slowly decay/increase base prob depending on progress\n            if no_improve_since > 12:\n                self.global_base_prob = min(max_global_prob, self.global_base_prob + 0.02)\n            else:\n                self.global_base_prob = max(0.02, self.global_base_prob * 0.997)\n\n            if evals >= self.budget:\n                break\n\n        # final fallback\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ALeCD scored 0.412 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "22fdb245-00ef-4d24-9240-afb45392d5d6", "operator": null, "metadata": {"aucs": [0.08613705529013382, 0.16574845938168858, 0.7964254976056858, 0.9937837020679599, 0.18100920824464017, 0.9910192779455861, 0.22389389077419608, 0.37051170568725156, 0.19921666401359195, 0.11578600238574266]}, "task_prompt": ""}
{"id": "0e2f8a89-01aa-4662-9f4b-111adee17c53", "fitness": "-inf", "name": "", "description": "ACED keeps a small sorted elite archive (size ~ ceil(1.8*sqrt(dim)) clipped 3–12) and computes per-dimension spread and a PCA principal direction to drive anisotropic moves and per-dim step sizes. Global exploration uses heavy-tailed Student-t jumps (student_df=3) biased toward the principal component and scaled by an anisotropy vector (mixing empirical std with a 0.03*span baseline) to produce long, directed jumps. Local refinement is a randomized Hooke–Jeeves style search with per-dim steps (bounded by 0.45*dscale and 0.35*avg_span), pattern-extension (pattern_factor=1.8) and geometric shrink (0.62), augmented by differential-style recombination and short directed line searches between archive points. The algorithm is budget-aware (initial uniform sampling proportional to dim/budget), adaptively selects among strategies using simple success/attempt counts with exploration floor, and injects occasional uniform samples to avoid premature convergence.", "code": "import numpy as np\n\nclass ACED (object):\n    \"\"\"\n    ACED: Archive-Covariance Enhanced Diversified search\n\n    - Budget-aware continuous optimizer designed for -5..5 box (works with func.bounds.lb/ub).\n    - Keeps a small elite archive, computes per-dim diversity and principal direction (PCA),\n      and mixes strategies: anisotropic heavy-tailed global jumps, randomized Hooke-Jeeves local searches,\n      differential recombination, and short directed line searches.\n    - Strategy selection is adjusted by recent success counts (simple adaptive weighting).\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 init_samples=None, archive_size=None,\n                 student_df=3.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.student_df = float(student_df)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive defaults\n        if self.init_samples is None:\n            init_samples = min(max(12, 6 * self.dim), max(10, self.budget // 20))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, self.budget)\n\n        if self.archive_size is None:\n            archive_k = int(max(3, min(12, int(np.ceil(np.sqrt(self.dim) * 1.8)))))\n        else:\n            archive_k = int(self.archive_size)\n\n        # bookkeeping\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x)\n\n        # evaluation wrapper: clips to bounds and enforces budget\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # maintain sorted archive\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        # initial uniform sampling\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one archive point\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # local search params\n        shrink = 0.62\n        pattern_factor = 1.8\n        tol = 1e-10\n        max_local_frac = max(3, int(0.04 * self.budget))\n\n        # strategy bookkeeping for adaptive selection\n        strategies = ['global', 'local', 'recomb', 'line']\n        attempts = {s: 1.0 for s in strategies}  # pseudo-counts to avoid zero division\n        successes = {s: 1.0 for s in strategies}\n\n        def diversity_scale():\n            # per-dim diversity based on archive spread, fallback to fraction of span\n            if len(archive) >= 2:\n                pts = np.vstack([t[1] for t in archive])\n                std = np.std(pts, axis=0)\n                # mix std with baseline lower bound\n                return np.maximum(std, 0.03 * span)\n            else:\n                return 0.2 * span\n\n        def principal_direction():\n            # compute first principal component of archive points (unit vector); fallback to random\n            if len(archive) >= 2:\n                pts = np.vstack([t[1] for t in archive])\n                mean = np.mean(pts, axis=0)\n                A = pts - mean\n                try:\n                    u, s, vt = np.linalg.svd(A, full_matrices=False)\n                    v = vt[0]\n                    nrm = np.linalg.norm(v)\n                    if nrm > 0:\n                        return v / nrm\n                except Exception:\n                    pass\n            # fallback: random unit\n            v = rng.randn(self.dim)\n            v /= (np.linalg.norm(v) + 1e-12)\n            return v\n\n        # global heavy-tailed anisotropic jump (Student-t)\n        def global_jump_from(center, scale):\n            direction = rng.randn(self.dim)\n            direction /= (np.linalg.norm(direction) + 1e-12)\n            t_draw = rng.standard_t(self.student_df)\n            dscale = diversity_scale()\n            anis = dscale / (np.mean(dscale) + 1e-12)\n            pdir = principal_direction()\n            # bias direction toward principal direction but keep randomness\n            direction = 0.65 * pdir + 0.35 * direction\n            direction /= (np.linalg.norm(direction) + 1e-12)\n            step = direction * (float(scale) * avg_span * (0.18 + 0.82 * rng.rand()))\n            step = step * anis\n            cand = center + t_draw * step\n            return np.minimum(np.maximum(cand, lb), ub)\n\n        # differential recombination\n        def recombine_from_archive():\n            if len(archive) >= 2:\n                i, j = rng.choice(len(archive), size=2, replace=False)\n                x1 = archive[i][1]\n                x2 = archive[j][1]\n                diff = x1 - x2\n                gamma = 0.7 + 0.2 * rng.rand()\n                noise = 0.04 * avg_span * rng.standard_t(self.student_df, size=self.dim)\n                child = x1 + gamma * diff + noise\n                return np.minimum(np.maximum(child, lb), ub)\n            else:\n                return rng.uniform(lb, ub)\n\n        # directed short line search between two archive points\n        def directed_line_search(x1, x2, base_f=None, budget_allowed=6):\n            # try a few points along the secant direction (both directions)\n            if np.allclose(x1, x2):\n                return base_f, x1\n            direction = x1 - x2\n            norm = np.linalg.norm(direction) + 1e-12\n            direction = direction / norm\n            # candidate alphas scaled to avg_span\n            alphas = np.array([0.15, 0.4, -0.2, 0.8]) * (min(avg_span, norm) + 1e-12)\n            best_f = base_f\n            best_x = x1.copy()\n            uses = 0\n            for a in alphas:\n                if uses >= budget_allowed or evals >= self.budget:\n                    break\n                x_try = np.minimum(np.maximum(x1 + a * direction, lb), ub)\n                res = eval_and_record(x_try)\n                uses += 1\n                if res is None:\n                    break\n                f_try, x_try = res\n                if f_try < best_f:\n                    best_f = f_try\n                    best_x = x_try.copy()\n            return best_f, best_x\n\n        # Hooke-Jeeves style randomized local search seeded by per-dim steps\n        def local_search(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            dscale = diversity_scale()\n            steps = np.minimum(0.45 * dscale, 0.35 * avg_span)\n            local_evals = 0\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_evals < local_budget and iters < iter_limit and np.any(steps > tol):\n                iters += 1\n                improved = False\n                probe = base.copy()\n                probe_f = base_f\n                order = rng.permutation(self.dim)\n                for idx in order:\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    # try positive\n                    xp = probe.copy()\n                    xp[idx] += steps[idx]\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res = eval_and_record(xp)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < probe_f:\n                        probe = xp.copy()\n                        probe_f = fp\n                        improved = True\n                        continue\n                    # try negative\n                    xn = probe.copy()\n                    xn[idx] -= steps[idx]\n                    xn = np.minimum(np.maximum(xn, lb), ub)\n                    res = eval_and_record(xn)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < probe_f:\n                        probe = xn.copy()\n                        probe_f = fn\n                        improved = True\n                # pattern extension or shrink\n                if improved and local_evals < local_budget and evals < self.budget:\n                    direction = probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_and_record(xp)\n                        local_evals += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = probe.copy()\n                                base_f = probe_f\n                        else:\n                            base = probe.copy()\n                            base_f = probe_f\n                    else:\n                        base = probe.copy()\n                        base_f = probe_f\n                else:\n                    steps *= shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # main loop\n        attempt = 0\n        no_improve = 0\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            # compute soft success-based probabilities\n            rates = np.array([successes[s] / attempts[s] for s in strategies])\n            # small baseline and softmax-like normalization\n            weights = (rates + 0.05) / (np.sum(rates + 0.05))\n            # ensure minimal exploration probability\n            probs = 0.85 * weights + 0.15 * (1.0 / len(strategies))\n            probs = probs / np.sum(probs)\n\n            # pick strategy\n            strat = rng.choice(strategies, p=probs)\n            attempts[strat] += 1.0\n\n            # allocate local budget conservatively\n            alloc_local = min(max_local_frac, max(2, int(0.03 * remaining)))\n            alloc_local = min(alloc_local, remaining - 1) if remaining > 1 else 0\n\n            improved_this_attempt = False\n\n            if strat == 'global':\n                # global jump from best or random elite\n                if len(archive) > 0:\n                    center = archive[0][1] if rng.rand() < 0.7 else archive[rng.randint(0, len(archive))][1]\n                else:\n                    center = rng.uniform(lb, ub)\n                scale = max(0.06, 1.0 / (1.0 + 0.01 * attempt))\n                cand = global_jump_from(center, scale)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n                if f_cand < f_best:\n                    improved_this_attempt = True\n                    no_improve = 0\n                else:\n                    no_improve += 1\n                # do a focused local search if promising\n                threshold = archive[0][0] if len(archive) > 0 else np.inf\n                if alloc_local > 0 and f_cand <= threshold * (1.12 + 0.03 * rng.rand()):\n                    local_alloc = min(remaining - 1, int(alloc_local * (1 + rng.rand())))\n                    local_alloc = max(1, local_alloc)\n                    f_after, x_after = local_search(cand, f_cand, local_alloc)\n                    if f_after < f_best:\n                        improved_this_attempt = True\n                        no_improve = 0\n\n            elif strat == 'local':\n                # pick start: best, random archive, or jittered restart\n                choose = rng.rand()\n                if choose < 0.6 and len(archive) > 0:\n                    start_f, start_x = archive[0]\n                elif choose < 0.9 and len(archive) > 1:\n                    idx = rng.randint(0, len(archive))\n                    start_f, start_x = archive[idx]\n                else:\n                    if x_best is not None:\n                        dscale = diversity_scale()\n                        jitter = rng.normal(scale=0.12 * dscale)\n                        start_x = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                    else:\n                        start_x = rng.uniform(lb, ub)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                local_budget = min(alloc_local, max(2, int(0.06 * remaining)))\n                f_after, x_after = local_search(start_x, start_f, local_budget)\n                if f_after < f_best:\n                    improved_this_attempt = True\n                    no_improve = 0\n                else:\n                    no_improve += 1\n\n            elif strat == 'recomb':\n                child = recombine_from_archive()\n                res = eval_and_record(child)\n                if res is None:\n                    break\n                f_c, child = res\n                if f_c < f_best:\n                    improved_this_attempt = True\n                    no_improve = 0\n                else:\n                    no_improve += 1\n                # sometimes follow recombination with a tiny local polish\n                if alloc_local > 0 and f_c <= (archive[0][0] if len(archive)>0 else np.inf) * 1.15:\n                    small_loc = max(1, int(0.4 * alloc_local))\n                    f_after, x_after = local_search(child, f_c, small_loc)\n                    if f_after < f_best:\n                        improved_this_attempt = True\n                        no_improve = 0\n\n            elif strat == 'line':\n                # choose two distinct archive points if possible\n                if len(archive) >= 2:\n                    x1 = archive[0][1]\n                    x2 = archive[min(1, len(archive)-1)][1]\n                    base_f = archive[0][0]\n                    f_after, x_after = directed_line_search(x1, x2, base_f=base_f, budget_allowed=min(6, remaining-1))\n                    if f_after < f_best:\n                        improved_this_attempt = True\n                        no_improve = 0\n                    else:\n                        no_improve += 1\n                else:\n                    # fallback to a global jump\n                    if len(archive) > 0:\n                        center = archive[0][1]\n                    else:\n                        center = rng.uniform(lb, ub)\n                    cand = global_jump_from(center, 0.9)\n                    res = eval_and_record(cand)\n                    if res is None:\n                        break\n                    f_cand, cand = res\n                    if f_cand < f_best:\n                        improved_this_attempt = True\n                        no_improve = 0\n                    else:\n                        no_improve += 1\n\n            # occasional uniform injection\n            if (attempt % 19) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # update simple success counters\n            if improved_this_attempt:\n                successes[strat] += 1.0\n            # small decay: encourage exploration if no improvement\n            if no_improve > 12:\n                # increase base willingness to take global actions by slightly favoring 'global' and 'recomb'\n                successes['global'] += 0.5\n                successes['recomb'] += 0.4\n                no_improve = 0  # reset to avoid runaway\n\n            if evals >= self.budget:\n                break\n\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 152, in evaluate, the following error occurred:\nKeyError: ''\nOn line: gamma = 0.7 + 0.2 * rng.rand()", "error": "In the code, line 152, in evaluate, the following error occurred:\nKeyError: ''\nOn line: gamma = 0.7 + 0.2 * rng.rand()", "parent_ids": "22fdb245-00ef-4d24-9240-afb45392d5d6", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "3cd34f89-5d7c-4441-abe7-0adeff606afa", "fitness": 0.1874651835414813, "name": "ADEP", "description": "The algorithm couples an archive-driven anisotropic sampling kernel with budget-aware 1D PCA-like line searches: a small elite archive (≈0.5·init samples, with init ≈4·dim) seeds anisotropic Gaussian proposals or directional line refinements depending on a moderate global_prob (0.36) and rare isotropic bursts (burst_prob 0.04). It maintains a lightweight diagonal covariance (diag_var) with exponential memory (cov_memory=0.75) and rank‑one updates from normalized accepted steps, plus an evolution path p_c (path_decay=0.92) that biases proposals and PCA directions. Directional search uses aggressive expansion (×1.8) on improvement and conservative shrink (×0.7) on failure, while sigma is adapted by a smoothed success rate p_succ (succ_alpha=0.15, target 0.25, adapt_rate=0.35) to control exploration/exploitation. The design is budget-aware (line_budget_frac≈0.045), includes occasional uniform injections and conservative restarts when stagnation (≈6% of budget) is detected to re-center, shrink scales, and increase exploration.", "code": "import numpy as np\n\nclass ADEP:\n    \"\"\"\n    Archive-directed Evolution with Evolution Path (ADEP)\n\n    One-line idea:\n      Archive-driven anisotropic sampling and 1D PCA line-searches, augmented with a lightweight\n      diagonal covariance and an evolution-path (p_c) momentum term plus smoothed success-rate\n      sigma adaptation and conservative restarts for robust budget-aware optimization.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n\n        # Tunables inspired by AEDS + ADRS\n        self.init_samples_factor = 4      # initial uniform samples ~ 4*dim (clipped)\n        self.archive_factor = 0.5         # archive size relative to init samples\n        self.global_prob = 0.36           # chance to attempt anisotropic global proposal\n        self.burst_prob = 0.04            # occasional isotropic bursts\n        self.line_budget_frac = 0.045     # fraction of budget for a directional line search\n        self.step_decay = 0.97            # decay of global/local step sizes over attempts\n\n        # covariance / evolution path params\n        self.cov_memory = 0.75\n        self.path_decay = 0.92\n        self.cov_learning = 0.15         # rank-one contribution weight when accepting steps\n\n        # sigma adaptation (smoothed success rate)\n        self.p_succ = 0.2\n        self.succ_alpha = 0.15\n        self.succ_target = 0.25\n        self.sigma_adapt_rate = 0.35\n\n        # stagnation / restart\n        self.stagnation_threshold_frac = 0.06  # fraction of budget without improvement to trigger conservative restart\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds (support scalar bounds too)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        eps = 1e-12\n\n        # init sizes\n        init_samples = min(max(8, self.init_samples_factor * self.dim), self.budget // 4 if self.budget >= 20 else self.budget)\n        archive_k = max(4, min(12, int(init_samples * self.archive_factor)))\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x) sorted by f\n\n        def update_archive(fv, xv):\n            nonlocal archive\n            if len(archive) < archive_k or fv < archive[-1][0]:\n                archive.append((float(fv), xv.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = float(func(x))\n            evals += 1\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            update_archive(f, x)\n            return f, x\n\n        # initial uniform sampling\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one point\n        if len(archive) == 0 and evals < self.budget:\n            eval_and_record(rng.uniform(lb, ub))\n\n        # initial diagonal covariance: use archive variance fallback to (span/6)^2\n        if len(archive) >= 2:\n            pts = np.stack([a[1] for a in archive], axis=0)\n            diag_var = np.var(pts, axis=0) + 1e-8\n            diag_var = np.maximum(diag_var, (span / 6.0) ** 2)\n        else:\n            diag_var = (span / 6.0) ** 2\n\n        # evolution path\n        p_c = np.zeros(self.dim, dtype=float)\n\n        # sigma initial\n        sigma = max(1e-12, 0.25 * avg_span)\n\n        # stepsizes for global/local proposals\n        global_step = 0.5 * avg_span\n        local_step = 0.35 * avg_span\n\n        # bookkeeping for stagnation detection\n        best_since = 0\n        stagnation_threshold = max(5, int(self.stagnation_threshold_frac * max(1, self.budget)))\n\n        # helper: principal direction from archive (PCA-ish power iteration)\n        def archive_principal_direction():\n            if len(archive) <= 1:\n                v = rng.randn(self.dim)\n                v /= (np.linalg.norm(v) + 1e-12)\n                return v\n            pts = np.stack([a[1] for a in archive], axis=0)\n            center = pts.mean(axis=0)\n            M = pts - center\n            cov = (M.T @ M) / max(1, M.shape[0]) + 1e-8 * np.eye(self.dim)\n            b = rng.randn(self.dim)\n            for _ in range(6):\n                b = cov @ b\n                nrm = np.linalg.norm(b)\n                if nrm < 1e-12:\n                    b = rng.randn(self.dim)\n                else:\n                    b /= nrm\n            return b\n\n        # directional 1D budget-aware line search with expansion on improvement\n        def directional_line_search(x0, f0, direction, budget_for_line, start_step):\n            nonlocal evals, f_best, x_best, diag_var, p_c, sigma\n            if budget_for_line <= 0 or evals >= self.budget:\n                return f0, x0, False\n            d = np.asarray(direction, dtype=float)\n            nrm = np.linalg.norm(d)\n            if nrm < 1e-12:\n                d = rng.randn(self.dim)\n                d /= np.linalg.norm(d)\n            else:\n                d = d / nrm\n\n            s = float(start_step)\n            best_x = x0.copy()\n            best_f = float(f0)\n            improved_any = False\n\n            remaining = min(budget_for_line, self.budget - evals)\n            # try a few iterations of expand/shrink\n            while remaining > 0 and s > 1e-12:\n                # probe +s\n                xp = np.minimum(np.maximum(x0 + s * d, lb), ub)\n                res = eval_and_record(xp)\n                if res is None:\n                    break\n                fp, xp = res\n                remaining = min(budget_for_line, self.budget - evals)\n                if fp < best_f:\n                    # accept improvement, update momentum and diag_var\n                    improved_any = True\n                    delta = (xp - x0) / (sigma + 1e-12)\n                    # rank-one like diag update: squared normalized step\n                    step_var = np.maximum((delta ** 2), 1e-16)\n                    diag_var = self.cov_memory * diag_var + (1.0 - self.cov_memory) * (step_var * (sigma ** 2))\n                    # update evolution path\n                    p_c = self.path_decay * p_c + (1.0 - self.path_decay) * delta\n                    best_f = fp\n                    best_x = xp.copy()\n                    x0 = best_x.copy()\n                    s *= 1.8  # aggressive expansion on improvement\n                    # adapt sigma modestly as success\n                    self.p_succ = (1.0 - self.succ_alpha) * self.p_succ + self.succ_alpha * 1.0\n                    dim_scale = 1.0 + 0.5 * np.sqrt(max(1, self.dim))\n                    sigma *= np.exp(self.sigma_adapt_rate * (self.p_succ - self.succ_target) / dim_scale)\n                else:\n                    # probe -s\n                    if remaining <= 0:\n                        break\n                    xn = np.minimum(np.maximum(x0 - s * d, lb), ub)\n                    res = eval_and_record(xn)\n                    if res is None:\n                        break\n                    fn, xn = res\n                    remaining = min(budget_for_line, self.budget - evals)\n                    if fn < best_f:\n                        improved_any = True\n                        delta = (xn - x0) / (sigma + 1e-12)\n                        step_var = np.maximum((delta ** 2), 1e-16)\n                        diag_var = self.cov_memory * diag_var + (1.0 - self.cov_memory) * (step_var * (sigma ** 2))\n                        p_c = self.path_decay * p_c + (1.0 - self.path_decay) * delta\n                        best_f = fn\n                        best_x = xn.copy()\n                        x0 = best_x.copy()\n                        s *= 1.8\n                        self.p_succ = (1.0 - self.succ_alpha) * self.p_succ + self.succ_alpha * 1.0\n                        dim_scale = 1.0 + 0.5 * np.sqrt(max(1, self.dim))\n                        sigma *= np.exp(self.sigma_adapt_rate * (self.p_succ - self.succ_target) / dim_scale)\n                    else:\n                        # shrink step when no improvement\n                        s *= 0.7\n                        # report failure to p_succ\n                        self.p_succ = (1.0 - self.succ_alpha) * self.p_succ + self.succ_alpha * 0.0\n                        dim_scale = 1.0 + 0.5 * np.sqrt(max(1, self.dim))\n                        sigma *= np.exp(self.sigma_adapt_rate * (self.p_succ - self.succ_target) / dim_scale)\n                remaining = min(budget_for_line, self.budget - evals)\n            return best_f, best_x, improved_any\n\n        attempt = 0\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            if remaining <= 0:\n                break\n\n            # small occasional isotropic burst\n            if rng.rand() < self.burst_prob:\n                center = x_best if x_best is not None else rng.uniform(lb, ub)\n                burst_scale = 0.6 * avg_span * max(0.15, 1.0 - attempt * 0.008)\n                cand = np.minimum(np.maximum(center + burst_scale * rng.randn(self.dim), lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                fc, xc = res\n                # small directional polish if promising\n                if fc <= (archive[0][0] if len(archive) > 0 else np.inf) * 1.05 and evals < self.budget:\n                    alloc_line = min(remaining - 1, max(2, int(self.line_budget_frac * self.budget)))\n                    directional_line_search(xc, fc, rng.randn(self.dim), alloc_line, local_step * 0.5)\n                global_step *= self.step_decay\n                local_step *= self.step_decay\n                continue\n\n            # choose between anisotropic global sampling and directional local refinement\n            do_global = (rng.rand() < self.global_prob)\n            if do_global:\n                # anisotropic Gaussian around best or random elite\n                if len(archive) > 0 and rng.rand() < 0.7:\n                    center = archive[0][1].copy()\n                else:\n                    center = rng.uniform(lb, ub)\n                # per-dim scales from diag_var\n                per_std = np.sqrt(np.maximum(diag_var, 1e-16))\n                anis = per_std * (0.8 + 0.4 * rng.rand(self.dim))\n                # incorporate evolution path as a bias term\n                bias = (0.4 * (p_c / (np.linalg.norm(p_c) + 1e-12))) if np.linalg.norm(p_c) > 0 else np.zeros(self.dim)\n                z = rng.randn(self.dim)\n                cand = center + sigma * (anis * z + 0.7 * bias)\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                fc, xc = res\n                improved = False\n                # update diag_var and p_c if improvement relative to center\n                if fc < (archive[0][0] if len(archive) > 0 else np.inf):\n                    # normalized step\n                    delta = (xc - center) / (sigma + 1e-12)\n                    step_var = np.maximum((delta ** 2), 1e-16)\n                    diag_var = self.cov_memory * diag_var + (1.0 - self.cov_memory) * (step_var * (sigma ** 2))\n                    p_c = self.path_decay * p_c + (1.0 - self.path_decay) * delta\n                    improved = True\n                    best_since = 0\n                else:\n                    best_since += 1\n\n                # adaptive sigma update\n                self.p_succ = (1.0 - self.succ_alpha) * self.p_succ + self.succ_alpha * float(improved)\n                dim_scale = 1.0 + 0.5 * np.sqrt(max(1, self.dim))\n                sigma *= np.exp(self.sigma_adapt_rate * (self.p_succ - self.succ_target) / dim_scale)\n                sigma = float(np.clip(sigma, 1e-12, 2.0 * np.max(span)))\n\n                # if candidate promising, do PCA-line search\n                if fc <= (archive[0][0] if len(archive) > 0 else np.inf) * 1.12 and remaining > 2:\n                    direction = archive_principal_direction()\n                    # bias direction towards candidate - best\n                    if x_best is not None:\n                        bias_dir = xc - x_best\n                        if np.linalg.norm(bias_dir) > 1e-12:\n                            direction = 0.6 * (bias_dir / np.linalg.norm(bias_dir)) + 0.4 * direction\n                            direction /= max(1e-12, np.linalg.norm(direction))\n                    alloc_line = min(max(2, int(self.line_budget_frac * self.budget)), remaining - 1)\n                    f_after, x_after, improved_line = directional_line_search(xc, fc, direction, alloc_line, local_step)\n                    if improved_line:\n                        best_since = 0\n\n            else:\n                # local directional refinement: start from best or an elite\n                if len(archive) > 0 and rng.rand() < 0.75:\n                    start_f, start_x = archive[0]\n                elif len(archive) > 1:\n                    idx = rng.randint(0, len(archive))\n                    start_f, start_x = archive[idx]\n                else:\n                    res = eval_and_record(rng.uniform(lb, ub))\n                    if res is None:\n                        break\n                    start_f, start_x = res\n\n                direction = archive_principal_direction()\n                if rng.rand() < 0.35:\n                    direction += 0.25 * rng.randn(self.dim)\n                line_budget = min(max(2, int(self.line_budget_frac * self.budget)), remaining - 1)\n                f_after, x_after, improved_line = directional_line_search(start_x, start_f, direction, line_budget, local_step)\n                if improved_line:\n                    best_since = 0\n                else:\n                    best_since += 1\n\n            # occasional uniform injection\n            if (attempt % 17) == 0 and evals < self.budget:\n                eval_and_record(rng.uniform(lb, ub))\n\n            # decay steps slowly\n            global_step *= self.step_decay\n            local_step *= self.step_decay\n\n            # conservative restart if stagnating\n            if best_since >= stagnation_threshold and evals < self.budget:\n                best_since = 0\n                # shrink sigma and reset diagonal covariance to local scale\n                sigma *= 0.3 + 0.4 * rng.rand()\n                if x_best is None and len(archive) > 0:\n                    x_best = archive[0][1].copy()\n                # re-center a sample near best\n                if x_best is not None:\n                    jitter = 0.06 * span * (0.5 + rng.rand(self.dim))\n                    m = np.minimum(np.maximum(x_best + rng.randn(self.dim) * jitter, lb), ub)\n                    res = eval_and_record(m)\n                    if res is None:\n                        break\n                # reset diag_var to smaller isotropic values\n                diag_var = np.maximum((span / 8.0) ** 2, 1e-12)\n                # reset evolution path\n                p_c = 0.3 * p_c\n                # slightly increase global exploration\n                self.global_prob = min(0.8, self.global_prob + 0.08)\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ADEP scored 0.187 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "22fdb245-00ef-4d24-9240-afb45392d5d6", "operator": null, "metadata": {"aucs": [0.08791218402510959, 0.13662810691896887, 0.29094845175505946, 0.19364204346267289, 0.17686913471726073, 0.318656326469713, 0.1783471365715824, 0.18981700368263177, 0.16926224367791898, 0.1325692041338955]}, "task_prompt": ""}
{"id": "f14f39a0-7602-46e7-b12b-e830c653784f", "fitness": 0.2574644400709353, "name": "DirectionalAdaptiveBanditSearch", "description": "Directional Adaptive Bandit Search (DABS) is a population-based continuous optimizer that starts with a Latin-like stratified initialization and a heuristic population size, using per-individual, per-dimension anisotropic step sizes (init_step_frac=0.25, bounded by step_min_frac/step_max_frac) and per-dimension importance weights to control searches. It perturbs solutions via bandit-style coordinate sampling (P derived from W) with anisotropic Gaussian noise, partner-directed moves (tournament-chosen partner), and a gentle pull toward an elite centroid, plus occasional opposition/extrapolation for diversification. Adaptation is driven by a sliding success window (win_len, default 10) that updates W/P and shrinks or grows per-dimension steps (step_decrease/step_increase thresholds tuned at >0.25 and <0.09 success rates), with small stochastic jitter to avoid locking. A persistent archive supports periodic weighted least-squares local linear modeling (local_period, local_k) to propose gradient-like steps, and stagnation-driven mild restarts (Cauchy-like jumps) inject diversity — all while strictly respecting the user-specified budget.", "code": "import numpy as np\n\nclass DirectionalAdaptiveBanditSearch:\n    \"\"\"\n    Directional Adaptive Bandit Search (DABS)\n    - Population of solutions with per-dimension step-sizes and per-dimension importance weights.\n    - For each candidate, choose coordinates to perturb using importance-weighted sampling (bandit-style).\n    - Propose anisotropic Gaussian perturbations, partner-directed moves and a gentle pull toward an elite centroid.\n    - Maintain a small sliding success window per individual/dimension to adapt step-sizes and importance.\n    - Periodically build a local linear model (weighted least squares) around the global best to propose a gradient-like step.\n    - Budget-aware: never calls func more times than self.budget.\n    -------------------------------------------------------------------------\n    Constructor signature: __init__(self, budget, dim, **optional)\n      - budget, dim required; optional args: pop, seed, init_step_frac, step_min_frac, step_max_frac,\n        win_len, step_decrease, step_increase, partner_beta, elite_alpha, local_period, local_k,\n        restart_stagn, restart_frac.\n    \"\"\"\n    def __init__(self, budget, dim,\n                 pop=None,\n                 seed=None,\n                 init_step_frac=0.25,\n                 step_min_frac=1e-6,\n                 step_max_frac=2.0,\n                 win_len=10,\n                 step_decrease=0.90,\n                 step_increase=1.10,\n                 partner_beta=0.2,\n                 elite_alpha=0.15,\n                 local_period=12,\n                 local_k=None,\n                 restart_stagn=80,\n                 restart_frac=0.5):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop = pop\n        self.seed = seed\n        self.init_step_frac = float(init_step_frac)\n        self.step_min_frac = float(step_min_frac)\n        self.step_max_frac = float(step_max_frac)\n        self.win_len = int(max(3, win_len))\n        self.step_decrease = float(step_decrease)\n        self.step_increase = float(step_increase)\n        self.partner_beta = float(partner_beta)\n        self.elite_alpha = float(elite_alpha)\n        self.local_period = int(local_period)\n        self.local_k = local_k if local_k is not None else max(2, self.dim + 1)\n        self.restart_stagn = int(restart_stagn)\n        self.restart_frac = float(restart_frac)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds: many-BBOB typically gives [-5,5], but read from func.bounds for generality\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        range_vec = ub - lb\n        range_mean = float(np.mean(range_vec))\n        eps = 1e-12\n\n        # population size heuristics\n        if self.pop is None:\n            pop = max(16, int(4 * np.sqrt(max(1, self.dim))))\n        else:\n            pop = int(self.pop)\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # Latin-like initialization (per-dim stratification)\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / float(pop)\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter a bit\n        jitter_scale = 0.15 * range_mean / max(1.0, np.sqrt(self.dim))\n        X += (rng.rand(pop, self.dim) - 0.5) * jitter_scale\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial pop\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            fx = float(func(X[i]))\n            f[i] = fx\n            evals += 1\n\n        # if budget exhausted in init, return best-so-far\n        if evals >= self.budget:\n            idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[idx])\n            self.x_opt = X[idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-dim step sizes (anisotropic) initialized to fraction of range\n        step = np.full((pop, self.dim), max(eps, self.init_step_frac * range_mean), dtype=float)\n        step_min = max(eps, self.step_min_frac * range_mean)\n        step_max = max(eps, self.step_max_frac * range_mean)\n\n        # per-dim importance weights for sampling coords (bandit-like), start uniform + small noise\n        W = np.clip(0.1 + 0.9 * rng.rand(pop, self.dim), 1e-3, 0.99)\n        # normalize to probabilities across dims per individual\n        P = W / (np.sum(W, axis=1, keepdims=True) + 1e-12)\n\n        # sliding success history: shape (pop, dim, win_len)\n        win = max(1, self.win_len)\n        success_hist = np.zeros((pop, self.dim, win), dtype=np.int8)\n        hist_pos = 0\n\n        # archive for local modeling (store evaluated points and values)\n        archive_X = [X[i].copy() for i in range(pop)]\n        archive_f = [float(f[i]) for i in range(pop)]\n\n        # elite centroid (weighted by fitness)\n        def elite_centroid(k= max(1, pop//4)):\n            k = max(1, min(pop, k))\n            idxs = np.argsort(f)[:k]\n            return np.mean(X[idxs], axis=0)\n\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n        gens_since_improve = 0\n        gen = 0\n\n        def reflect_and_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        # local linear model builder (weighted least squares) -> gradient estimate\n        def local_linear_gradient(xc, k_neigh):\n            # choose k nearest in archive (Euclidean)\n            if len(archive_X) < 2:\n                return None\n            Xarr = np.asarray(archive_X)\n            farr = np.asarray(archive_f)\n            dists = np.sum((Xarr - xc)**2, axis=1)\n            idx = np.argsort(dists)[:min(len(Xarr), k_neigh)]\n            Xloc = Xarr[idx]\n            floc = farr[idx]\n            # center coordinates\n            Xm = Xloc - xc\n            # weights decaying with distance\n            dloc = np.sqrt(np.maximum(1e-12, np.sum(Xm**2, axis=1)))\n            wloc = 1.0 / (1.0 + dloc)\n            Wmat = np.diag(wloc)\n            # design: add bias column\n            A = np.hstack([np.ones((Xm.shape[0],1)), Xm])\n            try:\n                # solve weighted least squares for [a, g] where f ~ a + g^T (x - xc)\n                AtW = A.T.dot(Wmat)\n                theta = np.linalg.lstsq(AtW.dot(A), AtW.dot(floc), rcond=None)[0]\n                grad = theta[1:]\n                return grad\n            except Exception:\n                return None\n\n        # main loop: generation-level iterations where we attempt one trial per individual\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # compute elite centroid\n            cen = elite_centroid(max(1, pop//4))\n\n            # shuffle individuals\n            order = rng.permutation(pop)\n            gen_success = np.zeros((pop, self.dim), dtype=np.int8)  # record which dims succeeded this gen for each individual\n\n            for ii in order:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fi = f[ii]\n\n                # sample how many dims to perturb (stochastic), controlled by per-dim probabilities P[ii]\n                # generate mask by comparing random uniforms to scaled probabilities\n                fraction = 0.12 + 0.25 * rng.rand()  # overall fraction of dims to mutate\n                prob_mask = P[ii] * (fraction * self.dim)\n                prob_mask = np.clip(prob_mask, 0.001, 0.95)\n                mask = rng.rand(self.dim) < prob_mask\n                if not np.any(mask):\n                    mask[rng.randint(self.dim)] = True\n\n                # pick a partner (tournament of 2 among population) to provide direction\n                a, b = rng.randint(pop), rng.randint(pop)\n                partner = X[a] if f[a] < f[b] else X[b]\n\n                # anisotropic Gaussian noise only on masked dims\n                noise = rng.randn(self.dim) * step[ii]\n                noise = noise * mask.astype(float)\n\n                # partner-directed move (along vector to partner)\n                dir_move = self.partner_beta * (partner - xi)\n\n                # slight pull toward elite centroid\n                elite_pull = self.elite_alpha * (cen - xi)\n\n                # combine to produce trial\n                trial = xi + noise + dir_move + elite_pull\n\n                # diversify occasionally via opposition (mirror) or coordinate perturbation\n                cand_list = [trial]\n                if rng.rand() < 0.12:\n                    opp = lb + ub - trial\n                    opp += rng.randn(self.dim) * (0.02 * range_mean)\n                    cand_list.append(opp)\n                if rng.rand() < 0.08:\n                    # directional extrapolation along partner direction\n                    extra = xi + 1.5 * self.partner_beta * (partner - xi) + rng.randn(self.dim) * (0.5 * step[ii])\n                    cand_list.append(extra)\n\n                # clamp/reflect and evaluate candidates opportunistically\n                best_local_x = None\n                best_local_f = np.inf\n                for xcand in cand_list:\n                    if evals >= self.budget:\n                        break\n                    xcand = reflect_and_clamp(xcand)\n                    fv = float(func(xcand))\n                    evals += 1\n                    # add to archive\n                    archive_X.append(xcand.copy())\n                    archive_f.append(fv)\n                    if fv < best_local_f:\n                        best_local_f = fv\n                        best_local_x = xcand.copy()\n\n                # selection and updates\n                if best_local_f <= fi:\n                    # improvement, accept replacement\n                    X[ii] = best_local_x\n                    f[ii] = best_local_f\n                    improved_dims = mask.astype(np.int8)\n                    gen_success[ii, :] = improved_dims  # mark dims that were mutated (we assume success linked to these)\n                    # update best\n                    if best_local_f < f_best:\n                        f_best = best_local_f\n                        x_best = best_local_x.copy()\n                        gens_since_improve = 0\n                        improved_in_gen = True\n                else:\n                    # no fitness improvement: mark no success dims (all zeros)\n                    gen_success[ii, :] = 0\n\n                # adjust importance weights P[ii] quickly in response to success on masked dims:\n                # increase weight for dims that participated in improvements (we only know if replaced)\n                # small exploration noise added\n                if np.any(gen_success[ii]):\n                    # reinforce dims that were active\n                    W[ii, :] = W[ii, :] * 0.98 + 0.12 * gen_success[ii]\n                else:\n                    # slightly decay weights to encourage exploration of other dims\n                    W[ii, :] = W[ii, :] * 0.995 + 0.0005\n                # normalize to probabilities\n                P[ii, :] = W[ii, :] / (np.sum(W[ii, :]) + 1e-12)\n                # small jitter to step sizes occasionally to avoid lock\n                if rng.rand() < 0.02:\n                    step[ii] = np.clip(step[ii] * (1.0 + rng.randn(self.dim) * 0.03), step_min, step_max)\n\n            # update success history circularly and adapt step sizes per-dim per-individual\n            success_hist[:, :, hist_pos] = gen_success\n            hist_pos = (hist_pos + 1) % win\n            # compute per-dim success rates\n            rate = np.sum(success_hist, axis=2) / float(win)\n            # adjust step sizes: if a dim's recent success rate > 0.25 -> shrink that dim step; if <0.09 -> increase\n            for i in range(pop):\n                for d in range(self.dim):\n                    if rate[i, d] > 0.25:\n                        step[i, d] = max(step_min, step[i, d] * self.step_decrease)\n                    elif rate[i, d] < 0.09:\n                        step[i, d] = min(step_max, step[i, d] * self.step_increase)\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # Periodic local linear-model descent around the best\n            if gen % self.local_period == 0 and evals < self.budget:\n                grad = local_linear_gradient(x_best, self.local_k)\n                if grad is not None and np.linalg.norm(grad) > 1e-14:\n                    # propose step in negative gradient, scaled by adaptive global step\n                    # choose scale as median of individual's mean step sizes\n                    global_scale = np.median(np.mean(step, axis=1))\n                    # scale factor is adaptive: reduce for high dim\n                    scale = 0.7 * global_scale / (1.0 + 0.5 * np.log(1 + self.dim))\n                    direction = -grad\n                    # normalize direction and apply per-dim anisotropic scale (use median step)\n                    dir_norm = np.linalg.norm(direction)\n                    if dir_norm > 0:\n                        direction = direction / dir_norm\n                        x_grad = x_best + direction * scale * (1.0 + 0.6 * rng.rand())\n                        x_grad = reflect_and_clamp(x_grad)\n                        if evals < self.budget:\n                            fv = float(func(x_grad))\n                            evals += 1\n                            archive_X.append(x_grad.copy())\n                            archive_f.append(fv)\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = x_grad.copy()\n                                gens_since_improve = 0\n                                # inject into population replacing worst\n                                worst = int(np.argmax(f))\n                                X[worst] = x_grad.copy()\n                                f[worst] = fv\n\n            # stagnation-driven mild restart around best\n            if gens_since_improve >= self.restart_stagn and evals < self.budget:\n                gens_since_improve = 0\n                nreinit = max(1, int(self.restart_frac * pop))\n                avg_step = np.median(np.mean(step, axis=1))\n                for k in range(nreinit):\n                    if evals >= self.budget:\n                        break\n                    # levy-like heavy-tailed jump around best (Cauchy-like)\n                    jump = rng.standard_cauchy(self.dim) * (0.3 * avg_step + 0.02 * range_mean)\n                    newx = reflect_and_clamp(x_best + jump)\n                    fv = float(func(newx))\n                    evals += 1\n                    archive_X.append(newx.copy())\n                    archive_f.append(fv)\n                    worst = int(np.argmax(f))\n                    X[worst] = newx.copy()\n                    f[worst] = fv\n                    step[worst] = np.clip(avg_step * (0.5 + 0.5 * rng.rand(self.dim)), step_min, step_max)\n                    W[worst] = 0.1 + 0.9 * rng.rand(self.dim)\n                    P[worst] = W[worst] / (np.sum(W[worst]) + 1e-12)\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = newx.copy()\n\n            # sync best from population as safe check\n            cur_best_idx = int(np.argmin(f))\n            if f[cur_best_idx] < f_best:\n                f_best = float(f[cur_best_idx])\n                x_best = X[cur_best_idx].copy()\n                gens_since_improve = 0\n\n        # done\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DirectionalAdaptiveBanditSearch scored 0.257 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "140086d9-7241-4560-a19e-2703a518521f", "operator": null, "metadata": {"aucs": [0.1368659316632007, 0.17190302217748632, 0.32238028922090456, 0.34430129688991673, 0.275083178918216, 0.379857374811286, 0.24660774119435502, 0.2880491904103577, 0.23827829200352102, 0.17131808342010912]}, "task_prompt": ""}
{"id": "01596f49-a56a-4ba6-98b7-bff0b29badfd", "fitness": "-inf", "name": "DMELK", "description": "This is a compact population-based heuristic that mixes anisotropic per-dimension step-sizes with a learned directional memory per individual and a mild ensemble-mean attraction, augmented by occasional heavy-tailed Lévy/Cauchy kicks and coordinate-wise mixing to balance local refinement and long jumps. Initialization uses stratified (Latin-like) sampling plus jitter for early coverage, and per-individual anisotropic sigmas (init_sigma_frac=0.15, clamped to sigma_min/sigma_max) are adapted with a windowed success history (adapt_decrease/increase) while mem_alpha/mem_decay control momentum-like updates. Exploration is diversified with opposition sampling, randomized mix_prob jitter, and rare Levy/opposition events (levy_prob≈0.12, opposition_prob≈0.12), while budget-aware opportunistic evaluation, periodic randomized subspace local searches (local_budget_frac≈0.03, local_period), and mild restarts around the current best on stagnation provide targeted exploitation and recovery. The algorithm enforces strict budget accounting, uses a modest population size, and tunes pulls/perturbations conservatively (mean_pull=0.4, moderate local_shrink/restarts) to favor robust global search across Many Affine BBOB tasks.", "code": "import numpy as np\n\nclass DMELK:\n    \"\"\"\n    Directional-Memory Ensemble with Anisotropic Lévy Kicks (DMELK).\n\n    Main ideas:\n    - Population of solutions with per-dimension sigma (anisotropic).\n    - Each individual keeps a directional memory vector that biases future proposals (momentum-like).\n    - Proposals combine memory pull, ensemble mean pull, anisotropic Gaussian noise, and\n      rare Lévy/Cauchy-style kicks for long-range exploration.\n    - Windowed success-history adapts per-individual sigma magnitudes.\n    - Occasional opposition sampling and opportunistic evaluation ordering.\n    - Periodic randomized subspace local search (limited evaluations) that shrinks step sizes.\n    - Mild restarts of worst individuals around current best on stagnation.\n    - Strict budget accounting: func is never called more than self.budget times.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10,\n                 pop=None,\n                 init_sigma_frac=0.15,   # anisotropic initial sigma fraction of range per-dim\n                 sigma_min_frac=1e-6,\n                 sigma_max_frac=2.0,\n                 mean_pull=0.4,         # weaker pull to mean than original\n                 mem_alpha=0.65,        # memory retention on improvement\n                 mem_decay=0.88,        # memory decay on no improvement\n                 levy_prob=0.12,        # chance of heavy-tailed long jump\n                 opposition_prob=0.12,\n                 adapt_window=10,\n                 adapt_decrease=0.90,\n                 adapt_increase=1.10,\n                 mix_base=0.25,\n                 mix_jitter=0.18,\n                 restart_patience=60,\n                 local_period=12,\n                 local_budget_frac=0.03, # fraction of remaining budget to spend on local search\n                 local_init_frac=0.08,\n                 local_shrink=0.5,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n\n        # population and sampling params\n        self.pop = pop\n        self.init_sigma_frac = float(init_sigma_frac)\n        self.sigma_min_frac = float(sigma_min_frac)\n        self.sigma_max_frac = float(sigma_max_frac)\n        self.mean_pull = float(mean_pull)\n\n        # memory and exploration\n        self.mem_alpha = float(mem_alpha)\n        self.mem_decay = float(mem_decay)\n        self.levy_prob = float(levy_prob)\n        self.opposition_prob = float(opposition_prob)\n\n        # adaptation\n        self.adapt_window = int(max(1, adapt_window))\n        self.adapt_decrease = float(adapt_decrease)\n        self.adapt_increase = float(adapt_increase)\n\n        # mixing and misc\n        self.mix_base = float(mix_base)\n        self.mix_jitter = float(mix_jitter)\n\n        # restarts and local search\n        self.restart_patience = int(restart_patience)\n        self.local_period = int(local_period)\n        self.local_budget_frac = float(local_budget_frac)\n        self.local_init_frac = float(local_init_frac)\n        self.local_shrink = float(local_shrink)\n\n        # RNG\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds and range\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        center = 0.5 * (lb + ub)\n        range_vec = ub - lb\n        range_mean = float(np.mean(range_vec))\n        eps = 1e-12\n\n        # choose population size (different scaling, relatively compact ensemble)\n        if self.pop is None:\n            pop = max(8, int(4 * np.log(max(2, self.dim)) + 6))\n        else:\n            pop = int(self.pop)\n        pop = min(pop, max(2, self.budget))  # cannot exceed budget\n\n        evals = 0\n\n        # Latin-like stratified initialization per-dimension for diversity\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # small jitter\n        jitter_scale = 0.12 * range_mean / max(1.0, self.dim)\n        X += (rng.rand(pop, self.dim) - 0.5) * jitter_scale\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population (sequential, budget-aware)\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            fv = float(func(X[i]))\n            f[i] = fv\n            evals += 1\n\n        # if budget exhausted during init, return best\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-dimension sigmas (anisotropic): shape (pop, dim)\n        sigma = np.maximum(eps, self.init_sigma_frac * range_vec[None, :])\n        sigma_min = max(eps, self.sigma_min_frac * range_mean)\n        sigma_max = max(eps, self.sigma_max_frac * range_mean)\n\n        # per-individual mixing probability (like crossover), with variety\n        mix_prob = np.clip(self.mix_base + (rng.randn(pop) * self.mix_jitter), 0.03, 0.95)\n\n        # directional memory per individual (vector)\n        mem = np.zeros((pop, self.dim), dtype=float)\n\n        # success history for windowed adaptation\n        win = max(1, self.adapt_window)\n        success_hist = np.zeros((pop, win), dtype=np.int8)\n        hist_pos = 0\n\n        # tracking best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        def reflect_and_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        # helper to sample a bounded Cauchy/Levy-like step (clamped)\n        def levy_kick(scale):\n            # sample per-dim Cauchy but clamp to moderate multiples\n            raw = rng.standard_cauchy(self.dim)\n            # avoid huge outliers: clamp at 10\n            raw = np.clip(raw, -10.0, 10.0)\n            return raw * scale\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            pop_mean = np.mean(X, axis=0)\n\n            # order\n            order = rng.permutation(pop)\n            gen_success = np.zeros(pop, dtype=np.int8)\n\n            for ii in order:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fi = f[ii]\n\n                # sometimes nudge sigma randomly to escape plateaus\n                if rng.rand() < 0.04:\n                    # small multiplicative jitter per-dim\n                    factor = 1.0 + (rng.randn(self.dim) * 0.08)\n                    sigma[ii] = np.minimum(np.maximum(sigma[ii] * factor, sigma_min), sigma_max)\n\n                # construct proposal:\n                # - memory pull (direction learned from previous successful moves)\n                # - ensemble mean pull (weaker)\n                # - anisotropic gaussian noise\n                # - occasional levy kick\n                mem_pull = mem[ii] * 0.9\n                mean_pull = self.mean_pull * (pop_mean - xi)\n                gauss = rng.randn(self.dim) * sigma[ii]\n                trial = xi + mem_pull + mean_pull + gauss\n\n                if rng.rand() < self.levy_prob:\n                    # add heavy-tailed jump scaled by a fraction of range\n                    trial += levy_kick(0.35 * range_mean)\n\n                # mixing: randomly keep some parent coords\n                mask = rng.rand(self.dim) < mix_prob[ii]\n                if not np.any(mask):\n                    mask[rng.randint(self.dim)] = True\n                trial = np.where(mask, trial, xi)\n\n                trial = reflect_and_clamp(trial)\n\n                # opposition sampling about center\n                candidate_points = [trial]\n                if rng.rand() < self.opposition_prob:\n                    opp = center + (center - trial)\n                    # small jitter\n                    opp += (rng.randn(self.dim) * 0.015 * range_mean)\n                    opp = reflect_and_clamp(opp)\n                    candidate_points.append(opp)\n\n                # opportunistic evaluation: evaluate candidates in order, pick best\n                best_local_f = np.inf\n                best_local_x = None\n                for xcand in candidate_points:\n                    if evals >= self.budget:\n                        break\n                    fv = float(func(xcand))\n                    evals += 1\n                    if fv < best_local_f:\n                        best_local_f = fv\n                        best_local_x = xcand.copy()\n\n                # selection and memory update\n                if best_local_f <= fi:\n                    # successful: replace, update memory toward the improvement vector\n                    delta = best_local_x - xi\n                    mem[ii] = self.mem_alpha * mem[ii] + (1.0 - self.mem_alpha) * delta\n                    X[ii] = best_local_x\n                    f[ii] = best_local_f\n                    gen_success[ii] = 1\n                    if best_local_f < f_best:\n                        f_best = best_local_f\n                        x_best = best_local_x.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # failed: damp memory slightly\n                    mem[ii] *= self.mem_decay\n                    gen_success[ii] = 0\n\n            # update success history\n            success_hist[:, hist_pos] = gen_success\n            hist_pos = (hist_pos + 1) % win\n\n            # adapt per-dimension sigma magnitudes based on recent success rate\n            success_rate = np.sum(success_hist, axis=1) / float(win)\n            for i in range(pop):\n                if success_rate[i] > 0.30:\n                    sigma[i] = np.maximum(sigma_min, sigma[i] * self.adapt_decrease)\n                elif success_rate[i] < 0.12:\n                    sigma[i] = np.minimum(sigma_max, sigma[i] * self.adapt_increase)\n                # occasionally perturb mix probability\n                if rng.rand() < 0.03:\n                    mix_prob[i] = np.clip(mix_prob[i] + (rng.randn() * 0.04), 0.01, 0.99)\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # periodic localized subspace search around best (budget-aware)\n            if (gen % self.local_period == 0) and (evals < self.budget):\n                remaining = self.budget - evals\n                local_budget = max(2, int(min(remaining * self.local_budget_frac, remaining)))\n                # randomized subspace: pick k dims (at least 1)\n                k = max(1, min(self.dim, max(1, int(0.25 * self.dim))))\n                dims = rng.choice(self.dim, size=k, replace=False)\n                step = max(eps, self.local_init_frac * range_mean)\n                local_x = x_best.copy()\n                local_f = f_best\n                used = 0\n                while step > eps and used < local_budget and evals < self.budget:\n                    moved = False\n                    # random order of dims\n                    dims_order = dims.copy()\n                    rng.shuffle(dims_order)\n                    for d in dims_order:\n                        if used >= local_budget or evals >= self.budget:\n                            break\n                        # try plus\n                        xt = local_x.copy()\n                        xt[d] = min(ub[d], xt[d] + step)\n                        # skip if no change\n                        if np.allclose(xt, local_x):\n                            xt[d] = max(lb[d], local_x[d] - step)\n                        fv = float(func(xt))\n                        evals += 1\n                        used += 1\n                        if fv < local_f:\n                            local_x = xt.copy()\n                            local_f = fv\n                            moved = True\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = local_x.copy()\n                                gens_since_improve = 0\n                            # opportunistic second step\n                            if used < local_budget and evals < self.budget:\n                                xt2 = local_x.copy()\n                                xt2[d] = np.minimum(np.maximum(xt2[d] + step, lb[d]), ub[d])\n                                fv2 = float(func(xt2))\n                                evals += 1\n                                used += 1\n                                if fv2 < local_f:\n                                    local_x = xt2.copy()\n                                    local_f = fv2\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = xt2.copy()\n                                        gens_since_improve = 0\n                        else:\n                            # try minus direction if we didn't already\n                            if used < local_budget and evals < self.budget:\n                                xtm = local_x.copy()\n                                xtm[d] = max(lb[d], local_x[d] - step)\n                                fv2 = float(func(xtm))\n                                evals += 1\n                                used += 1\n                                if fv2 < local_f:\n                                    local_x = xtm.copy()\n                                    local_f = fv2\n                                    moved = True\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = xtm.copy()\n                                        gens_since_improve = 0\n                    if not moved:\n                        step *= self.local_shrink\n\n                # inject local best back into population (replace worst)\n                if local_f < np.max(f):\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = local_x.copy()\n                    f[worst_idx] = local_f\n                    # set its sigma to a conservative fraction\n                    sigma[worst_idx] = np.maximum(sigma_min, np.minimum(sigma_max, 0.4 * np.mean(sigma)))\n\n            # if stagnating for long, mild restart: resample worst half around best\n            if gens_since_improve >= self.restart_patience and evals < self.budget:\n                half = pop // 2\n                for k in range(half):\n                    if evals >= self.budget:\n                        break\n                    worst_idx = int(np.argmax(f))\n                    # gaussian jitter around best with moderate scale\n                    jitter = rng.randn(self.dim) * (0.28 * range_mean)\n                    newx = reflect_and_clamp(x_best + jitter)\n                    fv = float(func(newx))\n                    evals += 1\n                    X[worst_idx] = newx\n                    f[worst_idx] = fv\n                    sigma[worst_idx] = np.maximum(sigma_min, np.minimum(sigma_max, 0.6 * np.mean(sigma)))\n                    mem[worst_idx] = 0.0\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = newx.copy()\n                        gens_since_improve = 0\n\n            # keep best synced to population\n            current_best_idx = int(np.argmin(f))\n            if f[current_best_idx] < f_best:\n                f_best = float(f[current_best_idx])\n                x_best = X[current_best_idx].copy()\n                gens_since_improve = 0\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 200, in __call__, the following error occurred:\nIndexError: index 2 is out of bounds for axis 0 with size 1\nOn line: gauss = rng.randn(self.dim) * sigma[ii]", "error": "In the code, line 200, in __call__, the following error occurred:\nIndexError: index 2 is out of bounds for axis 0 with size 1\nOn line: gauss = rng.randn(self.dim) * sigma[ii]", "parent_ids": "140086d9-7241-4560-a19e-2703a518521f", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "7aff347d-18ed-44a0-bf6c-3cf639da8891", "fitness": 0.2639927885709962, "name": "DirectionalAdaptiveOrthogonalSampler", "description": "The design is an archive-driven continuous sampler that starts with a stratified (Latin-hypercube–like) initialization with small jitter and keeps a compact sorted archive (archive_size ≈ max(6, 2√dim)) and a modest number of directional basis vectors (dir_count ≈ 1.5√dim) to focus search. Candidate generation mixes orthonormal directional bases (rows learned/maintained via QR and occasional PCA), per-direction adaptive radii (initialized as radii_init_frac=0.25 of the domain mean and clamped by radii_min/max fractions) and small isotropic noise, with occasional opposition sampling (prob≈0.12) and Lévy-like long jumps (prob≈0.06); candidates are evaluated opportunistically and credited back to the seed direction for online learning. Adaptation uses a windowed success history (window_len=12) with multiplicative increase/decrease factors to tune radii, a step-memory used for PCA updates (pca_update_period=8) to relearn promising directions, periodic local refinement (local_refine_period=15) around the best, and mild restarts on prolonged stagnation (stagnation_restart=80), all while strictly remaining budget-aware.", "code": "import numpy as np\n\nclass DirectionalAdaptiveOrthogonalSampler:\n    \"\"\"\n    DirectionalAdaptiveOrthogonalSampler(budget, dim, ...)\n    - Archive-driven search: keeps a small archive of best points and generates candidates\n      by combining learned directions (from successful steps and PCA) and orthogonal noise.\n    - Per-direction adaptive radii updated from windowed success history (increase/decrease).\n    - Generates small batches of orthogonal proposals each iteration, evaluates opportunistically.\n    - Occasional opposition sampling, Levy-like large jumps, and mild restarts on stagnation.\n    - Budget-aware: never calls func more than self.budget.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 archive_size=None,\n                 dir_count=None,\n                 init_samples=None,\n                 radii_init_frac=0.25,\n                 radii_min_frac=1e-5,\n                 radii_max_frac=2.0,\n                 window_len=12,\n                 decrease_factor=0.88,\n                 increase_factor=1.10,\n                 opposition_prob=0.12,\n                 levy_prob=0.06,\n                 proposals_per_iter=4,\n                 pca_update_period=8,\n                 stagnation_restart=80,\n                 local_refine_period=15,\n                 local_init_frac=0.08,\n                 local_shrink=0.5,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n\n        self.archive_size = archive_size if archive_size is not None else max(6, int(2 * np.sqrt(max(1, dim))))\n        self.dir_count = dir_count if dir_count is not None else max(6, int(1.5 * np.sqrt(max(1, dim))))\n        self.init_samples = init_samples if init_samples is not None else min(max(10, 2 * dim), self.budget // 10 + 1)\n\n        self.radii_init_frac = float(radii_init_frac)\n        self.radii_min_frac = float(radii_min_frac)\n        self.radii_max_frac = float(radii_max_frac)\n        self.window_len = int(window_len)\n        self.decrease_factor = float(decrease_factor)\n        self.increase_factor = float(increase_factor)\n\n        self.opposition_prob = float(opposition_prob)\n        self.levy_prob = float(levy_prob)\n        self.proposals_per_iter = int(proposals_per_iter)\n\n        self.pca_update_period = int(pca_update_period)\n        self.stagnation_restart = int(stagnation_restart)\n\n        self.local_refine_period = int(local_refine_period)\n        self.local_init_frac = float(local_init_frac)\n        self.local_shrink = float(local_shrink)\n\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # Bounds handling (support scalar or vector)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        range_vec = ub - lb\n        range_mean = float(np.mean(range_vec))\n        eps = 1e-12\n\n        # internal sizes\n        archive_size = min(self.archive_size, max(2, self.budget))\n        dir_count = min(self.dir_count, max(1, self.dim))\n\n        # Helper: reflect once then clamp\n        def reflect_and_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        # Latin-hypercube-like stratified initialization for initial samples\n        init_n = min(self.init_samples, self.budget)\n        X_init = np.empty((init_n, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(init_n)\n            strata = (np.arange(init_n) + rng.rand(init_n)) / init_n\n            X_init[:, d] = lb[d] + strata[perm] * (ub[d] - lb[d])\n        # small jitter\n        jitter_scale = 0.25 * range_mean / max(1.0, self.dim)\n        X_init += (rng.rand(init_n, self.dim) - 0.5) * jitter_scale\n        X_init = np.minimum(np.maximum(X_init, lb), ub)\n\n        evals = 0\n        archive_X = []\n        archive_f = []\n\n        # evaluate initial samples sequentially (budget-aware)\n        for i in range(init_n):\n            if evals >= self.budget:\n                break\n            xi = X_init[i]\n            fv = float(func(xi))\n            evals += 1\n            archive_X.append(xi.copy())\n            archive_f.append(fv)\n\n        # if budget exhausted during init\n        if evals >= self.budget:\n            idx = int(np.argmin(archive_f))\n            self.f_opt = float(archive_f[idx])\n            self.x_opt = archive_X[idx].copy()\n            return self.f_opt, self.x_opt\n\n        # convert archive to arrays and keep sorted by fitness\n        def sync_archive():\n            # keep top archive_size\n            nonlocal archive_X, archive_f\n            idxs = np.argsort(archive_f)\n            idxs = idxs[:min(len(archive_f), archive_size)]\n            archive_X = [archive_X[i] for i in idxs]\n            archive_f = [archive_f[i] for i in idxs]\n\n        sync_archive()\n\n        # directions initialization: random orthonormal set (rows)\n        def orthonormal_random(k):\n            A = rng.randn(k, self.dim)\n            # QR to orthonormalize rows: we want row-space orthonormal, so orthonormalize columns of A^T\n            q, _ = np.linalg.qr(A.T)\n            # q is dim x dim (or dim x k) - take first k columns and transpose to k x dim\n            return q[:, :k].T.copy()\n\n        directions = orthonormal_random(dir_count)\n        # per-direction radii (isotropic along direction vector)\n        radii = np.full(dir_count, max(eps, self.radii_init_frac * range_mean), dtype=float)\n        r_min = max(eps, self.radii_min_frac * range_mean)\n        r_max = max(eps, self.radii_max_frac * range_mean)\n\n        # windowed success history for directions\n        win = max(1, self.window_len)\n        success_hist = np.zeros((dir_count, win), dtype=np.int8)\n        hist_pos = 0\n\n        # step-memory for PCA: store recent successful steps\n        step_memory_capacity = max(10, 6 * self.dim)\n        step_memory = np.zeros((0, self.dim), dtype=float)\n\n        # tracking best\n        best_idx = int(np.argmin(archive_f))\n        x_best = archive_X[best_idx].copy()\n        f_best = float(archive_f[best_idx])\n\n        gen = 0\n        gens_since_improve = 0\n\n        # main loop: propose small batches until budget exhausted\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # build selection probabilities over archive: prefer better (softmax with scaling)\n            fs = np.array(archive_f, dtype=float)\n            # normalize\n            fmin, fmax = fs.min(), fs.max()\n            if fmax > fmin + 1e-12:\n                scores = np.exp(-2.0 * (fs - fmin) / (fmax - fmin))\n            else:\n                scores = np.ones_like(fs)\n            probs = scores / np.sum(scores)\n\n            # propose proposals_per_iter candidates generated from one chosen center\n            center_idx = rng.choice(len(archive_X), p=probs)\n            x_center = archive_X[center_idx].copy()\n\n            # occasionally pick best as center deterministically\n            if rng.rand() < 0.25:\n                x_center = x_best.copy()\n\n            # produce an orthonormal basis starting from a sampled directional seed\n            # sample seed direction index biased by radii\n            if np.sum(radii) > 0:\n                probs_dir = radii / (np.sum(radii) + 1e-30)\n            else:\n                probs_dir = np.ones(dir_count) / dir_count\n            seed_idx = rng.choice(dir_count, p=probs_dir)\n            seed = directions[seed_idx].copy()\n            # add small randomization proportional to radii\n            seed += 0.05 * rng.randn(self.dim) * range_mean\n            # orthonormalize seed with random vectors to create a small basis B (k_basis <= dim)\n            k_basis = min(self.dim, max(1, int(min(4, dir_count))))\n            B = np.empty((k_basis, self.dim), dtype=float)\n            # first row normalized seed\n            nrm = np.linalg.norm(seed)\n            if nrm < 1e-12:\n                seed = rng.randn(self.dim)\n                nrm = np.linalg.norm(seed)\n            B[0] = seed / nrm\n            # Gram-Schmidt to fill remaining rows\n            for r in range(1, k_basis):\n                v = rng.randn(self.dim)\n                # orthogonalize\n                for s in range(r):\n                    v -= np.dot(v, B[s]) * B[s]\n                nv = np.linalg.norm(v)\n                if nv < 1e-12:\n                    v = rng.randn(self.dim)\n                    for s in range(r):\n                        v -= np.dot(v, B[s]) * B[s]\n                    nv = np.linalg.norm(v) + 1e-12\n                B[r] = v / nv\n\n            # generate proposals by linear combination of basis vectors with coefficients drawn relative to radii\n            candidates = []\n            for p in range(self.proposals_per_iter):\n                # mixture coefficients: combine a few basis components\n                coeffs = rng.randn(k_basis)\n                # scale coefficients by selected directional radii summary (mean of selected)\n                coeff_scale = (np.mean(radii) if radii.size > 0 else range_mean * self.radii_init_frac)\n                coeffs *= coeff_scale * (0.6 + 0.8 * rng.rand())  # random scaling factor\n                # Levy-like occasional long jump via heavy-tailed scale\n                if rng.rand() < self.levy_prob:\n                    # Cauchy-like multiplier\n                    levy = np.tan(np.pi * (rng.rand() - 0.5))\n                    coeffs *= (1.0 + 0.5 * np.abs(levy))\n                cand = x_center + np.dot(coeffs, B)\n                # add small isotropic noise\n                cand += (rng.randn(self.dim) * 0.02 * range_mean)\n                cand = reflect_and_clamp(cand)\n                candidates.append((cand, seed_idx))  # keep seed index for success credit\n\n                # opposition sampling occasionally\n                if rng.rand() < self.opposition_prob and len(candidates) < 2 * self.proposals_per_iter:\n                    opp = lb + ub - cand\n                    opp += rng.randn(self.dim) * 0.005 * range_mean\n                    opp = reflect_and_clamp(opp)\n                    candidates.append((opp, seed_idx))\n\n            # Evaluate candidates opportunistically (stop if budget exhausted)\n            cand_results = []\n            for cand, seed_idx_for in candidates:\n                if evals >= self.budget:\n                    break\n                fv = float(func(cand))\n                evals += 1\n                cand_results.append((fv, cand, seed_idx_for))\n                # immediate archive insertion if very good\n                if fv < f_best:\n                    f_best = fv\n                    x_best = cand.copy()\n                    improved_in_gen = True\n                    gens_since_improve = 0\n                # early stop if reaching perfect optimum (optional small threshold)\n                # (We keep going until budget to be fair, but we check for reduced stagnation below)\n\n            # integrate candidate results into archive and step memory\n            for fv, cand, sid in cand_results:\n                archive_X.append(cand.copy())\n                archive_f.append(float(fv))\n                # record step relative to chosen center if that center was in the archive originally\n                step = cand - x_center\n                if np.linalg.norm(step) > 1e-12:\n                    # push to step memory, keep limited capacity\n                    if step_memory.shape[0] < step_memory_capacity:\n                        step_memory = np.vstack([step_memory, step.copy()])\n                    else:\n                        # replace oldest (circular) randomly\n                        ridx = rng.randint(step_memory_capacity)\n                        step_memory[ridx] = step.copy()\n\n                # credit success to the seed direction if candidate improved over chosen center\n                # find matching center fitness (approx)\n                center_f = archive_f[center_idx] if center_idx < len(archive_f) else None\n                if center_f is not None and fv <= archive_f[center_idx]:\n                    success_hist[sid, hist_pos] = 1\n                else:\n                    success_hist[sid, hist_pos] = 0\n\n            # advance circular history pos\n            hist_pos = (hist_pos + 1) % win\n\n            # update archive (keep top ones)\n            sync_archive()\n\n            # adapt per-direction radii using windowed success rates\n            success_rate = np.sum(success_hist, axis=1) / float(win)\n            for i in range(dir_count):\n                if success_rate[i] > 0.30:\n                    radii[i] = max(r_min, radii[i] * self.decrease_factor)\n                elif success_rate[i] < 0.12:\n                    radii[i] = min(r_max, radii[i] * self.increase_factor)\n                # occasional small jitter\n                if rng.rand() < 0.02:\n                    radii[i] = np.clip(radii[i] * (1.0 + 0.05 * rng.randn()), r_min, r_max)\n\n            # occasional direction re-learning via PCA of successful steps\n            if gen % self.pca_update_period == 0 and step_memory.shape[0] >= max(3, self.dim // 2):\n                # compute covariance of step memory (centered)\n                S = step_memory - np.mean(step_memory, axis=0, keepdims=True)\n                cov = (S.T @ S) / max(1, S.shape[0] - 1)\n                # eigen-decompose\n                try:\n                    eigvals, eigvecs = np.linalg.eigh(cov)\n                    # pick top dir_count eigenvectors\n                    order = np.argsort(eigvals)[::-1]\n                    top_k = min(dir_count, eigvecs.shape[1])\n                    new_dirs = eigvecs[:, order[:top_k]].T.copy()\n                    # mix old directions with new ones (momentum)\n                    mix = 0.6\n                    for i in range(min(new_dirs.shape[0], directions.shape[0])):\n                        directions[i] = (mix * directions[i] + (1.0 - mix) * new_dirs[i])\n                    # re-orthonormalize directions\n                    Q, _ = np.linalg.qr(directions.T)\n                    directions = Q[:, :dir_count].T.copy()\n                except Exception:\n                    # fallback: randomize a bit\n                    rand_dirs = orthonormal_random(dir_count)\n                    directions = 0.8 * directions + 0.2 * rand_dirs\n                    Q, _ = np.linalg.qr(directions.T)\n                    directions = Q[:, :dir_count].T.copy()\n\n            # update best and stagnation counter\n            current_best_idx = int(np.argmin(archive_f))\n            if archive_f[current_best_idx] < f_best:\n                f_best = float(archive_f[current_best_idx])\n                x_best = archive_X[current_best_idx].copy()\n                gens_since_improve = 0\n            else:\n                if not improved_in_gen:\n                    gens_since_improve += 1\n                else:\n                    gens_since_improve = 0\n\n            # periodic local refinement around best: randomized coordinate-like directional search\n            if gen % self.local_refine_period == 0 and evals < self.budget:\n                step = max(eps, self.local_init_frac * range_mean)\n                min_step = max(eps, self.radii_min_frac * range_mean)\n                x_work = x_best.copy()\n                f_work = f_best\n                while step > min_step and evals < self.budget:\n                    improved_local = False\n                    # try along principal directions from directions (use top few)\n                    k_try = min(dir_count, max(1, self.dim // 2))\n                    for dvec in directions[:k_try]:\n                        if evals >= self.budget:\n                            break\n                        # try positive\n                        xt = x_work + dvec * step\n                        xt = reflect_and_clamp(xt)\n                        fv = float(func(xt))\n                        evals += 1\n                        if fv < f_work:\n                            x_work = xt.copy()\n                            f_work = fv\n                            improved_local = True\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = xt.copy()\n                        else:\n                            # try negative\n                            xt = x_work - dvec * step\n                            xt = reflect_and_clamp(xt)\n                            if evals >= self.budget:\n                                break\n                            fv = float(func(xt))\n                            evals += 1\n                            if fv < f_work:\n                                x_work = xt.copy()\n                                f_work = fv\n                                improved_local = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = xt.copy()\n                    if not improved_local:\n                        step *= self.local_shrink\n                # inject improved local if found\n                if f_work < min(archive_f):\n                    archive_X.append(x_work.copy())\n                    archive_f.append(float(f_work))\n                    sync_archive()\n\n            # mild restart if stagnation too long: resample half of archive around best with larger jitter\n            if gens_since_improve >= self.stagnation_restart and evals < self.budget:\n                half = max(1, archive_size // 2)\n                for k in range(half):\n                    if evals >= self.budget:\n                        break\n                    jitter_scale = 0.35 * range_mean * (1.0 + 0.5 * rng.rand())\n                    newx = x_best + rng.randn(self.dim) * jitter_scale\n                    newx = reflect_and_clamp(newx)\n                    fv = float(func(newx))\n                    evals += 1\n                    archive_X.append(newx.copy())\n                    archive_f.append(float(fv))\n                    # perturb directions slightly\n                    if rng.rand() < 0.5:\n                        idx_r = rng.randint(dir_count)\n                        directions[idx_r] = directions[idx_r] + 0.1 * rng.randn(self.dim)\n                sync_archive()\n                gens_since_improve = 0\n                # reorthonormalize directions\n                Q, _ = np.linalg.qr(directions.T)\n                directions = Q[:, :dir_count].T.copy()\n\n        # finished search\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DirectionalAdaptiveOrthogonalSampler scored 0.264 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "140086d9-7241-4560-a19e-2703a518521f", "operator": null, "metadata": {"aucs": [0.12681603499419491, 0.15594980683091442, 0.5898706150363542, 0.14464140980522056, 0.15921294841003963, 0.680080739108879, 0.21080994060815883, 0.29534156103185216, 0.1498194457696489, 0.12738538411469913]}, "task_prompt": ""}
{"id": "5dc01e0b-9c96-4c2f-8194-405aa91578ae", "fitness": "-inf", "name": "AdaptiveLevyMeanShift", "description": "The algorithm combines a stratified Latin-like initialization and a moderate population (pop ~ max(12, 4*sqrt(dim))) with per-individual, per-dimension adaptive step-sizes (sigma initialized as 0.15·range_mean and clamped between sigma_min/sigma_max) to preserve diversity while allowing anisotropic search. Search operators mix a robust mean/median “pull” (alpha_mean = 0.4) with small directed differential pushes, per-dimension Gaussian perturbations, mask-based coordinate mixing, occasional frequent full sigma resets (tau_sigma_reset=0.12) and moderate-probability heavy-tailed Lévy jumps (levy_prob=0.12) plus opposition sampling to escape local basins. Step-size adaptation uses a short success-history window (window_len=8) with asymmetric thresholds (shrink if success_rate>0.30 using decrease_factor=0.90, expand if <0.10 using increase_factor=1.12) and occasional random sigma perturbations to balance exploitation/exploration. A budget-aware trust-region-like local refinement (every local_period=15 or after stagnation) performs anisotropic pattern search around the best, reseeds part of the population on heavy stagnation, and always reflects/clamps candidates to the problem bounds.", "code": "import numpy as np\n\nclass AdaptiveLevyMeanShift:\n    \"\"\"\n    AdaptiveLevyMeanShift optimizer\n    \n    Main idea (one-line): Combine a biased mean-pull search with per-dimension adaptive\n    step-sizes, occasional heavy-tailed jumps (Lévy/Cauchy), opposition sampling,\n    and a trust-region-like local refinement around the best solution.\n    \n    Identifies and exposes the main algorithm parameters (different choices from the\n    provided reference algorithm):\n      - pop_base: base population size (default: moderate, scaled with sqrt(dim))\n      - alpha_mean: mean-pull strength (default: 0.4, smaller than 0.7 in ref)\n      - sigma_init_frac: initial per-dimension sigma fractional to range mean (default: 0.15)\n      - per-dim sigma (sigma shape: (pop, dim)) instead of isotropic per-individual\n      - sigma_min_frac / sigma_max_frac: clamping for per-dim sigma (defaults differ)\n      - window_len: success-history window length (default: 8)\n      - decrease_factor / increase_factor: sigma adaptation multipliers (more aggressive increase)\n      - tau_sigma_reset: probability of full sigma re-sample (default: 0.12, more frequent)\n      - levy_prob, levy_scale, levy_beta: occasional heavy-tailed jumps\n      - opposition_prob: probability to test mirrored candidate (default: 0.25)\n      - local_period: frequency of local refinement (default: 15)\n      - local_init_frac, local_shrink, local_min_frac: local search trust-region params\n      - mix_prob: per-individual mix probability (crossover-like), jittered occasionally\n    The implementation is budget-aware and never calls func more than self.budget times.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 alpha_mean=0.4,\n                 sigma_init_frac=0.15,\n                 sigma_min_frac=1e-6,\n                 sigma_max_frac=2.0,\n                 window_len=8,\n                 decrease_factor=0.90,\n                 increase_factor=1.12,\n                 tau_sigma_reset=0.12,\n                 opposition_prob=0.25,\n                 levy_prob=0.12,\n                 levy_scale=0.5,\n                 local_period=15,\n                 local_stagn_gen=60,\n                 local_init_frac=0.08,\n                 local_shrink=0.5,\n                 local_min_frac=1e-6,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.alpha_mean = float(alpha_mean)\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.sigma_min_frac = float(sigma_min_frac)\n        self.sigma_max_frac = float(sigma_max_frac)\n        self.window_len = int(window_len)\n        self.decrease_factor = float(decrease_factor)\n        self.increase_factor = float(increase_factor)\n        self.tau_sigma_reset = float(tau_sigma_reset)\n        self.opposition_prob = float(opposition_prob)\n        self.levy_prob = float(levy_prob)\n        self.levy_scale = float(levy_scale)\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.local_init_frac = float(local_init_frac)\n        self.local_shrink = float(local_shrink)\n        self.local_min_frac = float(local_min_frac)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n        # Bounds handling (BBOB style usually [-5,5], but read from func)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        range_vec = ub - lb\n        range_mean = float(np.mean(range_vec))\n        eps = 1e-12\n\n        # population size (different scaling)\n        if self.pop_base is None:\n            pop = max(12, int(4 * np.sqrt(max(1, self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # Latin-ish stratified initialization for diversity (per-dim permutation)\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + rng.rand(pop)) / float(pop)\n            X[:, d] = lb[d] + strata[perm] * (ub[d] - lb[d])\n        # small isotropic jitter to avoid hyperplane clustering\n        jitter_scale = 0.15 * range_mean / max(1.0, np.sqrt(self.dim))\n        X += (rng.rand(pop, self.dim) - 0.5) * jitter_scale\n        # clamp\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            fx = float(func(X[i]))\n            f[i] = fx\n            evals += 1\n\n        # if budget exhausted during init, return best\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i + 1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-dimension sigma for each individual (shape: pop x dim)\n        base_sigma = max(eps, self.sigma_init_frac * range_mean)\n        sigma = np.full((pop, self.dim), base_sigma, dtype=float)\n        sigma_min = max(eps, self.sigma_min_frac * range_mean)\n        sigma_max = max(eps, self.sigma_max_frac * range_mean)\n\n        # per-individual mixing probabilities (crossover-like)\n        mix_prob = np.clip(0.15 + 0.3 * rng.rand(pop), 0.01, 0.95)\n\n        # success history per-dimension (for adaptation)\n        win = max(1, self.window_len)\n        success_hist = np.zeros((pop, self.dim, win), dtype=np.int8)\n        hist_pos = 0\n\n        # track best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        def reflect_and_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        # Levy step generator (Mantegna-style simplified for beta ~ 1.5)\n        def levy_step(dim, scale=1.0):\n            # Use Mantegna's algorithm approximate for symmetric alpha-stable with alpha ~ 1.5\n            beta = 1.5\n            sigma_u = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                       (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n            u = rng.randn(dim) * sigma_u\n            v = rng.randn(dim)\n            step = u / (np.abs(v) ** (1 / beta))\n            return scale * step\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # compute center / mean and a robust center (median)\n            pop_mean = np.mean(X, axis=0)\n            pop_median = np.median(X, axis=0)\n\n            # adaptive ordering to evaluate exploratory individuals earlier:\n            # compute a heuristic \"urgency\" = high sigma and poor fitness\n            urgency = np.mean(sigma, axis=1) * (f - np.min(f) + 1e-9)\n            order = np.argsort(-urgency)  # descend urgency\n            gen_success = np.zeros((pop, self.dim), dtype=np.int8)\n\n            for ii in order:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n\n                # occasional full sigma reset for this individual (exploration refresh)\n                if rng.rand() < self.tau_sigma_reset:\n                    sigma[ii] = rng.rand(self.dim) * (sigma_max - sigma_min) + sigma_min\n\n                # create candidate by combining: mean-pull + directed differential + gaussian per-dim\n                # choose two distinct partners for a directional push\n                a, b = rng.choice(pop, size=2, replace=False)\n                direction = X[a] - X[b]\n                # scale direction adaptively (small)\n                dir_scale = 0.05 * range_mean\n                directed = dir_scale * direction\n\n                # per-dim Gaussian noise\n                gauss = rng.randn(self.dim) * sigma[ii]\n\n                # mean-pull using median sometimes for robustness\n                if rng.rand() < 0.5:\n                    pull = self.alpha_mean * (pop_median - xi)\n                else:\n                    pull = (self.alpha_mean * 0.7) * (pop_mean - xi)\n\n                candidate = xi + pull + directed + gauss\n\n                # mixing: allow retaining some coords from parent\n                mask = rng.rand(self.dim) < mix_prob[ii]\n                if not np.any(mask):\n                    mask[rng.randint(self.dim)] = True\n                candidate = np.where(mask, candidate, xi)\n\n                # occasional heavy-tailed exploration (Lévy/Cauchy)\n                if rng.rand() < self.levy_prob:\n                    # mix a scaled Levy step in place of gaussian on a random subset\n                    keep = rng.rand(self.dim) < 0.3\n                    if not np.any(keep):\n                        keep[rng.randint(self.dim)] = True\n                    levy = levy_step(self.dim, scale=self.levy_scale * range_mean)\n                    candidate = np.where(keep, xi + levy, candidate)\n\n                # reflect/clamp\n                candidate = reflect_and_clamp(candidate)\n\n                # opposition sampling occasionally: test mirrored candidate about center (median)\n                candidate_points = [candidate]\n                if rng.rand() < self.opposition_prob:\n                    opp = 2.0 * pop_median - candidate\n                    # small jitter to break symmetry\n                    opp += rng.randn(self.dim) * (0.02 * range_mean)\n                    opp = reflect_and_clamp(opp)\n                    candidate_points.append(opp)\n\n                # evaluate candidates opportunistically (stop if budget runs out)\n                best_local_f = np.inf\n                best_local_x = None\n                for xcand in candidate_points:\n                    if evals >= self.budget:\n                        break\n                    fv = float(func(xcand))\n                    evals += 1\n                    if fv < best_local_f:\n                        best_local_f = fv\n                        best_local_x = xcand.copy()\n\n                # selection and success recording (per-dimension)\n                if best_local_f <= f[ii]:\n                    # determine which dimensions improved relative to parent\n                    improved_dims = (best_local_x != X[ii])\n                    X[ii] = best_local_x\n                    f[ii] = best_local_f\n                    # mark success for dims that changed (coarse)\n                    gen_success[ii, improved_dims] = 1\n                    if best_local_f < f_best:\n                        f_best = best_local_f\n                        x_best = best_local_x.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # no replacement: small penalty (no success flags)\n                    pass\n\n                # occasionally jitter mix_prob to diversify crossover tendencies\n                if rng.rand() < 0.03:\n                    mix_prob[ii] = np.clip(mix_prob[ii] + rng.randn() * 0.04, 0.01, 0.98)\n\n            # update circular success history and adapt per-dim sigma\n            success_hist[:, :, hist_pos] = gen_success\n            hist_pos = (hist_pos + 1) % win\n            # compute per-dim success rates\n            success_rate = np.sum(success_hist, axis=2) / float(win)  # shape (pop, dim)\n\n            # adapt sigma per-dim: high success -> shrink, low success -> expand\n            # thresholds shifted compared to ref algorithm\n            for i in range(pop):\n                for d in range(self.dim):\n                    sr = success_rate[i, d]\n                    if sr > 0.30:\n                        sigma[i, d] = max(sigma_min, sigma[i, d] * self.decrease_factor)\n                    elif sr < 0.10:\n                        sigma[i, d] = min(sigma_max, sigma[i, d] * self.increase_factor)\n                # occasional per-dimension random perturbation\n                if rng.rand() < 0.04:\n                    noise = (rng.randn(self.dim) * 0.02 * range_mean)\n                    sigma[i] = np.clip(sigma[i] + np.abs(noise), sigma_min, sigma_max)\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # Trust-region-like local refinement around x_best occasionally or on stagnation\n            if gen % self.local_period == 0 or gens_since_improve >= self.local_stagn_gen:\n                if evals >= self.budget:\n                    break\n                # local parameters\n                step = max(eps, self.local_init_frac * range_mean)\n                min_step = max(eps, self.local_min_frac * range_mean)\n                if gens_since_improve >= self.local_stagn_gen:\n                    step *= 2.0\n\n                x_work = x_best.copy()\n                f_work = f_best\n                local_improved = False\n\n                # anisotropic pattern search: try positive/negative steps per-dimension,\n                # prefer dimensions with larger sigma (more likely to help)\n                while step >= min_step and evals < self.budget:\n                    moved = False\n                    # dimension order by descending average sigma across population to bias search\n                    avg_sigma_dims = np.mean(sigma, axis=0)\n                    dims_order = np.argsort(-avg_sigma_dims)\n                    for d in dims_order:\n                        if evals >= self.budget:\n                            break\n                        # try plus\n                        x_try = x_work.copy()\n                        x_try[d] = np.minimum(ub[d], x_try[d] + step)\n                        if np.allclose(x_try, x_work):\n                            x_try[d] = np.maximum(lb[d], x_work[d] - step)\n                        fv = float(func(x_try))\n                        evals += 1\n                        if fv < f_work:\n                            x_work = x_try.copy()\n                            f_work = fv\n                            moved = True\n                            local_improved = True\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = x_work.copy()\n                                gens_since_improve = 0\n                            # opportunistic extra step in same direction (one more eval)\n                            if evals < self.budget:\n                                x_try2 = x_work.copy()\n                                x_try2[d] = np.minimum(ub[d], x_try2[d] + step)\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < f_work:\n                                    x_work = x_try2.copy()\n                                    f_work = fv2\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = x_try2.copy()\n                                        gens_since_improve = 0\n                        else:\n                            # try minus\n                            if evals >= self.budget:\n                                break\n                            x_try = x_work.copy()\n                            x_try[d] = np.maximum(lb[d], x_work[d] - step)\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                x_work = x_try.copy()\n                                f_work = fv\n                                moved = True\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_try.copy()\n                                    gens_since_improve = 0\n\n                    if not moved:\n                        step *= self.local_shrink\n\n                # inject local improvement into population (replace worst)\n                if local_improved:\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_work.copy()\n                    f[worst_idx] = f_work\n                    # set its sigma relatively small to exploit\n                    sigma[worst_idx] = np.clip(0.6 * np.mean(sigma, axis=0), sigma_min, sigma_max)\n                    gens_since_improve = 0\n                else:\n                    # if heavy stagnation, mildly re-seed a fraction of population around best with anisotropic jitter\n                    if gens_since_improve >= self.local_stagn_gen and evals < self.budget:\n                        n_reseed = max(1, pop // 3)\n                        for k in range(n_reseed):\n                            if evals >= self.budget:\n                                break\n                            # anisotropic jitter scaled by per-dim average sigma\n                            avg_sigma = np.mean(sigma, axis=0)\n                            jitter = rng.randn(self.dim) * (0.25 * avg_sigma + 0.05 * range_mean)\n                            newx = reflect_and_clamp(x_best + jitter)\n                            fv = float(func(newx))\n                            evals += 1\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = newx\n                            f[worst_idx] = fv\n                            sigma[worst_idx] = np.clip(0.7 * avg_sigma, sigma_min, sigma_max)\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = newx.copy()\n                                gens_since_improve = 0\n\n            # sync best from population\n            cur_best_idx = int(np.argmin(f))\n            if f[cur_best_idx] < f_best:\n                f_best = float(f[cur_best_idx])\n                x_best = X[cur_best_idx].copy()\n                gens_since_improve = 0\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "error": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "parent_ids": "140086d9-7241-4560-a19e-2703a518521f", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "4747e0ea-5335-49d5-9801-19465f0f98e6", "fitness": 0.5702649202959347, "name": "AMP_DE_Pattern", "description": "The algorithm is an ensemble hybrid that alternates current-to-pbest DE and a Gaussian mean-pull operator (controlled by p_frac and alpha_mean) with jDE-style self-adaptation of F and CR and per-individual isotropic sigmas that are adapted from a sliding success window (sigma_win, sigma_decrease/sigma_increase, tau_sigma_reset). Initialization uses stratified/Latin-like sampling with jitter and a population size that scales with sqrt(dim) but stays budget-aware, while bounds are handled by a reflect-and-clamp scheme and occasional opposition sampling (opposition_prob) for extra exploration. Operator choice is driven by recent sliding-window success rates (operator_win) to bias between DE and Gaussian moves, and candidate evaluations are opportunistic (multiple candidates tried only while budget remains) to conserve evaluations. Periodic or stagnation-triggered multi-scale Hooke–Jeeves coordinate refinement and mild restart nudges inject local search and diversification, all strictly budget-tracked so the algorithm never exceeds the allowed function-evaluation budget.", "code": "import numpy as np\n\nclass AMP_DE_Pattern:\n    \"\"\"\n    AMP-DE+ : Ensemble Adaptive Mean-Pulled Differential Evolution with Diagonal Gaussian\n    Mutations and Multi-scale Pattern Search.\n\n    Main idea (one line): Combine current-to-pbest DE and per-individual Gaussian mean-pull\n    mutations in an adaptive operator ensemble, with jDE-style F/CR and windowed sigma\n    adaptation, occasional opposition sampling, and periodic Hooke-Jeeves coordinate\n    refinement and mild restart nudges — all strictly budget-aware.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 p_frac=0.2,\n                 tau1=0.12, tau2=0.12, F_min=0.05, F_max=0.9,\n                 sigma_init_frac=0.25, sigma_min_frac=1e-5, sigma_max_frac=1.2,\n                 sigma_win=12, sigma_decrease=0.92, sigma_increase=1.06, tau_sigma_reset=0.04,\n                 alpha_mean=0.6,\n                 opposition_prob=0.15,\n                 local_period=15, local_stagn_gen=35,\n                 local_init_frac=0.12, local_shrink=0.5, local_min_frac=1e-5,\n                 operator_win=20,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.p_frac = float(p_frac)\n        self.tau1 = float(tau1)\n        self.tau2 = float(tau2)\n        self.F_min = float(F_min)\n        self.F_max = float(F_max)\n\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.sigma_min_frac = float(sigma_min_frac)\n        self.sigma_max_frac = float(sigma_max_frac)\n        self.sigma_win = int(sigma_win)\n        self.sigma_decrease = float(sigma_decrease)\n        self.sigma_increase = float(sigma_increase)\n        self.tau_sigma_reset = float(tau_sigma_reset)\n\n        self.alpha_mean = float(alpha_mean)\n        self.opposition_prob = float(opposition_prob)\n\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.local_init_frac = float(local_init_frac)\n        self.local_shrink = float(local_shrink)\n        self.local_min_frac = float(local_min_frac)\n\n        self.operator_win = int(operator_win)\n\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # read bounds, handle scalar bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        range_vec = ub - lb\n        range_mean = float(np.mean(range_vec))\n        eps = 1e-12\n\n        # population sizing: moderate population that scales with dim but stays budget-aware\n        if self.pop_base is None:\n            pop = max(12, int(min( max(12, 6 * np.sqrt(max(1, self.dim))), self.budget )))\n        else:\n            pop = int(min(self.pop_base, self.budget))\n        pop = max(2, pop)\n\n        evals = 0\n\n        # Stratified / Latin-like initialization per dimension, plus jitter\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        jitter_scale = 0.25 * range_mean / max(1.0, self.dim)\n        X += (rng.rand(pop, self.dim) - 0.5) * jitter_scale\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially (budget-aware)\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        # if budget exhausted during init\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # jDE-style F and CR per individual\n        F = np.clip(0.5 + 0.1 * rng.randn(pop), self.F_min, self.F_max)\n        CR = np.clip(rng.rand(pop), 0.0, 1.0)\n        tau1 = self.tau1\n        tau2 = self.tau2\n\n        # per-individual sigma (isotropic)\n        sigma = np.full(pop, max(eps, self.sigma_init_frac * range_mean), dtype=float)\n        sigma_min = max(eps, self.sigma_min_frac * range_mean)\n        sigma_max = max(eps, self.sigma_max_frac * range_mean)\n        sigma_hist = np.zeros((pop, max(1, self.sigma_win)), dtype=np.int8)\n        sigma_pos = 0\n\n        # operator ensemble statistics (DE vs GAUSS)\n        op_win = max(1, self.operator_win)\n        op_success = np.ones((2, op_win), dtype=np.int8)  # rows: 0=DE,1=GAUSS\n        op_trials = np.ones((2, op_win), dtype=np.int8)\n        op_pos = 0\n        # initial operator probability favoring GAUSS a bit for exploration\n        op_prob_de = 0.45\n        op_prob_gauss = 1.0 - op_prob_de\n\n        # tracking best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        # helper bounds reflection/clamp\n        def reflect_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        # p-best pool size min 2\n        def p_pool_indices(fvals):\n            pnum = max(2, int(np.ceil(self.p_frac * pop)))\n            order = np.argsort(fvals)\n            return order[:pnum], order\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # update operator probabilities from sliding window successes\n            de_success_rate = np.sum(op_success[0]) / float(np.sum(op_trials[0]))\n            ga_success_rate = np.sum(op_success[1]) / float(np.sum(op_trials[1]))\n            # soft max-like weighting to avoid zeros\n            denom = (de_success_rate + ga_success_rate + 1e-12)\n            op_prob_de = 0.2 + 0.8 * (de_success_rate / denom)  # keep some baseline on DE\n            op_prob_de = np.clip(op_prob_de, 0.05, 0.95)\n            op_prob_gauss = 1.0 - op_prob_de\n\n            pop_mean = np.mean(X, axis=0)\n\n            p_pool, order = p_pool_indices(f)\n\n            # iterate in shuffled order\n            idxs = rng.permutation(pop)\n            gen_success = np.zeros(pop, dtype=np.int8)\n\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fi = f[ii]\n\n                # adapt F and CR jDE-style\n                if rng.rand() < tau1:\n                    F[ii] = np.clip(0.4 + 0.3 * rng.rand(), self.F_min, self.F_max)\n                if rng.rand() < tau2:\n                    CR[ii] = rng.rand()\n\n                # pick operator: DE or GAUSS\n                use_de = (rng.rand() < op_prob_de)\n\n                if use_de:\n                    # DE current-to-pbest/1\n                    # choose pbest\n                    pbest_idx = int(rng.choice(p_pool))\n                    # choose r1, r2 distinct from ii and pbest\n                    pool = [j for j in range(pop) if j not in (ii, pbest_idx)]\n                    if len(pool) >= 2:\n                        r1, r2 = rng.choice(pool, size=2, replace=False)\n                    elif len(pool) == 1:\n                        r1 = pool[0]; r2 = pool[0]\n                    else:\n                        r1 = r2 = ii\n                    xp = X[pbest_idx]\n                    xr1 = X[r1]\n                    xr2 = X[r2]\n                    vi = xi + F[ii] * (xp - xi) + F[ii] * (xr1 - xr2)\n\n                    # binomial crossover\n                    jrand = rng.randint(self.dim)\n                    mask = (rng.rand(self.dim) < CR[ii])\n                    mask[jrand] = True\n                    trial = np.where(mask, vi, xi)\n                    trial = reflect_clamp(trial)\n\n                    # prepare candidates (opposition sometimes)\n                    candidates = [trial]\n                    if rng.rand() < self.opposition_prob:\n                        opp = lb + ub - trial\n                        opp += (rng.randn(self.dim) * 0.01 * range_mean)\n                        opp = reflect_clamp(opp)\n                        candidates.append(opp)\n\n                    # opportunistic evaluation: evaluate candidates in order, pick best\n                    best_local_x = None\n                    best_local_f = np.inf\n                    for xcand in candidates:\n                        if evals >= self.budget:\n                            break\n                        fv = float(func(xcand))\n                        evals += 1\n                        if fv < best_local_f:\n                            best_local_f = fv\n                            best_local_x = xcand.copy()\n\n                    # selection\n                    op_index = 0  # DE\n                    op_trials[op_index, op_pos] += 1\n                    if best_local_f <= fi:\n                        X[ii] = best_local_x\n                        f[ii] = best_local_f\n                        gen_success[ii] = 1\n                        op_success[op_index, op_pos] += 1\n                        if best_local_f < f_best:\n                            f_best = best_local_f\n                            x_best = best_local_x.copy()\n                            improved_in_gen = True\n                            gens_since_improve = 0\n                    else:\n                        gen_success[ii] = 0\n\n                else:\n                    # GAUSS mean-pull + isotropic Gaussian with per-individual sigma and mixing\n                    if rng.rand() < self.tau_sigma_reset:\n                        sigma[ii] = rng.rand() * (sigma_max - sigma_min) + sigma_min\n\n                    pull = self.alpha_mean * (pop_mean - xi)\n                    gauss = rng.randn(self.dim) * sigma[ii]\n                    trial = xi + pull + gauss\n\n                    # mixing mask to preserve some coords\n                    mask = rng.rand(self.dim) < 0.6\n                    if not np.any(mask):\n                        mask[rng.randint(self.dim)] = True\n                    trial = np.where(mask, trial, xi)\n                    trial = reflect_clamp(trial)\n\n                    candidates = [trial]\n                    if rng.rand() < self.opposition_prob:\n                        opp = lb + ub - trial\n                        opp += (rng.randn(self.dim) * 0.01 * range_mean)\n                        opp = reflect_clamp(opp)\n                        candidates.append(opp)\n\n                    best_local_x = None\n                    best_local_f = np.inf\n                    for xcand in candidates:\n                        if evals >= self.budget:\n                            break\n                        fv = float(func(xcand))\n                        evals += 1\n                        if fv < best_local_f:\n                            best_local_f = fv\n                            best_local_x = xcand.copy()\n\n                    op_index = 1  # GAUSS\n                    op_trials[op_index, op_pos] += 1\n                    if best_local_f <= fi:\n                        X[ii] = best_local_x\n                        f[ii] = best_local_f\n                        gen_success[ii] = 1\n                        op_success[op_index, op_pos] += 1\n                        if best_local_f < f_best:\n                            f_best = best_local_f\n                            x_best = best_local_x.copy()\n                            improved_in_gen = True\n                            gens_since_improve = 0\n                    else:\n                        gen_success[ii] = 0\n\n                # record sigma success for window\n                sigma_hist[ii, sigma_pos] = gen_success[ii]\n\n            # update sliding windows\n            sigma_pos = (sigma_pos + 1) % sigma_hist.shape[1]\n            # adapt sigma by windowed success rate\n            success_rate = np.sum(sigma_hist, axis=1) / float(sigma_hist.shape[1])\n            for i in range(pop):\n                if success_rate[i] > 0.25:\n                    sigma[i] = max(sigma_min, sigma[i] * self.sigma_decrease)\n                elif success_rate[i] < 0.15:\n                    sigma[i] = min(sigma_max, sigma[i] * self.sigma_increase)\n                # occasional jitter to encourage exploration\n                if rng.rand() < 0.015:\n                    sigma[i] = np.clip(sigma[i] * (1.0 + 0.1 * rng.randn()), sigma_min, sigma_max)\n\n            # operator window pos update\n            op_pos = (op_pos + 1) % op_win\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # periodic or stagnation-triggered multi-scale local search (Hooke-Jeeves style)\n            if gen % self.local_period == 0 or gens_since_improve >= self.local_stagn_gen:\n                remaining = self.budget - evals\n                if remaining <= 0:\n                    break\n\n                step = max(eps, self.local_init_frac * range_mean)\n                min_step = max(eps, self.local_min_frac * range_mean)\n                if gens_since_improve >= self.local_stagn_gen:\n                    step *= 2.0\n\n                local_improved = False\n                x_work = x_best.copy()\n                f_work = f_best\n\n                # randomized coordinate order to avoid bias\n                while step >= min_step and (self.budget - evals) > 0:\n                    moved = False\n                    dims = list(range(self.dim))\n                    rng.shuffle(dims)\n                    for d in dims:\n                        if evals >= self.budget:\n                            break\n                        # plus\n                        x_try = x_work.copy()\n                        x_try[d] = min(ub[d], x_try[d] + step)\n                        if np.allclose(x_try, x_work):\n                            x_try[d] = max(lb[d], x_work[d] - step)\n                        x_try = reflect_clamp(x_try)\n\n                        fv = float(func(x_try))\n                        evals += 1\n                        if fv < f_work:\n                            x_work = x_try.copy()\n                            f_work = fv\n                            moved = True\n                            local_improved = True\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = x_try.copy()\n                                gens_since_improve = 0\n                            # opportunistic extra probe in same direction\n                            if evals < self.budget:\n                                x_try2 = x_work.copy()\n                                x_try2[d] = np.minimum(np.maximum(x_try2[d] + step, lb[d]), ub[d])\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < f_work:\n                                    x_work = x_try2.copy()\n                                    f_work = fv2\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = x_try2.copy()\n                                        gens_since_improve = 0\n                        else:\n                            # try minus\n                            if evals >= self.budget:\n                                break\n                            x_try = x_work.copy()\n                            x_try[d] = max(lb[d], x_work[d] - step)\n                            x_try = reflect_clamp(x_try)\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                x_work = x_try.copy()\n                                f_work = fv\n                                moved = True\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_try.copy()\n                                    gens_since_improve = 0\n\n                    if not moved:\n                        step *= self.local_shrink\n                    # continue until step too small or budget done\n\n                # inject improvement into population\n                if local_improved:\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_work.copy()\n                    f[worst_idx] = f_work\n                    gens_since_improve = 0\n                else:\n                    # mild restart nudges if stagnating\n                    if gens_since_improve >= self.local_stagn_gen:\n                        half = pop // 2\n                        for k in range(half):\n                            if evals >= self.budget:\n                                break\n                            jitter = rng.randn(self.dim) * (0.08 * range_mean)\n                            newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                            fv = float(func(newx))\n                            evals += 1\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = newx\n                            f[worst_idx] = fv\n                            sigma[worst_idx] = np.clip(0.6 * np.mean(sigma), sigma_min, sigma_max)\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = newx.copy()\n                                gens_since_improve = 0\n\n            # synchronize best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n            # safety: break if budget exhausted\n            if evals >= self.budget:\n                break\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AMP_DE_Pattern scored 0.570 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "140086d9-7241-4560-a19e-2703a518521f", "operator": null, "metadata": {"aucs": [0.1153394462314391, 0.18712303727640534, 0.7291013946653631, 0.989082973429752, 0.7690833803744845, 0.8728058567638128, 0.31177813452730707, 0.6221599625950291, 0.7941691900026939, 0.3120058270930597]}, "task_prompt": ""}
{"id": "d5e303c8-daef-47be-bd23-de85307b588b", "fitness": 0.4492698798022303, "name": "MirrorDirectionalDECov", "description": "The algorithm is a hybrid global-local heuristic that interleaves mirrored Gaussian sampling around a weighted centroid with centroid-directed DE-style trial vectors informed by a SHADE-like memory for F/R (H=10) and an adaptively learned covariance (cov_lr≈0.12) to shape search directions. Initialization and diversity are emphasized via a small mirror-seeded population centered on the box midpoint, an archive of past points for DE differences/replacement, and reflect-then-clamp boundary handling to keep samples feasible. Several adaptive mechanisms guide step sizes and exploration: sigma starts as a fraction of the bound range (≈0.18·range_mean) and is adjusted by a success-rate rule (sigma_adapt_rate≈0.18 toward success_target≈0.22), SHADE memory updates successful F/CR statistics, and covariance is updated from weighted, normalized deltas and mean shifts. Robustness and exploitation are added by periodic opportunistic line probes (local_period≈30), occasional Lévy-like heavy-tailed escapes (levy_prob≈0.06), and mild reseeding around the best on stagnation to avoid long traps.", "code": "import numpy as np\n\nclass MirrorDirectionalDECov:\n    \"\"\"\n    MirrorDirectionalDECov:\n    - Hybrid algorithm combining mirrored Gaussian sampling (variance reduction) with centroid-directed\n      DE-style trials informed by a SHADE-like memory for F/CR, shaped by an adaptive covariance.\n    - Adds occasional Lévy-like escapes and periodic opportunistic line probes; stagnation triggers\n      mild reseeding around the best. Reflect-then-clamp bound handling is used throughout.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop_base=None,\n                 H=10,                    # SHADE memory length\n                 cov_lr=0.12,             # covariance learning rate\n                 sigma_init_frac=0.18,    # initial sigma as fraction of mean bound range\n                 sigma_adapt_rate=0.18,   # adaptation speed for sigma (success-rate rule)\n                 success_target=0.22,\n                 p_frac=0.25,             # fraction to form centroid / elites\n                 local_period=30,         # line-probe period\n                 stagnation_restart=45,   # reseed trigger\n                 levy_prob=0.06):         # occasional heavy-tailed jump prob\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.pop_base = pop_base\n\n        self.H = int(H)\n        self.cov_lr = float(cov_lr)\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.success_target = float(success_target)\n\n        self.p_frac = float(p_frac)\n        self.local_period = int(local_period)\n        self.stagnation_restart = int(stagnation_restart)\n        self.levy_prob = float(levy_prob)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        range_mean = float(np.mean(bounds_scale))\n        max_bound = float(np.max(bounds_scale))\n\n        # population size heuristic (small)\n        if self.pop_base is None:\n            pop = max(8, int(4 + 2 * np.sqrt(max(1, self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # initialize mirror-seeded population for coverage:\n        half = (pop + 1) // 2\n        X = np.empty((pop, self.dim), dtype=float)\n        center_init = 0.5 * (lb + ub)\n        for i in range(half):\n            u = rng.rand(self.dim)\n            X[i] = lb + u * (ub - lb)\n            j = i + half\n            if j < pop:\n                X[j] = 2.0 * center_init - X[i]\n        # small jitter\n        X += (rng.randn(pop, self.dim) * 1e-3 * bounds_scale.reshape(1, -1))\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        # If budget exhausted during init\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # SHADE-like memory for F and CR\n        H = max(1, int(self.H))\n        mem_F = np.full(H, 0.5, dtype=float)\n        mem_CR = np.full(H, 0.5, dtype=float)\n        mem_pos = 0\n\n        # covariance initialization (isotropic scaled)\n        C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n        # safe factorization helper\n        def chol_spd(mat):\n            eps = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        # reflect-then-clamp\n        def reflect_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        # membership for centroid (top p)\n        pnum_min = max(2, int(np.ceil(self.p_frac * pop)))\n\n        # initial mean m: weighted mean of top half\n        order0 = np.argsort(f)\n        mu0 = max(1, pop // 2)\n        elites0 = X[order0[:mu0]]\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 = w0 / np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # sigma initial and adaptive success smoothing\n        sigma = max(1e-12, self.sigma_init_frac * range_mean)\n        p_succ = float(self.success_target)\n\n        # archive to support DE selection and covariance learning\n        archive_X = [x.copy() for x in X]\n        archive_f = [float(fi) for fi in f]\n        archive_capacity = max(4 * self.dim, 20)\n\n        # best tracking\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            # generation budget: propose up to min(pop, remaining)\n            lam = min(pop, remaining)\n            mu = max(1, lam // 2)\n\n            # sampling transform from covariance\n            A = chol_spd(C)  # lower-triangular-like with shape (dim, dim) for matmul with normals\n\n            # build centroid of top p\n            order = np.argsort(f)\n            top_p = order[:max(pnum_min, 2)]\n            centroid = np.mean(X[top_p], axis=0)\n\n            # prepare lists for memory updates from DE successes\n            succ_F = []\n            succ_CR = []\n            succ_w = []\n\n            # Candidate composition: mirrored Gaussian half, DE-style half, and a few centroid-directed\n            n_mirror = lam // 2\n            n_de = lam - n_mirror\n\n            Xcand = np.empty((lam, self.dim), dtype=float)\n\n            # 1) mirrored Gaussian proposals centered at m with covariance C\n            if n_mirror > 0:\n                Z = rng.normal(size=(n_mirror, self.dim))\n                Y = Z @ (A.T)  # correlated samples with covariance C\n                Xg = m.reshape(1, -1) + sigma * Y\n                Xg_mirror = 2.0 * m.reshape(1, -1) - Xg\n                # interleave originals and mirrors up to n_mirror\n                for i in range(n_mirror):\n                    if i < Xg.shape[0]:\n                        cand = Xg[i]\n                    else:\n                        cand = Xg_mirror[i - Xg.shape[0]]\n                    Xcand[i] = np.minimum(np.maximum(cand, lb), ub)\n\n            # 2) DE-like centroid-directed trials for diversity, using SHADE memory per trial\n            for k in range(n_de):\n                idx = n_mirror + k\n                # pick memory index\n                mem_idx = rng.randint(H)\n                # sample F from Cauchy around mem_F[mem_idx]\n                attempts = 0\n                Fi = None\n                while attempts < 5:\n                    Fi = mem_F[mem_idx] + 0.1 * rng.standard_cauchy()\n                    if Fi > 1e-6 and np.isfinite(Fi):\n                        break\n                    attempts += 1\n                if Fi is None or not np.isfinite(Fi):\n                    Fi = 0.5\n                Fi = float(np.clip(Fi, 0.05, 1.0))\n                # sample CR from normal around mem_CR[mem_idx]\n                CRi = float(np.clip(mem_CR[mem_idx] + 0.1 * rng.randn(), 0.0, 1.0))\n\n                # choose base vector (either m or a random archive member)\n                if rng.rand() < 0.5 and len(archive_X) > 0:\n                    base = archive_X[rng.randint(len(archive_X))]\n                else:\n                    base = m\n\n                # pick two archive/ population vectors for differential term\n                if len(archive_X) >= 2:\n                    r1, r2 = rng.choice(len(archive_X), size=2, replace=False)\n                    xr1 = archive_X[r1]\n                    xr2 = archive_X[r2]\n                else:\n                    # fallback to population differences\n                    pool = [ii for ii in range(pop)]\n                    r1, r2 = rng.choice(pool, size=2, replace=False)\n                    xr1 = X[r1]\n                    xr2 = X[r2]\n\n                # pick a target from population (random)\n                target_idx = rng.randint(pop)\n                target = X[target_idx]\n\n                # centroid-directed mutated vector (inspired by No.1)\n                vi = target + Fi * (centroid - target) + Fi * (xr1 - xr2)\n\n                # binomial crossover with target to build trial\n                mask = rng.rand(self.dim) < CRi\n                if not np.any(mask):\n                    mask[rng.randint(self.dim)] = True\n                trial = np.where(mask, vi, target)\n\n                # small Gaussian shaping with covariance A — keep some structure\n                trial += (rng.normal(scale=0.25) * (A @ rng.randn(self.dim))) * (sigma / (1.0 + range_mean))\n\n                # occasional Lévy-like heavy-tailed jump from trial to escape (rare)\n                if rng.rand() < self.levy_prob * 0.7:\n                    scale = (0.05 + 2.0 * (rng.rand() ** -0.7)) * (ub - lb)\n                    trial = trial + rng.randn(self.dim) * scale\n\n                Xcand[idx] = reflect_clamp(trial)\n\n                # store sampled Fi/CR for potential updates per trial bookkeeping (we will record only on success)\n                # to track per-candidate params, temporarily store as attributes in arrays\n                # Use lists mapping to candidate index\n                # We'll evaluate sequentially below and use local lists to update memory\n\n                # attach to Xcand by storing Fi & CR in parallel lists\n            # Evaluate candidates sequentially (ensuring budget)\n            f_cand = np.full(lam, np.inf, dtype=float)\n            # to map DE parameters to their indices for memory update, recompute for DE slots\n            DE_params = {}\n            # Recompute DE sampling for slots to ensure Fi/CR values are available and deterministic consistent\n            # (the code above sampled Fi/CR but didn't store them; re-sample in same manner deterministically)\n            # For simplicity and reproducibility we will regenerate Fi/CR here similarly:\n            for k in range(n_de):\n                idx = n_mirror + k\n                mem_idx = rng.randint(H)\n                attempts = 0\n                Fi = None\n                while attempts < 5:\n                    Fi = mem_F[mem_idx] + 0.1 * rng.standard_cauchy()\n                    if Fi > 1e-6 and np.isfinite(Fi):\n                        break\n                    attempts += 1\n                if Fi is None or not np.isfinite(Fi):\n                    Fi = 0.5\n                Fi = float(np.clip(Fi, 0.05, 1.0))\n                CRi = float(np.clip(mem_CR[mem_idx] + 0.1 * rng.randn(), 0.0, 1.0))\n                DE_params[idx] = (Fi, CRi, mem_idx)\n\n            # Now evaluate candidates, but ensure we don't exceed budget and we properly handle DE successes\n            for i in range(lam):\n                if evals >= self.budget:\n                    break\n                # If the candidate was not filled due to earlier logic (shouldn't happen), fill with m\n                xi = Xcand[i]\n                fv = float(func(xi))\n                f_cand[i] = fv\n                evals += 1\n                # immediate archive and best updates\n                archive_X.append(xi.copy())\n                archive_f.append(float(fv))\n                if fv < f_best:\n                    f_best = fv\n                    x_best = xi.copy()\n                    gens_since_improve = 0\n                # If this was a DE-style index and it improved over a selected population index, record success\n                if i in DE_params:\n                    # map this candidate to closest population member to attempt replacement (we simulate rand/1 replacement by worst)\n                    # Choose parent as a random population member to compare; emulate replacement if better than that parent's current f.\n                    Fi, CRi, mem_idx_used = DE_params[i]\n                    # select a parent index randomly to compare (we could also use target_idx but not stored)\n                    parent_idx = rng.randint(pop)\n                    if f_cand[i] <= f[parent_idx]:\n                        # accept into population by replacing parent (a simple selection rule)\n                        X[parent_idx] = xi.copy()\n                        f[parent_idx] = float(f_cand[i])\n                        # record success stats for mem update\n                        # use improvement magnitude as weight\n                        w = max(1e-12, abs(f[parent_idx] - f_cand[i]))\n                        succ_F.append(Fi)\n                        succ_CR.append(CRi)\n                        succ_w.append(w)\n                # populate best-propagation into population: opportunistically replace worst with candidate if better\n                # but maintain careful budget accounting (we have already evaluated)\n                if f_cand[i] < np.max(f):\n                    worst = int(np.argmax(f))\n                    if f_cand[i] < f[worst]:\n                        X[worst] = Xcand[i].copy()\n                        f[worst] = float(f_cand[i])\n\n            # trim archive\n            if len(archive_X) > archive_capacity:\n                excess = len(archive_X) - archive_capacity\n                archive_X = archive_X[excess:]\n                archive_f = archive_f[excess:]\n\n            # SHADE-like memory updates if there were successes\n            if len(succ_F) > 0:\n                sF = np.asarray(succ_F)\n                sCR = np.asarray(succ_CR)\n                sW = np.asarray(succ_w)\n                if np.sum(sW) > 0:\n                    wnorm = sW / np.sum(sW)\n                else:\n                    wnorm = np.ones_like(sW) / len(sW)\n                numer = np.sum(wnorm * (sF ** 2))\n                denom = np.sum(wnorm * sF) + 1e-12\n                new_mF = numer / denom\n                new_mCR = np.sum(wnorm * sCR)\n                # store into memory with smoothing (conservative)\n                mem_F[mem_pos] = 0.9 * mem_F[mem_pos] + 0.1 * float(np.clip(new_mF, 1e-3, 1.0))\n                mem_CR[mem_pos] = 0.9 * mem_CR[mem_pos] + 0.1 * float(np.clip(new_mCR, 0.0, 1.0))\n                mem_pos = (mem_pos + 1) % H\n\n            # recompute generation best from the evaluated candidates\n            valid_idx = np.argmin(f_cand)\n            gen_best_f = float(f_cand[valid_idx])\n            gen_best_x = Xcand[valid_idx].copy()\n\n            # detect improvement relative to current mean approximation: find nearest archive point to m\n            if len(archive_X) > 0:\n                Xh = np.asarray(archive_X)\n                dists = np.sum((Xh - m)**2, axis=1)\n                idx0 = int(np.argmin(dists))\n                f_m_approx = float(archive_f[idx0])\n            else:\n                f_m_approx = f_best\n\n            improved_center = gen_best_f < f_m_approx - 1e-12\n\n            # recombination: weighted mean of top-mu candidates (log-weights)\n            order_c = np.argsort(f_cand)\n            mu_eff = max(1, min(mu, len(order_c)))\n            ranks = np.arange(mu_eff)\n            weights = np.log(mu_eff + 0.5) - np.log(ranks + 1.0)\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n            X_mu = Xcand[order_c[:mu_eff]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # covariance update using normalized deltas (w.r.t. sigma)\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas if deltas.shape[0] > 0 else np.zeros((self.dim, self.dim))\n            # small rank-1 term from mean shift\n            mean_shift = ((m_new - m) / (sigma + 1e-20)).reshape(-1, 1)\n            rank_one = 0.5 * (mean_shift @ mean_shift.T)\n            C = (1.0 - self.cov_lr) * C + self.cov_lr * (weighted_cov + rank_one)\n\n            # ensure symmetry and positive-definiteness via eigendecomposition\n            vals, vecs = np.linalg.eigh(C)\n            vals = np.clip(vals, 1e-12, None)\n            C = (vecs * vals) @ vecs.T\n\n            # update mean softly\n            m = 0.85 * m + 0.15 * m_new\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # success-based sigma adaptation (smoothed)\n            was_improved = gen_best_f < f_best\n            p_succ = 0.9 * p_succ + 0.1 * float(was_improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = float(np.clip(sigma, 1e-12, 2.0 * max_bound))\n\n            # Opportunistic line probes (doubling) around best periodically or on stagnation\n            if (gen % self.local_period == 0) or (gens_since_improve >= self.stagnation_restart):\n                if evals < self.budget:\n                    step0 = max(1e-12, 0.2 * range_mean)\n                    min_step = max(1e-12, 1e-4 * range_mean)\n                    if gens_since_improve >= self.stagnation_restart:\n                        step0 *= 2.0\n                    local_improved = False\n                    x_work = x_best.copy()\n                    f_work = f_best\n                    n_dirs = min(4, self.dim)\n                    for di in range(n_dirs):\n                        if evals >= self.budget:\n                            break\n                        dvec = rng.randn(self.dim)\n                        dn = np.linalg.norm(dvec)\n                        if dn == 0.0:\n                            continue\n                        dvec /= dn\n                        step = step0\n                        while step >= min_step and evals < self.budget:\n                            x_try = reflect_clamp(x_work + dvec * step)\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                x_work = x_try\n                                f_work = fv\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_try.copy()\n                                    gens_since_improve = 0\n                                step *= 2.0\n                            else:\n                                x_try2 = reflect_clamp(x_work - dvec * step)\n                                if evals >= self.budget:\n                                    break\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < f_work:\n                                    x_work = x_try2\n                                    f_work = fv2\n                                    local_improved = True\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = x_try2.copy()\n                                        gens_since_improve = 0\n                                    step *= 2.0\n                                else:\n                                    step *= 0.5\n                    if local_improved:\n                        # inject improvement into population replacing worst\n                        worst_idx = int(np.argmax(f))\n                        X[worst_idx] = x_work.copy()\n                        f[worst_idx] = f_work\n                        # small covariance nudging toward local step\n                        s = ((x_work - m) / (sigma + 1e-20)).reshape(-1, 1)\n                        C = 0.96 * C + 0.04 * (s @ s.T)\n                        gens_since_improve = 0\n                    else:\n                        # stagnation reseed half of population around best\n                        if gens_since_improve >= self.stagnation_restart:\n                            halfp = pop // 2\n                            for k in range(halfp):\n                                if evals >= self.budget:\n                                    break\n                                jitter = rng.randn(self.dim) * (0.06 * bounds_scale)\n                                newx = reflect_clamp(x_best + jitter)\n                                fv = float(func(newx))\n                                evals += 1\n                                worst_idx = int(np.argmax(f))\n                                X[worst_idx] = newx\n                                f[worst_idx] = fv\n                                archive_X.append(newx.copy())\n                                archive_f.append(float(fv))\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = newx.copy()\n                                    gens_since_improve = 0\n\n            # occasional Lévy escape if stuck\n            if (rng.rand() < self.levy_prob) and (evals < self.budget):\n                # heavy-tailed jump centered at a random elite in archive\n                if len(archive_X) > 0:\n                    idx_sort = np.argsort(archive_f)\n                    anchor = archive_X[idx_sort[rng.randint(min(len(idx_sort), max(3, self.dim)))]]\n                    scale = 0.5 * range_mean * (1.0 + rng.rand() * 2.0)\n                    jump = rng.standard_cauchy(self.dim) * (scale * 0.25)\n                    x_jump = reflect_clamp(anchor + jump)\n                    fj = float(func(x_jump))\n                    evals += 1\n                    archive_X.append(x_jump.copy())\n                    archive_f.append(float(fj))\n                    if fj < f_best:\n                        f_best = fj\n                        x_best = x_jump.copy()\n                        gens_since_improve = 0\n                        # nudge mean and inflate sigma slightly\n                        m = 0.9 * m + 0.1 * x_jump\n                        sigma = max(sigma, 0.5 * range_mean)\n\n            # synchronize best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n            # update stagnation counter\n            if f_best < np.min(f):  # if best improved into population earlier we already reset\n                pass\n            # increment if no improvement in generation (simple heuristic)\n            if gen == 1:\n                gens_since_improve = 0\n            else:\n                gens_since_improve += 1\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MirrorDirectionalDECov scored 0.449 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "140086d9-7241-4560-a19e-2703a518521f", "operator": null, "metadata": {"aucs": [0.18163661779187212, 0.266783894948152, 0.5545543578448866, 0.9638769267843292, 0.3807477419851113, 0.9710909717619668, 0.29656980394107235, 0.44420587638018705, 0.24237698466223412, 0.19085562192249095]}, "task_prompt": ""}
{"id": "e43618bc-bc8b-46dd-a7b5-c266ebadada2", "fitness": 0.546580496956259, "name": "MSARS", "description": "The algorithm maintains a single center m with per-direction step sizes sigma expressed in a learned orthonormal rotated basis R, plus a small evolution path p and an archive of recent evaluations to support local models and rotation learning. Candidate generation is a mixed ensemble: directional probes along rotated axes (both signs), multivariate Gaussian draws (short/long scales), a cheap diagonal-quadratic surrogate step fitted on the archive (with ridge regularization), occasional reflection/extrapolation of recent successful steps, and uniform jitter, all clipped to bounds. Adaptation is opportunistic and per-dimension: successful components multiply their sigma by eta_plus (1.2) while failures shrink by eta_minus (0.7), successful normalized steps are stored and R is updated periodically via SVD (rotation_update_every=3) to align search axes with promising directions, and the center is moved to better candidates (with soft moves on failure) while momentum p smooths progress. Robustness is added via an initial Latin/uniform batch to seed m and sigma (sigma_init_frac=0.25), archive sizing scaling (archive_factor=8), sigma min/max caps relative to problem range, adaptive surrogate regularization, stagnation detection and opportunistic restarts to escape collapse.", "code": "import numpy as np\n\nclass MSARS:\n    \"\"\"\n    Multi-Scale Adaptive Rotational Search (MSARS)\n\n    Main ideas:\n      - Maintain a center m, a per-direction step-size vector sigma (interpreted in a rotated basis R),\n        an orthonormal rotation R (learned from successful steps), and an archive of recent evaluations.\n      - Generate a small ensemble mixing:\n         * directional probes along rotated basis directions (both signs) with per-direction scales,\n         * multivariate Gaussian samples in rotated coordinates (mixture of long/short scale draws),\n         * a surrogate-derived step from a cheap diagonal-quadratic fit on recent archive,\n         * occasional reflection/extrapolation probes.\n      - Accept center improvements and adapt sigma multiplicatively per-direction (increase on success,\n        shrink on failure). Use a small evolution path (momentum) and update R from the principal directions\n        of recent successful normalized steps (SVD).\n      - Opportunistic restart when stagnation or collapse is detected.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop_base=None,\n                 sigma_init_frac=0.25,    # initial fraction of bound range for sigma (per-dim)\n                 eta_plus=1.2,            # multiplicative increase on successful directions\n                 eta_minus=0.7,           # multiplicative decrease on unsuccessful directions\n                 min_sigma=1e-9,\n                 max_sigma_factor=2.0,    # cap sigma upper relative to bound range\n                 archive_factor=8,        # archive size scaling with dim\n                 rotation_update_every=3, # update rotation every k iterations\n                 stagn_threshold_factor=0.05):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.pop_base = pop_base\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.eta_plus = float(eta_plus)\n        self.eta_minus = float(eta_minus)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma_factor = float(max_sigma_factor)\n        self.archive_factor = int(archive_factor)\n        self.rotation_update_every = int(rotation_update_every)\n        self.stagn_threshold_factor = float(stagn_threshold_factor)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        mean_range = float(np.mean(bounds_scale))\n        max_range = float(np.max(bounds_scale))\n\n        # population base\n        if self.pop_base is None:\n            lam = max(8, int(6 + np.sqrt(max(1, self.dim)) * 2))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # archive capacity\n        archive_capacity = max(self.dim * self.archive_factor, 4 * self.dim, 30)\n\n        # initial sampling (small Latin/Rand batch) to initialize center and sigma\n        init_batch = min(lam * 2, max(2, self.budget // 20), self.budget)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals = init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # center initialized as best of initial batch (conservative)\n        m = X0[best_idx].copy()\n\n        # per-direction sigma initialized isotropically but will be used in rotated basis\n        sigma0 = self.sigma_init_frac * mean_range\n        sigma = np.full(self.dim, sigma0, dtype=float)\n\n        # rotation matrix (orthonormal) initial identity\n        R = np.eye(self.dim)\n\n        # evolution path / momentum\n        p = np.zeros(self.dim)\n\n        # archives\n        X_hist = list(X0)\n        f_hist = list(f0)\n\n        # bookkeeping for rotation updates based on successful normalized steps\n        success_step_memory = []  # stores normalized steps (in rotated coords)\n        success_memory_capacity = max(4, self.dim * 2)\n\n        # stagnation counters\n        stagn_iters = 0\n        stagn_limit = max(5, int(self.stagn_threshold_factor * self.budget))\n        iter_count = 0\n\n        # helper: ensure orthonormal rotation via QR\n        def orthonormalize(mat):\n            # The first dim columns of random mat -> QR\n            q, r = np.linalg.qr(mat)\n            # enforce right-handedness\n            diag = np.sign(np.diag(r))\n            q *= diag\n            return q[:, :self.dim]\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu = max(1, lam_iter // 3)\n\n            # create rotated basis sigma vector\n            sigma_rot = sigma.copy()  # sigma interpreted in rotated coordinates\n\n            # generate candidates\n            candidates = []\n\n            # 1) directional probes along top rotated axes (both signs) with amplitude jitter\n            n_dir = min(self.dim, max(1, lam_iter // 4))\n            axes_idx = np.arange(self.dim)\n            rng.shuffle(axes_idx)\n            for k in axes_idx[:n_dir]:\n                # amplitude relative to sigma_rot[k], jitter multiplicative factor\n                amp = sigma_rot[k] * (0.8 + 0.8 * rng.rand())\n                vec_rot = np.zeros(self.dim)\n                vec_rot[k] = amp if rng.rand() < 0.5 else -amp\n                cand = m + R.dot(vec_rot)\n                candidates.append(cand)\n                if len(candidates) >= lam_iter:\n                    break\n\n            # 2) gaussian samples in rotated coords: mixture of short and long scales\n            if len(candidates) < lam_iter:\n                n_gauss = lam_iter - len(candidates) - 1  # keep one slot for surrogate if possible\n                if n_gauss < 0:\n                    n_gauss = 0\n                if n_gauss > 0:\n                    # create covariance diag(sigma_rot^2) and sample in rotated coordinates\n                    Z = rng.normal(size=(n_gauss, self.dim)) * sigma_rot\n                    Xg = m + (Z @ R.T)  # rotate back to original coords: if z in rot coords, x = m + R z\n                    candidates.extend(list(Xg))\n\n            # 3) surrogate-derived step (cheap diagonal quadratic) if enough archive\n            surrogate_added = False\n            if len(candidates) < lam_iter and len(f_hist) >= max(8, self.dim + 2):\n                n_fit = min(len(X_hist), archive_capacity)\n                X_fit = np.asarray(X_hist[-n_fit:])\n                f_fit = np.asarray(f_hist[-n_fit:])\n                # center around current m\n                D = X_fit - m  # (n_fit, dim)\n                # Approximate f(x) ~ f_c + g^T d + 0.5 * sum h_i d_i^2 (diagonal Hessian)\n                # Build feature matrix: [d_1 ... d_n, 0.5*d_1^2 ... 0.5*d_n^2]\n                F = np.hstack([D, 0.5 * (D ** 2)])\n                # target y = f - f_center (use nearest archived point to m for stability)\n                dists = np.sum((X_fit - m) ** 2, axis=1)\n                idxc = int(np.argmin(dists))\n                f_center = f_fit[idxc]\n                y = f_fit - f_center\n                # ridge solve\n                reg = 1e-6 + 1e-3 * np.var(y)  # small adaptive ridge\n                try:\n                    # Solve (F^T F + reg I) w = F^T y\n                    A = F.T @ F + reg * np.eye(F.shape[1])\n                    rhs = F.T @ y\n                    w = np.linalg.solve(A, rhs)\n                    g = w[:self.dim]\n                    h_diag = w[self.dim:]\n                    # safeguard h_diag: ensure positive curvature estimate\n                    h_diag = np.maximum(h_diag, 1e-6)\n                    # proposed minimizer in rotated coords: d* = -g / h_diag (coordinate-wise)\n                    d_star = - g / h_diag\n                    # limit step length in rotated coordinates to a multiple of mean sigma\n                    max_trust = 5.0 * np.mean(sigma_rot)\n                    norm_d = np.linalg.norm(d_star)\n                    if norm_d > 0:\n                        if norm_d > max_trust:\n                            d_star = d_star * (max_trust / norm_d)\n                        cand = m + d_star  # note: g and h were computed in original coordinates (since D is in original coords)\n                        candidates.append(cand)\n                        surrogate_added = True\n                except np.linalg.LinAlgError:\n                    surrogate_added = False\n\n            # 4) reflection/extrapolation: reflect last successful step if any\n            if len(success_step_memory) > 0 and len(candidates) < lam_iter:\n                # take the most recent successful normalized step in rotated coords\n                s_recent = success_step_memory[-1]\n                # transform back to original coords and reflect\n                step_orig = R.dot(s_recent * sigma_rot)  # s_recent scaled by sigma in rotated coords\n                # reflection magnitude randomize\n                alpha = 0.9 + 0.6 * rng.rand()\n                cand = m - alpha * step_orig\n                candidates.append(cand)\n\n            # fill remaining with small uniform jitter around m\n            while len(candidates) < lam_iter:\n                box = np.clip(0.5 * np.mean(sigma_rot), 1e-12, np.max(bounds_scale))\n                cand = m + rng.uniform(-box, box, size=self.dim)\n                candidates.append(cand)\n\n            # clip candidates to bounds\n            Xcand = np.asarray(candidates[:lam_iter])\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate sequentially (do not exceed budget)\n            fc = np.full(Xcand.shape[0], np.inf, dtype=float)\n            local_best_idx = None\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                xi = Xcand[i]\n                fi = func(xi)\n                fc[i] = float(fi)\n                evals += 1\n                # update global best\n                if fi < f_best:\n                    f_best = float(fi)\n                    x_best = xi.copy()\n                    stagn_iters = 0\n                # track local best\n                if (local_best_idx is None) or (fi < fc[local_best_idx]):\n                    local_best_idx = i\n\n            # add to archive (trim)\n            for xi, fi in zip(Xcand[:len(fc)], fc[:len(Xcand)]):\n                X_hist.append(xi.copy())\n                f_hist.append(float(fi))\n            if len(X_hist) > archive_capacity:\n                excess = len(X_hist) - archive_capacity\n                X_hist = X_hist[excess:]\n                f_hist = f_hist[excess:]\n\n            # determine generation best\n            if local_best_idx is None:\n                # no evaluations (budget exhausted)\n                break\n            gen_best_idx = int(local_best_idx)\n            gen_best_x = Xcand[gen_best_idx].copy()\n            gen_best_f = float(fc[gen_best_idx])\n\n            # estimate current center value f(m) from nearest archive point\n            if len(X_hist) > 0:\n                Xh = np.asarray(X_hist)\n                dists_m = np.sum((Xh - m) ** 2, axis=1)\n                idx0 = int(np.argmin(dists_m))\n                f_m_approx = float(f_hist[idx0])\n            else:\n                f_m_approx = f_best\n\n            improved = gen_best_f < f_m_approx - 1e-12\n\n            # compute step taken (in original coordinates)\n            step = gen_best_x - m\n            # transform step to rotated coordinates\n            try:\n                step_rot = R.T.dot(step)\n            except Exception:\n                step_rot = step.copy()\n\n            # update sigma per-direction depending on whether directional component yielded improvement\n            # We interpret success for direction k if absolute component along rotated axis k contributed\n            # Use soft update: increase sigma where |step_rot[k]| > 0.5*sigma_rot[k], else shrink slightly\n            if improved:\n                # accept center to new candidate with momentum\n                m_new = gen_best_x.copy()\n                # per-dim sigma update\n                for k in range(self.dim):\n                    if abs(step_rot[k]) > 0.5 * sigma_rot[k]:\n                        sigma_rot[k] *= self.eta_plus\n                    else:\n                        sigma_rot[k] *= 0.98  # small decay when not used\n                stagn_iters = 0\n                # record normalized successful step in rotated coords\n                normed = np.zeros(self.dim)\n                denom = sigma_rot + 1e-20\n                normed[:] = step_rot / denom\n                success_step_memory.append(normed)\n                if len(success_step_memory) > success_memory_capacity:\n                    success_step_memory.pop(0)\n            else:\n                # failed: shrink all sigma moderately\n                sigma_rot *= self.eta_minus\n                m_new = 0.9 * m + 0.1 * gen_best_x  # small soft move toward best candidate\n                stagn_iters += 1\n\n            # enforce sigma bounds and max cap relative to bounds\n            sigma_rot = np.clip(sigma_rot, self.min_sigma, self.max_sigma_factor * mean_range)\n\n            # update rotation R periodically using SVD on recent normalized successful steps\n            if (iter_count % self.rotation_update_every == 0) and (len(success_step_memory) >= min(2, self.dim)):\n                Smat = np.vstack(success_step_memory[-min(len(success_step_memory), self.dim*2):])  # (k, dim)\n                try:\n                    # compute principal directions via SVD of Smat^T\n                    U, svals, Vt = np.linalg.svd(Smat.T, full_matrices=False)\n                    # choose new R as U (principal directions)\n                    if U.shape[1] >= self.dim:\n                        R = orthonormalize(U[:, :self.dim])\n                    else:\n                        # pad with random orthonormal columns\n                        pad = orthonormalize(np.random.randn(self.dim, self.dim))\n                        R = orthonormalize(np.hstack([U, pad[:, :self.dim - U.shape[1]]]))\n                except np.linalg.LinAlgError:\n                    # keep previous R\n                    pass\n\n            # update evolution path (momentum) in original coords\n            p = 0.9 * p + 0.1 * (m_new - m)\n\n            # finalize center\n            m = np.minimum(np.maximum(m_new, lb), ub)\n\n            # map sigma_rot back to sigma in original frame: keep sigma stored in rotated coords,\n            # but to keep interpretation consistent across R updates we transform to original coords via multiplication\n            # A simple consistent policy: keep sigma in rotated coords (sigma_rot) and store; that's fine as R tracks rotation\n            sigma = sigma_rot.copy()\n\n            # opportunistic restart if stagnation or collapse\n            if (stagn_iters >= stagn_limit) or (np.all(sigma <= self.min_sigma * 10)):\n                stagn_iters = 0\n                # reinitialize around best found with jitter proportional to mean_range\n                jitter = 0.2 * mean_range\n                m = x_best + jitter * rng.randn(self.dim)\n                m = np.minimum(np.maximum(m, lb), ub)\n                sigma = np.full(self.dim, self.sigma_init_frac * mean_range)\n                R = np.eye(self.dim)\n                success_step_memory = []\n                p = np.zeros(self.dim)\n                # slightly reduce population if budget small\n                if self.budget < 200:\n                    lam = max(4, lam // 2)\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MSARS scored 0.547 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "7956008c-efb9-4476-b683-ba91bcce8d93", "operator": null, "metadata": {"aucs": [0.17802041629171916, 0.1556187962195561, 0.9687334850061341, 0.9837463269491517, 0.2736595458219624, 0.9859218611041003, 0.28702979016408936, 0.533666025171528, 0.9333390370070233, 0.16606968582732518]}, "task_prompt": ""}
{"id": "740ae81a-5276-41b7-a326-d5bbf61ba873", "fitness": 0.15615344124504998, "name": "DEDHS", "description": "This is a hybrid, population-based heuristic that mixes directional eigenvector moves, differential recombination, harmony-style component mixing and occasional heavy‑tailed Lévy jumps to balance exploitation and exploration. Directional proposals use eigenvectors of a learned covariance scaled by rho and eigenvalues; differential steps (diff_scale=0.8) pull from an elite/harmony pool while harmony_rate=0.6 drives frequent component-wise reuse; levy_prob≈0.12 injects rare large jumps to escape basins. Adaptation is conservative: a small covariance learning rate (cov_lr=0.12) blends an exponential-weighted outer-product estimate with an isotropic prior and adds a directional outer product on success, while the trust radius rho is adjusted slowly based on recent success_rate over a success_window (20) rather than immediate success/ failure toggles; the center m is robustly estimated by median/trimmed-mean of top μ. Practical choices favor robustness and diversity: initial covariance is relatively large (bounds/5), rho_init_frac=0.2, an archive and harmony memory keep top distinct solutions, lambda is kept moderate, and an opportunistic restart with jitter resets search if stagnation or tiny rho occurs.", "code": "import numpy as np\n\nclass DEDHS:\n    \"\"\"\n    Directional Ensemble Differential-Harmony Search (DEDHS)\n\n    Main idea (one-line): Combine directional eigenvector moves, differential recombination\n    between elites, harmony-style component mixing, occasional Lévy jumps, and a conservative\n    covariance learner with alternative adaptation equations to explore and exploit.\n\n    Main algorithm parameters (tunable):\n      - budget, dim: required.\n      - pop_factor: base population size scaling factor (used to derive lambda).\n      - cov_lr: covariance learning rate (smaller than ADES's ~0.22, e.g. 0.12).\n      - rho_init_frac: initial trust radius (fraction of bound range).\n      - rho_shrink, rho_expand: trust-radius multiplicative adaptation factors (different eqns).\n      - success_window: window length to compute recent success rate for adaptive rho control.\n      - archive_factor: how many points to keep for local regression/cov updates (~factor * dim).\n      - levy_prob: probability of using a heavy-tailed (Lévy) jump for diversity.\n      - harmony_rate: probability of taking a component from the harmony memory when building a candidate.\n      - diff_scale: scale for differential steps when combining elites (like DE/rand/1 but used sparingly).\n      - seed: RNG seed.\n\n    Differences vs provided ADES:\n      - Different cov_lr (smaller), different rho adaptation logic (based on recent success rate),\n        different covariance blending formula, explicit harmony memory mixing, differential recombination,\n        and occasional Lévy jumps (heavy tails) for escaping basins.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_factor=4,\n                 cov_lr=0.12,\n                 rho_init_frac=0.2,\n                 rho_shrink=0.5,\n                 rho_expand=1.5,\n                 success_window=20,\n                 archive_factor=5,\n                 levy_prob=0.12,\n                 harmony_rate=0.6,\n                 diff_scale=0.8,\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_factor = int(pop_factor)\n        self.cov_lr = float(cov_lr)\n        self.rho_init_frac = float(rho_init_frac)\n        self.rho_shrink = float(rho_shrink)\n        self.rho_expand = float(rho_expand)\n        self.success_window = int(success_window)\n        self.archive_factor = int(archive_factor)\n        self.levy_prob = float(levy_prob)\n        self.harmony_rate = float(harmony_rate)\n        self.diff_scale = float(diff_scale)\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds handling\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        max_bound = np.max(bounds_scale)\n        mean_range = np.mean(bounds_scale)\n\n        # population size (lambda) derived differently from ADES\n        lambda_ = max(6, int(self.pop_factor + 2 * np.log(max(2, self.dim))))\n        lambda_ = min(lambda_, max(2, self.budget))\n\n        # bookkeeping\n        evals = 0\n        archive_capacity = max(self.dim * self.archive_factor, 4 * self.dim, 20)\n\n        # initial sampling: small Latin-hypercube-like spread via uniform\n        init_batch = min(lambda_ * 2, max(2, self.budget // 30), self.budget)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # harmony memory: keep top 'H' solutions (component-wise mixing source)\n        H = max(4, min(12, lambda_))\n        order0 = np.argsort(f0)\n        harmony = [X0[i].copy() for i in order0[:H]]\n\n        # center m: median of harmony members (robust)\n        m = np.median(np.vstack(harmony), axis=0)\n\n        # trust radius and initial covariance (different scale)\n        rho = float(self.rho_init_frac * mean_range)\n        rho = max(rho, 1e-8)\n        # initial covariance: slightly larger variance than ADES to encourage exploration\n        C = np.diag(((bounds_scale / 5.0) ** 2).clip(min=1e-12))\n\n        # archive lists for regression and covariance smoothing\n        X_hist = list(X0)\n        f_hist = list(f0)\n\n        # success tracking for adaptive rho control\n        recent_success = []\n        iter_count = 0\n\n        # helper for SPD Cholesky-like factor\n        def chol_spd(mat):\n            eps = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        # small function to generate a Lévy step (Mantegna's algorithm simplified)\n        def levy_step(dim, beta=1.5):\n            # symmetric alpha-stable approximation: use heavy-tailed Cauchy-like sampling\n            # we'll use a scaled t-distribution with df related to beta for simplicity\n            # using numpy standard Cauchy for heavy tail (beta ~1) and mixing with normal for smoother tails\n            u = rng.standard_cauchy(size=dim)\n            # clamp extreme values\n            u = np.clip(u, -1e6, 1e6)\n            return u\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam = min(lambda_, remaining)\n            mu = max(1, lam // 3)  # use smaller mu than ADES (more selective)\n\n            # compute eigen-decomposition of C for directional proposals\n            try:\n                vals, vecs = np.linalg.eigh(C)\n            except np.linalg.LinAlgError:\n                vals = np.ones(self.dim)\n                vecs = np.eye(self.dim)\n            idxs = np.argsort(-vals)\n            vals = vals[idxs]\n            vecs = vecs[:, idxs]\n            avg_eig = np.mean(vals)\n\n            candidates = []\n\n            # 1) directional eigen proposals but use a different amplitude rule:\n            # amplitude scales with sqrt(eig) * rho * (1 + uniform(0,0.8)) and a nonlinear damp\n            n_dir = min(max(1, lam // 4), self.dim)\n            for k in range(n_dir):\n                v = vecs[:, k]\n                eig_scale = np.sqrt(max(vals[k], 1e-12))\n                amp = rho * eig_scale / (np.sqrt(avg_eig) + 1e-12)\n                amp *= (1.0 + 0.8 * rng.rand()) * (1.0 / (1.0 + 0.1 * k))  # damp by direction index\n                # both signs\n                candidates.append(m + amp * v)\n                if len(candidates) >= lam:\n                    break\n                candidates.append(m - amp * v)\n                if len(candidates) >= lam:\n                    break\n\n            # 2) differential recombination between random elite pairs (DE-inspired)\n            # choose from harmony/top archive if available\n            elite_pool = np.asarray(harmony + X_hist[-max(len(harmony), mu):])  # may include duplicates\n            if elite_pool.shape[0] >= 3 and len(candidates) < lam:\n                n_diff = min(lam - len(candidates), max(1, (lam // 6)))\n                for _ in range(n_diff):\n                    # pick three distinct indices\n                    idxs_r = rng.choice(elite_pool.shape[0], size=3, replace=False)\n                    x1, x2, x3 = elite_pool[idxs_r]\n                    diff = x2 - x3\n                    cand = x1 + self.diff_scale * diff\n                    # occasionally mix with harmony (component-wise)\n                    if rng.rand() < self.harmony_rate and len(harmony) > 0:\n                        h = harmony[rng.randint(len(harmony))]\n                        mask = rng.rand(self.dim) < 0.5\n                        cand[mask] = h[mask]\n                    candidates.append(cand)\n                    if len(candidates) >= lam:\n                        break\n\n            # 3) Gaussian proposals using C scaled to rho (like ADES) but fewer\n            if len(candidates) < lam:\n                A = chol_spd(C)\n                n_gauss = lam - len(candidates)\n                if n_gauss > 0:\n                    Z = rng.normal(size=(n_gauss, self.dim))\n                    Y = Z @ (A.T)\n                    Xg = m + rho * 0.9 * Y  # slightly attenuated\n                    candidates.extend(list(Xg))\n\n            # 4) occasional Lévy jumps for exploration\n            if rng.rand() < self.levy_prob and len(candidates) < lam:\n                lev = levy_step(self.dim)\n                scale = rho * (1.0 + rng.rand())\n                cand = m + scale * lev / (np.mean(np.abs(lev)) + 1e-12)\n                candidates.append(cand)\n\n            # 5) fill remaining slots with component-wise harmony mixing + jitter\n            while len(candidates) < lam:\n                # build candidate by taking vector from m then replace components from harmony with prob harmony_rate\n                cand = m.copy()\n                if len(harmony) > 0 and rng.rand() < self.harmony_rate:\n                    h = harmony[rng.randint(len(harmony))]\n                    mask = rng.rand(self.dim) < 0.5\n                    cand[mask] = h[mask]\n                # small uniform jitter scaled by rho\n                cand += rng.uniform(-0.4 * rho, 0.4 * rho, size=self.dim)\n                candidates.append(cand)\n\n            # clip candidates to bounds\n            Xcand = np.asarray(candidates[:lam])\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates one-by-one respecting budget\n            fc = np.empty(Xcand.shape[0], dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    fc[i:] = np.inf\n                    break\n                xi = Xcand[i]\n                fi = func(xi)\n                fc[i] = fi\n                evals += 1\n                # update global best immediately\n                if fi < f_best:\n                    f_best = float(fi)\n                    x_best = xi.copy()\n                    # update harmony memory: insert and evict worst\n                    harmony.append(xi.copy())\n                    # keep harmony unique-ish: sort by value later\n                # loop continues\n\n            # store evaluated points to archive\n            for xi, fi in zip(Xcand, fc):\n                X_hist.append(xi.copy())\n                f_hist.append(float(fi))\n            if len(X_hist) > archive_capacity:\n                excess = len(X_hist) - archive_capacity\n                X_hist = X_hist[excess:]\n                f_hist = f_hist[excess:]\n\n            # update harmony memory: keep top H distinct solutions from archive + recent\n            combined_idx = np.argsort(f_hist)\n            new_harmony = []\n            seen = []\n            for idx in combined_idx:\n                xcand = X_hist[idx]\n                # simple distinctness check\n                key = tuple(np.round(xcand, 8))\n                if key in seen:\n                    continue\n                seen.append(key)\n                new_harmony.append(xcand.copy())\n                if len(new_harmony) >= H:\n                    break\n            harmony = new_harmony\n\n            # determine generation best and compare to center m: approximate f(m) by nearest archive point\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            if len(X_hist) > 0:\n                Xh = np.asarray(X_hist)\n                dists = np.sum((Xh - m)**2, axis=1)\n                idx0 = int(np.argmin(dists))\n                f_m_approx = float(f_hist[idx0])\n            else:\n                f_m_approx = f_best\n\n            improved_center = gen_best_f < f_m_approx - 1e-12\n\n            # recompute new center: use weighted median-like recombination of top mu (robust)\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            # robust center: coordinate-wise trimmed mean (drop extremes)\n            trim = max(0, min(mu//4, (mu-1)//2))\n            if mu - 2*trim >= 1:\n                m_new = np.empty(self.dim)\n                for d in range(self.dim):\n                    col = np.sort(X_mu[:, d])\n                    if trim > 0:\n                        col = col[trim:-trim]\n                    m_new[d] = np.mean(col)\n            else:\n                m_new = np.mean(X_mu, axis=0)\n\n            # normalized deltas for covariance update (w.r.t. rho) but use exponentially weighted outer product\n            deltas = (X_mu - m) / (rho + 1e-20)\n            # compute weighted covariance with exponential emphasis: weight_j ∝ exp(-rank_j / (mu/2))\n            ranks = np.arange(1, mu + 1)\n            w = np.exp(- (ranks - 1) / (max(1, mu/2.0)))\n            w = w / np.sum(w)\n            W = w.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas\n\n            # covariance update: different blending equation (conservative)\n            # C <- (1 - alpha) * C + alpha * (weighted_cov * s + gamma * isotrope)\n            alpha = self.cov_lr\n            s = 0.9 if improved_center else 0.5\n            gamma_iso = np.diag(((bounds_scale / 10.0) ** 2).clip(min=1e-12))\n            C = (1.0 - alpha) * C + alpha * (s * weighted_cov + (1.0 - s) * gamma_iso)\n\n            # directional augmentation: if improved, nudge C toward successful direction outer product\n            if improved_center:\n                successful_step = (gen_best_x - m) / (rho + 1e-20)\n                dir_cov = np.outer(successful_step, successful_step)\n                C += 0.5 * alpha * dir_cov  # additive term (different eqn than ADES)\n\n            # rho adaptation based on recent success rate (instead of immediate expand/shrink)\n            recent_success.append(1 if improved_center else 0)\n            if len(recent_success) > self.success_window:\n                recent_success.pop(0)\n            success_rate = float(np.sum(recent_success)) / max(1, len(recent_success))\n            # if success rate sufficiently high, expand; if low, shrink more aggressively\n            if success_rate > 0.4:\n                rho = min(2.0 * max_bound, rho * (1.0 + 0.2 * (success_rate - 0.4) / 0.6) * self.rho_expand)\n            elif success_rate < 0.15:\n                rho = max(1e-9 * max_bound, rho * (self.rho_shrink ** (0.5 + (0.15 - success_rate) * 2.0)))\n            # also gently move center toward m_new (soft acceptance)\n            if improved_center:\n                m = 0.9 * m + 0.1 * m_new\n            else:\n                m = 0.7 * m + 0.3 * m_new\n\n            # clamp center\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # numerical safeguards for C: symmetry and eigen clipping\n            C = 0.5 * (C + C.T)\n            valsC, vecsC = np.linalg.eigh(C)\n            min_eig = 1e-14 * (mean_range**2 + 1.0)\n            valsC = np.clip(valsC, min_eig, None)\n            C = (vecsC * valsC) @ vecsC.T\n\n            # opportunistic restart if rho extremely small or no success for long time\n            if rho <= 1e-12 * max_bound or (len(recent_success) >= self.success_window and sum(recent_success) == 0):\n                # reinitialize around global best with larger jitter than ADES to escape\n                jitter = max(0.5 * rho, 0.05 * mean_range)\n                m = x_best + jitter * rng.randn(self.dim)\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((bounds_scale / 5.0) ** 2).clip(min=1e-12))\n                rho = max(self.rho_init_frac * mean_range * 0.7, 1e-8)\n                recent_success = []\n                # shrink lambda_ slightly if budget small\n                if self.budget < 200:\n                    lambda_ = max(4, lambda_ // 2)\n                continue\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DEDHS scored 0.156 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "7956008c-efb9-4476-b683-ba91bcce8d93", "operator": null, "metadata": {"aucs": [0.07740513282271144, 0.15238791931863171, 0.2085426054081092, 0.1526425353816393, 0.16850214789968732, 0.16702080134077624, 0.19193490552303205, 0.1490721624216076, 0.1649573503749231, 0.129068851959382]}, "task_prompt": ""}
{"id": "d09accc3-b2b7-44fc-a809-d2324562f324", "fitness": "-inf", "name": "ARSQN", "description": "The ARSQN algorithm centers search around an adaptive center x_c with a trust radius r (initialized as r_init_frac * mean_span and adaptively expanded by r_expand or shrunk by r_shrink on success/failure) and enforces strict budget/bounds handling and opportunistic restarts when stagnation or tiny radius occurs. It generates a mixed ensemble each generation (roughly n_sub ≈ 1/3 of the batch as subspace Gaussian probes, n_lev ≈ 1/6 Lévy long jumps, n_de ≈ 1/4 DE-style donor mutations, a small gradient/quasi‑Newton probe from ridge-regression on an archive, plus antithetic/local jitter to fill the rest) to balance global exploration, directional exploitation, and variance reduction. Online structure learning is used via a low-rank orthonormal basis (incrementally updated by SVD on recent steps) and a light limited‑memory secant store (s,y pairs with an L-BFGS-like two-loop apply_inverse_h) to propose quasi-Newton directions. The algorithm maintains an archive (capacity = max(20, archive_factor*dim)) for surrogate gradient estimation and DE donors, uses mirrored sampling and rank-based weighted recombination for center updates, and performs QR reorthonormalization and numeric safeguards to keep subspace and secant information stable.", "code": "import numpy as np\n\nclass ARSQN:\n    \"\"\"\n    Adaptive Random Subspace Quasi-Newton (ARSQN)\n\n    Main ideas (novel combination):\n      - Maintain a center x_c, an adaptive trust radius r, a small archive and a low-rank subspace\n        spanned by recent successful steps for efficient directional search.\n      - Generate a mixed ensemble each iteration from:\n         * subspace-projected Gaussian steps (low-rank directions learned online),\n         * Lévy flights for occasional long jumps (Mantegna),\n         * differential-evolution style donor mutations using archive points,\n         * a surrogate linear-gradient exploitation step (ridge regression),\n         * antithetic/mirrored samples for variance reduction and local jitter.\n      - Light limited-memory secant updates (like an L-BFGS-ish two-loop but using secant y approximations\n        from objective differences) to propose quasi-Newton directions when possible.\n      - Trust-radius adaptation (expand on success, shrink on failure), archive-guided restarts,\n        and strict budget accounting.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, pop_base=None, archive_factor=8,\n                 r_init_frac=0.25, r_shrink=0.6, r_expand=1.3,\n                 max_lmem=10, levy_beta=1.5, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.archive_factor = int(archive_factor)\n        self.r_init_frac = float(r_init_frac)\n        self.r_shrink = float(r_shrink)\n        self.r_expand = float(r_expand)\n        self.max_lmem = int(max_lmem)  # memory for secant pairs\n        self.levy_beta = float(levy_beta)\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n\n        # quick checks\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        mean_span = np.mean(span)\n        max_span = np.max(span)\n\n        # population size\n        if self.pop_base is None:\n            pop = max(6, int(4 + 2.5 * np.log(max(2, self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        # archive capacity\n        archive_capacity = max(20, self.archive_factor * self.dim)\n\n        # initial batch (small)\n        init_batch = min(pop * 2, max(4, self.budget // 20))\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.empty(init_batch, dtype=float)\n        evals = 0\n        for i in range(init_batch):\n            if evals >= self.budget:\n                f0[i:] = np.inf\n                break\n            f0[i] = func(X0[i])\n            evals += 1\n\n        best_idx = int(np.argmin(f0))\n        x_best = X0[best_idx].copy()\n        f_best = float(f0[best_idx])\n\n        # initial center: weighted average of top quarter\n        mu0 = max(1, init_batch // 4)\n        inds = np.argsort(f0)[:mu0]\n        weights = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        weights = np.maximum(weights, 0.0)\n        weights = weights / np.sum(weights)\n        x_c = (weights.reshape(-1, 1) * X0[inds]).sum(axis=0)\n\n        # trust radius\n        r = max(1e-8, self.r_init_frac * mean_span)\n\n        # low-rank basis for subspace exploration (columns orthonormal)\n        subspace_k = min(self.dim, max(1, int(np.sqrt(self.dim) + 1)))\n        basis = np.eye(self.dim)[:, :subspace_k].copy()  # start with coordinate directions\n\n        # limited memory secant storage: lists of s,y pairs\n        s_list = []\n        y_list = []\n\n        # archive\n        X_hist = [x.copy() for x in X0[:init_batch]]\n        f_hist = [float(fi) for fi in f0[:init_batch]]\n\n        # counters for stagnation\n        stagn = 0\n        stagn_limit = max(10, int(0.02 * self.budget))\n\n        # helper: levy step (Mantegna)\n        def levy_step(shape=()):\n            beta = max(0.5, min(2.0, self.levy_beta))\n            # Mantegna's algorithm\n            sigma_u = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                       (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n            u = rng.normal(0, sigma_u, size=shape)\n            v = rng.normal(0, 1.0, size=shape)\n            step = u / (np.abs(v) ** (1.0 / beta) + 1e-20)\n            return step\n\n        # helper: two-loop L-BFGS-like application (approx inverse-H to a vector)\n        def apply_inverse_h(v):\n            # If no memory, return v scaled\n            m = len(s_list)\n            if m == 0:\n                return v\n            alphas = []\n            q = v.copy()\n            rho = []\n            for i in range(m - 1, -1, -1):\n                s = s_list[i]\n                y = y_list[i]\n                sy = np.dot(s, y)\n                if sy <= 1e-12:\n                    alphas.append(0.0)\n                    rho.append(1e12)\n                    continue\n                rh = 1.0 / sy\n                rho.append(rh)\n                alpha = rh * np.dot(s, q)\n                alphas.append(alpha)\n                q = q - alpha * y\n            # initial H0 scalar\n            y_last = y_list[-1]\n            s_last = s_list[-1]\n            yy = np.dot(y_last, y_last)\n            if yy > 1e-12:\n                H0 = np.dot(s_last, y_last) / yy\n            else:\n                H0 = 1.0\n            z = H0 * q\n            # second loop\n            for i in range(m):\n                s = s_list[i]\n                y = y_list[i]\n                rh = rho[m - 1 - i]\n                alpha = alphas[m - 1 - i]\n                beta = rh * np.dot(y, z)\n                z = z + s * (alpha - beta)\n            return z\n\n        # ridge regression gradient estimation\n        def estimate_grad_from_archive(center, n_fit=None):\n            if len(X_hist) < max(6, self.dim + 2):\n                return None\n            n_fit = min(len(X_hist), archive_capacity) if n_fit is None else min(len(X_hist), n_fit)\n            Xf = np.asarray(X_hist[-n_fit:])\n            ff = np.asarray(f_hist[-n_fit:])\n            Xc = Xf - center  # center coordinates\n            # target is f - f_center; approximate f_center with nearest archive point\n            dists = np.sum((Xf - center) ** 2, axis=1)\n            idx = int(np.argmin(dists))\n            f_center = ff[idx]\n            y = ff - f_center\n            lam = 1e-6 * (1.0 + np.var(y))\n            XT_X = Xc.T @ Xc\n            try:\n                beta = np.linalg.solve(XT_X + lam * np.eye(self.dim), Xc.T @ y)\n                # beta is approximate gradient (f change per unit in coordinates)\n                return beta\n            except np.linalg.LinAlgError:\n                return None\n\n        # main loop\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam = min(pop, remaining)\n            # ensemble composition heuristics\n            n_sub = max(1, lam // 3)\n            n_lev = max(0, lam // 6)\n            n_de = max(0, lam // 4)\n            n_grad = 1 if (len(X_hist) >= max(6, self.dim + 2) and lam > 2) else 0\n            # rest local jitter\n            n_local = lam - (n_sub + n_lev + n_de + n_grad)\n            if n_local < 0:\n                n_local = 0\n\n            cand_list = []\n\n            # 1) Subspace Gaussian probes using current basis\n            # Sample coefficients in low-dim subspace, then lift\n            for _ in range(n_sub):\n                coefs = rng.normal(scale=1.0, size=basis.shape[1])\n                step = basis @ coefs\n                # scale by r and by adaptive per-dim scale\n                step = step / (np.linalg.norm(step) + 1e-12) * (r * (0.6 + 0.8 * rng.rand()))\n                cand = x_c + step\n                cand_list.append(cand)\n\n            # 2) Lévy flights (occasional long jumps)\n            for _ in range(n_lev):\n                v = levy_step(shape=(self.dim,))\n                v = v / (np.linalg.norm(v) + 1e-12)\n                scale = r * (2.0 + 6.0 * rng.rand())  # potentially much larger than r\n                cand = x_c + scale * v\n                cand_list.append(cand)\n\n            # 3) Differential-Evolution style donors from archive\n            # donor = a + F*(b-c), then crossover with center\n            for _ in range(n_de):\n                if len(X_hist) >= 3:\n                    a, b, c = rng.choice(len(X_hist), size=3, replace=False)\n                    a = np.asarray(X_hist[a])\n                    b = np.asarray(X_hist[b])\n                    c = np.asarray(X_hist[c])\n                    F = 0.5 + 0.5 * rng.rand()  # adaptive-ish\n                    donor = a + F * (b - c)\n                    # binomial crossover with center\n                    mask = rng.rand(self.dim) < (0.2 + 0.6 * rng.rand())\n                    trial = x_c.copy()\n                    trial[mask] = donor[mask]\n                    # small local scaling\n                    trial = trial + rng.normal(scale=0.05 * r, size=self.dim)\n                    cand_list.append(trial)\n                else:\n                    # fallback to local\n                    cand_list.append(x_c + rng.normal(scale=0.5 * r, size=self.dim))\n\n            # 4) gradient exploitation using linear surrogate (if possible)\n            grad_est = None\n            if n_grad:\n                g = estimate_grad_from_archive(x_c)\n                if g is not None:\n                    grad_est = g\n                    # quasi-Newton propose: use apply_inverse_h to get direction\n                    qn_dir = -apply_inverse_h(g)\n                    if np.linalg.norm(qn_dir) > 1e-12:\n                        # scale to trust radius\n                        cand = x_c + (r * (0.6 + 0.6 * rng.rand())) * (qn_dir / (np.linalg.norm(qn_dir) + 1e-12))\n                        cand_list.append(cand)\n                    else:\n                        # simple gradient step\n                        cand_list.append(x_c - (r * 0.5) * (g / (np.linalg.norm(g) + 1e-12)))\n\n            # 5) local jitter and antithetic pairs to fill up\n            while len(cand_list) < lam:\n                z = rng.normal(size=self.dim)\n                step = z / (np.linalg.norm(z) + 1e-12) * r * (0.2 + 0.8 * rng.rand())\n                cand_list.append(x_c + step)\n                if len(cand_list) < lam:\n                    cand_list.append(x_c - step)  # mirrored sample\n\n            # finalize candidate array, clip to bounds\n            Xcand = np.asarray(cand_list[:lam])\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # Evaluate candidates sequentially, update best on the fly\n            fc = np.full(Xcand.shape[0], np.inf, dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                xi = Xcand[i]\n                fi = func(xi)\n                fc[i] = float(fi)\n                evals += 1\n                # update global best\n                if fi < f_best:\n                    f_best = float(fi)\n                    x_best = xi.copy()\n                    stagn = 0\n\n            # push evaluated cand to archive (trim)\n            for xi, fi in zip(Xcand, fc):\n                X_hist.append(xi.copy())\n                f_hist.append(float(fi))\n            if len(X_hist) > archive_capacity:\n                excess = len(X_hist) - archive_capacity\n                X_hist = X_hist[excess:]\n                f_hist = f_hist[excess:]\n\n            # determine generation best\n            valid_idx = np.where(np.isfinite(fc))[0]\n            if valid_idx.size == 0:\n                break\n            gi = int(valid_idx[np.argmin(fc[valid_idx])])\n            gen_best_x = Xcand[gi].copy()\n            gen_best_f = float(fc[gi])\n\n            # estimate f at center by nearest archive\n            Xh = np.asarray(X_hist)\n            dists = np.sum((Xh - x_c) ** 2, axis=1)\n            idx0 = int(np.argmin(dists))\n            f_center = float(f_hist[idx0])\n\n            # decide acceptance: require improvement by tiny absolute amount to avoid noise acceptance\n            eps_improve = 1e-12\n            improved = gen_best_f < f_center - eps_improve\n\n            # recompute new center as weighted recombination of top half of candidates (sorted by fc)\n            ordc = np.argsort(fc)\n            mu = max(1, len(ordc) // 2)\n            topX = Xcand[ordc[:mu]]\n            # weights: exponential ranks\n            ranks = np.arange(1, mu + 1)\n            w = np.exp(-0.5 * (ranks - 1))\n            w = w / np.sum(w)\n            x_new = (w.reshape(-1, 1) * topX).sum(axis=0)\n\n            # update trust radius and center\n            if improved:\n                # accept and expand radius\n                s = x_new - x_c\n                x_c = x_new.copy()\n                r = min(2.0 * max_span, r * self.r_expand)\n                stagn = 0\n\n                # form secant pair: approximate y using secant-slope along s\n                # y ≈ (f(x_new) - f_center) / ||s||^2 * s  (a scalar curvature times s)\n                snorm2 = np.dot(s, s)\n                if snorm2 > 1e-14:\n                    ypos = (gen_best_f - f_center) / (snorm2 + 1e-20)\n                    y = ypos * s\n                    # store s,y\n                    if np.linalg.norm(y) > 1e-16:\n                        s_list.append(s.copy())\n                        y_list.append(y.copy())\n                        if len(s_list) > self.max_lmem:\n                            s_list.pop(0)\n                            y_list.pop(0)\n                # update low-rank basis using recent step history (simple incremental PCA on scaled steps)\n                # collect last K steps\n                K = min(50, len(X_hist) - 1)\n                if K >= 2:\n                    steps = np.asarray(X_hist[-K:]) - np.asarray(X_hist[-K - 1:-1]) if len(X_hist) > K else np.diff(np.asarray(X_hist[-K:]), axis=0)\n                    # fallback if shape mismatch\n                    if steps.size == 0:\n                        steps = np.asarray([s])\n                    S = (steps - steps.mean(axis=0, keepdims=True)).T  # dim x K'\n                    # compute top singular vectors\n                    try:\n                        U, Svals, Vt = np.linalg.svd(S, full_matrices=False)\n                        k = min(subspace_k, U.shape[1])\n                        basis = U[:, :k]\n                    except np.linalg.LinAlgError:\n                        pass\n            else:\n                # no improvement: shrink trust region and soft move towards x_new\n                stagn += 1\n                r = max(1e-10, r * self.r_shrink)\n                # soft acceptance: move small fraction toward recombined center\n                x_c = 0.9 * x_c + 0.1 * x_new\n\n            # clamp center\n            x_c = np.minimum(np.maximum(x_c, lb), ub)\n\n            # numeric safeguards: reorthonormalize basis occasionally\n            if basis.shape[1] > 0:\n                # QR\n                try:\n                    Q, _ = np.linalg.qr(basis)\n                    basis = Q[:, :basis.shape[1]]\n                except np.linalg.LinAlgError:\n                    pass\n\n            # opportunistic restart\n            if stagn >= stagn_limit or r <= 1e-12 * max_span:\n                # reinitialize around best found so far with jitter\n                jitter = 0.2 * mean_span * max(1.0, 0.1 * (stagn / (stagn_limit + 1)))\n                x_c = x_best + rng.normal(scale=jitter, size=self.dim)\n                x_c = np.minimum(np.maximum(x_c, lb), ub)\n                r = max(r, self.r_init_frac * mean_span * 0.5)\n                s_list = []\n                y_list = []\n                # reset basis to random orthonormal subspace\n                randM = rng.normal(size=(self.dim, subspace_k))\n                try:\n                    Q, _ = np.linalg.qr(randM)\n                    basis = Q[:, :subspace_k]\n                except np.linalg.LinAlgError:\n                    basis = np.eye(self.dim)[:, :subspace_k]\n                stagn = 0\n\n        # store and return best found\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "error": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "parent_ids": "7956008c-efb9-4476-b683-ba91bcce8d93", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "a0f993c6-561c-4e3c-bc89-059e8516a8f1", "fitness": 0.19869223648877074, "name": "ALDE", "description": "The algorithm is a mixture-based search that combines eigen-direction proposals (guided by the largest eigenvectors of an online covariance), Gaussian local sampling from a learned covariance, occasional heavy‑tailed Lévy-style jumps (levy_alpha≈1.6, levy_prob≈0.18), a DE-like differential mutation path (diff_prob≈0.25), and small uniform/jitter fills, seeded from a stratified Latin‑hypercube initial batch and a modest, dimension‑aware population. Covariance is learned adaptively via an exponential moving average of normalized outer products (cov_lr≈0.15) with a diagonal shrink toward recent variances and eigenvalue clipping, plus a rank‑1 boost on successful steps to emphasize promising directions. Trust radius rho is multiplicatively expanded on (softly) accepted improvements (rho_expand≈1.5) and shrunk on failures (rho_shrink≈0.85) with a decaying soft‑acceptance probability over the budget, and the center uses robust median/trimmed aggregation of elites. An archive with controlled capacity (archive_factor≈8) supplies differential candidates and nearest‑point f approximations, and the solver opportunistically restarts near the global best if stagnation or excessive contraction occurs.", "code": "import numpy as np\n\nclass ALDE:\n    \"\"\"\n    Adaptive Lévy-Eigen Differential Ensemble (ALDE)\n\n    Main idea (one line): combine eigen-direction proposals, Gaussian local sampling,\n    occasional heavy-tailed Lévy jumps, and differential recombination with an alternative\n    covariance learner and multiplicative radius control.\n\n    Notes and main algorithm parameters (documented here):\n      - budget, dim : required\n      - pop_base : base population size (if None, computed adaptively via dim)\n      - cov_lr : covariance learning rate (exponential blend to running covariance)\n      - rho_init_frac : initial trust radius fraction of bound range (different default)\n      - rho_shrink : multiplicative shrink on unsuccessful iterations (different)\n      - rho_expand : multiplicative expand on successful iterations (different)\n      - levy_alpha : Pareto tail alpha for Lévy-like jumps (lower alpha => heavier tail)\n      - levy_prob : probability to include a Lévy jump candidate\n      - diff_prob : probability to include differential-mutation style candidate\n      - archive_factor : archive size relative to dim (different scaling)\n      - restart_no_improve : number of iterations without improvement before restart\n      - seed : RNG seed\n\n    Differences to ADES:\n      - uses Pareto (Lévy-like) jumps with different scaling rules instead of a single\n        gradient-exploitation step frequency.\n      - covariance update uses exponential moving average of normalized outer products\n        plus a diagonal shrink towards recent variances (different blend coefficients).\n      - radius adaptation uses larger expansion and gentler shrink by default and\n        reduces with a sigmoid-like schedule for stability.\n      - differential-style candidate generator (inspired by DE) is included.\n      - opportunistic acceptance: accept mildly worse centers sometimes (small smoothing)\n        but with a decaying acceptance rate across budget.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 cov_lr=0.15,\n                 rho_init_frac=0.35,\n                 rho_shrink=0.85,\n                 rho_expand=1.5,\n                 levy_alpha=1.6,\n                 levy_prob=0.18,\n                 diff_prob=0.25,\n                 archive_factor=8,\n                 restart_no_improve=None,\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.cov_lr = float(cov_lr)\n        self.rho_init_frac = float(rho_init_frac)\n        self.rho_shrink = float(rho_shrink)\n        self.rho_expand = float(rho_expand)\n        self.levy_alpha = float(levy_alpha)\n        self.levy_prob = float(levy_prob)\n        self.diff_prob = float(diff_prob)\n        self.archive_factor = int(archive_factor)\n        self.seed = seed\n        # default restart threshold: proportional to budget (if None)\n        self.restart_no_improve = (restart_no_improve if restart_no_improve is not None\n                                   else max(10, int(0.02 * self.budget)))\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_range = ub - lb\n        avg_range = float(np.mean(bounds_range))\n        max_range = float(np.max(bounds_range))\n\n        # choose population size differently from ADES\n        if self.pop_base is None:\n            # smaller base but grows mildly with sqrt(dim)\n            lambda_ = max(6, int(6 + 2.2 * np.sqrt(max(1, self.dim))))\n        else:\n            lambda_ = int(self.pop_base)\n        lambda_ = min(lambda_, max(2, self.budget))\n\n        # archive capacity (different scaling)\n        archive_capacity = max(self.archive_factor * self.dim, 20)\n\n        # initial sampling: small Latin-hypercube-like spread via stratified uniform draws\n        init_batch = min(max(4, lambda_ * 2), max(2, self.budget // 30), self.budget)\n        # simple stratified: sample each dim uniformly, then shuffle across points\n        X0 = np.empty((init_batch, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(init_batch)\n            X0[:, d] = lb[d] + (perm + rng.rand(init_batch)) / init_batch * (ub[d] - lb[d])\n        f0 = np.array([func(x) for x in X0])\n        evals = init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize center m as robust average (trimmed mean of top 40%)\n        mu0 = max(1, int(0.4 * init_batch))\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        m = np.median(elites0, axis=0)  # use median to be robust\n\n        # initial rho and covariance (different scale choices)\n        rho = float(max(1e-8, self.rho_init_frac * avg_range))\n        # start with diagonal covariance based on spread of initial elites but shrunk\n        var_init = np.var(X0, axis=0)\n        C = np.diag(( (var_init + 1e-12) * 0.8 ) + 1e-12)\n\n        # running statistics for covariance learning\n        cov_running = C.copy()\n        var_running = np.diag(C).copy()\n\n        # archive history\n        X_hist = [x.copy() for x in X0]\n        f_hist = [float(v) for v in f0]\n\n        # counters\n        no_improve_iters = 0\n        iter_count = 0\n\n        # helpers\n        def ensure_spd(mat):\n            # small jitter if needed\n            try:\n                A = np.linalg.cholesky(mat + 1e-14 * np.eye(self.dim))\n                return mat\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals_clipped = np.clip(vals, 1e-12, None)\n                return (vecs * vals_clipped) @ vecs.T\n\n        def sample_levy(scale, alpha):\n            # heavy-tailed step lengths using Pareto-like tail (shifted)\n            # Draw s ~ 1 + pareto(alpha) so typical moderate plus heavy outliers.\n            s = 1.0 + rng.pareto(alpha)\n            # isotropic direction\n            z = rng.normal(size=self.dim)\n            z /= (np.linalg.norm(z) + 1e-20)\n            return scale * s * z\n\n        # main loop: generate ensembles and update\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam = min(lambda_, remaining)\n            mu = max(1, lam // 2)\n\n            # eigen-decomposition of covariance for directional proposals\n            try:\n                vals, vecs = np.linalg.eigh(C)\n            except np.linalg.LinAlgError:\n                vals = np.ones(self.dim)\n                vecs = np.eye(self.dim)\n            idxs = np.argsort(-vals)\n            vals = vals[idxs]\n            vecs = vecs[:, idxs]\n\n            # generate candidates mixture:\n            candidates = []\n\n            # a) eigen-directed proposals (both signs), but scale uses different weighting\n            n_dir = min(self.dim, max(1, lam // 3))\n            for k in range(n_dir):\n                v = vecs[:, k]\n                eig_scale = np.sqrt(max(vals[k], 1e-12))\n                amp = rho * (0.6 + 1.2 * rng.rand()) * (eig_scale / (np.sqrt(np.mean(vals)) + 1e-12))\n                candidates.append(m + amp * v)\n                if len(candidates) >= lam:\n                    break\n                candidates.append(m - amp * v)\n                if len(candidates) >= lam:\n                    break\n\n            # b) Gaussian local sampling using current C\n            if len(candidates) < lam:\n                try:\n                    L = np.linalg.cholesky(ensure_spd(C))\n                except np.linalg.LinAlgError:\n                    vals_tmp, vecs_tmp = np.linalg.eigh(C)\n                    L = (vecs_tmp * np.sqrt(np.clip(vals_tmp, 1e-12, None))).T\n                n_gauss = max(0, lam - len(candidates) - 2)  # keep room for levy and diff\n                if n_gauss > 0:\n                    Z = rng.normal(size=(n_gauss, self.dim))\n                    Y = Z @ L.T\n                    Xg = m + rho * Y\n                    candidates.extend(list(Xg))\n\n            # c) a Lévy jump candidate with some probability (heavy-tailed exploration)\n            if (len(candidates) < lam) and (rng.rand() < self.levy_prob):\n                # scale relative to bounds and current rho; heavier when no recent improvements\n                scale_factor = rho * (1.0 + 0.4 * (1 + no_improve_iters / (1 + self.restart_no_improve)))\n                cand = m + sample_levy(scale_factor, self.levy_alpha)\n                candidates.append(cand)\n\n            # d) differential mutation style candidate: x_r1 + F*(x_r2 - x_r3)\n            if (len(candidates) < lam) and (len(X_hist) >= 3) and (rng.rand() < self.diff_prob):\n                # pick three distinct archived points\n                idxs = rng.choice(len(X_hist), size=3, replace=False)\n                xr1 = X_hist[idxs[0]]\n                xr2 = X_hist[idxs[1]]\n                xr3 = X_hist[idxs[2]]\n                F = 0.6 + 0.6 * rng.rand()  # mutation factor\n                cand = xr1 + F * (xr2 - xr3)\n                candidates.append(cand)\n\n            # e) fill remaining with localized uniform jitter around current center (small box)\n            while len(candidates) < lam:\n                box = np.clip(0.5 * rho, 1e-12, max_range)\n                cand = m + rng.uniform(-box, box, size=self.dim)\n                candidates.append(cand)\n\n            # clip to bounds and finalize candidate array\n            Xcand = np.asarray(candidates[:lam])\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # Evaluate candidates sequentially (respect budget)\n            fc = np.empty(Xcand.shape[0], dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    fc[i:] = np.inf\n                    break\n                xi = Xcand[i]\n                fv = func(xi)\n                fc[i] = float(fv)\n                evals += 1\n                # update global best if seen\n                if fv < f_best:\n                    f_best = float(fv)\n                    x_best = xi.copy()\n                    no_improve_iters = 0\n            else:\n                # normal completion\n                pass\n\n            # append to archive trimming older ones\n            for xi, fi in zip(Xcand, fc):\n                X_hist.append(xi.copy())\n                f_hist.append(float(fi))\n            if len(X_hist) > archive_capacity:\n                excess = len(X_hist) - archive_capacity\n                X_hist = X_hist[excess:]\n                f_hist = f_hist[excess:]\n\n            # select mu best in this generation\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            f_mu = fc[order[:mu]]\n\n            # compute a robust center estimate from the top performers (median-of-means)\n            m_candidate = np.mean(X_mu, axis=0)\n\n            # approximate f(m) by nearest archive point (as ADES does)\n            Xh = np.asarray(X_hist)\n            dists = np.sum((Xh - m) ** 2, axis=1)\n            idx_closest = int(np.argmin(dists))\n            f_m_approx = float(f_hist[idx_closest]) if len(f_hist) > 0 else f_best\n\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            # success definition: sizable improvement compared to approximate center value\n            improved = gen_best_f < f_m_approx - 1e-12\n\n            # update covariance: use normalized steps but with exponential moving average and diagonal shrink\n            # normalized by rho, using deltas of the selected mu\n            deltas = (X_mu - m) / (rho + 1e-20)  # shape (mu, dim)\n            # compute outer product average\n            S = np.zeros((self.dim, self.dim))\n            for dvec in deltas:\n                S += np.outer(dvec, dvec)\n            S /= max(1, deltas.shape[0])\n\n            # update running variance (diagonal) from recent archive and blend\n            recent = np.asarray(X_hist[-min(len(X_hist), 10 + self.dim):])\n            var_recent = np.var(recent, axis=0) if len(recent) > 1 else var_running\n            var_running = 0.9 * var_running + 0.1 * var_recent\n\n            # blend matrices: favor S on success, otherwise drift slightly towards diagonal\n            if improved:\n                # weight more the directional info, and add a stronger rank-1 boost in successful step direction\n                success_step = (gen_best_x - m) / (rho + 1e-20)\n                rank1 = np.outer(success_step, success_step)\n                cov_running = (1.0 - self.cov_lr) * cov_running + self.cov_lr * (0.8 * S + 0.2 * rank1)\n            else:\n                # conservative: partially move towards diagonal matrix of var_running and keep some previous\n                diag_mat = np.diag(var_running + 1e-12)\n                cov_running = (1.0 - 0.5 * self.cov_lr) * cov_running + (0.5 * self.cov_lr) * (0.6 * S + 0.4 * diag_mat)\n\n            # enforce SPD and reasonable scaling (clip eigenvalues relative to bounds)\n            cov_running = ensure_spd(cov_running)\n            eval_vals, eval_vecs = np.linalg.eigh(cov_running)\n            # clip eigenvalues to avoid collapse or explosion (relative to bounds_range)\n            min_ev = (1e-8 * avg_range) ** 2\n            max_ev = ( (2.0 * max_range) ) ** 2\n            eval_vals = np.clip(eval_vals, min_ev, max_ev)\n            cov_running = (eval_vecs * eval_vals) @ eval_vecs.T\n            C = cov_running.copy()\n\n            # acceptance: accept m_candidate if improved or with small probability (soft acceptance that decays)\n            decay = max(0.01, 1.0 - (evals / max(1, self.budget)))\n            accept_prob = 0.15 * decay  # small chance to accept a non-improving centroid early\n            if improved or (rng.rand() < accept_prob):\n                # accept: move center and expand radius moderately\n                m = m_candidate\n                # use multiplicative expansion but tempered by decay\n                rho = min(2.0 * max_range, rho * (1.0 + (self.rho_expand - 1.0) * (0.5 + 0.5 * decay)))\n                no_improve_iters = 0\n            else:\n                # reject: keep center but shrink radius gently\n                no_improve_iters += 1\n                rho = max(1e-9, rho * self.rho_shrink)\n\n            # mild smoothing of m towards candidate even when not fully accepted (soft acceptance)\n            m = 0.9 * m + 0.1 * m_candidate\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # update global best stagnation counter if no new best seen in this generation\n            # (already reset when global best updated during evaluation loop)\n\n            # opportunistic restart if no improvements for long or radius too small relative to bounds\n            if (no_improve_iters >= self.restart_no_improve) or (rho <= 1e-12 * max_range):\n                # restart near global best with jitter decreasing over budget\n                no_improve_iters = 0\n                # jitter scales down as we consume budget\n                budget_frac = evals / max(1, self.budget)\n                jitter_scale = max(0.05 * avg_range, 0.25 * (1.0 - budget_frac) * avg_range)\n                m = x_best + rng.normal(scale=jitter_scale, size=self.dim)\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset covariance to moderate diagonal\n                C = np.diag(((bounds_range / 6.0) ** 2).clip(min=1e-12))\n                cov_running = C.copy()\n                var_running = np.diag(C).copy()\n                rho = max(self.rho_init_frac * avg_range * 0.8, 1e-8)\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ALDE scored 0.199 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "7956008c-efb9-4476-b683-ba91bcce8d93", "operator": null, "metadata": {"aucs": [0.11824460542068949, 0.17379805070819787, 0.2884896112144981, 0.22893168740023884, 0.19409904104368836, 0.23617187927288597, 0.21433858425371766, 0.20353314338763395, 0.1864857418067617, 0.14283002037939563]}, "task_prompt": ""}
{"id": "918b1ad7-c5e3-4850-9b4a-50d62d4a29b2", "fitness": 0.2642845260037265, "name": "HDACS", "description": "The algorithm is a hybrid strategy that combines CMA-style covariance learning (rank-mu + rank-1 updates) with a trust-region radius and dual step-size adaptation (global search scale sigma and local radius rho) so it can balance exploration and exploitation. It generates candidates via dominant-eigenvector directional moves, Gaussian samples from the learned covariance (via a safe Cholesky), and local uniform jitter, with initial covariance and scales explicitly scaled to problem bounds (cov ~ (bounds/6)^2, sigma=0.25*mean_bound, rho proportional to mean_bound). An archive of recent evaluated points is used both to fit a ridge linear surrogate for a surrogate-gradient proposal and to approximate f(m) for center acceptance, while generation-wise weighted recombination and soft smoothing of the mean enable steady learning even when not fully accepted. Robustness comes from explicit safeguards (cov eigenvalue clipping, chol fallback), adaptive rules (p_succ-driven sigma update, cov_lr blending, rho shrink/expand), opportunistic restarts on stagnation, and budget-aware population sizing and archive trimming.", "code": "import numpy as np\n\nclass HDACS:\n    \"\"\"\n    Hybrid Directional Adaptive Covariance Strategy (HDACS)\n\n    One-line description:\n      Hybrid CMA-style covariance learning + trust-region radius + eigen-direction and surrogate-gradient proposals,\n      with dual step-size adaptation (sigma & rho), rank-mu + rank-1 covariance updates, archive-assisted surrogate,\n      and opportunistic restarts for robust continuous optimization.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 cov_lr=0.22,\n                 sigma_adapt_rate=0.18,\n                 rho_shrink=0.66,\n                 rho_expand=1.2,\n                 rho_init_frac=0.25,\n                 archive_factor=6,\n                 stagn_thresh_ratio=0.05,\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.cov_lr = float(cov_lr)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.rho_shrink = float(rho_shrink)\n        self.rho_expand = float(rho_expand)\n        self.rho_init_frac = float(rho_init_frac)\n        self.archive_factor = int(archive_factor)\n        self.stagn_thresh_ratio = float(stagn_thresh_ratio)\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        max_bound = np.max(bounds_scale)\n        mean_bound = np.mean(bounds_scale)\n\n        # adaptive population\n        if self.pop_base is None:\n            lambda_ = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lambda_ = int(self.pop_base)\n        lambda_ = min(lambda_, max(2, self.budget))\n\n        # bookkeeping\n        evals = 0\n        archive_capacity = max(self.dim * self.archive_factor, 20)\n\n        # initial uniform batch to seed mean, covariance, archive\n        init_batch = min(max(4, 2 * lambda_), self.budget, max(10, self.dim * 3))\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize mean as weighted recombination of top-half\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        weights0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        weights0 = np.maximum(weights0, 0.0)\n        weights0 = weights0 / np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initialize covariance (moderate isotropic scaled by bounds)\n        C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n        # global scale (sigma) and trust radius (rho)\n        sigma = 0.25 * mean_bound\n        rho = max(self.rho_init_frac * mean_bound, 1e-8)\n\n        # archive\n        X_hist = list(X0)\n        f_hist = list(f0)\n\n        # adaptation state\n        p_succ = 0.2\n        success_target = 0.2\n        stagn_iters = 0\n        stagn_thresh = max(5, int(self.stagn_thresh_ratio * self.budget))\n        iter_count = 0\n\n        # helpers\n        def chol_spd(mat):\n            eps = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        def clip_C(mat):\n            # symmetrize and enforce lower eigenvalue bound\n            mat = 0.5 * (mat + mat.T)\n            vals, vecs = np.linalg.eigh(mat)\n            vals = np.clip(vals, 1e-12, None)\n            return (vecs * vals) @ vecs.T\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam = min(lambda_, remaining)\n            mu = max(1, lam // 2)\n\n            # recompute weights\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # eigen-decomposition for directional proposals\n            try:\n                vals, vecs = np.linalg.eigh(C)\n            except np.linalg.LinAlgError:\n                vals = np.ones(self.dim)\n                vecs = np.eye(self.dim)\n            idxs = np.argsort(-vals)\n            vals = vals[idxs]\n            vecs = vecs[:, idxs]\n            # normalize eigen scales to mean\n            eigscale = np.sqrt(vals + 1e-20)\n            mean_eig = np.mean(eigscale) + 1e-20\n\n            candidates = []\n\n            # 1) directional eigen proposals: both signs, scaled by rho and eigen scale\n            n_dir = min(max(1, lam // 4), self.dim)\n            for k in range(n_dir):\n                v = vecs[:, k]\n                amp = rho * (0.8 + 0.8 * rng.rand()) * (eigscale[k] / mean_eig)\n                candidates.append(m + amp * v)\n                if len(candidates) >= lam:\n                    break\n                candidates.append(m - amp * v)\n                if len(candidates) >= lam:\n                    break\n\n            # 2) Gaussian proposals using learned covariance scaled by sigma\n            if len(candidates) < lam:\n                A = chol_spd(C)\n                n_gauss = lam - len(candidates) - 1  # reserve one slot for surrogate gradient candidate\n                n_gauss = max(0, n_gauss)\n                if n_gauss > 0:\n                    Z = rng.normal(size=(n_gauss, self.dim))\n                    Y = Z @ (A.T)  # covariance C\n                    Xg = m + sigma * Y\n                    candidates.extend(list(Xg))\n\n            # 3) surrogate-gradient proposal from ridge linear fit on recent archive\n            grad_proposed = False\n            if len(candidates) < lam:\n                grad_candidate = None\n                if len(f_hist) >= min(self.dim + 2, 8):\n                    # use most recent up to archive_capacity points\n                    n_fit = min(len(X_hist), archive_capacity)\n                    X_fit = np.asarray(X_hist[-n_fit:])\n                    f_fit = np.asarray(f_hist[-n_fit:])\n                    # center coords\n                    Xc = X_fit - m\n                    # choose f_center as nearest point in archive (approx f(m))\n                    dists = np.sum((X_fit - m)**2, axis=1)\n                    idxc = int(np.argmin(dists))\n                    f_center = f_fit[idxc]\n                    y = f_fit - f_center\n                    lam_reg = 1e-6 * (1.0 + np.var(y))\n                    XT_X = Xc.T @ Xc\n                    try:\n                        beta = np.linalg.solve(XT_X + lam_reg * np.eye(self.dim), Xc.T @ y)\n                        g = beta\n                        gnorm = np.linalg.norm(g)\n                        if gnorm > 0:\n                            step_scale = rho * (0.9 + 0.6 * rng.rand())\n                            grad_candidate = m - (step_scale * (g / (gnorm + 1e-20)))\n                    except np.linalg.LinAlgError:\n                        grad_candidate = None\n                if grad_candidate is not None:\n                    candidates.append(grad_candidate)\n                    grad_proposed = True\n\n            # 4) local uniform jitter around m to fill remaining slots (encourage local search)\n            while len(candidates) < lam:\n                box = np.clip(0.5 * min(sigma, rho), 1e-12, np.max(bounds_scale))\n                cand = m + rng.uniform(-box, box, size=self.dim)\n                candidates.append(cand)\n\n            # finalize candidates and clip\n            Xcand = np.asarray(candidates[:lam])\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates one by one (never exceed budget)\n            fc = np.full(Xcand.shape[0], np.inf, dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                xi = Xcand[i]\n                fi = func(xi)\n                fc[i] = fi\n                evals += 1\n                # update global best immediately\n                if fi < f_best:\n                    f_best = float(fi)\n                    x_best = xi.copy()\n                    stagn_iters = 0\n\n            # append to archive and trim\n            for xi, fi in zip(Xcand, fc):\n                X_hist.append(xi.copy())\n                f_hist.append(float(fi))\n            if len(X_hist) > archive_capacity:\n                excess = len(X_hist) - archive_capacity\n                X_hist = X_hist[excess:]\n                f_hist = f_hist[excess:]\n\n            # find generation best\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            # estimate f(m) by nearest archived point\n            if len(X_hist) > 0:\n                Xh = np.asarray(X_hist)\n                dists = np.sum((Xh - m)**2, axis=1)\n                id0 = int(np.argmin(dists))\n                f_m_approx = float(f_hist[id0])\n            else:\n                f_m_approx = f_best\n\n            improved_center = gen_best_f < f_m_approx - 1e-12\n\n            # recompute new center by weighted recombination of top mu candidates\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # compute normalized steps for covariance update (use sigma as normalization for gaussian-like steps)\n            deltas = (X_mu - m) / (sigma + 1e-20)  # shape (mu, dim)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas\n\n            # rank-1 successful step direction (if any improvement)\n            if improved_center:\n                successful_step = (gen_best_x - m) / (sigma + 1e-20)\n                dir_cov = np.outer(successful_step, successful_step)\n                C = (1.0 - self.cov_lr) * C + self.cov_lr * (0.8 * weighted_cov + 0.2 * dir_cov)\n            else:\n                # conservative blend toward small isotropic to reduce noise\n                iso = np.diag(((bounds_scale / 12.0) ** 2).clip(min=1e-12))\n                C = (1.0 - 0.5 * self.cov_lr) * C + (0.5 * self.cov_lr) * weighted_cov + (0.5 * self.cov_lr) * iso\n\n            # safeguard covariance\n            C = clip_C(C)\n\n            # update center acceptance and radius/sigma adaptation\n            # update smoothed success rate\n            p_succ = 0.85 * p_succ + 0.15 * float(improved_center)\n            # update sigma multiplicatively\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - success_target))\n            sigma = np.clip(sigma, 1e-12, 2.0 * mean_bound)\n\n            if improved_center:\n                m = m_new\n                rho = min(2.0 * np.max(bounds_scale), rho * self.rho_expand)\n                stagn_iters = 0\n            else:\n                stagn_iters += 1\n                rho = max(1e-9 * max_bound, rho * self.rho_shrink)\n\n            # soft acceptance: small smoothing toward m_new to allow learning even when not accepted fully\n            m = 0.9 * m + 0.1 * m_new\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # opportunistic restart if stagnation too long or radius collapsed\n            if (stagn_iters >= stagn_thresh) or (rho <= 1e-9 * max_bound) or (sigma <= 1e-12):\n                stagn_iters = 0\n                # re-center near global best with jitter\n                jitter = 0.4 * max(rho, 0.05 * mean_bound)\n                m = x_best + jitter * rng.randn(self.dim)\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset covariance and scales\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                rho = max(self.rho_init_frac * mean_bound * 0.8, 1e-8)\n                sigma = max(0.2 * mean_bound, sigma * 0.7)\n                # reduce lambda_ a bit if very tight budget to avoid oversampling\n                if self.budget < 200:\n                    lambda_ = max(4, lambda_ // 2)\n                # continue loop\n                continue\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HDACS scored 0.264 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "7956008c-efb9-4476-b683-ba91bcce8d93", "operator": null, "metadata": {"aucs": [0.14581531165102612, 0.1970075700693915, 0.31146816040950287, 0.6327303865980646, 0.19786857476807762, 0.22488439696382778, 0.2562798227641141, 0.27413243595806314, 0.23576037857310284, 0.1668982222820946]}, "task_prompt": ""}
{"id": "2354f9af-21cb-46af-9cd7-63a83a10fc24", "fitness": 0.2939313769861066, "name": "OPFAMS", "description": "OPFAMS hybridizes compact CMA-style global search (mean, covariance + sigma) with a pool of local \"FAMS-like\" probes and diverse operators (Gaussian CMA samples, parabolic directional probes, archive-based elite-mix, PCA-guided Cauchy jumps), letting each operator compete via decaying credits (op_decay=0.88) and probabilistic selection. Each probe carries its own radius, age and momentum and uses symmetric parabolic probing, momentum extrapolation and adaptive radius expansion/shrink (radius_expand=1.25, radius_shrink=0.65) to exploit local curvature and propagate successful moves. The CMA core is intentionally lightweight (cov_lr≈0.18, sigma_adapt_rate≈0.22, success_target≈0.2) with robust chol_safe/floor/SPD enforcement and mean/cov updates driven by a small weighted set of best recent candidates rather than full-population statistics. Robustness and exploration are enforced by adaptive initialization and archive maintenance, temperature-based probe selection, stagnation detection that triggers Levy/Cauchy escapes or reseeding, and budget-aware probe replacement and sampling heuristics (init_samples ~6*dim, sigma/init radii ~O(0.2–0.25*span)).", "code": "import numpy as np\n\nclass OPFAMS:\n    \"\"\"\n    Operator-Pooled Fractal Adaptive Multi-Scale CMA (OPFAMS)\n\n    One-line: Combine FAMS-style probes (parabolic directional probing + momentum + adaptive radii)\n    with a compact CMA-like mean/cov/sigma core and an operator pool (gaussian, parabolic-probe,\n    differential/elite-mix, PCA-Cauchy jump), adapting operator credits and sigma by smoothed success rate.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 init_samples=None, archive_size=None, probe_count=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.probe_count = probe_count\n\n        # CMA-like knobs\n        self.cov_lr = 0.18\n        self.sigma_adapt_rate = 0.22\n        self.success_target = 0.2\n        self.min_sigma = 1e-12\n\n        # probe/parabola knobs\n        self.radius_expand = 1.25\n        self.radius_shrink = 0.65\n        self.mom_alpha = 0.6  # smoothing for momentum update (mom = mom_alpha * mom + (1-mom_alpha)*move)\n        self.extrap_alpha = 0.8\n\n        # operator pool: gaussian, parabola_probe, elite_mix, pca_cauchy\n        self.n_ops = 4\n        self.op_decay = 0.88\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds support scalar or per-dim\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        eps = 1e-12\n\n        # adaptive defaults\n        if self.init_samples is None:\n            init_samples = max(12, min(60, 6 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, max(1, self.budget // 6))\n\n        if self.archive_size is None:\n            archive_k = max(4, min(12, init_samples // 3))\n        else:\n            archive_k = int(self.archive_size)\n\n        if self.probe_count is None:\n            probe_count = max(2, min(12, archive_k))\n        else:\n            probe_count = int(self.probe_count)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x)\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = float(func(x))\n            evals += 1\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # maintain sorted archive\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # initial sampling (space-filling)\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # Initialize CMA-like core (mean, covariance, sigma)\n        if len(archive) > 0:\n            m = np.mean(np.vstack([t[1] for t in archive]), axis=0)\n        else:\n            m = 0.5 * (lb + ub)\n        C = np.diag(((span / 6.0) ** 2).clip(min=1e-12))\n        sigma = max(self.min_sigma, 0.25 * avg_span)\n\n        def chol_safe(Cmat):\n            eps_ch = 1e-12 * np.maximum(np.diag(Cmat), 1.0)\n            try:\n                A = np.linalg.cholesky(Cmat + np.diag(eps_ch))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(Cmat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        # initialize probes from top archive or random\n        probes = []\n        for i in range(min(probe_count, len(archive))):\n            f0, x0 = archive[i]\n            probes.append({\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': max(0.08 * avg_span, 0.25 * avg_span * (0.9 ** i)),\n                'mom': np.zeros(self.dim, dtype=float),\n                'age': 0\n            })\n        # fill remaining probes by sampling around mean or uniformly\n        while len(probes) < probe_count and evals < self.budget:\n            # sample near mean with some jitter\n            x0 = m + 0.2 * avg_span * rng.randn(self.dim)\n            res = eval_and_record(x0)\n            if res is None:\n                break\n            f0, x0 = res\n            probes.append({\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': 0.25 * avg_span,\n                'mom': np.zeros(self.dim, dtype=float),\n                'age': 0\n            })\n\n        # operator credits and selection parameters\n        op_credit = np.ones(self.n_ops, dtype=float)\n        sel_temp = 1.0\n        p_succ = self.success_target\n\n        attempt = 0\n        stagn = 0\n\n        # main loop\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            if len(probes) == 0:\n                break\n\n            # select probe via softmax over -f\n            fs = np.array([p['f'] for p in probes], dtype=float)\n            z = -fs / max(1e-9, sel_temp)\n            probs = np.exp(z - np.max(z))\n            probs /= probs.sum()\n            pid = rng.choice(len(probes), p=probs)\n            probe = probes[pid]\n            x0 = probe['x'].copy()\n            f0 = probe['f']\n            r0 = probe['r']\n\n            # choose operator by op_credit soft probabilities\n            op_probs = op_credit / (np.sum(op_credit) + 1e-20)\n            op_probs = np.maximum(op_probs, 1e-6)\n            op_probs = op_probs / np.sum(op_probs)\n            op = rng.choice(self.n_ops, p=op_probs)\n            origin_success = False\n\n            # prepare temporary list of evaluated candidates to potentially update CMA\n            cand_pool = []\n\n            # operator implementations\n            if op == 0:\n                # Gaussian CMA sample around mean using learned cov\n                A = chol_safe(C)\n                z = rng.randn(self.dim)\n                y = z @ A.T\n                xc = m + sigma * y\n                res = eval_and_record(xc)\n                if res is not None:\n                    fc, xc = res\n                    cand_pool.append((fc, xc))\n                    if fc < probe['f']:\n                        origin_success = True\n                        # inject into probe\n                        probe['x'] = xc.copy()\n                        probe['f'] = float(fc)\n                        move = probe['x'] - x0\n                        probe['mom'] = self.mom_alpha * probe['mom'] + (1 - self.mom_alpha) * move\n                        probe['r'] = min(probe['r'] * self.radius_expand, 2.0 * avg_span)\n                        probe['age'] = 0\n                else:\n                    # budget exhausted\n                    pass\n\n            elif op == 1:\n                # Parabolic multi-direction probing (like FAMS) around probe\n                k = min(self.dim, 3)\n                Adirs = rng.randn(self.dim, k)\n                try:\n                    Q, _ = np.linalg.qr(Adirs)\n                except Exception:\n                    Q = Adirs / (np.linalg.norm(Adirs, axis=0, keepdims=True) + 1e-12)\n                improved_any = False\n                for j in range(min(k, Q.shape[1])):\n                    if evals >= self.budget:\n                        break\n                    d = Q[:, j]\n                    s = r0 * (0.6 + 0.8 * rng.rand())\n                    step = d * s\n                    # symmetric evals\n                    resm = eval_and_record(x0 - step)\n                    if resm is None:\n                        break\n                    fm, xm = resm\n                    resp = eval_and_record(x0 + step)\n                    if resp is None:\n                        break\n                    fp, xp = resp\n                    # try parabola center using known f0 (note f0 may be stale; use probe['f'])\n                    denom = (fm + fp - 2.0 * probe['f'])\n                    if abs(denom) > 1e-12:\n                        t_star = 0.5 * (fm - fp) / denom\n                        t_star = float(np.clip(t_star, -2.0, 2.0))\n                        xpar = x0 + t_star * step\n                        respar = eval_and_record(xpar)\n                        if respar is not None:\n                            fpar, xpar = respar\n                            candidate = (fpar, xpar)\n                        else:\n                            candidate = None\n                    else:\n                        candidate = None\n                    # consider best among fm, fp, fpar, and current\n                    candidates = [(fm, xm), (fp, xp)]\n                    if candidate is not None:\n                        candidates.append(candidate)\n                    candidates.append((probe['f'], probe['x']))\n                    candidates.sort(key=lambda t: t[0])\n                    bestf, bestx = candidates[0]\n                    cand_pool.extend(candidates[:2])\n                    if bestf < probe['f'] - 1e-12:\n                        # accept improvement\n                        move = bestx - probe['x']\n                        probe['x'] = bestx.copy()\n                        probe['f'] = float(bestf)\n                        probe['mom'] = self.mom_alpha * probe['mom'] + (1 - self.mom_alpha) * move\n                        probe['r'] = min(probe['r'] * self.radius_expand, 2.0 * avg_span)\n                        probe['age'] = 0\n                        improved_any = True\n                    else:\n                        probe['r'] = max(1e-8, probe['r'] * self.radius_shrink)\n                        probe['age'] += 1\n                origin_success = improved_any\n\n            elif op == 2:\n                # Elite mix / differential recombination using archive\n                if len(archive) >= 2:\n                    # choose two elites\n                    i, j = rng.choice(len(archive), size=2, replace=False)\n                    a = archive[i][1]\n                    b = archive[j][1]\n                    gamma = 0.6 + 0.4 * rng.rand()\n                    child = probe['x'] + gamma * (a - b) + 0.05 * avg_span * rng.randn(self.dim)\n                else:\n                    child = probe['x'] + 0.3 * avg_span * rng.randn(self.dim)\n                res = eval_and_record(child)\n                if res is not None:\n                    fc, xc = res\n                    cand_pool.append((fc, xc))\n                    if fc < probe['f']:\n                        origin_success = True\n                        move = xc - probe['x']\n                        probe['x'] = xc.copy()\n                        probe['f'] = float(fc)\n                        probe['mom'] = self.mom_alpha * probe['mom'] + (1 - self.mom_alpha) * move\n                        probe['r'] = min(probe['r'] * self.radius_expand, 2.0 * avg_span)\n                        probe['age'] = 0\n\n            else:\n                # PCA-guided Cauchy jump from archive/mean\n                if len(archive) >= 3:\n                    pts = np.vstack([t[1] for t in archive])\n                    mean_a = np.mean(pts, axis=0)\n                    Xc = pts - mean_a\n                    Ccov = (Xc.T @ Xc) / max(1.0, pts.shape[0])\n                    try:\n                        eigvals, eigvecs = np.linalg.eigh(Ccov)\n                        idx_top = np.argsort(eigvals)[-1]\n                        v = eigvecs[:, idx_top]\n                        lam = max(1e-8, float(eigvals[idx_top]))\n                    except Exception:\n                        v = rng.randn(self.dim)\n                        v = v / (np.linalg.norm(v) + 1e-12)\n                        lam = 1.0\n                    step_len = rng.standard_cauchy() * (np.sqrt(lam) + 0.2) * 0.6 * avg_span\n                    step_len = float(np.clip(step_len, -5.0 * avg_span, 5.0 * avg_span))\n                    xjump = mean_a + step_len * v\n                else:\n                    # fallback isotropic cauchy jump around probe\n                    v = rng.randn(self.dim)\n                    v = v / (np.linalg.norm(v) + 1e-12)\n                    step_len = rng.standard_cauchy() * 0.6 * avg_span\n                    xjump = probe['x'] + step_len * v\n                res = eval_and_record(xjump)\n                if res is not None:\n                    fc, xc = res\n                    cand_pool.append((fc, xc))\n                    if fc < probe['f']:\n                        origin_success = True\n                        move = xc - probe['x']\n                        probe['x'] = xc.copy()\n                        probe['f'] = float(fc)\n                        probe['mom'] = self.mom_alpha * probe['mom'] + (1 - self.mom_alpha) * move\n                        probe['r'] = min(probe['r'] * self.radius_expand, 2.0 * avg_span)\n                        probe['age'] = 0\n                    else:\n                        probe['r'] = max(1e-8, probe['r'] * self.radius_shrink)\n                        probe['age'] += 1\n\n            # momentum extrapolation attempt (try small extrapolation)\n            if evals < self.budget and np.linalg.norm(probe['mom']) > 1e-8:\n                xm = probe['x'] + self.extrap_alpha * probe['mom']\n                xm = np.minimum(np.maximum(xm, lb), ub)\n                resm = eval_and_record(xm)\n                if resm is not None:\n                    fm, xm = resm\n                    cand_pool.append((fm, xm))\n                    if fm < probe['f'] - 1e-12:\n                        move = xm - probe['x']\n                        probe['x'] = xm.copy()\n                        probe['f'] = float(fm)\n                        probe['mom'] = 0.8 * probe['mom']\n                        probe['r'] = min(probe['r'] * 1.2, 2.0 * avg_span)\n                        origin_success = True\n                    else:\n                        probe['mom'] *= 0.5\n\n            # Update operator credits: decay + add success\n            op_succ = 1.0 if origin_success else 0.0\n            # decay\n            op_credit = op_credit * self.op_decay\n            op_credit[op] += (1.0 - self.op_decay) * op_succ\n            op_credit = np.maximum(op_credit, 1e-8)\n\n            # Update CMA core occasionally using best candidates from cand_pool\n            if len(cand_pool) > 0:\n                # select top few to update mean and cov\n                cand_pool.sort(key=lambda t: t[0])\n                k = min(len(cand_pool), max(1, int(0.2 * len(probes) + 1)))\n                Xcands = np.vstack([t[1] for t in cand_pool[:k]])\n                weights = np.log(k + 0.5) - np.log(np.arange(1, k + 1))\n                weights = np.maximum(weights, 0.0)\n                weights = weights / np.sum(weights)\n                m_new = (weights.reshape(-1, 1) * Xcands).sum(axis=0)\n                deltas = (Xcands - m) / (sigma + 1e-20)\n                W = weights.reshape(-1, 1)\n                weighted_cov = (deltas * W).T @ deltas\n                # update covariance with blend to floor\n                floor = np.diag(((span / 30.0) ** 2).clip(min=1e-12))\n                C = (1.0 - self.cov_lr) * C + self.cov_lr * weighted_cov + 1e-12 * np.eye(self.dim)\n                C = 0.985 * C + 0.015 * floor\n                # update mean\n                m = m_new.copy()\n\n            # sigma adaptation: compute success fraction on this attempt (origin_success approximates)\n            p_succ = 0.92 * p_succ + 0.08 * (1.0 if origin_success else 0.0)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = float(np.clip(sigma, self.min_sigma, 2.0 * np.max(span)))\n\n            # occasional re-centering or escape if stagnation detected\n            # track stagn: increment if no op success\n            if origin_success:\n                stagn = 0\n            else:\n                stagn += 1\n\n            if stagn > max(25, int(0.002 * self.budget)):\n                # attempt a Levy-like escape anchored on best\n                if x_best is not None and rng.rand() < 0.6:\n                    jump = rng.standard_cauchy(self.dim) * (0.6 * avg_span)\n                    x_jump = x_best + jump\n                    x_jump = np.minimum(np.maximum(x_jump, lb), ub)\n                    resj = eval_and_record(x_jump)\n                    if resj is not None:\n                        fj, xj = resj\n                        if fj < f_best:\n                            # re-center CMA core to new best and inflate sigma\n                            m = xj.copy()\n                            sigma = max(sigma, 0.4 * avg_span)\n                            C = np.diag(((span / 6.0) ** 2).clip(min=1e-12))\n                            stagn = 0\n                else:\n                    # isotropic re-seed around mean with jitter\n                    m = np.minimum(np.maximum(m + 0.25 * avg_span * rng.randn(self.dim), lb), ub)\n                    C = np.diag(((span / 5.0) ** 2).clip(min=1e-12))\n                    sigma = max(sigma, 0.25 * avg_span)\n                    for p in probes:\n                        p['r'] = max(1e-8, p['r'] * 0.9)\n                    stagn = 0\n\n            # maintain probes: replace old/poor probes with new samples from archive/mean\n            if attempt % 7 == 0:\n                # compute worst probe and replace if budget allows\n                if len(probes) > 0:\n                    worst_idx = int(np.argmax([p['f'] for p in probes]))\n                    if rng.rand() < 0.6 and len(archive) > 0:\n                        base = archive[0][1]\n                        newx = base + 0.12 * avg_span * rng.randn(self.dim)\n                    else:\n                        newx = m + 0.3 * avg_span * rng.randn(self.dim)\n                    resn = eval_and_record(newx)\n                    if resn is not None:\n                        fn, xn = resn\n                        probes[worst_idx] = {\n                            'x': xn.copy(),\n                            'f': float(fn),\n                            'r': 0.25 * avg_span,\n                            'mom': np.zeros(self.dim, dtype=float),\n                            'age': 0\n                        }\n\n            # prune probes if too many (safety)\n            if len(probes) > probe_count:\n                probes.sort(key=lambda p: p['f'])\n                probes = probes[:probe_count]\n\n            # adapt selection temperature gently\n            if stagn > 30:\n                sel_temp = min(5.0, sel_temp * 1.04)\n            else:\n                sel_temp = max(0.3, sel_temp * 0.996)\n\n            # safety SPD enforcement occasionally\n            if attempt % 11 == 0:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-16, None)\n                C = (vecs * vals) @ vecs.T\n\n            # ensure x_best tracked from probes and archive\n            for p in probes:\n                if p['f'] < f_best:\n                    f_best = p['f']\n                    x_best = p['x'].copy()\n\n            # loop continues until budget exhausted\n\n        # finish\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best) if f_best is not None else np.inf\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm OPFAMS scored 0.294 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "7956008c-efb9-4476-b683-ba91bcce8d93", "operator": null, "metadata": {"aucs": [0.1211388603906195, 0.1508803287603686, 0.424646452296208, 0.41148124530744257, 0.26457621120234764, 0.6343448670904801, 0.24403636260053663, 0.27389091678669897, 0.268789511451501, 0.14552901397486295]}, "task_prompt": ""}
{"id": "ac2d156a-5a54-4ce8-b4b0-7ba466ab6fae", "fitness": 0.43937288228454463, "name": "AIRES", "description": "AIRES is a small-population ensemble that uses Latin‑like stratified initialization and per‑individual adaptive Gaussian step‑sizes (jDE‑style; sigma in [sigma_min,sigma_max], tau_sigma controls mutation) to balance global exploration and local exploitation. It maintains a compact elite archive (archive_k) to estimate local affine geometry via PCA and produces anisotropic, eigenvector‑aligned Gaussian probes and Student‑t heavy‑tailed jumps (student_nu≈3) from best/archive centers for affine‑invariant exploration. A lightweight diagonal‑quadratic surrogate (ridge regularized by surrogate_ridge) provides an analytic minimizer used in trust‑region convex combinations, while periodic local intensification runs PCA coordinate descent (local_budget_frac, local_period) around the best; mixture probabilities (mix_prob_surrogate, mix_prob_student) and sigmas are success‑driven adapted. Additional practical designs include bounds reflection+clamp, strict budget accounting, archive deduplication and maintenance, occasional random injections/restarts, and budget‑aware local allocations to ensure robust performance across Many Affine BBOB problems.", "code": "import numpy as np\n\nclass AIRES:\n    \"\"\"\n    Affine-Invariant Rotational Ensemble Search (AIRES)\n\n    Main ideas / novel mechanisms:\n    - Small population ensemble with per-individual adaptive step-sizes (jDE-like) controlling Gaussian exploration.\n    - Archive of elites used to estimate a local affine geometry (covariance PCA) to generate anisotropic,\n      rotation-aligned proposals and Student-t heavy-tailed jumps along principal axes.\n    - A lightweight diagonal-quadratic surrogate (only linear + diagonal quadratic terms) is fitted\n      on accumulated archive points via ridge regression to produce promising local minima proposals cheaply.\n    - Local coordinate descent operates along PCA directions (pattern-style) with adaptive step shrinkage.\n    - Success-driven adaptation adjusts global mixture probabilities and step-sizes to balance exploration/exploitation.\n    - Strict evaluation counter, bounds reflection+clamp, and budget-aware local allocations.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop_min=12, p_frac=0.2, tau_sigma=0.12, sigma_min=1e-4, sigma_max=2.0,\n                 archive_max=None, student_nu=3.0, surrogate_ridge=1e-6,\n                 local_budget_frac=0.03, local_period=20):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # population and per-individual adaptation\n        self.pop_min = int(pop_min)\n        self.p_frac = float(p_frac)\n        self.tau_sigma = float(tau_sigma)\n        self.sigma_min = float(sigma_min)\n        self.sigma_max = float(sigma_max)\n\n        # archive and surrogate parameters\n        self.archive_max = archive_max\n        self.student_nu = float(student_nu)\n        self.surrogate_ridge = float(surrogate_ridge)\n\n        # local search and scheduling\n        self.local_budget_frac = float(local_budget_frac)\n        self.local_period = int(local_period)\n\n        # internal state to be set at call time\n        self.f_opt = None\n        self.x_opt = None\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        # population size small & budget-aware\n        pop = max(self.pop_min, int(4 + 2 * np.log(max(2, self.dim))))\n        pop = min(pop, max(2, self.budget))\n        # archive size\n        if self.archive_max is None:\n            archive_k = max(4, min(10, pop // 2))\n        else:\n            archive_k = int(self.archive_max)\n\n        # bookkeeping\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f,x) sorted ascending by f\n\n        def clamp_bounds(x):\n            x = np.asarray(x, dtype=float)\n            # reflect if outside then clamp\n            below = x < lb\n            if np.any(below):\n                x[below] = lb[below] + (lb[below] - x[below])\n            above = x > ub\n            if np.any(above):\n                x[above] = ub[above] - (x[above] - ub[above])\n            x = np.minimum(np.maximum(x, lb), ub)\n            return x\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = clamp_bounds(x)\n            f = float(func(x))\n            evals += 1\n            # update best\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # maintain archive (keeps unique-ish points)\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                # deduplicate close points (for conditioning)\n                # keep at most archive_k\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # --- Initialization: stratified Latin-like seeds (per-dim permutations) but jittered differently ---\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / float(pop)\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        X += (rng.rand(pop, self.dim) - 0.5) * (0.6 * span / max(1.0, self.dim))\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            res = eval_and_record(X[i])\n            if res is None:\n                break\n            f[i], X[i] = res\n\n        # ensure at least one point evaluated\n        if x_best is None:\n            while evals < self.budget:\n                x0 = rng.uniform(lb, ub)\n                res = eval_and_record(x0)\n                if res is None:\n                    break\n                f0, x0 = res\n                break\n\n        # per-individual step sizes (sigma) initialized relative to range\n        sigma = np.clip(0.25 * avg_span * (0.8 + 0.4 * rng.randn(pop)), self.sigma_min, self.sigma_max)\n        # success counters\n        success_counts = np.zeros(pop, dtype=int)\n        try_counts = np.ones(pop, dtype=int)\n\n        # global mixture params\n        mix_prob_surrogate = 0.2   # probability to use surrogate-guided candidate\n        mix_prob_student = 0.25    # probability to do heavy-tailed Student-t jump\n\n        gen = 0\n        gens_since_improve = 0\n\n        # utility: fit diagonal-quadratic surrogate model on archive (1 + d linear + d diagonal quadratic)\n        def fit_diag_quadratic(archive_list):\n            # returns coef vector: c0 + b^T x + 0.5 * sum(q * x^2)\n            # solve ridge least squares: Phi * theta = y\n            n_pts = len(archive_list)\n            if n_pts < (1 + 2 * self.dim):\n                # allow smaller fit with regularization\n                pass\n            Y = np.array([p[0] for p in archive_list], dtype=float)\n            Xpts = np.array([p[1] for p in archive_list], dtype=float)\n            # design matrix: [1, x1..xd, x1^2..xd^2]\n            Phi = np.empty((n_pts, 1 + 2 * self.dim), dtype=float)\n            Phi[:, 0] = 1.0\n            Phi[:, 1:1 + self.dim] = Xpts\n            Phi[:, 1 + self.dim:] = 0.5 * (Xpts ** 2)\n            # ridge solve\n            ridge = self.surrogate_ridge * (np.linalg.norm(Y) + 1.0)\n            A = Phi.T.dot(Phi) + ridge * np.eye(Phi.shape[1])\n            bvec = Phi.T.dot(Y)\n            try:\n                theta = np.linalg.solve(A, bvec)\n                return theta\n            except np.linalg.LinAlgError:\n                # fallback to regularized least squares via pinv\n                theta = np.linalg.lstsq(Phi, Y, rcond=1e-6)[0]\n                return theta\n\n        def surrogate_minimizer(theta):\n            # analytical minimizer for diagonal-quadratic: minimize c0 + b^T x + 0.5 * sum(q_i x_i^2)\n            # gradient = b + q * x => x* = -b / q  (where q_i != 0)\n            if theta is None:\n                return None\n            b = theta[1:1 + self.dim]\n            q = theta[1 + self.dim:]\n            x_star = np.zeros(self.dim, dtype=float)\n            # guard against tiny q: use small positive floor\n            q_floor = np.maximum(np.abs(q), 1e-8)\n            x_star = - b / q_floor\n            # clamp to bounds\n            x_star = clamp_bounds(x_star)\n            return x_star\n\n        # PCA of archive -> eigenvectors & eigenvalues for anisotropic proposals\n        def archive_pca(archive_list):\n            if len(archive_list) < 2:\n                return np.eye(self.dim), np.ones(self.dim)\n            Xpts = np.array([p[1] for p in archive_list], dtype=float)\n            C = np.cov(Xpts.T)\n            # regularize\n            C += 1e-8 * np.eye(self.dim)\n            try:\n                vals, vecs = np.linalg.eigh(C)\n            except np.linalg.LinAlgError:\n                vals = np.ones(self.dim)\n                vecs = np.eye(self.dim)\n            # sort descending\n            idx = np.argsort(vals)[::-1]\n            vals = np.maximum(vals[idx], 1e-12)\n            vecs = vecs[:, idx]\n            return vecs, vals\n\n        # Student-t directional jump: along principal axis directions\n        def student_t_jump(center, vecs, vals, scale=1.0):\n            # choose principal axis biased by eigenvalue\n            probs = vals / np.sum(vals)\n            axis = rng.choice(self.dim, p=probs)\n            direction = vecs[:, axis]\n            # sample Student-t (nu=self.student_nu)\n            t = rng.standard_t(self.student_nu)\n            step = direction * (t * scale * np.sqrt(vals[axis]) * avg_span * (0.2 + 0.8 * rng.rand()))\n            return clamp_bounds(center + step)\n\n        # Local coordinate descent along PCA directions\n        def local_pca_descent(x0, f0, budget_local):\n            nonlocal evals, f_best, x_best, archive\n            if budget_local <= 0 or evals >= self.budget:\n                return f0, x0\n            # build local PCA from archive\n            vecs, vals = archive_pca(archive if len(archive) > 0 else [(f0, x0)])\n            x = x0.copy()\n            fx = float(f0)\n            steps = np.maximum(0.2 * avg_span, 0.08 * np.sqrt(vals) * avg_span)\n            steps = np.asarray(steps, dtype=float)\n            used = 0\n            # loop decreasing steps\n            while used + self.dim <= budget_local and np.any(steps > (1e-6 * avg_span)) and evals < self.budget:\n                improved = False\n                for k in range(self.dim):\n                    if used >= budget_local or evals >= self.budget:\n                        break\n                    d = vecs[:, k]\n                    # try + direction\n                    xp = clamp_bounds(x + steps[k] * d)\n                    res = eval_and_record(xp)\n                    used += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < fx:\n                        x = xp.copy()\n                        fx = fp\n                        improved = True\n                        continue\n                    # try - direction\n                    xn = clamp_bounds(x - steps[k] * d)\n                    res = eval_and_record(xn)\n                    used += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < fx:\n                        x = xn.copy()\n                        fx = fn\n                        improved = True\n                if not improved:\n                    # shrink steps\n                    steps *= 0.6\n                # else continue with same step possibly increased locally\n            return fx, x\n\n        # MAIN LOOP\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # sort population indices by fitness\n            order = np.argsort(f)\n            p_pool_size = max(2, int(np.ceil(self.p_frac * pop)))\n            p_pool = order[:p_pool_size]\n\n            # compute PCA for archive (for anisotropic proposals)\n            vecs, vals = archive_pca(archive if len(archive) > 0 else [(f_best, x_best if x_best is not None else X[0])])\n\n            # occasionally fit surrogate\n            theta = None\n            if len(archive) >= max(6, 2 * self.dim):\n                try:\n                    theta = fit_diag_quadratic(archive)\n                except Exception:\n                    theta = None\n\n            # iterate individuals\n            order_iter = rng.permutation(pop)\n            for ii in order_iter:\n                if evals >= self.budget:\n                    break\n\n                # jDE-like sigma adaptation\n                if rng.rand() < self.tau_sigma:\n                    sigma[ii] = sigma[ii] * (1.2 if rng.rand() < 0.5 else 0.8)\n                    sigma[ii] = np.clip(sigma[ii], self.sigma_min, self.sigma_max)\n\n                xi = X[ii].copy()\n                fi = f[ii]\n\n                # decide strategy: surrogate-guided / student-t jump / anisotropic Gaussian around xi\n                use_surrogate = (theta is not None) and (rng.rand() < mix_prob_surrogate)\n                use_student = (rng.rand() < mix_prob_student)\n\n                candidate = None\n\n                if use_surrogate:\n                    # propose from surrogate minimizer shifted slightly towards xi (trust-region)\n                    x_s = surrogate_minimizer(theta)\n                    if x_s is not None:\n                        # convex combination with xi, plus small gaussian noise\n                        alpha = rng.rand() * 0.8 + 0.1\n                        cand = clamp_bounds(alpha * x_s + (1.0 - alpha) * xi + rng.randn(self.dim) * 0.02 * sigma[ii])\n                        candidate = cand\n\n                if candidate is None and use_student and len(archive) >= 2:\n                    # Student-t heavy-tailed jump from a chosen center (prefer best)\n                    if rng.rand() < 0.7:\n                        center = archive[0][1]\n                    else:\n                        center = archive[rng.randint(0, len(archive))][1]\n                    candidate = student_t_jump(center, vecs, vals, scale=1.0)\n\n                if candidate is None:\n                    # anisotropic Gaussian probe: align with PCA directions scaled by sigma[ii]\n                    # sample in PCA coordinates\n                    z = rng.randn(self.dim) * (sigma[ii] / (avg_span + 1e-12))\n                    # scale per PC by sqrt(eigenvalue) to be affine-invariant\n                    z = z * np.sqrt(vals + 1e-12)\n                    candidate = clamp_bounds(xi + vecs.dot(z) * avg_span)\n\n                # evaluate candidate\n                if evals >= self.budget:\n                    break\n                res = eval_and_record(candidate)\n                if res is None:\n                    break\n                fcand, candidate = res\n\n                try_counts[ii] += 1\n                if fcand <= fi:\n                    # accept (greedy), replace\n                    X[ii] = candidate.copy()\n                    f[ii] = fcand\n                    success_counts[ii] += 1\n                    improved_in_gen = True\n                    gens_since_improve = 0\n                    # slightly increase sigma on success (encourage larger steps) or decrease based on success ratio\n                    succ_ratio = success_counts[ii] / max(1, try_counts[ii])\n                    if succ_ratio > 0.2:\n                        sigma[ii] = min(self.sigma_max, sigma[ii] * 1.05)\n                    else:\n                        sigma[ii] = max(self.sigma_min, sigma[ii] * 0.97)\n                else:\n                    # failure: modestly shrink sigma\n                    sigma[ii] = max(self.sigma_min, sigma[ii] * 0.98)\n\n                # update global best if needed\n                if f[ii] < f_best:\n                    f_best = float(f[ii])\n                    x_best = X[ii].copy()\n                    gens_since_improve = 0\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # periodic local intensification using PCA descent around best\n            remaining = self.budget - evals\n            if remaining > 0 and (gen % self.local_period == 0 or gens_since_improve > 3 * self.local_period):\n                alloc = int(max(1, min(int(self.local_budget_frac * self.budget), remaining)))\n                # if strongly stagnating, allow larger local attempt\n                if gens_since_improve > 3 * self.local_period:\n                    alloc = min(remaining, alloc * 3)\n                if x_best is None:\n                    anchor = X[np.argmin(f)].copy()\n                    f_anchor = np.min(f)\n                else:\n                    anchor = x_best.copy()\n                    f_anchor = f_best\n                f_after, x_after = local_pca_descent(anchor, f_anchor, alloc)\n                if f_after < f_best:\n                    # inject into worst\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_after.copy()\n                    f[worst_idx] = f_after\n                    f_best = f_after\n                    x_best = x_after.copy()\n                    gens_since_improve = 0\n\n            # occasional random global restart-like injection (diversify)\n            if (gen % 17) == 0 and evals < self.budget:\n                xr = rng.uniform(lb, ub)\n                res = eval_and_record(xr)\n                if res is not None:\n                    fr, xr = res\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = xr.copy()\n                    f[worst_idx] = fr\n                    if fr < f_best:\n                        f_best = fr\n                        x_best = xr.copy()\n                        gens_since_improve = 0\n\n            # update archive from population and ensure it contains best\n            for i in range(pop):\n                if np.isfinite(f[i]):\n                    if len(archive) < archive_k or f[i] < archive[-1][0]:\n                        archive.append((float(f[i]), X[i].copy()))\n                        archive.sort(key=lambda t: t[0])\n                        if len(archive) > archive_k:\n                            archive.pop()\n\n            # adapt mixture probabilities based on recent success across population\n            global_success_rate = np.sum(success_counts) / max(1, np.sum(try_counts))\n            # if many successes, tilt towards local search/surrogate; if few successes, increase student jumps\n            mix_prob_surrogate = np.clip(0.1 + 0.8 * global_success_rate, 0.05, 0.6)\n            mix_prob_student = np.clip(0.15 + 0.9 * (1.0 - global_success_rate), 0.05, 0.7)\n\n            # keep track of best inside population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n            # small maintenance: reset counters occasionally to avoid overflow\n            if gen % 100 == 0:\n                success_counts[:] = (success_counts * 0.6).astype(int)\n                try_counts[:] = (try_counts * 0.9).astype(int) + 1\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AIRES scored 0.439 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "d69d92c9-8b06-4d06-bd45-db0cc1d62d31", "operator": null, "metadata": {"aucs": [0.1327293547180024, 0.1555767696881587, 0.8715040991057896, 0.9879558745513265, 0.22555553424424546, 0.9811333681601829, 0.24388892833997433, 0.4807514295163011, 0.17792169779617995, 0.13671176672528595]}, "task_prompt": ""}
{"id": "1711e851-3643-4e93-bf42-180f165a6a79", "fitness": 0.33380423144961363, "name": "TriModeDEAdaptiveLocal", "description": "The algorithm is a hybrid evolutionary strategy that blends three mutation modes (p-best DE, covariance-guided Gaussian steps, and focused uniform jumps) whose selection probabilities are adapted online from success counts (mode_smooth=0.2) while jDE-style per-individual F/CR adaptation maintains diverse operator settings. The DE mode uses a p-best fraction (p_frac=0.25) with binomial crossover, the Gaussian mode samples multivariate normals from an archive-/population-derived covariance scaled by avg_span to make step sizes dimension-aware, and the uniform mode performs focused/localized jumps around the current best with a decaying radius plus occasional heavy‑tailed Student-t global jumps for exploration. Intensification is provided by an adaptive coordinate-descent local search (initial_step_frac=0.25, expand=1.3, shrink=0.5, local_budget_frac=0.03) triggered periodically or on stagnation, with nudges and rare worst-replacements to maintain diversity. Practical safeguards include stratified quasi-uniform initialization with jitter, bound reflection/clamping, a small elite archive for covariance estimation, compact population sized by dim, and strict budget-aware evaluation bookkeeping.", "code": "import numpy as np\n\nclass TriModeDEAdaptiveLocal:\n    \"\"\"\n    Tri-modal Adaptive DE + Local Coordinate Descent\n\n    Main idea (one line): Blend three mutation \"modes\" (p-best DE, covariance-guided Gaussian steps, and focused uniform jumps),\n    adapt the mode probabilities online by success, use jDE-style per-individual F/CR, keep a small elite archive for covariance,\n    and intensify with an adaptive coordinate-descent local search when promising or stagnating.\n\n    Main tunable parameters (defaults chosen differently from the provided algorithm):\n    - pop selection: smaller compact population (base on dim)\n    - jDE adaptation rates: tau1=0.08, tau2=0.08, F in [0.1, 0.9]\n    - p-best fraction: 0.25\n    - mode initial probabilities: [0.45 (DE), 0.35 (Gaussian), 0.20 (Uniform-focused)]\n    - mode adaptation smoothing: 0.2\n    - local search: adaptive coordinate descent with initial_step_frac=0.25, expand=1.3, shrink=0.5, local_budget_frac=0.03\n    - global_jump uses Student-t (df=2) heavy tails\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # jDE-style adaptation\n        self.tau1 = 0.08\n        self.tau2 = 0.08\n        self.F_min = 0.1\n        self.F_max = 0.9\n\n        # mutation modes and p-best\n        self.p_frac = 0.25\n        self.mode_weights = np.array([0.45, 0.35, 0.20], dtype=float)  # DE, Gaussian, Uniform-focused\n        self.mode_smooth = 0.2  # smoothing of mode adaptation\n        self.mode_success = np.zeros(3, dtype=float)\n        self.mode_trials = np.zeros(3, dtype=float)\n\n        # local search parameters (adaptive coordinate descent)\n        self.local_period = 16\n        self.local_stagn_gen = 30\n        self.local_budget_frac = 0.03\n        self.initial_step_frac = 0.25\n        self.expand = 1.3\n        self.shrink = 0.5\n        self.min_step_frac = 1e-5\n\n        # archive\n        self.archive_size = None  # auto adapt\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # population size: compact, different from original\n        pop = max(8, int(3 + 2 * np.log(max(2, self.dim))))\n        pop = min(pop, max(2, self.budget))\n        # archive size\n        if self.archive_size is None:\n            archive_k = max(2, min(6, pop // 2))\n        else:\n            archive_k = int(self.archive_size)\n\n        # budget and state\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f,x), sorted\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # clamp to bounds (strict)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = float(func(x))\n            evals += 1\n            # update best\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # maintain archive\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # initialize population with quasi-uniform stratified sampling + jitter\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        X += (rng.rand(pop, self.dim) - 0.5) * (0.4 * span / max(1.0, self.dim))\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            res = eval_and_record(X[i])\n            if res is None:\n                break\n            f[i], X[i] = res\n\n        # ensure at least one evaluated\n        if x_best is None:\n            while evals < self.budget:\n                x0 = rng.uniform(lb, ub)\n                res = eval_and_record(x0)\n                if res is None:\n                    break\n                break\n\n        # jDE-style F and CR initialization (different bounds)\n        F = np.clip(0.5 + 0.15 * rng.randn(pop), self.F_min, self.F_max)\n        CR = np.clip(rng.rand(pop), 0.0, 1.0)\n\n        # strategy state\n        gen = 0\n        gens_since_improve = 0\n        pnum_min = max(2, int(np.ceil(self.p_frac * pop)))\n\n        def reflect_bounds(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # estimate covariance from archive/pop for Gaussian mode\n        def estimate_cov(scale=0.08):\n            # try archive first\n            if len(archive) >= 3:\n                xs = np.vstack([a[1] for a in archive])\n                cov = np.cov(xs.T)\n            else:\n                # fallback to small-sample covariance from population\n                cov = np.cov(X.T) if pop >= 2 else np.eye(self.dim)\n            # ensure positivity and scale\n            cov = np.atleast_2d(cov)\n            # regularize\n            cov = cov + np.eye(self.dim) * (1e-8 * avg_span**2)\n            return cov * (scale * avg_span)**2\n\n        # local coordinate descent (adaptive steps)\n        def local_coordinate_descent(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            xcur = x_start.copy()\n            fcur = float(f_start)\n            step = max(1e-12, self.initial_step_frac * avg_span * (0.9 + 0.2 * rng.rand()))\n            steps = np.full(self.dim, step, dtype=float)\n            local_evals = 0\n            while local_evals < local_budget and evals < self.budget and np.any(steps > (self.min_step_frac * avg_span)):\n                improved_this_round = False\n                for i in range(self.dim):\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    # plus\n                    xp = xcur.copy()\n                    xp[i] = np.minimum(xp[i] + steps[i], ub[i])\n                    res = eval_and_record(xp)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < fcur:\n                        xcur = xp.copy()\n                        fcur = fp\n                        steps[i] *= self.expand\n                        improved_this_round = True\n                        continue\n                    # minus\n                    xn = xcur.copy()\n                    xn[i] = np.maximum(xn[i] - steps[i], lb[i])\n                    res = eval_and_record(xn)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < fcur:\n                        xcur = xn.copy()\n                        fcur = fn\n                        steps[i] *= self.expand\n                        improved_this_round = True\n                    else:\n                        steps[i] *= self.shrink\n                if not improved_this_round:\n                    steps *= self.shrink\n            return fcur, xcur\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # ranking and p-best pool\n            order = np.argsort(f)\n            p_pool = order[:max(pnum_min, 2)]\n\n            # iterate individuals in random order\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                # jDE adaptation\n                if rng.rand() < self.tau1:\n                    F[ii] = np.clip(0.45 + 0.5 * rng.rand(), self.F_min, self.F_max)\n                if rng.rand() < self.tau2:\n                    CR[ii] = rng.rand()\n\n                # choose mutation mode by weights\n                mode = rng.choice(3, p=self.mode_weights)\n\n                # prepare components\n                xi = X[ii].copy()\n\n                trial = xi.copy()\n                if mode == 0:\n                    # p-best / 1 like DE differential mutation\n                    pbest_idx = rng.choice(p_pool)\n                    pool = [j for j in range(pop) if j not in (ii, pbest_idx)]\n                    if len(pool) < 2:\n                        r1 = r2 = ii\n                    else:\n                        r1, r2 = rng.choice(pool, size=2, replace=False)\n                    xp = X[pbest_idx].copy()\n                    xr1 = X[r1].copy()\n                    xr2 = X[r2].copy()\n                    vi = xi + F[ii] * (xp - xi) + F[ii] * (xr1 - xr2)\n                    # binomial crossover\n                    jrand = rng.randint(self.dim)\n                    mask = (rng.rand(self.dim) < CR[ii])\n                    mask[jrand] = True\n                    trial = np.where(mask, vi, xi)\n                    trial = reflect_bounds(trial)\n                elif mode == 1:\n                    # covariance-guided Gaussian mutation (multivariate normal)\n                    cov = estimate_cov(scale=0.07)\n                    try:\n                        step = rng.multivariate_normal(np.zeros(self.dim), cov)\n                    except Exception:\n                        step = rng.randn(self.dim) * (0.07 * avg_span)\n                    # center around xi or around best sometimes\n                    center = xi if rng.rand() < 0.6 or x_best is None else x_best\n                    trial = center + step * (0.8 + 0.4 * rng.rand())\n                    # small crossover to keep some genes\n                    mask = (rng.rand(self.dim) < (0.5 + 0.5 * CR[ii]))\n                    trial = np.where(mask, trial, xi)\n                    trial = reflect_bounds(trial)\n                else:\n                    # focused uniform jump near best (radius decays with gen)\n                    if x_best is None:\n                        center = rng.uniform(lb, ub)\n                    else:\n                        center = x_best\n                    radius = avg_span * max(0.06, 0.5 * np.exp(-0.02 * gen))\n                    trial = center + rng.uniform(-1.0, 1.0, size=self.dim) * radius\n                    # mix with xi to keep diversity\n                    mask = (rng.rand(self.dim) < CR[ii])\n                    trial = np.where(mask, trial, xi)\n                    trial = reflect_bounds(trial)\n\n                # evaluate trial\n                if evals >= self.budget:\n                    break\n                res = eval_and_record(trial)\n                if res is None:\n                    break\n                fv, trial = res\n\n                # selection and mode bookkeeping\n                self.mode_trials[mode] += 1.0\n                if fv <= f[ii]:\n                    # success\n                    X[ii] = trial\n                    f[ii] = fv\n                    self.mode_success[mode] += 1.0\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = trial.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # occasionally replace worst with small prob to maintain diversity\n                    if rng.rand() < 0.002:\n                        worst = int(np.argmax(f))\n                        X[worst] = trial.copy()\n                        f[worst] = fv\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # adapt mode_weights based on smoothed success rates\n            success_rates = (self.mode_success / (self.mode_trials + 1e-9))\n            # avoid zero vector\n            if np.sum(success_rates) > 0:\n                new_weights = success_rates / (np.sum(success_rates) + 1e-12)\n                self.mode_weights = (1.0 - self.mode_smooth) * self.mode_weights + self.mode_smooth * new_weights\n                # ensure small floor\n                self.mode_weights = np.maximum(self.mode_weights, 0.01)\n                self.mode_weights /= np.sum(self.mode_weights)\n\n            # occasional heavy-tailed global jump guided by best/archive\n            if len(archive) > 0 and rng.rand() < 0.18:\n                # use Student-t (df=2) heavy tails\n                center = archive[0][1] if rng.rand() < 0.8 else archive[rng.randint(0, len(archive))][1]\n                df = 2.0\n                tstep = rng.standard_t(df, size=self.dim)\n                scale = max(0.05, 0.5 * np.exp(-0.015 * gen))\n                cand = center + tstep * (scale * avg_span * (0.6 + 0.8 * rng.rand()))\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is not None:\n                    f_cand, cand = res\n                    if f_cand < f_best:\n                        # local intensification if candidate is promising\n                        local_alloc = min(int(self.local_budget_frac * self.budget) * 2, self.budget - evals)\n                        local_alloc = max(1, local_alloc)\n                        f_after, x_after = local_coordinate_descent(cand, f_cand, local_alloc)\n                        if f_after < np.max(f):\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = x_after.copy()\n                            f[worst_idx] = f_after\n                            if f_after < f_best:\n                                f_best = f_after\n                                x_best = x_after.copy()\n                                gens_since_improve = 0\n\n            # periodic or stagnation-triggered local search around best\n            remaining = self.budget - evals\n            if remaining > 0 and (gen % self.local_period == 0 or gens_since_improve >= self.local_stagn_gen):\n                alloc = int(max(1, min(int(self.local_budget_frac * self.budget), remaining)))\n                if gens_since_improve >= self.local_stagn_gen:\n                    alloc = min(remaining, alloc * 4)\n                if x_best is not None and alloc > 0:\n                    f_after, x_after = local_coordinate_descent(x_best, f_best, alloc)\n                    if f_after < f_best:\n                        worst_idx = int(np.argmax(f))\n                        X[worst_idx] = x_after.copy()\n                        f[worst_idx] = f_after\n                        f_best = f_after\n                        x_best = x_after.copy()\n                        gens_since_improve = 0\n                    else:\n                        # small nudges if still stagnating\n                        if gens_since_improve >= self.local_stagn_gen:\n                            nudges = min(pop // 2, max(1, int((gens_since_improve - self.local_stagn_gen + 1))))\n                            for k in range(nudges):\n                                if evals >= self.budget:\n                                    break\n                                jitter = rng.randn(self.dim) * (0.03 * span)\n                                newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                                res = eval_and_record(newx)\n                                if res is None:\n                                    break\n                                fv, newx = res\n                                worst_idx = int(np.argmax(f))\n                                X[worst_idx] = newx.copy()\n                                f[worst_idx] = fv\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = newx.copy()\n                                    gens_since_improve = 0\n\n            # occasional uniform injection\n            if (gen % 29) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                res = eval_and_record(xu)\n                if res is not None:\n                    fu, xu = res\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = xu.copy()\n                    f[worst_idx] = fu\n                    if fu < f_best:\n                        f_best = fu\n                        x_best = xu.copy()\n                        gens_since_improve = 0\n\n            # update archive with current best\n            if x_best is not None:\n                if len(archive) < archive_k or f_best < archive[-1][0]:\n                    archive.append((float(f_best), x_best.copy()))\n                    archive.sort(key=lambda t: t[0])\n                    if len(archive) > archive_k:\n                        archive.pop()\n\n            # ensure best tracked from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n            # tiny safeguard: break if budget exhausted\n            if evals >= self.budget:\n                break\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm TriModeDEAdaptiveLocal scored 0.334 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "d69d92c9-8b06-4d06-bd45-db0cc1d62d31", "operator": null, "metadata": {"aucs": [0.16553691604984644, 0.16418469458570728, 0.6943989256974625, 0.1948814004837729, 0.28837092350857496, 0.8614066391351445, 0.22987578551990595, 0.313640422816991, 0.26903439696072995, 0.1567122097380007]}, "task_prompt": ""}
{"id": "ee5e0b1b-9638-4448-a6da-33faf9154157", "fitness": 0.27882757887602916, "name": "EigenMomentumSearch", "description": "EigenMomentumSearch uses a small, budget-aware population with per-individual momentum vectors (momentum_gamma=0.7) and three complementary operators — a DE-like p-best directed move (F_base≈0.6, p_frac=0.2), a momentum-driven local push, and a PCA-guided global probe sampled from an archive — to capture both recent successful displacements and anisotropic structure. Operator mixing is learned online via exponential-recoupling success scores (op_learn_beta=0.12) turned into softmax-like probabilities, while a scalar trust radius (init ~0.25·span) expands on successes and contracts on failures to adapt step sizes. Initialization is stratified LHS with jitter for coverage, an archive of best points is maintained and used for PCA/eigenvector probes and occasional probes/reinjections, and periodic radial intensification focuses budgeted spherical samples around the current best. Robustness features include reflect-with-clamp bound handling, momentum decay on failures, and budget-respecting sequential evaluation and archive maintenance.", "code": "import numpy as np\n\nclass EigenMomentumSearch:\n    \"\"\"\n    Eigen-Momentum Adaptive Search (EMAS)\n\n    Main ideas / novel pieces:\n    - Small population with per-individual momentum vectors that capture recent successful displacements.\n    - Three complementary operators: directed \"DE-like\" moves, momentum-driven local pushes, and PCA-eigenvector\n      global probes sampled from an archive covariance (captures anisotropic structure).\n    - Adaptive operator mixing probabilities learned online from short-term success statistics (softmax-ish).\n    - Adaptive trust-radius (per-population scalar) that expands on success and contracts on failures.\n    - Budget-aware radial intensification around the best using spherical/quasi-random radial samples.\n    - Robust bound handling using a reflection-with-clamp scheme; Latin-hypercube style init for coverage.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None, pop_size=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        # user-provided or auto\n        self.pop_size = pop_size\n\n        # Tunables (sensible defaults chosen for BBOB-like ranges [-5,5])\n        self.p_frac = 0.2  # fraction used for p-best directed operator\n        self.F_base = 0.6  # base scaling for directed moves\n        self.momentum_gamma = 0.7  # momentum retention\n        self.trust_init_frac = 0.25\n        self.trust_expand = 1.12\n        self.trust_shrink = 0.75\n        self.trust_min_frac = 1e-4\n        self.trust_max_frac = 1.5\n\n        # radial intensification parameters\n        self.radial_period = 17\n        self.radial_samples = 6\n        self.radial_shrink = 0.7\n\n        # operator learning\n        self.op_learn_beta = 0.12  # exponential recency for success counts\n\n        # archive size\n        self.archive_k = None  # auto-set\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # population size (small and budget-aware)\n        if self.pop_size is None:\n            pop = max(8, int(6 + 2 * np.sqrt(max(1, self.dim))))\n        else:\n            pop = int(self.pop_size)\n        pop = min(pop, max(2, self.budget // 5))  # leave evaluations for other ops\n        pop = max(2, pop)\n\n        # archive size\n        if self.archive_k is None:\n            archive_k = max(4, min(12, pop))\n        else:\n            archive_k = int(self.archive_k)\n\n        # budget/eval wrapper\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of tuples (f, x), sorted by f ascending\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # reflect-with-clamp bound handling: reflect until inside, then clamp\n            x = reflect_and_clamp(x, lb, ub)\n            f = float(func(x))\n            evals += 1\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # maintain archive\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # Latin-hypercube like initialization (per-dim stratified)\n        def lhs_samples(n):\n            # generate n samples in [0,1]^dim\n            cut = np.linspace(0.0, 1.0, n + 1)\n            u = rng.rand(n, self.dim)\n            a = cut[:n]\n            b = cut[1:n + 1]\n            samples = np.zeros((n, self.dim))\n            for j in range(self.dim):\n                idx = rng.permutation(n)\n                samples[:, j] = u[:, j] * (b - a) + a\n                samples[:, j] = np.clip(samples[:, j], 0.0, 1.0)\n                samples[:, j] = samples[idx, j]\n            return samples\n\n        # reflection utility (separate function)\n        def reflect_and_clamp(x, lb, ub):\n            xr = x.copy()\n            for i in range(xr.size):\n                if xr[i] < lb[i] or xr[i] > ub[i]:\n                    # reflect iteratively with decreasing overshoot\n                    # single reflection step to reduce chance of infinite loop\n                    if xr[i] < lb[i]:\n                        xr[i] = lb[i] + (lb[i] - xr[i])\n                    if xr[i] > ub[i]:\n                        xr[i] = ub[i] - (xr[i] - ub[i])\n                    # still might be outside; clamp finally\n                    if xr[i] < lb[i] or xr[i] > ub[i]:\n                        xr[i] = np.minimum(np.maximum(xr[i], lb[i]), ub[i])\n            return xr\n\n        # initialize population X with LHS mapped to bounds and jitter\n        X = np.zeros((pop, self.dim), dtype=float)\n        S = lhs_samples(pop)\n        X = lb[np.newaxis, :] + S * (ub - lb)[np.newaxis, :]\n        # jitter proportional to span/dim to break strict stratification\n        jitter_scale = 0.08 * span / max(1.0, self.dim)\n        X += (rng.randn(*X.shape) * jitter_scale)\n        for i in range(pop):\n            X[i] = np.minimum(np.maximum(X[i], lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            res = eval_and_record(X[i])\n            if res is None:\n                break\n            f[i], X[i] = res\n\n        # ensure at least one eval succeeded\n        if x_best is None:\n            # sample a random point and evaluate, but budget obeyed\n            while evals < self.budget:\n                x0 = rng.uniform(lb, ub)\n                res = eval_and_record(x0)\n                if res is None:\n                    break\n                break\n\n        # state variables\n        momentum = np.zeros((pop, self.dim), dtype=float)   # per-individual momentum\n        trust = max(self.trust_min_frac * avg_span, self.trust_init_frac * avg_span)  # scalar trust radius (in absolute units)\n        # operator success trackers (small positive initial counts)\n        ops = ['directed', 'momentum', 'pca']\n        op_score = np.array([1.0, 1.0, 1.0], dtype=float)\n        op_prob = op_score / np.sum(op_score)\n\n        gen = 0\n        gens_since_improve = 0\n        pnum_min = max(2, int(np.ceil(self.p_frac * pop)))\n\n        # utility: compute PCA from archive points (if enough) and return top eigenvector and scale\n        def archive_pca_direction():\n            if len(archive) < 2:\n                # fallback to random direction\n                v = rng.randn(self.dim)\n                v /= (np.linalg.norm(v) + 1e-12)\n                scale = 1.0\n                return v, scale\n            pts = np.vstack([a[1] for a in archive])\n            mean = np.mean(pts, axis=0)\n            C = np.cov((pts - mean).T)\n            # regularize\n            C += np.eye(self.dim) * 1e-8 * avg_span\n            try:\n                w, V = np.linalg.eigh(C)\n                idx = np.argsort(w)[::-1]\n                top_vec = V[:, idx[0]]\n                top_val = max(1e-12, w[idx[0]])\n                # direction sign randomize a bit\n                if rng.rand() < 0.5:\n                    top_vec = -top_vec\n                return top_vec / (np.linalg.norm(top_vec) + 1e-12), float(np.sqrt(top_val))\n            except Exception:\n                v = rng.randn(self.dim)\n                v /= (np.linalg.norm(v) + 1e-12)\n                return v, 1.0\n\n        # small helper to pick p-best index (prefer best but allow some variety)\n        def pick_pbest_index():\n            order = np.argsort(f)\n            pool_sz = max(pnum_min, 2)\n            pool = order[:pool_sz]\n            # weighted towards best\n            if rng.rand() < 0.7:\n                return pool[0]\n            else:\n                return int(rng.choice(pool))\n\n        # radial (spherical) quasi-random samples: generate points roughly evenly on sphere radii\n        def radial_samples_around(xc, radius, n):\n            # use gaussian then normalize -> gives uniform on sphere\n            samples = []\n            for _ in range(n):\n                v = rng.randn(self.dim)\n                v /= (np.linalg.norm(v) + 1e-12)\n                r = radius * (0.3 + 0.7 * rng.rand())  # randomize radius fraction\n                samples.append(xc + v * r)\n            return samples\n\n        # Main optimization loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n            # sort for p-best selection\n            order = np.argsort(f)\n            # adapt op_probs via softmax-like normalization\n            op_prob = np.exp(op_score) / np.sum(np.exp(op_score))\n\n            # iterate individuals in random order\n            indices = rng.permutation(pop)\n            for ii in indices:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fi = float(f[ii])\n\n                # pick operator using op_prob\n                op_choice = rng.choice(len(ops), p=op_prob)\n\n                # operator implementations (produce candidate candidate)\n                candidate = None\n                # 1) Directed DE-like operator (uses p-best and two randoms)\n                if op_choice == 0:\n                    pidx = pick_pbest_index()\n                    # choose two distinct others\n                    pool = [j for j in range(pop) if j != ii and j != pidx]\n                    if len(pool) >= 2:\n                        r1, r2 = rng.choice(pool, size=2, replace=False)\n                        r1v, r2v = X[r1], X[r2]\n                    elif len(pool) == 1:\n                        r1v = X[pool[0]]\n                        r2v = X[pool[0]]\n                    else:\n                        r1v = xi\n                        r2v = xi\n                    pbest = X[pidx]\n                    F = max(0.05, min(0.95, self.F_base * (0.8 + 0.4 * rng.rand())))\n                    # mixture equation: directed + difference scaled + small random isotropic noise\n                    candidate = xi + F * (pbest - xi) + 0.5 * F * (r1v - r2v) + (rng.randn(self.dim) * 0.03 * span)\n                    # scale by trust radius influence\n                    candidate = xi + (candidate - xi) * (min(1.0, trust / (0.5 * avg_span)))\n                # 2) Momentum-driven local push (momentum vector + gaussian)\n                elif op_choice == 1:\n                    m = momentum[ii]\n                    sigma = (0.2 + 0.8 * rng.rand()) * (trust / max(1e-12, avg_span))\n                    candidate = xi + m + rng.randn(self.dim) * sigma * avg_span\n                # 3) PCA-guided global probe\n                else:\n                    v, eigscale = archive_pca_direction()\n                    # sample along eigenvector with heavy-tailed factor: student-t like by using randn/|u|\n                    u = rng.randn()\n                    t_scale = np.abs(u) + 0.05\n                    step = v * (t_scale * (1.6 + 0.8 * rng.rand()) * eigscale * avg_span)\n                    # also add orthogonal gaussian\n                    orth = rng.randn(self.dim)\n                    orth -= orth.dot(v) * v  # remove component along v\n                    orth *= (0.06 * avg_span)\n                    candidate = (x_best if x_best is not None else xi) + step + orth\n                    # occasionally bias toward distant archive member\n                    if len(archive) >= 2 and rng.rand() < 0.25:\n                        aidx = rng.randint(0, len(archive))\n                        candidate = 0.6 * candidate + 0.4 * archive[aidx][1]\n\n                # enforce bounds by reflection/clamp\n                candidate = reflect_and_clamp(candidate, lb, ub)\n\n                # evaluate candidate\n                if evals >= self.budget:\n                    break\n                res = eval_and_record(candidate)\n                if res is None:\n                    break\n                fc, x_cand = res\n\n                # success criteria: improvement for that individual (or improvement over global best)\n                success = False\n                if fc < fi:\n                    # accept candidate: replace individual and update momentum\n                    displacement = x_cand - xi\n                    momentum[ii] = self.momentum_gamma * momentum[ii] + (1.0 - self.momentum_gamma) * displacement\n                    X[ii] = x_cand.copy()\n                    f[ii] = fc\n                    success = True\n                    if fc < f_best:\n                        f_best = fc\n                        x_best = x_cand.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # no improvement: penalize momentum and shrink trust slightly\n                    momentum[ii] *= (0.9 - 0.2 * rng.rand())\n\n                # update operator scores with exponential recency\n                if success:\n                    op_score[op_choice] = (1.0 - self.op_learn_beta) * op_score[op_choice] + self.op_learn_beta * 2.0\n                    # expand trust mildly on success\n                    trust = min(self.trust_max_frac * avg_span, trust * self.trust_expand)\n                else:\n                    op_score[op_choice] = (1.0 - self.op_learn_beta) * op_score[op_choice] + self.op_learn_beta * 0.5\n                    trust = max(self.trust_min_frac * avg_span, trust * self.trust_shrink)\n\n                # safety clamp for trust\n                trust = np.clip(trust, self.trust_min_frac * avg_span, self.trust_max_frac * avg_span)\n\n            # end per-individual loop\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n            else:\n                gens_since_improve = 0\n\n            # Periodic radial intensification around current best\n            if evals < self.budget and (gen % self.radial_period == 0 or gens_since_improve > 5):\n                # compute a modest budget slice for radial sampling\n                remaining = self.budget - evals\n                nrad = min(self.radial_samples, max(1, remaining // 50))\n                if nrad <= 0:\n                    nrad = min(self.radial_samples, remaining)\n                rad = trust * (0.8 + 0.6 * rng.rand())\n                if x_best is None:\n                    x_center = X[np.argmin(f)]\n                else:\n                    x_center = x_best\n                candidates = radial_samples_around(x_center, rad, nrad)\n                # evaluate radial candidates sequentially\n                for cand in candidates:\n                    if evals >= self.budget:\n                        break\n                    res = eval_and_record(cand)\n                    if res is None:\n                        break\n                    fc, xc = res\n                    if fc < np.max(f):\n                        worst = int(np.argmax(f))\n                        X[worst] = xc.copy()\n                        f[worst] = fc\n                        # update momentum of worst slot to small displacement\n                        momentum[worst] = 0.5 * (xc - x_center)\n                        if fc < f_best:\n                            f_best = fc\n                            x_best = xc.copy()\n                            gens_since_improve = 0\n                            # expand trust because radial found something\n                            trust = min(self.trust_max_frac * avg_span, trust * 1.25)\n                # shrink trust after radial to focus\n                trust = max(self.trust_min_frac * avg_span, trust * self.radial_shrink)\n\n            # Occasionally re-evaluate/evaluate a small \"probe\" population around diverse archive members\n            if evals < self.budget and (gen % (self.radial_period * 2) == 0):\n                if len(archive) >= 2:\n                    # probe around one random archive member using small gaussian radius\n                    aidx = rng.randint(0, len(archive))\n                    center = archive[aidx][1]\n                    nprobe = min(3, self.budget - evals)\n                    for _ in range(nprobe):\n                        if evals >= self.budget:\n                            break\n                        probe = center + rng.randn(self.dim) * (0.06 * avg_span)\n                        res = eval_and_record(probe)\n                        if res is None:\n                            break\n                        fp, xp = res\n                        if fp < np.max(f):\n                            worst = int(np.argmax(f))\n                            X[worst] = xp.copy()\n                            f[worst] = fp\n                            momentum[worst] = 0.5 * (xp - center)\n                            if fp < f_best:\n                                f_best = fp\n                                x_best = xp.copy()\n                                gens_since_improve = 0\n\n            # occasional random reinjection of worst individuals when stagnating\n            if gens_since_improve > 12 and evals < self.budget:\n                nrepl = max(1, min(pop // 3, (gens_since_improve - 12)))\n                for _ in range(nrepl):\n                    if evals >= self.budget:\n                        break\n                    xnew = rng.uniform(lb, ub)\n                    res = eval_and_record(xnew)\n                    if res is None:\n                        break\n                    fn, xn = res\n                    worst = int(np.argmax(f))\n                    X[worst] = xn.copy()\n                    f[worst] = fn\n                    momentum[worst] = np.zeros(self.dim)\n                    if fn < f_best:\n                        f_best = fn\n                        x_best = xn.copy()\n                        gens_since_improve = 0\n\n            # ensure archive has current best inserted (already done in eval_and_record),\n            # but we may update op_score gently to avoid collapse\n            op_score = np.maximum(op_score, 1e-3)\n\n            # also ensure best from population is tracked\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finalization: if no best recorded but archive has entries\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n\n        # package result\n        self.f_opt = float(f_best) if f_best is not None else np.inf\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EigenMomentumSearch scored 0.279 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "d69d92c9-8b06-4d06-bd45-db0cc1d62d31", "operator": null, "metadata": {"aucs": [0.09444573880363327, 0.15645603920567952, 0.524213407486697, 0.4955110535852819, 0.29021222335925, 0.3077632629634408, 0.22989417154395386, 0.28418023113282553, 0.26523875936881935, 0.14036090131070988]}, "task_prompt": ""}
{"id": "a3bc4d69-e5b9-4e5b-978f-d1f819ab52a1", "fitness": 0.5234299130520371, "name": "DirectionalGaussianStudentHybrid", "description": "The algorithm is a small-population hybrid that mixes three proposal generators—directional DE-like moves (p_directional=0.45), covariance-informed multivariate Gaussians (p_cov=0.35) and mirrored/opposition moves—augmented by occasional heavy-tailed Student-t jumps (student_prob=0.12, df=3) for global exploration. It uses budget-aware design choices: a compact population (pop_base=9 with log(dim) scaling), quasi‑uniform stratified initialization, strict evaluation counting and bound reflection+clamp to keep all evaluations valid. Each individual carries an adaptive per‑individual sigma (init_sigma_frac=0.22 of avg span) that is increased on success (succ_inc=1.25) and decreased on failure (fail_dec=0.82) within tight min/max fractions to balance local search and robustness. An elite archive and a regularized elite covariance estimate (elite_frac=0.25, cov_reg) seed covariance proposals and Student-t injections, while budget-aware local coordinate descent (local_period=20, local_stagn=30, local_budget_frac=0.03) and mild randomization under stagnation provide intensification and escape mechanisms.", "code": "import numpy as np\n\nclass DirectionalGaussianStudentHybrid:\n    \"\"\"\n    Directional Gaussian–Student Hybrid (DGSH)\n\n    Main idea:\n    - Small population with per-individual adaptive Gaussian scale (sigma).\n    - Combine three proposal generators: (A) directional differential-like move towards elite,\n      (B) covariance-informed Gaussian perturbation using an elite covariance estimate,\n      (C) mirrored/opposition move relative to the current best.\n    - Occasional heavy-tailed Student-t jumps for global exploration.\n    - Per-individual sigma adapted by simple success rule (increase on success, decrease on failure).\n    - Small budget-aware local coordinate descent when stagnating.\n    - Strict evaluation counting, bound reflection+clamp, and an elite archive to seed covariance.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # algorithm hyper-parameters (different from the provided algorithm)\n        self.pop_base = 9                       # baseline pop (small, budget-aware)\n        self.pop_scale = 2.0                    # factor with log(dim)\n        self.init_sigma_frac = 0.22             # initial sigma relative to avg span\n        self.succ_inc = 1.25                    # sigma multiplier on success\n        self.fail_dec = 0.82                    # sigma multiplier on failure\n        self.sigma_min_frac = 1e-6\n        self.sigma_max_frac = 1.6\n\n        self.p_directional = 0.45               # probability to use directional DE-like move\n        self.p_cov = 0.35                       # probability to use covariance-informed Gaussian\n        # remainder uses mirrored/opposition\n        self.student_prob = 0.12                # occasional Student-t heavy-tailed jumps\n        self.student_df = 3.0                   # degrees of freedom for Student-t\n\n        self.elite_frac = 0.25                  # fraction of pop used to estimate covariance\n        self.cov_reg = 1e-6\n\n        self.local_period = 20                  # gens between local descent attempts\n        self.local_stagn = 30                   # gens without improve to trigger local intensification\n        self.local_budget_frac = 0.03           # fraction of total budget for a local search call\n        self.local_shrink = 0.6                 # shrink factor for local coordinate steps\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds handling (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # population size (novel small-pop formula)\n        pop = max(self.pop_base, int(self.pop_base + self.pop_scale * np.log(max(2, self.dim))))\n        pop = min(pop, max(2, self.budget))\n        top_k = max(2, int(np.ceil(self.elite_frac * pop)))\n\n        # budget counter and eval wrapper\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of tuples (f, x) sorted by f\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # reflection then clamp to bounds for robustness\n            x = reflect_bounds(x)\n            f = float(func(x))\n            evals += 1\n            # update best\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # archive maintenance (keep few best)\n            if len(archive) < top_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > top_k:\n                    archive.pop()\n            return f, x\n\n        def reflect_bounds(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            # clamp after reflection to ensure inside bounds\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # quasi-uniform stratified initialization (different jitter scale)\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter with a slightly larger jitter than the reference algorithm\n        X += (rng.rand(pop, self.dim) - 0.5) * (0.8 * span / max(1.0, self.dim))\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            res = eval_and_record(X[i])\n            if res is None:\n                break\n            f[i], X[i] = res\n\n        # ensure we have at least one point\n        if x_best is None:\n            while evals < self.budget:\n                x0 = rng.uniform(lb, ub)\n                res = eval_and_record(x0)\n                if res is None:\n                    break\n                f0, x0 = res\n                break\n\n        # per-individual sigma (scale) for Gaussian proposals\n        sigma = np.clip(self.init_sigma_frac * avg_span * (1.0 + 0.3 * rng.randn(pop)),\n                        self.sigma_min_frac * avg_span,\n                        self.sigma_max_frac * avg_span)\n\n        # state\n        gen = 0\n        gens_since_improve = 0\n\n        # small budget-aware local coordinate descent\n        def local_coordinate_descent(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            x = x_start.copy()\n            fx = float(f_start)\n            # initial step is a fraction of avg_span (different constant)\n            step = max(1e-12, 0.12 * avg_span)\n            iters = 0\n            local_evals = 0\n            # iterate until step small or budget exhausted\n            while local_evals < local_budget and step > 1e-6 * avg_span:\n                improved = False\n                # scan coordinates\n                for d in range(self.dim):\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    xp = x.copy()\n                    xp[d] = np.minimum(xp[d] + step, ub[d])\n                    res = eval_and_record(xp)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < fx:\n                        x = xp.copy()\n                        fx = fp\n                        improved = True\n                        continue\n                    xn = x.copy()\n                    xn[d] = np.maximum(xn[d] - step, lb[d])\n                    res = eval_and_record(xn)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < fx:\n                        x = xn.copy()\n                        fx = fn\n                        improved = True\n                if not improved:\n                    step *= self.local_shrink\n                iters += 1\n                if evals >= self.budget:\n                    break\n            return fx, x\n\n        # helper to compute elite covariance (regularized)\n        def elite_covariance(elite_X):\n            if elite_X.shape[0] < 2:\n                return np.eye(self.dim) * (avg_span ** 2) * 1e-3\n            C = np.cov(elite_X, rowvar=False)\n            # ensure correct shape and regularize\n            if C.shape != (self.dim, self.dim):\n                C = np.atleast_2d(C)\n                C = np.eye(self.dim) * (np.diag(C) if C.shape[0] == self.dim else np.var(elite_X, axis=0))\n            reg = (self.cov_reg * (avg_span ** 2))\n            C += np.eye(self.dim) * reg\n            return C\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # ordering and elites\n            order = np.argsort(f)\n            elites = X[order[:max(1, top_k)]]\n            elite_fs = f[order[:max(1, top_k)]]\n            # update archive from current best\n            if x_best is not None:\n                if len(archive) < top_k or f_best < archive[-1][0]:\n                    archive.append((float(f_best), x_best.copy()))\n                    archive.sort(key=lambda t: t[0])\n                    if len(archive) > top_k:\n                        archive.pop()\n\n            # compute covariance from elites for covariance-informed proposals\n            cov = elite_covariance(elites)\n            # scale covariance by median sigma squared for stability\n            cov_scale = max(1e-12, np.median(sigma) ** 2)\n            cov_mat = cov * (cov_scale / (np.trace(cov) / max(1, self.dim) / (avg_span ** 2) + 1e-12))\n\n            # iterate individuals in random order\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fi = float(f[ii])\n\n                # pick proposal type\n                r = rng.rand()\n                if r < self.p_directional and pop >= 3:\n                    # directional DE-like move toward a random elite (not self)\n                    p_idx = order[rng.randint(0, min(pop, top_k))]\n                    pbest = X[p_idx].copy()\n                    # pick two distinct random indices\n                    pool = [j for j in range(pop) if j != ii and j != p_idx]\n                    if len(pool) >= 2:\n                        r1, r2 = rng.choice(pool, size=2, replace=False)\n                        xr1 = X[r1]\n                        xr2 = X[r2]\n                    elif len(pool) == 1:\n                        r1 = pool[0]\n                        xr1 = X[r1]\n                        xr2 = X[r1]\n                    else:\n                        xr1 = xr2 = xi\n                    F = 0.6 * (0.7 + 0.6 * rng.rand())  # different F sampling\n                    candidate = xi + F * (pbest - xi) + F * 0.9 * (xr1 - xr2)\n                elif r < self.p_directional + self.p_cov:\n                    # covariance-informed Gaussian centered at xi\n                    # sample multivariate normal via Cholesky or eigen-decomposition\n                    try:\n                        L = np.linalg.cholesky(cov_mat + np.eye(self.dim) * 1e-12)\n                        z = rng.randn(self.dim)\n                        perturb = L.dot(z) * (sigma[ii] / (np.sqrt(np.trace(cov_mat) / self.dim) + 1e-12))\n                    except np.linalg.LinAlgError:\n                        perturb = rng.randn(self.dim) * sigma[ii]\n                    candidate = xi + perturb\n                else:\n                    # mirrored/opposition move relative to current best with small noise\n                    if x_best is None:\n                        candidate = xi + rng.randn(self.dim) * sigma[ii]\n                    else:\n                        beta = 0.85 * (0.8 + 0.4 * rng.rand())\n                        candidate = x_best + beta * (x_best - xi) + rng.randn(self.dim) * (0.25 * sigma[ii])\n\n                # occasional heavy-tailed Student-t global jump\n                if rng.rand() < self.student_prob:\n                    # draw from standard Student-t and scale\n                    t_noise = rng.standard_t(self.student_df, size=self.dim)\n                    candidate = x_best + 1.0 * np.abs(sigma[ii]) * t_noise\n\n                # reflection/clamp\n                candidate = reflect_bounds(candidate)\n\n                # evaluate\n                if evals >= self.budget:\n                    break\n                res = eval_and_record(candidate)\n                if res is None:\n                    break\n                fc, candidate = res\n\n                # replacement and adaptation\n                if fc <= fi:\n                    X[ii] = candidate.copy()\n                    f[ii] = fc\n                    # success: increase sigma moderately\n                    sigma[ii] = min(self.sigma_max_frac * avg_span, sigma[ii] * self.succ_inc)\n                    if fc < f_best:\n                        f_best = fc\n                        x_best = candidate.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # failure: reduce sigma\n                    sigma[ii] = max(self.sigma_min_frac * avg_span, sigma[ii] * self.fail_dec)\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # occasional injection from Student-t around a random elite to keep exploration\n            if rng.rand() < 0.08 and evals < self.budget:\n                if len(archive) > 0:\n                    center = archive[rng.randint(0, len(archive))]\n                    center_x = center[1]\n                else:\n                    center_x = x_best if x_best is not None else rng.uniform(lb, ub)\n                t_noise = rng.standard_t(self.student_df, size=self.dim)\n                cand = center_x + 1.8 * (np.median(sigma) if np.isfinite(np.median(sigma)) else avg_span * 0.1) * t_noise\n                cand = reflect_bounds(cand)\n                res = eval_and_record(cand)\n                if res is not None:\n                    fc, cand = res\n                    # replace worst if better\n                    worst_idx = int(np.argmax(f))\n                    if fc < f[worst_idx]:\n                        X[worst_idx] = cand.copy()\n                        f[worst_idx] = fc\n                        # nudging sigma of replaced individual\n                        sigma[worst_idx] = max(self.sigma_min_frac * avg_span,\n                                              min(self.sigma_max_frac * avg_span, 1.2 * np.median(sigma)))\n\n            # periodic or stagnation-triggered local intensification (coordinate descent)\n            remaining = self.budget - evals\n            if remaining > 0 and (gen % self.local_period == 0 or gens_since_improve >= self.local_stagn):\n                alloc = int(max(1, min(int(self.local_budget_frac * self.budget), remaining)))\n                if gens_since_improve >= self.local_stagn:\n                    alloc = min(remaining, alloc * 4)\n                anchor = x_best.copy() if x_best is not None else X[np.argmin(f)].copy()\n                f_after, x_after = local_coordinate_descent(anchor, f_best if x_best is not None else np.min(f), alloc)\n                if f_after < f_best:\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_after.copy()\n                    f[worst_idx] = f_after\n                    f_best = f_after\n                    x_best = x_after.copy()\n                    gens_since_improve = 0\n                else:\n                    # mild randomization of a few individuals if heavy stagnation\n                    if gens_since_improve >= self.local_stagn:\n                        nm = min(pop // 2, 2 + (gens_since_improve - self.local_stagn) // 10)\n                        for _ in range(nm):\n                            if evals >= self.budget:\n                                break\n                            idx = rng.randint(0, pop)\n                            jitter = rng.randn(self.dim) * (0.06 * avg_span)\n                            newx = reflect_bounds(x_best + jitter) if x_best is not None else rng.uniform(lb, ub)\n                            res = eval_and_record(newx)\n                            if res is None:\n                                break\n                            fv, newx = res\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = newx.copy()\n                            f[worst_idx] = fv\n                            sigma[worst_idx] = max(self.sigma_min_frac * avg_span, 0.9 * np.median(sigma))\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = newx.copy()\n                                gens_since_improve = 0\n\n            # ensure best from population is recorded\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DirectionalGaussianStudentHybrid scored 0.523 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "d69d92c9-8b06-4d06-bd45-db0cc1d62d31", "operator": null, "metadata": {"aucs": [0.1287004631757097, 0.21874619335401568, 0.8177764761082844, 0.9891919723031202, 0.9442381565621666, 0.9501864852085669, 0.25924507871083635, 0.49006780960174556, 0.282833317222714, 0.15331317827321156]}, "task_prompt": ""}
{"id": "98c94b76-cbd9-44cf-b747-cfc253e95fad", "fitness": 0.4709307787019452, "name": "HybridAdaptiveLevyCMADE", "description": "The algorithm is a hybrid metaheuristic that blends a compact, CMA-like covariance learner (diag C, mean m, sigma initialized to 0.25*avg_span, cov_update=0.18, sigma_adapt_rate=0.22, success_target=0.2) with a jDE-style differential evolution (per-individual F≈0.6, CR random, tau1=tau2=0.12, current-to-pbest/1 using p_frac=0.2) and occasional heavy‑tailed Levy global jumps (standard Cauchy steps, global_jump_prob≈0.20) driven by a small elite archive (archive_k in 3–8). It uses adaptive operator selection (p_cma/p_de/p_levy updated from recent success counts), quasi‑uniform stratified initialization with jitter for diversity, and strict bound handling via reflection+clamp and chol_safe (eigen fallback) for numerical robustness. Periodic intensification is provided by a budget‑limited Hooke–Jeeves local search (local_period=16, local_budget_frac=0.035, pattern_factor=1.5) and opportunistic restarts that nudge the mean toward the best and inflate sigma on stagnation. Overall the design favors a small/population-light, multi‑operator strategy with adaptive control, archive‑guided exploration, and local refinement to balance global search and intensification under a tight evaluation budget.", "code": "import numpy as np\n\nclass HybridAdaptiveLevyCMADE:\n    \"\"\"\n    HybridAdaptiveLevyCMADE\n\n    Key ideas:\n      - Compact CMA-style covariance learning (m, C, sigma) to adapt search directions.\n      - Small population with jDE-style adaptation of F and CR for DE current-to-pbest/1 steps.\n      - Small elite archive driving occasional heavy-tailed Levy/global jumps.\n      - Adaptive operator-selection probabilities based on recent success rates (CMA / DE / Levy).\n      - Periodic budget-limited Hooke-Jeeves local search around the best solution for intensification.\n      - Bound reflection+clamp and numerical safeguards; strict evaluation budget accounting.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # population and operator settings\n        self.pop_base = None\n        self.p_frac = 0.2  # p-best fraction for DE\n        self.tau1 = 0.12\n        self.tau2 = 0.12\n        self.F_min = 0.05\n        self.F_max = 0.95\n\n        # CMA-like settings\n        self.cov_update = 0.18\n        self.sigma_adapt_rate = 0.22\n        self.success_target = 0.2\n\n        # Levy & archive\n        self.global_jump_prob = 0.20\n        self.archive_size = None\n\n        # local search settings\n        self.local_period = 16\n        self.local_budget_frac = 0.035\n        self.initial_step_frac = 0.18\n        self.pattern_factor = 1.5\n        self.shrink = 0.6\n        self.min_step_frac = 1e-5\n\n        # stagnation/restart\n        self.stagnation_threshold_iters = max(6, int(0.04 * self.budget))\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # population size (small)\n        if self.pop_base is None:\n            pop = max(12, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        # archive size\n        if self.archive_size is None:\n            archive_k = max(3, min(8, pop // 2))\n        else:\n            archive_k = int(self.archive_size)\n\n        # evaluation bookkeeping\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # reflect then clamp\n            below = x < lb\n            if np.any(below):\n                x[below] = lb[below] + (lb[below] - x[below])\n            above = x > ub\n            if np.any(above):\n                x[above] = ub[above] - (x[above] - ub[above])\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = float(func(x))\n            evals += 1\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # archive maintenance\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # quasi-uniform stratified initialization\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # small jitter\n        X += (rng.rand(pop, self.dim) - 0.5) * (0.5 * span / max(1.0, self.dim))\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            res = eval_and_record(X[i])\n            if res is None:\n                break\n            f[i], X[i] = res\n\n        if x_best is None:\n            while evals < self.budget:\n                x0 = rng.uniform(lb, ub)\n                res = eval_and_record(x0)\n                if res is None:\n                    break\n                f0, x0 = res\n                break\n\n        # initialize compact CMA state using population elites\n        lam0 = max(2, pop // 2)\n        order0 = np.argsort(f)\n        elites = X[order0[:lam0]]\n        weights0 = np.log(lam0 + 0.5) - np.log(np.arange(1, lam0 + 1))\n        weights0 = np.maximum(weights0, 0.0)\n        weights0 /= np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites).sum(axis=0)\n        bounds_scale = span\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.25 * avg_span)\n\n        # per-individual DE parameters (jDE)\n        F = np.clip(0.6 + 0.1 * rng.randn(pop), self.F_min, self.F_max)\n        CR = np.clip(rng.rand(pop), 0.0, 1.0)\n\n        # operator selection probabilities and success counters\n        p_cma = 0.45\n        p_de = 0.35\n        p_levy = 0.20\n        succ_cma = succ_de = succ_levy = 1e-6\n        tries_cma = tries_de = tries_levy = 1e-6\n\n        gen = 0\n        gens_since_improve = 0\n        stagn_iters = 0\n\n        # helper: robust chol / eigen correction\n        def chol_safe(M):\n            eps = 1e-12 * np.maximum(np.diag(M), 1.0)\n            try:\n                A = np.linalg.cholesky(M + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(M)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        # Levy-like heavy-tailed step\n        def global_jump_from(x_center, scale):\n            direction = rng.randn(self.dim)\n            nd = np.linalg.norm(direction) + 1e-12\n            direction /= nd\n            step_length = rng.standard_cauchy()\n            step_length = np.clip(step_length, -1e3, 1e3)\n            step = direction * (float(scale) * avg_span * (0.4 + 0.6 * rng.rand()))\n            return x_center + step_length * step\n\n        # Hooke-Jeeves local search (budget-limited)\n        def local_search(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            step0 = max(1e-12, self.initial_step_frac * avg_span * (0.8 + 0.4 * rng.rand()))\n            steps = np.full(self.dim, step0, dtype=float)\n            local_evals = 0\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_evals < local_budget and iters < iter_limit and np.any(steps > (self.min_step_frac * avg_span)):\n                iters += 1\n                improved = False\n                x_probe = base.copy()\n                x_probe_f = base_f\n                for i in range(self.dim):\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    xp = x_probe.copy()\n                    xp[i] = np.minimum(xp[i] + steps[i], ub[i])\n                    res = eval_and_record(xp)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < x_probe_f:\n                        x_probe = xp.copy()\n                        x_probe_f = fp\n                        improved = True\n                        continue\n                    xn = x_probe.copy()\n                    xn[i] = np.maximum(xn[i] - steps[i], lb[i])\n                    res = eval_and_record(xn)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < x_probe_f:\n                        x_probe = xn.copy()\n                        x_probe_f = fn\n                        improved = True\n                # pattern move\n                if improved and local_evals < local_budget and evals < self.budget:\n                    direction = x_probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + self.pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_and_record(xp)\n                        local_evals += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < x_probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = x_probe.copy()\n                                base_f = x_probe_f\n                        else:\n                            base = x_probe.copy()\n                            base_f = x_probe_f\n                    else:\n                        base = x_probe.copy()\n                        base_f = x_probe_f\n                else:\n                    steps *= self.shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # update operator probabilities from recent success ratios\n            total_succ = succ_cma + succ_de + succ_levy\n            p_cma = 0.4 * (succ_cma / total_succ) + 0.15\n            p_de = 0.35 * (succ_de / total_succ) + 0.10\n            p_levy = max(0.05, 1.0 - p_cma - p_de)\n            # normalize\n            s = p_cma + p_de + p_levy\n            p_cma /= s; p_de /= s; p_levy /= s\n\n            # prepare Cholesky for CMA sampling\n            A = chol_safe(C)\n\n            # prepare p-best pool\n            order = np.argsort(f)\n            p_pool_size = max(2, int(np.ceil(self.p_frac * pop)))\n            p_pool = order[:p_pool_size]\n\n            # offspring generation: each individual gets one candidate from a chosen operator\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                # jDE adaptation for this individual\n                if rng.rand() < self.tau1:\n                    F[ii] = np.clip(0.4 + 0.4 * rng.rand(), self.F_min, self.F_max)\n                if rng.rand() < self.tau2:\n                    CR[ii] = rng.rand()\n\n                # pick operator\n                r = rng.rand()\n                if r < p_cma:\n                    # CMA sample\n                    tries_cma += 1\n                    Z = rng.normal(size=self.dim)\n                    y = Z @ A.T\n                    cand = m + sigma * y\n                    cand = np.minimum(np.maximum(cand, lb), ub)\n                    res = eval_and_record(cand)\n                    if res is None:\n                        break\n                    fc, cand = res\n                    if fc <= f[ii]:\n                        succ_cma += 1\n                        X[ii] = cand.copy()\n                        f[ii] = fc\n                        if fc < f_best:\n                            f_best = fc; x_best = cand.copy(); improved_in_gen = True; gens_since_improve = 0\n                    else:\n                        gens_since_improve += 0  # no immediate increment here\n                elif r < p_cma + p_de:\n                    # DE current-to-pbest/1\n                    tries_de += 1\n                    pbest_idx = rng.choice(p_pool)\n                    pool = [j for j in range(pop) if j not in (ii, pbest_idx)]\n                    if len(pool) < 2:\n                        r1 = r2 = ii\n                    else:\n                        r1, r2 = rng.choice(pool, size=2, replace=False)\n                    xi = X[ii].copy()\n                    xp = X[pbest_idx].copy()\n                    xr1 = X[r1].copy()\n                    xr2 = X[r2].copy()\n                    vi = xi + F[ii] * (xp - xi) + F[ii] * (xr1 - xr2)\n                    jrand = rng.randint(self.dim)\n                    mask = (rng.rand(self.dim) < CR[ii])\n                    mask[jrand] = True\n                    trial = np.where(mask, vi, xi)\n                    # small chance to use a Levy-perturbed trial if archive promising\n                    if rng.rand() < 0.035 and len(archive) > 0:\n                        center = archive[0][1] if rng.rand() < 0.7 else archive[rng.randint(len(archive))][1]\n                        trial = global_jump_from(center, scale=0.6)\n                    trial = np.minimum(np.maximum(trial, lb), ub)\n                    res = eval_and_record(trial)\n                    if res is None:\n                        break\n                    fv, trial = res\n                    if fv <= f[ii]:\n                        succ_de += 1\n                        X[ii] = trial.copy()\n                        f[ii] = fv\n                        if fv < f_best:\n                            f_best = fv; x_best = trial.copy(); improved_in_gen = True; gens_since_improve = 0\n                    else:\n                        pass\n                else:\n                    # Levy global jump from archive or from m\n                    tries_levy += 1\n                    if len(archive) > 0 and rng.rand() < 0.8:\n                        center = archive[0][1]\n                    else:\n                        center = m if rng.rand() < 0.6 else X[rng.randint(pop)]\n                    cand = global_jump_from(center, scale=max(0.06, 1.0 - 0.012 * gen))\n                    cand = np.minimum(np.maximum(cand, lb), ub)\n                    res = eval_and_record(cand)\n                    if res is None:\n                        break\n                    fc, cand = res\n                    if fc <= f[ii]:\n                        succ_levy += 1\n                        X[ii] = cand.copy()\n                        f[ii] = fc\n                        if fc < f_best:\n                            f_best = fc; x_best = cand.copy(); improved_in_gen = True; gens_since_improve = 0\n                    else:\n                        pass\n\n            # Update success rates smoothing\n            total_tries = tries_cma + tries_de + tries_levy\n            if total_tries > 0:\n                # small smoothing to keep probabilities bounded\n                succ_cma = max(1e-6, succ_cma)\n                succ_de = max(1e-6, succ_de)\n                succ_levy = max(1e-6, succ_levy)\n\n            # Update compact CMA mean and covariance from current population elites\n            lam = max(2, pop // 2)\n            order = np.argsort(f)\n            X_mu = X[order[:lam]]\n            weights = np.log(lam + 0.5) - np.log(np.arange(1, lam + 1))\n            weights = np.maximum(weights, 0.0)\n            weights /= np.sum(weights)\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas\n            C = (1.0 - self.cov_update) * C + self.cov_update * weighted_cov\n            # update mean and sigma using smoothed success-rate rule\n            improved_flag = improved_in_gen\n            if improved_flag:\n                stagn_iters = 0\n            else:\n                stagn_iters += 1\n            # success estimate from recent improvement frequency\n            p_succ = (succ_cma + succ_de + succ_levy) / (total_tries + 1e-12)  # rough\n            sigma *= np.exp(self.sigma_adapt_rate * (min(0.9, p_succ) - self.success_target))\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n            m = m_new.copy()\n\n            # periodic local search around best\n            remaining = self.budget - evals\n            if remaining > 0 and (gen % self.local_period == 0 or stagn_iters >= (self.local_period * 2)):\n                alloc = int(max(1, min(int(self.local_budget_frac * self.budget), remaining)))\n                if stagn_iters >= (self.local_period * 2):\n                    alloc = min(remaining, alloc * 3)\n                f_after, x_after = local_search(x_best, f_best, alloc)\n                if f_after < f_best:\n                    # inject into population replacing worst\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_after.copy()\n                    f[worst_idx] = f_after\n                    f_best = f_after; x_best = x_after.copy()\n                    gens_since_improve = 0\n                    improved_in_gen = True\n\n            # archive maintenance and adapt global jump probability by diversity\n            if x_best is not None:\n                if len(archive) < archive_k or f_best < archive[-1][0]:\n                    archive.append((float(f_best), x_best.copy()))\n                    archive.sort(key=lambda t: t[0])\n                    if len(archive) > archive_k:\n                        archive.pop()\n            if len(archive) >= 2:\n                diversity = np.linalg.norm(archive[0][1] - archive[-1][1])\n                if diversity < 0.01 * avg_span + 1e-9:\n                    self.global_jump_prob = min(0.65, self.global_jump_prob + 0.02)\n                else:\n                    self.global_jump_prob = max(0.05, self.global_jump_prob * 0.995)\n\n            # opportunistic restart if long stagnation\n            if stagn_iters * pop >= self.stagnation_threshold_iters and evals < self.budget:\n                stagn_iters = 0\n                # nudge mean to best with jitter and inflate sigma moderately\n                jitter = 0.6 * sigma * (1.0 + 0.5 * rng.rand(self.dim))\n                if x_best is not None:\n                    m = x_best + rng.randn(self.dim) * jitter\n                else:\n                    m = lb + rng.rand(self.dim) * span\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                sigma = max(sigma, 0.5 * avg_span)\n                # diversify population by stratified jitter around m\n                for i in range(pop):\n                    X[i] = m + rng.randn(self.dim) * (0.8 * sigma)\n                    X[i] = np.minimum(np.maximum(X[i], lb), ub)\n                    if evals < self.budget:\n                        res = eval_and_record(X[i])\n                        if res is None:\n                            break\n                        f[i], X[i] = res\n\n            # finalize generation housekeeping\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n            # early exit if budget exhausted\n            if evals >= self.budget:\n                break\n\n        # finalize result\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveLevyCMADE scored 0.471 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "d69d92c9-8b06-4d06-bd45-db0cc1d62d31", "operator": null, "metadata": {"aucs": [0.1777618259314493, 0.1497310458871357, 0.5264120644747621, 0.9907117410667466, 0.34425346783645205, 0.8471854511005976, 0.2600985454036594, 0.47857001041012814, 0.784849530960956, 0.14973410394756448]}, "task_prompt": ""}
{"id": "2f7a407b-c333-49b8-98cb-2df036704c2c", "fitness": "-inf", "name": "HFAMS_APLS", "description": "HFAMS_APLS is a hybrid explorer/exploiter that mixes archive-anchored heavy‑tailed global jumps with probe-based local searches: global moves use Cauchy-like jumps around archived elites (initial global_jump_prob=0.22, anchor biased to best) plus occasional uniform injections and jittered restarts near the best (jitter_scale=0.12, uniform_inject_period=41) to preserve diversity. Local exploitation is driven by a small population of probes seeded from the archive that perform parabolic directional probing (orthogonal directions via QR), momentum extrapolation (mom update 0.6/0.4 and momentum decay), and budget-aware Hooke–Jeeves / pattern mini-searches (pattern_shrink=0.6, pattern_factor=1.5, local_budget_frac≈0.03) to refine promising areas. Adaptation and robustness are provided by archive maintenance (adaptive archive_size and probe_count), softmax probe selection with a tunable temperature and stagnation counter, probe radius adaptation, bounds clipping/scaling by avg_span, and limited Cauchy clipping to avoid extreme steps. Everything is strictly budget-aware (central eval counter, local searches constrained by remaining budget) with many safeguards (eval checks, clipping, probe pruning/refreshing) to work reliably across varying dimensions and the [-5,5] search range.", "code": "import numpy as np\n\nclass HFAMS_APLS:\n    \"\"\"\n    Hybrid Fractal Adaptive Multi-Scale Search with APLS-inspired escapes (HFAMS_APLS)\n\n    One-line: Combine FAMS-style probes (parabolic directional probing + momentum) with APLS-style\n    heavy-tailed archive-anchored jumps and Hooke-Jeeves mini-local searches, all strictly budget-aware.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 init_samples=None, archive_size=None, probe_count=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.probe_count = probe_count\n\n        # APLS-inspired knobs\n        self.global_jump_prob = 0.22\n        self.local_budget_frac = 0.03\n        self.pattern_shrink = 0.6\n        self.pattern_factor = 1.5\n        self.jitter_scale = 0.12  # jitter around best for restarts\n        self.uniform_inject_period = 41\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        max_span = float(np.max(span))\n\n        # adaptive defaults\n        if self.init_samples is None:\n            init_samples = max(12, min(60, 6 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, self.budget)\n\n        if self.archive_size is None:\n            archive_k = max(4, min(12, init_samples // 3))\n        else:\n            archive_k = int(self.archive_size)\n\n        if self.probe_count is None:\n            probe_count = max(2, min(12, archive_k))\n        else:\n            probe_count = int(self.probe_count)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of tuples (f, x), sorted by f\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # clip to bounds\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            # update best\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # insert into archive\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        # initial sampling (uniform)\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one point\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # initialize probes from archive top entries (or random)\n        probes = []\n        for i in range(min(probe_count, len(archive))):\n            f0, x0 = archive[i]\n            probe = {\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': max(0.08 * avg_span, 0.25 * avg_span * (0.9 ** i)),\n                'mom': np.zeros(self.dim, dtype=float),\n                'age': 0\n            }\n            probes.append(probe)\n        # if not enough probes, create from uniform samples\n        while len(probes) < probe_count and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            res = eval_and_record(x0)\n            if res is None:\n                break\n            f0, x0 = res\n            probes.append({\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': 0.25 * avg_span,\n                'mom': np.zeros(self.dim, dtype=float),\n                'age': 0\n            })\n\n        sel_temp = 1.0\n        attempt = 0\n        stagn_counter = 0\n\n        # Hooke-Jeeves like small local search around a point (budget-aware)\n        def mini_pattern_search(x_start, f_start, local_budget, step0):\n            nonlocal evals, f_best, x_best\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            steps = np.full(self.dim, float(step0))\n            local_evals = 0\n            iters = 0\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            while local_evals < local_budget and iters < iter_limit and np.any(steps > 1e-12) and evals < self.budget:\n                iters += 1\n                improved = False\n                probe = base.copy()\n                probe_f = base_f\n                for i in range(self.dim):\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    # positive\n                    xp = probe.copy()\n                    xp[i] += steps[i]\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res = eval_and_record(xp)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < probe_f:\n                        probe = xp.copy()\n                        probe_f = fp\n                        improved = True\n                        continue\n                    # negative\n                    xn = probe.copy()\n                    xn[i] -= steps[i]\n                    xn = np.minimum(np.maximum(xn, lb), ub)\n                    res = eval_and_record(xn)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < probe_f:\n                        probe = xn.copy()\n                        probe_f = fn\n                        improved = True\n                # pattern move\n                if improved and local_evals < local_budget and evals < self.budget:\n                    direction = probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + self.pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_and_record(xp)\n                        local_evals += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = probe.copy()\n                                base_f = probe_f\n                        else:\n                            base = probe.copy()\n                            base_f = probe_f\n                    else:\n                        base = probe.copy()\n                        base_f = probe_f\n                else:\n                    steps *= self.pattern_shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # global heavy-tailed jump generator (Cauchy-like) anchored on a center\n        def cauchy_jump(center, scale):\n            # random direction\n            dirv = rng.randn(self.dim)\n            n = np.linalg.norm(dirv) + 1e-12\n            dirv = dirv / n\n            # cauchy scalar\n            s = rng.standard_cauchy()\n            s = np.clip(s, -1e3, 1e3)\n            step = dirv * (float(scale) * avg_span * (0.4 + 0.6 * rng.rand()))\n            return center + s * step\n\n        # main loop\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            if remaining <= 0:\n                break\n\n            # choose between global jump vs probe-based local work\n            if rng.rand() < self.global_jump_prob and len(archive) > 0 and remaining > 1:\n                # pick anchor: best more often\n                if rng.rand() < 0.75:\n                    anchor = archive[0][1]\n                else:\n                    anchor = archive[rng.randint(0, len(archive))]\n                cand = cauchy_jump(anchor, scale=0.9)\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                fcand, xcand = res\n                # if promising, perform a small local pattern search\n                if remaining > 3 and (fcand <= (archive[0][0] if len(archive)>0 else np.inf) * 1.12):\n                    loc_budget = min(max(3, int(self.local_budget_frac * self.budget)), remaining - 1)\n                    mini_pattern_search(xcand, fcand, loc_budget, step0=0.12 * avg_span)\n            else:\n                # probe selection via softmax on -f\n                fs = np.array([p['f'] for p in probes], dtype=float)\n                z = -fs / max(1e-9, sel_temp)\n                probs = np.exp(z - np.max(z))\n                probs /= probs.sum()\n                idx = rng.choice(len(probes), p=probs)\n                probe = probes[idx]\n                x0 = probe['x'].copy()\n                f0 = probe['f']\n                r0 = probe['r']\n\n                improved_any = False\n\n                # small parabolic directional probing (like FAMS)\n                k = min(self.dim, max(1, int(np.ceil(np.sqrt(self.dim)))))\n                k = min(k, 3)\n                A = rng.randn(self.dim, k)\n                try:\n                    Q, _ = np.linalg.qr(A)\n                except Exception:\n                    Q = A / (np.linalg.norm(A, axis=0, keepdims=True) + 1e-12)\n                directions = [Q[:, j] for j in range(k)]\n\n                for d in directions:\n                    if evals >= self.budget:\n                        break\n                    s = r0 * (0.6 + 0.8 * rng.rand())\n                    step = d * s\n                    x_minus = np.minimum(np.maximum(x0 - step, lb), ub)\n                    resm = eval_and_record(x_minus)\n                    if resm is None:\n                        break\n                    f_minus, x_minus = resm\n\n                    x_plus = np.minimum(np.maximum(x0 + step, lb), ub)\n                    resp = eval_and_record(x_plus)\n                    if resp is None:\n                        break\n                    f_plus, x_plus = resp\n\n                    # parabola fit\n                    denom = (f_minus + f_plus - 2.0 * f0)\n                    x_candidate = None\n                    f_candidate = None\n                    if abs(denom) > 1e-12:\n                        t_star = 0.5 * (f_minus - f_plus) / denom\n                        t_star = float(np.clip(t_star, -2.0, 2.0))\n                        x_parab = x0 + t_star * step\n                        x_parab = np.minimum(np.maximum(x_parab, lb), ub)\n                        respb = eval_and_record(x_parab)\n                        if respb is None:\n                            pass\n                        else:\n                            f_parab, x_parab = respb\n                            x_candidate = x_parab\n                            f_candidate = f_parab\n\n                    # select best among evaluated for this direction\n                    cand_list = [(f_minus, x_minus), (f_plus, x_plus), (f0, x0)]\n                    if x_candidate is not None:\n                        cand_list.append((f_candidate, x_candidate))\n                    cand_list.sort(key=lambda t: t[0])\n                    best_dir_f, best_dir_x = cand_list[0]\n\n                    if best_dir_f + 1e-12 < probe['f']:\n                        old_x = probe['x'].copy()\n                        probe['x'] = best_dir_x.copy()\n                        probe['f'] = float(best_dir_f)\n                        move = probe['x'] - old_x\n                        probe['mom'] = 0.6 * probe['mom'] + 0.4 * move\n                        probe['r'] = min(probe['r'] * 1.25, 2.0 * avg_span)\n                        probe['age'] = 0\n                        improved_any = True\n                        stagn_counter = 0\n                    else:\n                        probe['r'] = max(1e-8, probe['r'] * 0.66)\n                        probe['age'] += 1\n                        stagn_counter += 1\n\n                # momentum extrapolation\n                if evals < self.budget and np.linalg.norm(probe['mom']) > 1e-8:\n                    alpha = 0.8\n                    xm = probe['x'] + alpha * probe['mom']\n                    xm = np.minimum(np.maximum(xm, lb), ub)\n                    resm = eval_and_record(xm)\n                    if resm is not None:\n                        fm, xm = resm\n                        if fm + 1e-12 < probe['f']:\n                            probe['x'] = xm.copy()\n                            probe['f'] = float(fm)\n                            probe['r'] = min(probe['r'] * 1.3, 2.0 * avg_span)\n                            probe['mom'] *= 0.8\n                            improved_any = True\n                            stagn_counter = 0\n                        else:\n                            probe['mom'] *= 0.5\n\n                # if probe improved, do a small Hooke-Jeeves style mini search around it\n                if improved_any and evals < self.budget:\n                    loc_budget = min(max(3, int(self.local_budget_frac * self.budget)), self.budget - evals)\n                    if loc_budget > 0:\n                        _ = mini_pattern_search(probe['x'], probe['f'], loc_budget, step0=0.08 * avg_span)\n                        # mini_pattern_search updates archive and global best internally\n\n                # occasionally jitter around global best to diversify\n                if attempt % 7 == 0 and len(archive) > 0 and evals < self.budget:\n                    base = archive[0][1]\n                    jitter = self.jitter_scale * avg_span * rng.randn(self.dim)\n                    xj = np.minimum(np.maximum(base + jitter, lb), ub)\n                    resj = eval_and_record(xj)\n                    if resj is not None:\n                        fj, xj = resj\n                        # replace a poor probe with this jitter if good\n                        worst_idx = int(np.argmax([p['f'] for p in probes]))\n                        if fj < probes[worst_idx]['f']:\n                            probes[worst_idx] = {\n                                'x': xj.copy(),\n                                'f': float(fj),\n                                'r': 0.25 * avg_span,\n                                'mom': np.zeros(self.dim, dtype=float),\n                                'age': 0\n                            }\n\n            # occasional uniform injection\n            if (attempt % self.uniform_inject_period) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # archive diversity feedback to adapt global jump probability\n            if len(archive) >= 2:\n                div = np.linalg.norm(archive[0][1] - archive[-1][1])\n                if div < 1e-9 + 0.01 * avg_span:\n                    self.global_jump_prob = min(0.6, self.global_jump_prob + 0.03)\n                else:\n                    self.global_jump_prob = max(0.05, self.global_jump_prob * 0.995)\n\n            # prune/refresh probes when necessary\n            if len(probes) > probe_count:\n                probes.sort(key=lambda p: p['f'])\n                probes = probes[:probe_count]\n            # if too few probes, add jittered probe near best\n            if len(probes) < probe_count and len(archive) > 0 and evals < self.budget:\n                base = archive[0][1]\n                jitter = 0.12 * avg_span * rng.randn(self.dim)\n                xn = np.minimum(np.maximum(base + jitter, lb), ub)\n                resn = eval_and_record(xn)\n                if resn is not None:\n                    fn, xn = resn\n                    probes.append({\n                        'x': xn.copy(),\n                        'f': float(fn),\n                        'r': 0.25 * avg_span,\n                        'mom': np.zeros(self.dim, dtype=float),\n                        'age': 0\n                    })\n\n            # slowly adapt selection temperature\n            if stagn_counter > 30:\n                sel_temp = min(5.0, sel_temp * 1.04)\n            else:\n                sel_temp = max(0.3, sel_temp * 0.997)\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 214, in cauchy_jump, the following error occurred:\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\nOn line: return center + s * step", "error": "In the code, line 214, in cauchy_jump, the following error occurred:\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\nOn line: return center + s * step", "parent_ids": "d69d92c9-8b06-4d06-bd45-db0cc1d62d31", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "fa12d762-4676-473b-ae52-3a6a217e6133", "fitness": 0.3036137743009523, "name": "ASTProbe", "description": "AST-Probe keeps a single incumbent x_best and an adaptive scalar trust radius r (initialized as r_init_frac*mean(range) and bounded by r_min_frac/r_max_frac) and performs small \"epochs\" of directional probes (probes_per_epoch ≈ O(√dim)) around the center, growing r by 1.15 on improvement and shrinking by 0.66 on failure to adapt exploration scale. Directions come from an evolving compact orthonormal subspace B (sub_dim ≈ ceil(√dim)) plus occasional random directions, with bandit-style softmax weights on basis columns and a history of successful directions/rewards used to rebuild B by weighted SVD every rot_update_period epochs. Each probe runs an opportunistic 1-D doubling line-search along a direction (try positive then negative), accepting immediate improvements and doubling step on success or halving on failure, supplemented by low-rank Gaussian sampling in the learned subspace, rare Lévy-like heavy-tailed jumps for escapes, and reflect-then-clamp bound handling. A small elite archive and stagnation mechanisms (mild reseed around elites, occasional jittered restarts) prevent premature convergence, and careful budgeting ensures the algorithm never exceeds the user-specified function-evaluation budget.", "code": "import numpy as np\n\nclass ASTProbe:\n    \"\"\"\n    Adaptive Subspace Trust-region Probing (AST-Probe)\n\n    Main features:\n    - Keeps a single center (x_best) and an adaptive trust radius r (scalar).\n    - Generates directional probes from an evolving compact orthonormal basis (subspace)\n      learned from previously successful directions, combined with occasional random directions.\n    - Each probe performs an opportunistic 1-D doubling line search along the chosen direction,\n      trying both positive and negative senses, with step control based on the trust radius.\n    - Subspace Gaussian sampling: occasional low-rank gaussian perturbations inside learned subspace.\n    - Bandit-style reward bookkeeping for basis columns to bias future direction choices (softmax).\n    - Rare Lévy-like heavy-tailed jumps to escape traps.\n    - Simple reflect-then-clamp bounds handling.\n    - Observes the function evaluation budget exactly.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 sub_dim=None, init_samples=None,\n                 r_init_frac=0.25, r_min_frac=1e-5, r_max_frac=1.0,\n                 probes_per_epoch=None, rot_update_period=15,\n                 levy_prob=0.03, levy_scale_frac=0.5,\n                 stagnation_restart=40, rng_seed=None):\n        \"\"\"\n        budget: allowed function evaluations\n        dim: problem dimensionality\n        sub_dim: dimensionality of learned subspace (defaults to ceil(sqrt(dim)) or at least 1)\n        init_samples: number of initial random samples (defaults to min(max(4,2*dim), budget//8))\n        r_init_frac: initial trust radius as fraction of mean bound range\n        r_min_frac, r_max_frac: min/max trust radius fractions of mean bound range\n        probes_per_epoch: how many directional probes per iteration (default ~ sqrt(dim) clipped)\n        rot_update_period: epochs between basis rebuilds from successful directions\n        levy_prob: probability of applying a Lévy-like jump each epoch\n        levy_scale_frac: scale of Lévy jump relative to mean range\n        stagnation_restart: epochs without improvement before mild reseed\n        rng_seed: random seed\n        \"\"\"\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.sub_dim = int(sub_dim) if sub_dim is not None else max(1, int(np.ceil(np.sqrt(dim))))\n        self.init_samples = init_samples\n        self.r_init_frac = float(r_init_frac)\n        self.r_min_frac = float(r_min_frac)\n        self.r_max_frac = float(r_max_frac)\n        self.probes_per_epoch = probes_per_epoch\n        self.rot_update_period = int(rot_update_period)\n        self.levy_prob = float(levy_prob)\n        self.levy_scale_frac = float(levy_scale_frac)\n        self.stagnation_restart = int(stagnation_restart)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # extract bounds and normalize shapes\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # mean range\n        range_mean = float(np.mean(ub - lb))\n        if range_mean <= 0:\n            range_mean = 1.0\n\n        # initial trust radius\n        r = max(1e-12, self.r_init_frac * range_mean)\n        r_min = max(1e-12, self.r_min_frac * range_mean)\n        r_max = max(r_min, self.r_max_frac * range_mean)\n\n        # initial sampling budget for warm start\n        if self.init_samples is None:\n            n0 = min(max(4, 2 * self.dim), max(1, self.budget // 8))\n        else:\n            n0 = int(min(max(1, self.init_samples), self.budget))\n        evals = 0\n\n        # reflect-then-clamp\n        def reflect_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        # initial random exploration (Latin-ish jittered)\n        X0 = np.empty((n0, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(n0)\n            strata = (np.arange(n0) + 0.5) / n0\n            X0[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        X0 += (rng.rand(n0, self.dim) - 0.5) * (0.5 * (ub - lb) / max(1.0, self.dim))\n        X0 = np.minimum(np.maximum(X0, lb), ub)\n\n        f0 = np.full(n0, np.inf, dtype=float)\n        for i in range(n0):\n            if evals >= self.budget:\n                break\n            f0[i] = float(func(X0[i]))\n            evals += 1\n\n        # ensure we have at least one evaluated point\n        if evals == 0:\n            x_rand = np.minimum(np.maximum(lb + rng.rand(self.dim) * (ub - lb), lb), ub)\n            f_rand = float(func(x_rand))\n            evals += 1\n            x_best = x_rand.copy()\n            f_best = f_rand\n        else:\n            best_idx = int(np.argmin(f0[:min(n0, evals)]))\n            x_best = X0[best_idx].copy()\n            f_best = float(f0[best_idx])\n\n        # subspace basis: start with orthonormal random matrix (dim x sub_dim)\n        m = min(self.sub_dim, self.dim)\n        # construct orthonormal basis B (dim x m)\n        B = np.linalg.svd(rng.randn(self.dim, m), full_matrices=False)[0][:, :m]\n        # bandit-like weights for each basis vector (for selection)\n        weights = np.ones(m, dtype=float)\n\n        # store recent successful directions (for rotation update)\n        succ_dirs = []\n        succ_rewards = []\n\n        # probe counts etc.\n        if self.probes_per_epoch is None:\n            probes_per_epoch = min(6, max(2, int(np.ceil(np.sqrt(self.dim)))))\n        else:\n            probes_per_epoch = int(self.probes_per_epoch)\n\n        epoch = 0\n        epochs_since_improve = 0\n        # small archive of elites\n        archive = [(f_best, x_best.copy())]\n\n        # main loop: repeatedly perform small epochs of probes until budget exhausted\n        while evals < self.budget:\n            epoch += 1\n            improved_this_epoch = False\n\n            # decide number of probes (cap to remaining budget)\n            k = min(probes_per_epoch, max(1, (self.budget - evals)))\n            for probe_idx in range(k):\n                if evals >= self.budget:\n                    break\n\n                # Select direction:\n                # With prob p_choose_basis choose a basis vector (weighted softmax); else a random orth direction\n                p_choose_basis = 0.7\n                if rng.rand() < p_choose_basis and m > 0:\n                    # softmax sampling\n                    exps = np.exp(weights - np.max(weights))\n                    probs = exps / np.sum(exps)\n                    j = rng.choice(m, p=probs)\n                    d = B[:, j].copy()\n                    source_tag = ('basis', j)\n                else:\n                    # random Gaussian direction normalized\n                    d = rng.randn(self.dim)\n                    nd = np.linalg.norm(d)\n                    if nd == 0.0:\n                        continue\n                    d /= nd\n                    source_tag = ('rand', None)\n\n                # small local perturbation to avoid exact repeats\n                d += 1e-12 * rng.randn(self.dim)\n                d /= np.linalg.norm(d)\n\n                # initial step length for this probe drawn log-uniform around r\n                # sample multiplicative factor between 0.25 and 1.5 loosely\n                factor = float(0.5 + 1.5 * (rng.rand() ** 2))\n                alpha0 = r * factor\n\n                # opportunistic probe: try positive direction first, then negative. Doubling on success, halving on failure.\n                def try_direction(sign):\n                    nonlocal evals, x_best, f_best\n                    alpha = alpha0 * (1.0 if sign > 0 else -1.0)\n                    local_improved = False\n                    total_reward = 0.0\n                    # allow a few doubling steps but guard budget and bounds\n                    for step_iter in range(10):\n                        if evals >= self.budget:\n                            break\n                        x_try = reflect_clamp(x_best + alpha * d)\n                        # skip if identical\n                        if np.allclose(x_try, x_best):\n                            alpha *= 0.5\n                            if abs(alpha) < r_min * 1e-3:\n                                break\n                            continue\n                        f_try = float(func(x_try))\n                        evals += 1\n                        if f_try < f_best:\n                            # success: accept at center (we update x_best immediately)\n                            reward = (f_best - f_try)\n                            f_best = f_try\n                            x_best = x_try.copy()\n                            total_reward += reward\n                            local_improved = True\n                            # continue doubling to exploit\n                            alpha *= 2.0\n                        else:\n                            # not better: shrink step (we keep center unchanged)\n                            alpha *= 0.5\n                        # stop if step too small\n                        if abs(alpha) < r_min * 1e-6:\n                            break\n                    return local_improved, total_reward\n\n                # Try positive then negative\n                pos_impr, pos_reward = try_direction(+1)\n                neg_impr, neg_reward = (False, 0.0)\n                if not pos_impr and evals < self.budget:\n                    neg_impr, neg_reward = try_direction(-1)\n\n                any_impr = pos_impr or neg_impr\n                reward = pos_reward + neg_reward\n\n                if any_impr:\n                    improved_this_epoch = True\n                    epochs_since_improve = 0\n                    # record direction (use sign of net improvement by projecting center movement onto d)\n                    move = None\n                    # find last archive best (we're tracking x_best)\n                    # derive effective direction: difference between improved point and previous archive best if available\n                    if len(archive) > 0:\n                        prev_best = archive[0][1]\n                        move = x_best - prev_best\n                    else:\n                        move = x_best - x_best  # zero\n                    if np.linalg.norm(move) > 0:\n                        dir_vec = move / (np.linalg.norm(move) + 1e-12)\n                    else:\n                        dir_vec = d.copy()\n                    succ_dirs.append(dir_vec)\n                    succ_rewards.append(max(1e-12, reward))\n                    # update archive\n                    archive.append((f_best, x_best.copy()))\n                    archive.sort(key=lambda t: t[0])\n                    if len(archive) > 10:\n                        archive = archive[:10]\n                    # boost weight of selected basis vector if it was chosen from basis\n                    if source_tag[0] == 'basis' and source_tag[1] is not None:\n                        weights[source_tag[1]] += reward\n                else:\n                    epochs_since_improve += 0.0  # not penalize heavily per probe\n\n            # After probes: trust region adaptation\n            if improved_this_epoch:\n                r = min(r_max, r * 1.15)\n            else:\n                r = max(r_min, r * 0.66)\n\n            # occasional subspace Gaussian sampling (low-rank exploration)\n            if evals < self.budget and rng.rand() < 0.5:\n                # sample in the subspace spanned by B: x_try = x_best + B * z\n                if m > 0:\n                    z = rng.randn(m) * (0.6 * r)\n                    x_try = reflect_clamp(x_best + B.dot(z))\n                else:\n                    x_try = reflect_clamp(x_best + rng.randn(self.dim) * (0.6 * r))\n                f_try = float(func(x_try))\n                evals += 1\n                if f_try < f_best:\n                    # accept\n                    reward = (f_best - f_try)\n                    f_best = f_try\n                    x_best = x_try.copy()\n                    improved_this_epoch = True\n                    succ_dirs.append((x_try - archive[0][1]) / (np.linalg.norm(x_try - archive[0][1]) + 1e-12) if archive else z)\n                    succ_rewards.append(max(1e-12, reward))\n                    archive.insert(0, (f_best, x_best.copy()))\n                    archive = sorted(archive, key=lambda t: t[0])[:10]\n\n            # occasional Lévy-like jump\n            if evals < self.budget and rng.rand() < self.levy_prob:\n                # heavy-tailed using scaled Cauchy with tuned clipping\n                step_size = self.levy_scale_frac * range_mean * (1.0 + abs(rng.standard_cauchy()))\n                step_vec = rng.randn(self.dim)\n                step_vec /= (np.linalg.norm(step_vec) + 1e-12)\n                x_try = reflect_clamp(x_best + step_vec * step_size)\n                f_try = float(func(x_try))\n                evals += 1\n                if f_try < f_best:\n                    reward = (f_best - f_try)\n                    f_best = f_try\n                    x_best = x_try.copy()\n                    improved_this_epoch = True\n                    succ_dirs.append(step_vec)\n                    succ_rewards.append(max(1e-12, reward))\n                    archive.insert(0, (f_best, x_best.copy()))\n                    archive = sorted(archive, key=lambda t: t[0])[:10]\n\n            # Periodic basis rebuild from recent successful directions\n            if (epoch % self.rot_update_period == 0) and len(succ_dirs) > 0:\n                # form matrix of weighted directions\n                D = np.vstack(succ_dirs)\n                w = np.asarray(succ_rewards, dtype=float)\n                w = w / np.sum(w)\n                # centerless weighted covariance-like matrix: (D^T * W * D)\n                # build weighted matrix by sqrt weights and SVD\n                sqrtw = np.sqrt(w)[:, None]\n                Dw = D * sqrtw\n                # compute SVD for principal directions\n                try:\n                    U, svals, Vt = np.linalg.svd(Dw, full_matrices=False)\n                except np.linalg.LinAlgError:\n                    # fallback to QR of random matrix if SVD fails\n                    Vt = np.linalg.qr(rng.randn(self.dim, Dw.shape[0]))[0].T\n                # leading left singular vectors correspond to row-space; we want basis in R^dim, given by Vt.T\n                # Vt shape: (min(#succ, dim), dim) so take the first m columns of Vt.T\n                if Vt.shape[0] >= 1:\n                    # Build new B by taking top-m principal directions\n                    B_new = Vt.T[:, :m]\n                    # orthonormalize (in case)\n                    try:\n                        Q, _ = np.linalg.qr(B_new)\n                        B = Q[:, :m]\n                    except np.linalg.LinAlgError:\n                        # ignore and keep old B\n                        pass\n                # decay succ_dirs to keep recent memory\n                # keep only last 5*m entries\n                keep = max(0, len(succ_dirs) - 5 * m)\n                if keep > 0:\n                    succ_dirs = succ_dirs[-(5 * m):]\n                    succ_rewards = succ_rewards[-(5 * m):]\n\n                # slightly reset weights to avoid lock-in\n                weights = 0.9 * weights + 0.1 * (1.0 + rng.rand(m))\n\n            # stagnation mild reseed: sample around elite archive entries\n            if epochs_since_improve >= self.stagnation_restart or len(archive) == 0:\n                epochs_since_improve = 0\n                # replace a few candidate directions by random small perturbations of best archive members\n                for _ in range(min(3, max(1, m))):\n                    if evals >= self.budget:\n                        break\n                    # sample one elite and jitter it\n                    if len(archive) > 0:\n                        _, xp = archive[rng.randint(len(archive))]\n                    else:\n                        xp = x_best\n                    jitter = rng.randn(self.dim) * (0.08 * range_mean)\n                    x_try = reflect_clamp(xp + jitter)\n                    f_try = float(func(x_try))\n                    evals += 1\n                    if f_try < f_best:\n                        f_best = f_try\n                        x_best = x_try.copy()\n                        archive.insert(0, (f_best, x_best.copy()))\n                        archive = sorted(archive, key=lambda t: t[0])[:10]\n                        # store direction\n                        dvec = (x_try - xp)\n                        if np.linalg.norm(dvec) > 0:\n                            succ_dirs.append(dvec / (np.linalg.norm(dvec) + 1e-12))\n                            succ_rewards.append(max(1e-12, (f_best - f_try)))\n                # slightly expand trust region to encourage exploration\n                r = min(r_max, r * 1.5)\n\n            # maintain archive size and keep best\n            archive = sorted(archive, key=lambda t: t[0])[:20]\n            # immediate sync (redundant but explicit)\n            if archive and archive[0][0] < f_best:\n                f_best, x_best = archive[0][0], archive[0][1].copy()\n\n        # finished: store and return best found\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ASTProbe scored 0.304 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "dd291d53-01ec-4a34-9cd6-09226201dd4e", "operator": null, "metadata": {"aucs": [0.06753954849036536, 0.1606309709937741, 0.7939177071924866, 0.15891150346984928, 0.16474252986012172, 0.8839428888486652, 0.26145985961581286, 0.2081571233880467, 0.20714515606139716, 0.12969045508900456]}, "task_prompt": ""}
{"id": "f0955187-ab49-42c4-a9ad-c488ae467471", "fitness": 0.34977320451328037, "name": "AdaptiveMultiScaleDirectionalSwarm", "description": "Adaptive Multi-Scale Directional Swarm (AMDS) is a compact, PSO-inspired hybrid that uses a small population (scaled with sqrt(dim)) and velocity updates combining inertia (w), cognitive (c1), social (c2) and a centroid/crowding pull (c3) to steer search while keeping function-evaluation overhead low. Initialization uses quasi‑uniform stratified samples with small jitter and strict reflect‑then‑clamp boundary handling, and the algorithm enforces strict budget accounting so func() is never called beyond self.budget. Exploration is boosted by per‑particle multiplicative step scales (initial_scale_frac, scale_up/scale_down) that grow on success and shrink on failure, occasional heavy‑tailed Laplace jumps (laplace_prob), periodic directional line probes around the global best (local_period), and a stagnation restart that reseeds half the population with Cauchy‑like perturbations (stagnation_restart). Selection is greedy and local (accept improvements immediately), inertia is slowly adapted toward w_min or back toward w0 based on progress, and beneficial local finds are injected into worst individuals to spread improvements while personal and global bests are maintained.", "code": "import numpy as np\n\nclass AdaptiveMultiScaleDirectionalSwarm:\n    \"\"\"\n    Adaptive Multi-Scale Directional Swarm (AMDS)\n\n    Key ideas:\n    - Small, efficient population to afford many function evaluations.\n    - Velocity-based updates (PSO-style) blended with a centroid-directed pull.\n    - Per-particle multiplicative step scales that grow on success and shrink on failure.\n    - Occasional Laplace (heavy-tailed) jumps to enable long-range escapes.\n    - Cheap opportunistic directional line probes around the global best periodically.\n    - Reflect-then-clamp boundary handling.\n    - Strict budget accounting: func() never called more than self.budget times.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, pop_base=None, rng_seed=None,\n                 w0=0.85, c1=1.2, c2=1.2, c3=0.6,\n                 initial_scale_frac=0.12, scale_up=1.25, scale_down=0.85,\n                 laplace_prob=0.04, local_period=30, stagnation_restart=60):\n        \"\"\"\n        Parameters:\n        - budget, dim: required by contract.\n        - pop_base: optional override of population size.\n        - rng_seed: optional RNG seed for reproducibility.\n        - w0: initial inertia weight.\n        - c1, c2: cognitive and social coefficients.\n        - c3: centroid (crowd) coefficient.\n        - initial_scale_frac: initial step scale as fraction of mean range.\n        - scale_up / scale_down: multiplicative updates of per-particle scale.\n        - laplace_prob: chance to perform a heavy-tailed jump instead of normal step.\n        - local_period: every this many generations perform cheap line probes around global best.\n        - stagnation_restart: if no improvement for this many generations, perform reseed.\n        \"\"\"\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.rng_seed = rng_seed\n\n        # motion and adaptation params\n        self.w0 = float(w0)\n        self.c1 = float(c1)\n        self.c2 = float(c2)\n        self.c3 = float(c3)\n\n        self.initial_scale_frac = float(initial_scale_frac)\n        self.scale_up = float(scale_up)\n        self.scale_down = float(scale_down)\n\n        self.laplace_prob = float(laplace_prob)\n        self.local_period = int(local_period)\n        self.stagnation_restart = int(stagnation_restart)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds (BBOB: usually -5..5, but follow func.bounds)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size: small-pop heuristic\n        if self.pop_base is None:\n            pop = max(6, int(1.5 * np.sqrt(max(1, self.dim)) + 4))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # quasi-uniform per-dimension stratified init with small jitter\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        jitter = (rng.rand(pop, self.dim) - 0.5) * (0.3 * (ub - lb) / max(1.0, self.dim))\n        X += jitter\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # initial evaluations (stop if budget runs out)\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        # If budget exhausted during init, return best we have\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:min(pop, i + 1)]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # velocities\n        V = np.zeros_like(X)\n\n        # personal bests\n        pbest = X.copy()\n        pbest_f = f.copy()\n\n        # global best\n        bi = int(np.argmin(f))\n        gbest = X[bi].copy()\n        gbest_f = float(f[bi])\n\n        # per-particle multiplicative scales (step lengths)\n        range_mean = np.mean(ub - lb)\n        initial_scale = max(1e-12, self.initial_scale_frac * range_mean)\n        scales = np.full(pop, initial_scale, dtype=float)\n\n        # inertia weight (can be adapted slowly)\n        w = float(self.w0)\n        w_min = 0.4\n\n        gen = 0\n        gens_since_improve = 0\n\n        def reflect_clamp(x):\n            xr = x.copy()\n            low = lb\n            high = ub\n            below = xr < low\n            if np.any(below):\n                xr[below] = low[below] + (low[below] - xr[below])\n            above = xr > high\n            if np.any(above):\n                xr[above] = high[above] - (xr[above] - high[above])\n            xr = np.minimum(np.maximum(xr, low), high)\n            return xr\n\n        pnum_min = max(2, int(max(1, 0.25 * pop)))  # centroid uses top 25%\n\n        # main loop: iterate until budget exhausted\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # rank and centroid of top p\n            order = np.argsort(f)\n            p_pool = order[:pnum_min]\n            centroid = np.mean(X[p_pool], axis=0)\n\n            # random order updates\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii]\n                vi = V[ii]\n                # velocity update combining inertia, personal pull, social pull, centroid crowding (with gaussian perturbation)\n                r1 = rng.rand(self.dim)\n                r2 = rng.rand(self.dim)\n                # personal best pull vector\n                cog = self.c1 * r1 * (pbest[ii] - xi)\n                soc = self.c2 * r2 * (gbest - xi)\n                crowd = self.c3 * rng.randn(self.dim) * (centroid - xi)  # random-signed centroid pull\n                vi_new = w * vi + cog + soc + crowd\n\n                # propose candidate: scale-modulated velocity step\n                step_scale = scales[ii]\n                candidate = xi + step_scale * vi_new\n\n                # occasional Laplace heavy-tailed jump (different from original algorithm's surrogate)\n                if rng.rand() < self.laplace_prob:\n                    # Laplace(0, b) with b drawn from 0.5..3 times scale to give heavy tails\n                    b = step_scale * (0.5 + 2.5 * rng.rand())\n                    # sample elementwise Laplace\n                    u = rng.rand(self.dim) - 0.5\n                    lap = -b * np.sign(u) * np.log(1.0 - 2.0 * np.abs(u))\n                    candidate = xi + lap\n\n                # ensure we actually move (if zero move, add tiny jitter)\n                if np.allclose(candidate, xi):\n                    candidate = xi + (rng.randn(self.dim) * (1e-6 * (ub - lb)))\n\n                # bounds\n                candidate = reflect_clamp(candidate)\n\n                # evaluate if budget allows\n                if evals >= self.budget:\n                    break\n                fv = float(func(candidate))\n                evals += 1\n\n                # selection: greedy per-particle\n                if fv <= f[ii]:\n                    # success: accept\n                    X[ii] = candidate\n                    f[ii] = fv\n                    V[ii] = vi_new  # keep momentum\n                    # increase step scale moderately\n                    scales[ii] = min(scales[ii] * self.scale_up, (ub - lb).max() * 2.0)\n                    # update personal best\n                    if fv < pbest_f[ii]:\n                        pbest[ii] = candidate.copy()\n                        pbest_f[ii] = fv\n                    # update global\n                    if fv < gbest_f:\n                        gbest_f = fv\n                        gbest = candidate.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # failure: damp velocity and shrink scale\n                    V[ii] = 0.5 * vi_new\n                    scales[ii] = max(1e-12, scales[ii] * self.scale_down)\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # slowly decay inertia toward w_min if no improvement, else gently restore toward w0\n            if improved_in_gen:\n                w = min(self.w0, w * 1.01 + 0.0005)\n            else:\n                w = max(w_min, w * 0.995)\n\n            # periodic opportunistic directional probes around global best (cheap)\n            if (gen % self.local_period == 0) and (evals < self.budget):\n                # try a few random directions, but limit evaluations to stay budget-friendly\n                probes = min(3, max(1, self.dim // 4))\n                local_improved = False\n                probe_steps = [initial := initial if False else None]  # trick to avoid lint; will not be used\n                for di in range(probes):\n                    if evals >= self.budget:\n                        break\n                    dvec = rng.randn(self.dim)\n                    dn = np.linalg.norm(dvec)\n                    if dn == 0.0:\n                        continue\n                    dvec /= dn\n                    # start from small scale relative to mean range, try doubling opportunistically twice\n                    step = max(1e-12, 0.06 * range_mean)\n                    attempts = 0\n                    while attempts < 3 and evals < self.budget:\n                        x_try = reflect_clamp(gbest + dvec * step)\n                        if np.allclose(x_try, gbest):\n                            step *= 0.5\n                            attempts += 1\n                            continue\n                        fv = float(func(x_try))\n                        evals += 1\n                        if fv < gbest_f:\n                            # accept and try larger step\n                            gbest = x_try.copy()\n                            gbest_f = fv\n                            local_improved = True\n                            # inject into worst later\n                            step *= 2.0\n                            attempts += 1\n                        else:\n                            # try opposite direction once\n                            x_try2 = reflect_clamp(gbest - dvec * step)\n                            if np.allclose(x_try2, gbest):\n                                step *= 0.5\n                                attempts += 1\n                                continue\n                            fv2 = float(func(x_try2))\n                            evals += 1\n                            if fv2 < gbest_f:\n                                gbest = x_try2.copy()\n                                gbest_f = fv2\n                                local_improved = True\n                                step *= 2.0\n                            else:\n                                step *= 0.5\n                            attempts += 1\n\n                # if local improved, inject into worst individual to spread improvement\n                if local_improved and evals < self.budget:\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = gbest.copy()\n                    f[worst_idx] = gbest_f\n                    pbest[worst_idx] = gbest.copy()\n                    pbest_f[worst_idx] = gbest_f\n                    scales[worst_idx] = initial_scale\n\n            # stagnation handling: reseed a portion of population around gbest using Cauchy perturbation\n            if gens_since_improve >= self.stagnation_restart and evals < self.budget:\n                half = max(1, pop // 2)\n                for k in range(half):\n                    if evals >= self.budget:\n                        break\n                    # heavy-tailed Cauchy-like perturbation with coordinate-wise scale related to ranges\n                    b = 0.08 * (ub - lb)\n                    # sample using standard Cauchy transform\n                    u = rng.rand(self.dim) - 0.5\n                    cauch = np.tan(np.pi * u)\n                    jitter = cauch * b\n                    newx = reflect_clamp(gbest + jitter)\n                    fv = float(func(newx))\n                    evals += 1\n                    # replace worst\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = newx\n                    f[worst_idx] = fv\n                    pbest[worst_idx] = newx.copy()\n                    pbest_f[worst_idx] = fv\n                    scales[worst_idx] = initial_scale\n                    if fv < gbest_f:\n                        gbest_f = fv\n                        gbest = newx.copy()\n                        gens_since_improve = 0\n\n            # synchronize global best from population as conservative check\n            bi = int(np.argmin(f))\n            if f[bi] < gbest_f:\n                gbest_f = float(f[bi])\n                gbest = X[bi].copy()\n                gens_since_improve = 0\n\n        # finished\n        self.f_opt = float(gbest_f)\n        self.x_opt = np.asarray(gbest, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveMultiScaleDirectionalSwarm scored 0.350 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "dd291d53-01ec-4a34-9cd6-09226201dd4e", "operator": null, "metadata": {"aucs": [0.11413026934099935, 0.16318013343083848, 0.39676894814892383, 0.8113591575673063, 0.19715216423079573, 0.9621313472888455, 0.2342054586019029, 0.25146728360189274, 0.22805782484540094, 0.13927945807589814]}, "task_prompt": ""}
{"id": "80ce79c9-92b1-41a6-8388-c9cc8521646d", "fitness": "-inf", "name": "AdaptiveSpiralEnsemble", "description": "The algorithm runs a small-to-moderate population (stratified jittered init, pop chosen heuristically) with per-individual momentum (x_prev) and strict budget accounting, using reflect_clamp to respect box bounds. It generates diverse candidate moves per individual—spiral momentum rotations, centroid-directed differential updates (alpha, beta, gamma), PCA subspace edits, surrogate-guided gradient steps, and occasional heavy‑tailed hyperjumps (hyperjump_prob≈0.02)—then uses a cheap k‑NN predictor to select which candidate to actually evaluate. A SHADE-style memory (H default 8) stores and updates alpha/beta/gamma (Lehmer-like update for gamma, smoothing 0.88/0.12) based on success-weighted statistics, while an archive (archive_max up to 1000) and recent step diffs feed the local linear surrogate and PCA directions. Diversity is maintained via periodic orthogonal reseeding (orthogonal_period≈30 using QR), archive replacement policies, and occasional random archive replacement, with greedy parent replacement and budget-aware evaluations throughout.", "code": "import numpy as np\n\nclass AdaptiveSpiralEnsemble:\n    \"\"\"\n    Adaptive Spiral Differential Ensemble (ASDE)\n\n    Key ideas:\n    - Small-to-moderate ensemble with momentum-based 'spiral' moves (rotations in random planes),\n      centroid-directed differential variation and PCA subspace sampling for anisotropic search.\n    - Lightweight local linear surrogate (k-NN + linear regression) used as a cheap predictor to pick\n      among several candidate moves before committing a function evaluation.\n    - SHADE-style memory for three move-parameters (alpha: momentum, beta: centroid pull, gamma: differential scale),\n      updated by success-weighted statistics (Lehmer-like for scale).\n    - Occasional heavy-tailed hyper-jumps and periodic orthogonal reseeding to regain diversity.\n    - Strict budget accounting: func() is called at most self.budget times.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, pop=None, H=8, archive_max=1000,\n                 p_top_frac=0.2, rng_seed=None,\n                 hyperjump_prob=0.02, orthogonal_period=30):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_user = pop\n        self.H = max(1, int(H))\n        self.archive_max = int(archive_max)\n        self.p_top_frac = float(p_top_frac)\n        self.rng_seed = rng_seed\n        self.hyperjump_prob = float(hyperjump_prob)\n        self.orthogonal_period = int(orthogonal_period)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds: allow functions that provide vector or scalar bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size heuristic: not too small, not exceeding budget\n        if self.pop_user is None:\n            pop = int(min(max(6, int(4 + np.log1p(self.dim) * 3)), max(2, self.budget)))\n        else:\n            pop = int(min(max(2, self.pop_user), max(2, self.budget)))\n        pop = max(2, min(pop, self.budget))\n\n        evals = 0\n\n        # initialize population with per-dimension stratified sampling (quasi-uniform) + jitter\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            strata = (np.arange(pop) + rng.rand(pop)) / pop  # jittered strata\n            perm = rng.permutation(pop)\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # slight global jitter\n        X += (rng.rand(pop, self.dim) - 0.5) * 0.2 * (ub - lb)\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        # If budget exhausted right away\n        if evals >= self.budget:\n            bi = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[bi])\n            self.x_opt = X[bi].copy()\n            return self.f_opt, self.x_opt\n\n        # archive of evaluated points (for surrogate & PCA)\n        X_archive = X[:evals].copy()\n        f_archive = f[:evals].copy()\n        # ensure archive arrays exist and can grow\n        # We'll append rows as we evaluate more points\n\n        # SHADE-like memory for three parameters: alpha (momentum), beta (centroid pull), gamma (diff scale)\n        H = self.H\n        mem_alpha = np.full(H, 0.5, dtype=float)\n        mem_beta = np.full(H, 0.5, dtype=float)\n        mem_gamma = np.full(H, 0.5, dtype=float)\n        mem_pos = 0\n\n        # per-individual previous position for momentum\n        x_prev = X.copy()\n\n        # working best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        # helper: reflect then clamp (one reflection)\n        def reflect_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        # helper: build cheap local surrogate gradient by k-NN linear fit\n        def local_linear_grad(xq, k= max( min(2*self.dim, 20), 4 )):\n            # if not enough archive points, return None\n            if X_archive.shape[0] < self.dim + 1:\n                return None\n            # compute distances\n            diffs = X_archive - xq\n            dists = np.sum(diffs**2, axis=1)\n            idx = np.argsort(dists)[:k]\n            Xk = X_archive[idx]\n            fk = f_archive[idx]\n            # center\n            Xm = Xk - Xk.mean(axis=0)\n            fm = fk - fk.mean()\n            # linear regression solve for gradient (least squares)\n            # add small ridge for stability\n            try:\n                A = Xm\n                y = fm\n                # Solve A * g = y in least-squares for g\n                # if poorly conditioned, return None\n                g, *_ = np.linalg.lstsq(A + 1e-8 * np.eye(self.dim), y, rcond=None)\n                g = np.asarray(g).reshape(self.dim)\n                if not np.all(np.isfinite(g)):\n                    return None\n                return g\n            except Exception:\n                return None\n\n        # helper: PCA principal directions of recent successful steps\n        def pca_directions(recent_steps, m= min( max(1, self.dim//4), 6 )):\n            if recent_steps.shape[0] < 2:\n                return None\n            C = np.cov(recent_steps, rowvar=False)\n            try:\n                vals, vecs = np.linalg.eigh(C)\n                # sort descending\n                idx = np.argsort(vals)[::-1]\n                vecs = vecs[:, idx]\n                # return top-m directions\n                return vecs[:, :m]\n            except Exception:\n                return None\n\n        # auxiliary: keep last N step diffs for PCA\n        recent_diffs = []\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # ranking and centroid of top p\n            order = np.argsort(f)\n            pnum = max(2, int(np.ceil(self.p_top_frac * pop)))\n            ppool = order[:pnum]\n            centroid = np.mean(X[ppool], axis=0)\n\n            # prepare success lists for memory update\n            succ_alpha = []\n            succ_beta = []\n            succ_gamma = []\n            succ_w = []\n\n            idxs = rng.permutation(pop)\n            # compute PCA directions from recent_diffs if available\n            if len(recent_diffs) >= 2:\n                pd = pca_directions(np.array(recent_diffs))\n            else:\n                pd = None\n\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                # sample memory index\n                m_idx = rng.randint(H)\n                # sample params with small stochasticity; alpha may be >1 to allow overshoot\n                alpha = float(np.clip(mem_alpha[m_idx] + 0.12 * rng.randn(), -0.4, 1.4))\n                beta = float(np.clip(mem_beta[m_idx] + 0.12 * rng.randn(), 0.0, 1.5))\n                # gamma sampled from heavy tailed (ish) to allow occasional strong diffs\n                gamma = float(np.clip(mem_gamma[m_idx] + 0.08 * rng.standard_cauchy(), 1e-4, 1.5))\n\n                x_i = X[ii].copy()\n                prev = x_prev[ii].copy()\n\n                # sample two random other indices for differential term\n                pool = [j for j in range(pop) if j != ii]\n                if len(pool) >= 2:\n                    r1, r2 = rng.choice(pool, size=2, replace=False)\n                elif len(pool) == 1:\n                    r1 = r2 = pool[0]\n                else:\n                    r1 = r2 = ii\n\n                xr1 = X[r1]; xr2 = X[r2]\n\n                candidates = []\n\n                # 1) Spiral momentum move: rotate momentum vector in a random coordinate plane\n                vel = x_i - prev\n                if np.allclose(vel, 0):\n                    vel = (rng.randn(self.dim) * 0.01 * (ub - lb))\n                # choose two dims to rotate\n                a, b = rng.randint(0, self.dim, size=2)\n                theta = (rng.rand() - 0.5) * np.pi * 0.2  # small rotation angle\n                vel2 = vel.copy()\n                # 2D rotation in [a,b] plane\n                ca = np.cos(theta); sa = np.sin(theta)\n                va, vb = vel[a], vel[b]\n                vel2[a] = ca * va - sa * vb\n                vel2[b] = sa * va + ca * vb\n                v_spiral = x_i + alpha * vel2\n                candidates.append(('spiral', v_spiral, (alpha, beta, gamma)))\n\n                # 2) centroid-directed + differential\n                v_diff = x_i + beta * (centroid - x_i) + gamma * (xr1 - xr2)\n                candidates.append(('centroid_diff', v_diff, (alpha, beta, gamma)))\n\n                # 3) PCA subspace sample (if available): combine top principal direction moves\n                if pd is not None:\n                    # sample coefficients along top components\n                    coeffs = rng.randn(pd.shape[1]) * (0.05 + 0.4 * rng.rand())\n                    v_pca = x_i + (pd @ coeffs)\n                    candidates.append(('pca_sub', v_pca, (alpha, beta, gamma)))\n\n                # 4) surrogate-guided gradient descent step (if model available)\n                grad = local_linear_grad(x_i, k=min( max(4, self.dim), max(6, int(2*self.dim)) ))\n                if grad is not None and np.linalg.norm(grad) > 0:\n                    # step size scaled to problem range\n                    range_mean = np.mean(ub - lb)\n                    step = 0.08 * range_mean * (0.5 + rng.rand())\n                    v_grad = x_i - step * grad / (np.linalg.norm(grad) + 1e-12)\n                    candidates.append(('grad_surrogate', v_grad, (alpha, beta, gamma)))\n\n                # 5) occasional heavy-tailed hyperjump anchored at best\n                if rng.rand() < self.hyperjump_prob:\n                    tail = (rng.rand() ** -0.8)  # heavy-ish tail\n                    v_jump = x_best + rng.randn(self.dim) * (0.03 * tail * (ub - lb))\n                    candidates.append(('hyperjump', v_jump, (alpha, beta, gamma)))\n\n                # reflect and clamp each candidate and compute cheap predicted f (via surrogate k-NN)\n                best_pred = np.inf\n                best_cand = None\n                # k-NN predictive function: weighted average of nearest f in archive\n                def knn_predict(xq, k= min( max(4, self.dim//2), 12 )):\n                    if X_archive.shape[0] == 0:\n                        return np.inf\n                    diffs = X_archive - xq\n                    d2 = np.sum(diffs**2, axis=1)\n                    idx = np.argsort(d2)[:min(k, X_archive.shape[0])]\n                    d = np.sqrt(np.maximum(d2[idx], 1e-12))\n                    w = 1.0 / (d + 1e-8)\n                    return np.sum(w * f_archive[idx]) / np.sum(w)\n\n                for tag, cand, params in candidates:\n                    cand = reflect_clamp(np.asarray(cand, dtype=float))\n                    pred = knn_predict(cand)\n                    # small bias favoring centroid_diff and grad moves\n                    if tag == 'centroid_diff':\n                        pred *= 0.98\n                    if tag == 'grad_surrogate':\n                        pred *= 0.95\n                    # prefer moves closer to current x if predicted equal (conservative)\n                    # use distance penalty\n                    pred += 1e-6 * np.linalg.norm(cand - x_i)\n                    if pred < best_pred:\n                        best_pred = pred\n                        best_cand = (tag, cand, params)\n\n                # Evaluate chosen candidate if budget allows\n                if best_cand is None:\n                    continue\n                tag, trial, (alpha_used, beta_used, gamma_used) = best_cand\n                trial = reflect_clamp(trial)\n                if evals >= self.budget:\n                    break\n                f_trial = float(func(trial))\n                evals += 1\n\n                # append to archive\n                if X_archive.shape[0] < self.archive_max:\n                    X_archive = np.vstack([X_archive, trial])\n                    f_archive = np.concatenate([f_archive, [f_trial]])\n                else:\n                    # replace worst in archive (circularly or by rand)\n                    worst_ai = int(np.argmax(f_archive))\n                    if f_trial < f_archive[worst_ai]:\n                        X_archive[worst_ai] = trial\n                        f_archive[worst_ai] = f_trial\n                    else:\n                        # occasionally replace a random archive item to keep variety\n                        if rng.rand() < 0.05:\n                            rid = rng.randint(X_archive.shape[0])\n                            X_archive[rid] = trial\n                            f_archive[rid] = f_trial\n\n                # selection: greedy replacement if better than parent\n                parent_f = f[ii]\n                if f_trial <= parent_f:\n                    # record success params and weights (improvement magnitude)\n                    w = max(1e-12, parent_f - f_trial)\n                    succ_alpha.append(alpha_used)\n                    succ_beta.append(beta_used)\n                    succ_gamma.append(gamma_used)\n                    succ_w.append(w)\n\n                    # update recent diffs (for PCA)\n                    recent_diffs.append((trial - x_i))\n                    if len(recent_diffs) > 50:\n                        recent_diffs.pop(0)\n\n                    # replace parent\n                    x_prev[ii] = x_i.copy()\n                    X[ii] = trial.copy()\n                    f[ii] = f_trial\n\n                    # update best\n                    if f_trial < f_best:\n                        f_best = f_trial\n                        x_best = trial.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # even if not accepted, still update previous to current for momentum\n                    x_prev[ii] = x_i.copy()\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # update memories (SHADE-like weighted Lehmer for scales)\n            if len(succ_alpha) > 0:\n                succ_alpha = np.asarray(succ_alpha)\n                succ_beta = np.asarray(succ_beta)\n                succ_gamma = np.asarray(succ_gamma)\n                succ_w = np.asarray(succ_w)\n                if np.sum(succ_w) > 0:\n                    w = succ_w / np.sum(succ_w)\n                else:\n                    w = np.ones_like(succ_w) / len(succ_w)\n                # Lehmer mean for gamma (scale)\n                numer_g = np.sum(w * (succ_gamma ** 2))\n                denom_g = np.sum(w * succ_gamma) + 1e-12\n                new_gamma = float(np.clip(numer_g / denom_g, 1e-4, 2.0))\n                # simple weighted arithmetic for alpha and beta\n                new_alpha = float(np.clip(np.sum(w * succ_alpha), -0.5, 1.5))\n                new_beta = float(np.clip(np.sum(w * succ_beta), 0.0, 2.0))\n                # write to memory with mild smoothing\n                mem_alpha[mem_pos] = 0.88 * mem_alpha[mem_pos] + 0.12 * new_alpha\n                mem_beta[mem_pos] = 0.88 * mem_beta[mem_pos] + 0.12 * new_beta\n                mem_gamma[mem_pos] = 0.88 * mem_gamma[mem_pos] + 0.12 * new_gamma\n                mem_pos = (mem_pos + 1) % H\n\n            # periodic orthogonal reseed to keep population diverse\n            if gen % self.orthogonal_period == 0 and evals < self.budget:\n                # form random orthonormal basis (via QR of random matrix)\n                M = rng.randn(self.dim, min(self.dim, pop))\n                try:\n                    Q, _ = np.linalg.qr(M)\n                except Exception:\n                    Q = np.eye(self.dim)[:, :min(self.dim, pop)]\n                # replace worst half with orthogonal perturbations around best\n                worst_order = np.argsort(f)[::-1]\n                half = max(1, pop // 2)\n                for k in range(half):\n                    if evals >= self.budget:\n                        break\n                    idx_w = worst_order[k]\n                    # sample coefficients along Q columns\n                    coeffs = (rng.randn(Q.shape[1]) * 0.03 * (ub - lb).mean())\n                    newx = x_best + (Q[:, :Q.shape[1]] @ coeffs)\n                    newx = reflect_clamp(newx)\n                    fv = float(func(newx))\n                    evals += 1\n                    X[idx_w] = newx\n                    f[idx_w] = fv\n                    # archive update\n                    if X_archive.shape[0] < self.archive_max:\n                        X_archive = np.vstack([X_archive, newx])\n                        f_archive = np.concatenate([f_archive, [fv]])\n                    else:\n                        worst_ai = int(np.argmax(f_archive))\n                        if fv < f_archive[worst_ai]:\n                            X_archive[worst_ai] = newx\n                            f_archive[worst_ai] = fv\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = newx.copy()\n                        gens_since_improve = 0\n\n            # final sync best from current pop\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n            # optional early termination if objective extremely low (practical guard)\n            # (not strictly necessary, but safe): do nothing (we must adhere to budget strictly)\n\n        # done\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": "dd291d53-01ec-4a34-9cd6-09226201dd4e", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "d585d28b-092b-4474-ad49-36b481e88234", "fitness": 0.4116493803574085, "name": "AdaptiveEnsembleSearch", "description": "The algorithm uses a small, dimension‑aware ensemble (pop ≈ max(6, 3·sqrt(dim)+6)) with a quasi‑uniform stratified initialization to cover the [-5,5] box while keeping evaluations efficient. Mutation combines a leader‑directed step, a differential term, an orthogonal lateral perturbation and isotropic noise, with occasional heavy‑tailed Student‑t jumps to balance exploitation and rare long explorations; CR is sampled from a Beta(2,2) warped toward memory and sigma is sampled multiplicatively via a log‑normal perturbation to maintain positive, scale‑aware steps. Successes update a short memory (M, default 12) using a weighted geometric mean for sigma and weighted arithmetic mean for CR with light smoothing (alpha=0.2), while per‑individual sigma/CR bookkeeping and weightings by improvement magnitude guide adaptive sampling. Robust bound handling uses repeated reflection then clamping, and periodic local halving probes plus a mild stagnation restart (reseeding a quarter of the population around the best) provide focused refinement and recovery from stagnation.", "code": "import numpy as np\n\nclass AdaptiveEnsembleSearch:\n    \"\"\"\n    Adaptive Ensemble Directional Search (AEDS)\n    \n    Main ideas and (main) parameters (different choices / equations compared to the provided algorithm):\n      - ensemble_size (pop): small ensemble tuned to dimension: pop = max(6, int(3*sqrt(dim) + 6))\n      - memory length M for scale/crossover adaptation (default M=12)\n      - mem_sigma initialized to 0.3 (scale). Sigma updates use weighted geometric mean (multiplicative adaptation).\n      - mem_CR initialized to 0.5. CR updates use weighted arithmetic mean but stored with light smoothing (alpha_smooth=0.2).\n      - Mutation:\n          mutant = xi + s*(leader - xi)\n                   + s*(xr1 - xr2)*(1 + 0.2 * N(0,1))\n                   + ortho_scale * (noise projected orthogonal to (leader-xi))\n                   + isotropic_noise ~ N(0, sigma_iso * pop_std)\n        (orthogonal perturbation biases lateral exploration around the leader direction;\n         s sampled multiplicatively via lognormal around mem_sigma — different from Cauchy from SHADE)\n      - CR sampled from Beta(2,2) warped around mem_CR to produce different exploration/exploitation behavior\n      - Tempered Student-t jumps (heavier tail than Gaussian) with a different probability (0.06)\n      - Local probing uses halving (shrink) search along random directions (opposite to doubling in original)\n      - On stagnation, reseed quarter of population around best (milder than half)\n      - Bound handling uses repeated reflection (bounce) then clamp\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 ensemble_coef=3.0, min_pop=6, M=12,\n                 init_sigma=0.3, init_CR=0.5,\n                 jump_prob=0.06, student_df=3.0,\n                 ortho_frac=0.25, iso_frac=0.06,\n                 local_period=30, stagnation_restart=60,\n                 local_initial_frac=0.15, local_min_frac=1e-4):\n        \"\"\"\n        Parameters:\n          budget (int): max number of function evaluations\n          dim (int): problem dimension\n          rng_seed: optional RNG seed\n          ensemble_coef: used to set pop ~ ensemble_coef * sqrt(dim)\n          M: memory length for adaptation\n          init_sigma: initial adaptation scale\n          jump_prob: probability for tempered Student-t random jump\n          student_df: degrees of freedom for Student-t sampling (heavy tails)\n          ortho_frac: fraction of leader-distance used for orthogonal perturbation scale\n          iso_frac: fraction of search range used for isotropic noise\n          local_*: parameters for local probing (halving search)\n        \"\"\"\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # population size heuristic (different from provided algorithm)\n        self.ensemble_coef = float(ensemble_coef)\n        self.min_pop = int(min_pop)\n\n        # adaptation memory\n        self.M = max(1, int(M))\n        self.init_sigma = float(init_sigma)\n        self.init_CR = float(init_CR)\n\n        # jump parameters\n        self.jump_prob = float(jump_prob)\n        self.student_df = float(student_df)\n\n        # perturbation fractions\n        self.ortho_frac = float(ortho_frac)\n        self.iso_frac = float(iso_frac)\n\n        # probing / restart\n        self.local_period = int(local_period)\n        self.stagnation_restart = int(stagnation_restart)\n        self.local_initial_frac = float(local_initial_frac)\n        self.local_min_frac = float(local_min_frac)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds handling: func.bounds.lb/ub may be scalars or arrays\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size\n        pop = max(self.min_pop, int(self.ensemble_coef * np.sqrt(max(1, self.dim)) + 6))\n        pop = min(pop, max(2, self.budget))  # cannot exceed budget\n\n        evals = 0\n\n        # repeated reflection (bounce) then clamp bound handler\n        def reflect_clamp(x):\n            xr = x.copy()\n            low = lb\n            high = ub\n            # repeat reflection until inside or shallow clamp\n            for _ in range(3):\n                below = xr < low\n                if np.any(below):\n                    xr[below] = low[below] + (low[below] - xr[below])\n                above = xr > high\n                if np.any(above):\n                    xr[above] = high[above] - (xr[above] - high[above])\n            # final clamp to be safe\n            xr = np.minimum(np.maximum(xr, low), high)\n            return xr\n\n        # initialize population quasi-uniform with jitter (stratified per-dim)\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        X += (rng.rand(pop, self.dim) - 0.5) * (0.3 * (ub - lb) / max(1.0, self.dim))\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        # if budget exhausted during init\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i + 1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # adaptation memories\n        M = self.M\n        mem_sigma = np.full(M, self.init_sigma, dtype=float)\n        mem_CR = np.full(M, self.init_CR, dtype=float)\n        mem_pos = 0\n\n        # per-individual last-used params (bookkeeping)\n        sigma_pop = np.clip(np.abs(self.init_sigma + 0.05 * rng.randn(pop)), 1e-4, 2.0)\n        CR_pop = np.clip(self.init_CR + 0.1 * rng.randn(pop), 0.0, 1.0)\n\n        # best tracking\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # ranking and leader selection (use best as leader)\n            order = np.argsort(f)\n            leader_idx = int(order[0])\n            leader = X[leader_idx].copy()\n\n            # compute population std for isotropic noise scaling\n            pop_std = np.mean(np.std(X, axis=0))\n\n            # success record lists for memory update\n            succ_sigma = []\n            succ_CR = []\n            succ_w = []\n\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                # sample memory index\n                m_idx = rng.randint(M)\n\n                # sample multiplicative scale sigma from lognormal centered at mem_sigma[m_idx]\n                # This is different from Cauchy sampling; we use lognormal to preserve positivity and multiplicative behavior\n                base = mem_sigma[m_idx]\n                sigma_i = base * np.exp(0.25 * rng.randn())  # log-normal perturbation\n                sigma_i = float(np.clip(sigma_i, 1e-4, 5.0))\n\n                # sample CR by warping Beta around mem_CR: create a Beta(2,2) then shift towards mem_CR\n                b = rng.beta(2.0, 2.0)\n                CRi = float(np.clip(0.5 * (b + mem_CR[m_idx]), 0.0, 1.0))\n\n                sigma_pop[ii] = sigma_i\n                CR_pop[ii] = CRi\n\n                # pick two distinct others\n                pool = [j for j in range(pop) if j != ii]\n                if len(pool) >= 2:\n                    r1, r2 = rng.choice(pool, size=2, replace=False)\n                elif len(pool) == 1:\n                    r1 = r2 = pool[0]\n                else:\n                    r1 = r2 = ii\n\n                xi = X[ii]\n                xr1 = X[r1]\n                xr2 = X[r2]\n\n                # primary directed vector toward leader\n                d_lead = (leader - xi)\n                dnorm = np.linalg.norm(d_lead)\n                if dnorm > 0:\n                    d_unit = d_lead / dnorm\n                else:\n                    d_unit = rng.randn(self.dim)\n                    d_unit /= max(1e-12, np.linalg.norm(d_unit))\n\n                # orthogonal noise: sample noise and remove projection on leader direction\n                noise = rng.randn(self.dim)\n                proj = np.dot(noise, d_unit) * d_unit\n                ortho = noise - proj\n                ortho_norm = np.linalg.norm(ortho)\n                if ortho_norm > 0:\n                    ortho = ortho / ortho_norm\n                else:\n                    ortho = np.zeros_like(noise)\n\n                # differential term with small multiplicative jitter (different formula from original)\n                diff_term = (xr1 - xr2) * (1.0 + 0.2 * rng.randn())\n\n                # isotropic gaussian noise scaled by pop_std and iso_frac\n                iso_scale = max(1e-12, self.iso_frac * (np.mean(ub - lb)))\n                iso_noise = rng.randn(self.dim) * (iso_scale * (1.0 + 0.5 * rng.randn()))\n\n                # combine mutation components (different equation)\n                mutant = xi \\\n                         + sigma_i * d_lead \\\n                         + sigma_i * diff_term \\\n                         + (self.ortho_frac * dnorm) * ortho \\\n                         + iso_noise\n\n                # occasional tempered Student-t jump (different probability and distribution)\n                if rng.rand() < self.jump_prob:\n                    t_scaler = np.abs(rng.standard_t(self.student_df))  # heavy tail\n                    jump_scale = (ub - lb) * (0.03 + 1.5 * (t_scaler ** 0.9))\n                    mutant = xi + rng.randn(self.dim) * jump_scale\n\n                # binomial crossover\n                jrand = rng.randint(self.dim)\n                mask = rng.rand(self.dim) < CRi\n                mask[jrand] = True\n                trial = np.where(mask, mutant, xi)\n\n                # bound handling\n                trial = reflect_clamp(trial)\n\n                # evaluate parent value stored before selection\n                parent_f = float(f[ii])\n\n                if evals >= self.budget:\n                    break\n                fv = float(func(trial))\n                evals += 1\n\n                # selection\n                if fv <= parent_f:\n                    # accept\n                    X[ii] = trial\n                    f[ii] = fv\n                    improved_in_gen = improved_in_gen or (fv < f_best)\n                    # record success parameters\n                    succ_sigma.append(sigma_i)\n                    succ_CR.append(CRi)\n                    # weight proportional to improvement magnitude (parent_f - fv)\n                    w = max(1e-12, (parent_f - fv))\n                    succ_w.append(w)\n                    # update global best if needed\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = trial.copy()\n                        gens_since_improve = 0\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # adaptation memory update (if any successes)\n            if len(succ_sigma) > 0:\n                succ_sigma = np.asarray(succ_sigma, dtype=float)\n                succ_CR = np.asarray(succ_CR, dtype=float)\n                succ_w = np.asarray(succ_w, dtype=float)\n\n                if np.sum(succ_w) > 0:\n                    w = succ_w / np.sum(succ_w)\n                else:\n                    w = np.ones_like(succ_sigma) / len(succ_sigma)\n\n                # geometric (multiplicative) mean for sigma: exp(sum(w * log(s)))\n                log_mean = np.sum(w * np.log(succ_sigma + 1e-12))\n                new_sigma = float(np.exp(log_mean))\n                # arithmetic mean for CR (weighted)\n                new_CR = float(np.sum(w * succ_CR))\n\n                # light smoothing mixing into memory (different smoothing from original: alpha=0.2)\n                alpha_smooth = 0.2\n                mem_sigma[mem_pos] = (1.0 - alpha_smooth) * mem_sigma[mem_pos] + alpha_smooth * np.clip(new_sigma, 1e-4, 5.0)\n                mem_CR[mem_pos] = (1.0 - alpha_smooth) * mem_CR[mem_pos] + alpha_smooth * np.clip(new_CR, 0.0, 1.0)\n                mem_pos = (mem_pos + 1) % M\n\n            # periodic local probing (halving style) or stagnation-triggered targeted reseed\n            if (gen % self.local_period == 0) or (gens_since_improve >= self.stagnation_restart):\n                remaining = self.budget - evals\n                if remaining > 0:\n                    range_mean = np.mean(ub - lb)\n                    step0 = max(1e-12, self.local_initial_frac * range_mean)\n                    min_step = max(1e-12, self.local_min_frac * range_mean)\n                    if gens_since_improve >= self.stagnation_restart:\n                        step0 *= 1.5  # try slightly larger moves on stagnation\n\n                    local_improved = False\n                    x_work = x_best.copy()\n                    f_work = f_best\n\n                    n_dirs = min(4, self.dim)\n                    for di in range(n_dirs):\n                        if evals >= self.budget:\n                            break\n                        dvec = rng.randn(self.dim)\n                        dn = np.linalg.norm(dvec)\n                        if dn == 0.0:\n                            continue\n                        dvec /= dn\n\n                        step = step0\n                        # halving search: try positive/negative, shrink step on failure\n                        while step >= min_step and (self.budget - evals) > 0:\n                            x_try = np.minimum(np.maximum(x_work + dvec * step, lb), ub)\n                            if np.allclose(x_try, x_work):\n                                # try other side\n                                x_try = np.minimum(np.maximum(x_work - dvec * step, lb), ub)\n                                if np.allclose(x_try, x_work):\n                                    step *= 0.5\n                                    continue\n                            if evals >= self.budget:\n                                break\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                x_work = x_try\n                                f_work = fv\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_try.copy()\n                                    gens_since_improve = 0\n                                # continue in same direction but shrink step moderately to refine (opposite of doubling)\n                                step *= 0.7\n                            else:\n                                # try opposite side once\n                                x_try2 = np.minimum(np.maximum(x_work - dvec * step, lb), ub)\n                                if np.allclose(x_try2, x_work):\n                                    step *= 0.5\n                                    continue\n                                if evals >= self.budget:\n                                    break\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < f_work:\n                                    x_work = x_try2\n                                    f_work = fv2\n                                    local_improved = True\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = x_try2.copy()\n                                        gens_since_improve = 0\n                                    step *= 0.7\n                                else:\n                                    step *= 0.5\n\n                    # inject local improvement replacing worst if improved\n                    if local_improved:\n                        worst_idx = int(np.argmax(f))\n                        X[worst_idx] = x_work.copy()\n                        f[worst_idx] = f_work\n                        gens_since_improve = 0\n                    else:\n                        # if stagnating, reseed quarter of population around best with mild Gaussian jitter\n                        if gens_since_improve >= self.stagnation_restart:\n                            q = max(1, pop // 4)\n                            for k in range(q):\n                                if evals >= self.budget:\n                                    break\n                                jitter = rng.randn(self.dim) * (0.04 * range_mean)\n                                newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                                fv = float(func(newx))\n                                evals += 1\n                                worst_idx = int(np.argmax(f))\n                                X[worst_idx] = newx\n                                f[worst_idx] = fv\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = newx.copy()\n                                    gens_since_improve = 0\n\n            # synchronize best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # done\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveEnsembleSearch scored 0.412 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "dd291d53-01ec-4a34-9cd6-09226201dd4e", "operator": null, "metadata": {"aucs": [0.17211709717475376, 0.22942922225084916, 0.5439190113406254, 0.8533334395222141, 0.3298840724547958, 0.6320086303863688, 0.2601714976326511, 0.36653723470498223, 0.5529448423601159, 0.17614875574672828]}, "task_prompt": ""}
{"id": "60b2a8a1-2a1c-412e-ab58-aff0a03077df", "fitness": 0.44725587036382536, "name": "EnsembleDirectionalPatternDE", "description": "The algorithm starts with a small, quasi‑uniform stratified population (pop ≈ max(12, 4+3·log(dim))) jittered inside bounds to give good initial coverage while keeping evaluations low. Its DE core uses SHADE‑style memories for F and CR (Cauchy for F, Normal for CR), per‑individual F/CR, Lehmer‑weighted updates with smoothing (mem_F[mem_pos] = 0.9*old + 0.1*new) and a p_frac‑based pbest pool, and it adaptively mixes two mutation modes (centroid‑directed vs current‑to‑pbest/1) by tracking recent success counts. Exploration is enhanced with occasional Lévy‑like jumps, reflect‑then‑clamp bound handling, stochastic r1/r2 selection, and a small population to keep the method nimble. To escape stagnation and exploit promising regions in a budget‑aware way it periodically runs Hooke‑Jeeves coordinate searches and opportunistic doubling line probes (controlled by local_period, local_stagn_gen, initial_step_frac/min_step_frac), injects local improvements by replacing the worst individual, and reseeds half the population when needed.", "code": "import numpy as np\n\nclass EnsembleDirectionalPatternDE:\n    \"\"\"\n    EnsembleDirectionalPatternDE (EDP-DE)\n\n    - Small quasi-uniform population with jitter.\n    - SHADE-like memory for F and CR (Cauchy for F, Normal for CR) with Lehmer-weighted updates.\n    - Two mutation modes:\n        * centroid-directed: xi + F*(centroid - xi) + F*(r1 - r2)\n        * current-to-pbest/1: xi + F*(pbest - xi) + F*(r1 - r2)\n      Strategy choice is adaptive based on recent success counts.\n    - Rare Lévy-like jumps for escape.\n    - Periodic budget-aware Hooke-Jeeves coordinate pattern search + opportunistic doubling line probes around best.\n    - Reflect-then-clamp bound handling, replace worst with local improvements, stagnation reseed.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None, p_frac=0.2, H=10,\n                 local_period=25, local_stagn_gen=40,\n                 initial_step_frac=0.2, min_step_frac=1e-4,\n                 levy_prob=0.03, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.p_frac = float(p_frac)\n        self.H = max(1, int(H))\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.initial_step_frac = float(initial_step_frac)\n        self.min_step_frac = float(min_step_frac)\n        self.levy_prob = float(levy_prob)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size heuristic similar to algorithm1 but slightly larger for ensemble\n        if self.pop_base is None:\n            pop = max(12, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # quasi-uniform stratified init per-dimension\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter\n        X += (rng.rand(pop, self.dim) - 0.5) * (0.45 * (ub - lb) / max(1.0, self.dim))\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.empty(pop, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i + 1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # memory arrays (SHADE-style)\n        mem_F = np.full(self.H, 0.5, dtype=float)\n        mem_CR = np.full(self.H, 0.5, dtype=float)\n        mem_pos = 0\n\n        # per-individual bookkeeping\n        F_pop = np.clip(0.5 + 0.1 * rng.randn(pop), 0.05, 0.95)\n        CR_pop = np.clip(rng.rand(pop), 0.0, 1.0)\n\n        # adaptive strategy mixing: probability of using centroid-directed\n        p_centroid = 0.5\n        success_centroid = 0\n        success_pbest = 0\n        adapt_window = 20  # adapt p_centroid every adapt_window generations\n\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        def reflect_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        pnum_min = max(2, int(np.ceil(self.p_frac * pop)))\n\n        # main evolutionary loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            order = np.argsort(f)\n            p_pool = order[:max(pnum_min, 2)]\n            centroid = np.mean(X[p_pool], axis=0)\n\n            succ_F = []\n            succ_CR = []\n            succ_w = []\n\n            # iterate randomized order\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                # sample memory index and F,CR (SHADE-style)\n                mem_idx = rng.randint(self.H)\n                # Cauchy for F\n                attempts = 0\n                Fi = None\n                while attempts < 7:\n                    Fi = mem_F[mem_idx] + 0.1 * rng.standard_cauchy()\n                    if Fi > 1e-6 and np.isfinite(Fi):\n                        break\n                    attempts += 1\n                if Fi is None or not np.isfinite(Fi):\n                    Fi = 0.5\n                Fi = float(np.clip(Fi, 0.01, 1.0))\n                # normal for CR\n                CRi = float(np.clip(mem_CR[mem_idx] + 0.1 * rng.randn(), 0.0, 1.0))\n\n                F_pop[ii] = Fi\n                CR_pop[ii] = CRi\n\n                # pick strategy: centroid-directed or current-to-pbest\n                use_centroid = rng.rand() < p_centroid\n\n                # pick r1, r2 distinct\n                pool = [j for j in range(pop) if j != ii]\n                if len(pool) >= 2:\n                    r1, r2 = rng.choice(pool, size=2, replace=False)\n                elif len(pool) == 1:\n                    r1 = r2 = pool[0]\n                else:\n                    r1 = r2 = ii\n\n                xi = X[ii]\n                xr1 = X[r1]\n                xr2 = X[r2]\n\n                if use_centroid:\n                    vi = xi + Fi * (centroid - xi) + Fi * (xr1 - xr2)\n                else:\n                    # select pbest\n                    p_idx = int(rng.choice(p_pool))\n                    xp = X[p_idx]\n                    vi = xi + Fi * (xp - xi) + Fi * (xr1 - xr2)\n\n                # occasional Lévy-like jump to escape\n                if rng.rand() < self.levy_prob:\n                    scale = (ub - lb) * (0.05 + 2.0 * (rng.rand() ** -0.7))\n                    vi = xi + rng.randn(self.dim) * scale\n\n                # binomial crossover\n                jrand = rng.randint(self.dim)\n                mask = rng.rand(self.dim) < CRi\n                mask[jrand] = True\n                trial = np.where(mask, vi, xi)\n\n                trial = reflect_clamp(trial)\n\n                if evals >= self.budget:\n                    break\n                fv = float(func(trial))\n                evals += 1\n\n                # selection\n                if fv <= f[ii]:\n                    # success\n                    # weight is improvement magnitude (parent value prior to update is f[ii])\n                    w = max(1e-12, f[ii] - fv)\n                    succ_F.append(Fi)\n                    succ_CR.append(CRi)\n                    succ_w.append(w)\n\n                    # update individual\n                    X[ii] = trial\n                    f[ii] = fv\n\n                    # record strategy success counts\n                    if use_centroid:\n                        success_centroid += 1\n                    else:\n                        success_pbest += 1\n\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = trial.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n\n                # else keep parent\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # memory update (SHADE-style with Lehmer mean for F)\n            if len(succ_F) > 0:\n                sF = np.asarray(succ_F)\n                sCR = np.asarray(succ_CR)\n                sw = np.asarray(succ_w)\n                if np.sum(sw) > 0:\n                    w = sw / np.sum(sw)\n                else:\n                    w = np.ones_like(sw) / len(sw)\n                numer = np.sum(w * (sF ** 2))\n                denom = np.sum(w * sF) + 1e-12\n                new_mF = numer / denom\n                new_mCR = np.sum(w * sCR)\n                # circular store with smoothing to avoid abrupt changes\n                mem_F[mem_pos] = 0.9 * mem_F[mem_pos] + 0.1 * float(np.clip(new_mF, 1e-3, 1.0))\n                mem_CR[mem_pos] = 0.9 * mem_CR[mem_pos] + 0.1 * float(np.clip(new_mCR, 0.0, 1.0))\n                mem_pos = (mem_pos + 1) % self.H\n\n            # adapt strategy mixing probability periodically based on recent successes\n            if gen % adapt_window == 0:\n                total = success_centroid + success_pbest + 1e-12\n                p_centroid = 0.2 + 0.6 * (success_centroid / total)  # keep within [0.2,0.8] roughly\n                # decay counters\n                success_centroid = int(success_centroid * 0.2)\n                success_pbest = int(success_pbest * 0.2)\n\n            # Periodic local refinements: coordinate search and opportunistic doubling line probes\n            if (gen % self.local_period == 0) or (gens_since_improve >= self.local_stagn_gen):\n                remaining = self.budget - evals\n                if remaining <= 0:\n                    break\n\n                range_mean = np.mean(ub - lb)\n                step = max(1e-12, self.initial_step_frac * range_mean)\n                min_step = max(1e-12, self.min_step_frac * range_mean)\n                if gens_since_improve >= self.local_stagn_gen:\n                    step *= 2.0\n\n                local_improved = False\n                x_work = x_best.copy()\n                f_work = f_best\n\n                # Coordinate (Hooke-Jeeves style) but limited to a small number of evaluations\n                max_coord_evals = min(remaining, max(8, 2 * self.dim))\n                coord_evals = 0\n                while step >= min_step and evals < self.budget and coord_evals < max_coord_evals:\n                    moved = False\n                    for d in range(self.dim):\n                        if evals >= self.budget or coord_evals >= max_coord_evals:\n                            break\n                        # try plus\n                        x_try = x_work.copy()\n                        x_try[d] = x_try[d] + step\n                        if x_try[d] > ub[d]:\n                            x_try[d] = ub[d]\n                        if np.allclose(x_try, x_work):\n                            x_try[d] = x_work[d] - step\n                            if x_try[d] < lb[d]:\n                                x_try[d] = lb[d]\n                        # evaluate\n                        fv = float(func(x_try))\n                        evals += 1\n                        coord_evals += 1\n                        if fv < f_work:\n                            x_work = x_try\n                            f_work = fv\n                            moved = True\n                            local_improved = True\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = x_try.copy()\n                                gens_since_improve = 0\n                            # opportunistic extra probe in same direction\n                            if evals < self.budget and coord_evals < max_coord_evals:\n                                x_try2 = x_work.copy()\n                                x_try2[d] = np.minimum(np.maximum(x_try2[d] + step, lb[d]), ub[d])\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                coord_evals += 1\n                                if fv2 < f_work:\n                                    x_work = x_try2\n                                    f_work = fv2\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = x_try2.copy()\n                                        gens_since_improve = 0\n                        else:\n                            # try minus once\n                            if evals >= self.budget or coord_evals >= max_coord_evals:\n                                break\n                            x_try = x_work.copy()\n                            x_try[d] = x_work[d] - step\n                            if x_try[d] < lb[d]:\n                                x_try[d] = lb[d]\n                            fv = float(func(x_try))\n                            evals += 1\n                            coord_evals += 1\n                            if fv < f_work:\n                                x_work = x_try\n                                f_work = fv\n                                moved = True\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_try.copy()\n                                    gens_since_improve = 0\n                    if not moved:\n                        step *= 0.5\n                    # continue until eval cap or step too small\n\n                # Opportunistic doubling line probes in a few random directions if budget allows\n                if evals < self.budget:\n                    n_dirs = min(3, max(1, self.dim // 3))\n                    line_evals_cap = min(remaining, 12)\n                    line_evals = 0\n                    for di in range(n_dirs):\n                        if evals >= self.budget or line_evals >= line_evals_cap:\n                            break\n                        dvec = rng.randn(self.dim)\n                        dn = np.linalg.norm(dvec)\n                        if dn == 0.0:\n                            continue\n                        dvec /= dn\n                        step_l = max(1e-12, self.initial_step_frac * range_mean)\n                        while step_l >= min_step and evals < self.budget and line_evals < line_evals_cap:\n                            x_try = x_work + dvec * step_l\n                            x_try = np.minimum(np.maximum(x_try, lb), ub)\n                            if np.allclose(x_try, x_work):\n                                x_try = x_work - dvec * step_l\n                                x_try = np.minimum(np.maximum(x_try, lb), ub)\n                                if np.allclose(x_try, x_work):\n                                    break\n                            fv = float(func(x_try))\n                            evals += 1\n                            line_evals += 1\n                            if fv < f_work:\n                                x_work = x_try\n                                f_work = fv\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_try.copy()\n                                    gens_since_improve = 0\n                                # double step opportunistically\n                                step_l *= 2.0\n                                if evals >= self.budget or line_evals >= line_evals_cap:\n                                    break\n                            else:\n                                # try opposite once\n                                x_try2 = x_work - dvec * step_l\n                                x_try2 = np.minimum(np.maximum(x_try2, lb), ub)\n                                if np.allclose(x_try2, x_work):\n                                    step_l *= 0.5\n                                    continue\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                line_evals += 1\n                                if fv2 < f_work:\n                                    x_work = x_try2\n                                    f_work = fv2\n                                    local_improved = True\n                                    if fv2 < f_best:\n                                        f_best = fv2\n                                        x_best = x_try2.copy()\n                                        gens_since_improve = 0\n                                    step_l *= 2.0\n                                else:\n                                    step_l *= 0.5\n\n                # inject local improvement if any\n                if local_improved:\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_work.copy()\n                    f[worst_idx] = f_work\n                    gens_since_improve = 0\n                else:\n                    # if stagnating, reseed half population around best with mild jitter\n                    if gens_since_improve >= self.local_stagn_gen:\n                        half = pop // 2\n                        for k in range(half):\n                            if evals >= self.budget:\n                                break\n                            jitter = rng.randn(self.dim) * (0.06 * (ub - lb))\n                            newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                            fv = float(func(newx))\n                            evals += 1\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = newx\n                            f[worst_idx] = fv\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = newx.copy()\n                                gens_since_improve = 0\n\n            # sync best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnsembleDirectionalPatternDE scored 0.447 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "dd291d53-01ec-4a34-9cd6-09226201dd4e", "operator": null, "metadata": {"aucs": [0.21674098938185082, 0.25621976816395764, 0.46349139051963184, 0.8364864840549596, 0.552212217192313, 0.9230072677039399, 0.32866788554739457, 0.4017075440895741, 0.2633668556613794, 0.23065830132325238]}, "task_prompt": ""}
{"id": "c799851d-b068-4bd0-b963-ba94acdaae81", "fitness": 0.2555878825979164, "name": "AMDES", "description": "The algorithm seeds a center m from a small uniform archive and elite-weighted recombination with an initial diagonal covariance scaled to the search bounds and an adaptive population size lam0. Candidate generation mixes targeted eigenvector directional probes (both signs), antithetic Gaussian draws using the Cholesky/eigendecomposition of C, a cheap linear-ridge surrogate gradient probe built from the archive, and local uniform jitter — all clipped to box bounds. Adaptation blends rank-mu covariance updates with a momentum-derived rank-one term and an extra successful-step rank-1, applies per-coordinate EMA scaling (s_diag), enforces a tiny isotropic floor and eigen-clipping for SPD stability, and uses soft acceptance (partial nudge toward recombined m_new). A trust-region radius rho expands on center improvement and shrinks on failure (with a smoothed success rate), f(m) is approximated from the archive for acceptance decisions, and prolonged stagnation or rho collapse triggers opportunistic restarts around the global best (with budget-aware adjustments).", "code": "import numpy as np\n\nclass AMDES:\n    \"\"\"\n    Adaptive Momentum Directional Ensemble Sampler (AMDES)\n\n    One-line: Antithetic momentum-covariance sampling (MCAS-style) augmented with ADES-inspired\n    directional eigenvector proposals, a tiny linear-surrogate gradient probe, trust-region rho\n    expansion/shrinkage on center improvement, and rank-mu + rank-1 covariance updates with\n    per-coordinate scaling and opportunistic restarts.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop_base=None,\n                 cov_lr=0.20,          # rank-mu covariance learning rate\n                 rank1=0.06,           # rank-one momentum weight\n                 mom_beta=0.85,        # momentum smoothing\n                 s_diag_beta=0.6,      # per-coordinate EMA smoothing\n                 rho_init_frac=0.25,   # initial trust radius fraction of bounds\n                 rho_shrink=0.66,      # shrink factor on failure\n                 rho_expand=1.25,      # expand factor on success\n                 archive_size_factor=6,\n                 stagn_thresh_ratio=0.05):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.pop_base = pop_base\n        self.cov_lr = float(cov_lr)\n        self.rank1 = float(rank1)\n        self.mom_beta = float(mom_beta)\n        self.s_diag_beta = float(s_diag_beta)\n        self.rho_init_frac = float(rho_init_frac)\n        self.rho_shrink = float(rho_shrink)\n        self.rho_expand = float(rho_expand)\n        self.archive_size_factor = int(archive_size_factor)\n        self.stagn_thresh_ratio = float(stagn_thresh_ratio)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds support\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = ub - lb\n        max_bound = np.max(bounds_scale)\n        mean_range = float(np.mean(bounds_scale))\n\n        # population base (even for antithetic pairing)\n        if self.pop_base is None:\n            lam0 = max(6, int(3 + 2 * np.log(max(2, self.dim))))\n        else:\n            lam0 = int(self.pop_base)\n        lam0 = min(lam0, max(2, self.budget))\n        if lam0 % 2 == 1 and lam0 > 2:\n            lam0 -= 1\n\n        # archive and capacities\n        archive_capacity = max(self.dim * self.archive_size_factor, 4 * self.dim, 20)\n\n        evals = 0\n        # initial modest uniform sampling to seed m and C and archive\n        init_batch = min(max(2, lam0), max(2, int(self.budget // 25)))\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.empty(init_batch, dtype=float)\n        for i in range(init_batch):\n            f0[i] = float(func(X0[i]))\n            evals += 1\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # center m initialized by weighted recombination of top half\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w = np.maximum(w, 0.0)\n        if np.sum(w) <= 0:\n            w = np.ones_like(w)\n        w /= np.sum(w)\n        m = (w.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance and rho\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        rho = max(1e-8, self.rho_init_frac * mean_range)\n\n        # momentum and per-coordinate scaling\n        v = np.zeros(self.dim, dtype=float)\n        s_diag = np.ones(self.dim, dtype=float)\n\n        # archive lists\n        X_hist = [x.copy() for x in X0]\n        f_hist = [float(fi) for fi in f0]\n\n        stagn_iters = 0\n        stagn_thresh = max(5, int(self.stagn_thresh_ratio * self.budget))\n        p_succ = 0.2  # smoothed success-rate for mild sigma-like adaptation\n        iter_count = 0\n\n        # helper: SPD cholesky/eig factor\n        def chol_spd(mat):\n            eps = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam = min(lam0, remaining)\n            # ensure even for antithetic where possible\n            if remaining >= 2 and lam % 2 == 1 and lam > 1:\n                lam -= 1\n            lam = max(1, lam)\n            mu = max(1, lam // 2)\n\n            # recompute weights\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n            W = weights.reshape(-1, 1)\n\n            # eigen decomposition for directional proposals\n            try:\n                vals, vecs = np.linalg.eigh(C)\n            except np.linalg.LinAlgError:\n                vals = np.ones(self.dim)\n                vecs = np.eye(self.dim)\n            idxs = np.argsort(-vals)\n            vals = vals[idxs]\n            vecs = vecs[:, idxs]\n\n            candidates = []\n\n            # 1) directional eigenvector proposals (both signs) - a few slots\n            n_dir = min(max(1, lam // 4), self.dim)\n            for k in range(n_dir):\n                vdir = vecs[:, k]\n                eig_scale = np.sqrt(max(vals[k], 1e-12)) / (np.sqrt(np.mean(vals)) + 1e-12)\n                amp = rho * (0.9 + 0.5 * rng.rand()) * eig_scale\n                candidates.append(m + amp * vdir)\n                if len(candidates) >= lam:\n                    break\n                candidates.append(m - amp * vdir)\n                if len(candidates) >= lam:\n                    break\n\n            # 2) antithetic Gaussian proposals using C (fill half as pairs)\n            if len(candidates) < lam:\n                A = chol_spd(C)\n                remaining_slots = lam - len(candidates)\n                half = remaining_slots // 2\n                if half > 0:\n                    Zpos = rng.normal(size=(half, self.dim))\n                    Z = np.vstack([Zpos, -Zpos])\n                else:\n                    Z = np.empty((0, self.dim))\n                if remaining_slots % 2 == 1:\n                    Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n                if Z.shape[0] > 0:\n                    Y = Z @ A.T\n                    Xg = m + rho * (Y * s_diag.reshape(1, -1))\n                    for xi in Xg:\n                        candidates.append(xi)\n                        if len(candidates) >= lam:\n                            break\n\n            # 3) gradient-exploitation linear surrogate candidate (cheap linear ridge) if archive enough\n            grad_candidate = None\n            if len(candidates) < lam and len(f_hist) >= min(self.dim + 2, 8):\n                n_fit = min(len(X_hist), archive_capacity)\n                X_fit = np.asarray(X_hist[-n_fit:])\n                f_fit = np.asarray(f_hist[-n_fit:])\n                # center w.r.t current m\n                Xc = X_fit - m\n                # pick archive point closest to m to estimate f(m)\n                dists = np.sum((X_fit - m) ** 2, axis=1)\n                idxc = int(np.argmin(dists))\n                f_center = float(f_fit[idxc])\n                y = f_fit - f_center\n                lam_reg = 1e-6 * (1.0 + np.var(y))\n                XT_X = Xc.T @ Xc\n                try:\n                    beta = np.linalg.solve(XT_X + lam_reg * np.eye(self.dim), Xc.T @ y)\n                    g = beta\n                    gnorm = np.linalg.norm(g)\n                    if gnorm > 0:\n                        step_scale = rho * (0.7 + 0.5 * rng.rand())\n                        # move opposite to gradient estimate\n                        grad_candidate = m - (step_scale * (g / (gnorm + 1e-20)))\n                except np.linalg.LinAlgError:\n                    grad_candidate = None\n            if grad_candidate is not None:\n                candidates.append(grad_candidate)\n\n            # 4) fill remaining with local jitter uniform box around m\n            while len(candidates) < lam:\n                box = np.clip(0.8 * rho, 1e-12, np.max(bounds_scale))\n                cand = m + rng.uniform(-box, box, size=self.dim)\n                candidates.append(cand)\n\n            # clip candidates to bounds\n            Xcand = np.asarray(candidates[:lam])\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates sequentially\n            fc = np.full(Xcand.shape[0], np.inf, dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                xi = Xcand[i]\n                fv = float(func(xi))\n                fc[i] = fv\n                evals += 1\n                # immediate global best update\n                if fv < f_best:\n                    f_best = fv\n                    x_best = xi.copy()\n                    stagn_iters = 0\n\n            # if budget exhausted mid-batch, truncate\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                if Xcand.shape[0] == 0:\n                    break\n\n            # append to archive (trim)\n            for xi, fi in zip(Xcand, fc):\n                X_hist.append(xi.copy())\n                f_hist.append(float(fi))\n            if len(X_hist) > archive_capacity:\n                excess = len(X_hist) - archive_capacity\n                X_hist = X_hist[excess:]\n                f_hist = f_hist[excess:]\n\n            # determine generation best and approximate f(m) using nearest archive point\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            # approximate f(m) from archive\n            if len(X_hist) > 0:\n                Xh = np.asarray(X_hist)\n                dists = np.sum((Xh - m) ** 2, axis=1)\n                idx0 = int(np.argmin(dists))\n                f_m_approx = float(f_hist[idx0])\n            else:\n                f_m_approx = f_best\n\n            improved_center = gen_best_f < f_m_approx - 1e-12\n\n            # recompute new center by weighted recombination of top mu candidates\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            if X_mu.shape[0] == 0:\n                m_new = m.copy()\n            else:\n                if X_mu.shape[0] != weights.shape[0]:\n                    mu_eff = X_mu.shape[0]\n                    w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if np.sum(w_eff) <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff /= np.sum(w_eff)\n                    m_new = (w_eff.reshape(-1, 1) * X_mu).sum(axis=0)\n                else:\n                    m_new = (W * X_mu).sum(axis=0)\n\n            # normalized deltas for covariance/momentum update (w.r.t rho)\n            deltas = (X_mu - m) / (rho + 1e-20)  # shape (mu, dim)\n            if deltas.shape[0] > 0:\n                if deltas.shape[0] != weights.shape[0]:\n                    mu_eff = deltas.shape[0]\n                    w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if np.sum(w_eff) <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff /= np.sum(w_eff)\n                    Wd = w_eff.reshape(-1, 1)\n                    weighted_cov = (deltas * Wd).T @ deltas\n                    delta_mean = (Wd * deltas).sum(axis=0)\n                else:\n                    weighted_cov = (deltas * W).T @ deltas\n                    delta_mean = (W * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # momentum update (in normalized coordinates)\n            v = self.mom_beta * v + (1.0 - self.mom_beta) * delta_mean\n            rank_one = np.outer(v, v)\n\n            # additional small rank-1 from successful step direction if improved\n            if improved_center:\n                succ_step = (gen_best_x - m) / (rho + 1e-20)\n                dir_cov = np.outer(succ_step, succ_step)\n            else:\n                dir_cov = np.zeros((self.dim, self.dim))\n\n            # covariance update: mix old, weighted_cov and rank-one and successful-step component\n            c = float(self.cov_lr)\n            r1 = float(self.rank1)\n            # blend weights: keep some weight on old covariance to stabilize\n            C = (1.0 - c) * C + c * (0.8 * weighted_cov + 0.15 * rank_one + 0.05 * dir_cov)\n            # tiny isotropic floor to avoid collapse\n            floor = np.diag(((bounds_scale / 30.0) ** 2).clip(min=1e-12))\n            C = 0.997 * C + 0.003 * floor\n\n            # symmetry and eigen clipping\n            C = 0.5 * (C + C.T)\n            valsC, vecsC = np.linalg.eigh(C)\n            valsC = np.clip(valsC, 1e-12, None)\n            C = (vecsC * valsC) @ vecsC.T\n\n            # center acceptance and trust-region adaptation\n            if improved_center:\n                m = m_new.copy()\n                rho = min(2.0 * max_bound, rho * self.rho_expand)\n                stagn_iters = 0\n                p_succ = 0.9 * p_succ + 0.1 * 1.0\n            else:\n                stagn_iters += 1\n                rho = max(1e-12, rho * self.rho_shrink)\n                p_succ = 0.9 * p_succ + 0.1 * 0.0\n\n            # soft acceptance: nudge m toward m_new even if not fully accepted\n            m = 0.85 * m + 0.15 * m_new\n            # clamp center\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # update per-coordinate scale s_diag (EMA of sqrt of mean squared deltas)\n            if deltas.shape[0] > 0:\n                stat = np.mean(deltas ** 2, axis=0)\n            else:\n                stat = 1e-6 * np.ones(self.dim)\n            s_diag = self.s_diag_beta * s_diag + (1.0 - self.s_diag_beta) * np.sqrt(stat + 1e-20)\n            s_diag = np.clip(s_diag, 0.2, 5.0)\n\n            # opportunistic restart if stagnation prolonged or rho collapsed too small\n            if (stagn_iters >= stagn_thresh) or (rho <= 1e-12 * max_bound):\n                stagn_iters = 0\n                # reinitialize around best with jitter proportionate to bounds and rho\n                jitter = np.maximum(0.5 * rho, 0.06 * mean_range)\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                rho = max(self.rho_init_frac * mean_range * 0.8, 1e-12)\n                v = np.zeros(self.dim)\n                s_diag = np.ones(self.dim)\n                # slightly shrink population if budget tiny (not strictly necessary)\n                if self.budget < 200:\n                    lam0 = max(4, lam0 // 2)\n                continue\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AMDES scored 0.256 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "dd291d53-01ec-4a34-9cd6-09226201dd4e", "operator": null, "metadata": {"aucs": [0.13695895784317447, 0.16661110276337798, 0.1988352518383446, 0.9597119828708756, 0.1296987793719232, 0.2292980456311441, 0.21855319057186828, 0.1686400573951643, 0.19665553562459437, 0.15091592206869764]}, "task_prompt": ""}
{"id": "ed921f66-687b-45fd-840f-bb80c0d186a6", "fitness": "-inf", "name": "ASLLevy", "description": "ASLLevy maintains a small archive of best points and a population of \"swarmlets\" (position, value, trust-radius, age, recent-move history) initialized by adaptive sampling (init_samples ≈ 6*dim capped at 60, archive_k and pop_size chosen in small ranges) and evaluated via a budget‑aware wrapper. Each iteration it picks a swarmlet by a rank+novelty softmax (temperature-controlled) and fits a regularized quadratic surrogate in a random low‑rank orthonormal subspace (dim ≤ 3) using an oversampled design matrix (features [1, t, 0.5 t_i t_j]) and Tikhonov regularization whose strength scales with radius, then computes the analytic minimizer t* (clamped), maps it back to the full space and evaluates the candidate. Behavior adapts: radii expand on success and contract on failure, recent moves provide momentum-style extrapolation, and stuck swarmlets trigger heavy‑tailed Lévy (Cauchy) jumps or jitter/replacement around archive best to revive exploration. Global diversification is provided by periodic PCA‑guided jumps from the archive mean, occasional uniform injections, and budget-aware pruning/temperature scheduling to balance local surrogate search and wide exploration.", "code": "import numpy as np\nfrom collections import deque\n\nclass ASLLevy:\n    \"\"\"\n    Adaptive Subspace-Lévy Search (ASL)\n\n    Key ideas:\n    - Maintain a small archive of best points and a population of \"swarmlets\"\n      (position, value, trust-radius, age, recent-moves history).\n    - For each selected swarmlet build a local low-rank quadratic surrogate in a\n      random orthonormal subspace (dim ≤ 3). Solve for the surrogate minimizer\n      analytically (t* = -H^{-1} b) with Tikhonov regularization. Clamp steps.\n    - If surrogate improvement occurs, expand trust radius and update momentum;\n      on failure contract radius and attempt a Lévy-style heavy-tailed jump.\n    - Periodically perform PCA-guided Lévy jumps from the archive mean along\n      top eigenvectors and occasionally replace oldest/poorest swarmlets to\n      maintain exploration/diversity.\n    - Budget-aware eval wrapper ensures we never exceed self.budget.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop_size=None, archive_k=None, init_samples=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.pop_size = pop_size\n        self.archive_k = archive_k\n        self.init_samples = init_samples\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds (support scalar or array)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive defaults\n        if self.init_samples is None:\n            init_samples = max(12, min(60, 6 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, self.budget)\n\n        if self.archive_k is None:\n            archive_k = max(4, min(12, init_samples // 3))\n        else:\n            archive_k = int(self.archive_k)\n\n        if self.pop_size is None:\n            pop_size = max(3, min(12, archive_k))\n        else:\n            pop_size = int(self.pop_size)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        # archive of best points (sorted by f)\n        archive = []\n\n        # eval wrapper that clips to bounds and enforces budget\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = float(func(x))\n            evals += 1\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # insert into archive if good\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        # initial sampling\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one archive point\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # initialize swarmlets from top archive + jitter if needed\n        swarmlets = []\n        for i in range(min(pop_size, len(archive))):\n            f0, x0 = archive[i]\n            r0 = max(0.04 * avg_span, 0.2 * avg_span * (0.9 ** i))\n            swarmlets.append({\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': float(r0),\n                'age': 0,\n                'hist': deque(maxlen=6)  # recent moves for momentum\n            })\n        while len(swarmlets) < pop_size and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            res = eval_and_record(x0)\n            if res is None:\n                break\n            f0, x0 = res\n            swarmlets.append({\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': 0.25 * avg_span,\n                'age': 0,\n                'hist': deque(maxlen=6)\n            })\n\n        # selection hyperparams\n        temp = 1.0\n        iteration = 0\n        stagn = 0\n\n        # helper: orthonormal basis with k columns\n        def random_orthonormal(k):\n            A = rng.randn(self.dim, k)\n            try:\n                Q, _ = np.linalg.qr(A)\n            except Exception:\n                Q = A / (np.linalg.norm(A, axis=0, keepdims=True) + 1e-12)\n            return Q[:, :k]\n\n        # main loop\n        while evals < self.budget:\n            iteration += 1\n\n            # selection: combine rank and novelty\n            fs = np.array([s['f'] for s in swarmlets], dtype=float)\n            ranks = np.argsort(np.argsort(fs))  # lower is better\n            # novelty = distance to archive best if available\n            arch_center = np.mean([p[1] for p in archive], axis=0) if len(archive) > 0 else np.zeros(self.dim)\n            nov = np.array([np.linalg.norm(s['x'] - arch_center) for s in swarmlets])\n            # score: favor low f and moderate novelty\n            score = - ( -ranks + 0.5 * (nov / (1e-8 + np.mean(nov)+1e-12)) )\n            # softmax selection\n            z = -score / max(1e-9, temp)\n            probs = np.exp(z - np.max(z))\n            probs /= probs.sum()\n            idx = rng.choice(len(swarmlets), p=probs)\n            s = swarmlets[idx]\n            x0 = s['x'].copy()\n            f0 = s['f']\n            r0 = float(s['r'])\n\n            improved = False\n            # subspace dimension: prefer 1-3 depending on radius and dim\n            max_sub = min(3, self.dim)\n            # smaller radius -> smaller subspace to save evals\n            if r0 < 0.02 * avg_span:\n                sub_d = 1\n            else:\n                sub_d = rng.choice([1, 2, max_sub], p=[0.4, 0.4, 0.2]) if max_sub > 1 else 1\n\n            B = random_orthonormal(sub_d)  # columns are basis vectors\n\n            # generate sample points for quadratic fit in the subspace:\n            # if sub_d <= 3 try to fit full quadratic: params = 1 + s + s*(s+1)/2\n            sdim = sub_d\n            if sdim <= 3:\n                num_params = 1 + sdim + (sdim * (sdim + 1)) // 2\n            else:\n                num_params = 1 + 2 * sdim  # fallback (not used)\n            # required samples\n            m = max(num_params + 1, 2 * num_params)  # oversample for stability\n            m = min(m, max(6, 2 * num_params))  # cap m\n            # limit evaluations so not to exhaust budget\n            m = int(min(m, max(1, self.budget - evals - 1)))  # leave room for candidate eval\n\n            # sample points t in subspace (center + random +/- steps scaled by r0)\n            # use a small design: include center, axis +/-1, and random points\n            Ts = []\n            Xs = []\n            Fs = []\n            # center\n            Ts.append(np.zeros(sdim))\n            Xs.append(x0.copy())\n            Fs.append(f0)\n            # axis points and some random directions\n            axis_count = min(sdim, max(1, m - 1))\n            for i in range(axis_count):\n                for sign in [-1, 1]:\n                    if len(Ts) >= m:\n                        break\n                    t = np.zeros(sdim)\n                    t[i] = sign * (0.6 + 0.8 * rng.rand())  # relative step multiplier\n                    Ts.append(t)\n                    Xs.append(np.minimum(np.maximum(x0 + B @ (t * r0), lb), ub))\n                    res = eval_and_record(Xs[-1])\n                    if res is None:\n                        break\n                    Fs.append(res[0])\n                if evals >= self.budget or len(Ts) >= m:\n                    break\n            # fill with random t if budget allows\n            while len(Ts) < m and evals < self.budget:\n                t = rng.randn(sdim)\n                t = t / (np.linalg.norm(t) + 1e-12)\n                t = t * (0.3 + 1.4 * rng.rand())  # scaled unit\n                Ts.append(t)\n                Xs.append(np.minimum(np.maximum(x0 + B @ (t * r0), lb), ub))\n                res = eval_and_record(Xs[-1])\n                if res is None:\n                    break\n                Fs.append(res[0])\n\n            # if not enough samples collected, skip surrogate step\n            if len(Ts) < 3:\n                # fallback: small random exploration\n                step_len = r0 * (0.5 + rng.rand())\n                step = rng.randn(self.dim)\n                step = step / (np.linalg.norm(step) + 1e-12) * step_len\n                x_try = np.minimum(np.maximum(x0 + step, lb), ub)\n                res = eval_and_record(x_try)\n                if res is not None:\n                    ftry, xtry = res\n                    if ftry < s['f'] - 1e-12:\n                        s['x'] = xtry.copy(); s['f'] = float(ftry); improved = True\n                        s['r'] = min(2.0 * avg_span, s['r'] * 1.25)\n                        s['hist'].append(xtry - x0)\n                        s['age'] = 0\n                    else:\n                        s['r'] = max(1e-8, s['r'] * 0.7)\n                        s['age'] += 1\n                        stagn += 1\n                continue\n\n            # build regression to fit quadratic in t variables: features are [1, t_i, 0.5*t_i*t_j (i<=j)]\n            Ts_arr = np.asarray(Ts, dtype=float)\n            Fs_arr = np.asarray(Fs, dtype=float)\n            n_samples, sd = Ts_arr.shape[0], sdim\n\n            # construct design matrix\n            def build_design(Ts_local):\n                rows = []\n                for t in Ts_local:\n                    row = [1.0]\n                    row.extend(list(t))\n                    # quadratic terms i<=j\n                    for i in range(sd):\n                        for j in range(i, sd):\n                            row.append(0.5 * t[i] * t[j])\n                    rows.append(row)\n                return np.asarray(rows, dtype=float)\n            Phi = build_design(Ts_arr)\n            # regularized least squares\n            lam = 1e-6 + 1e-3 * (1.0 / max(1.0, r0 / (avg_span + 1e-12)))\n            try:\n                # solve theta = (Phi^T Phi + lam I)^{-1} Phi^T y\n                A = Phi.T @ Phi\n                A += lam * np.eye(A.shape[0])\n                bvec = Phi.T @ Fs_arr\n                theta = np.linalg.solve(A, bvec)\n            except Exception:\n                theta = None\n\n            if theta is None:\n                # fallback small random step\n                step_len = r0 * (0.3 + rng.rand())\n                step = rng.randn(self.dim)\n                step = step / (np.linalg.norm(step) + 1e-12) * step_len\n                x_try = np.minimum(np.maximum(x0 + step, lb), ub)\n                res = eval_and_record(x_try)\n                if res is not None:\n                    ftry, xtry = res\n                    if ftry < s['f'] - 1e-12:\n                        s['x'] = xtry.copy(); s['f'] = float(ftry); improved = True\n                        s['r'] = min(2.0 * avg_span, s['r'] * 1.25)\n                        s['hist'].append(xtry - x0)\n                        s['age'] = 0\n                    else:\n                        s['r'] = max(1e-8, s['r'] * 0.7)\n                        s['age'] += 1\n                        stagn += 1\n                continue\n\n            # parse theta into a, b, H\n            idx = 0\n            a_est = float(theta[idx]); idx += 1\n            b_est = np.array(theta[idx: idx + sd], dtype=float); idx += sd\n            H_est = np.zeros((sd, sd), dtype=float)\n            for i in range(sd):\n                for j in range(i, sd):\n                    H_est[i, j] = float(theta[idx]); H_est[j, i] = H_est[i, j]\n                    idx += 1\n\n            # compute minimizer in t-space: solve H t = -b (note H here is 0.5*second derivatives in our parameterization\n            # because we used 0.5*t_i*t_j in features; actual Hessian = H_est)\n            # ensure H_reg positive definite by adding small diagonal\n            H_reg = H_est.copy()\n            # regularization proportional to spectral norm\n            try:\n                eigs = np.linalg.eigvalsh(H_reg)\n                min_eig = np.min(eigs)\n            except Exception:\n                min_eig = 0.0\n            tau = max(1e-8, 1e-3 * (1.0 + max(0.0, -min_eig)))\n            H_reg += tau * np.eye(sd)\n\n            try:\n                t_star = -np.linalg.solve(H_reg, b_est)\n            except Exception:\n                t_star = -b_est / (np.diag(H_reg) + 1e-12)\n\n            # clamp t_star magnitude relative to r0 (limit to 2*r0 in Euclidean norm in t-space units)\n            t_norm = np.linalg.norm(t_star)\n            if t_norm > 2.0:\n                t_star = t_star * (2.0 / (t_norm + 1e-12))\n            # candidate in full space\n            x_cand = np.minimum(np.maximum(x0 + B @ (t_star * r0), lb), ub)\n            res_c = eval_and_record(x_cand)\n            if res_c is not None:\n                f_c, x_cand = res_c\n                if f_c < s['f'] - 1e-12:\n                    # accept surrogate suggestion\n                    s['x'] = x_cand.copy()\n                    s['f'] = float(f_c)\n                    s['r'] = min(2.0 * avg_span, s['r'] * 1.3)\n                    s['hist'].append(x_cand - x0)\n                    s['age'] = 0\n                    improved = True\n                    stagn = 0\n                else:\n                    # try small extrapolation along principal surrogate direction (first basis)\n                    dir_try = B[:, 0]\n                    step_len = r0 * (0.6 + rng.rand() * 0.8)\n                    x_try = np.minimum(np.maximum(x0 + dir_try * step_len, lb), ub)\n                    res_try = eval_and_record(x_try)\n                    if res_try is not None:\n                        f_try, x_try = res_try\n                        if f_try < s['f'] - 1e-12:\n                            s['x'] = x_try.copy()\n                            s['f'] = float(f_try)\n                            s['r'] = min(2.0 * avg_span, s['r'] * 1.2)\n                            s['hist'].append(x_try - x0)\n                            s['age'] = 0\n                            improved = True\n                            stagn = 0\n                        else:\n                            s['r'] = max(1e-8, s['r'] * 0.68)\n                            s['age'] += 1\n                            stagn += 1\n                    else:\n                        s['r'] = max(1e-8, s['r'] * 0.68)\n                        s['age'] += 1\n                        stagn += 1\n            else:\n                # out of budget\n                break\n\n            # if failed and age high, attempt a Lévy jump (heavy-tailed)\n            if not improved and s['age'] > 6 and evals < self.budget:\n                # Lévy (Cauchy) scaled by radius and archive spread\n                scale = max(0.5 * s['r'], 0.1 * avg_span)\n                step_len = float(np.clip(rng.standard_cauchy() * scale, -5.0 * avg_span, 5.0 * avg_span))\n                dir_rand = rng.randn(self.dim)\n                dir_rand /= (np.linalg.norm(dir_rand) + 1e-12)\n                x_jump = np.minimum(np.maximum(s['x'] + dir_rand * step_len, lb), ub)\n                res_j = eval_and_record(x_jump)\n                if res_j is not None:\n                    fj, x_jump = res_j\n                    if fj < s['f'] - 1e-12:\n                        s['x'] = x_jump.copy(); s['f'] = float(fj); s['r'] = max(s['r'], scale)\n                        s['hist'].clear(); s['age'] = 0\n                        improved = True\n                        stagn = 0\n                    else:\n                        # if still bad, replace this swarmlet by jitter around archive best sometimes\n                        if rng.rand() < 0.4 and len(archive) > 0:\n                            base = archive[0][1]\n                            jitter = 0.2 * avg_span * rng.randn(self.dim)\n                            new_x = np.minimum(np.maximum(base + jitter, lb), ub)\n                            res_n = eval_and_record(new_x)\n                            if res_n is not None:\n                                fn, new_x = res_n\n                                s['x'] = new_x.copy(); s['f'] = float(fn); s['r'] = 0.3 * avg_span\n                                s['hist'].clear(); s['age'] = 0\n\n            # momentum-style extrapolation using recent history\n            if len(s['hist']) >= 2 and evals < self.budget:\n                # compute EMA momentum\n                hist_arr = np.vstack(list(s['hist']))\n                mom = np.mean(hist_arr, axis=0)\n                mom_norm = np.linalg.norm(mom)\n                if mom_norm > 1e-10:\n                    alpha = 0.6\n                    x_m = np.minimum(np.maximum(s['x'] + alpha * mom, lb), ub)\n                    res_m = eval_and_record(x_m)\n                    if res_m is not None:\n                        fm, xm = res_m\n                        if fm < s['f'] - 1e-12:\n                            s['x'] = xm.copy(); s['f'] = float(fm)\n                            s['r'] = min(2.0 * avg_span, s['r'] * 1.2)\n                            s['hist'].append(xm - x0)\n                            s['age'] = 0\n                            improved = True\n                            stagn = 0\n                        else:\n                            # damp history to avoid repeating bad directions\n                            for _ in range(min(2, len(s['hist']))):\n                                s['hist'].pop()\n\n            # periodic PCA-guided archive jump for global exploration\n            if (iteration % 23 == 0 or stagn > 120) and len(archive) >= 3 and evals < self.budget:\n                pts = np.vstack([p[1] for p in archive])\n                mean = np.mean(pts, axis=0)\n                Xc = pts - mean\n                C = (Xc.T @ Xc) / max(1.0, pts.shape[0]) + 1e-9 * np.eye(self.dim)\n                try:\n                    eigvals, eigvecs = np.linalg.eigh(C)\n                    idx_top = np.argsort(eigvals)[-min(3, len(eigvals))]\n                    v = eigvecs[:, idx_top]\n                    # mix top directions into a single vector\n                    v = np.mean(v, axis=1)\n                    v = v / (np.linalg.norm(v) + 1e-12)\n                    lam = float(np.mean(eigvals[-min(3, len(eigvals)):]))\n                except Exception:\n                    v = rng.randn(self.dim); v /= (np.linalg.norm(v) + 1e-12); lam = 1.0\n                # heavy tail move\n                scale = (np.sqrt(max(1e-8, lam)) + 0.2) * 0.8 * avg_span\n                step_len = float(np.clip(rng.standard_cauchy() * scale, -6.0 * avg_span, 6.0 * avg_span))\n                x_jump = np.minimum(np.maximum(mean + step_len * v, lb), ub)\n                res_j = eval_and_record(x_jump)\n                if res_j is not None:\n                    fj, x_jump = res_j\n                    # replace worst swarmlet or append with some chance\n                    worst_idx = int(np.argmax([sw['f'] for sw in swarmlets]))\n                    if fj < swarmlets[worst_idx]['f']:\n                        swarmlets[worst_idx] = {\n                            'x': x_jump.copy(),\n                            'f': float(fj),\n                            'r': 0.4 * avg_span,\n                            'age': 0,\n                            'hist': deque(maxlen=6)\n                        }\n                    else:\n                        if rng.rand() < 0.15 and len(swarmlets) < 2 * pop_size:\n                            swarmlets.append({\n                                'x': x_jump.copy(),\n                                'f': float(fj),\n                                'r': 0.4 * avg_span,\n                                'age': 0,\n                                'hist': deque(maxlen=6)\n                            })\n                stagn = 0\n\n            # prune/pop control: keep best pop_size swarmlets\n            swarmlets.sort(key=lambda t: t['f'])\n            if len(swarmlets) > pop_size:\n                swarmlets = swarmlets[:pop_size]\n\n            # adaptive temperature and stagnation update\n            if improved:\n                temp = max(0.3, temp * 0.97)\n                stagn = 0\n            else:\n                temp = min(5.0, temp * 1.02)\n                stagn += 1\n\n            # occasional uniform injection\n            if iteration % 37 == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # break if no budget left\n            if evals >= self.budget:\n                break\n\n        # finalize best\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 110, in __call__, the following error occurred:\nNameError: name 'deque' is not defined\nOn line: 'hist': deque(maxlen=6)  # recent moves for momentum", "error": "In the code, line 110, in __call__, the following error occurred:\nNameError: name 'deque' is not defined\nOn line: 'hist': deque(maxlen=6)  # recent moves for momentum", "parent_ids": "190f07d3-62a5-43e2-82e1-78ebbbad2370", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "d0821918-aa48-47fd-8374-2b73ff166718", "fitness": 0.3468028605479785, "name": "LAVA", "description": "LAVA is a hybrid local–global heuristic that maintains a sorted archive and a set of adaptive probes: it combines directional local search (asymmetric 3‑point parabolic probes and small local polish) with momentum‑biased extrapolation and PCA‑guided global Cauchy/Levy jumps for exploration. Probe step control is aggressive: radius expansion is large (expand_factor=1.5) while shrink is strong (shrink_factor=0.5), momentum smoothing is biased toward new moves (mom_old_weight=0.3, mom_new_weight=0.7) and extrapolation is deliberately aggressive (extrap_alpha=1.2) but clamped; local polishing uses a smaller radius fraction (local_polish_frac=0.15) for fine tuning. Initialization and population sizing use explicit formulae and stratified (Latin‑hypercube‑like) seeding, selection of probes is a softmax over negative fitness with a small age penalty and adaptive temperature annealing, and probes are replaced by age‑weighted worst scoring entries to retain diversity. Robustness safeguards (bounds clipping, min_radius, max_probe_multiplier), scheduled injections/restarts (inject, uniform_restart, global_jump frequencies), and PCA/eigenvector scaling for global jumps (with a tempered Cauchy multiplier) further balance exploration versus exploitation.", "code": "import numpy as np\n\nclass LAVA:\n    \"\"\"\n    LAVA: Levy-Adaptive Variable-scale Archive\n\n    Main ideas (differences vs typical FAMS-style):\n    - Different default parameter equations: larger expansion (×1.5) and stronger shrink (×0.5),\n      momentum smoothing biased to new moves (mom = 0.3*mom + 0.7*move), more aggressive extrapolation\n      (alpha=1.2, clamped), smaller local polish (0.15*r), and different injection/jump schedules.\n    - Uses an explicit set of tunable parameters exposed in __init__ so the parameter choices\n      are clear and different from the provided algorithm.\n    - Mixes directional parabolic 1D probes (as in FAMS) with Levy/Cauchy global jumps guided\n      by PCA of the archive and age-weighted probe replacement.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10,\n                 rng_seed=None,\n                 init_samples=None,\n                 archive_size=None,\n                 probe_count=None,\n                 # parameter differences / equations compared to original:\n                 init_samples_eq=lambda d: max(10, 4 * d),   # new init sampling equation\n                 archive_frac_eq=lambda n: max(4, min(10, n // 2)),\n                 probe_count_eq=lambda k, d: max(3, min(k, max(3, d // 2))),\n                 expand_factor=1.5,   # was 1.25\n                 shrink_factor=0.5,   # was 0.65\n                 mom_old_weight=0.3,  # old momentum weight (was 0.6)\n                 mom_new_weight=0.7,  # new move weight (was 0.4)\n                 extrap_alpha=1.2,    # was 0.8 (more aggressive)\n                 local_polish_frac=0.15,  # was 0.3 (smaller polish radius)\n                 sel_temp_init=0.8,\n                 stagnation_pca_thresh=25,  # different threshold\n                 inject_frequency=13,\n                 uniform_restart_frequency=37,\n                 global_jump_frequency=19,\n                 max_probe_multiplier=2.5,\n                 min_radius=1e-8):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.probe_count = probe_count\n\n        # exposed strategy equations / parameters (so they are explicit)\n        self.init_samples_eq = init_samples_eq\n        self.archive_frac_eq = archive_frac_eq\n        self.probe_count_eq = probe_count_eq\n\n        self.expand_factor = float(expand_factor)\n        self.shrink_factor = float(shrink_factor)\n        self.mom_old_weight = float(mom_old_weight)\n        self.mom_new_weight = float(mom_new_weight)\n        self.extrap_alpha = float(extrap_alpha)\n        self.local_polish_frac = float(local_polish_frac)\n        self.sel_temp_init = float(sel_temp_init)\n        self.stagnation_pca_thresh = int(stagnation_pca_thresh)\n        self.inject_frequency = int(inject_frequency)\n        self.uniform_restart_frequency = int(uniform_restart_frequency)\n        self.global_jump_frequency = int(global_jump_frequency)\n        self.max_probe_multiplier = float(max_probe_multiplier)\n        self.min_radius = float(min_radius)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds similarly (support scalar or arrays). Many-BBOB uses [-5,5].\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive defaults using the alternate equations supplied\n        if self.init_samples is None:\n            init_samples = min(self.budget, int(self.init_samples_eq(self.dim)))\n        else:\n            init_samples = min(self.budget, int(self.init_samples))\n\n        if self.archive_size is None:\n            archive_k = int(self.archive_frac_eq(init_samples))\n        else:\n            archive_k = int(self.archive_size)\n\n        if self.probe_count is None:\n            probe_count = int(self.probe_count_eq(archive_k, self.dim))\n        else:\n            probe_count = int(self.probe_count)\n\n        # bookkeeping\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x)\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # clip to bounds\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            # update best\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # insert into archive (sorted)\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        # initial sampling: use stratified-ish seeding (simple Latin-hypercube-like)\n        # to diversify initial archive (different eq than original).\n        if init_samples > 0:\n            # generate init_samples points via simple stratified sampling per dimension\n            # (avoid extra libraries)\n            strata = np.linspace(0.0, 1.0, init_samples + 1)\n            centers = 0.5 * (strata[:-1] + strata[1:])\n            for i in range(init_samples):\n                if evals >= self.budget:\n                    break\n                u = rng.rand(self.dim)\n                # permute centers per dimension to reduce clustering\n                perm_centers = centers.copy()\n                rng.shuffle(perm_centers)\n                x = lb + (perm_centers[i] + 0.5 * (u - 0.5) / init_samples) * span\n                # fallback: if any NaNs or out-of-bounds, use uniform\n                if not np.all(np.isfinite(x)):\n                    x = rng.uniform(lb, ub)\n                eval_and_record(x)\n\n        # ensure at least one sample\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # initialize probes from archive top entries but with different radius eq\n        probes = []\n        for i in range(min(probe_count, len(archive))):\n            f0, x0 = archive[i]\n            # radius: base 0.2*avg_span scaled by (1 + 0.3*rand) and decayed with rank\n            r_init = 0.2 * avg_span * (1.0 + 0.3 * rng.rand()) * (0.85 ** i)\n            r_init = max(self.min_radius, min(r_init, self.max_probe_multiplier * avg_span))\n            probe = {\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': float(r_init),\n                'mom': np.zeros(self.dim, dtype=float),\n                'age': 0\n            }\n            probes.append(probe)\n        # fill remaining probes with random archive samples or uniform random\n        while len(probes) < probe_count and evals < self.budget:\n            if len(archive) > 0 and rng.rand() < 0.7:\n                # jitter around a random archive entry\n                base = archive[rng.randint(len(archive))][1]\n                jitter = 0.25 * avg_span * rng.randn(self.dim)\n                x0 = np.minimum(np.maximum(base + jitter, lb), ub)\n            else:\n                x0 = rng.uniform(lb, ub)\n            res = eval_and_record(x0)\n            if res is None:\n                break\n            f0, x0 = res\n            probes.append({\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': 0.2 * avg_span,\n                'mom': np.zeros(self.dim, dtype=float),\n                'age': 0\n            })\n\n        sel_temp = float(self.sel_temp_init)\n        attempt = 0\n        stagnation_counter = 0\n\n        # main loop\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n\n            # choose a probe: softmax over -f but incorporate age to favor fresh probes slightly\n            fs = np.array([p['f'] for p in probes], dtype=float)\n            ages = np.array([p['age'] for p in probes], dtype=float)\n            score = -fs - 0.02 * ages * avg_span  # penalize very old probes slightly\n            z = score / max(1e-9, sel_temp)\n            z = z - np.max(z)\n            probs = np.exp(z)\n            probs = probs / probs.sum()\n            idx = rng.choice(len(probes), p=probs)\n            probe = probes[idx]\n            x0 = probe['x'].copy()\n            f0 = probe['f']\n            r0 = probe['r']\n\n            improved = False\n\n            # choose subspace dimension: bias to 1D or 2D depending on dim, with occasional coordinate search\n            if rng.rand() < 0.7 or self.dim == 1:\n                k = min(2, self.dim)\n            else:\n                k = min(3, self.dim)\n            # build random orthonormal directions\n            A = rng.randn(self.dim, k)\n            try:\n                Q, _ = np.linalg.qr(A)\n            except Exception:\n                Q = A / (np.linalg.norm(A, axis=0, keepdims=True) + 1e-12)\n            directions = [Q[:, j] for j in range(k)]\n\n            # directional probing: asymmetric 3-point probing (we will use -s, 0, +c*s)\n            for d in directions:\n                if evals >= self.budget:\n                    break\n                # step magnitude: probe radius times factor uniform [0.4,1.6] (wider than original)\n                s = r0 * (0.4 + 1.2 * rng.rand())\n                # pick asymmetry factor c in [0.8, 1.8] to allow non-symmetric fits\n                c = 0.8 + 1.0 * rng.rand()\n                step_minus = d * s\n                step_plus = d * (c * s)\n\n                # evaluate -step\n                x_minus = np.minimum(np.maximum(x0 - step_minus, lb), ub)\n                res_minus = eval_and_record(x_minus)\n                if res_minus is None:\n                    break\n                f_minus, x_minus = res_minus\n\n                # evaluate +step\n                x_plus = np.minimum(np.maximum(x0 + step_plus, lb), ub)\n                res_plus = eval_and_record(x_plus)\n                if res_plus is None:\n                    break\n                f_plus, x_plus = res_plus\n\n                # parabolic fit generalized for points at -s and +c*s\n                # map to t parameter where center is 0, left at t=-1, right at t=+c\n                # quadratic fit f(t)=a t^2 + b t + c0; use three points to get minimizer t* = -b/(2a)\n                denom = ( (f_minus * (c**2)) + (f_plus * (1.0)) - ( (1.0 + c**2) * f0 ) )\n                t_star = None\n                if abs(denom) > 1e-12:\n                    # derived formula for t* for these sample positions:\n                    # using system solve gives t* = (c*(f_minus - f_plus) + (c-1)*f0 ) / (2*denom_scaled)\n                    # we use a numerically stable approximate that reduces to symmetric case when c=1\n                    t_num = c * (f_minus - f_plus)\n                    t_den = 2.0 * denom\n                    t_star = float(np.clip(t_num / t_den, -3.0, 3.0))\n                    # convert t_star to displacement along d (units of s)\n                    # t is in units where right point is at +c, so displacement = t_star * s\n                    disp = t_star * s\n                    x_parab = x0 + d * disp\n                    x_parab = np.minimum(np.maximum(x_parab, lb), ub)\n                    res_parab = eval_and_record(x_parab)\n                    if res_parab is not None:\n                        f_parab, x_parab = res_parab\n                    else:\n                        f_parab = None\n                else:\n                    f_parab = None\n                    x_parab = None\n\n                # choose best among f_minus, f_plus, f_parab (if any), and center f0\n                candidates = [(f_minus, x_minus), (f_plus, x_plus)]\n                if f_parab is not None:\n                    candidates.append((f_parab, x_parab))\n                candidates.append((f0, x0))\n                candidates.sort(key=lambda t: t[0])\n                best_dir_f, best_dir_x = candidates[0]\n\n                if best_dir_f < probe['f'] - 1e-12:\n                    # improvement: accept best\n                    old_x = probe['x'].copy()\n                    probe['x'] = best_dir_x.copy()\n                    probe['f'] = float(best_dir_f)\n                    # update momentum with biased smoothing towards new move (different eq)\n                    move = probe['x'] - old_x\n                    probe['mom'] = self.mom_old_weight * probe['mom'] + self.mom_new_weight * move\n                    # expand radius more aggressively\n                    probe['r'] = min(max(self.min_radius, probe['r'] * self.expand_factor),\n                                     self.max_probe_multiplier * avg_span)\n                    probe['age'] = 0\n                    improved = True\n                    stagnation_counter = 0\n                else:\n                    # failure: shrink more aggressively and age the probe\n                    probe['r'] = max(self.min_radius, probe['r'] * self.shrink_factor)\n                    probe['age'] += 1\n                    stagnation_counter += 1\n\n                if evals >= self.budget:\n                    break\n\n            # momentum extrapolation: more aggressive multiplier but clamped\n            if evals < self.budget and np.linalg.norm(probe['mom']) > 1e-9:\n                alpha = self.extrap_alpha\n                xm = probe['x'] + alpha * probe['mom']\n                xm = np.minimum(np.maximum(xm, lb), ub)\n                res_m = eval_and_record(xm)\n                if res_m is not None:\n                    fm, xm = res_m\n                    if fm < probe['f'] - 1e-12:\n                        probe['x'] = xm.copy()\n                        probe['f'] = float(fm)\n                        # expand radius moderately on success\n                        probe['r'] = min(probe['r'] * 1.35, self.max_probe_multiplier * avg_span)\n                        # damp momentum somewhat\n                        probe['mom'] = 0.7 * probe['mom']\n                        improved = True\n                        stagnation_counter = 0\n                    else:\n                        # if extrapolation failed, penalize momentum (stronger damping)\n                        probe['mom'] *= 0.3\n\n            # small local polish if improved\n            if improved and evals < self.budget:\n                small_r = max(self.min_radius, self.local_polish_frac * probe['r'])\n                # take two orthonormal directions and try small +/-\n                A2 = rng.randn(self.dim, min(2, self.dim))\n                try:\n                    Q2, _ = np.linalg.qr(A2)\n                except Exception:\n                    Q2 = A2 / (np.linalg.norm(A2, axis=0, keepdims=True) + 1e-12)\n                for j in range(Q2.shape[1]):\n                    if evals >= self.budget:\n                        break\n                    d = Q2[:, j]\n                    for sign in (+1.0, -1.0):\n                        xp = probe['x'] + sign * d * small_r\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res_p = eval_and_record(xp)\n                        if res_p is None:\n                            break\n                        fp, xp = res_p\n                        if fp < probe['f']:\n                            probe['x'] = xp.copy()\n                            probe['f'] = float(fp)\n\n            # occasionally inject new probe near best archive or random for exploration\n            if attempt % self.inject_frequency == 0 and evals < self.budget:\n                if len(archive) > 0:\n                    base = archive[0][1]\n                    jitter = 0.12 * avg_span * rng.randn(self.dim)\n                    new_x = np.minimum(np.maximum(base + jitter, lb), ub)\n                else:\n                    new_x = rng.uniform(lb, ub)\n                res_new = eval_and_record(new_x)\n                if res_new is not None:\n                    fnew, new_x = res_new\n                    # replace oldest-worst probe if beneficial, else append with small chance\n                    worst_idx = int(np.argmax([p['f'] + 0.02 * p['age'] * avg_span for p in probes]))\n                    if fnew < probes[worst_idx]['f']:\n                        probes[worst_idx] = {\n                            'x': new_x.copy(), 'f': float(fnew),\n                            'r': 0.25 * avg_span, 'mom': np.zeros(self.dim, dtype=float), 'age': 0\n                        }\n                    elif rng.rand() < 0.15 and len(probes) < 2 * probe_count:\n                        probes.append({\n                            'x': new_x.copy(), 'f': float(fnew),\n                            'r': 0.25 * avg_span, 'mom': np.zeros(self.dim, dtype=float), 'age': 0\n                        })\n\n            # PCA-guided global jump triggered by stagnation or periodic schedule (different threshold)\n            if (stagnation_counter > self.stagnation_pca_thresh and len(archive) >= 3) or (attempt % self.global_jump_frequency == 0 and len(archive) >= 3):\n                pts = np.vstack([t[1] for t in archive])\n                mean = np.mean(pts, axis=0)\n                Xc = pts - mean\n                # covariance with small regularization\n                C = (Xc.T @ Xc) / max(1.0, pts.shape[0]) + 1e-8 * np.eye(self.dim)\n                try:\n                    eigvals, eigvecs = np.linalg.eigh(C)\n                    idx_top = np.argmax(eigvals)\n                    v = eigvecs[:, idx_top]\n                    lam = max(1e-8, float(eigvals[idx_top]))\n                except Exception:\n                    v = rng.randn(self.dim)\n                    v = v / (np.linalg.norm(v) + 1e-12)\n                    lam = 1.0\n                # use a scaled Cauchy but with different multiplier (less extreme than original)\n                step_len = rng.standard_cauchy() * (np.sqrt(lam) + 0.15) * 0.6 * avg_span\n                step_len = float(np.clip(step_len, -6.0 * avg_span, 6.0 * avg_span))\n                x_jump = np.minimum(np.maximum(mean + step_len * v, lb), ub)\n                res_jump = eval_and_record(x_jump)\n                if res_jump is not None:\n                    fj, x_jump = res_jump\n                    # age-weighted replacement: replace the probe with largest (f + age_penalty)\n                    age_penalty = np.array([p['age'] for p in probes], dtype=float) * 0.02 * avg_span\n                    scores = np.array([p['f'] for p in probes], dtype=float) + age_penalty\n                    worst_idx = int(np.argmax(scores))\n                    if fj < probes[worst_idx]['f']:\n                        probes[worst_idx] = {\n                            'x': x_jump.copy(), 'f': float(fj),\n                            'r': 0.35 * avg_span, 'mom': np.zeros(self.dim, dtype=float), 'age': 0\n                        }\n                    else:\n                        # occasional append to encourage diversity\n                        if rng.rand() < 0.18 and len(probes) < 2 * probe_count:\n                            probes.append({\n                                'x': x_jump.copy(), 'f': float(fj),\n                                'r': 0.35 * avg_span, 'mom': np.zeros(self.dim, dtype=float), 'age': 0\n                            })\n                stagnation_counter = 0\n\n            # occasional uniform restart injection (different frequency)\n            if attempt % self.uniform_restart_frequency == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # prune probes to maintain budgeted probe_count\n            if len(probes) > probe_count:\n                probes.sort(key=lambda p: p['f'])\n                probes = probes[:probe_count]\n\n            # adapt selection temperature: decrease when progress, increase slowly on stagnation (different scale)\n            if stagnation_counter > 20:\n                sel_temp = min(6.0, sel_temp * 1.04)\n            else:\n                sel_temp = max(0.2, sel_temp * 0.992)\n\n            # safety: ensure all probes have reasonable radii\n            for p in probes:\n                p['r'] = float(np.clip(p['r'], self.min_radius, self.max_probe_multiplier * avg_span))\n\n            # loop continues until budget used\n\n        # finalize best\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm LAVA scored 0.347 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "190f07d3-62a5-43e2-82e1-78ebbbad2370", "operator": null, "metadata": {"aucs": [0.11912133820716553, 0.16770993899193942, 0.5514895313306439, 0.7832825791821036, 0.21551034797465274, 0.8215562009691968, 0.21829691805562756, 0.25321773459162056, 0.20055132548372423, 0.13729269069311067]}, "task_prompt": ""}
{"id": "82d2a91d-1b60-4346-814c-ef913a32474f", "fitness": 0.24346862318089801, "name": "LEO", "description": "LEO maintains a compact sorted archive of best points and a small ensemble of local \"probes\", each with its own position, adaptive radius r, momentum vector and a local covariance Sigma that is updated online (rank‑1 outer-product blending with strength beta=0.25) to shape elliptical proposals and guide exploitation. Directional probing explicitly uses the top eigenvectors of Sigma (k_dir up to 3) with heavy‑tailed Cauchy/Lévy step multipliers and symmetric +/- evaluations plus an optional parabolic interpolation to cheaply estimate and accept directional improvements. Exploration is provided by elliptical Gaussian sampling transformed by sqrt(Sigma) with additional heavy‑tail scaling, PCA‑guided global Lévy jumps from the archive mean, occasional pure random probe injections, and probe replacement/append logic to insert promising jumps. Several budget‑ and dimension‑aware heuristics control behavior (init_samples ≈ 6*dim clipped, archive_k and probe_count derived from init_samples, base radius ∝ avg_span, radius growth 1.25 / shrink 0.72, momentum smoothing and punishments, adaptive selection temperature, and pruning/refill to maintain diversity while respecting the evaluation budget).", "code": "import numpy as np\n\nclass LEO:\n    \"\"\"\n    LEO: Locally-Evolving Orthogonal search with Lévy jumps\n\n    Main ideas / novelty:\n    - Maintain a compact archive of best points and a small ensemble of probes.\n    - Each probe keeps a local covariance (Sigma) that shapes elliptical proposals\n      learned from successful moves via an online rank-1 update.\n    - Directional probing uses principal directions (top eigenvectors of Sigma)\n      with heavy-tailed (Cauchy) step-length modulation — encourages rare large jumps.\n    - Momentum-like extrapolation is attempted when moves are coherent.\n    - Global exploration uses PCA-guided Lévy/elliptical jumps from archive mean\n      and occasional random injections. Probes adapt radii and Sigma on success/failure.\n    - Budget-aware evaluation wrapper ensures func is never called beyond budget.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 init_samples=None, archive_size=None, probe_count=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.probe_count = probe_count\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds: support func.bounds if present, else default [-5,5] for BBOB\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n            if lb.size == 1:\n                lb = np.full(self.dim, lb.item(), dtype=float)\n            if ub.size == 1:\n                ub = np.full(self.dim, ub.item(), dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        eps = 1e-12\n\n        # adaptive defaults\n        if self.init_samples is None:\n            init_samples = max(12, min(60, 6 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, self.budget)\n\n        if self.archive_size is None:\n            archive_k = max(4, min(12, init_samples // 3))\n        else:\n            archive_k = int(self.archive_size)\n\n        if self.probe_count is None:\n            probe_count = max(2, min(12, archive_k))\n        else:\n            probe_count = int(self.probe_count)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x)\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = float(func(x))\n            evals += 1\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # insert to archive (sorted)\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        # initial sampling (diverse)\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least 1 archive point\n        if len(archive) == 0 and evals < self.budget:\n            eval_and_record(rng.uniform(lb, ub))\n\n        # initialize probes from archive top entries (or random)\n        probes = []\n        base_r = max(0.08 * avg_span, 0.2 * avg_span)\n        for i in range(min(probe_count, len(archive))):\n            f0, x0 = archive[i]\n            # local covariance starts small isotropic, biases by archive spread\n            Sigma0 = np.eye(self.dim) * ((0.2 * avg_span) ** 2)\n            probe = {\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': max(1e-8, base_r * (0.9 ** i)),\n                'Sigma': Sigma0,\n                'mom': np.zeros(self.dim, dtype=float),\n                'age': 0,\n                'success': 0\n            }\n            probes.append(probe)\n        # fill remaining probes randomly\n        while len(probes) < probe_count and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            res = eval_and_record(x0)\n            if res is None:\n                break\n            f0, x0 = res\n            probes.append({\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': 0.25 * avg_span,\n                'Sigma': np.eye(self.dim) * ((0.25 * avg_span) ** 2),\n                'mom': np.zeros(self.dim, dtype=float),\n                'age': 0,\n                'success': 0\n            })\n\n        # selection temperature for choosing probes\n        sel_temp = 1.0\n        attempt = 0\n        stagnation = 0\n\n        # helper: pairwise distance-based uniqueness prune\n        def prune_similar(probes_list, min_dist):\n            kept = []\n            for p in sorted(probes_list, key=lambda q: q['f']):\n                if all(np.linalg.norm(p['x'] - q['x']) > min_dist for q in kept):\n                    kept.append(p)\n            return kept\n\n        # main loop\n        while evals < self.budget:\n            attempt += 1\n            # choose probe (softmax on -f)\n            fs = np.array([p['f'] for p in probes], dtype=float)\n            z = -fs / max(1e-9, sel_temp)\n            z = z - np.max(z)\n            probs = np.exp(z)\n            probs /= probs.sum()\n            idx = rng.choice(len(probes), p=probs)\n            probe = probes[idx]\n            x0 = probe['x'].copy()\n            f0 = probe['f']\n            r0 = float(probe['r'])\n            Sigma = probe['Sigma'].copy()\n\n            improved = False\n            # compute eigen-decomposition of Sigma for directional proposals\n            try:\n                eigvals, eigvecs = np.linalg.eigh(Sigma + np.eye(self.dim) * 1e-12)\n            except Exception:\n                eigvecs = np.eye(self.dim)\n                eigvals = np.ones(self.dim)\n            # sort descending\n            order = np.argsort(eigvals)[::-1]\n            eigvals = eigvals[order]\n            eigvecs = eigvecs[:, order]\n\n            # number of principal directions to probe (1..min(3,dim))\n            k_dir = min(self.dim, 1 + (self.dim > 4) + (self.dim > 16))\n            k_dir = min(k_dir, 3)\n\n            # directional proposals along top k_dir eigenvectors (use symmetric sampling on each)\n            for j in range(k_dir):\n                if evals >= self.budget:\n                    break\n                u = eigvecs[:, j]\n                # heavy-tailed multiplier for step length (Cauchy-like)\n                levy = rng.standard_cauchy()\n                levy = float(np.clip(levy, -10.0, 10.0))\n                # step size base is radius * sqrt(eigval_norm)\n                scale_dir = r0 * (0.6 + 0.8 * rng.rand()) * (1.0 + 0.15 * abs(levy))\n                s = u * scale_dir\n                # symmetric evals at +s and -s\n                x_p = np.minimum(np.maximum(x0 + s, lb), ub)\n                res_p = eval_and_record(x_p)\n                if res_p is None:\n                    break\n                fp, x_p = res_p\n\n                x_m = np.minimum(np.maximum(x0 - s, lb), ub)\n                res_m = eval_and_record(x_m)\n                if res_m is None:\n                    break\n                fm, x_m = res_m\n\n                # simple parabolic estimator along direction (no extra eval beyond +/- and center)\n                denom = (fm + fp - 2.0 * f0)\n                x_candidate = None\n                fcand = None\n                if abs(denom) > 1e-12:\n                    t_star = 0.5 * (fm - fp) / denom\n                    t_star = float(np.clip(t_star, -2.0, 2.0))\n                    x_par = np.minimum(np.maximum(x0 + t_star * s, lb), ub)\n                    res_par = eval_and_record(x_par)\n                    if res_par is None:\n                        # budget exhausted\n                        pass\n                    else:\n                        fpar, x_par = res_par\n                        x_candidate = x_par\n                        fcand = fpar\n\n                # aggregate candidates\n                cand = [(f0, x0), (fp, x_p), (fm, x_m)]\n                if x_candidate is not None:\n                    cand.append((fcand, x_candidate))\n                cand.sort(key=lambda t: t[0])\n                best_f_dir, best_x_dir = cand[0]\n\n                if best_f_dir < probe['f'] - 1e-12:\n                    # successful move: update probe location, Sigma (rank-1), radius, momentum\n                    old_x = probe['x'].copy()\n                    probe['x'] = best_x_dir.copy()\n                    probe['f'] = float(best_f_dir)\n                    move = probe['x'] - old_x\n                    # online rank-1 covariance update towards moves\n                    beta = 0.25  # adaptation strength\n                    outer = np.outer(move, move)\n                    probe['Sigma'] = (1.0 - beta) * probe['Sigma'] + beta * outer + np.eye(self.dim) * 1e-10\n                    # momentum smoothing\n                    probe['mom'] = 0.5 * probe['mom'] + 0.5 * move\n                    # radius expansion (soft)\n                    probe['r'] = min(probe['r'] * 1.25, 2.0 * avg_span)\n                    probe['age'] = 0\n                    probe['success'] += 1\n                    improved = True\n                    stagnation = 0\n                else:\n                    # failure: shrink radius, increase age, damp momentum slightly\n                    probe['r'] = max(1e-8, probe['r'] * 0.72)\n                    probe['age'] += 1\n                    probe['mom'] *= 0.7\n                    stagnation += 1\n\n            # momentum extrapolation (try once): novel damping schedule\n            if evals < self.budget and np.linalg.norm(probe['mom']) > 1e-10:\n                # attempt smaller fraction if recent successes small\n                alpha = 0.6 if probe['success'] > 0 else 0.35\n                xm = probe['x'] + alpha * probe['mom']\n                xm = np.minimum(np.maximum(xm, lb), ub)\n                resm = eval_and_record(xm)\n                if resm is not None:\n                    fm, xm = resm\n                    if fm < probe['f'] - 1e-12:\n                        # accept and reinforce Sigma along momentum\n                        move = xm - probe['x']\n                        probe['x'] = xm.copy()\n                        probe['f'] = float(fm)\n                        probe['Sigma'] = 0.85 * probe['Sigma'] + 0.15 * np.outer(move, move)\n                        probe['r'] = min(probe['r'] * 1.2, 2.0 * avg_span)\n                        probe['mom'] = 0.9 * probe['mom']\n                        probe['success'] += 1\n                        improved = True\n                        stagnation = 0\n                    else:\n                        # punish bad momentum\n                        probe['mom'] *= 0.4\n\n            # elliptical randomization: sample inside local Gaussian shaped by Sigma with heavy-tail scaling\n            if evals < self.budget:\n                # sample z ~ N(0,I), transform by sqrt(Sigma)\n                try:\n                    vals, vecs = np.linalg.eigh(probe['Sigma'] + np.eye(self.dim) * 1e-12)\n                    sqrt_vals = np.sqrt(np.maximum(vals, 1e-16))\n                    L = vecs @ np.diag(sqrt_vals)\n                except Exception:\n                    L = np.eye(self.dim) * (0.3 * probe['r'])\n                # heavy tail scaling (1 + small * |Cauchy|)\n                tail = 1.0 + 0.2 * min(8.0, abs(rng.standard_cauchy()))\n                z = rng.randn(self.dim)\n                step = (0.7 * probe['r']) * L.dot(z) / (np.linalg.norm(z) + 1e-12) * tail\n                x_ell = np.minimum(np.maximum(probe['x'] + step, lb), ub)\n                res_e = eval_and_record(x_ell)\n                if res_e is not None:\n                    fe, x_ell = res_e\n                    if fe < probe['f'] - 1e-12:\n                        move = x_ell - probe['x']\n                        probe['x'] = x_ell.copy()\n                        probe['f'] = float(fe)\n                        probe['Sigma'] = 0.9 * probe['Sigma'] + 0.1 * np.outer(move, move)\n                        probe['r'] = min(probe['r'] * 1.15, 2.0 * avg_span)\n                        probe['mom'] = 0.6 * probe['mom'] + 0.4 * move\n                        improved = True\n                        stagnation = 0\n\n            # small local refinement on improvement (coordinate jitter around probe)\n            if improved and evals < self.budget:\n                jitter_scale = 0.25 * probe['r']\n                for _ in range(2):\n                    xp = probe['x'] + jitter_scale * rng.randn(self.dim)\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    resp = eval_and_record(xp)\n                    if resp is None:\n                        break\n                    fp, xp = resp\n                    if fp < probe['f']:\n                        probe['x'] = xp.copy()\n                        probe['f'] = float(fp)\n\n            # global PCA-guided Lévy jump when stagnating or periodically\n            if (stagnation > 50 and len(archive) >= 3) or (attempt % 25 == 0 and len(archive) >= 3):\n                pts = np.vstack([t[1] for t in archive])\n                mean = np.mean(pts, axis=0)\n                Xc = pts - mean\n                C = (Xc.T @ Xc) / max(1.0, pts.shape[0]) + np.eye(self.dim) * 1e-12\n                try:\n                    eigvals_g, eigvecs_g = np.linalg.eigh(C)\n                    idx_top = np.argsort(eigvals_g)[-1]\n                    v = eigvecs_g[:, idx_top]\n                    lam = max(1e-8, float(eigvals_g[idx_top]))\n                except Exception:\n                    v = rng.randn(self.dim)\n                    v /= (np.linalg.norm(v) + 1e-12)\n                    lam = 1.0\n                # heavy-tailed step along v combined with small orthogonal component\n                step_len = rng.standard_cauchy() * (np.sqrt(lam) + 0.3) * 0.8 * avg_span\n                step_len = float(np.clip(step_len, -6.0 * avg_span, 6.0 * avg_span))\n                x_jump = mean + step_len * v + 0.08 * avg_span * rng.randn(self.dim)\n                x_jump = np.minimum(np.maximum(x_jump, lb), ub)\n                resj = eval_and_record(x_jump)\n                if resj is not None:\n                    fj, x_jump = resj\n                    # if jump is good, replace worst probe else possibly add extra probe\n                    worst_f = max([p['f'] for p in probes]) if probes else np.inf\n                    if fj < worst_f:\n                        worst_idx = int(np.argmax([p['f'] for p in probes]))\n                        probes[worst_idx] = {\n                            'x': x_jump.copy(),\n                            'f': float(fj),\n                            'r': 0.35 * avg_span,\n                            'Sigma': np.eye(self.dim) * ((0.25 * avg_span) ** 2),\n                            'mom': np.zeros(self.dim, dtype=float),\n                            'age': 0,\n                            'success': 0\n                        }\n                    else:\n                        # small chance to append exploration probe\n                        if rng.rand() < 0.12 and len(probes) < 2 * probe_count:\n                            probes.append({\n                                'x': x_jump.copy(),\n                                'f': float(fj),\n                                'r': 0.35 * avg_span,\n                                'Sigma': np.eye(self.dim) * ((0.25 * avg_span) ** 2),\n                                'mom': np.zeros(self.dim, dtype=float),\n                                'age': 0,\n                                'success': 0\n                            })\n                stagnation = 0\n\n            # occasionally inject a random probe to avoid collapse\n            if attempt % 37 == 0 and evals < self.budget:\n                xr = rng.uniform(lb, ub)\n                resr = eval_and_record(xr)\n                if resr is not None and len(probes) < 2 * probe_count:\n                    fr, xr = resr\n                    probes.append({\n                        'x': xr.copy(),\n                        'f': float(fr),\n                        'r': 0.25 * avg_span,\n                        'Sigma': np.eye(self.dim) * ((0.25 * avg_span) ** 2),\n                        'mom': np.zeros(self.dim, dtype=float),\n                        'age': 0,\n                        'success': 0\n                    })\n\n            # prune probes if too many or too similar\n            if len(probes) > probe_count:\n                # keep best probe_count by f, but also remove near-duplicates\n                probes.sort(key=lambda p: p['f'])\n                probes = probes[:max(probe_count, 2 * probe_count)]\n                min_dist = 1e-3 * avg_span\n                probes = prune_similar(probes, min_dist)\n                # ensure not less than probe_count by re-trimming if necessary\n                if len(probes) > probe_count:\n                    probes = sorted(probes, key=lambda p: p['f'])[:probe_count]\n                else:\n                    # if we pruned too aggressively, refill randomly\n                    while len(probes) < probe_count and evals < self.budget:\n                        xr = rng.uniform(lb, ub)\n                        resp = eval_and_record(xr)\n                        if resp is None:\n                            break\n                        fr, xr = resp\n                        probes.append({\n                            'x': xr.copy(),\n                            'f': float(fr),\n                            'r': 0.25 * avg_span,\n                            'Sigma': np.eye(self.dim) * ((0.25 * avg_span) ** 2),\n                            'mom': np.zeros(self.dim, dtype=float),\n                            'age': 0,\n                            'success': 0\n                        })\n\n            # adapt selection temperature and stagnation measure\n            if stagnation > 40:\n                sel_temp = min(5.0, sel_temp * 1.06)\n            else:\n                sel_temp = max(0.2, sel_temp * 0.995)\n\n            # small periodic archive-centered jitter to feed archive diversity\n            if attempt % 53 == 0 and len(archive) > 0 and evals < self.budget:\n                base = archive[0][1]\n                jitter = 0.12 * avg_span * rng.randn(self.dim)\n                xj = np.minimum(np.maximum(base + jitter, lb), ub)\n                eval_and_record(xj)\n\n            # loop continues until budget exhausted\n\n        # finalize best\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm LEO scored 0.243 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "190f07d3-62a5-43e2-82e1-78ebbbad2370", "operator": null, "metadata": {"aucs": [0.09229908061367209, 0.14564811874703776, 0.36567641497594483, 0.3471649239323241, 0.24164732568894787, 0.3674801985274805, 0.2579024458724626, 0.26308390890319633, 0.2277278403832812, 0.12605597416463254]}, "task_prompt": ""}
{"id": "b75ffa09-809b-4828-ac32-ff9e0c981ab0", "fitness": 0.4204059528284926, "name": "DLAS", "description": "The DLAS algorithm begins with an overcomplete initial sampling (init_samples = min(budget, max(8,8*dim)) ) and maintains a sorted archive of best points to seed a small population of directional \"probes\" (probe_count chosen from archive or random draws) so it balances global coverage and focused search. Each probe performs multi-scale directional probing in a low-dimensional random subspace using symmetric ±step evaluations plus a 1D parabola fit (clamped t*), combined with momentum-smoothed moves and small coordinate polishes; successful moves aggressively expand the probe radius (×1.5) while failures strongly shrink it (×0.5), producing fast contraction/expansion adaptation. Global exploration is driven by heavy-tailed Levy/Cauchy-style jumps and occasional PCA low-rank jumps computed from archive points (two-eigenvector perturbations) plus periodic uniform or jitter injections to reintroduce diversity, while probe aging triggers radius resets to escape stagnation. Selection of probes uses a softmax over negative fitness with an adaptive temperature (sel_temp) to trade exploration/exploitation over time, and probes are pruned to keep the best ones while retaining occasional random explorers to preserve diversity.", "code": "import numpy as np\n\nclass DLAS:\n    \"\"\"\n    Directional Levy Adaptive Search (DLAS)\n\n    Main ideas (differences vs. the FAMS reference):\n    - Different initialization and sizing heuristics (init more samples per dim).\n    - Stronger radius adaptation: expand more aggressively and shrink more strongly.\n    - Momentum smoothing uses different weights; extrapolation fraction differs.\n    - Directional probing still uses a 1D parabola fit on symmetric samples but\n      with a tighter clamp on extrapolation and randomized multi-scale step draws.\n    - Global exploration uses a two-eigenvector low-rank jump with a Levy/Cauchy\n      flavored heavy-tailed multiplier and a small chance of \"large reset\" probes.\n    - Probe aging leads to radius reset to re-invigorate exploration.\n    - Budget-respecting wrapper and conservative numerical guards.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 init_samples=None, archive_size=None, probe_count=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.probe_count = probe_count\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive defaults (different from reference)\n        if self.init_samples is None:\n            init_samples = max(8, min(80, 8 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, self.budget)\n\n        if self.archive_size is None:\n            archive_k = max(6, min(16, max(3, init_samples // 4)))\n        else:\n            archive_k = int(self.archive_size)\n\n        if self.probe_count is None:\n            probe_count = max(3, min(16, archive_k // 2))\n        else:\n            probe_count = int(self.probe_count)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x)\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # clip to bounds\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            # update global best\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # insert into sorted archive\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        # initial sampling (diverse)\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one point\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # initialize probes from top archive entries or random draws\n        probes = []\n        n_from_archive = min(probe_count, len(archive))\n        for i in range(n_from_archive):\n            f0, x0 = archive[i]\n            # different radius schedule: base * (1 + 0.6*exp(-i/2))\n            base_r = 0.12 * avg_span\n            r_i = base_r * (1.0 + 0.6 * np.exp(-0.5 * i))\n            probe = {\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': float(np.clip(r_i, 1e-8, 2.5 * avg_span)),\n                'mom': np.zeros(self.dim, dtype=float),\n                'age': 0\n            }\n            probes.append(probe)\n\n        # fill remaining probes by random archive samples or uniform samples\n        while len(probes) < probe_count and evals < self.budget:\n            if len(archive) > 0 and rng.rand() < 0.6:\n                # sample around a random archive member\n                aidx = rng.randint(len(archive))\n                base = archive[aidx][1]\n                jitter = 0.2 * avg_span * rng.randn(self.dim)\n                x0 = np.minimum(np.maximum(base + jitter, lb), ub)\n            else:\n                x0 = rng.uniform(lb, ub)\n            res = eval_and_record(x0)\n            if res is None:\n                break\n            f0, x0 = res\n            probes.append({\n                'x': x0.copy(),\n                'f': float(f0),\n                'r': 0.2 * avg_span,\n                'mom': np.zeros(self.dim, dtype=float),\n                'age': 0\n            })\n\n        # selection temperature (different adaptation law)\n        sel_temp = 1.2\n\n        attempt = 0\n        stagnation_counter = 0\n\n        # helper to sample a Levy-like positive scalar (heavy tail)\n        def levy_scale(scale_base):\n            # mix of Cauchy and Pareto-ish tail via exponentiated heavy tail\n            if rng.rand() < 0.6:\n                # Cauchy-centered at 0\n                s = rng.standard_cauchy()\n            else:\n                # heavy-tailed positive: Pareto-like with alpha in (0.5,2)\n                alpha = 0.8 + 1.2 * rng.rand()\n                u = rng.rand()\n                s = (u ** (-1.0 / alpha))  # positive\n                # random sign\n                if rng.rand() < 0.5:\n                    s = -s\n            # damp and scale\n            s = np.clip(s, -10.0, 10.0)\n            return float(s * scale_base)\n\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n\n            # select a probe by softmax over -f (favor smaller f)\n            fs = np.array([p['f'] for p in probes], dtype=float)\n            # stable softmax\n            z = -fs / max(1e-12, sel_temp)\n            z = z - np.max(z)\n            probs = np.exp(z)\n            probs = probs / (np.sum(probs) + 1e-16)\n            idx = rng.choice(len(probes), p=probs)\n            probe = probes[idx]\n            x0 = probe['x'].copy()\n            f0 = probe['f']\n            r0 = probe['r']\n\n            improved = False\n\n            # choose subspace dimension k randomly (1..min(4,dim))\n            k = int(min(4, max(1, 1 + rng.randint(0, min(3, self.dim - 1) + 1))))\n            # build random orthonormal directions\n            A = rng.randn(self.dim, k)\n            try:\n                Q, _ = np.linalg.qr(A)\n            except Exception:\n                Q = A / (np.linalg.norm(A, axis=0, keepdims=True) + 1e-12)\n            directions = [Q[:, j] for j in range(k)]\n\n            # multi-scale directional probing: for each direction, try a randomized step magnitude\n            for d in directions:\n                if evals >= self.budget:\n                    break\n                # randomized multi-scale factor in [0.3,1.8] (wider range)\n                scale_factor = 0.3 + 1.5 * rng.rand()\n                s = r0 * scale_factor\n                step = d * s\n\n                # symmetric evaluations at -step and +step\n                x_minus = np.minimum(np.maximum(x0 - step, lb), ub)\n                res_minus = eval_and_record(x_minus)\n                if res_minus is None:\n                    break\n                f_minus, x_minus = res_minus\n\n                x_plus = np.minimum(np.maximum(x0 + step, lb), ub)\n                res_plus = eval_and_record(x_plus)\n                if res_plus is None:\n                    break\n                f_plus, x_plus = res_plus\n\n                # parabola fit along t in units of step, but combine with a small momentum bias\n                denom = (f_minus + f_plus - 2.0 * f0)\n                x_candidate = None\n                f_candidate = None\n                if abs(denom) > 1e-14:\n                    # compute t* (same algebra but we'll damp it towards momentum direction)\n                    t_star = 0.5 * (f_minus - f_plus) / denom  # note: same base formula but will be clamped tighter\n                    # clamp stronger to [-1.5, 1.5]\n                    t_star = float(np.clip(t_star, -1.5, 1.5))\n\n                    # bias t_star slightly towards momentum projection on d, if momentum exists\n                    proj = float(np.dot(probe['mom'], d))\n                    if abs(proj) > 1e-12:\n                        # momentum influence weight depends on probe age (older -> more influence)\n                        mom_w = np.clip(0.15 + 0.02 * probe['age'], 0.05, 0.6)\n                        # convert proj to t units roughly by dividing by step length\n                        t_star = (1.0 - mom_w) * t_star + mom_w * (proj / (s + 1e-12))\n\n                    x_parab = x0 + t_star * step\n                    x_parab = np.minimum(np.maximum(x_parab, lb), ub)\n                    res_parab = eval_and_record(x_parab)\n                    if res_parab is not None:\n                        f_parab, x_parab = res_parab\n                        x_candidate = x_parab\n                        f_candidate = f_parab\n\n                # collect candidates\n                cand_list = [(f_minus, x_minus), (f_plus, x_plus), (f0, x0)]\n                if x_candidate is not None:\n                    cand_list.append((f_candidate, x_candidate))\n                cand_list.sort(key=lambda t: t[0])\n                best_dir_f, best_dir_x = cand_list[0]\n\n                if best_dir_f < probe['f'] - 1e-12:\n                    # improvement found\n                    old_x = probe['x'].copy()\n                    probe['x'] = best_dir_x.copy()\n                    probe['f'] = float(best_dir_f)\n                    move = probe['x'] - old_x\n                    # different momentum smoothing: heavier on past (0.7/0.3)\n                    probe['mom'] = 0.7 * probe['mom'] + 0.3 * move\n                    # expand radius more aggressively\n                    probe['r'] = float(np.clip(probe['r'] * 1.5, 1e-8, 3.0 * avg_span))\n                    probe['age'] = 0\n                    improved = True\n                    stagnation_counter = 0\n                else:\n                    # failure: stronger shrink\n                    probe['r'] = float(max(1e-9, probe['r'] * 0.5))\n                    probe['age'] += 1\n                    stagnation_counter += 1\n\n                if evals >= self.budget:\n                    break\n\n            # momentum extrapolation: try a scaled momentum with different alpha\n            if evals < self.budget and np.linalg.norm(probe['mom']) > 1e-9:\n                # try slightly larger than momentum sometimes, clipped\n                alpha = 1.0 + 0.2 * (rng.rand() - 0.5)  # in ~[0.9,1.1]\n                alpha = float(np.clip(alpha, -1.2, 1.5))\n                xm = probe['x'] + alpha * probe['mom']\n                xm = np.minimum(np.maximum(xm, lb), ub)\n                res_m = eval_and_record(xm)\n                if res_m is not None:\n                    fm, xm = res_m\n                    if fm < probe['f'] - 1e-12:\n                        probe['x'] = xm.copy()\n                        probe['f'] = float(fm)\n                        # expand a bit\n                        probe['r'] = float(min(probe['r'] * 1.25, 3.0 * avg_span))\n                        # damp momentum slightly (different damping)\n                        probe['mom'] *= 0.85\n                        improved = True\n                        stagnation_counter = 0\n                    else:\n                        # if extrapolation failed, damp momentum more\n                        probe['mom'] *= 0.4\n\n            # small local polish when improved: try coordinate mini-search (random subset)\n            if improved and evals < self.budget:\n                small_r = max(1e-9, 0.25 * probe['r'])\n                # try up to 3 random coordinate perturbations\n                coords_to_try = min(3, self.dim)\n                idxs = rng.choice(self.dim, size=coords_to_try, replace=False)\n                for j in idxs:\n                    if evals >= self.budget:\n                        break\n                    dvec = np.zeros(self.dim, dtype=float)\n                    dvec[j] = 1.0\n                    xp = probe['x'] + dvec * small_r * (0.5 + rng.rand())\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res_p = eval_and_record(xp)\n                    if res_p is None:\n                        break\n                    fp, xp = res_p\n                    if fp < probe['f']:\n                        probe['x'] = xp.copy()\n                        probe['f'] = float(fp)\n\n            # occasionally inject a new probe around the global best with a strong jitter\n            if attempt % 9 == 0 and len(archive) > 0 and evals < self.budget and len(probes) < 2 * probe_count:\n                base = archive[0][1]\n                jitter = 0.25 * avg_span * rng.randn(self.dim)\n                new_x = np.minimum(np.maximum(base + jitter, lb), ub)\n                res_new = eval_and_record(new_x)\n                if res_new is not None:\n                    fnew, new_x = res_new\n                    probes.append({\n                        'x': new_x.copy(),\n                        'f': float(fnew),\n                        'r': 0.25 * avg_span,\n                        'mom': np.zeros(self.dim, dtype=float),\n                        'age': 0\n                    })\n\n            # PCA-guided low-rank global jump: uses top 2 eigenvectors and Levy-like scale\n            if (stagnation_counter > 35 and len(archive) >= 4) or (attempt % 20 == 0 and len(archive) >= 3):\n                pts = np.vstack([t[1] for t in archive])\n                mean = np.mean(pts, axis=0)\n                Xc = pts - mean\n                C = (Xc.T @ Xc) / max(1.0, pts.shape[0])  # covariance-ish\n                try:\n                    eigvals, eigvecs = np.linalg.eigh(C)\n                    idxs = np.argsort(eigvals)[-2:]  # top two\n                    v1 = eigvecs[:, idxs[-1]]\n                    v2 = eigvecs[:, idxs[0]] if len(idxs) > 1 else eigvecs[:, idxs[-1]]\n                    lam1 = max(1e-12, float(eigvals[idxs[-1]]))\n                    lam2 = max(1e-12, float(eigvals[idxs[0]]))\n                except Exception:\n                    v1 = rng.randn(self.dim)\n                    v1 /= (np.linalg.norm(v1) + 1e-12)\n                    v2 = rng.randn(self.dim)\n                    v2 /= (np.linalg.norm(v2) + 1e-12)\n                    lam1 = lam2 = 1.0\n\n                # sample two coefficients from levy_scale with different scales, combine\n                c1 = levy_scale(0.6 * np.sqrt(lam1 + 1e-12) * avg_span)\n                c2 = levy_scale(0.3 * np.sqrt(lam2 + 1e-12) * avg_span)\n                x_jump = mean + c1 * v1 + c2 * v2\n                x_jump = np.minimum(np.maximum(x_jump, lb), ub)\n                res_jump = eval_and_record(x_jump)\n                if res_jump is not None:\n                    fj, x_jump = res_jump\n                    worst_f = max([p['f'] for p in probes])\n                    if fj < worst_f:\n                        # replace worst probe\n                        worst_idx = int(np.argmax([p['f'] for p in probes]))\n                        probes[worst_idx] = {\n                            'x': x_jump.copy(),\n                            'f': float(fj),\n                            'r': 0.35 * avg_span,\n                            'mom': np.zeros(self.dim, dtype=float),\n                            'age': 0\n                        }\n                    else:\n                        # occasionally append new exploratory probe\n                        if rng.rand() < 0.15 and len(probes) < 3 * probe_count:\n                            probes.append({\n                                'x': x_jump.copy(),\n                                'f': float(fj),\n                                'r': 0.35 * avg_span,\n                                'mom': np.zeros(self.dim, dtype=float),\n                                'age': 0\n                            })\n                stagnation_counter = 0\n\n            # prune probes if too many: keep best ones, but also keep one random exploratory slot\n            if len(probes) > max(1, probe_count):\n                probes.sort(key=lambda p: p['f'])\n                # keep best (probe_count-1) plus one random among the remaining to preserve diversity\n                keep = probes[:max(1, probe_count - 1)]\n                remainder = probes[max(1, probe_count - 1):]\n                if len(remainder) > 0:\n                    if rng.rand() < 0.3:\n                        keep.append(remainder[rng.randint(len(remainder))])\n                probes = keep\n\n            # aging: if a probe is old and hasn't improved, reset its radius to a larger exploratory value\n            for p in probes:\n                if p['age'] > 25:\n                    # reset radius occasionally to encourage escape (different scale)\n                    p['r'] = float(max(p['r'], 0.35 * avg_span))\n                    p['age'] = 0\n                    p['mom'] *= 0.5  # damp momentum on reset\n\n            # adaptive selection temperature update: favor exploration early, exploitation late\n            if stagnation_counter > 40:\n                sel_temp = min(6.0, sel_temp * 1.08)\n            else:\n                sel_temp = max(0.2, sel_temp * 0.992)\n\n            # occasional uniform injection to ensure global coverage\n            if attempt % 37 == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # budget loop continues until exhausted\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best) if f_best is not None else np.inf\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DLAS scored 0.420 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "190f07d3-62a5-43e2-82e1-78ebbbad2370", "operator": null, "metadata": {"aucs": [0.12825481795456084, 0.14557305623485095, 0.7894784783251315, 0.9515770271614441, 0.2611893222190881, 0.9366474616934465, 0.19566266599946935, 0.41733006547121587, 0.22613634596918142, 0.15221028725653818]}, "task_prompt": ""}
{"id": "56116e5e-0853-4803-b623-2e854233a352", "fitness": 0.4744663786310806, "name": "HAGMS", "description": "HAGMS is a hybrid search that maintains a small elite archive (kept to ~4–12 best samples from an initial uniform sampling of max(12, min(60, 6*dim)) points) plus a probe population (2–12) that drive local exploitation; all evaluations are budget-tracked and inputs are clipped to the given [-5,5] bounds. For global exploration it uses heavy‑tailed Cauchy jumps from elite centers and PCA‑guided low‑rank jumps along dominant eigenvectors (with step magnitudes scaled by avg_span and clipped), with occasional uniform injections and an adaptive global_prob that increases when archive spread is low. For local exploitation each probe performs multiscale 1‑D probing along random orthonormal directions with three‑point parabolic fits (t_star clipped to [-2,2]), momentum extrapolation (momentum update 0.6/0.4 and extrapolation alpha≈0.85), adaptive radius expansion (×~1.28) on success and shrinkage (×~0.67) on failure, plus small randomized polishing and occasional Hooke‑Jeeves (step0≈0.4·avg_span, shrink≈0.6) when budget allows. The algorithm also uses softmax selection over probe fitness with an adaptive temperature, probe aging/replacement and pruning, and archive/probe promotions to balance exploration and exploitation across BBOB landscapes.", "code": "import numpy as np\n\nclass HAGMS:\n    \"\"\"\n    Hybrid Archive-Guided Multi-Scale Search (HAGMS)\n\n    - Maintains an elite archive and a small probe population (x, f, r, mom, age).\n    - Uses PCA/Cauchy heavy-tailed global jumps from the archive, parabolic 1D probing\n      along random orthonormal directions for cheap line-searches, momentum extrapolation,\n      and occasional Hooke-Jeeves style local polishing when budget allows.\n    - Adaptive radii (expand on success, shrink on failure), softmax probe selection,\n      adaptive selection temperature and global-vs-local probability based on archive diversity.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 init_samples=None, archive_size=None, probe_count=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.init_samples = init_samples\n        self.archive_size = archive_size\n        self.probe_count = probe_count\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive defaults\n        if self.init_samples is None:\n            init_samples = max(12, min(60, 6 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, self.budget)\n\n        if self.archive_size is None:\n            archive_k = max(4, min(12, init_samples // 3))\n        else:\n            archive_k = int(self.archive_size)\n\n        if self.probe_count is None:\n            probe_count = max(2, min(12, archive_k))\n        else:\n            probe_count = int(self.probe_count)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f,x) sorted\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # archive insertion\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        # initial sampling (uniform)\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure archive non-empty\n        if len(archive) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # initialize probes from top archive entries\n        probes = []\n        for i in range(min(probe_count, len(archive))):\n            f0, x0 = archive[i]\n            r0 = max(0.06 * avg_span, 0.25 * avg_span * (0.9 ** i))\n            probes.append({'x': x0.copy(), 'f': float(f0), 'r': r0, 'mom': np.zeros(self.dim), 'age': 0})\n\n        # fill remaining probes by jittering best or sampling\n        while len(probes) < probe_count and evals < self.budget:\n            if len(archive) > 0:\n                base = archive[min(len(archive)-1, len(probes))][1]\n                jitter = 0.2 * avg_span * rng.randn(self.dim)\n                x0 = np.minimum(np.maximum(base + jitter, lb), ub)\n            else:\n                x0 = rng.uniform(lb, ub)\n            res = eval_and_record(x0)\n            if res is None:\n                break\n            f0, x0 = res\n            probes.append({'x': x0.copy(), 'f': float(f0), 'r': 0.25 * avg_span, 'mom': np.zeros(self.dim), 'age': 0})\n\n        # algorithm state\n        sel_temp = 1.0\n        global_prob = 0.25\n        attempt = 0\n        stagnation = 0\n\n        # small Hooke-Jeeves local search for occasional polishing\n        def hooke_jeeves(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            step0 = 0.4 * avg_span\n            steps = np.full(self.dim, step0, dtype=float)\n            shrink = 0.6\n            pattern_factor = 1.5\n            local_evals = 0\n            while local_evals < local_budget and np.any(steps > 1e-12):\n                improved = False\n                probe = base.copy()\n                probe_f = base_f\n                for i in range(self.dim):\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    # plus\n                    xp = probe.copy()\n                    xp[i] += steps[i]\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res = eval_and_record(xp)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < probe_f:\n                        probe = xp.copy()\n                        probe_f = fp\n                        improved = True\n                        continue\n                    # minus\n                    xn = probe.copy()\n                    xn[i] -= steps[i]\n                    xn = np.minimum(np.maximum(xn, lb), ub)\n                    res = eval_and_record(xn)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < probe_f:\n                        probe = xn.copy()\n                        probe_f = fn\n                        improved = True\n                if improved and evals < self.budget and local_evals < local_budget:\n                    direction = probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_and_record(xp)\n                        local_evals += 1\n                        if res is not None:\n                            fp2, xp = res\n                            if fp2 < probe_f:\n                                base = xp.copy()\n                                base_f = fp2\n                            else:\n                                base = probe.copy()\n                                base_f = probe_f\n                        else:\n                            base = probe.copy()\n                            base_f = probe_f\n                    else:\n                        base = probe.copy()\n                        base_f = probe_f\n                else:\n                    steps *= shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # main loop\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            # adjust diversity feedback\n            if len(archive) >= 2:\n                spread = np.linalg.norm(archive[0][1] - archive[-1][1])\n                if spread < 1e-9 + 0.02 * avg_span:\n                    global_prob = min(0.7, global_prob + 0.03)\n                else:\n                    global_prob = max(0.05, global_prob * 0.995)\n\n            # choose strategy: global jump vs probe refine vs local polish\n            r = rng.rand()\n            # occasionally perform small Hooke-Jeeves local polish around best\n            if r < 0.08 and len(archive) > 0 and remaining > 5:\n                # local budget small fraction\n                lb_local = min(remaining-1, max(4, int(0.02 * self.budget)))\n                base = archive[0][1]\n                # evaluate base to get current f if not exactly known\n                res = eval_and_record(base)\n                if res is None:\n                    break\n                f_base, base = res\n                f_after, x_after = hooke_jeeves(base, f_base, lb_local)\n                # record done by wrapper\n                continue\n\n            # Global jump\n            if r < global_prob and len(archive) >= 2:\n                # mix PCA low-rank jump and Cauchy from an elite point\n                if rng.rand() < 0.6 and len(archive) >= 3:\n                    # PCA-guided low-rank jump\n                    pts = np.vstack([t[1] for t in archive])\n                    mean = np.mean(pts, axis=0)\n                    Xc = pts - mean\n                    C = (Xc.T @ Xc) / max(1.0, pts.shape[0])\n                    try:\n                        eigvals, eigvecs = np.linalg.eigh(C)\n                        idx_top = np.argsort(eigvals)[-1]\n                        v = eigvecs[:, idx_top]\n                        lam = max(1e-8, float(eigvals[idx_top]))\n                    except Exception:\n                        v = rng.randn(self.dim)\n                        v /= (np.linalg.norm(v) + 1e-12)\n                        lam = 1.0\n                    step_len = rng.standard_cauchy() * (np.sqrt(lam) + 0.15) * 0.6 * avg_span\n                    step_len = float(np.clip(step_len, -6.0 * avg_span, 6.0 * avg_span))\n                    x_jump = mean + step_len * v\n                    x_jump = np.minimum(np.maximum(x_jump, lb), ub)\n                    res = eval_and_record(x_jump)\n                    if res is None:\n                        break\n                    fj, x_jump = res\n                    # if good, inject as new probe or replace worst\n                    if len(probes) > 0 and fj < max([p['f'] for p in probes]):\n                        worst_idx = int(np.argmax([p['f'] for p in probes]))\n                        probes[worst_idx] = {'x': x_jump.copy(), 'f': float(fj), 'r': 0.3 * avg_span, 'mom': np.zeros(self.dim), 'age': 0}\n                    else:\n                        if rng.rand() < 0.25 and len(probes) < 2 * probe_count:\n                            probes.append({'x': x_jump.copy(), 'f': float(fj), 'r': 0.3 * avg_span, 'mom': np.zeros(self.dim), 'age': 0})\n                else:\n                    # Cauchy jump from a random elite center (with bias to best)\n                    if rng.rand() < 0.7:\n                        center = archive[0][1]\n                    else:\n                        center = archive[rng.randint(0, len(archive))][1]\n                    direction = rng.randn(self.dim)\n                    direction /= (np.linalg.norm(direction) + 1e-12)\n                    step_mag = rng.standard_cauchy()\n                    step_scale = (0.6 + 0.8 * rng.rand()) * avg_span * max(0.05, 1.0 - 0.01 * attempt)\n                    cand = center + step_mag * direction * step_scale\n                    cand = np.minimum(np.maximum(cand, lb), ub)\n                    res = eval_and_record(cand)\n                    if res is None:\n                        break\n                    fc, cand = res\n                    # promote to probe if promising\n                    if len(probes) > 0 and fc < max([p['f'] for p in probes]):\n                        worst_idx = int(np.argmax([p['f'] for p in probes]))\n                        probes[worst_idx] = {'x': cand.copy(), 'f': float(fc), 'r': 0.25 * avg_span, 'mom': np.zeros(self.dim), 'age': 0}\n                # occasional uniform injection after a jump\n                if attempt % 17 == 0 and evals < self.budget:\n                    xu = rng.uniform(lb, ub)\n                    eval_and_record(xu)\n                continue\n\n            # Otherwise: probe-based multiscale parabolic probing\n            if len(probes) == 0:\n                # if no probes, create one by sampling\n                x0 = rng.uniform(lb, ub)\n                res = eval_and_record(x0)\n                if res is None:\n                    break\n                f0, x0 = res\n                probes.append({'x': x0.copy(), 'f': float(f0), 'r': 0.25 * avg_span, 'mom': np.zeros(self.dim), 'age': 0})\n\n            # softmax selection over -f\n            fs = np.array([p['f'] for p in probes], dtype=float)\n            z = -fs / max(1e-9, sel_temp)\n            probs = np.exp(z - np.max(z))\n            probs = probs / probs.sum()\n            idx = rng.choice(len(probes), p=probs)\n            probe = probes[idx]\n            x0 = probe['x'].copy()\n            f0 = probe['f']\n            r0 = probe['r']\n\n            improved = False\n            # choose up to k directions (1..3)\n            k = min(3, max(1, int(np.ceil(np.sqrt(self.dim)))))\n            A = rng.randn(self.dim, k)\n            try:\n                Q, _ = np.linalg.qr(A)\n            except Exception:\n                Q = A / (np.linalg.norm(A, axis=0, keepdims=True) + 1e-12)\n            directions = [Q[:, j] for j in range(min(k, Q.shape[1]))]\n\n            for d in directions:\n                if evals >= self.budget:\n                    break\n                s = r0 * (0.55 + 0.9 * rng.rand())\n                step = d * s\n                x_minus = np.minimum(np.maximum(x0 - step, lb), ub)\n                res_m = eval_and_record(x_minus)\n                if res_m is None:\n                    break\n                f_minus, x_minus = res_m\n\n                x_plus = np.minimum(np.maximum(x0 + step, lb), ub)\n                res_p = eval_and_record(x_plus)\n                if res_p is None:\n                    break\n                f_plus, x_plus = res_p\n\n                # parabola fit using f_minus, f0, f_plus\n                denom = (f_minus + f_plus - 2.0 * f0)\n                candidate = None\n                if abs(denom) > 1e-12:\n                    t_star = 0.5 * (f_minus - f_plus) / denom\n                    t_star = float(np.clip(t_star, -2.0, 2.0))\n                    x_par = x0 + t_star * step\n                    x_par = np.minimum(np.maximum(x_par, lb), ub)\n                    res_par = eval_and_record(x_par)\n                    if res_par is not None:\n                        f_par, x_par = res_par\n                        candidate = (f_par, x_par)\n                # choose best among observed\n                cand_list = [(f_minus, x_minus), (f_plus, x_plus), (f0, x0)]\n                if candidate is not None:\n                    cand_list.append(candidate)\n                cand_list.sort(key=lambda t: t[0])\n                best_dir_f, best_dir_x = cand_list[0]\n\n                if best_dir_f < probe['f'] - 1e-12:\n                    old_x = probe['x'].copy()\n                    probe['x'] = best_dir_x.copy()\n                    probe['f'] = float(best_dir_f)\n                    move = probe['x'] - old_x\n                    probe['mom'] = 0.6 * probe['mom'] + 0.4 * move\n                    probe['r'] = min(probe['r'] * 1.28, 2.0 * avg_span)\n                    probe['age'] = 0\n                    improved = True\n                    stagnation = 0\n                else:\n                    probe['r'] = max(1e-8, probe['r'] * 0.67)\n                    probe['age'] += 1\n                    stagnation += 1\n\n                if evals >= self.budget:\n                    break\n\n            # momentum extrapolation\n            if evals < self.budget and np.linalg.norm(probe['mom']) > 1e-9:\n                alpha = 0.85\n                xm = probe['x'] + alpha * probe['mom']\n                xm = np.minimum(np.maximum(xm, lb), ub)\n                res_m = eval_and_record(xm)\n                if res_m is not None:\n                    fm, xm = res_m\n                    if fm < probe['f'] - 1e-12:\n                        probe['x'] = xm.copy()\n                        probe['f'] = float(fm)\n                        probe['r'] = min(probe['r'] * 1.25, 2.0 * avg_span)\n                        probe['mom'] *= 0.85\n                        improved = True\n                        stagnation = 0\n                    else:\n                        probe['mom'] *= 0.5\n\n            # small local polish on improvement\n            if improved and evals < self.budget:\n                small_r = max(1e-8, 0.28 * probe['r'])\n                A2 = rng.randn(self.dim, min(2, self.dim))\n                try:\n                    Q2, _ = np.linalg.qr(A2)\n                except Exception:\n                    Q2 = A2 / (np.linalg.norm(A2, axis=0, keepdims=True) + 1e-12)\n                for j in range(Q2.shape[1]):\n                    if evals >= self.budget:\n                        break\n                    d = Q2[:, j]\n                    xp = probe['x'] + d * small_r\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res_p = eval_and_record(xp)\n                    if res_p is None:\n                        break\n                    fp, xp = res_p\n                    if fp < probe['f']:\n                        probe['x'] = xp.copy()\n                        probe['f'] = float(fp)\n\n            # probe maintenance: replace old/poor probes occasionally\n            if probe['age'] > 30 and len(archive) > 0 and evals < self.budget:\n                base = archive[rng.randint(0, len(archive))]\n                jitter = 0.18 * avg_span * rng.randn(self.dim)\n                x_new = np.minimum(np.maximum(base[1] + jitter, lb), ub)\n                res_new = eval_and_record(x_new)\n                if res_new is not None:\n                    fnew, x_new = res_new\n                    probe.update({'x': x_new.copy(), 'f': float(fnew), 'r': 0.25 * avg_span, 'mom': np.zeros(self.dim), 'age': 0})\n\n            # prune probes if too many\n            if len(probes) > 2 * probe_count:\n                probes.sort(key=lambda p: p['f'])\n                probes = probes[:probe_count]\n\n            # adapt selection temperature\n            if stagnation > 30:\n                sel_temp = min(5.0, sel_temp * 1.05)\n            else:\n                sel_temp = max(0.25, sel_temp * 0.995)\n\n            # occasional uniform injection\n            if attempt % 41 == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n        # finalize best\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HAGMS scored 0.474 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "190f07d3-62a5-43e2-82e1-78ebbbad2370", "operator": null, "metadata": {"aucs": [0.09380605033368172, 0.15505104039394269, 0.9769123099145801, 0.9725538270663888, 0.3233370583219496, 0.9835658539148308, 0.2648186894878518, 0.3677242807434411, 0.4613219760736915, 0.1455727000604483]}, "task_prompt": ""}
{"id": "e3b9be57-5697-4b60-a5b4-89c202f647e8", "fitness": 0.26120675187220366, "name": "MomentumDirectionalCMA", "description": "The design is a compact CMA-style Gaussian search (mean m, covariance C, global sigma) with bounds-aware diagonal initialization (C from bounds, sigma = 0.25 * mean_span) and a small adaptive population size to favor many iterations. Sampling uses antithetic pairs for variance reduction plus a small directional bias along a momentum vector v, and a per-coordinate multiplicative scale s_diag (EMA, clipped to [0.2,5]) to adapt anisotropically. The mean is updated by rank-mu weighted recombination, while covariance is a blend (cov_lr ≈ 0.2) of the rank-mu weighted sample covariance and a small rank-1 outer product from momentum (rank1 ≈ 0.06); momentum persistence (mom_beta ≈ 0.8) and SPD enforcement (Cholesky/eigen fallback) stabilize updates. Step-size sigma is adapted with an exponential rule driven by a smoothed success rate (target ≈ 0.2, sigma_adapt_rate ≈ 0.2), and opportunistic restarts (stagnation_frac ≈ 0.05) re-center and inflate search around the current best when progress stalls.", "code": "import numpy as np\n\nclass MomentumDirectionalCMA:\n    \"\"\"\n    Momentum-Directional Compact CMA (MD-CMA)\n\n    - Compact Gaussian search distribution (mean m, covariance C, global sigma).\n    - Antithetic sampling for variance reduction, plus a small directional bias along momentum v.\n    - Weighted recombination (rank-mu) of the best half to update the mean.\n    - Covariance updated as a blend of rank-mu weighted covariance and a small rank-1 momentum outer product.\n    - Per-coordinate scale (s_diag) maintained as EMA of normalized step magnitudes.\n    - Sigma adapted via smoothed success-rate (approx 1/5th rule).\n    - Opportunistic restarts on prolonged stagnation that inflate sigma and re-center near best.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 cov_lr=0.2,\n                 rank1=0.06,\n                 mom_beta=0.8,\n                 s_diag_beta=0.6,\n                 sigma_adapt_rate=0.2,\n                 success_target=0.2,\n                 stagnation_frac=0.05,\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.cov_lr = float(cov_lr)\n        self.rank1 = float(rank1)\n        self.mom_beta = float(mom_beta)\n        self.s_diag_beta = float(s_diag_beta)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.success_target = float(success_target)\n        self.stagnation_frac = float(stagnation_frac)\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds handling (Many BBOB: typically [-5,5])\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = ub - lb\n        mean_span = float(np.mean(bounds_scale))\n\n        # adaptive population size (small to allow many iterations)\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # initial uniform batch to seed mean and covariance\n        evals = 0\n        batch0 = min(lam, max(2, int(max(2, np.ceil(0.5 * lam)))))\n        X0 = rng.uniform(lb, ub, size=(batch0, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += batch0\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize mean as weighted mean of top half (rank-mu)\n        mu0 = max(1, batch0 // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w = np.maximum(w, 0.0)\n        if w.sum() <= 0:\n            w = np.ones_like(w)\n        w = w / np.sum(w)\n        m = (w.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance & sigma\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.25 * mean_span)\n\n        # momentum and per-coordinate scale\n        v = np.zeros(self.dim, dtype=float)\n        s_diag = np.ones(self.dim, dtype=float)\n\n        p_succ = float(self.success_target)  # start at target\n        stagn_count = 0\n        stagn_thresh = max(5, int(self.stagnation_frac * self.budget))\n\n        iter_count = 0\n\n        # helper: ensure SPD cholesky or eigen fallback\n        def chol_spd(mat):\n            eps = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            # ensure at least 2 for antithetic pairing when possible\n            if remaining >= 2:\n                lam_iter = max(2, lam_iter)\n\n            mu = max(1, lam_iter // 2)\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            if weights.sum() <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n            W = weights.reshape(-1, 1)\n\n            # ensure C SPD for sampling\n            A = chol_spd(C)\n\n            # Antithetic sampling\n            half = lam_iter // 2\n            Zpos = rng.normal(size=(half, self.dim))\n            Z = np.vstack([Zpos, -Zpos])\n            if lam_iter % 2 == 1:\n                Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n\n            # transform to correlated space\n            Y = Z @ A.T  # shape (lam_iter, dim)\n\n            # directional bias along momentum (small)\n            vlen = np.linalg.norm(v) + 1e-20\n            if vlen > 0:\n                v_unit = v / vlen\n                dir_strength = 0.6 * (vlen / (1.0 + vlen))  # in [0,0.6)\n                s_scalar = rng.normal(scale=dir_strength, size=(Y.shape[0], 1))\n                Y = Y + s_scalar * v_unit.reshape(1, -1)\n\n            # per-coordinate multiplicative scaling\n            Y = Y * s_diag.reshape(1, -1)\n\n            Xcand = m + sigma * Y\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates one-by-one\n            lam_actual = Xcand.shape[0]\n            fc = np.full(lam_actual, np.inf, dtype=float)\n            for i in range(lam_actual):\n                if evals >= self.budget:\n                    break\n                fc[i] = float(func(Xcand[i]))\n                evals += 1\n                # update immediate best to allow restarts to center on best quickly\n                if fc[i] < f_best:\n                    f_best = float(fc[i])\n                    x_best = Xcand[i].copy()\n                    stagn_count = 0\n\n            # handle truncation due to budget\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                lam_actual = fc.shape[0]\n                if lam_actual == 0:\n                    break\n\n            # generation best\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best - 1e-15:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # select elites and recombine mean (rank-mu)\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            # compute new mean with weights (handle fewer elites)\n            if X_mu.shape[0] != weights.shape[0]:\n                mu_eff = X_mu.shape[0]\n                w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                w_eff = np.maximum(w_eff, 0.0)\n                if w_eff.sum() <= 0:\n                    w_eff = np.ones_like(w_eff)\n                w_eff = w_eff / np.sum(w_eff)\n                W_eff = w_eff.reshape(-1, 1)\n                m_new = (W_eff * X_mu).sum(axis=0)\n            else:\n                m_new = (W * X_mu).sum(axis=0)\n\n            # normalized deltas for covariance (in sample coordinates)\n            deltas = (X_mu - m) / (sigma + 1e-20)  # shape (mu, dim)\n            if deltas.shape[0] > 0:\n                if deltas.shape[0] != weights.shape[0]:\n                    mu_eff = deltas.shape[0]\n                    w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if w_eff.sum() <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff = w_eff / np.sum(w_eff)\n                    Wd = w_eff.reshape(-1, 1)\n                    weighted_cov = (deltas * Wd).T @ deltas\n                    delta_mean = (Wd * deltas).sum(axis=0)\n                else:\n                    weighted_cov = (deltas * W).T @ deltas\n                    delta_mean = (W * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # update momentum (normalized coords)\n            v = self.mom_beta * v + (1.0 - self.mom_beta) * delta_mean\n\n            # rank-one from momentum\n            rank_one = np.outer(v, v)\n\n            # covariance update (blend)\n            c_cov = float(self.cov_lr)\n            c1 = float(self.rank1)\n            # ensure coefficients sum < 1, adjust if necessary\n            rem = max(0.0, 1.0 - c_cov - c1)\n            C = rem * C + c_cov * weighted_cov + c1 * rank_one\n            # enforce symmetry and SPD\n            C = 0.5 * (C + C.T)\n            vals, vecs = np.linalg.eigh(C)\n            vals = np.clip(vals, 1e-12, None)\n            C = (vecs * vals) @ vecs.T\n\n            # update per-coordinate scale as EMA of sqrt(mean squared deltas)\n            if deltas.shape[0] > 0:\n                stat = np.mean(deltas ** 2, axis=0)\n            else:\n                stat = 1e-6 * np.ones(self.dim)\n            s_diag = (self.s_diag_beta * s_diag +\n                      (1.0 - self.s_diag_beta) * np.sqrt(stat + 1e-20))\n            s_diag = np.clip(s_diag, 0.2, 5.0)\n\n            # accept new mean\n            m = m_new.copy()\n\n            # sigma adaptation via smoothed success rate (exponential update)\n            p_succ = 0.9 * p_succ + 0.1 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n            # opportunistic restart on prolonged stagnation\n            if stagn_count * lam_iter >= stagn_thresh and evals < self.budget:\n                stagn_count = 0\n                # jitter around best\n                jitter = 0.6 * sigma * (1.0 + 0.5 * rng.rand(self.dim))\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                sigma = max(sigma, 0.5 * mean_span)\n                v = np.zeros_like(v)\n                s_diag = np.ones_like(s_diag)\n                # continue (do not consume additional evals here)\n                continue\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MomentumDirectionalCMA scored 0.261 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "190f07d3-62a5-43e2-82e1-78ebbbad2370", "operator": null, "metadata": {"aucs": [0.1626208078575786, 0.20196469208670542, 0.3026491955244168, 0.34416216488769535, 0.25924112197594873, 0.38012433792375333, 0.2511350111439412, 0.26612087885747093, 0.2464652547668824, 0.19758405369764342]}, "task_prompt": ""}
{"id": "5d882999-45d0-46cb-a905-63f5612e89b3", "fitness": 0.14699454734491746, "name": "HADS", "description": "HADS is a hybrid gradient-free search that generates mirrored sample pairs from a mixture of a small low-rank direction memory (S) and per-coordinate Gaussian noise, which reduces estimator variance and lets a few learned directions guide anisotropic exploration. Per-coordinate scales D are adapted from the weighted variance of normalized perturbations so the algorithm cheaply learns anisotropy, while the memory S is updated by a weighted SVD of elites and each memory row has an adaptive trust weight (lamb) based on alignment with the weighted mean step. Recombination forms the new center m as a softmax-weighted average of top elites (adaptive temperature controls selection pressure) and a global step-size sigma is driven by a normalized-RMS diversity measure (alpha_sigma, diversity_target) and an improvement EMA to balance exploration vs. exploitation. Additional practical choices include mirrored paired sampling and a moderate population size scaling with sqrt(dim), conservative initialization (D ~ bounds/8, sigma ~0.12·mean(bounds)), slow memory blending (mem_update_rate ≈ 0.12) and an opportunistic restart that inflates sigma and reinitializes D/S after stagnation.", "code": "import numpy as np\n\nclass HADS:\n    \"\"\"\n    Hybrid Adaptive Directional Search (HADS)\n\n    Main ideas:\n     - Mirrored pair sampling for variance-efficient gradient-free sampling.\n     - Per-coordinate adaptive scales (D) to learn anisotropy cheaply.\n     - Small low-rank direction memory (S) that stores recent successful directions;\n       new samples are drawn as mixtures of memory directions and coordinate noise.\n     - Softmax-based recombination (adaptive temperature) to blend selection pressure.\n     - Step-size adapted by measured population spread (like CMA-style normalized RMS)\n       and by a running improvement signal.\n     - Opportunistic restart: re-center around best, reinitialize D/S and inflate sigma.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 k_memory=3,                 # memory size for low-rank directions\n                 alpha_sigma=0.6,            # strength of sigma adaptation\n                 diversity_target=0.30,      # target normalized RMS (relative to sqrt(dim))\n                 temp_init=0.5,              # initial temperature for softmax recombination\n                 stagnation_ratio=0.02,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.k = int(min(k_memory, max(1, dim)))\n        self.alpha_sigma = float(alpha_sigma)\n        self.diversity_target = float(diversity_target)\n        self.temp_init = float(temp_init)\n        self.stagnation_ratio = float(stagnation_ratio)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds support (Many Affine BBOB uses [-5,5])\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size (moderate)\n        if self.pop_base is None:\n            lam = max(10, int(6 + 1.5 * np.sqrt(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # initial sampling\n        evals = 0\n        first_batch = min(lam, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(first_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += first_batch\n\n        best_idx = np.argmin(f0)\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize mean using top-half recombination (rank-based)\n        mu = max(1, first_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu]]\n        # simple linear ranks but softmax temperature will modulate influence later\n        weights0 = np.linspace(mu, 1, mu)\n        weights0 = np.maximum(weights0, 1e-12)\n        weights0 = weights0 / np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # scales: per-coordinate scale vector D (positive)\n        bounds_scale = (ub - lb)\n        # start conservative local scales\n        D = (bounds_scale / 8.0).clip(min=1e-12)\n\n        # low-rank memory matrix S (k x dim), initialize from top PCA-like directions of elites\n        k = self.k\n        if mu >= 2:\n            diffs = (elites0 - m) / (np.maximum(D, 1e-12))  # normalized\n            # small SVD for principal directions\n            try:\n                U, svals, Vt = np.linalg.svd(diffs - diffs.mean(axis=0, keepdims=True), full_matrices=False)\n                S = (Vt[:k]).copy()  # shape (k, dim)\n            except Exception:\n                S = rng.randn(k, self.dim)\n        else:\n            S = rng.randn(k, self.dim)\n        # normalize memory vectors\n        for i in range(k):\n            nrm = np.linalg.norm(S[i])\n            if nrm > 0:\n                S[i] = S[i] / nrm\n\n        # directional strengths (how much to trust each memory vector)\n        lamb = np.ones(k, dtype=float) * 0.2\n\n        # scalar global step-size\n        sigma = 0.12 * np.mean(bounds_scale)  # somewhat conservative to start\n\n        # adaptive temperature for softmax recombination\n        temp = float(self.temp_init)\n\n        # stagnation control\n        stagn_limit = max(10, int(self.stagnation_ratio * self.budget))\n        stagn_count = 0\n\n        # running improvement EMA (for adaptivity)\n        improv_ema = 0.0\n        improv_alpha = 0.08  # smoothing for improvement signal\n\n        # helper: softmax\n        def softmax(a):\n            a = a - np.max(a)\n            e = np.exp(a)\n            return e / np.sum(e)\n\n        # main loop\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n\n            # dynamic mu: prefer top one-third\n            mu_iter = max(1, lam_iter // 3)\n\n            # generate mirrored samples using mixture of memory directions + coordinatewise noise\n            half = lam_iter // 2\n            odd = (lam_iter % 2) != 0\n\n            Xcand_list = []\n            Y_list = []  # normalized perturbations y = (x - m) / sigma\n            # precompute normalized memory contributions per sample\n            for _ in range(half):\n                # draw weights for memory vectors (small gaussian)\n                w = rng.randn(k) * np.sqrt(lamb + 1e-12)\n                # build directional vector (linear combination)\n                dir_vec = w @ S  # shape (dim,)\n                # scale directional part to have moderate magnitude relative to D\n                dir_scale = 0.5  # fraction of step from memory\n                dir_part = dir_scale * dir_vec\n\n                # coordinate noise\n                eps = rng.randn(self.dim)\n                coord_part = (D / (np.maximum(D.mean(), 1e-12))) * eps  # element-wise scaled noise\n                # normalized perturbation y (unitless)\n                y = dir_part + coord_part\n                x_plus = m + sigma * y\n                x_minus = m - sigma * y\n                Xcand_list.append(x_plus)\n                Xcand_list.append(x_minus)\n                Y_list.append(y)\n                Y_list.append(-y)\n\n            if odd:\n                # last unpaired sample uses pure coordinate noise plus small memory mix\n                w = rng.randn(k) * np.sqrt(lamb + 1e-12)\n                dir_vec = w @ S\n                dir_part = 0.5 * dir_vec\n                eps = rng.randn(self.dim)\n                coord_part = (D / (np.maximum(D.mean(), 1e-12))) * eps\n                y = dir_part + coord_part\n                Xcand_list.append(m + sigma * y)\n                Y_list.append(y)\n\n            # stack and clip to the actual lam_iter\n            Xcand = np.vstack(Xcand_list)[:lam_iter]\n            Ymat = np.vstack(Y_list)[:lam_iter]\n\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate (one by one to strictly respect call budget)\n            fc = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                fc[i] = func(Xcand[i])\n            evals += lam_iter\n\n            # update global best\n            gen_best_idx = np.argmin(fc)\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # selection: pick top mu_iter by fitness\n            order = np.argsort(fc)\n            top_idx = order[:mu_iter]\n            X_mu = Xcand[top_idx]\n            Y_mu = Ymat[top_idx]  # these are normalized perturbations (y = (x-m)/sigma)\n\n            # recombination weights: softmax over negative fitness scaled by temperature\n            scores = -fc[top_idx]  # higher is better\n            # adapt temperature slightly to spread weights when diversity is low\n            # (reduce selection pressure if very low diversity)\n            temp = np.clip(temp * (1.0 + 0.02 * (np.linalg.norm(D) / (np.mean(bounds_scale) + 1e-12) - 0.2)), 0.05, 5.0)\n            w = softmax(scores / max(1e-12, temp))\n            # ensure weights sum to 1\n            w = w.reshape(-1, 1)\n\n            # new mean in original coordinates\n            m_new = (w * X_mu).sum(axis=0)\n\n            # weighted normalized mean step\n            y_w = (w * Y_mu).sum(axis=0)\n\n            # update per-coordinate scales D using weighted variance of y's (smoothed)\n            y_var = np.maximum(np.var(Y_mu, axis=0, ddof=0), 1e-16)\n            target_D = np.sqrt(y_var)  # want per-coordinate scale ~ sqrt(var)\n            adapt_D = 0.18  # smoothing\n            D = (1.0 - adapt_D) * D + adapt_D * (target_D * np.maximum(np.mean(D), 1e-12))\n            # avoid degenerate D\n            D = np.clip(D, 1e-12, 2.0 * bounds_scale)\n\n            # update low-rank memory S: extract principal directions from weighted Y_mu\n            # compute weighted centered matrix\n            Yc = (Y_mu - y_w.reshape(1, -1)) * (w)\n            # if few elites, pad to at least rows > dim to permit svd, but we can do svd on small matrix\n            try:\n                U, svals, Vt = np.linalg.svd(Yc, full_matrices=False)\n                new_vecs = Vt[:k].copy()\n                # normalize\n                for i in range(new_vecs.shape[0]):\n                    nv = np.linalg.norm(new_vecs[i])\n                    if nv > 0:\n                        new_vecs[i] = new_vecs[i] / nv\n            except Exception:\n                new_vecs = rng.randn(k, self.dim)\n                for i in range(k):\n                    nrm = np.linalg.norm(new_vecs[i])\n                    if nrm > 0:\n                        new_vecs[i] = new_vecs[i] / nrm\n\n            # blend memory (slow update)\n            mem_update_rate = 0.12\n            S = (1.0 - mem_update_rate) * S + mem_update_rate * new_vecs\n            # renormalize memory rows\n            for i in range(k):\n                nrm = np.linalg.norm(S[i])\n                if nrm > 0:\n                    S[i] = S[i] / nrm\n\n            # update lamb (direction strengths) based on how aligned y_w is with each memory vector\n            align = np.maximum(0.0, S @ y_w)  # projection strengths\n            # normalize and blend\n            if np.sum(align) > 0:\n                align = align / (np.sum(align) + 1e-12)\n                lamb = (1.0 - 0.08) * lamb + 0.08 * (0.6 * lamb + 0.4 * align)\n            else:\n                lamb = (1.0 - 0.04) * lamb + 0.04 * 0.1\n\n            # update mean\n            m = m_new\n\n            # step-size update using normalized RMS of population (like AMES but with slight modification)\n            y_all = (Xcand - m) / (sigma + 1e-20)\n            norm_rms = np.sqrt(np.mean(np.sum(y_all**2, axis=1)) / max(1.0, float(self.dim)))\n            # move sigma toward diversity_target: increase if collapsed (norm_rms < target)\n            sigma *= np.exp(self.alpha_sigma * (self.diversity_target - norm_rms))\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n            # improvement signal: magnitude of improvement (if any) normalized\n            if improved:\n                last_improv = max(1e-12, (f_best - gen_best_f) if f_best < gen_best_f else 1e-12)\n                # actually gen_best_f is already min of fc; use absolute improvement relative to previous\n                # we simply reward improvement by lowering sigma slightly to localize\n                improv_ema = (1.0 - improv_alpha) * improv_ema + improv_alpha * (abs(f_best - gen_best_f) + 1e-12)\n                # a rule: if improvement large, slightly reduce sigma; else allow exploration\n                sigma *= np.exp(-0.04 * min(1.0, improv_ema / (abs(f_best) + 1e-12)))\n            else:\n                improv_ema = (1.0 - improv_alpha) * improv_ema  # decay\n\n            # small safeguard for numeric stability on D and lamb\n            D = np.clip(D, 1e-12, 10.0 * np.maximum(1e-12, bounds_scale))\n            lamb = np.clip(lamb, 1e-8, 10.0)\n\n            # opportunistic restart if stagnation\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # inflate sigma and re-center near best with jitter\n                sigma *= 3.0\n                jitter = 0.25 * sigma * (0.5 + rng.rand(self.dim))\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reinitialize D more broadly but not too large\n                D = (bounds_scale / 6.0).clip(min=1e-12)\n                # reset memory with random directions\n                S = rng.randn(k, self.dim)\n                for i in range(k):\n                    nrm = np.linalg.norm(S[i])\n                    if nrm > 0:\n                        S[i] = S[i] / nrm\n                lamb = np.ones(k, dtype=float) * 0.2\n                improv_ema = 0.0\n                # bound sigma\n                sigma = min(sigma, 1.0 * np.max(bounds_scale))\n                continue\n\n        # final record\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HADS scored 0.147 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "cebdb775-6824-4b44-af56-7c5277130528", "operator": null, "metadata": {"aucs": [0.1153312436998516, 0.1585631715389555, 0.19379725865255415, 0.14562201857999957, 0.14105016382581614, 0.1554012474519706, 0.16900248249562932, 0.13216279037594447, 0.13841059364418185, 0.1206045031842714]}, "task_prompt": ""}
{"id": "9e3a313c-a4cb-4f91-9dfe-02c301f25974", "fitness": 0.16400240816223718, "name": "DAES", "description": "The algorithm maintains a moderate ensemble of orthonormal search directions and performs mirrored sampling along each direction around a recombined mean (initialized from an elite sample), using per-dimension scales and a global sigma to control step magnitudes. It adapts exploration via multiplicative sigma updates driven by observed success rate (target_success≈0.18, sigma_adapt_rate≈0.25) and multiplicative per-dimension scale updates based on the weighted normalized step (scale_lr≈0.15), while rotating directions toward the weighted successful step with occasional re-orthonormalization (rotate_lr≈0.3) to keep directional diversity. Budget-aware mechanics (mirrored pairs, limiting max_pairs, and avoiding extra evaluations by conservatively updating the mean’s objective) ensure the number of func calls never exceeds the given budget. Opportunistic restarts after stagnation (restart_patience ≈ max(20, 0.03*budget)) increase sigma, jitter the mean around the best found point, and reinitialize scales and directions to escape local minima.", "code": "import numpy as np\n\nclass DAES:\n    \"\"\"\n    Directional Adaptive Ensemble Search (DAES)\n\n    Main idea (one-line): Maintain an ensemble of orthogonal search directions and per-dimension\n    step scales; sample mirrored candidates along those directions, adapt global sigma by\n    observed success-rate and rotate directions toward successful steps, with lightweight\n    per-dimension scale adaptation and opportunistic restarts.\n\n    Key parameters (exposed via __init__):\n     - budget, dim: required interface\n     - ensemble_size: number of search directions (k). More directions -> more exploration.\n     - init_sigma: initial global step-size (absolute scale).\n     - sigma_adapt_rate: multiplicative adaptation strength for sigma based on success-rate.\n     - target_success: desired fraction of improving candidates per generation.\n     - scale_lr: learning rate for per-dimension scale adaptation.\n     - rotate_lr: rate to rotate/align directions toward successful steps.\n     - restart_patience: iterations without improvement to trigger restart.\n     - rng_seed: optional random seed for reproducibility.\n\n    This implementation respects the budget: it will not call func() more times than self.budget.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 ensemble_size=None,\n                 init_sigma=None,\n                 sigma_adapt_rate=0.25,\n                 target_success=0.18,\n                 scale_lr=0.15,\n                 rotate_lr=0.30,\n                 restart_patience=None,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # algorithmic parameters with defaults chosen to differ from AMES:\n        if ensemble_size is None:\n            # moderate ensemble, slightly smaller than AMES' lam but directional\n            self.ensemble_size = max(6, int(4 + np.sqrt(max(2, self.dim))))\n        else:\n            self.ensemble_size = int(ensemble_size)\n\n        # sigma defaults to a moderate fraction of the search range (different scale from AMES)\n        self.init_sigma = init_sigma  # resolved later using bounds if None\n\n        self.sigma_adapt_rate = float(sigma_adapt_rate)   # multiplicative adaptation strength\n        self.target_success = float(target_success)       # desired success fraction\n        self.scale_lr = float(scale_lr)                   # per-dimension scale learning rate\n        self.rotate_lr = float(rotate_lr)                 # direction rotation learning rate\n\n        if restart_patience is None:\n            self.restart_patience = max(20, int(0.03 * self.budget))\n        else:\n            self.restart_patience = int(restart_patience)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds handling (Many Affine BBOB uses [-5,5])\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        mean_bounds = float(np.mean(bounds_scale))\n\n        # initialize sigma if not provided\n        if self.init_sigma is None:\n            sigma = 0.18 * mean_bounds  # different base step-size than AMES (slightly larger)\n        else:\n            sigma = float(self.init_sigma)\n\n        # per-dimension scale (diagonal-like) -- start conservative, encouraging exploration but not full-range jumps\n        scales = np.maximum(bounds_scale * 0.12, 1e-12)  # different bias than AMES (per-dim)\n\n        k = max(2, min(self.ensemble_size, self.budget // 2))  # ensure we can evaluate mirrored pairs\n        # prepare ensemble directions (k x dim), orthonormal rows\n        def orthonormal_rows(mat):\n            # Gram-Schmidt on rows\n            Q = np.zeros_like(mat)\n            for i in range(mat.shape[0]):\n                v = mat[i].copy().astype(float)\n                for j in range(i):\n                    pj = Q[j]\n                    v -= np.dot(v, pj) * pj\n                norm = np.linalg.norm(v)\n                if norm < 1e-12:\n                    # reinitialize to random\n                    v = rng.randn(mat.shape[1])\n                    for j in range(i):\n                        pj = Q[j]\n                        v -= np.dot(v, pj) * pj\n                    norm = max(1e-12, np.linalg.norm(v))\n                Q[i] = v / norm\n            return Q\n\n        D = rng.randn(k, self.dim)\n        D = orthonormal_rows(D)\n\n        # initialize mean m by sampling a small initial batch and taking best + small localization\n        evals = 0\n        init_batch = min(max(4, k), self.budget)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.empty(init_batch, dtype=float)\n        for i in range(init_batch):\n            f0[i] = func(X0[i])\n        evals += init_batch\n\n        best_idx = np.argmin(f0)\n        x_best = X0[best_idx].copy()\n        f_best = float(f0[best_idx])\n\n        # set starting mean to a slight recombination of initial elites (linear weights)\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.linspace(mu0, 1, mu0)\n        w0 = np.maximum(w0, 0.0)\n        w0 = w0 / np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # evaluate m if better than recorded best? (we'll evaluate it)\n        fm = func(m)\n        evals += 1\n        if fm < f_best:\n            f_best = fm\n            x_best = m.copy()\n\n        # strategy state\n        stagn_count = 0\n        best_since_restart = 0\n        iters = 0\n\n        # helper clamp\n        def clamp(x):\n            return np.minimum(np.maximum(x, lb), ub)\n\n        # main loop: each generation samples mirrored points along each direction (2*k candidates)\n        while evals < self.budget:\n            iters += 1\n            # plan how many candidate evaluations we can do this generation\n            remaining = self.budget - evals\n            max_pairs = min(k, remaining // 2)  # each pair consumes 2 evals\n            if max_pairs <= 0:\n                break\n\n            Xcand = []\n            fc = []\n\n            # for reproducibility, shuffle order of directions each generation\n            idxs = rng.permutation(k)[:max_pairs]\n            for j in idxs:\n                d = D[j]  # unit direction\n                # directional step incorporating per-dim scales\n                step_vec = d * scales  # element-wise\n                # mirrored candidates\n                x_plus = clamp(m + sigma * step_vec)\n                x_minus = clamp(m - sigma * step_vec)\n\n                # evaluate plus\n                f_plus = func(x_plus); evals += 1\n                Xcand.append(x_plus); fc.append(float(f_plus))\n                if f_plus < f_best:\n                    f_best = float(f_plus)\n                    x_best = x_plus.copy()\n                    stagn_count = 0\n                    best_since_restart += 1\n                # if budget exhausted after plus, break\n                if evals >= self.budget:\n                    break\n\n                # evaluate minus\n                f_minus = func(x_minus); evals += 1\n                Xcand.append(x_minus); fc.append(float(f_minus))\n                if f_minus < f_best:\n                    f_best = float(f_minus)\n                    x_best = x_minus.copy()\n                    stagn_count = 0\n                    best_since_restart += 1\n                if evals >= self.budget:\n                    break\n\n            # convert lists to arrays\n            if len(Xcand) == 0:\n                break\n            Xcand = np.vstack(Xcand)\n            fc = np.asarray(fc, dtype=float)\n\n            # how many of these improved over the current mean evaluation fm?\n            successes = (fc < fm - 1e-12).sum()\n            success_rate = float(successes) / max(1, len(fc))\n\n            # choose elites among candidates for recombination (top mu)\n            mu = max(1, len(fc) // 2)\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            weights = np.linspace(mu, 1, mu)\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # compute new mean as weighted recombination\n            m_new = (weights.reshape(-1,1) * X_mu).sum(axis=0)\n\n            # compute weighted mean step in normalized coordinates relative to sigma and per-dim scales\n            # define normalized step y = (x - m) / (sigma * scales)  (dimensionless)\n            denom = sigma * scales + 1e-20\n            y_steps = (X_mu - m) / denom  # shape (mu, dim)\n            y_w = (weights.reshape(-1,1) * y_steps).sum(axis=0)\n\n            # update per-dimension scales:\n            # move scales up on dimensions with large |y_w|, down otherwise (multiplicative)\n            # different equation than AMES: multiplicative log-space update\n            adapt_factor = np.exp(self.scale_lr * (np.abs(y_w) - 0.8))\n            scales = scales * adapt_factor\n            # keep scales within reasonable bounds\n            scales = np.clip(scales, bounds_scale * 1e-4, bounds_scale * 0.8)\n\n            # rotate directions toward the successful weighted step (makes directions adapt)\n            if np.linalg.norm(y_w) > 1e-12:\n                target_dir = y_w / (np.linalg.norm(y_w) + 1e-20)\n                # rotate a random subset of directions moderately toward target_dir\n                nrot = max(1, int(max_pairs * 0.5))\n                rot_idxs = rng.choice(k, size=nrot, replace=False)\n                for j in rot_idxs:\n                    dj = D[j]\n                    newd = (1.0 - self.rotate_lr) * dj + self.rotate_lr * target_dir\n                    # small randomization to avoid collapse\n                    newd += 0.02 * rng.randn(self.dim)\n                    # normalize and replace\n                    norm = np.linalg.norm(newd)\n                    if norm < 1e-12:\n                        newd = rng.randn(self.dim)\n                        norm = np.linalg.norm(newd)\n                    D[j] = newd / norm\n                # re-orthonormalize ensemble occasionally to keep diversity\n                if (iters % 5) == 0:\n                    D = orthonormal_rows(D)\n\n            # adapt sigma multiplicatively based on success rate (different rule from AMES)\n            if success_rate > self.target_success:\n                sigma *= (1.0 + self.sigma_adapt_rate * (success_rate - self.target_success))\n            else:\n                sigma /= (1.0 + self.sigma_adapt_rate * (self.target_success - success_rate))\n            # clamp sigma w.r.t. bounds\n            sigma = float(np.clip(sigma, 1e-12, 2.0 * mean_bounds))\n\n            # update mean without evaluating m_new to save budget; set fm conservatively:\n            # if any candidate among recombined elites was better than fm, use min(fc) as new fm,\n            # otherwise keep previous fm (we avoid an extra eval)\n            if np.min(fc) < fm:\n                fm = float(np.min(fc))\n            else:\n                # slight optimistic move: if recombination is not worse than best elite candidate, keep fm\n                # (this avoids inflating fm)\n                pass\n            m = m_new\n\n            # stagnation tracking: if no global improvement in many generations -> restart\n            if best_since_restart == 0:\n                stagn_count += 1\n            else:\n                stagn_count = 0\n            best_since_restart = 0\n\n            if stagn_count >= self.restart_patience and evals < self.budget:\n                # opportunistic restart: increase sigma, randomize directions and slightly jitter mean near best\n                stagn_count = 0\n                sigma = min(sigma * 2.5, 2.0 * mean_bounds)\n                # jitter mean around best solution found so far\n                jitter = sigma * (0.25 + 0.75 * rng.rand(self.dim))\n                m = clamp(x_best + rng.randn(self.dim) * jitter)\n                # reinitialize scales to moderate small values to encourage local search\n                scales = np.maximum(bounds_scale * 0.08, 1e-12)\n                # reinit and orthonormalize directions\n                D = rng.randn(k, self.dim)\n                D = orthonormal_rows(D)\n                # evaluate the new mean after restart if budget allows, to get fresh fm\n                if evals < self.budget:\n                    fm = float(func(m)); evals += 1\n                    if fm < f_best:\n                        f_best = fm\n                        x_best = m.copy()\n\n        # final outputs\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DAES scored 0.164 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "cebdb775-6824-4b44-af56-7c5277130528", "operator": null, "metadata": {"aucs": [0.0948397986059134, 0.15779408604322487, 0.2703220000820894, 0.21032437496237077, 0.09587477130274147, 0.1437581772036446, 0.21679736724603094, 0.1975624112299169, 0.10325582427532198, 0.14949527067111756]}, "task_prompt": ""}
{"id": "09e76a82-ba97-4ad4-95ed-479d717119c0", "fitness": 0.2030432513964203, "name": "HAMOS", "description": "The algorithm maintains a central mean m with anisotropic per-dimension step sizes sigma_vec (initialized as a fraction of the bounds) and a small ensemble of initial centers to seed exploration, and it sizes each iteration's population lam from the problem dimension and remaining budget. Candidates are generated along a compact set of orthonormal probe directions (QR of a random matrix) using mirrored pairs for variance reduction, occasional heavy-tailed Cauchy jumps (levy_prob, levy_scale) and small coordinate jitter to enable both local search and escapes. Selection uses rank-weighted recombination (exponential decay weights) to update the mean, while per-dimension sigmas are adapted toward a target dispersion via MAD-based statistics and clipped scaling (sigma_adapt_strength, sigma_target_frac), and a small momentum covariance M (momentum_beta) is estimated from normalized elite steps to introduce persistent anisotropy. Stagnation is tracked (stagnation_ratio) and triggers an opportunistic diversify restart that inflates sigmas, recenters near the best with Cauchy jitter, injects heavy-tailed bursts, and always enforces strict bound clamping and budget-aware evaluation.", "code": "import numpy as np\n\nclass HAMOS:\n    \"\"\"\n    Hierarchical Adaptive Multi-scale Orthogonal Search (HAMOS)\n\n    Key ideas:\n     - Maintain a central mean m and a per-dimension step vector sigma_vec for anisotropic exploration.\n     - Generate candidate steps along a small set of orthonormal directions (orthogonal probes),\n       using mirrored pairs for variance reduction and occasional heavy-tailed (Cauchy) jumps for escapes.\n     - Adapt per-dimension sigmas using robust dispersion (MAD) of the current population relative to bounds;\n       also use a small momentum covariance matrix M to bias anisotropy over time.\n     - Use rank-weighted recombination to update the mean and a momentum update for M.\n     - Opportunistic \"diversify\" restart on stagnation: jitter around best, enlarge sigmas, and inject heavy-tailed samples.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 k_dirs_factor=2.0,\n                 levy_prob=0.08,\n                 levy_scale=3.0,\n                 sigma_init_frac=0.12,\n                 sigma_target_frac=0.22,\n                 sigma_adapt_strength=0.6,\n                 momentum_beta=0.85,\n                 stagnation_ratio=0.02,\n                 seed=None):\n        \"\"\"\n        Parameters:\n         - budget: number of function evaluations allowed\n         - dim: problem dimensionality\n         - pop_base: optional base population size; if None computed from dim\n         - k_dirs_factor: controls number of orthogonal probe directions (~k_dirs_factor * sqrt(dim))\n         - levy_prob: probability per sample to draw a heavy-tailed jump (Cauchy)\n         - levy_scale: additional multiplier for Cauchy jump magnitude\n         - sigma_init_frac: initial sigma as fraction of bounds range (per-dim)\n         - sigma_target_frac: desired normalized dispersion fraction used for sigma adaptation\n         - sigma_adapt_strength: how aggressively per-dim sigma_vec is adapted (0..1)\n         - momentum_beta: momentum for covariance-like matrix M\n         - stagnation_ratio: fraction of budget that defines stagnation limit\n         - seed: RNG seed\n        \"\"\"\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.k_dirs_factor = float(k_dirs_factor)\n        self.levy_prob = float(levy_prob)\n        self.levy_scale = float(levy_scale)\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.sigma_target_frac = float(sigma_target_frac)\n        self.sigma_adapt_strength = float(sigma_adapt_strength)\n        self.momentum_beta = float(momentum_beta)\n        self.stagnation_ratio = float(stagnation_ratio)\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds (support scalar or array)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        bounds_scale = np.maximum(ub - lb, 1e-12)\n\n        # population / directions sizing\n        if self.pop_base is None:\n            lam = max(8, int(4 + 2 * np.sqrt(max(2, self.dim))))\n        else:\n            lam = max(4, int(self.pop_base))\n        lam = min(lam, max(2, self.budget))\n\n        # initial multiple centers (small ensemble) to encourage exploration\n        k_centers = min(3, lam)  # keep cheap\n        evals = 0\n        centers = rng.uniform(lb, ub, size=(k_centers, self.dim))\n        f_centers = np.empty(k_centers, dtype=float)\n        for i in range(k_centers):\n            f_centers[i] = func(centers[i])\n        evals += k_centers\n\n        # pick best center as primary mean\n        best_idx = int(np.argmin(f_centers))\n        m = centers[best_idx].copy()\n        f_best = float(f_centers[best_idx])\n        x_best = m.copy()\n\n        # initial per-dimension sigma (anisotropic)\n        sigma_vec = self.sigma_init_frac * bounds_scale  # vector scaling per-dim\n\n        # small momentum covariance / anisotropy accumulator (dim x dim)\n        M = np.eye(self.dim) * (1e-8)\n\n        # stagnation tracking\n        stagn_limit = max(8, int(self.stagnation_ratio * self.budget))\n        stagn_count = 0\n\n        # main loop\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            # number of orthogonal directions to sample from this iteration\n            k_dirs = min(self.dim, max(2, int(self.k_dirs_factor * np.sqrt(self.dim))))\n            # build an orthonormal basis (columns of Q)\n            # small randomization to avoid deterministic QR degeneracy\n            R = rng.normal(size=(self.dim, self.dim))\n            try:\n                Q, _ = np.linalg.qr(R)\n            except np.linalg.LinAlgError:\n                # fall back to eigenvectors of a symmetric random matrix\n                vals, vecs = np.linalg.eigh((R + R.T) / 2.0)\n                Q = vecs\n            dirs = Q[:, :k_dirs].T  # shape (k_dirs, dim), unit length rows\n\n            # produce mirrored candidate set\n            Xcand = []\n            Ynorm = []  # normalized steps (X - m) / sigma_effective\n            # compute effective scalar from sigma_vec to scale direction steps\n            sigma_scalar = np.mean(sigma_vec)\n            half_pairs = lam_iter // 2\n            odd = (lam_iter % 2) != 0\n\n            for _ in range(half_pairs):\n                di = rng.randint(0, k_dirs)\n                d = dirs[di]  # unit vector\n                # choose heavy-tailed or gaussian step magnitude\n                if rng.rand() < self.levy_prob:\n                    # Cauchy jump scaled relative to sigma_scalar and bounds\n                    s = np.random.standard_cauchy() * self.levy_scale\n                    # clip extreme values to avoid infinite/unbounded jumps\n                    s = np.clip(s, -10.0, 10.0)\n                else:\n                    s = rng.randn()  # normal scalar\n                # small orthogonal jitter proportional to per-dim sigma_vec\n                orth_jitter = rng.randn(self.dim) * (0.08 * sigma_vec)\n                step = (d * s * sigma_scalar) + orth_jitter\n\n                x_plus = m + step\n                x_minus = m - step\n                # clamp\n                x_plus = np.minimum(np.maximum(x_plus, lb), ub)\n                x_minus = np.minimum(np.maximum(x_minus, lb), ub)\n\n                Xcand.append(x_plus)\n                Xcand.append(x_minus)\n\n                # normalized steps by per-dim sigma_vec (avoid divide-by-zero)\n                denom = sigma_vec.copy()\n                denom[denom <= 1e-12] = 1e-12\n                Ynorm.append((x_plus - m) / denom)\n                Ynorm.append((x_minus - m) / denom)\n\n            if odd:\n                # single extra sample: combine a random orthogonal direction and a coordinate-wise perturb\n                di = rng.randint(0, k_dirs)\n                d = dirs[di]\n                if rng.rand() < self.levy_prob:\n                    s = np.random.standard_cauchy() * self.levy_scale\n                    s = np.clip(s, -12.0, 12.0)\n                else:\n                    s = rng.randn()\n                coord_noise = rng.randn(self.dim) * (0.15 * sigma_vec)\n                step = d * s * sigma_scalar + coord_noise\n                xc = m + step\n                xc = np.minimum(np.maximum(xc, lb), ub)\n                Xcand.append(xc)\n                denom = sigma_vec.copy()\n                denom[denom <= 1e-12] = 1e-12\n                Ynorm.append((xc - m) / denom)\n\n            # trim to lam_iter (safety)\n            Xcand = Xcand[:lam_iter]\n            Ynorm = Ynorm[:lam_iter]\n            Xcand = np.asarray(Xcand)\n            Ynorm = np.asarray(Ynorm)\n\n            # Evaluate candidates one-by-one (to allow early stopping)\n            fc = np.empty(Xcand.shape[0], dtype=float)\n            for i in range(Xcand.shape[0]):\n                fc[i] = func(Xcand[i])\n                evals += 1\n                if fc[i] < f_best:\n                    f_best = float(fc[i])\n                    x_best = Xcand[i].copy()\n                    stagn_count = 0\n                # global eval budget check\n                if evals >= self.budget:\n                    # fill remaining indices with inf if any (shouldn't usually happen because lam_iter bounded)\n                    break\n\n            # selection and recombination\n            order = np.argsort(fc)\n            mu = max(1, lam_iter // 2)\n            elites_idx = order[:mu]\n            elites = Xcand[elites_idx]\n            elites_y = Ynorm[elites_idx]  # normalized steps relative to per-dim sigma_vec\n\n            # rank-weighting (exponential decay)\n            ranks = np.arange(mu)\n            w_raw = np.exp(-ranks / max(1.0, mu / 3.0))\n            weights = w_raw / np.sum(w_raw)\n            # update mean m (in original coordinates)\n            m_new = (weights.reshape(-1, 1) * elites).sum(axis=0)\n\n            # compute robust per-dim dispersion (MAD) of the full evaluated population this iter\n            # use median absolute deviation relative to median\n            med = np.median(Xcand, axis=0)\n            mad = np.median(np.abs(Xcand - med), axis=0)\n            # normalized MAD relative to bounds (clamp)\n            mad_norm = mad / (bounds_scale + 1e-20)\n\n            # adapt per-dim sigma_vec toward a desired fraction of bounds\n            # if mad_norm < target -> increase sigma, else decrease\n            target = self.sigma_target_frac\n            # scale factor per-dim\n            adapt_factor = np.exp(self.sigma_adapt_strength * (target - mad_norm))\n            # stabilize adapt_factor bounds\n            adapt_factor = np.clip(adapt_factor, 0.6, 1.8)\n            sigma_vec = sigma_vec * adapt_factor\n            # ensure sigma stays in reasonable bounds\n            sigma_vec = np.clip(sigma_vec, 1e-12, 1.2 * bounds_scale)\n\n            # momentum covariance update (using normalized elite steps)\n            # weighted outer products of normalized steps (per-dim)\n            if elites_y.shape[0] >= 1:\n                W = weights.reshape(-1, 1)\n                cov_est = (W * elites_y).T @ elites_y  # shape (dim, dim)\n                # small shrink toward diagonal proportional to current sigma_vec\n                shrink_diag = np.diag((sigma_vec / (np.mean(sigma_vec) + 1e-20))**2)\n                cov_est = 0.9 * cov_est + 0.1 * shrink_diag\n                # momentum update\n                M = self.momentum_beta * M + (1.0 - self.momentum_beta) * cov_est\n                # ensure symmetry and positive definiteness (clip eigenvalues)\n                try:\n                    # small jitter for stability\n                    _ = np.linalg.cholesky(M + np.eye(self.dim) * 1e-18)\n                except np.linalg.LinAlgError:\n                    vals, vecs = np.linalg.eigh(M)\n                    vals = np.clip(vals, 1e-12, None)\n                    M = (vecs * vals) @ vecs.T\n\n            # use M to slightly rescale sigma_vec (introduce anisotropy)\n            # scale sigma_vec by sqrt(diag(I + small * M))\n            diagM = np.diag(M)\n            diagM = np.maximum(diagM, 0.0)\n            anisotropy = np.sqrt(1.0 + 0.5 * diagM)\n            sigma_vec = np.minimum(sigma_vec * anisotropy, 1.2 * bounds_scale)\n\n            # accept new mean (move)\n            m = m_new\n\n            # stagnation tracking\n            if f_best < np.min(fc):  # if improvement came from current batch we've handled above\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # opportunistic diversify restart when stagnated\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # enlarge exploration: inflate sigma_vec and perform a burst of heavy-tailed probes\n                sigma_vec = np.minimum(sigma_vec * (1.8 + 0.6 * rng.rand(self.dim)), bounds_scale * 1.0)\n                # re-center m near best with moderate Cauchy jitter for escape\n                jitter = np.random.standard_cauchy(size=self.dim) * (0.6 * np.mean(bounds_scale))\n                jitter = np.clip(jitter, -2.0 * bounds_scale, 2.0 * bounds_scale)\n                m = np.minimum(np.maximum(x_best + jitter * (0.4 * rng.rand(self.dim)), lb), ub)\n                M = np.eye(self.dim) * 1e-8  # reset momentum\n                # small burst: evaluate a few heavy-tailed samples around new center (but respect budget)\n                burst = min(6, self.budget - evals)\n                if burst > 0:\n                    for _ in range(burst):\n                        # heavy-tailed sample\n                        s = np.random.standard_cauchy()\n                        s = np.clip(s, -12.0, 12.0)\n                        dvec = rng.randn(self.dim)\n                        dvec /= (np.linalg.norm(dvec) + 1e-12)\n                        step = dvec * s * np.mean(sigma_vec)\n                        x_try = np.minimum(np.maximum(m + step, lb), ub)\n                        f_try = func(x_try)\n                        evals += 1\n                        if f_try < f_best:\n                            f_best = float(f_try)\n                            x_best = x_try.copy()\n                            # nudge m slightly toward new best\n                            m = 0.6 * m + 0.4 * x_best\n                        if evals >= self.budget:\n                            break\n                # continue main loop\n                continue\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HAMOS scored 0.203 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "cebdb775-6824-4b44-af56-7c5277130528", "operator": null, "metadata": {"aucs": [0.11575898965826825, 0.1908293962545098, 0.2575177641975015, 0.22940629790781297, 0.2052353424579837, 0.2293099406524477, 0.21919828752653037, 0.2203421654031016, 0.2147668107321844, 0.14806751917386263]}, "task_prompt": ""}
{"id": "40b03e57-bbe6-4db1-826f-4bde1b46bd73", "fitness": 0.15735079546746883, "name": "DSMAS", "description": "The algorithm maintains dual-scale search by keeping a slow global mean and a fast local mean and sampling from their convex mixture (mix_w) so it can smoothly shift between broad exploration and focused exploitation. It uses mirrored (antithetic) sampling from a diagonal Gaussian with per-dimension scale s = sigma_vec * sqrt(C_diag), geometric recombination weights for elites, and a modest, dimension-dependent population size to get robust rank-based updates while remaining budget-aware. Adaptation is twofold: a diagonal covariance update combining a rank‑1 evolution-path term (c1) and a rank‑mu term (cmu) for stable per-dimension variance learning, and an independent multiplicative per-dimension sigma_vec update driven by the median absolute deviation (beta_sigma, target_mad) to prevent collapse or runaway step-sizes (all scales are clipped relative to the problem bounds). Finally, a simple improvement-driven mixing rule (mix_step_up/down) biases search toward the local mean when improving and toward global when not, and an opportunistic restart (stagnation_ratio) inflates sigma, perturbs the means, and resets covariance to rekindle exploration.", "code": "import numpy as np\n\nclass DSMAS:\n    \"\"\"\n    Dual-Scale Mirrored Adaptive Search (DSM-AS)\n\n    Main idea (one-line): Maintain a slow global mean + a fast local mean and sample mirrored pairs\n    from a diagonal, per-dimension scaled Gaussian; adapt per-dimension step-sizes using median\n    absolute deviation (MAD) of normalized steps, adapt covariance diagonals with a rank-mu + rank-1\n    style update (kept diagonal for stability), and change mixing between local/global based on\n    recent improvements. Occasional opportunistic restarts expand global exploration.\n\n    Main algorithm parameters (exposed and tunable):\n     - budget, dim: mandatory\n     - pop_base: base population size (default derived from dim)\n     - c1, cmu: diagonal covariance mixing coefficients (rank-1 and rank-mu)\n     - beta_sigma: strength of per-dimension sigma (step-size) adaptation using MAD\n     - target_mad: desired normalized MAD (controls sigma adaptation)\n     - gamma_global: learning rate to move global mean toward local mean (slow)\n     - mix_step_up/down: how mixing weight changes on improvement/no-improvement\n     - stagnation_limit: evaluations without improvement to trigger a restart\n     - rng_seed: random seed\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 c1=0.08, cmu=0.02,\n                 beta_sigma=0.5, target_mad=0.6,\n                 gamma_global=0.05,\n                 mix_step_up=0.06, mix_step_down=0.03,\n                 stagnation_ratio=0.02,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.c1 = float(c1)\n        self.cmu = float(cmu)\n        self.beta_sigma = float(beta_sigma)\n        self.target_mad = float(target_mad)\n        self.gamma_global = float(gamma_global)\n        self.mix_step_up = float(mix_step_up)\n        self.mix_step_down = float(mix_step_down)\n        self.stagnation_ratio = float(stagnation_ratio)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds (support scalar or vector lb/ub)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size (different formula from AMES): slowly growing with log(dim)\n        if self.pop_base is None:\n            lam = int(max(8, 4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # evaluation bookkeeping\n        evals = 0\n        remaining = self.budget - evals\n\n        # initial random sampling to seed means and best\n        initial_batch = min(lam, remaining)\n        X0 = rng.uniform(lb, ub, size=(initial_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += initial_batch\n\n        best_idx = np.argmin(f0)\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize local mean (fast) and global mean (slow) via top-half geometric weights\n        mu0 = max(1, initial_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        # geometric weights (decreasing): heavier weight on best\n        geom_weights = np.geomspace(1.0, 0.3, mu0)\n        geom_weights = geom_weights / np.sum(geom_weights)\n        local_mean = (geom_weights.reshape(-1, 1) * elites0).sum(axis=0)\n        global_mean = local_mean.copy()\n\n        # diagonal covariance (per-dim variance) initialisation: narrower than wide range\n        bounds_scale = (ub - lb)\n        # initialize diagonal variance as small fraction of bounds^2\n        init_var = ((bounds_scale / 8.0) ** 2).clip(min=1e-12)\n        C_diag = init_var.copy()\n\n        # per-dimension multiplicative step-size (sigma vector)\n        sigma_base = 0.10 * np.mean(bounds_scale)  # somewhat conservative initial scale\n        sigma_vec = np.full(self.dim, sigma_base, dtype=float)\n\n        # mixing weight between local (fast) and global (slow): 0..1, 1 -> use global mean\n        mix_w = 0.5\n\n        # stagnation and restart control\n        stagn_limit = max(10, int(self.stagnation_ratio * self.budget))\n        stagn_count = 0\n\n        # evolution path (for rank-1 like diagonal update)\n        p = np.zeros(self.dim, dtype=float)\n\n        # helper: recombination (geometric decreasing)\n        def recombination_weights(mu_local):\n            w = np.geomspace(1.0, 0.4, mu_local)\n            w = w / np.sum(w)\n            return w\n\n        # main loop\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu_iter = max(1, lam_iter // 2)\n            weights = recombination_weights(mu_iter)\n\n            # compute current mean used for sampling as mix of global/local\n            m = mix_w * global_mean + (1.0 - mix_w) * local_mean\n\n            # prepare diagonal sqrt-variance scaling: s = sigma_vec * sqrt(C_diag) elementwise\n            s = sigma_vec * np.sqrt(C_diag)\n            # ensure no zero scale\n            s = np.maximum(s, 1e-12)\n\n            # mirrored sampling with antithetic pairs (and one odd if needed)\n            half = lam_iter // 2\n            odd = (lam_iter % 2) == 1\n            # generate half gaussian draws\n            Z_half = rng.normal(size=(half, self.dim))\n            Xcand_list = []\n            Z_list = []\n            for z in Z_half:\n                y = z * s  # elementwise\n                Xcand_list.append(m + y)\n                Xcand_list.append(m - y)\n                Z_list.append(z)\n                Z_list.append(-z)\n            if odd:\n                z = rng.normal(size=self.dim)\n                y = z * s\n                Xcand_list.append(m + y)\n                Z_list.append(z)\n\n            Xcand = np.vstack(Xcand_list)[:lam_iter]\n            Zmat = np.vstack(Z_list)[:lam_iter]\n\n            # clamp candidates to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate one-by-one (respect budget)\n            fc = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                # protect against accidental extra evals (shouldn't happen since lam_iter <= remaining)\n                if evals >= self.budget:\n                    fc = fc[:i]\n                    Xcand = Xcand[:i]\n                    Zmat = Zmat[:i]\n                    lam_iter = i\n                    break\n                fc[i] = func(Xcand[i])\n                evals += 1\n\n            if lam_iter == 0:\n                break\n\n            # update best\n            gen_best_idx = np.argmin(fc)\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += lam_iter\n\n            # select elites and compute weighted local mean (use original X coordinates)\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu_iter]]\n            Z_mu = Zmat[order[:mu_iter]]  # raw standard normal vectors corresponding to samples\n            w = weights.reshape(-1, 1)\n            new_local_mean = (w * X_mu).sum(axis=0)\n\n            # compute normalized y_steps = (X - m) / s  (elementwise)\n            # note: s maybe zero but ensured min earlier\n            y_steps = (X_mu - m) / (s + 1e-20)  # shape (mu_iter, dim)\n            # weighted diagonal cov (variance per-dim in normalized coords)\n            cov_mu_diag = (w * (y_steps ** 2)).sum(axis=0) - ((w * y_steps).sum(axis=0)) ** 2\n            cov_mu_diag = np.maximum(cov_mu_diag, 0.0)  # numerical safety\n\n            # effective mu for scaling\n            mu_eff = (np.sum(weights) ** 2) / np.sum(weights ** 2)\n\n            # evolution path update (diagonal form)\n            y_w = (w * y_steps).sum(axis=0)\n            c_p = 1.0 / (self.dim + 3.0)\n            p = (1.0 - c_p) * p + np.sqrt(c_p * (2.0 - c_p) * mu_eff) * y_w\n\n            # diagonal covariance update: keep diagonal only for robustness\n            coef_fix = max(0.0, 1.0 - self.c1 - self.cmu)\n            C_diag = coef_fix * C_diag + self.c1 * (p ** 2) + self.cmu * (cov_mu_diag * (s != 0.0) + 0.0)\n            # avoid numerical collapse\n            min_var = ((bounds_scale / 200.0) ** 2).clip(min=1e-16)\n            C_diag = np.maximum(C_diag, min_var)\n\n            # update local and global means\n            local_mean = new_local_mean\n            global_mean = (1.0 - self.gamma_global) * global_mean + self.gamma_global * local_mean\n\n            # per-dimension sigma adaptation using MAD of normalized population\n            # build normalized steps for all evaluated candidates this iteration relative to current m\n            y_all = (Xcand - m) / (s + 1e-20)  # shape (lam_iter, dim)\n            # median absolute deviation per-dim\n            med = np.median(y_all, axis=0)\n            mad = np.median(np.abs(y_all - med), axis=0)\n            # guard mad > 0\n            mad = np.maximum(mad, 1e-8)\n\n            # adjust sigma_vec toward target_mad: increase where MAD small (collapsed), decrease where large\n            # multiplicative update\n            sigma_vec *= np.exp(self.beta_sigma * (self.target_mad - mad))\n            # clamp sigma_vec to reasonable bounds relative to range\n            sigma_vec = np.clip(sigma_vec, 1e-12, 2.0 * np.maximum(1e-12, bounds_scale))\n\n            # adjust mixing weight based on improvement (bias toward local when improving)\n            if improved:\n                mix_w = max(0.0, mix_w - self.mix_step_up)  # move toward local (lower mix_w)\n            else:\n                mix_w = min(1.0, mix_w + self.mix_step_down)  # move toward global\n\n            # opportunistic restart if stagnation persists\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # expand global exploration: increase global sigma, randomize global mean slightly around best\n                sigma_vec *= 3.0\n                global_mean = x_best + rng.randn(self.dim) * (0.5 * sigma_vec)\n                # reset local mean near best but with small jitter\n                local_mean = x_best + rng.randn(self.dim) * (0.1 * sigma_vec)\n                # reset diagonal covariances to medium values\n                C_diag = ((bounds_scale / 6.0) ** 2).clip(min=1e-12)\n                # reset evolution path\n                p = np.zeros_like(p)\n                # nudge mixing toward global to favor exploration\n                mix_w = min(1.0, mix_w + 0.4)\n                # limit sigma to avoid runaway\n                sigma_vec = np.clip(sigma_vec, 1e-12, 2.0 * bounds_scale)\n                continue\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DSMAS scored 0.157 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "cebdb775-6824-4b44-af56-7c5277130528", "operator": null, "metadata": {"aucs": [0.11472699281665444, 0.15582247758238632, 0.25110756158017944, 0.16156883061840466, 0.10295552098433591, 0.15703474917492177, 0.18170618713928577, 0.15068124899871105, 0.14971196614004922, 0.1481924196397596]}, "task_prompt": ""}
{"id": "bbbfa396-c700-4a49-8057-4e460f1b4e1d", "fitness": 0.2118657203635113, "name": "HMICPS", "description": "The HMICPS is a hybrid IPOP-style CMA-like strategy that uses mirrored (antithetic) sampling and log‑weighted recombination to reduce variance and robustly form a new mean from elites, with a moderate default population size computed as max(12, 6+2*sqrt(dim)) and initial sigma set by sigma_factor=0.18 times the average bound range. Covariance learning is a stable mix of rank-1 evolution path (c1=0.12) and rank-mu weighted covariance (cmu=0.08) with a small diagonal shrink toward isotropy and multiple SPD safeguards (Cholesky try, eigenvalue correction, jitter, reset from bounds/6), and symmetry enforced after updates. Step‑size adaptation is dual: an exponentially smoothed success‑rate controller targeting success_target=0.2 (alpha_succ=0.25) combined with a spread/RMS‑based controller (alpha_spread=0.6) to keep population dispersion in check; sigma and C are clipped to reasonable ranges to avoid blowup. Robustness mechanisms include budget‑aware IPOP restarts (stagnation detected after stagnation_ratio=0.03 of budget, doubling lambda, re‑centering near global best with jitter and increasing sigma), occasional global uniform injections (~1% chance), and strict bound clamping for all candidates.", "code": "import numpy as np\n\nclass HMICPS:\n    \"\"\"\n    Hybrid Mirrored IPOP-Covariance Strategy (HMICPS)\n\n    Key features:\n     - Mirrored / antithetic sampling for variance-efficient sampling.\n     - Covariance adapted by a mix of rank-1 evolution path and rank-mu weighted covariance.\n     - Dual step-size adaptation: smoothed success-rate (approx 1/5th) plus normalized spread control.\n     - Robust SPD safeguards (Cholesky + eigen-correction + diagonal jitter).\n     - Opportunistic IPOP-style restarts (increase population on restart), re-center near best with jitter,\n       and occasional global uniform injections to escape local traps.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None, rng_seed=None,\n                 c1=0.12, cmu=0.08,\n                 sigma_factor=0.18,      # base sigma factor (relative to average bound range)\n                 success_target=0.2,     # target success rate\n                 alpha_succ=0.25,        # weight for success-based sigma adaptation\n                 alpha_spread=0.6,       # weight for spread-based sigma adaptation\n                 stagnation_ratio=0.03,  # fraction of budget to detect stagnation\n                 max_restarts=6):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.rng_seed = rng_seed\n\n        # covariance learning rates\n        self.c1 = float(c1)\n        self.cmu = float(cmu)\n\n        # sigma adaptation parameters\n        self.sigma_factor = float(sigma_factor)\n        self.success_target = float(success_target)\n        self.alpha_succ = float(alpha_succ)\n        self.alpha_spread = float(alpha_spread)\n\n        # stagnation / restarts\n        self.stagnation_ratio = float(stagnation_ratio)\n        self.max_restarts = int(max_restarts)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = ub - lb\n        avg_range = float(np.mean(bounds_scale))\n\n        # initial population size (moderate), favor a somewhat larger base than DACS\n        if self.pop_base is None:\n            lam_base = max(12, int(6 + 2 * np.sqrt(max(2, self.dim))))\n        else:\n            lam_base = int(self.pop_base)\n        lam_base = min(lam_base, max(2, self.budget))\n\n        # initial sigma and covariance\n        sigma0 = max(1e-12, self.sigma_factor * avg_range)\n        C0 = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n\n        # algorithm state\n        evals = 0\n        f_best = np.inf\n        x_best = None\n\n        # restart / IPOP state\n        restart_count = 0\n        lam = lam_base\n\n        # stagnation tracking (evaluations without improvement)\n        stagn_evals = 0\n        stagn_limit = max(10, int(self.stagnation_ratio * self.budget))\n\n        # main loop over restarts (IPOP-style), but stop when budget exhausted\n        while evals < self.budget and restart_count <= self.max_restarts:\n            # initial sampling for this run: draw lam candidates (uniform) for first evaluation to seed mean\n            lam_run = min(lam, max(2, self.budget - evals))\n            batch0 = lam_run\n            X0 = rng.uniform(lb, ub, size=(batch0, self.dim))\n            f0 = np.empty(batch0, dtype=float)\n            for i in range(batch0):\n                f0[i] = func(X0[i])\n            evals += batch0\n\n            # update global best\n            idx0 = int(np.argmin(f0))\n            if f0[idx0] < f_best:\n                f_best = float(f0[idx0])\n                x_best = X0[idx0].copy()\n                stagn_evals = 0\n            else:\n                stagn_evals += batch0\n\n            # initialize mean from top-half weighted recombination (use log-weights like DACS for robustness)\n            mu0 = max(1, batch0 // 2)\n            order0 = np.argsort(f0)\n            elites0 = X0[order0[:mu0]]\n            weights = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n            m = (weights.reshape(-1, 1) * elites0).sum(axis=0)\n\n            # set strategy parameters for the run\n            C = C0.copy()\n            sigma = sigma0 * (1.0 + 0.2 * restart_count)  # mildly increase sigma with restarts\n            p = np.zeros(self.dim, dtype=float)           # evolution path\n            p_succ = self.success_target                   # smoothed success rate\n            success_target = float(self.success_target)\n\n            # per-run counters\n            iter_count = 0\n\n            # per-run main loop\n            while evals < self.budget:\n                iter_count += 1\n                remaining = self.budget - evals\n                lam_iter = min(lam, remaining)\n                mu_iter = max(1, lam_iter // 2)\n\n                # recombination weights (log-weights for stability)\n                w = np.log(mu_iter + 0.5) - np.log(np.arange(1, mu_iter + 1))\n                w = np.maximum(w, 0.0)\n                w = w / np.sum(w)\n\n                # SPD safeguard: try Cholesky, fallback to eigen correction\n                eps = 1e-12 * np.maximum(np.diag(C), 1.0)\n                try:\n                    A = np.linalg.cholesky(C + np.diag(eps))\n                except np.linalg.LinAlgError:\n                    vals, vecs = np.linalg.eigh(C)\n                    vals = np.clip(vals, 1e-12, None)\n                    A = (vecs * np.sqrt(vals)).T\n\n                # mirrored sampling construction\n                half = lam_iter // 2\n                odd = (lam_iter % 2) != 0\n                Z = rng.normal(size=(half, self.dim))\n                Y_half = Z @ A.T\n                Xcand_list = []\n                Z_list = []\n                for y in Y_half:\n                    Xcand_list.append(m + sigma * y)\n                    Xcand_list.append(m - sigma * y)\n                    Z_list.append(y)\n                    Z_list.append(-y)\n                if odd:\n                    z = rng.normal(size=self.dim)\n                    yc = z @ A.T\n                    Xcand_list.append(m + sigma * yc)\n                    Z_list.append(yc)\n                Xcand = np.vstack(Xcand_list)[:lam_iter]\n                Zmat = np.vstack(Z_list)[:lam_iter]\n\n                # clamp candidates to bounds\n                Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n                # evaluate candidates\n                fc = np.empty(lam_iter, dtype=float)\n                for i in range(lam_iter):\n                    fc[i] = func(Xcand[i])\n                evals += lam_iter\n\n                # update run and global best\n                gen_best_idx = int(np.argmin(fc))\n                gen_best_f = float(fc[gen_best_idx])\n                gen_best_x = Xcand[gen_best_idx].copy()\n                improved = False\n                if gen_best_f < f_best:\n                    f_best = gen_best_f\n                    x_best = gen_best_x.copy()\n                    improved = True\n                    stagn_evals = 0\n                else:\n                    stagn_evals += lam_iter\n\n                # select elites and compute weighted mean (old m used here)\n                order = np.argsort(fc)\n                X_mu = Xcand[order[:mu_iter]]\n                y_steps = (X_mu - m) / (sigma + 1e-20)  # normalized steps\n                w_resh = w.reshape(-1, 1)\n                m_new = (w_resh * X_mu).sum(axis=0)\n\n                # rank-mu covariance in normalized coordinates\n                cov_mu = (w_resh * y_steps).T @ y_steps\n\n                # update evolution path (rank-1)\n                mu_eff = (np.sum(w)) ** 2 / np.sum(w ** 2)\n                c_p = 2.0 / (self.dim + 2.0)\n                y_w = (w_resh * y_steps).sum(axis=0)\n                p = (1.0 - c_p) * p + np.sqrt(c_p * (2.0 - c_p) * mu_eff) * y_w\n\n                # covariance update: mix rank-1 and rank-mu, shrink towards diagonal for stability\n                c1 = float(self.c1)\n                cmu = float(self.cmu)\n                coef_fix = max(0.0, 1.0 - c1 - cmu)\n                # small shrink to diagonal to avoid overfitting to few samples\n                shrink = 0.01\n                diag_shrink = shrink * np.diag(np.diag(C))\n                C = coef_fix * C + c1 * np.outer(p, p) + cmu * cov_mu + diag_shrink\n\n                # ensure symmetry\n                C = 0.5 * (C + C.T)\n\n                # update mean\n                m = m_new\n\n                # step-size adaptation: combine success-based and spread-based updates\n                # success-rate smoothing\n                p_succ = 0.85 * p_succ + 0.15 * float(improved)\n                # population spread (normalized RMS): compute with respect to new mean\n                y_all = (Xcand - m) / (sigma + 1e-20)\n                norm_rms = np.sqrt(np.mean(np.sum(y_all ** 2, axis=1)) / max(1.0, float(self.dim)))\n                # combine updates multiplicatively\n                sigma *= np.exp(self.alpha_succ * (p_succ - success_target) + self.alpha_spread * (0.35 - norm_rms))\n                # clip sigma reasonably\n                sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n                # SPD safeguard: numerical sanity\n                if np.any(np.isnan(C)) or np.any(np.isinf(C)):\n                    C = np.diag(((bounds_scale / 8.0) ** 2).clip(min=1e-12))\n                try:\n                    _ = np.linalg.cholesky(C + np.eye(self.dim) * 1e-16)\n                except np.linalg.LinAlgError:\n                    vals, vecs = np.linalg.eigh(C)\n                    vals = np.clip(vals, 1e-12, None)\n                    C = (vecs * vals) @ vecs.T\n\n                # occasional small uniform injection to diversify (1% chance each iteration)\n                if rng.rand() < 0.01 and evals < self.budget:\n                    inject = rng.uniform(lb, ub, size=self.dim)\n                    f_inj = func(inject)\n                    evals += 1\n                    if f_inj < f_best:\n                        f_best = float(f_inj)\n                        x_best = inject.copy()\n                        stagn_evals = 0\n                    else:\n                        stagn_evals += 1\n\n                # check local stagnation and decide to restart (IPOP-style)\n                if stagn_evals >= stagn_limit and evals < self.budget:\n                    # restart: increase population (IPOP), re-center near best with jitter, reset covariances\n                    restart_count += 1\n                    lam = min(max(2, lam * 2), max(2, self.budget))  # double population up to budget\n                    # re-center near global best with jitter proportional to sigma and bound range\n                    jitter = sigma * (0.5 + 0.5 * rng.rand(self.dim))\n                    m = x_best + rng.randn(self.dim) * jitter\n                    m = np.minimum(np.maximum(m, lb), ub)\n                    # reset covariance to moderate isotropic (smaller to encourage local search)\n                    C = np.diag(((bounds_scale / (6.0 + restart_count)) ** 2).clip(min=1e-12))\n                    sigma = min(sigma * 1.8, 1.0 * np.max(bounds_scale))\n                    p = np.zeros_like(p)\n                    stagn_evals = 0\n                    break  # break inner loop to start new run with larger lambda\n\n                # also break-run if we have exhausted budget (loop condition will handle)\n                # else continue generating batches\n\n            # continue outer restart loop (may exit if budget exhausted or max restarts reached)\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else None\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HMICPS scored 0.212 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "cebdb775-6824-4b44-af56-7c5277130528", "operator": null, "metadata": {"aucs": [0.12869346272176563, 0.1740138565412488, 0.2977559273969609, 0.18218688503864833, 0.14110748966756215, 0.3181735727367041, 0.24818624011958434, 0.24923942874508653, 0.23138886975882977, 0.1479114709087226]}, "task_prompt": ""}
{"id": "f583b32a-800e-4699-83ca-44e9e939d2d3", "fitness": 0.10775603834341126, "name": "LevyDACS", "description": "LevyDACS is a compact covariance-adaptive sampler that starts from a quasi‑uniform stratified initialization (small population size lam computed from dim) with a moderate sigma (0.25*avg_span) and diagonal covariance to give broad initial coverage. It uses rank‑mu weighted recombination to update a robust mean and a conservative covariance learning rate (cov_update=0.20) blended with an isotropic floor, enforcing SPD via Cholesky/eigendecomposition for numerical stability. A small elite archive (3–8) of best points seeds heavy‑tailed Cauchy/Levy jumps (adaptive jump_prob) to drive global, long‑range exploration, while periodic budget‑aware Hooke–Jeeves coordinate pattern searches (local_budget_frac, local_period) around the best point provide local intensification and archive updates. Safety measures and diversification include reflection+clamp bound handling, occasional uniform injections, sigma adaptation via a smoothed success rate (sigma_adapt_rate=0.2), adaptive jump probability based on archive diversity, and opportunistic restarts when stagnation or sigma collapse is detected.", "code": "import numpy as np\n\nclass LevyDACS:\n    \"\"\"\n    LevyDACS: Compact covariance-adaptive sampler (DACS style) augmented with:\n      - quasi-uniform stratified initialization,\n      - a small elite archive to seed adaptive Levy-like global jumps,\n      - budget-aware Hooke-Jeeves coordinate pattern local searches for intensification,\n      - reflection+clamp bound handling, occasional uniform injections, and adaptive jump probability.\n    One-line: Compact covariance search with archive-seeded Levy jumps and Hooke–Jeeves intensification.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 cov_update=0.20,\n                 sigma_adapt_rate=0.2,\n                 local_budget_frac=0.035,\n                 local_period=18,\n                 jump_prob_init=0.20,\n                 archive_size=None,\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.cov_update = float(cov_update)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.local_budget_frac = float(local_budget_frac)\n        self.local_period = int(local_period)\n        self.jump_prob = float(jump_prob_init)\n        self.archive_size = archive_size\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds handling: support scalar or per-dim\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = ub - lb\n        avg_span = float(np.mean(bounds_scale))\n\n        # population size similar to DACS but small/compact\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # quasi-uniform initialization (stratified per-dim)\n        pop0 = min(lam, max(4, int(lam)))\n        X0 = np.empty((pop0, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop0)\n            strata = (np.arange(pop0) + 0.5) / max(1, pop0)\n            X0[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # small jitter\n        X0 += (rng.rand(pop0, self.dim) - 0.5) * (0.3 * bounds_scale / max(1.0, self.dim))\n        X0 = np.minimum(np.maximum(X0, lb), ub)\n\n        evals = 0\n        f0 = np.empty(pop0, dtype=float)\n        for i in range(pop0):\n            if evals >= self.budget:\n                f0[i:] = np.inf\n                break\n            f0[i] = float(func(X0[i]))\n            evals += 1\n\n        # fallback if no evals succeeded\n        if evals == 0:\n            self.f_opt = np.inf\n            self.x_opt = np.zeros(self.dim, dtype=float)\n            return self.f_opt, self.x_opt\n\n        # track best\n        bi = int(np.argmin(f0[:min(evals, pop0)]))\n        f_best = float(f0[bi])\n        x_best = X0[bi].copy()\n\n        # initialize mean m from top-half\n        mu = max(1, pop0 // 2)\n        order0 = np.argsort(f0[:pop0])\n        elites0 = X0[order0[:mu]]\n        weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n        weights = np.maximum(weights, 0.0)\n        if np.sum(weights) <= 0:\n            weights = np.ones(mu) / mu\n        else:\n            weights = weights / np.sum(weights)\n        m = (weights.reshape(-1,1) * elites0).sum(axis=0)\n\n        # covariance and sigma initialization (moderate)\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-12, 0.25 * np.mean(bounds_scale))\n\n        # archive initialization\n        if self.archive_size is None:\n            archive_k = max(3, min(8, pop0 // 2))\n        else:\n            archive_k = max(1, int(self.archive_size))\n        archive = []  # list of (f, x) sorted ascending by f\n        # insert initial evaluated points into archive\n        for xi, fi in zip(X0, f0):\n            archive.append((float(fi), xi.copy()))\n        archive.sort(key=lambda t: t[0])\n        # trim\n        archive = archive[:archive_k]\n        # ensure best present\n        if len(archive) == 0 and x_best is not None:\n            archive.append((f_best, x_best.copy()))\n\n        # helper: reflect then clamp bounds\n        def reflect_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        # local Hooke-Jeeves coordinate pattern search (budget-limited)\n        def hooke_jeeves(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            step0 = max(1e-12, 0.18 * avg_span)\n            steps = np.full(self.dim, step0, dtype=float)\n            local_evals = 0\n            # iterate until budget for local search exhausted or steps too small\n            while local_evals < local_budget and np.any(steps > 1e-6 * avg_span) and evals < self.budget:\n                improved = False\n                x_probe = base.copy()\n                x_probe_f = base_f\n                for i in range(self.dim):\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    # plus\n                    xp = x_probe.copy()\n                    xp[i] = min(ub[i], xp[i] + steps[i])\n                    xp = reflect_clamp(xp)\n                    fv = float(func(xp))\n                    evals += 1\n                    local_evals += 1\n                    if fv < x_probe_f:\n                        x_probe = xp.copy()\n                        x_probe_f = fv\n                        improved = True\n                        # update best/ archive\n                        if fv < f_best:\n                            f_best = fv\n                            x_best = xp.copy()\n                            # insert into archive\n                            archive.append((fv, xp.copy()))\n                            archive.sort(key=lambda t: t[0])\n                            if len(archive) > archive_k:\n                                archive.pop()\n                        continue\n                    # minus\n                    xn = x_probe.copy()\n                    xn[i] = max(lb[i], xn[i] - steps[i])\n                    xn = reflect_clamp(xn)\n                    fv2 = float(func(xn))\n                    evals += 1\n                    local_evals += 1\n                    if fv2 < x_probe_f:\n                        x_probe = xn.copy()\n                        x_probe_f = fv2\n                        improved = True\n                        if fv2 < f_best:\n                            f_best = fv2\n                            x_best = xn.copy()\n                            archive.append((fv2, xn.copy()))\n                            archive.sort(key=lambda t: t[0])\n                            if len(archive) > archive_k:\n                                archive.pop()\n                # pattern move\n                if improved and local_evals < local_budget and evals < self.budget:\n                    direction = x_probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + 1.5 * direction\n                        xp = reflect_clamp(xp)\n                        fv = float(func(xp))\n                        evals += 1\n                        local_evals += 1\n                        if fv < x_probe_f:\n                            base = xp.copy()\n                            base_f = fv\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = xp.copy()\n                                archive.append((fv, xp.copy()))\n                                archive.sort(key=lambda t: t[0])\n                                if len(archive) > archive_k:\n                                    archive.pop()\n                        else:\n                            base = x_probe.copy()\n                            base_f = x_probe_f\n                    else:\n                        base = x_probe.copy()\n                        base_f = x_probe_f\n                else:\n                    steps *= 0.6\n                # break if budget done\n            return base_f, base\n\n        # heavy-tailed global jump from an archive center (Cauchy-like)\n        def levy_jump(center, scale_factor=0.2):\n            direction = rng.randn(self.dim)\n            nrm = np.linalg.norm(direction) + 1e-12\n            direction /= nrm\n            step_length = rng.standard_cauchy()\n            step_length = np.clip(step_length, -1e3, 1e3)\n            step = direction * (scale_factor * avg_span * (0.3 + 0.7 * rng.rand()))\n            return center + step_length * step\n\n        # main loop\n        iter_count = 0\n        p_succ = 0.2  # smoothed success rate\n        stagn_count = 0\n        local_counter = 0\n\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu_iter = max(1, lam_iter // 2)\n\n            # ensure C is SPD and get Cholesky A\n            eps = 1e-12 * np.maximum(np.diag(C), 1.0)\n            try:\n                A = np.linalg.cholesky(C + np.diag(eps))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n\n            # sample lam_iter candidates from N(m, sigma^2 C)\n            Z = rng.normal(size=(lam_iter, self.dim))\n            Y = Z @ (A.T)\n            Xcand = m + sigma * Y\n            # clamp\n            for i in range(Xcand.shape[0]):\n                Xcand[i] = np.minimum(np.maximum(Xcand[i], lb), ub)\n\n            # occasionally insert a Levy-seeded candidate based on archive\n            if len(archive) > 0 and rng.rand() < self.jump_prob and evals < self.budget:\n                # choose center probabilistically favoring best\n                if rng.rand() < 0.75:\n                    center = archive[0][1]\n                else:\n                    center = archive[rng.randint(0, len(archive))][1]\n                cand = levy_jump(center, scale_factor=max(0.06, 0.15 * (1.0 - float(iter_count) / max(10.0, 200.0))))\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                # replace a random candidate to evaluate it\n                replace_idx = rng.randint(0, Xcand.shape[0])\n                Xcand[replace_idx] = cand\n\n            # evaluate candidates (one by one)\n            fc = np.empty(Xcand.shape[0], dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    fc[i:] = np.inf\n                    break\n                xi = Xcand[i]\n                fc[i] = float(func(xi))\n                evals += 1\n                # update best and archive on the fly\n                if fc[i] < f_best:\n                    f_best = float(fc[i])\n                    x_best = xi.copy()\n                    archive.append((f_best, x_best.copy()))\n                    archive.sort(key=lambda t: t[0])\n                    if len(archive) > archive_k:\n                        archive.pop()\n                    stagn_count = 0\n                # safety: keep archive trimmed to best\n                if len(archive) > archive_k:\n                    archive = archive[:archive_k]\n\n            # select elites and update mean, covariance (rank-mu style)\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu_iter]]\n            weights_mu = np.log(mu_iter + 0.5) - np.log(np.arange(1, mu_iter + 1))\n            weights_mu = np.maximum(weights_mu, 0.0)\n            if np.sum(weights_mu) <= 0:\n                weights_mu = np.ones(mu_iter) / mu_iter\n            else:\n                weights_mu = weights_mu / np.sum(weights_mu)\n            m_new = (weights_mu.reshape(-1,1) * X_mu).sum(axis=0)\n\n            # normalized steps for covariance update\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            W = weights_mu.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas\n\n            # small rank-1 boost towards best step (if improvement)\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = gen_best_f < f_best + 1e-12  # note: f_best updated earlier, so many cases false\n\n            # update covariance C with conservative learning rate\n            c_cov = float(self.cov_update)\n            # blend with tiny isotropic floor to avoid collapse\n            iso = np.diag(((bounds_scale / 12.0) ** 2).clip(min=1e-12))\n            C = (1.0 - c_cov) * C + c_cov * (0.85 * weighted_cov + 0.15 * iso)\n            # ensure symmetry and SPD\n            C = 0.5 * (C + C.T)\n            vals, vecs = np.linalg.eigh(C)\n            vals = np.clip(vals, 1e-12, None)\n            C = (vecs * vals) @ vecs.T\n\n            # accept new mean and softly blend to avoid abrupt moves\n            m = 0.85 * m + 0.15 * m_new\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # success definition for sigma adaptation: any candidate improved global best\n            # (we already updated f_best during evals), so check if gen_best improved earlier than when recorded\n            # we approximate success by whether gen_best is better than the previous m (using archive closest)\n            # fallback: use whether any candidate equals current f_best (cheap)\n            # compute success flag: any fc < previous_m_f where previous_m_f approximated by nearest archive point to m_old\n            # approximate previous m value by closest archived point\n            if len(archive) > 0:\n                Xh = np.array([a[1] for a in archive])\n                dists = np.sum((Xh - m) ** 2, axis=1)\n                prev_m_f = archive[int(np.argmin(dists))][0]\n            else:\n                prev_m_f = f_best\n            # success if we found strictly better than prev_m_f\n            success_flag = np.any(fc < (prev_m_f - 1e-12))\n            # smooth success rate\n            p_succ = 0.9 * p_succ + 0.1 * float(success_flag)\n            success_target = 0.2\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - success_target))\n            sigma = float(np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale)))\n\n            # adapt jump probability based on archive diversity\n            if len(archive) >= 2:\n                diversity = np.linalg.norm(archive[0][1] - archive[-1][1])\n                if diversity < 0.01 * avg_span + 1e-12:\n                    self.jump_prob = min(0.65, self.jump_prob + 0.03)\n                else:\n                    self.jump_prob = max(0.03, self.jump_prob * 0.995)\n\n            # periodic local intensification: Hooke-Jeeves around best\n            local_counter += 1\n            if (local_counter % self.local_period == 0 or stagn_count * lam_iter >= int(0.02 * self.budget)) and evals < self.budget:\n                # allocate local budget conservatively\n                alloc = min(int(self.local_budget_frac * self.budget), self.budget - evals)\n                if stagn_count * lam_iter >= int(0.02 * self.budget):\n                    alloc = min(self.budget - evals, max(1, alloc * 2))\n                if alloc > 0:\n                    f_after, x_after = hooke_jeeves(x_best, f_best, alloc)\n                    # inject improvements\n                    if f_after < f_best:\n                        # replace worst by local result\n                        f_best = f_after\n                        x_best = x_after.copy()\n                        # replace worst in archive if better\n                        archive.append((f_after, x_after.copy()))\n                        archive.sort(key=lambda t: t[0])\n                        if len(archive) > archive_k:\n                            archive.pop()\n                        # nudge mean toward local best\n                        m = 0.8 * m + 0.2 * x_after\n                        stagn_count = 0\n                    else:\n                        stagn_count += 1\n\n            # occasional uniform injection to maintain diversity\n            if (iter_count % 23) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                fu = float(func(xu))\n                evals += 1\n                # replace worst archive/population if useful\n                if fu < f_best:\n                    f_best = fu\n                    x_best = xu.copy()\n                archive.append((fu, xu.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n\n            # opportunistic restart if stagnation prolonged or sigma collapsed\n            if (stagn_count * lam_iter >= int(0.15 * self.budget)) or sigma <= 1e-12:\n                stagn_count = 0\n                # inflate sigma and reinitialize m near best with jitter\n                sigma = max(sigma, 0.5 * np.mean(bounds_scale))\n                jitter = sigma * (0.2 + 0.8 * rng.rand(self.dim))\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                # reduce jump_prob temporarily to focus local\n                self.jump_prob = max(0.03, self.jump_prob * 0.5)\n                continue\n\n            # update stagn_count conservatively\n            if not success_flag:\n                stagn_count += 1\n            else:\n                stagn_count = 0\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm LevyDACS scored 0.108 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "cebdb775-6824-4b44-af56-7c5277130528", "operator": null, "metadata": {"aucs": [0.1496771703940224, 0.1735909446362114, 0]}, "task_prompt": ""}
{"id": "ab6afe0d-0bde-4d10-b826-cc3e4f5b876d", "fitness": "-inf", "name": "AMGRE", "description": "AMGRE maintains a Gaussian search distribution (mean m, global step-size sigma) augmented by a learned rotation matrix R and per-coordinate scales s to adapt anisotropic, rotated landscapes, with population size and archive length scaled modestly with dimension (pop_base ~ O(log dim), arch_size ~ O(dim)). It builds a weighted local linear surrogate from a recent FIFO archive to extract a pseudo-gradient for directed line probes, while also generating rotated-Gaussian samples and archive recombinations to balance exploration and exploitation. The algorithm incrementally updates R using cheap, small Givens-plane rotations (with occasional QR re-orthonormalization), smooths per-coordinate scales with EMA (momentum_beta = 0.7), adapts sigma multiplicatively based on a smoothed success rate (sigma_adapt_rate = 0.3, succ_target = 0.2), and allows simulated-annealing-style uphill acceptance for escape. Opportunistic restarts, bounds-aware initialization, clipping of scales, and modest temperature decay provide robustness against stagnation and numerical issues.", "code": "import numpy as np\n\nclass AMGRE:\n    \"\"\"\n    Adaptive Memory-Guided Rotational Explorer (AMGRE)\n\n    Summary of novel mechanisms:\n    - Maintains a mean m, a global step-size sigma, a learned rotation matrix R (axis rotation\n      basis) and per-coordinate scaling s.\n    - Keeps an archive of recent evaluated points and uses a weighted linear regression\n      on the archive to obtain a local pseudo-gradient for directional proposals.\n    - Learns small Givens-plane rotations to align sampling axes to consistently successful\n      step directions (cheap low-rank rotation updates).\n    - Produces three types of proposals each generation: rotated-Gaussian samples, gradient-\n      guided line probes, and archive recombinations. Uses a simulated-annealing style\n      acceptance probability to allow occasional uphill moves for escaping traps.\n    - Step-size and per-coordinate scales adapt with success statistics (multiplicative\n      sigma updates and EMA on coordinate magnitudes). Opportunistic restart if stagnated.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # hyperparameters (tunable)\n        self.pop_base = max(6, int(4 + 1.5 * np.log(max(2, dim))))  # baseline population\n        self.arch_size = max(20, 4 * dim)         # archive length for local linear model\n        self.succ_target = 0.2                    # target success rate for sigma adapt\n        self.sigma_adapt_rate = 0.3               # multiplicative adaptation exponent factor\n        self.rotation_rate = 0.12                 # magnitude for incremental Givens rotations\n        self.momentum_beta = 0.7                  # EMA for per-coordinate scale\n        self.coord_scale_clip = (0.1, 6.0)\n        self.min_sigma = 1e-10\n        self.max_sigma_scale = 2.5\n        self.temp_start = 1.0                     # simulated annealing starting temperature\n        self.temp_end = 1e-3\n        self.temp_decay = 0.995                   # per-generation multiplicative decay\n        self.stagnation_frac = 0.05               # fraction of budget to detect stagnation\n        self.restart_inflate = 1.6\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # Bounds (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # initial mean and scale from bounds\n        bounds_scale = (ub - lb)\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(1e-8, 0.15 * np.mean(bounds_scale))\n        # rotation matrix starts identity\n        R = np.eye(self.dim)\n        # per-coordinate multiplicative scales in rotated space\n        s = np.ones(self.dim)\n        # archive of evaluated points (FIFO)\n        X_arch = []\n        f_arch = []\n\n        # seed with an initial random population (small)\n        evals = 0\n        init_pop = min(self.pop_base, max(6, self.budget // 50))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(f)\n\n        # ensure we always have at least one evaluated point\n        if len(f_arch) == 0:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(f)\n\n        # best so far\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # smoothed success rate and temperature\n        p_succ = 0.2\n        T = float(self.temp_start)\n\n        # stagnation detection\n        stagn_count = 0\n        stagn_limit = max(5, int(self.stagnation_frac * self.budget))\n\n        # main loop\n        gen = 0\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            lam = max(1, lam)\n\n            # compute weighted local linear surrogate (pseudo-gradient) if archive has enough points\n            grad = None\n            if len(X_arch) >= 3:\n                # use the most recent entries and ones near m (by distance)\n                X_arr = np.asarray(X_arch)\n                f_arr = np.asarray(f_arch)\n                # center data at m to fit local linear model f ≈ a + g·(x-m)\n                Xc = X_arr - m.reshape(1, -1)\n                dnorm = np.linalg.norm(Xc / (sigma + 1e-20), axis=1)\n                # weights favor nearby points and better objective values\n                w_dist = np.exp(-0.6 * dnorm)\n                w_rank = np.exp(-0.8 * (f_arr - np.min(f_arr)) / (np.ptp(f_arr) + 1e-12))\n                w = w_dist * (0.6 * w_rank + 0.4)\n                W = np.sqrt(w).reshape(-1, 1)\n                # solve ridge regression for gradient estimate: minimize ||W*(Xc g - (f - f0))||^2 + lambda ||g||^2\n                y = (f_arr - f_best)  # relative residual to best (f_best acts as anchor)\n                # regularization\n                reg = 1e-6 * np.eye(self.dim)\n                try:\n                    A = (W * Xc).T @ (W * Xc) + reg\n                    b = (W * Xc).T @ (W * y)\n                    g_est = np.linalg.solve(A, b)\n                    grad = g_est\n                except np.linalg.LinAlgError:\n                    grad = None\n\n            # generate candidates\n            candidates = []\n            gen_types = []  # track type for update rules\n            # 1) rotated Gaussian samples (majority)\n            n_gauss = max(1, int(0.7 * lam))\n            # sample in rotated coordinates, apply per-coordinate scales s, then transform back\n            Z = rng.normal(size=(n_gauss, self.dim))\n            Z = Z * s.reshape(1, -1)  # coordinate-wise modulation\n            Xg = m.reshape(1, -1) + sigma * (Z @ R.T)\n            candidates.extend(Xg.tolist())\n            gen_types.extend(['gauss'] * Xg.shape[0])\n\n            # 2) gradient-guided probes (if we have grad)\n            if grad is not None and remaining - len(candidates) > 0:\n                # take a step opposite to gradient (minimization)\n                gnorm = np.linalg.norm(grad) + 1e-20\n                step_len = sigma * min(3.0, 1.5 * (sigma / (np.mean(bounds_scale) + 1e-20)))  # scaled probe length\n                x_dir = m - (step_len * (grad / gnorm))\n                # include a bracket/line samples around this point\n                candidates.append(x_dir)\n                gen_types.append('grad_probe')\n\n                # also propose a longer exploratory probe in same direction\n                x_dir2 = m - 2.2 * (step_len * (grad / gnorm))\n                candidates.append(x_dir2)\n                gen_types.append('grad_probe')\n\n            # 3) recombination from archive (differential/crossover style)\n            n_recomb = lam - len(candidates)\n            for _ in range(n_recomb):\n                # select two archive points biased by fitness\n                if len(X_arch) >= 2:\n                    idx = rng.choice(len(X_arch), size=2, replace=False, p=None)\n                    a = X_arch[idx[0]]\n                    b = X_arch[idx[1]]\n                    alpha = rng.rand()\n                    xrec = alpha * a + (1 - alpha) * b\n                    # add small directional noise in rotated space\n                    z = rng.normal(scale=0.7, size=self.dim) * s\n                    xrec = xrec + 0.6 * sigma * (z @ R.T)\n                    candidates.append(xrec)\n                    gen_types.append('recomb')\n                else:\n                    # fallback random\n                    xrand = rng.uniform(lb, ub, size=self.dim)\n                    candidates.append(xrand)\n                    gen_types.append('recomb')\n\n            # clamp candidates to bounds and ensure not to exceed budget when evaluating\n            Xcand = np.asarray([np.minimum(np.maximum(np.array(x), lb), ub) for x in candidates])\n            # Evaluate sequentially until budget\n            fc = np.full(Xcand.shape[0], np.inf)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                x = Xcand[i]\n                # optional tiny jitter for numerical variety (no extra budget)\n                fc[i] = float(func(x))\n                evals += 1\n\n                # update archive incrementally (FIFO)\n                X_arch.append(x.copy())\n                f_arch.append(fc[i])\n                if len(X_arch) > self.arch_size:\n                    del X_arch[0]\n                    del f_arch[0]\n\n                # update global best immediately if improved\n                if fc[i] < f_best:\n                    f_best = float(fc[i])\n                    x_best = x.copy()\n                    stagn_count = 0\n                else:\n                    stagn_count += 1\n\n            # truncate arrays in case of budget cut\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n\n            if fc.size == 0:\n                break\n\n            # selection: pick the best candidate in this generation\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_x = Xcand[gen_best_idx].copy()\n            gen_best_f = float(fc[gen_best_idx])\n            improved = gen_best_f < f_best  # note: f_best was already updated in incremental loop, but keep for local success\n\n            # compute per-candidate normalized steps in rotated space for update statistics\n            # normalized step u = R*(x - m)/sigma in rotated coordinates\n            deltas_rot = ((Xcand - m.reshape(1, -1)) / (sigma + 1e-20)) @ R.T  # shape (pop, dim)\n\n            # compute success indicators per candidate (improvement relative to current m estimate)\n            # treat candidate improving global best as success\n            successes = (fc < f_best + 1e-16).astype(float)\n\n            # update acceptance: we move mean m towards good samples with probabilistic acceptance\n            # choose a \"parent\" candidate to influence mean: sample among evaluated candidates weighted by fitness\n            # weights inversely proportional to f (shifted)\n            fshift = fc - np.min(fc) + 1e-12\n            invw = 1.0 / fshift\n            probs = invw / np.sum(invw)\n            chosen_idx = rng.choice(len(Xcand), p=probs)\n            chosen_x = Xcand[chosen_idx]\n            chosen_f = fc[chosen_idx]\n            # acceptance probability for uphill moves\n            delta_f = chosen_f - np.min([f_best, np.min(fc)])\n            if chosen_f <= f_best or rng.rand() < np.exp(-max(0.0, delta_f) / (T + 1e-12)):\n                # accept: move mean towards chosen_x\n                eta = 0.25 if chosen_f < f_best else 0.12  # stronger pull if actually improving\n                m = (1.0 - eta) * m + eta * chosen_x\n            else:\n                # weak exploration: small random shift\n                m = m + 0.05 * sigma * (rng.randn(self.dim) @ R.T)\n\n            # update per-coordinate scales (EMA of absolute rotated steps)\n            stat = np.mean(np.abs(deltas_rot), axis=0)\n            s = self.momentum_beta * s + (1.0 - self.momentum_beta) * (stat + 1e-12)\n            s = np.clip(s, self.coord_scale_clip[0], self.coord_scale_clip[1])\n\n            # update rotation matrix R using small Givens rotations from successful normalized steps\n            # For each successful (or best) candidate, align the basis to its dominant rotated coordinates\n            # Use cheap plane rotations: pick top-2 coordinates in magnitude in deltas_rot[chosen_idx]\n            try:\n                for idx_try in [chosen_idx, gen_best_idx]:\n                    if 0 <= idx_try < deltas_rot.shape[0]:\n                        u = deltas_rot[idx_try]\n                        if np.linalg.norm(u) > 1e-12:\n                            # find two largest coordinates by absolute value\n                            p, q = np.argsort(np.abs(u))[-2:]\n                            if p != q:\n                                # compute small rotation to increase alignment of R's p-th axis toward u\n                                # project current axis onto the plane\n                                a = R[:, p].copy()\n                                b = R[:, q].copy()\n                                # compute components of u in the current basis columns p and q\n                                up = np.dot(u, R.T[p])\n                                uq = np.dot(u, R.T[q])\n                                # desired angle to rotate q towards p proportional to sign(uq)\n                                theta = self.rotation_rate * (uq / (abs(up) + abs(uq) + 1e-12))\n                                # build Givens rotation in (p,q) plane\n                                c = np.cos(theta)\n                                srot = np.sin(theta)\n                                G = np.eye(self.dim)\n                                G[[p, p, q, q], [p, q, p, q]] = [c, -srot, srot, c]\n                                # update R <- R @ G (rotate columns)\n                                R = R @ G\n                                # re-orthonormalize occasionally, cheaply via QR for stability\n                                if (gen % 31) == 0:\n                                    try:\n                                        Q, _ = np.linalg.qr(R)\n                                        R = Q\n                                    except np.linalg.LinAlgError:\n                                        R = np.eye(self.dim)\n            except Exception:\n                # any rotation numerical problem revert to identity (robust fallback)\n                R = np.eye(self.dim)\n\n            # sigma adaptation via smoothed success rate of this generation\n            # success means any candidate improved the stored best (global)\n            gen_success = float(np.any(fc < f_best + 1e-16))\n            # update smoothed success probability\n            p_succ = 0.9 * p_succ + 0.1 * gen_success\n            # multiplicative update\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, self.min_sigma, self.max_sigma_scale * np.max(bounds_scale))\n\n            # temperature decay\n            T = max(self.temp_end, T * (self.temp_decay ** 1.0))\n\n            # opportunistic restart if stagnation\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # restart around current best with some jitter\n                jitter = max(0.05 * np.mean(bounds_scale), 0.5 * sigma)\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reinitialize rotation and scales\n                R = np.eye(self.dim)\n                s = np.ones(self.dim)\n                sigma = max(sigma * self.restart_inflate, 0.2 * np.mean(bounds_scale))\n                # clear part of archive to encourage new exploration\n                keep = max(1, len(X_arch) // 4)\n                X_arch = X_arch[-keep:]\n                f_arch = f_arch[-keep:]\n                # small temperature bump to encourage exploration\n                T = min(1.0, T * 2.0)\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 149, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x_dir = m - (step_len * (grad / gnorm))", "error": "In the code, line 149, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x_dir = m - (step_len * (grad / gnorm))", "parent_ids": "51281bd0-71d4-4c04-ae61-5338826a446f", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "1633aea6-26bf-4162-bb84-405f13c3940c", "fitness": 0.1819980737047667, "name": "DHT_ACS", "description": "This algorithm is a CMA-like directional search that blends momentum and per-coordinate scaling with antithetic correlated sampling and occasional heavy-tailed (Cauchy) jumps to combine steady local adaptation and rare large escapes. Covariance/mean choices favor a larger rank-mu learning rate (cov_update=0.25) and a much smaller rank-one weight (rank1=0.03), while the mean is conservatively blended toward the recombined candidate (mean_lr=0.35) and momentum v is smoothed with mom_beta=0.6 to provide directional bias. Step-size and coordinate adaptation use an EMA of absolute normalized steps (s_diag_beta=0.4, s_diag clipped to [0.15,6]) and an aggressive multiplicative sigma update (sigma_adapt_rate=0.5) targeting a higher success probability (success_target=0.3), plus periodic Cauchy jumps (heavy_tail_period=12, scale≈0.7·sigma) to escape plateaus. The design also includes bounds-aware initialization and isotropic C aligned to bounds, antithetic sampling for variance reduction, partial re-seeding restarts on stagnation (replace subset of dims with jitter, anneal C and sigma), and numeric safeguards (shrinkage, clipping, eigen-fix) to maintain SPD covariance and stable search.", "code": "import numpy as np\n\nclass DHT_ACS:\n    \"\"\"\n    Directional Heavy-Tailed Adaptive Covariance Search (DHT-ACS)\n\n    Key differences vs typical MCAS-like samplers:\n    - Different hyperparameter choices and update equations (see __init__ defaults).\n    - Mean updated by a conservative learning-rate blend (instead of full replace).\n    - Covariance uses a slightly larger rank-mu weight and smaller rank-one weight.\n    - Per-coordinate scale adapts from EMA of absolute normalized steps (not sqrt of squared).\n    - Step-size (sigma) adaptation uses a more aggressive multiplicative rule and a higher success target.\n    - Occasional heavy-tailed (Cauchy) jumps to escape flat regions.\n    - Restart/shrinking strategy different: partial re-seeding and sigma annealing.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, pop_base=None, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        # algorithm hyperparameters (intentionally different from the provided MCAS)\n        self.cov_update = 0.25         # rank-mu learning rate (bigger)\n        self.rank1 = 0.03              # rank-one momentum outer-product (smaller)\n        self.mom_beta = 0.6            # momentum smoothing (different)\n        self.s_diag_beta = 0.4         # EMA for per-coordinate absolute steps (different)\n        self.sigma_adapt_rate = 0.5    # multiplicative update aggressiveness (bigger)\n        self.success_target = 0.3      # target success probability (higher than 0.2)\n        self.p_succ_beta = 0.8         # smoothing for success prob\n        self.min_sigma = 1e-12\n        self.max_sigma_scale = 3.0\n        self.heavy_tail_period = 12    # every such iterations try a Cauchy jump\n        self.mean_lr = 0.35            # learning rate for mean blending (conservative mean update)\n        self.stagnation_frac = 0.03    # different stagnation fraction\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds support (scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # adaptive base population size (different heuristic)\n        if self.pop_base is None:\n            lam0 = max(6, int(4 + int(2.0 * np.sqrt(max(1, self.dim)))))\n        else:\n            lam0 = int(self.pop_base)\n        lam0 = min(lam0, max(2, self.budget))\n\n        evals = 0\n        # initial pool to set mean and baseline\n        init_batch = min(lam0, max(4, int(0.05 * self.budget)))  # take a slightly larger initial pool if budget allows\n        init_batch = min(init_batch, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        best_idx = np.argmin(f0)\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # robust initial mean: weighted average of top half but retain the original centeredness by blending later\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 = w0 / np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initialize covariance isotropic aligned to bounds (different scale)\n        bounds_scale = (ub - lb)\n        C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.25 * np.mean(bounds_scale))  # different initial sigma\n\n        # directional momentum and per-coordinate scale\n        v = np.zeros(self.dim, dtype=float)\n        s_diag = np.ones(self.dim, dtype=float)\n        p_succ = 0.25  # initial success prob guess\n        stagn_iter = 0\n        stagnation_threshold = max(6, int(self.stagnation_frac * self.budget))\n        iter_count = 0\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam = min(lam0, remaining)\n            lam = max(2 if remaining >= 2 else 1, lam)\n\n            mu = max(1, lam // 2)\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n            W = weights.reshape(-1, 1)\n\n            # ensure SPD covariance\n            eps_diag = 1e-12 * np.maximum(np.diag(C), 1.0)\n            try:\n                A = np.linalg.cholesky(C + np.diag(eps_diag))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n\n            # antithetic sampling for variance reduction\n            half = lam // 2\n            Zpos = rng.normal(size=(half, self.dim))\n            Z = np.vstack([Zpos, -Zpos])\n            if lam % 2 == 1:\n                Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n\n            Y = Z @ A.T  # correlated samples in normalized coords\n\n            # incorporate directional momentum but with a different blending: multiply by s_diag and add small tilt\n            vlen = np.linalg.norm(v) + 1e-20\n            if vlen > 0:\n                v_unit = v / vlen\n                dir_strength = 0.6 * (vlen / (1.0 + vlen))  # different factor\n            else:\n                v_unit = np.zeros_like(v)\n                dir_strength = 0.0\n            s_scalar = rng.normal(scale=dir_strength, size=(Y.shape[0], 1))\n            Y = Y + (s_scalar * v_unit.reshape(1, -1))\n\n            # apply coordinate scaling (multiplicative)\n            Y = Y * s_diag.reshape(1, -1)\n\n            # occasionally perform a heavy-tailed additive jump (Cauchy) to escape plateaus\n            if (iter_count % self.heavy_tail_period == 0) and (rng.rand() < 0.5):\n                cauchy_scale = 0.7 * sigma\n                jumps = rng.standard_cauchy(size=(Y.shape[0], self.dim)) * cauchy_scale\n                # clamp large Cauchy values to keep reasonable proposals\n                jumps = np.clip(jumps, -5.0 * np.mean(bounds_scale), 5.0 * np.mean(bounds_scale))\n                Y = Y + jumps / max(1.0, np.linalg.norm(jumps, axis=1).mean())\n\n            Xcand = m + sigma * Y\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            lam_actual = Xcand.shape[0]\n            fc = np.full(lam_actual, np.inf, dtype=float)\n            for i in range(lam_actual):\n                if evals >= self.budget:\n                    break\n                fc[i] = func(Xcand[i])\n                evals += 1\n\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                lam_actual = fc.shape[0]\n                if lam_actual == 0:\n                    break\n\n            gen_best_idx = np.argmin(fc)\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_iter = 0\n            else:\n                stagn_iter += 1\n\n            # elites\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            # compute a candidate new mean as weighted recombination\n            if X_mu.shape[0] > 0:\n                mu_eff = X_mu.shape[0]\n                if mu_eff != mu:\n                    w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if np.sum(w_eff) <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff = w_eff / np.sum(w_eff)\n                    W_eff = w_eff.reshape(-1, 1)\n                    m_cand = (W_eff * X_mu).sum(axis=0)\n                else:\n                    m_cand = (W * X_mu).sum(axis=0)\n            else:\n                m_cand = m.copy()\n\n            # normalized deltas in sample coords\n            deltas = (X_mu - m) / (sigma + 1e-20) if X_mu.shape[0] > 0 else np.zeros((0, self.dim))\n\n            # weighted covariance in normalized coords (with small shrinkage)\n            if deltas.shape[0] > 0:\n                if deltas.shape[0] != mu:\n                    mu_eff = deltas.shape[0]\n                    w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if np.sum(w_eff) <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff = w_eff / np.sum(w_eff)\n                    Wd = w_eff.reshape(-1, 1)\n                    weighted_cov = (deltas * Wd).T @ deltas\n                    delta_mean = (Wd * deltas).sum(axis=0)\n                else:\n                    weighted_cov = (deltas * W).T @ deltas\n                    delta_mean = (W * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # update momentum (different smoothing)\n            v = self.mom_beta * v + (1.0 - self.mom_beta) * delta_mean\n\n            # rank-one from momentum\n            rank_one = np.outer(v, v)\n\n            # covariance mix with slight shrinkage towards isotropic to keep numerical stability\n            c_cov = float(self.cov_update)\n            c1 = float(self.rank1)\n            shrink = 1e-6 * np.eye(self.dim)\n            C = (1.0 - c_cov - c1) * C + c_cov * (weighted_cov + 1e-8 * np.diag(np.ones(self.dim))) + c1 * rank_one\n            C = 0.5 * (C + C.T) + shrink\n\n            # per-coordinate adaptation: EMA of absolute normalized steps (different aggregator)\n            if deltas.shape[0] > 0:\n                stat = np.mean(np.abs(deltas), axis=0)\n            else:\n                stat = 1e-6 * np.ones(self.dim)\n            s_diag = (self.s_diag_beta * s_diag +\n                      (1.0 - self.s_diag_beta) * (stat + 1e-20))\n            s_diag = np.clip(s_diag, 0.15, 6.0)\n\n            # conservative mean update (blend old mean toward recombined candidate)\n            m = (1.0 - self.mean_lr) * m + self.mean_lr * m_cand\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # success rate update and sigma adaptation (different smoothing and target)\n            p_succ = self.p_succ_beta * p_succ + (1.0 - self.p_succ_beta) * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, self.min_sigma, self.max_sigma_scale * np.max(bounds_scale))\n\n            # partial re-seeding restart when stagnating: re-seed fraction of mean values\n            if stagn_iter >= stagnation_threshold and evals < self.budget:\n                stagn_iter = 0\n                # replace a random subset of dimensions in m with best-known coords plus jitter\n                frac = min(0.6, 1.0 * (1.0 - (evals / max(1, self.budget))))\n                k = max(1, int(self.dim * frac))\n                idx = rng.choice(self.dim, size=k, replace=False)\n                jitter = rng.randn(k) * (0.4 * sigma + 0.05 * np.mean(bounds_scale))\n                m[idx] = np.minimum(np.maximum(x_best[idx] + jitter, lb[idx]), ub[idx])\n                # shrink covariance slightly to focus search then broaden sigma a bit\n                C = 0.8 * C + 0.2 * np.diag(((bounds_scale / 7.0) ** 2).clip(min=1e-12))\n                sigma = max(0.85 * sigma, 0.15 * np.mean(bounds_scale))\n                v = np.zeros_like(v)\n                s_diag = np.ones_like(s_diag)\n                continue\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DHT_ACS scored 0.182 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "51281bd0-71d4-4c04-ae61-5338826a446f", "operator": null, "metadata": {"aucs": [0.10405963717199584, 0.1712482427381241, 0.2225689529583199, 0.16605816523710704, 0.16121196078637567, 0.20775588566566006, 0.21974717160021973, 0.22452946473345092, 0.2030261099669669, 0.13977514618944686]}, "task_prompt": ""}
{"id": "f2c625db-745d-4fc4-9ecc-06a70e413190", "fitness": 0.15262831030115134, "name": "ALGAS", "description": "ALGAS runs a hybrid global–local search: a Gaussian global explorer (mean g, covariance Cg, sigma_g) samples most proposals (global_mix_init=0.7) while a small pool of adaptive localizers (centers, sigmas ~0.06·scale, per-local covariances and weights) focuses exploitation and can be respawned when stale. Successful normalized step directions are accumulated with a smoothed PCA_cov (pca_beta=0.85) and injected as a low-rank boost into Cg (rank_dir up to 3) to learn prominent search axes, while coordinate-wise RMS scaling s_diag and safe Cholesky maintain numeric stability. Exploration mechanisms include rare Lévy/Cauchy jumps (p_levy=0.04), annealed Metropolis-like acceptance (temp0 and anneal_k) for locals to escape basins, and EMA-based adaptation of global/local sigmas and weights (fast/slow rates like global_sigma_adapt=0.30, p_succ_beta=0.75). Budget-aware minibatching, bound clipping, stagnation counters that trigger partial resets (inflate sigma_g, reinitialize locals), and conservative SPD fixes ensure robustness across Many Affine BBOB functions.", "code": "import numpy as np\n\nclass ALGAS:\n    \"\"\"\n    Adaptive Local-Global Annealed Search (ALGAS)\n\n    Main ideas:\n    - Maintain a global Gaussian explorer (mean g, covariance Cg) and a small pool\n      of adaptive localizers (centers Li with their local scales and covariances).\n    - Sample from a mixture: most proposals from global explorer, some from localizers.\n    - Learn prominent search directions via an incremental low-rank PCA of successful\n      normalized steps and inject them into the global covariance (low-rank boost).\n    - Occasional Lévy/Cauchy jumps for long-distance exploration.\n    - Annealed Metropolis-like acceptance for localizers to occasionally accept worse\n      moves (helps escape local minima); sigma and local scales adapt from success rates.\n    - Opportunistic partial restarts of weak localizers and global covariance\n      resets if stagnation detected.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10,\n                 n_localizers=None,\n                 init_frac=0.08,\n                 global_mix_init=0.7,\n                 p_levy=0.04,\n                 rank_dir=3):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.init_frac = float(init_frac)\n        self.global_mix_init = float(global_mix_init)\n        self.p_levy = float(p_levy)\n        self.rank_dir = int(max(1, min(rank_dir, dim)))\n        # number of localizers defaults to a small multiple of sqrt(dim)\n        if n_localizers is None:\n            self.n_localizers = int(max(1, min(8, int(np.sqrt(dim) + 0.5))))\n        else:\n            self.n_localizers = int(n_localizers)\n\n        # adaptation speeds\n        self.global_sigma_adapt = 0.30\n        self.local_sigma_adapt = 0.25\n        self.p_succ_beta = 0.75\n        self.s_diag_beta = 0.6\n        # low-rank PCA memory smoothing\n        self.pca_beta = 0.85\n        # stochastic acceptance temperature schedule\n        self.temp0 = 1.0\n        self.anneal_k = 8.0  # controls how fast temperature decays\n        # jitter for SPD fixes\n        self._chol_eps = 1e-12\n        # limits\n        self.min_sigma = 1e-12\n\n    def __call__(self, func):\n        rng = np.random.RandomState()  # isolated RNG\n        # read bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # initialization budget: sample a small initial population\n        init_budget = max(2, int(self.init_frac * self.budget))\n        init_budget = min(init_budget, self.budget)\n        X0 = rng.uniform(lb, ub, size=(init_budget, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals = init_budget\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize global mean as weighted average of top half\n        mu0 = max(1, init_budget // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 = w0 / np.sum(w0)\n        g = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial global covariance: aligned with bounds but modest\n        bounds_scale = (ub - lb)\n        Cg = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n        # initial global sigma (overall step-size)\n        sigma_g = max(1e-8, 0.15 * np.mean(bounds_scale))\n\n        # localizers: centers, sigmas, covariances, success trackers\n        L = []\n        for i in range(self.n_localizers):\n            # initialize local centers by perturbing global mean or random points among initial pop\n            idx = order0[i % init_budget] if init_budget > 0 else None\n            if idx is not None:\n                center = X0[idx].copy()\n            else:\n                center = rng.uniform(lb, ub)\n            sigma_l = max(1e-8, 0.06 * np.mean(bounds_scale))\n            Cl = np.diag(((bounds_scale / 10.0) ** 2).clip(min=1e-12))\n            p_succ = 0.2\n            weight = 1.0  # selection weight for picking a localizer\n            L.append({\n                'center': center,\n                'sigma': sigma_l,\n                'C': Cl,\n                'p_succ': p_succ,\n                'weight': weight,\n                'age': 0,\n            })\n\n        # coordinate-wise scaling (RMS style) used by both global and locals\n        s_diag = np.ones(self.dim, dtype=float)\n        # low-rank directional memory matrix (for PCA-like directional learning)\n        # we will store a smoothed covariance of successful normalized steps\n        PCA_cov = np.zeros((self.dim, self.dim), dtype=float)\n\n        # mixture parameter (probability to sample global)\n        global_mix = float(self.global_mix_init)\n\n        # prepare Cholesky utility\n        def chol_safe(M):\n            eps_diag = np.maximum(np.diag(M) * 1e-12, self._chol_eps)\n            try:\n                A = np.linalg.cholesky(M + np.diag(eps_diag))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(M)\n                vals = np.clip(vals, 1e-18, None)\n                A = (vecs * np.sqrt(vals)).T\n            return A\n\n        # main loop: propose candidates until budget exhausted\n        while evals < self.budget:\n            remaining = self.budget - evals\n            # batch size: propose up to small minibatch to amortize linear algebra\n            batch = min(8, remaining)\n            Xcand = []\n            meta = []  # store metadata: 'global' or local index and additional info\n            # precompute chol for global\n            A_g = chol_safe(Cg)\n\n            for b in range(batch):\n                # choose sampler: global or local\n                if rng.rand() < global_mix or all(l['age'] < 3 for l in L):\n                    # Global sample\n                    z = rng.normal(size=self.dim)\n                    y = (A_g @ z) * s_diag\n                    # occasional Lévy-style long jump (Cauchy)\n                    if rng.rand() < self.p_levy:\n                        # scale a Cauchy random vector in principal subspace direction or full\n                        levy_scale = 0.8 * sigma_g + 0.25 * np.mean(bounds_scale)\n                        # draw Cauchy scalar for each dim\n                        c = rng.standard_cauchy(size=self.dim)\n                        y = y + (0.3 * levy_scale) * np.tanh(c)  # scaled, clipped heavy-tail\n                    x = g + sigma_g * y\n                    sampler = ('global', None, y)  # include normalized y for learning\n                else:\n                    # pick a localizer with probability proportional to weight\n                    weights = np.array([l['weight'] for l in L], dtype=float)\n                    if np.sum(weights) <= 0:\n                        weights = np.ones(len(L))\n                    probs = weights / weights.sum()\n                    idx = rng.choice(len(L), p=probs)\n                    loc = L[idx]\n                    A_l = chol_safe(loc['C'])\n                    z = rng.normal(size=self.dim)\n                    y = (A_l @ z) * s_diag\n                    x = loc['center'] + loc['sigma'] * y\n                    sampler = ('local', idx, y)\n                # clip to bounds\n                x = np.minimum(np.maximum(x, lb), ub)\n                Xcand.append(x)\n                meta.append(sampler)\n\n            # evaluate these candidates one by one\n            fc = np.full(len(Xcand), np.inf, dtype=float)\n            for i, x in enumerate(Xcand):\n                if evals >= self.budget:\n                    break\n                fc[i] = func(x)\n                evals += 1\n\n            # process evaluated candidates\n            for i, (x, f) in enumerate(zip(Xcand, fc)):\n                if not np.isfinite(f):\n                    continue\n                # update global best\n                improved_global = False\n                if f < f_best:\n                    f_best = float(f)\n                    x_best = x.copy()\n                    improved_global = True\n\n                sampler_type, idx, y = meta[i]\n                # normalized step in sample coords is y (we used s_diag * A @ z)\n                # but treat it as 'normalized' for learning: delta = y\n                delta = y  # shape (dim,)\n\n                # update PCA_cov (smoothed second moment of successful deltas)\n                # use only successful moves relative to chosen center: successful = better than that center's recorded fitness?\n                # We use improvement relative to global best or improvement for localizer\n                accepted = False\n                if sampler_type == 'global':\n                    # accept into global mean if improves global mean (we use conservative moving mean update)\n                    # simple rule: if candidate improves global best OR improves current mean by lowering f relative to fictitious mean val:\n                    # (no explicit mean value tracked), we accept if it's better than current global best with small prob, else probabilistic drift.\n                    if improved_global or rng.rand() < 0.08:\n                        # move the global mean toward x\n                        g = 0.9 * g + 0.1 * x\n                        accepted = True\n                else:\n                    # localizer handling\n                    loc = L[idx]\n                    loc['age'] += 1\n                    # to decide acceptance, compare to local center by evaluating center value lazily: we don't re-evaluate centers;\n                    # instead keep implicit acceptance by improvement to global or local p_succ biased criteria:\n                    # if candidate improves global best we definitely accept; otherwise accept if it's better than local center's last known proxy\n                    # We'll approximate local center's proxy f_center by using a rolling estimate (store in dict); if not stored, fallback to global best.\n                    if 'f_center' not in loc:\n                        loc['f_center'] = f_best + 1e-6  # pessimistic fallback\n                    # Metropolis-like acceptance\n                    if f < loc['f_center'] or rng.rand() < np.exp(-(f - loc['f_center']) / max(1e-8, (self.temp0 * np.exp(-self.anneal_k * (evals / self.budget))))):\n                        # accept as new local center\n                        loc['center'] = 0.85 * loc['center'] + 0.15 * x\n                        loc['f_center'] = f\n                        loc['age'] = 0\n                        # increase its weight moderately\n                        loc['weight'] = 0.9 * loc['weight'] + 0.1 * 2.0\n                        accepted = True\n                    else:\n                        # occasionally nudge local center if stagnating\n                        loc['weight'] *= 0.995\n                        loc['age'] += 1\n\n                # success definition for adaptation: improvement over current best or accepted into sampler's center\n                success_flag = (improved_global or accepted)\n                # update PCA covariance using delta if success (focus on successful step directions)\n                if success_flag:\n                    # form outer product of normalized delta (normalize by its norm to emphasize direction)\n                    norm = np.linalg.norm(delta) + 1e-20\n                    dnorm = (delta / norm).reshape(-1, 1)\n                    PCA_cov = self.pca_beta * PCA_cov + (1.0 - self.pca_beta) * (dnorm @ dnorm.T)\n                else:\n                    # minor decay to PCA_cov to forget stale directions\n                    PCA_cov = self.pca_beta * PCA_cov\n\n                # update s_diag (coordinate-wise RMS of delta magnitudes) using EMA\n                stat = delta ** 2\n                s_diag = self.s_diag_beta * s_diag + (1.0 - self.s_diag_beta) * np.sqrt(stat + 1e-20)\n                s_diag = np.clip(s_diag, 1e-3, 8.0)\n\n                # update success probabilities and adapt sigmas per sampler\n                if sampler_type == 'global':\n                    # global p_succ stored in separate var; approximate using mix of improvements\n                    if not hasattr(self, '_p_succ_g'):\n                        self._p_succ_g = 0.2\n                    self._p_succ_g = self.p_succ_beta * self._p_succ_g + (1.0 - self.p_succ_beta) * float(success_flag)\n                    sigma_g *= np.exp(self.global_sigma_adapt * (self._p_succ_g - 0.2))\n                    sigma_g = max(sigma_g, self.min_sigma)\n                    # adjust global_mix slightly: if locals are doing well, reduce global mix\n                    avg_local_weight = np.mean([l['weight'] for l in L])\n                    global_mix = 0.95 * global_mix + 0.05 * (0.6 + 0.4 * (1.0 - avg_local_weight / (1.0 + avg_local_weight)))\n                    global_mix = np.clip(global_mix, 0.15, 0.95)\n                else:\n                    # update the chosen localizer statistics\n                    loc = L[idx]\n                    loc['p_succ'] = self.p_succ_beta * loc['p_succ'] + (1.0 - self.p_succ_beta) * float(success_flag)\n                    loc['sigma'] *= np.exp(self.local_sigma_adapt * (loc['p_succ'] - 0.2))\n                    loc['sigma'] = max(loc['sigma'], self.min_sigma)\n                    # reward/punish weight\n                    loc['weight'] = 0.95 * loc['weight'] + 0.05 * (1.0 if success_flag else 0.1)\n\n                # opportunistic global mean nudging toward best occasionally\n                if improved_global and rng.rand() < 0.5:\n                    g = 0.7 * g + 0.3 * x_best\n\n            # after batch: incorporate low-rank directions into global covariance\n            # compute top-k eigenpairs of PCA_cov\n            try:\n                vals, vecs = np.linalg.eigh(PCA_cov)\n                # pick top rank_dir eigenvectors\n                top_idx = np.argsort(vals)[-self.rank_dir:]\n                dirs = vecs[:, top_idx]  # shape (dim, rank_dir)\n                strengths = np.clip(vals[top_idx], 1e-8, None)\n                # form low-rank update as sum strength * (u u^T)\n                lowrank = np.zeros_like(Cg)\n                for j in range(dirs.shape[1]):\n                    u = dirs[:, j:j+1]\n                    lowrank += (strengths[j] * (u @ u.T))\n                # mix lowrank into Cg with small weight\n                Cg = 0.92 * Cg + 0.08 * (Cg + (np.mean(np.diag(Cg)) * lowrank))\n                # ensure SPD and reasonable scale (clip diagonal)\n                Cg = 0.5 * (Cg + Cg.T)\n                diag = np.diag(Cg)\n                diag = np.clip(diag, 1e-12, (bounds_scale / 2.0) ** 2)\n                Cg = Cg + np.diag(np.maximum(np.zeros_like(diag), diag - np.diag(Cg)))\n            except Exception:\n                # fallback: slight isotropic inflation if PCA fails\n                Cg = 1.02 * Cg + np.diag(((bounds_scale / 20.0) ** 2))\n\n            # occasional maintenance: prune and respawn weak localizers\n            # if a localizer hasn't improved for many generations, reinitialize it near global best or random place\n            for li, loc in enumerate(L):\n                if loc['age'] > 8 and loc['weight'] < 0.5:\n                    # respawn: center near best with some jitter or random if no best\n                    if np.isfinite(f_best):\n                        jitter = 0.2 * np.mean(bounds_scale)\n                        loc['center'] = np.minimum(np.maximum(x_best + rng.randn(self.dim) * jitter, lb), ub)\n                    else:\n                        loc['center'] = rng.uniform(lb, ub)\n                    loc['sigma'] = max(loc['sigma'] * 0.7, 0.01 * np.mean(bounds_scale))\n                    loc['C'] = np.diag(((bounds_scale / 12.0) ** 2).clip(min=1e-12))\n                    loc['p_succ'] = 0.2\n                    loc['weight'] = 1.0\n                    loc['age'] = 0\n\n            # stagnation-based partial global reset: if no improvement for long time, partially reset Cg and increase sigma\n            if not hasattr(self, '_no_improve_count'):\n                self._no_improve_count = 0\n            # increment by batch if no improvement in this batch\n            if evals < self.budget:\n                # we detect by comparing existence of x_best change: we track a simple counter by noticing last update time\n                if not (f_best < getattr(self, '_last_recorded_best', np.inf)):\n                    self._no_improve_count += 1\n                else:\n                    self._no_improve_count = 0\n                self._last_recorded_best = f_best\n\n            if self._no_improve_count > max(6, int(0.02 * self.budget)):\n                # partial reset: inflate global sigma and slightly reset covariance toward isotropic\n                sigma_g = max(sigma_g * 1.6, 0.2 * np.mean(bounds_scale))\n                Cg = 0.85 * Cg + 0.15 * np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                # respawn a random localizer to diversify\n                k = rng.randint(len(L))\n                L[k]['center'] = rng.uniform(lb, ub)\n                L[k]['sigma'] = 0.08 * np.mean(bounds_scale)\n                L[k]['C'] = np.diag(((bounds_scale / 10.0) ** 2).clip(min=1e-12))\n                L[k]['weight'] = 1.0\n                L[k]['age'] = 0\n                self._no_improve_count = 0\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ALGAS scored 0.153 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "51281bd0-71d4-4c04-ae61-5338826a446f", "operator": null, "metadata": {"aucs": [0.0926032235609503, 0.1626779048177932, 0.19751031573509026, 0.13351750130493178, 0.13484708275498225, 0.17065220022635597, 0.18818712579095442, 0.16512161806076708, 0.16286121438963475, 0.11830491637005336]}, "task_prompt": ""}
{"id": "ae08dbe1-86ad-442c-a70c-572e580e7b73", "fitness": 0.25286610575041435, "name": "DECS", "description": "The algorithm maintains an ensemble Gaussian search distribution (mean m, step-size sigma, full covariance C) augmented by a directional momentum vector v and coordinate-wise RMS scales s_diag, and generates antithetic (mirrored) samples plus occasional heavy‑tailed Student‑t/Cauchy shocks to combine stable local search with rare long jumps. Population size lam0 is scaled gently with sqrt(dim) and elites mu are chosen conservatively (≈ lam/3) with log‑rank weights to form a weighted rank‑mu covariance estimate, while momentum (high mom_beta) supplies a stronger rank‑one update (c1 > c_cov) so covariance learning is conservative but responsive to persistent directions. Step‑size is adapted multiplicatively using a smoothed success probability p_succ (sigma_adapt_rate reduced by sqrt(dim) for stability), coordinate scales are tracked via an RMS EMA (s_diag_beta), and numerical robustness is enforced by Cholesky with jitter/fallback, bounds clamping, and diagonal floor. Stagnation triggers opportunistic restarts centered on the best solution with moderate jitter and sigma inflation, plus small isotropic jitter in sampling and shrinkage toward isotropy in updates to prevent premature convergence.", "code": "import numpy as np\n\nclass DECS:\n    \"\"\"\n    Directional Ensemble Covariance Search (DECS)\n\n    One-line idea:\n    - Maintain an ensemble Gaussian search distribution with a covariance C,\n      a directional momentum v, and coordinate-wise RMS scales s_diag.\n      Use mirrored sampling combined with occasional heavy-tailed directional\n      shocks (Student-t/Cauchy) to improve global exploration, update covariance\n      conservatively (smaller rank-mu but larger rank-one momentum weight than MCAS),\n      adapt sigma multiplicatively with a smoothed success rate, and restart\n      opportunistically on stagnation.\n\n    Main algorithm parameters (tunable) and how they differ from the provided MCAS:\n    - pop_base / lam0: base population scaled roughly as O(sqrt(dim)). (different formula)\n    - c_cov (rank-mu learning): default 0.08 (smaller than MCAS's 0.18).\n    - c1 (rank-one momentum): default 0.12 (larger emphasis on rank-one than MCAS).\n    - mom_beta: 0.95 (stronger momentum smoothing).\n    - s_diag_beta: 0.3 (slower smoothing of coordinate-wise RMS compared with MCAS's 0.6).\n    - sigma_adapt_rate: 0.15 (slower multiplicative adaptation).\n    - success_target: 0.25 (slightly higher target success prob).\n    - Uses heavy-tailed scalar perturbations (Student-t df=3) for directional shocks,\n      and occasional Cauchy-like extra samples to help escape local minima.\n    - Coordinate scale update uses RMS (square-root of EMA of squared deltas),\n      and mean is updated with a learning-rate blending to damp oscillations.\n    - Restart fraction and restart inflation factors are different and tuned conservatively.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 c_cov=0.08,      # rank-mu learning rate (smaller)\n                 c1=0.12,         # rank-one momentum (larger)\n                 mom_beta=0.95,   # momentum smoothing (stronger)\n                 s_diag_beta=0.3, # RMS smoothing for coordinate scales (slower)\n                 sigma_adapt_rate=0.15,\n                 success_target=0.25,\n                 stagnation_frac=0.03,\n                 min_sigma=1e-12,\n                 max_sigma_scale=3.0,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n\n        self.pop_base = pop_base\n        self.c_cov = float(c_cov)\n        self.c1 = float(c1)\n        self.mom_beta = float(mom_beta)\n        self.s_diag_beta = float(s_diag_beta)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.success_target = float(success_target)\n        self.stagnation_frac = float(stagnation_frac)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma_scale = float(max_sigma_scale)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds - expected to be [-5,5] for Many Affine BBOB, but we read from func\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population base scaling: gentle growth with sqrt(dim)\n        if self.pop_base is None:\n            lam0 = max(6, int(4 + int(2.0 * np.sqrt(max(1, self.dim)))))\n        else:\n            lam0 = int(self.pop_base)\n        lam0 = min(lam0, max(2, self.budget))\n\n        # initial exploratory batch\n        evals = 0\n        batch0 = min(lam0, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(batch0, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += batch0\n\n        best_idx = np.argmin(f0)\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initialize mean from a robust average of the top quarter (if possible)\n        mu0 = max(1, batch0 // 4)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        # logarithmic weights but less peaky\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 = w0 / np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance: conservative isotropic aligned to bounds (narrower than MCAS)\n        bounds_scale = (ub - lb)\n        avg_span = np.mean(bounds_scale)\n        C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.2 * avg_span)  # initial step-size\n\n        # auxiliary state\n        v = np.zeros(self.dim, dtype=float)     # directional momentum in normalized units\n        s_diag = np.ones(self.dim, dtype=float) # coordinate RMS scales (multiplicative)\n        p_succ = self.success_target            # smoothed success rate\n        stagn_iter = 0\n        iter_count = 0\n        stagnation_threshold = max(5, int(self.stagnation_frac * max(1, self.budget)))\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam = min(lam0, remaining)\n            # ensure lam at least 2 if budget allows for antithetic pairing\n            lam = max(2 if remaining >= 2 else 1, lam)\n\n            # choose number of elites smaller fraction (1/3 of lam) to be conservative\n            mu = max(1, lam // 3)\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n            W = weights.reshape(-1, 1)\n\n            # ensure C is SPD for sampling\n            # Add small relative jitter based on trace rather than diag entry\n            traceC = np.trace(C)\n            eps_diag = 1e-10 * max(traceC / max(1, self.dim), 1.0)\n            try:\n                A = np.linalg.cholesky(C + np.eye(self.dim) * eps_diag)\n            except np.linalg.LinAlgError:\n                # fallback to eigen-decomposition and clip\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n\n            # mirrored Gaussian sampling with occasional heavy tail extra sample\n            half = lam // 2\n            Zpos = rng.normal(size=(half, self.dim))\n            Z = np.vstack([Zpos, -Zpos])\n            if lam % 2 == 1:\n                # heavy-tailed extra sample (Cauchy-like) to help jumps\n                extra = rng.standard_t(df=3, size=(1, self.dim)) * 0.7\n                Z = np.vstack([Z, extra])\n\n            # correlated perturbations\n            Y = Z @ A.T  # shape (lam, dim)\n\n            # directional shock: Student-t scalars (df=3) scaled by momentum magnitude\n            vlen = np.linalg.norm(v) + 1e-20\n            if vlen > 0:\n                v_unit = v / vlen\n            else:\n                v_unit = np.zeros_like(v)\n            # direction strength: saturates but uses a different mapping than MCAS\n            dir_strength = 0.9 * (vlen / (1.0 + vlen))  # in [0,0.9)\n            s_scalar = rng.standard_t(df=3, size=(Y.shape[0], 1)) * dir_strength\n            Y = Y + (s_scalar * v_unit.reshape(1, -1))\n\n            # coordinate-wise multiplicative scale (RMS style)\n            Y = Y * s_diag.reshape(1, -1)\n\n            # small isotropic random jitter to promote exploration\n            Y += rng.normal(scale=0.02 * np.sqrt(np.mean(np.diag(C)) + 1e-20) / (sigma + 1e-20),\n                            size=Y.shape)\n\n            Xcand = m + sigma * Y\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates sequentially while respecting budget\n            lam_actual = Xcand.shape[0]\n            fc = np.full(lam_actual, np.inf, dtype=float)\n            for i in range(lam_actual):\n                if evals >= self.budget:\n                    break\n                fc[i] = func(Xcand[i])\n                evals += 1\n\n            # handle truncated evaluations\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                lam_actual = fc.shape[0]\n                if lam_actual == 0:\n                    break  # budget exhausted\n\n            # update best\n            gen_best_idx = np.argmin(fc)\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_iter = 0\n            else:\n                stagn_iter += 1\n\n            # select elites\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            if X_mu.shape[0] == 0:\n                # nothing to update this round\n                continue\n\n            # compute new mean as weighted average of elites, but blend with old mean\n            if X_mu.shape[0] != weights.shape[0]:\n                mu_eff = X_mu.shape[0]\n                w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                w_eff = np.maximum(w_eff, 0.0)\n                if np.sum(w_eff) <= 0:\n                    w_eff = np.ones_like(w_eff)\n                w_eff = w_eff / np.sum(w_eff)\n                W_eff = w_eff.reshape(-1, 1)\n                m_new = (W_eff * X_mu).sum(axis=0)\n            else:\n                m_new = (W * X_mu).sum(axis=0)\n\n            # normalized deltas in sample coordinates\n            deltas = (X_mu - m) / (sigma + 1e-20)  # shape (mu, dim)\n\n            # weighted covariance estimate from elites (normalized coords)\n            if deltas.shape[0] > 0:\n                if deltas.shape[0] != weights.shape[0]:\n                    mu_eff = deltas.shape[0]\n                    w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if np.sum(w_eff) <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff = w_eff / np.sum(w_eff)\n                    Wd = w_eff.reshape(-1, 1)\n                    weighted_cov = (deltas * Wd).T @ deltas\n                    delta_mean = (Wd * deltas).sum(axis=0)\n                else:\n                    weighted_cov = (deltas * W).T @ deltas\n                    delta_mean = (W * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # update momentum (normalized coords) more conservatively\n            v = self.mom_beta * v + (1.0 - self.mom_beta) * (delta_mean * 0.6)\n\n            # rank-one from momentum\n            rank_one = np.outer(v, v)\n\n            # conservative covariance update: mix previous C, weighted elite cov and rank-one\n            c_cov = float(self.c_cov)\n            c1 = float(self.c1)\n            # small shrinkage towards isotropic constructed from trace\n            shrink_scale = 0.02 * np.trace(C) / max(1.0, self.dim)\n            C = (1.0 - c_cov - c1) * C + c_cov * (weighted_cov + np.eye(self.dim) * shrink_scale) + c1 * rank_one\n\n            # enforce symmetry and positive-definiteness with adaptive jitter\n            C = 0.5 * (C + C.T)\n            diag_min = 1e-14 * (np.trace(C) / max(1.0, self.dim) + 1e-12)\n            C[np.diag_indices(self.dim)] = np.maximum(C.diagonal(), diag_min)\n\n            # coordinate-wise RMS scale update (root of EMA of squared normalized deltas)\n            if deltas.shape[0] > 0:\n                stat = np.mean(deltas ** 2, axis=0)\n            else:\n                stat = 1e-6 * np.ones(self.dim)\n            s_diag = np.sqrt(self.s_diag_beta * (s_diag ** 2) + (1.0 - self.s_diag_beta) * stat + 1e-20)\n            s_diag = np.clip(s_diag, 0.1, 6.0)\n\n            # update mean with conservative blending to avoid oscillations\n            alpha_m = 0.6  # how quickly we move mean to new elite average\n            m = (1.0 - alpha_m) * m + alpha_m * m_new\n\n            # step-size adaptation via multiplicative update with dimension-aware scaling\n            p_succ = 0.9 * p_succ + 0.1 * float(improved)\n            # scale down update rate slightly with dimension to avoid explosive changes\n            dim_scale = np.sqrt(max(1, self.dim))\n            sigma *= np.exp((self.sigma_adapt_rate / dim_scale) * (p_succ - self.success_target))\n            sigma = np.clip(sigma, self.min_sigma, self.max_sigma_scale * np.max(bounds_scale))\n\n            # opportunistic restart if stagnation detected\n            if stagn_iter >= stagnation_threshold and evals < self.budget:\n                stagn_iter = 0\n                # if we have a best, center new search around it with jitter; else global random\n                if np.isfinite(f_best):\n                    jitter_scale = max(0.4 * sigma, 0.06 * np.mean(bounds_scale))\n                    m = x_best + rng.randn(self.dim) * jitter_scale\n                else:\n                    m = rng.uniform(lb, ub, size=self.dim)\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset covariance to modest isotropic but not too wide\n                C = np.diag(((bounds_scale / 7.0) ** 2).clip(min=1e-12))\n                # moderately inflate sigma to encourage exploration after restart\n                sigma = max(sigma * 1.6, 0.4 * np.mean(bounds_scale))\n                v = np.zeros_like(v)\n                s_diag = np.ones_like(s_diag)\n                p_succ = self.success_target\n                # continue to next iteration\n                continue\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DECS scored 0.253 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "51281bd0-71d4-4c04-ae61-5338826a446f", "operator": null, "metadata": {"aucs": [0.16014750735018313, 0.16382219931950504, 0.26792625646032353, 0.13847139552504872, 0.2898391436658989, 0.6326311594167976, 0.231846981503132, 0.21167871933681148, 0.26231304299133396, 0.16998465193510948]}, "task_prompt": ""}
{"id": "096d4b0d-b662-4a81-bdf0-4efcbb071a53", "fitness": 0.10702263724599141, "name": "HMACS", "description": "HMACS is a hybrid evolution-strategy style sampler that maintains a Gaussian search distribution (mean m, covariance C, global step-size sigma) augmented with a momentum vector v and per-coordinate scales s_diag; it generates antithetic, Cholesky-correlated samples and injects directional biases along momentum and best-to-mean directions to combine directed search with isotropic exploration. Covariance is updated as a mixture of a rank-mu weighted normalized-covariance (c_cov=0.18) and a rank-one momentum term (c1=0.06) while momentum uses EMA (mom_beta=0.85) and s_diag is adapted by an EMA of squared normalized steps (s_diag_beta=0.65) to capture anisotropy; sigma is multiplicatively adapted from a smoothed success probability (sigma_adapt_rate=0.25, success_target=0.2) and clipped to sensible bounds. Practical safeguards and control mechanisms include antithetic sampling to reduce variance, SPD enforcement via Cholesky/eigendecomposition and jitter, per-dimension clipping of s_diag, adaptive population scaling under stagnation (pop boosts up to 4×), opportunistic trust-region restarts with jitter when progress stalls, and bound clamping of candidates to [-5,5] (via func.bounds) to ensure robust behavior across Many Affine BBOB problems.", "code": "import numpy as np\n\nclass HMACS:\n    \"\"\"\n    Hybrid Momentum-Adaptive Covariance Sampler (HMACS)\n\n    Key ideas:\n      - Maintain mean m, covariance C, global sigma, momentum v and per-coordinate scales s_diag.\n      - Use antithetic sampling + occasional directional injections along momentum to bias sampling.\n      - Update C by mixture of rank-mu and rank-one (momentum); adapt s_diag by EMA of squared normalized steps.\n      - Adapt sigma multiplicatively using a smoothed success rate (1/5-style); change population size and perform trust-region restarts on stagnation.\n      - Numerical SPD safeguards (Cholesky + jitter/eigen).\n    \"\"\"\n    def __init__(self, budget=10000, dim=10):\n        self.budget = int(budget)\n        self.dim = int(dim)\n\n        # Tunables (reasonable defaults; user may override)\n        self.pop_base = None\n        self.cov_update = 0.18\n        self.rank1 = 0.06\n        self.mom_beta = 0.85\n        self.s_diag_beta = 0.65\n        self.sigma_adapt_rate = 0.25\n        self.success_target = 0.2\n        self.min_sigma = 1e-12\n        self.max_sigma_scale = 4.0\n        self.stagnation_frac = 0.04\n        self.max_pop_boost = 4  # allow population to multiply up to this factor on stagnation\n\n    def __call__(self, func):\n        rng = np.random.RandomState()  # isolated RNG\n\n        # bounds handling\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        avg_range = float(np.mean(bounds_scale))\n\n        # adaptive base population\n        if self.pop_base is None:\n            lam_base = max(6, int(3 + 2 * np.log(max(2, self.dim))))\n        else:\n            lam_base = int(self.pop_base)\n        lam_base = min(lam_base, max(2, self.budget))\n\n        # initial sampling to seed mean and covariance\n        evals = 0\n        batch0 = min(lam_base, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(batch0, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += batch0\n\n        best_idx = np.argmin(f0)\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        mu0 = max(1, batch0 // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 = w0 / np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance and sigma\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(self.min_sigma, 0.2 * avg_range)\n\n        # momentum and coordinate scales\n        v = np.zeros(self.dim, dtype=float)\n        s_diag = np.ones(self.dim, dtype=float)\n\n        p_succ = 0.2\n        stagn_iter = 0\n        iter_count = 0\n        stagnation_threshold = max(5, int(self.stagnation_frac * self.budget))\n\n        current_pop_factor = 1\n\n        # helper: compute weights for mu elites\n        def recombination_weights(mu):\n            w = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            w = np.maximum(w, 0.0)\n            if np.sum(w) <= 0:\n                w = np.ones_like(w)\n            return w / np.sum(w)\n\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n\n            # adaptive population: escalate population when stagnating to explore more\n            lam = min(lam_base * current_pop_factor, remaining)\n            lam = int(max(2 if remaining >= 2 else 1, lam))\n\n            # enforce at least 2 for antithetic if budget allows\n            lam = min(lam, remaining)\n            mu = max(1, lam // 2)\n            weights = recombination_weights(mu)\n            W = weights.reshape(-1, 1)\n\n            # ensure C SPD\n            eps_diag = 1e-12 * np.maximum(np.diag(C), 1.0)\n            try:\n                A = np.linalg.cholesky(C + np.diag(eps_diag))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-18, None)\n                A = (vecs * np.sqrt(vals)).T\n\n            # antithetic sampling\n            half = lam // 2\n            Zpos = rng.normal(size=(half, self.dim))\n            Z = np.vstack([Zpos, -Zpos])\n            if lam % 2 == 1:\n                Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n\n            # transform to correlated coordinates\n            Y = Z @ A.T  # shape (lam, dim)\n\n            # directional injection: occasional stronger push along momentum and best-to-mean direction\n            vlen = np.linalg.norm(v) + 1e-20\n            if vlen > 0:\n                v_unit = v / vlen\n            else:\n                v_unit = np.zeros_like(v)\n            # bias scalar drawn small; increase bias if momentum large\n            dir_strength = 0.6 * (vlen / (1.0 + vlen))\n            s_scalar = rng.normal(scale=dir_strength, size=(Y.shape[0], 1))\n            Y = Y + (s_scalar * v_unit.reshape(1, -1))\n\n            # also bias toward the best if recent improvements happened, via best_dir\n            best_dir = (x_best - m)\n            best_dir_norm = np.linalg.norm(best_dir) + 1e-20\n            if best_dir_norm > 0:\n                bd_unit = best_dir / best_dir_norm\n                # small occasional nudge proportional to improvement frequency\n                nudges = (0.15 * (1.0 - p_succ))  # nudge more when p_succ low (encourage exploration)\n                if nudges > 1e-8:\n                    s_b = rng.normal(scale=nudges, size=(Y.shape[0], 1))\n                    Y = Y + (s_b * bd_unit.reshape(1, -1))\n\n            # apply per-coordinate scaling (multiplicative)\n            Y = Y * s_diag.reshape(1, -1)\n\n            # produce candidate points and clamp\n            Xcand = m + sigma * Y\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate sequentially without exceeding budget\n            lam_actual = Xcand.shape[0]\n            fc = np.full(lam_actual, np.inf, dtype=float)\n            for i in range(lam_actual):\n                if evals >= self.budget:\n                    break\n                fc[i] = func(Xcand[i])\n                evals += 1\n\n            # truncate unevaluated tails\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                lam_actual = fc.shape[0]\n                if lam_actual == 0:\n                    break\n\n            # update global best\n            gen_best_idx = np.argmin(fc)\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_iter = 0\n                # when improvement happens frequently, slightly tighten trust region\n                if p_succ > 0.35:\n                    sigma = max(self.min_sigma, sigma * 0.9)\n                    C = 0.98 * C  # slight shrink of covariance to focus search\n            else:\n                stagn_iter += 1\n\n            # select elites and compute new mean\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            if X_mu.shape[0] == 0:\n                # nothing to update\n                p_succ = 0.9 * p_succ + 0.1 * float(improved)\n                continue\n\n            if X_mu.shape[0] != weights.shape[0]:\n                mu_eff = X_mu.shape[0]\n                w_eff = recombination_weights(mu_eff)\n                W_eff = w_eff.reshape(-1, 1)\n                m_new = (W_eff * X_mu).sum(axis=0)\n            else:\n                m_new = (W * X_mu).sum(axis=0)\n\n            # normalized deltas\n            deltas = (X_mu - m) / (sigma + 1e-20)  # (mu, dim)\n\n            # weighted covariance in normalized coordinates\n            if deltas.shape[0] > 0:\n                if deltas.shape[0] != weights.shape[0]:\n                    mu_eff = deltas.shape[0]\n                    w_eff = recombination_weights(mu_eff)\n                    Wd = w_eff.reshape(-1, 1)\n                    weighted_cov = (deltas * Wd).T @ deltas\n                    delta_mean = (Wd * deltas).sum(axis=0)\n                else:\n                    weighted_cov = (deltas * W).T @ deltas\n                    delta_mean = (W * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # update momentum in normalized coords\n            v = self.mom_beta * v + (1.0 - self.mom_beta) * delta_mean\n\n            # rank-one from momentum\n            rank_one = np.outer(v, v)\n\n            # covariance update mixture\n            c_cov = float(self.cov_update)\n            c1 = float(self.rank1)\n            mix = (1.0 - c_cov - c1)\n            if mix < 0:\n                # safety: normalize coefficients\n                s = c_cov + c1\n                c_cov = c_cov / s * 0.9\n                c1 = c1 / s * 0.1\n                mix = 1.0 - c_cov - c1\n            C = mix * C + c_cov * weighted_cov + c1 * rank_one\n            # symmetrize & ensure positive diag\n            C = 0.5 * (C + C.T) + np.diag(np.maximum(np.diag(C), 1e-18))\n\n            # coordinate-wise scale update: EMA of sqrt(mean(deltas^2))\n            if deltas.shape[0] > 0:\n                stat = np.mean(deltas ** 2, axis=0)\n            else:\n                stat = 1e-6 * np.ones(self.dim)\n            s_diag = (self.s_diag_beta * s_diag +\n                      (1.0 - self.s_diag_beta) * np.sqrt(stat + 1e-20))\n            s_diag = np.clip(s_diag, 0.15, 6.0)\n\n            # update mean\n            m = m_new.copy()\n\n            # step-size adaptation\n            p_succ = 0.85 * p_succ + 0.15 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, self.min_sigma, self.max_sigma_scale * np.max(bounds_scale))\n\n            # dynamic population factor control: increase pop under stagnation, reduce when improving\n            if stagn_iter >= stagnation_threshold:\n                # escalate population factor up to max_pop_boost to explore wider\n                current_pop_factor = min(self.max_pop_boost, current_pop_factor * 2)\n            else:\n                # gently decay back to 1 when progress seen\n                if improved:\n                    current_pop_factor = max(1, current_pop_factor // 2)\n\n            # opportunistic trust-region restart on persistent stagnation\n            if stagn_iter >= 2 * stagnation_threshold and evals < self.budget:\n                stagn_iter = 0\n                current_pop_factor = 1\n                # restart around best with moderate jitter; if best at bounds nudge inward\n                jitter_scale = max(0.06 * avg_range, 0.4 * sigma)\n                m = x_best + rng.randn(self.dim) * jitter_scale\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset covariance to narrower trust-region and inflate sigma to jump out\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                sigma = max(sigma * 1.6, 0.3 * avg_range)\n                # reset momentum and per-dim scales partially\n                v = np.zeros_like(v)\n                s_diag = np.ones_like(s_diag)\n                # continue without consuming budget\n                continue\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HMACS scored 0.107 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "51281bd0-71d4-4c04-ae61-5338826a446f", "operator": null, "metadata": {"aucs": [0.055901691897967565, 0.071946293596023, 0.1696707195676147, 0.11577183029959426, 0.0833491623179724, 0.12232019267879479, 0.135363789315171, 0.09965512443434255, 0.11362602380756259, 0.10262154454487127]}, "task_prompt": ""}
{"id": "c5bd23ef-83a5-4317-9db1-df455dfcfd50", "fitness": "-inf", "name": "MirrorLevyPCADE", "description": "The algorithm is a small cooperative-population, archive-driven continuous optimizer initialized by a jittered LHS and using per-individual adaptive step scales (sigma) to balance exploration/exploitation (pop size ~ max(8, 6+2√dim), sigma_init_frac=0.10). It mixes complementary operators by probability (mirror Gaussian shaped by a learned covariance, adaptive DE rand/pbest, PCA-projected elite sampling, and occasional Levy/multivariate‑t or Cauchy heavy-tailed probes) and even sometimes evaluates mirrored pairs to exploit symmetry while being budget-aware. Covariance and principal directions are learned from a pruned elite archive with eigendecomposition and eigenvalue clamping (max_eig_ratio) to form a square-root transform A for covariance-shaped proposals, plus occasional small archive injections to avoid collapse; bounds are handled by a reflect-then-clamp rule and all function calls are guarded against the budget. Sigma adapts both per-individual (log-normal perturbation and reward/penalty on success) and globally via a smoothed success rate (success_target ≈ 0.22, sigma_adapt_rate ≈ 0.16), biasing moderate local search with sporadic heavy-tailed jumps for robustness on multimodal/noiseless BBOB problems.", "code": "import numpy as np\n\nclass MirrorLevyPCADE:\n    \"\"\"\n    MirrorLevyPCADE\n    - Small cooperative population with per-individual adaptive step scales.\n    - Hybrid operators: mirrored covariance-shaped Gaussian proposals, adaptive DE (rand/pbest style),\n      PCA-projected sampling from elite archive, and occasional Levy/multivariate-t probes.\n    - Covariance learned from elite archive with eigendecomposition, eigen-clamping and mild injection.\n    - Sigma adapts via smoothed success rate; DE F/CR sampled per-trial (heavy-tailed / normal).\n    - Budget-aware, bounds-safe with reflect-then-clamp protection.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop_base=None,\n                 p_de=0.40, p_pca=0.30, p_mirror=0.20, p_levy=0.10,\n                 cov_lr=0.12,\n                 sigma_init_frac=0.10,\n                 success_target=0.22,\n                 sigma_adapt_rate=0.16,\n                 archive_factor=4,\n                 levy_prob=0.08,\n                 max_eig_ratio=1e6):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.pop_base = pop_base\n        self.p_de = float(p_de)\n        self.p_pca = float(p_pca)\n        self.p_mirror = float(p_mirror)\n        self.p_levy = float(p_levy)\n        self.cov_lr = float(cov_lr)\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.success_target = float(success_target)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.archive_factor = int(archive_factor)\n        self.levy_prob = float(levy_prob)\n        self.max_eig_ratio = float(max_eig_ratio)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        domain = ub - lb\n        mean_domain = float(np.mean(domain))\n        # population size similar to No.5 style\n        if self.pop_base is None:\n            pop = max(8, int(np.ceil(6 + 2.0 * np.sqrt(max(1, self.dim)))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        # reflect-then-clamp helper\n        def reflect_clamp(x):\n            x = np.asarray(x, dtype=float).copy()\n            low = lb\n            high = ub\n            below = x < low\n            if np.any(below):\n                x[below] = low[below] + (low[below] - x[below])\n            above = x > high\n            if np.any(above):\n                x[above] = high[above] - (x[above] - high[above])\n            np.minimum(np.maximum(x, low), high, out=x)\n            return x\n\n        # small heavy tailed vector generator (truncated Cauchy)\n        def cauchy_vec(scale):\n            # sample standard Cauchy via tan(pi*(u-0.5))\n            u = rng.rand(self.dim)\n            s = np.tan(np.pi * (u - 0.5))\n            s = np.clip(s, -1e3, 1e3)\n            return scale * s\n\n        # initialize population via LHS-like stratification and jitter\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / float(pop)\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        X += (rng.rand(pop, self.dim) - 0.5) * 0.5 * domain / max(1.0, self.dim)\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        f = np.full(pop, np.inf, dtype=float)\n        evals = 0\n        # evaluate initial population sequentially\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        # per-individual sigma (relative to domain)\n        sigma = np.full(pop, self.sigma_init_frac, dtype=float)  # fraction of mean domain\n        # maintain archive (X and f)\n        archive_X = X.copy()\n        archive_f = f.copy()\n        max_archive = max(self.archive_factor * pop, pop + 10, 20)\n\n        # helpers to manage archive\n        def archive_add(x_new, f_new):\n            nonlocal archive_X, archive_f\n            archive_X = np.vstack([archive_X, x_new.reshape(1, -1)])\n            archive_f = np.concatenate([archive_f, np.array([f_new], dtype=float)])\n            if archive_X.shape[0] > max_archive:\n                order = np.argsort(archive_f)\n                keep = order[:max_archive]\n                archive_X = archive_X[keep]\n                archive_f = archive_f[keep]\n\n        # covariance learning from archive elites\n        def build_cov_and_basis():\n            # use top K elites if available\n            if archive_X.shape[0] < 2:\n                C = np.diag((domain / 6.0) ** 2)\n                A = np.eye(self.dim)\n                eigvals = np.ones(self.dim)\n                eigvecs = np.eye(self.dim)\n                return C, A, eigvals, eigvecs\n            # use up to top_k points\n            k = min(max(4, int(0.6 * archive_X.shape[0])), archive_X.shape[0])\n            idx = np.argsort(archive_f)[:k]\n            pts = archive_X[idx]\n            mean = np.mean(pts, axis=0)\n            Z = pts - mean\n            # covariance with small regularization\n            C = (Z.T @ Z) / max(1.0, Z.shape[0]) + 1e-10 * np.eye(self.dim)\n            # eigen-decompose\n            eigvals, eigvecs = np.linalg.eigh(C)\n            # clamp eigenvalues to avoid ill-conditioning\n            eigvals = np.clip(eigvals, 1e-12, None)\n            min_ev = eigvals.min()\n            if eigvals.max() / max(min_ev, 1e-30) > self.max_eig_ratio:\n                eigvals = np.minimum(eigvals, min_ev * self.max_eig_ratio)\n            # form A such that Y = Z @ A^T yields samples with cov C (we build sqrt)\n            A = (eigvecs * np.sqrt(eigvals)).T\n            return C, A, eigvals, eigvecs\n\n        # helper to sample multivariate-t like heavy-tailed probe\n        def multivariate_t_probe(center, scale):\n            df = 2.0\n            gamma = max(1e-8, rng.chisquare(df))\n            z = rng.normal(size=self.dim)\n            jump = z / np.sqrt(gamma / df) * scale\n            return reflect_clamp(center + jump)\n\n        # initial best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n        gens = 0\n        # smoothed success fraction (for global sigma adaptation)\n        p_succ = self.success_target\n\n        # main loop: produce one candidate per individual per \"gen\" until budget used\n        while evals < self.budget:\n            gens += 1\n            improved_in_gen = False\n            remaining = self.budget - evals\n            # rebuild covariance and basis from archive\n            C, A, eigvals, eigvecs = build_cov_and_basis()\n            # compute mean of elites for mirrored proposals center\n            if archive_X.shape[0] > 0:\n                mean_elite = np.mean(archive_X[np.argsort(archive_f)[:max(1, min(archive_X.shape[0], pop))]], axis=0)\n            else:\n                mean_elite = np.mean(X, axis=0)\n            # per-gen counters for adaptation\n            succ_count = 0\n            trials = 0\n            # random order\n            order = rng.permutation(pop)\n            for ii in order:\n                if evals >= self.budget:\n                    break\n                x_i = X[ii].copy()\n                f_i = float(f[ii])\n                trials += 1\n\n                # adapt per-individual sigma with mild log-normal mutation\n                if rng.rand() < 0.14:\n                    sigma[ii] *= np.exp(0.08 * rng.randn())\n                    sigma[ii] = np.clip(sigma[ii], 1e-6, 2.0)\n\n                r = rng.rand()\n                candidate = None\n\n                # 1) mirrored covariance-shaped Gaussian proposals\n                if r < self.p_mirror:\n                    # sample z from N(0,I) and transform: y = (A^T z) gives covariance approx C\n                    z = rng.normal(size=self.dim)\n                    y = A.T @ z\n                    step = sigma[ii] * np.mean(domain) * y / (np.sqrt(np.mean(eigvals)) + 1e-12)\n                    x1 = reflect_clamp(mean_elite + step)\n                    x2 = reflect_clamp(2.0 * mean_elite - x1)  # mirrored\n                    # evaluate the cheaper option first (x1), evaluate x2 only if budget allows and promising\n                    cand_eval_first = x1\n                    cand_eval_second = x2\n                    # prefer to evaluate better of the two predicted by simple surrogate (distance to best)\n                    # we choose to evaluate both occasionally if budget permits for variance reduction\n                    if evals + 2 <= self.budget and rng.rand() < 0.25:\n                        # evaluate both\n                        f1 = float(func(cand_eval_first)); evals += 1\n                        f2 = float(func(cand_eval_second)); evals += 1\n                        if f1 <= f2:\n                            f_cand = f1; candidate = cand_eval_first\n                        else:\n                            f_cand = f2; candidate = cand_eval_second\n                    else:\n                        f_cand = float(func(cand_eval_first)); evals += 1\n                        candidate = cand_eval_first\n                else:\n                    # not mirror; choose among DE, PCA, Levy\n                    if r < self.p_mirror + self.p_de:\n                        # adaptive DE-like operator (pbest/rand style)\n                        # sample F from heavy-tailed Cauchy around 0.6\n                        F = rng.standard_cauchy() * 0.12 + 0.6\n                        F = float(np.clip(F, 0.15, 1.2))\n                        CR = float(np.clip(rng.normal(loc=0.9, scale=0.12), 0.0, 1.0))\n                        p = max(2, int(np.ceil(0.12 * pop)))\n                        pbest_idx = rng.choice(np.argsort(f)[:p])\n                        pbest = X[pbest_idx]\n                        # pick two distinct random indices\n                        others = [j for j in range(pop) if j != ii]\n                        if len(others) >= 2:\n                            r1, r2 = rng.choice(others, size=2, replace=False)\n                        else:\n                            r1 = r2 = ii\n                        mutant = x_i + F * (pbest - x_i) + 0.6 * (X[r1] - X[r2])\n                        # binomial crossover\n                        mask = rng.rand(self.dim) < CR\n                        if not np.any(mask):\n                            mask[rng.randint(self.dim)] = True\n                        trial = np.where(mask, mutant, x_i)\n                        # small jitter scaled by sigma and domain\n                        trial += rng.normal(scale=0.25 * sigma[ii] * domain)\n                        candidate = reflect_clamp(trial)\n                        f_cand = float(func(candidate)); evals += 1\n                    elif r < self.p_mirror + self.p_de + self.p_pca:\n                        # PCA-projected sampling: step along top eigenvectors of archive covariance\n                        if archive_X.shape[0] >= 3:\n                            # use top-k elites\n                            topk = min(max(3, int(0.6 * archive_X.shape[0])), archive_X.shape[0])\n                            idxs = np.argsort(archive_f)[:topk]\n                            base = archive_X[rng.choice(idxs)]\n                            # principal direction is top eigenvector of C computed above (eigvecs last col)\n                            # ensure eigvecs computed\n                            # top eigenvector corresponds to largest eigval\n                            idx_top = np.argmax(eigvals)\n                            v = eigvecs[:, idx_top]\n                        else:\n                            base = X[rng.randint(pop)]\n                            v = rng.randn(self.dim)\n                            v /= max(1e-12, np.linalg.norm(v))\n                        # step length heavy-tailed but scaled by sigma\n                        length = sigma[ii] * mean_domain * (0.6 + rng.rand() * 1.6)\n                        # occasional heavy-tail\n                        if rng.rand() < 0.15:\n                            step_len = cauchy_vec(0.6 * length)\n                            step_vec = step_len * v\n                        else:\n                            step_vec = rng.randn() * length * v\n                        candidate = reflect_clamp(base + step_vec)\n                        f_cand = float(func(candidate)); evals += 1\n                    else:\n                        # Levy/multivariate-t probe\n                        center = x_i if rng.rand() < 0.7 else mean_elite\n                        # multivariate t-like using chi-square trick\n                        if rng.rand() < 0.7:\n                            candidate = multivariate_t_probe(center, scale=0.9 * sigma[ii] * mean_domain)\n                        else:\n                            # coordinate-wise cauchy scaled\n                            step = cauchy_vec(sigma[ii] * mean_domain)\n                            step = step * (domain / mean(domain))\n                            candidate = reflect_clamp(center + step)\n                        f_cand = float(func(candidate)); evals += 1\n\n                # selection and book-keeping\n                if candidate is not None and f_cand < f_i:\n                    X[ii] = candidate.copy()\n                    f[ii] = float(f_cand)\n                    archive_add(candidate.copy(), float(f_cand))\n                    # reward sigma if improved\n                    sigma[ii] *= np.exp(self.sigma_adapt_rate * (1.0 - self.success_target))\n                    succ_count += 1\n                    improved_in_gen = True\n                    if f_cand < f_best:\n                        f_best = float(f_cand)\n                        x_best = candidate.copy()\n                else:\n                    # slightly penalize sigma on failures\n                    sigma[ii] *= np.exp(self.sigma_adapt_rate * (0.0 - self.success_target))\n\n                # occasionally perform light covariance injection to avoid collapse\n                if rng.rand() < 0.02:\n                    # nudge archive mean with small isotropic variance\n                    if archive_X.shape[0] > 0:\n                        idx = rng.randint(archive_X.shape[0])\n                        x_inj = archive_X[idx] + 1e-3 * mean_domain * rng.randn(self.dim)\n                        archive_add(np.minimum(np.maximum(x_inj, lb), ub), float(func(np.minimum(np.maximum(x_inj, lb), ub))) if evals < self.budget else np.inf)\n                        # Note: we guarded by evals check; if budget exhausted, function call not done\n\n            # adapt global smoothed success probability and possibly scale sigma globally\n            if trials > 0:\n                succ_frac = succ_count / max(1.0, float(trials))\n                p_succ = 0.9 * p_succ + 0.1 * succ_frac\n                # gently adjust a multiplicative global factor based on p_succ vs target: here adjust per-individual already\n                global_adj = np.exp(self.sigma_adapt_rate * (p_succ - self.success_target) * 0.5)\n                sigma *= np.clip(global_adj, 0.8, 1.25)\n\n            # stagnation handling: occasional heavy multivariate-t probe from best\n            # estimate stagnation as few improvements in recent gens\n            if not improved_in_gen and rng.rand() < self.levy_prob and evals < self.budget:\n                probe_center = mean_elite if rng.rand() < 0.6 else x_best\n                jump_point = multivariate_t_probe(probe_center, scale=1.2 * mean_domain)\n                if evals < self.budget:\n                    fj = float(func(jump_point)); evals += 1\n                    archive_add(jump_point.copy(), fj)\n                    if fj < f_best:\n                        f_best = fj\n                        x_best = jump_point.copy()\n                        # inflate sigma moderately on success\n                        sigma *= 1.2\n\n        # finish\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 280, in __call__, the following error occurred:\nNameError: name 'mean' is not defined\nOn line: step = step * (domain / mean(domain))", "error": "In the code, line 280, in __call__, the following error occurred:\nNameError: name 'mean' is not defined\nOn line: step = step * (domain / mean(domain))", "parent_ids": "51281bd0-71d4-4c04-ae61-5338826a446f", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "9fca9d25-909e-4bd4-b334-fc218d03079d", "fitness": "-inf", "name": "HAMGE", "description": "HAMGE is a hybrid, budget-aware continuous optimiser that mixes model-based, directional, heavy-tailed and differential-style moves: it uses a compact quasi‑uniform initial population with jitter and an archive (archive_size=60) to fit a cheap diagonal-quadratic surrogate periodically (model_build_period=9) for stationary-point probes (model_prob≈0.28), while also using PCA on recent successful steps (success_hist_len=20) to extract promising directions. Exploration/exploitation is balanced via explicit strategy probabilities (levy_prob≈0.06 for heavy-tailed jumps, diff_prob≈0.12 for small differential recombination, p_frac≈0.2 to select a pool) and opportunistic backtracking/extrapolation of improved candidates. Adaptation and diversity are maintained by an adaptive local scale (step_scale starts ~0.15, bounded [1e-6,2.0], increased by adapt_up=1.12 on success and decayed by adapt_down=0.88 on failure), occasional injection of best into worst slots, and mild restarts when stagnation/diversity collapse is detected. Boundary handling is reflect‑then‑clamp, all function evaluations are strictly budget-counted, and cheap model/PCA heuristics keep computational overhead low.", "code": "import numpy as np\n\nclass HAMGE:\n    \"\"\"\n    Hybrid Adaptive Model-Guided Explorer (HAMGE)\n\n    Main ideas:\n    - Small quasi-uniform initial population (stratified per-dimension + jitter).\n    - Maintain an archive of good samples; build a cheap surrogate (linear + diagonal quadratic)\n      from archive when enough points collected to propose model-critical points.\n    - PCA on recent successful displacement vectors to get promising search directions.\n    - Mix strategies: model-based step, PCA-directional line probes, Lévy heavy-tail jumps,\n      and a small differential-style mutation for diversity.\n    - Budget-aware backtracking line probes and opportunistic extension on success.\n    - Adaptive local scale (step_scale) increased on success, decayed on failures.\n    - Reflect-then-clamp boundary handling. Always honors self.budget limit of func calls.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop=None,\n                 archive_size=60,\n                 levy_prob=0.06,\n                 model_prob=0.28,\n                 diff_prob=0.12,\n                 p_frac=0.2,\n                 step_scale_init=0.15,\n                 step_scale_min=1e-6,\n                 step_scale_max=2.0,\n                 adapt_up=1.12,\n                 adapt_down=0.88,\n                 model_build_period=9,\n                 success_hist_len=20,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop = pop\n        self.archive_size = int(archive_size)\n        self.levy_prob = float(levy_prob)\n        self.model_prob = float(model_prob)\n        self.diff_prob = float(diff_prob)\n        self.p_frac = float(p_frac)\n        self.step_scale = float(step_scale_init)\n        self.step_scale_min = float(step_scale_min)\n        self.step_scale_max = float(step_scale_max)\n        self.adapt_up = float(adapt_up)\n        self.adapt_down = float(adapt_down)\n        self.model_build_period = int(model_build_period)\n        self.success_hist_len = int(success_hist_len)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds handling (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size (compact)\n        if self.pop is None:\n            pop = max(12, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            pop = max(2, int(self.pop))\n        pop = min(pop, max(2, self.budget))\n        self.pop = pop\n\n        evals = 0\n\n        # quasi-uniform initialization (stratified per-dimension)\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter to break symmetry\n        jitter_scale = 0.5 * (ub - lb) / max(1.0, self.dim)\n        X += (rng.rand(pop, self.dim) - 0.5) * jitter_scale\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially (budget-aware)\n        f = np.empty(pop, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # tracking\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        # archive of best points (sorted by value)\n        archive_X = [X[i].copy() for i in np.argsort(f)[:min(self.archive_size, pop)]]\n        archive_f = [float(f[i]) for i in np.argsort(f)[:min(self.archive_size, pop)]]\n\n        # store recent successful steps for PCA\n        success_steps = []\n\n        # helper: reflect then clamp\n        def reflect_then_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # levy step generator (Mantegna symmetric alpha-stable approx using normal ratio)\n        def levy_step(scale=1.0, alpha=1.5):\n            # Mantegna's algorithm for symmetric stable distributions (approx)\n            # Draw u ~ N(0, sigma_u^2), v ~ N(0,1), step = u / |v|^(1/alpha)\n            sigma_u = (np.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) /\n                       (np.gamma((1 + alpha) / 2) * alpha * 2 ** ((alpha - 1) / 2))) ** (1.0 / alpha)\n            u = rng.randn(self.dim) * sigma_u\n            v = rng.randn(self.dim)\n            denom = np.abs(v) ** (1.0 / alpha)\n            step = u / np.maximum(1e-12, denom)\n            return scale * step\n\n        # lightweight model builder: fit f ≈ a + b^T x + 0.5 * h^T x^2 (diagonal quadratic)\n        # returns centroid, grad b, diag Hessian h (length dim); uses ridge regularization\n        def build_diagonal_quadratic_model(Xs, fs):\n            Xs = np.asarray(Xs)\n            fs = np.asarray(fs)\n            n = Xs.shape[0]\n            if n < 1:\n                return None\n            # design: [1, x_i..., 0.5 * x_i^2...]\n            A = np.empty((n, 1 + self.dim + self.dim), dtype=float)\n            A[:, 0] = 1.0\n            A[:, 1:1 + self.dim] = Xs\n            A[:, 1 + self.dim:] = 0.5 * (Xs ** 2)\n            # ridge solve\n            lambda_ridge = 1e-6 * max(1.0, np.var(fs))\n            try:\n                # solve (A^T A + λI) c = A^T f\n                ATA = A.T.dot(A)\n                for k in range(ATA.shape[0]):\n                    ATA[k, k] += lambda_ridge\n                rhs = A.T.dot(fs)\n                coeff = np.linalg.solve(ATA, rhs)\n                a = coeff[0]\n                b = coeff[1:1 + self.dim]\n                h = coeff[1 + self.dim:]\n                centroid = np.mean(Xs, axis=0)\n                return {'a': float(a), 'b': b, 'h': h, 'centroid': centroid}\n            except Exception:\n                return None\n\n        # compute PCA principal direction from success_steps\n        def principal_direction(steps):\n            if len(steps) < 2:\n                return None\n            S = np.vstack(steps)\n            S_centered = S - S.mean(axis=0, keepdims=True)\n            try:\n                _, svals, vh = np.linalg.svd(S_centered, full_matrices=False)\n                dir0 = vh[0]\n                nrm = np.linalg.norm(dir0)\n                if nrm > 0:\n                    return dir0 / nrm\n            except Exception:\n                return None\n            return None\n\n        gen = 0\n        # main loop: repeatedly propose candidates until budget exhausted\n        while evals < self.budget:\n            gen += 1\n            order = np.argsort(f)\n            p_pool_size = max(2, int(np.ceil(self.p_frac * pop)))\n            p_pool = order[:p_pool_size]\n\n            # optionally rebuild model periodically based on archive\n            model = None\n            if (gen % self.model_build_period == 0) and (len(archive_X) >= min(3, self.dim + 1)):\n                # use at most archive_size most recent best points\n                model = build_diagonal_quadratic_model(archive_X[-min(len(archive_X), self.archive_size):],\n                                                       archive_f[-min(len(archive_f), self.archive_size):])\n\n            # compute principal direction from recent steps\n            pc_dir = principal_direction(success_steps[-self.success_hist_len:])\n\n            # iterate over population in random order producing at most one eval per individual (budget-aware)\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fi = float(f[ii])\n\n                # choose strategy\n                r = rng.rand()\n                candidate = None\n                candidate_source = None\n\n                # 1) Model-guided candidate (if available) - aim for stationary model point\n                if (model is not None) and (r < self.model_prob):\n                    b = model['b']\n                    h = model['h']\n                    centroid = model['centroid']\n                    # clamp tiny h to avoid division by zero\n                    h_clamped = np.where(np.abs(h) < 1e-6, np.sign(h) * 1e-6, h)\n                    # model stationary solution x* = -b / h\n                    x_star = -b / h_clamped\n                    # combine with centroid to stabilize: try steps along (x_star - centroid)\n                    direction = x_star - centroid\n                    dir_norm = np.linalg.norm(direction)\n                    if dir_norm > 0:\n                        direction = direction / dir_norm\n                        # propose several shrinked probes along centroid->x_star\n                        found = False\n                        lam = 1.0\n                        # backtracking list of multipliers\n                        for lam_try in (1.0, 0.5, 0.25, 0.1):\n                            if evals >= self.budget:\n                                break\n                            x_try = centroid + lam_try * (x_star - centroid)\n                            x_try = reflect_then_clamp(x_try)\n                            fv_try = float(func(x_try))\n                            evals += 1\n                            if fv_try < fi:\n                                candidate = x_try\n                                candidate_source = 'model_backtrack'\n                                found = True\n                                # opportunistic extension further towards x_star (if budget)\n                                if lam_try == 1.0 and evals < self.budget:\n                                    x_ext = centroid + 1.5 * (x_star - centroid)\n                                    x_ext = reflect_then_clamp(x_ext)\n                                    fv_ext = float(func(x_ext))\n                                    evals += 1\n                                    if fv_ext < fv_try:\n                                        candidate = x_ext\n                                break\n                        if not found:\n                            # fallback to centroid + small step in direction\n                            x_try = centroid + 0.5 * self.step_scale * (ub - lb) * direction\n                            x_try = reflect_then_clamp(x_try)\n                            candidate = x_try\n                            candidate_source = 'model_fallback'\n                    else:\n                        # model degenerate; fallback\n                        candidate = xi + self.step_scale * (ub - lb) * (rng.randn(self.dim))\n                        candidate_source = 'model_degenerate_fallback'\n\n                # 2) Levy heavy-tail exploration\n                elif r < (self.model_prob + self.levy_prob):\n                    scale = self.step_scale * np.mean(ub - lb)\n                    candidate = xi + levy_step(scale=scale)\n                    candidate_source = 'levy'\n\n                # 3) Differential-style recombination (small prob)\n                elif r < (self.model_prob + self.levy_prob + self.diff_prob):\n                    idxs_pool = [j for j in range(pop) if j != ii]\n                    if len(idxs_pool) >= 3:\n                        r1, r2, r3 = rng.choice(idxs_pool, size=3, replace=False)\n                        F = 0.6 * (0.8 + 0.4 * rng.rand())  # adaptive-ish\n                        vi = X[r1] + F * (X[r2] - X[r3])\n                        # crossover\n                        cr = 0.7\n                        jrand = rng.randint(self.dim)\n                        mask = rng.rand(self.dim) < cr\n                        mask[jrand] = True\n                        candidate = np.where(mask, vi, xi)\n                        candidate_source = 'differential'\n                    else:\n                        candidate = xi + self.step_scale * (rng.randn(self.dim) * (ub - lb))\n                        candidate_source = 'diff_fallback'\n\n                # 4) PCA-directional local probe\n                else:\n                    base = x_best if rng.rand() < 0.6 else xi\n                    if pc_dir is not None and rng.rand() < 0.7:\n                        # try both signs with step proportional to step_scale\n                        s = self.step_scale * np.mean(ub - lb)\n                        # choose sign by random and add gaussian perturbation\n                        sign = 1.0 if rng.rand() < 0.5 else -1.0\n                        candidate = base + sign * s * pc_dir + 0.3 * s * rng.randn(self.dim)\n                        candidate_source = 'pca_dir'\n                    else:\n                        # isotropic gaussian local search around base\n                        s = self.step_scale * np.mean(ub - lb)\n                        candidate = base + s * rng.randn(self.dim)\n                        candidate_source = 'isotropic_local'\n\n                # ensure candidate defined\n                if candidate is None:\n                    candidate = xi + self.step_scale * rng.randn(self.dim) * (ub - lb)\n                    candidate_source = 'fallback'\n\n                # reflect and clamp\n                candidate = reflect_then_clamp(np.asarray(candidate, dtype=float))\n\n                # candidate evaluation (budget-aware)\n                if evals >= self.budget:\n                    break\n                fv = float(func(candidate))\n                evals += 1\n\n                # opportunistic extension: if improved, attempt small extrapolation\n                if fv < fi and evals < self.budget:\n                    step_vec = candidate - xi\n                    # extrapolate 1.5x\n                    x_ext = reflect_then_clamp(candidate + 0.5 * step_vec)\n                    f_ext = float(func(x_ext))\n                    evals += 1\n                    if f_ext < fv:\n                        candidate = x_ext\n                        fv = f_ext\n\n                # selection: replace if improved\n                if fv <= fi:\n                    # push success step into history\n                    step_vec = candidate - xi\n                    if np.linalg.norm(step_vec) > 0:\n                        success_steps.append(step_vec.copy())\n                        if len(success_steps) > self.success_hist_len:\n                            success_steps.pop(0)\n                    X[ii] = candidate\n                    f[ii] = fv\n                    # adapt step_scale upward\n                    self.step_scale = min(self.step_scale * self.adapt_up, self.step_scale_max)\n                    # update archive\n                    # maintain as sorted by value (we will keep archive arrays sorted ascending)\n                    insert_pos = np.searchsorted(archive_f, fv)\n                    archive_f.insert(insert_pos, fv)\n                    archive_X.insert(insert_pos, candidate.copy())\n                    if len(archive_f) > self.archive_size:\n                        archive_f.pop(0)  # maintain as ascending, so pop worst (first entry)\n                        archive_X.pop(0)\n                    # update global best\n                    if fv < f_best:\n                        f_best = float(fv)\n                        x_best = candidate.copy()\n                else:\n                    # decay step_scale on failure\n                    self.step_scale = max(self.step_scale * self.adapt_down, self.step_scale_min)\n\n                # occasionally inject the best into worst slot to maintain diversity\n                if rng.rand() < 0.02 and evals < self.budget:\n                    worst_idx = int(np.argmax(f))\n                    # small jitter around best\n                    jitter = 0.03 * (ub - lb) * rng.randn(self.dim)\n                    newx = reflect_then_clamp(x_best + jitter)\n                    newf = float(func(newx))\n                    evals += 1\n                    X[worst_idx] = newx\n                    f[worst_idx] = newf\n                    # update archive / best if improved\n                    insert_pos = np.searchsorted(archive_f, newf)\n                    archive_f.insert(insert_pos, newf)\n                    archive_X.insert(insert_pos, newx.copy())\n                    if len(archive_f) > self.archive_size:\n                        archive_f.pop(0)\n                        archive_X.pop(0)\n                    if newf < f_best:\n                        f_best = float(newf)\n                        x_best = newx.copy()\n\n            # end per-population loop\n\n            # synchronize global best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n\n            # if stagnation (no improvement for many gens), do mild restart of half population\n            if gen % (3 * self.model_build_period) == 0:\n                # measure diversity and improvement\n                diversity = np.mean(np.std(X, axis=0))\n                # if diversity very small, jitter half of population around best\n                if diversity < 1e-6 or self.step_scale < 1.5 * self.step_scale_min:\n                    half = max(1, pop // 2)\n                    for k in range(half):\n                        if evals >= self.budget:\n                            break\n                        idx_replace = rng.randint(pop)\n                        jitter = 0.06 * (ub - lb) * rng.randn(self.dim)\n                        newx = reflect_then_clamp(x_best + jitter)\n                        newf = float(func(newx))\n                        evals += 1\n                        X[idx_replace] = newx\n                        f[idx_replace] = newf\n                        insert_pos = np.searchsorted(archive_f, newf)\n                        archive_f.insert(insert_pos, newf)\n                        archive_X.insert(insert_pos, newx.copy())\n                        if len(archive_f) > self.archive_size:\n                            archive_f.pop(0)\n                            archive_X.pop(0)\n                        if newf < f_best:\n                            f_best = float(newf)\n                            x_best = newx.copy()\n                    # increase step scale a bit after restart\n                    self.step_scale = min(self.step_scale * 1.4, self.step_scale_max)\n\n        # finish\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "error": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "parent_ids": "bb3480f9-49d6-486a-8da6-7beaf8ccece9", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "3cb21822-5947-45ad-8a97-34d0163e9db5", "fitness": 0.30511304835671577, "name": "RAMES_GT", "description": "RAMES-GT is a population-based DE-style optimizer with SHADE-like adaptive memory (Lehmer mean for F and weighted mean for CR) and Latin-strata initialization with population size scaled ~sqrt(dim), plus reflect-then-clamp bounds handling to keep points feasible. It mixes two mutation modes (rand/1 for exploration and a current-to-elite/1 variant with per-individual Gaussian perturbation for exploitation), selects elites by rank (elite_frac) and stores successful F/CR/weight samples to update the M-slot memory. Each individual carries a multiplicative per-individual sigma (trust-region-like) that increases on success and shrinks on failure, and the algorithm periodically runs a budget-aware directional local search using PCA of recent successful steps (principal direction), coordinate probes, opportunistic extra probes and trust-radius expansion/shrink. To avoid stagnation it jitters a fraction of the population around the global best, constrains sigma/step sizes with explicit min/max fractions, and always respects the global evaluation budget.", "code": "import numpy as np\n\nclass RAMES_GT:\n    \"\"\"\n    RAMES-GT: Rank-based Adaptive Memetic Evolution with SHADE-style memory and Gaussian trust-region.\n\n    Key ideas:\n    - Population DE-style search with SHADE memory (Lehmer mean) for F and arithmetic mean for CR.\n    - Per-individual Gaussian step-size (sigma) that self-adapts multiplicatively (trust-region-like).\n    - Mutation: primarily current-to-elite/1 plus Gaussian perturbation; occasional rand/1 for exploration.\n    - Maintain short success history for SVD principal direction; perform budget-aware directional local search\n      with multiplicative trust-radius shrink/expand and opportunistic extra probes.\n    - Reflect-then-clamp bounds handling.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 M=8,                    # SHADE memory size\n                 F_min=0.10, F_max=0.80, # F range\n                 strategy_mix_prob=0.25, # rand/1 prob\n                 pop_scale_factor=4.0,   # used to grow pop with sqrt(dim)\n                 elite_frac=0.20,        # p_frac\n                 initial_step_frac=0.15, min_step_frac=1e-6, step_shrink=0.6,\n                 sigma_increase=1.15, sigma_decrease=0.85, sigma_min_frac=1e-4, sigma_max_frac=0.5,\n                 local_period=12, local_stagn_gen=40,\n                 success_hist_len=20, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.M = int(M)\n        self.F_min = float(F_min)\n        self.F_max = float(F_max)\n        self.strategy_mix_prob = float(strategy_mix_prob)\n        self.pop_scale_factor = float(pop_scale_factor)\n        self.elite_frac = float(elite_frac)\n        self.initial_step_frac = float(initial_step_frac)\n        self.min_step_frac = float(min_step_frac)\n        self.step_shrink = float(step_shrink)\n        self.sigma_increase = float(sigma_increase)\n        self.sigma_decrease = float(sigma_decrease)\n        self.sigma_min_frac = float(sigma_min_frac)\n        self.sigma_max_frac = float(sigma_max_frac)\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.success_hist_len = int(success_hist_len)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds (Many Affine BBOB: typically [-5,5] each dimension)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        range_mean = np.mean(ub - lb)\n        # population size scaled with sqrt(dim); ensure >= 4 and <= budget\n        pop = max(4, int(np.ceil(8 + self.pop_scale_factor * np.sqrt(max(1, self.dim)))))\n        pop = min(pop, max(2, self.budget))\n        evals = 0\n\n        # quasi-uniform Latin-strata initialization (per-dim stratification + jitter)\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + rng.rand(pop)) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter scaled by smaller fraction than original\n        jitter_scale = 0.3 * (ub - lb) / max(1.0, np.sqrt(self.dim))\n        X += (rng.rand(pop, self.dim) - 0.5) * jitter_scale\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population (sequential)\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # SHADE memory for F and CR\n        M = max(1, min(self.M, 20))\n        memory_F = np.full(M, 0.5)\n        memory_CR = np.full(M, 0.5)\n        memory_pos = 0\n\n        # per-individual sigma (Gaussian step-size), relative to range_mean\n        sigma = np.full(pop, max(1e-12, self.initial_step_frac * range_mean))\n        sigma_min = max(1e-12, self.sigma_min_frac * range_mean)\n        sigma_max = max(1e-12, self.sigma_max_frac * range_mean)\n\n        # success history for principal direction\n        success_steps = []\n\n        # reflect-then-clamp bounds handler\n        def reflect_then_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # tracking\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n        gen = 0\n        gens_since_improve = 0\n\n        # parameters for SHADE update accumulation\n        successful_Fs = []\n        successful_CRs = []\n        successful_ws = []\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # elite pool selection (rank-based)\n            order = np.argsort(f)\n            pnum = max(2, int(np.ceil(self.elite_frac * pop)))\n            elite_idx = order[:pnum]\n\n            # prepare per-generation lists\n            succ_F_gen = []\n            succ_CR_gen = []\n            succ_w_gen = []  # weights for Lehmer mean (based on improvement magnitude)\n\n            # process individuals in random order\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                # pick memory slot\n                r_mem = rng.randint(M)\n                mu_F = memory_F[r_mem]\n                mu_CR = memory_CR[r_mem]\n\n                # sample F from Cauchy (as in SHADE), retry until valid, fallback to mu_F\n                for _ in range(10):\n                    F = mu_F + 0.1 * rng.standard_cauchy()\n                    if np.isfinite(F) and F > 0:\n                        break\n                if not np.isfinite(F) or F <= 0:\n                    F = mu_F\n                F = float(np.clip(F, self.F_min, self.F_max))\n\n                # sample CR from normal around mu_CR\n                CR = float(np.clip(rng.normal(mu_CR, 0.1), 0.0, 1.0))\n\n                # choose mutation: rand/1 with prob strategy_mix_prob, else current-to-elite/1 + gaussian noise\n                if rng.rand() < self.strategy_mix_prob:\n                    # rand/1\n                    pool = [j for j in range(pop) if j != ii]\n                    if len(pool) < 3:\n                        r1 = r2 = r3 = ii\n                    else:\n                        r1, r2, r3 = rng.choice(pool, size=3, replace=False)\n                    vi = X[r1] + F * (X[r2] - X[r3])\n                    # add small Gaussian perturbation scaled by sigma\n                    vi = vi + rng.randn(self.dim) * (0.5 * sigma[ii])\n                else:\n                    # current-to-elite/1 variant\n                    pbest = int(rng.choice(elite_idx))\n                    pool = [j for j in range(pop) if j not in (ii, pbest)]\n                    if len(pool) < 2:\n                        r1 = r2 = ii\n                    else:\n                        r1, r2 = rng.choice(pool, size=2, replace=False)\n                    xi = X[ii]\n                    xp = X[pbest]\n                    vi = xi + F * (xp - xi) + F * (X[r1] - X[r2])\n                    # add Gaussian perturbation (exploit/explore)\n                    vi = vi + rng.randn(self.dim) * sigma[ii]\n\n                # binomial crossover\n                jrand = rng.randint(self.dim)\n                mask = rng.rand(self.dim) < CR\n                mask[jrand] = True\n                trial = np.where(mask, vi, X[ii])\n                trial = reflect_then_clamp(trial)\n\n                if evals >= self.budget:\n                    break\n                fv = float(func(trial))\n                evals += 1\n\n                # selection\n                if fv <= f[ii]:\n                    # success: record step vector and update lists for memory update\n                    step_vec = trial - X[ii]\n                    if np.linalg.norm(step_vec) > 0:\n                        success_steps.append(step_vec.copy())\n                        if len(success_steps) > self.success_hist_len:\n                            success_steps.pop(0)\n                    X[ii] = trial\n                    prev_f = f[ii]\n                    f[ii] = fv\n\n                    # weight proportional to improvement magnitude (positive)\n                    w = max(1e-12, prev_f - fv)\n                    succ_w_gen.append(w)\n                    succ_F_gen.append(F)\n                    succ_CR_gen.append(CR)\n\n                    # adapt sigma (increase on success)\n                    sigma[ii] = min(sigma_max, sigma[ii] * self.sigma_increase)\n\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = trial.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # failure: shrink sigma\n                    sigma[ii] = max(sigma_min, sigma[ii] * self.sigma_decrease)\n\n            # update SHADE memory if we have successes\n            if len(succ_F_gen) > 0:\n                succ_F_gen = np.asarray(succ_F_gen, dtype=float)\n                succ_CR_gen = np.asarray(succ_CR_gen, dtype=float)\n                succ_w_gen = np.asarray(succ_w_gen, dtype=float)\n                w_sum = np.sum(succ_w_gen)\n                if w_sum > 0:\n                    # Lehmer mean update for F: sum(w * F^2) / sum(w * F)\n                    new_F = np.sum(succ_w_gen * (succ_F_gen ** 2)) / np.sum(succ_w_gen * succ_F_gen)\n                    new_CR = np.sum(succ_w_gen * succ_CR_gen) / w_sum\n                    memory_F[memory_pos] = float(np.clip(new_F, self.F_min, self.F_max))\n                    memory_CR[memory_pos] = float(np.clip(new_CR, 0.0, 1.0))\n                    memory_pos = (memory_pos + 1) % M\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # Local directional search (budget-aware, trust-region style) triggered periodically or on stagnation\n            do_local = (gen % self.local_period == 0) or (gens_since_improve >= self.local_stagn_gen)\n            if do_local and (evals < self.budget):\n                remaining = self.budget - evals\n                if remaining <= 0:\n                    break\n\n                # trust radius and steps\n                trust_radius = 1.0  # multiplicative factor\n                step = max(1e-12, self.initial_step_frac * range_mean * trust_radius)\n                min_step = max(1e-12, self.min_step_frac * range_mean)\n                if gens_since_improve >= self.local_stagn_gen:\n                    step *= 2.0\n\n                local_improved = False\n                x_work = x_best.copy()\n                f_work = f_best\n\n                # compute principal direction from success_steps if available (PCA/SVD)\n                principal_dir = None\n                if len(success_steps) >= 3:\n                    S = np.vstack(success_steps)\n                    try:\n                        Sc = S - S.mean(axis=0, keepdims=True)\n                        u, svals, vh = np.linalg.svd(Sc, full_matrices=False)\n                        principal_dir = vh[0]\n                        nrm = np.linalg.norm(principal_dir)\n                        if nrm > 0:\n                            principal_dir = principal_dir / nrm\n                        else:\n                            principal_dir = None\n                    except Exception:\n                        principal_dir = None\n\n                # directional and coordinate probing loop\n                while step >= min_step and (self.budget - evals) > 0:\n                    moved = False\n\n                    # try principal direction first (if available)\n                    if principal_dir is not None and (self.budget - evals) > 0:\n                        for sign in (+1.0, -1.0):\n                            if evals >= self.budget:\n                                break\n                            x_try = x_work + sign * step * principal_dir\n                            x_try = reflect_then_clamp(x_try)\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                # opportunistic extra probe same direction (expand)\n                                if evals < self.budget:\n                                    x_try2 = x_try + sign * step * principal_dir\n                                    x_try2 = reflect_then_clamp(x_try2)\n                                    fv2 = float(func(x_try2))\n                                    evals += 1\n                                    if fv2 < fv:\n                                        x_try, fv = x_try2, fv2\n                                        # expand trust radius\n                                        trust_radius = min(5.0, trust_radius * 1.2)\n                                        step = max(min_step, step * 1.2)\n                                # accept\n                                step_vec = x_try - x_work\n                                if np.linalg.norm(step_vec) > 0:\n                                    success_steps.append(step_vec.copy())\n                                    if len(success_steps) > self.success_hist_len:\n                                        success_steps.pop(0)\n                                x_work = x_try\n                                f_work = fv\n                                moved = True\n                                local_improved = True\n                                # update global best\n                                if f_work < f_best:\n                                    f_best = f_work\n                                    x_best = x_work.copy()\n                                    gens_since_improve = 0\n                                break\n\n                    # anisotropic coordinate probes (pattern search style)\n                    if (self.budget - evals) <= 0:\n                        break\n                    for d in range(self.dim):\n                        if evals >= self.budget:\n                            break\n                        # try plus direction\n                        x_try = x_work.copy()\n                        x_try[d] += step\n                        x_try = reflect_then_clamp(x_try)\n                        # if no change due to bounds reflect, also try minus\n                        if np.allclose(x_try, x_work):\n                            x_try = x_work.copy()\n                            x_try[d] -= step\n                            x_try = reflect_then_clamp(x_try)\n                        fv = float(func(x_try))\n                        evals += 1\n                        if fv < f_work:\n                            # opportunistic extra probe further in same sense\n                            if evals < self.budget:\n                                delta_dir = np.sign(x_try[d] - x_work[d]) if not np.isclose(x_try[d], x_work[d]) else 1.0\n                                x_try2 = x_try.copy()\n                                x_try2[d] += delta_dir * step\n                                x_try2 = reflect_then_clamp(x_try2)\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < fv:\n                                    x_try, fv = x_try2, fv2\n                                    trust_radius = min(5.0, trust_radius * 1.1)\n                                    step = max(min_step, step * 1.1)\n                            step_vec = x_try - x_work\n                            if np.linalg.norm(step_vec) > 0:\n                                success_steps.append(step_vec.copy())\n                                if len(success_steps) > self.success_hist_len:\n                                    success_steps.pop(0)\n                            x_work = x_try\n                            f_work = fv\n                            moved = True\n                            local_improved = True\n                            if f_work < f_best:\n                                f_best = f_work\n                                x_best = x_work.copy()\n                                gens_since_improve = 0\n\n                    if not moved:\n                        # shrink step and trust radius\n                        step *= self.step_shrink\n                        trust_radius = max(1e-3, trust_radius * self.step_shrink)\n\n                # inject local improvement into population (replace worst)\n                if local_improved:\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_work.copy()\n                    f[worst_idx] = f_work\n                    # encourage sigma of replaced individual\n                    sigma[worst_idx] = np.clip(sigma[worst_idx] * 1.05, sigma_min, sigma_max)\n                    gens_since_improve = 0\n                else:\n                    # on prolonged stagnation, jitter a quarter of the population around best\n                    if gens_since_improve >= self.local_stagn_gen:\n                        quarter = max(1, pop // 4)\n                        for k in range(quarter):\n                            if evals >= self.budget:\n                                break\n                            jitter = rng.randn(self.dim) * (0.08 * (ub - lb))\n                            newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                            fv = float(func(newx))\n                            evals += 1\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = newx\n                            f[worst_idx] = fv\n                            sigma[worst_idx] = np.clip(0.5 * sigma[worst_idx], sigma_min, sigma_max)\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = newx.copy()\n                                gens_since_improve = 0\n\n            # sync best from population (safety)\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finish\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm RAMES_GT scored 0.305 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "bb3480f9-49d6-486a-8da6-7beaf8ccece9", "operator": null, "metadata": {"aucs": [0.20223723468814703, 0.14955052474067343, 0.686370393849776, 0.1834360121973635, 0.2471769450350889, 0.8205599795735434, 0.2209844692960018, 0.17435118057605015, 0.18770851657350618, 0.17875522703700686]}, "task_prompt": ""}
{"id": "c1973829-b73d-41d2-8b88-bb434404d55e", "fitness": 0.30751886799568623, "name": "CovarianceLevyEnsemble", "description": "The Covariance-Lévy Ensemble uses a small stratified population (Latin‑hypercube per dimension) and strict budget-aware sequential evaluations with reflect‑then‑clamp boundary handling to keep all candidates in the [-5,5] box. It mixes four complementary operators (differential‑like move toward the best, eigen‑direction Lévy hops along principal axes estimated from a short success‑step archive, a diagonal quadratic local model fit around the best, and uniform local probes) and chooses operators by a softmax‑ish weighting (op_weights) that is updated exponentially by success rewards and small penalties on failures (operator_decay, operator_lr, success_hist_len control adaptation speed and memory). Heavy‑tailed exploration is realized by Cauchy/Lévy hops scaled by estimated eigenvalues (levy_scale) while exploitation uses a differential factor (diff_F) and opportunistic extra probing along successful directions; local model fitting regularizes via least squares and clamps stationary steps. Practical safeguards include small population relative to budget, short success history for fast principal‑axis estimation, jittered partial restarts on stagnation, and explicit budget enforcement so no extra function calls occur.", "code": "import numpy as np\n\nclass CovarianceLevyEnsemble:\n    \"\"\"\n    Covariance-Lévy Ensemble (CLE)\n\n    Key ideas:\n    - Small quasi-uniform initial population (stratified per-dimension) inside given bounds.\n    - Maintain a short success-step archive to estimate a local covariance / principal axes.\n    - Mix several operators via an adaptive bandit (softmax) weighting:\n        1) Differential-like exploitation (from individual toward best + difference noise)\n        2) Eigen-direction Lévy hops (heavy-tailed exploration along principal axes)\n        3) Local diagonal-quadratic model step (attempt a stationary point of a fitted diagonal quadratic)\n        4) Uniform local probe around best (small random restart / diversification)\n    - Operators are credited on success; weights are updated with exponential decay.\n    - Opportunistic extra probe along the same direction after an improvement (budget permitting).\n    - Reflect-then-clamp bounds handling (mirroring).\n    - Budget-aware: never exceeds self.budget calls to func.\n    - Designed to be robust on bounded noiseless continuous problems (BBOB-like).\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop=None,\n                 success_hist_len=24,\n                 init_step_frac=0.25,\n                 levy_scale=0.8,\n                 levy_prob=0.3,\n                 diff_F=0.6,\n                 operator_decay=0.9,\n                 operator_lr=1.0,\n                 stagnation_restart_gen=40,\n                 stagnation_jitter_frac=0.08,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        # adaptive/population parameters\n        self.pop = pop if pop is not None else max(8, int(3 + 1.5 * np.log(max(2, dim))))\n        self.success_hist_len = int(success_hist_len)\n        self.init_step_frac = float(init_step_frac)\n        self.levy_scale = float(levy_scale)\n        self.levy_prob = float(levy_prob)\n        self.diff_F = float(diff_F)\n        self.operator_decay = float(operator_decay)\n        self.operator_lr = float(operator_lr)\n        self.stagnation_restart_gen = int(stagnation_restart_gen)\n        self.stagnation_jitter_frac = float(stagnation_jitter_frac)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds (use provided bounds; BBOB default is [-5,5])\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # enforce sensible pop relative to budget\n        pop = int(min(self.pop, max(2, self.budget)))\n        pop = max(2, pop)\n\n        evals = 0\n\n        # --- initialization: stratified per-dimension (Latin-hypercube style) with jitter\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + rng.rand(pop)) / float(pop)\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population (sequentially)\n        f = np.empty(pop, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        # if budget exhausted early\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # bookkeeping\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        # short success history (step vectors)\n        success_steps = []\n\n        # operator definitions: 0=diff-like, 1=eigen-levy, 2=diag-quadratic, 3=uniform-local\n        n_ops = 4\n        # operator weights (positive scalars), will be updated by success rewards\n        op_weights = np.ones(n_ops, dtype=float)\n\n        gens_since_improve = 0\n        gen = 0\n\n        # helpers\n        def reflect_then_clamp(x):\n            # reflect (mirror) repeatedly until in bounds then clamp for numeric stability\n            xr = x.copy()\n            # reflect lower\n            low_mask = xr < lb\n            if np.any(low_mask):\n                xr[low_mask] = lb[low_mask] + (lb[low_mask] - xr[low_mask])\n            high_mask = xr > ub\n            if np.any(high_mask):\n                xr[high_mask] = ub[high_mask] - (xr[high_mask] - ub[high_mask])\n            # after one reflect, clamp\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        def sample_cauchy(size=1):\n            # standard Cauchy via inverse CDF of uniform (heavy-tailed)\n            u = rng.rand(size)\n            return np.tan(np.pi * (u - 0.5))\n\n        # function to compute principal axes (eigenvectors) from success_steps (covariance)\n        def compute_principal_axes(steps, k_max= min(6, self.dim)):\n            if len(steps) < 2:\n                return None, None\n            S = np.vstack(steps)\n            # center rows\n            S -= S.mean(axis=0, keepdims=True)\n            # compute covariance-like matrix (small memory)\n            C = np.dot(S.T, S) / max(1.0, S.shape[0] - 1.0)\n            try:\n                # eigen decomposition (symmetric)\n                vals, vecs = np.linalg.eigh(C)\n                # sort descending\n                order = np.argsort(vals)[::-1]\n                vals = vals[order]\n                vecs = vecs[:, order]\n                return vals[:k_max], vecs[:, :k_max]\n            except Exception:\n                return None, None\n\n        # diagonal-quadratic fit around center x0 using nearby points:\n        # fit f ~ a + g^T dx + 0.5 * q^T (dx**2) where dx = x - x0\n        def fit_diagonal_quadratic(center_x, X_pool, f_pool):\n            # collect up to m points\n            m_needed = min(len(X_pool), 1 + 2 * self.dim)\n            if m_needed < (1 + 2 * self.dim) // 2:\n                # not enough points for a stable fit, return None\n                return None, None\n            # compute distances to center\n            dxs = X_pool - center_x\n            dists = np.linalg.norm(dxs, axis=1)\n            order = np.argsort(dists)[:m_needed]\n            Xs = dxs[order]  # shape (m, dim)\n            ys = f_pool[order] - float(f_best)  # fit relative to f_best\n            # design matrix: [1, dx_i (dim), 0.5 * dx_i^2 (dim)]\n            # parameters: a, g (dim), q (dim)  => p = 1 + 2*dim\n            m = Xs.shape[0]\n            A = np.zeros((m, 1 + 2 * self.dim), dtype=float)\n            A[:, 0] = 1.0\n            A[:, 1:1 + self.dim] = Xs\n            A[:, 1 + self.dim:] = 0.5 * (Xs ** 2)\n            # solve least squares with small regularization\n            try:\n                reg = 1e-8 * np.eye(1 + 2 * self.dim)\n                theta, *_ = np.linalg.lstsq(A, ys, rcond=None)\n                a = theta[0]\n                g = theta[1:1 + self.dim]\n                q = theta[1 + self.dim:]\n                return g, q\n            except Exception:\n                return None, None\n\n        # main loop: generate candidates until budget exhausted\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # compute principal axes from success steps (if any)\n            eig_vals, eig_vecs = compute_principal_axes(success_steps, k_max=min(6, self.dim))\n\n            # operator probabilities via softmax-ish normalization\n            w = op_weights - op_weights.min() + 1e-8  # keep positive\n            op_probs = w / (w.sum() + 1e-12)\n\n            # iterate through population in random order\n            order = rng.permutation(pop)\n            for idx in order:\n                if evals >= self.budget:\n                    break\n\n                # choose operator (roulette by op_probs)\n                r = rng.rand()\n                cum = 0.0\n                op = 0\n                for o in range(n_ops):\n                    cum += op_probs[o]\n                    if r <= cum:\n                        op = o\n                        break\n\n                x = X[idx].copy()\n\n                # base candidate depends on operator\n                cand = x.copy()\n                cand_dir = None\n                used_info = None  # store info for opportunistic probing (sign/direction/axis)\n\n                if op == 0:\n                    # Differential-like exploitation: move towards best plus small difference noise\n                    # cand = x + F*(x_best - x) + F*noise_diff\n                    noise_idx = rng.choice([j for j in range(pop) if j != idx]) if pop > 1 else idx\n                    diff = X[noise_idx] - x\n                    cand = x + self.diff_F * (x_best - x) + 0.5 * self.diff_F * diff\n                    cand = reflect_then_clamp(cand)\n                    cand_dir = cand - x\n                    used_info = (\"diff\", cand_dir)\n\n                elif op == 1:\n                    # Eigen-direction Lévy hop: sample a principal axis, choose heavy-tailed length\n                    if eig_vecs is not None:\n                        k_axes = eig_vecs.shape[1]\n                        j = rng.randint(k_axes)\n                        axis = eig_vecs[:, j]\n                        # scale by sqrt(eigval) if available\n                        scale = np.sqrt(max(1e-12, eig_vals[j])) if eig_vals is not None else 1.0\n                        # cauchy for heavy tail\n                        c = sample_cauchy(size=1)[0]\n                        step = self.levy_scale * scale * c * (ub - lb).mean()\n                        cand = x + step * axis\n                        cand = reflect_then_clamp(cand)\n                        cand_dir = cand - x\n                        used_info = (\"levy\", axis, step)\n                    else:\n                        # fallback to uniform local probe\n                        cand = x + (rng.rand(self.dim) - 0.5) * self.init_step_frac * (ub - lb)\n                        cand = reflect_then_clamp(cand)\n                        cand_dir = cand - x\n                        used_info = (\"fallback\", cand_dir)\n\n                elif op == 2:\n                    # Diagonal-quadratic local model attempt (centered at best)\n                    # Fit a diagonal quadratic to a neighborhood and compute stationary point dx = -g / q\n                    g, q = fit_diagonal_quadratic(x_best, X, f)\n                    if g is not None and q is not None:\n                        # avoid tiny / zero q components\n                        q_safe = q.copy()\n                        small_mask = np.abs(q_safe) < 1e-8\n                        q_safe[small_mask] = np.sign(q_safe[small_mask]) * 1e-8 + 1e-8\n                        dx = -g / q_safe\n                        # clamp step size to a fraction of box range\n                        max_step = (ub - lb) * 0.5 * self.init_step_frac\n                        dx = np.maximum(np.minimum(dx, max_step), -max_step)\n                        cand = x_best + dx\n                        cand = reflect_then_clamp(cand)\n                        cand_dir = cand - x\n                        used_info = (\"quad\", dx)\n                    else:\n                        # fallback to small perturbation around best\n                        cand = x_best + (rng.randn(self.dim) * 0.02) * (ub - lb)\n                        cand = reflect_then_clamp(cand)\n                        cand_dir = cand - x\n                        used_info = (\"quad_fallback\", cand_dir)\n\n                elif op == 3:\n                    # uniform local probe around best (diversification / mild restart)\n                    radius = self.init_step_frac * (ub - lb) * (0.5 + 0.5 * rng.rand())\n                    cand = x_best + (rng.rand(self.dim) - 0.5) * 2.0 * radius\n                    cand = reflect_then_clamp(cand)\n                    cand_dir = cand - x\n                    used_info = (\"local\", cand_dir)\n\n                # Evaluate candidate if budget allows\n                if evals >= self.budget:\n                    break\n                fcand = float(func(cand))\n                evals += 1\n\n                # Selection: replace if better\n                if fcand < f[idx]:\n                    # accept\n                    # credit operator with reward proportional to improvement (log-scaled to avoid huge swings)\n                    reward = max(1e-12, (f[idx] - fcand) / (abs(f_best) + 1.0))\n                    # exponential update\n                    op_weights[op] = op_weights[op] * self.operator_decay + self.operator_lr * reward\n                    # add step to success history\n                    step_vec = cand - X[idx]\n                    if np.linalg.norm(step_vec) > 0:\n                        success_steps.append(step_vec.copy())\n                        if len(success_steps) > self.success_hist_len:\n                            success_steps.pop(0)\n                    X[idx] = cand\n                    f[idx] = fcand\n                    # opportunistic extra probe: try to continue along same direction if we used one\n                    if used_info is not None and evals < self.budget:\n                        # try one additional probe further along same vector (small multiplier)\n                        if cand_dir is not None and np.linalg.norm(cand_dir) > 0:\n                            mult = 1.0 + 0.5 * rng.rand()\n                            x_try = cand + mult * cand_dir\n                            x_try = reflect_then_clamp(x_try)\n                            if evals < self.budget:\n                                fv2 = float(func(x_try))\n                                evals += 1\n                                if fv2 < f[idx]:\n                                    # accept further\n                                    step_vec2 = x_try - cand\n                                    if np.linalg.norm(step_vec2) > 0:\n                                        success_steps.append(step_vec2.copy())\n                                        if len(success_steps) > self.success_hist_len:\n                                            success_steps.pop(0)\n                                    X[idx] = x_try\n                                    f[idx] = fv2\n                    # update global best\n                    if f[idx] < f_best:\n                        f_best = float(f[idx])\n                        x_best = X[idx].copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # small negative credit for operator (discourage repeated failures)\n                    loss = max(1e-12, (fcand - f[idx]) / (abs(f[idx]) + 1.0))\n                    op_weights[op] = op_weights[op] * self.operator_decay + 0.001 * (-loss + 1e-6)\n                    # keep op_weights positive\n                    op_weights[op] = max(op_weights[op], 1e-8)\n\n            # generation end: stagnation tracking\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # stagnation-triggered mild jittered partial restart\n            if gens_since_improve >= self.stagnation_restart_gen and evals < self.budget:\n                gens_since_improve = 0\n                half = max(1, pop // 2)\n                for k in range(half):\n                    if evals >= self.budget:\n                        break\n                    noise = rng.randn(self.dim) * (self.stagnation_jitter_frac * (ub - lb))\n                    newx = reflect_then_clamp(x_best + noise)\n                    fv = float(func(newx))\n                    evals += 1\n                    # replace worst\n                    worst = int(np.argmax(f))\n                    X[worst] = newx\n                    f[worst] = fv\n                    if fv < f_best:\n                        f_best = float(fv)\n                        x_best = newx.copy()\n\n            # maintain best from current population (synchronization)\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CovarianceLevyEnsemble scored 0.308 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "bb3480f9-49d6-486a-8da6-7beaf8ccece9", "operator": null, "metadata": {"aucs": [0.14303638646742922, 0.1497007362823587, 0.3777215556701258, 0.7888968586014342, 0.22875927049385136, 0.42812952689822426, 0.27300545846805213, 0.23834233976433772, 0.3068500190841993, 0.14074652822684952]}, "task_prompt": ""}
{"id": "5aec721e-a578-46c1-8f8e-b6e75356db30", "fitness": 0.4289399996803976, "name": "EnsembleDirectionalAdaptiveSearch", "description": "EnsembleDirectionalAdaptiveSearch runs a small ensemble (sqrt-based pop sizing) initialized quasi-uniformly with jitter and maintains per-agent adaptive step scales (sigma_init ≈ 0.15·range, clipped to [1e-6,5], multiplicatively adapted by tau_up=1.18 / tau_down=0.85) to balance exploration and exploitation. Exploitation combines p-best directed moves (p_frac=0.25) with a PCA-like principal direction extracted from a recent success history (success_hist_len=16), plus a small random differential and mild anisotropic per-dimension scaling (1+0.05·N). Exploration is driven by occasional heavy‑tailed Cauchy/Lévy jumps (levy_prob=0.08, normalized to avoid extreme jumps) and opportunistic geometric expansion/contraction line-search along accepted step directions (expand_factor=1.8, contract_factor=0.6), while reflect_then_clamp enforces bounds. Periodic local PCA/coordinate probes (local_period=12), injecting local improvements into the worst member, plus stagnation-triggered jittered partial restarts, keep diversity and allow recovery from local traps.", "code": "import numpy as np\n\nclass EnsembleDirectionalAdaptiveSearch:\n    \"\"\"\n    EnsembleDirectionalAdaptiveSearch (EDAS)\n\n    Main idea (one-line): Maintain a small ensemble of candidate solutions with\n    per-agent adaptive step scales, combine exploitation along PCA/principal\n    difference directions with occasional heavy-tailed Lévy jumps, and perform\n    cheap opportunistic line-search (expansion/contraction) along successful\n    directions before injecting improved points into the ensemble.\n\n    Main tunable parameters (defaults chosen to differ from the provided algorithm):\n      - pop: ensemble size (default uses max(8, int(2 + 2*sqrt(dim))))\n      - p_frac: top-fraction used as p-best pool (default 0.25)\n      - tau_up, tau_down: multiplicative adaptation rates for per-agent sigma (0.18, 0.85)\n      - sigma_init: initial step scale relative to bound range (0.15)\n      - sigma_min, sigma_max: limits on sigma (1e-6, 5.0)\n      - levy_prob: probability to take a Levy (Cauchy) jump for exploration (0.08)\n      - success_hist_len: number of recent successful step vectors for PCA (16)\n      - expand_factor, contract_factor: line-search expansion/contraction (1.8, 0.6)\n      - local_period: perform consolidated PCA/local procedures every local_period gens (default 12)\n      - stagn_restart_gen: if no improvement for this many gens, jitter half population (default 30)\n\n    Differences from provided algorithm:\n      - Different population sizing rule (sqrt-based), different sigma adaptation (multiplicative up/down),\n        different mixing probabilities, uses Cauchy (approximate Levy) heavy-tail jumps, and an\n        opportunistic expansion line-search (geometric expansion) instead of fixed small-step shrinking.\n    \"\"\"\n\n    def __init__(self, budget, dim,\n                 pop=None,\n                 p_frac=0.25,\n                 tau_up=1.18, tau_down=0.85,\n                 sigma_init=0.15, sigma_min=1e-6, sigma_max=5.0,\n                 levy_prob=0.08,\n                 success_hist_len=16,\n                 expand_factor=1.8, contract_factor=0.6,\n                 local_period=12, stagn_restart_gen=30,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop = int(pop) if pop is not None else max(8, int(2 + 2 * np.sqrt(max(1, dim))))\n        self.p_frac = float(p_frac)\n        self.tau_up = float(tau_up)\n        self.tau_down = float(tau_down)\n        self.sigma_init = float(sigma_init)\n        self.sigma_min = float(sigma_min)\n        self.sigma_max = float(sigma_max)\n        self.levy_prob = float(levy_prob)\n        self.success_hist_len = int(success_hist_len)\n        self.expand_factor = float(expand_factor)\n        self.contract_factor = float(contract_factor)\n        self.local_period = int(local_period)\n        self.stagn_restart_gen = int(stagn_restart_gen)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds (Many Affine BBOB uses -5..5 typically, but use func.bounds if provided)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # ensure pop does not exceed budget or be too small\n        pop = min(self.pop, max(2, self.budget))\n        pop = max(2, pop)\n\n        evals = 0\n\n        # quasi-uniform (per-dim stratified) initialization similar idea but different sizing\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # small jitter\n        jitter_scale = 0.3 * (ub - lb) / max(1.0, np.sqrt(self.dim))\n        X += (rng.randn(pop, self.dim) * jitter_scale)\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population (sequential)\n        f = np.empty(pop, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-agent adaptive sigma (step size), multiplicative scheme\n        bound_range = np.mean(ub - lb)\n        sigma = np.full(pop, self.sigma_init * bound_range, dtype=float)\n        sigma = np.clip(sigma, self.sigma_min, self.sigma_max)\n\n        # tracking\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n        gen = 0\n        gens_since_improve = 0\n\n        # success history for PCA-like principal direction\n        success_steps = []\n\n        def reflect_then_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_this_gen = False\n\n            order = rng.permutation(pop)\n            # p-best pool indices (top p_frac of population)\n            pcount = max(2, int(np.ceil(self.p_frac * pop)))\n            p_pool = np.argsort(f)[:pcount]\n\n            for ii in order:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fxi = f[ii]\n\n                # decide exploration vs exploitation\n                if rng.rand() < self.levy_prob:\n                    # heavy-tailed exploration: Cauchy (approximate Levy)\n                    step_dir = rng.standard_cauchy(size=self.dim)\n                    # normalize direction to avoid enormous jumps, scale by sigma\n                    norm = np.linalg.norm(step_dir)\n                    if norm == 0:\n                        step_dir = rng.randn(self.dim)\n                        norm = np.linalg.norm(step_dir)\n                    step_dir = step_dir / norm\n                    step_len = abs(rng.standard_cauchy())  # heavy-tailed length\n                    step = xi + step_dir * (step_len * sigma[ii])\n                else:\n                    # directed exploitation: combine (pbest - xi), PCA principal direction from history,\n                    # and a small random difference vector\n                    # choose a pbest\n                    pidx = int(rng.choice(p_pool))\n                    pvec = X[pidx] - xi\n                    # random difference vector from two distinct population members\n                    idxs = [j for j in range(pop) if j != ii]\n                    if len(idxs) >= 2:\n                        r1, r2 = rng.choice(idxs, size=2, replace=False)\n                        diff = X[r1] - X[r2]\n                    else:\n                        diff = rng.randn(self.dim) * (ub - lb) * 1e-3\n\n                    # principal direction from recent successes (if available)\n                    principal = None\n                    if len(success_steps) >= 2:\n                        S = np.vstack(success_steps)\n                        try:\n                            S_centered = S - S.mean(axis=0, keepdims=True)\n                            # compute first right-singular vector\n                            u, svals, vh = np.linalg.svd(S_centered, full_matrices=False)\n                            principal = vh[0]\n                            nrm = np.linalg.norm(principal)\n                            if nrm > 0:\n                                principal = principal / nrm\n                            else:\n                                principal = None\n                        except Exception:\n                            principal = None\n\n                    # combine with coefficients (weights tuned differently)\n                    w_p = 0.6\n                    w_pr = 0.25\n                    w_r = 0.15\n                    combined = w_p * pvec\n                    if principal is not None:\n                        combined = combined + w_pr * principal * np.linalg.norm(pvec)\n                    combined = combined + w_r * diff * 0.3\n\n                    # if combined is tiny, use random direction\n                    normc = np.linalg.norm(combined)\n                    if normc < 1e-12:\n                        combined = rng.randn(self.dim)\n                        normc = np.linalg.norm(combined)\n                    direction = combined / normc\n\n                    # anisotropic scaling: small per-dim random factor to encourage exploration\n                    anis = 1.0 + 0.05 * rng.randn(self.dim)\n                    step = xi + direction * (sigma[ii] * np.mean(anis))\n\n                # reflect and clamp, evaluate\n                xt = reflect_then_clamp(step)\n                if evals >= self.budget:\n                    break\n                ft = float(func(xt))\n                evals += 1\n\n                accepted = False\n                used_dir = None\n                if ft < fxi:\n                    # success: record step, accept, and try opportunistic geometric expansion along the same direction\n                    step_vec = xt - xi\n                    if np.linalg.norm(step_vec) > 0:\n                        success_steps.append(step_vec.copy())\n                        if len(success_steps) > self.success_hist_len:\n                            success_steps.pop(0)\n                    X[ii] = xt\n                    f[ii] = ft\n                    accepted = True\n                    used_dir = step_vec.copy()\n                    # opportunistic expansion: try to expand along the accepted direction\n                    # we will multiply step length by expand_factor while improvement occurs\n                    base_dir = used_dir\n                    cur_x = X[ii].copy()\n                    cur_f = f[ii]\n                    expand_step = 1.0\n                    while evals < self.budget:\n                        trial = cur_x + base_dir * (expand_step * (self.expand_factor - 1.0))\n                        trial = reflect_then_clamp(trial)\n                        ft2 = float(func(trial))\n                        evals += 1\n                        if ft2 < cur_f:\n                            # accept and continue expanding\n                            step_vec2 = trial - cur_x\n                            if np.linalg.norm(step_vec2) > 0:\n                                success_steps.append(step_vec2.copy())\n                                if len(success_steps) > self.success_hist_len:\n                                    success_steps.pop(0)\n                            cur_x = trial\n                            cur_f = ft2\n                            X[ii] = cur_x\n                            f[ii] = cur_f\n                            # grow expand_step multiplicatively\n                            expand_step *= self.expand_factor\n                        else:\n                            # try a contraction probe in the same direction (shorter step)\n                            trial2 = X[ii] + base_dir * (self.contract_factor)\n                            trial2 = reflect_then_clamp(trial2)\n                            if evals >= self.budget:\n                                break\n                            ft3 = float(func(trial2))\n                            evals += 1\n                            if ft3 < f[ii]:\n                                step_vec3 = trial2 - X[ii]\n                                if np.linalg.norm(step_vec3) > 0:\n                                    success_steps.append(step_vec3.copy())\n                                    if len(success_steps) > self.success_hist_len:\n                                        success_steps.pop(0)\n                                X[ii] = trial2\n                                f[ii] = ft3\n                            break  # stop expansion loop\n\n                    # update best if improved\n                    if f[ii] < f_best:\n                        f_best = float(f[ii])\n                        x_best = X[ii].copy()\n                        improved_this_gen = True\n                        gens_since_improve = 0\n                else:\n                    # if not accepted, consider a tiny coordinate probe (one-dim) opportunistically\n                    # use small fraction of sigma in one random dimension\n                    d = rng.randint(self.dim)\n                    probe = xi.copy()\n                    probe[d] = probe[d] + 0.5 * sigma[ii] * (rng.rand() * 2.0 - 1.0)\n                    probe = reflect_then_clamp(probe)\n                    if evals < self.budget:\n                        fp = float(func(probe))\n                        evals += 1\n                        if fp < fxi:\n                            # accept probe\n                            step_vec = probe - xi\n                            if np.linalg.norm(step_vec) > 0:\n                                success_steps.append(step_vec.copy())\n                                if len(success_steps) > self.success_hist_len:\n                                    success_steps.pop(0)\n                            X[ii] = probe\n                            f[ii] = fp\n                            accepted = True\n                            used_dir = probe - xi\n                            if f[ii] < f_best:\n                                f_best = float(f[ii])\n                                x_best = X[ii].copy()\n                                improved_this_gen = True\n                                gens_since_improve = 0\n\n                # adapt sigma multiplicatively based on success (simple up/down rule)\n                if accepted:\n                    sigma[ii] = min(self.sigma_max, sigma[ii] * self.tau_up)\n                else:\n                    sigma[ii] = max(self.sigma_min, sigma[ii] * self.tau_down)\n\n            # after loop over population\n            if not improved_this_gen:\n                gens_since_improve += 1\n\n            # periodic consolidated PCA and small local coordinated probes around current best\n            if (gen % self.local_period == 0) or (gens_since_improve >= self.stagn_restart_gen // 2):\n                # compute principal direction from success_steps\n                principal = None\n                if len(success_steps) >= 2:\n                    S = np.vstack(success_steps)\n                    try:\n                        S_centered = S - S.mean(axis=0, keepdims=True)\n                        u, svals, vh = np.linalg.svd(S_centered, full_matrices=False)\n                        principal = vh[0]\n                        nrm = np.linalg.norm(principal)\n                        if nrm > 0:\n                            principal = principal / nrm\n                        else:\n                            principal = None\n                    except Exception:\n                        principal = None\n\n                # small targeted probes along principal direction and coordinate axes\n                if evals < self.budget:\n                    local_step = max(1e-12, 0.08 * bound_range)\n                    if gens_since_improve >= (self.stagn_restart_gen // 2):\n                        local_step *= 1.6\n\n                    xw = x_best.copy()\n                    fw = f_best\n\n                    # try principal direction both signs\n                    if principal is not None:\n                        for sign in (+1.0, -1.0):\n                            if evals >= self.budget:\n                                break\n                            xt = xw + sign * local_step * principal\n                            xt = reflect_then_clamp(xt)\n                            ft = float(func(xt))\n                            evals += 1\n                            if ft < fw:\n                                step_vec = xt - xw\n                                if np.linalg.norm(step_vec) > 0:\n                                    success_steps.append(step_vec.copy())\n                                    if len(success_steps) > self.success_hist_len:\n                                        success_steps.pop(0)\n                                xw = xt\n                                fw = ft\n                                if fw < f_best:\n                                    f_best = fw\n                                    x_best = xw.copy()\n                                    gens_since_improve = 0\n\n                    # coordinate probes\n                    for d in range(self.dim):\n                        if evals >= self.budget:\n                            break\n                        xt = xw.copy()\n                        xt[d] += local_step\n                        xt = reflect_then_clamp(xt)\n                        ft = float(func(xt))\n                        evals += 1\n                        if ft < fw:\n                            step_vec = xt - xw\n                            if np.linalg.norm(step_vec) > 0:\n                                success_steps.append(step_vec.copy())\n                                if len(success_steps) > self.success_hist_len:\n                                    success_steps.pop(0)\n                            xw = xt\n                            fw = ft\n                            if fw < f_best:\n                                f_best = fw\n                                x_best = xw.copy()\n                                gens_since_improve = 0\n\n                    # inject any local improvement into worst member\n                    if fw < np.max(f):\n                        worst_idx = int(np.argmax(f))\n                        X[worst_idx] = xw.copy()\n                        f[worst_idx] = fw\n\n            # stagnation-triggered jittered restarts (mild)\n            if gens_since_improve >= self.stagn_restart_gen and evals < self.budget:\n                half = max(1, pop // 2)\n                for k in range(half):\n                    if evals >= self.budget:\n                        break\n                    jitter = rng.randn(self.dim) * (0.08 * (ub - lb))\n                    newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                    fv = float(func(newx))\n                    evals += 1\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = newx\n                    f[worst_idx] = fv\n                    # reset sigma a bit for restarted individuals\n                    sigma[worst_idx] = max(self.sigma_min, min(self.sigma_max, 0.6 * sigma[worst_idx] + 0.4 * (self.sigma_init * bound_range)))\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = newx.copy()\n                        gens_since_improve = 0\n                # small decay of recorded successes to avoid stale directions dominating\n                if len(success_steps) > 0:\n                    # keep only last half\n                    keep = max(1, len(success_steps) // 2)\n                    success_steps = success_steps[-keep:]\n                gens_since_improve = 0\n\n            # sync best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finish\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EnsembleDirectionalAdaptiveSearch scored 0.429 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "bb3480f9-49d6-486a-8da6-7beaf8ccece9", "operator": null, "metadata": {"aucs": [0.1174201153825436, 0.1681219330305994, 0.9347550593039645, 0.9497859751671822, 0.12524591996575618, 0.9476539157671302, 0.24884696128153216, 0.4316410542006922, 0.23279042819115803, 0.1331386345134178]}, "task_prompt": ""}
{"id": "0c5ad497-95bc-4403-9040-a0a1158c04fb", "fitness": 0.5166710311881542, "name": "HybridAdaptiveDirectionalDE", "description": "The algorithm uses a small, quasi‑uniform stratified initialization (default pop ≈ max(12,4+3·log(dim))) with small jitter and a reflect‑then‑clamp boundary handler to cover the search box efficiently. The core is a DE loop with jDE‑style per‑individual F and CR adaptation, binomial crossover and a mixed mutation policy that favors current‑to‑pbest/1 (p_frac≈0.2) but occasionally does rand/1 (strategy_mix_prob≈0.12) to balance exploitation and exploration. It augments global DE with a short success history (success_steps) whose SVD gives a principal direction used for cheap directional line‑search probes and opportunistic extra probes, plus periodic anisotropic Hooke–Jeeves coordinate searches with geometric step shrinking (initial_step_frac≈0.18, step_shrink=0.5) for local refinement. Stagnation triggers injection of the local best into the population or mild jittered restarts of half the population, and every operation is strictly budget‑aware to never exceed the allotted function evaluations.", "code": "import numpy as np\n\nclass HybridAdaptiveDirectionalDE:\n    \"\"\"\n    HybridAdaptiveDirectionalDE\n\n    Key ideas:\n    - Quasi-uniform stratified initialization + small population for many generations.\n    - jDE-style per-individual F and CR adaptation.\n    - Strategy mixing: mostly current-to-pbest/1 with occasional rand/1 exploration.\n    - Maintain a short history of successful step vectors; use SVD principal direction\n      for cheap directional line-search probes (with opportunistic extra probes).\n    - Periodic anisotropic Hooke-Jeeves-style coordinate search with geometric shrinking.\n    - Inject local improvements by replacing the worst; mild jitter restarts on stagnation.\n    - Strict budget-awareness: never exceed self.budget calls to func.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 p_frac=0.2,\n                 tau1=0.1, tau2=0.1,\n                 F_min=0.05, F_max=0.9,\n                 strategy_mix_prob=0.12,\n                 pop_base=None,\n                 local_period=18, local_stagn_gen=28,\n                 initial_step_frac=0.18, min_step_frac=1e-5, step_shrink=0.5,\n                 success_hist_len=14, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.p_frac = float(p_frac)\n        self.tau1 = float(tau1)\n        self.tau2 = float(tau2)\n        self.F_min = float(F_min)\n        self.F_max = float(F_max)\n        self.strategy_mix_prob = float(strategy_mix_prob)\n        self.pop_base = pop_base\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.initial_step_frac = float(initial_step_frac)\n        self.min_step_frac = float(min_step_frac)\n        self.step_shrink = float(step_shrink)\n        self.success_hist_len = int(success_hist_len)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds (functions in this suite have bounds -5..5, but use given func.bounds)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size (small)\n        if self.pop_base is None:\n            pop = max(12, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # stratified quasi-uniform initialization per-dimension\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # small jitter to break symmetry\n        jitter_scale = 0.5 * (ub - lb) / max(1.0, self.dim)\n        X += (rng.rand(pop, self.dim) - 0.5) * jitter_scale\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        # early exit if budget exhausted\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-individual F and CR (jDE-like initialization)\n        F = np.clip(0.5 + 0.1 * rng.randn(pop), self.F_min, self.F_max)\n        CR = np.clip(rng.rand(pop), 0.0, 1.0)\n\n        # tracking best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n        gen = 0\n        gens_since_improve = 0\n\n        # success history for principal direction\n        success_steps = []\n\n        def reflect_then_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        pnum_min = max(2, int(np.ceil(self.p_frac * pop)))\n\n        # main optimization loop (generation by generation)\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            order = np.argsort(f)\n            p_pool = order[:max(pnum_min, 2)]\n\n            # iterate individuals in random order\n            for ii in rng.permutation(pop):\n                if evals >= self.budget:\n                    break\n\n                # jDE adaptation\n                if rng.rand() < self.tau1:\n                    F[ii] = np.clip(0.5 * (1.0 + 0.5 * rng.randn()), self.F_min, self.F_max)\n                if rng.rand() < self.tau2:\n                    CR[ii] = rng.rand()\n\n                # strategy mixing: mostly current-to-pbest/1, occasionally rand/1\n                if rng.rand() < self.strategy_mix_prob:\n                    # rand/1\n                    idxs_pool = [j for j in range(pop) if j != ii]\n                    if len(idxs_pool) < 3:\n                        r1 = r2 = r3 = ii\n                    else:\n                        r1, r2, r3 = rng.choice(idxs_pool, size=3, replace=False)\n                    vi = X[r1] + F[ii] * (X[r2] - X[r3])\n                else:\n                    # current-to-pbest/1\n                    pbest_idx = int(rng.choice(p_pool))\n                    idxs_pool = [j for j in range(pop) if j not in (ii, pbest_idx)]\n                    if len(idxs_pool) < 2:\n                        r1 = r2 = ii\n                    else:\n                        r1, r2 = rng.choice(idxs_pool, size=2, replace=False)\n                    xi = X[ii]\n                    xp = X[pbest_idx]\n                    xr1 = X[r1]\n                    xr2 = X[r2]\n                    vi = xi + F[ii] * (xp - xi) + F[ii] * (xr1 - xr2)\n\n                # binomial crossover\n                jrand = rng.randint(self.dim)\n                mask = rng.rand(self.dim) < CR[ii]\n                mask[jrand] = True\n                trial = np.where(mask, vi, X[ii])\n                trial = reflect_then_clamp(trial)\n\n                if evals >= self.budget:\n                    break\n                fv = float(func(trial))\n                evals += 1\n\n                # selection\n                if fv <= f[ii]:\n                    step_vec = trial - X[ii]\n                    if np.linalg.norm(step_vec) > 0:\n                        success_steps.append(step_vec.copy())\n                        if len(success_steps) > self.success_hist_len:\n                            success_steps.pop(0)\n                    X[ii] = trial\n                    f[ii] = fv\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = trial.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # Periodic / stagnation-triggered local refinement:\n            do_local = (gen % self.local_period == 0) or (gens_since_improve >= self.local_stagn_gen)\n            if do_local and (evals < self.budget):\n                remaining = self.budget - evals\n                if remaining <= 0:\n                    break\n\n                range_mean = np.mean(ub - lb)\n                step = max(1e-12, self.initial_step_frac * range_mean)\n                min_step = max(1e-12, self.min_step_frac * range_mean)\n                # if very stagnated, increase step to escape\n                if gens_since_improve >= self.local_stagn_gen:\n                    step *= 2.0\n\n                local_improved = False\n                x_work = x_best.copy()\n                f_work = f_best\n\n                # compute principal direction from success_steps (SVD on centered rows)\n                principal_dir = None\n                if len(success_steps) >= 2:\n                    S = np.vstack(success_steps)\n                    try:\n                        S_centered = S - S.mean(axis=0, keepdims=True)\n                        _, _, vh = np.linalg.svd(S_centered, full_matrices=False)\n                        principal_dir = vh[0]\n                        nrm = np.linalg.norm(principal_dir)\n                        if nrm > 0:\n                            principal_dir = principal_dir / nrm\n                        else:\n                            principal_dir = None\n                    except Exception:\n                        principal_dir = None\n\n                # directional line-search guided by principal_dir, with opportunistic extra probes\n                while step >= min_step and (self.budget - evals) > 0:\n                    moved = False\n\n                    # try principal direction first (both signs)\n                    if principal_dir is not None and (self.budget - evals) > 0:\n                        for sign in (+1.0, -1.0):\n                            if evals >= self.budget:\n                                break\n                            x_try = reflect_then_clamp(x_work + sign * step * principal_dir)\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                # opportunistic extra probe further in same sense\n                                if evals < self.budget:\n                                    x_try2 = reflect_then_clamp(x_try + sign * step * principal_dir)\n                                    fv2 = float(func(x_try2))\n                                    evals += 1\n                                    if fv2 < fv:\n                                        x_try, fv = x_try2, fv2\n                                step_vec = x_try - x_work\n                                if np.linalg.norm(step_vec) > 0:\n                                    success_steps.append(step_vec.copy())\n                                    if len(success_steps) > self.success_hist_len:\n                                        success_steps.pop(0)\n                                x_work = x_try\n                                f_work = fv\n                                moved = True\n                                local_improved = True\n                                if f_work < f_best:\n                                    f_best = f_work\n                                    x_best = x_work.copy()\n                                    gens_since_improve = 0\n                                break\n\n                    # anisotropic Hooke-Jeeves-style coordinate probes (per-dim)\n                    if (self.budget - evals) <= 0:\n                        break\n                    for d in range(self.dim):\n                        if evals >= self.budget:\n                            break\n                        # try plus\n                        x_try = x_work.copy()\n                        x_try[d] = x_try[d] + step\n                        x_try = reflect_then_clamp(x_try)\n                        if np.allclose(x_try, x_work):\n                            # try minus\n                            x_try = x_work.copy()\n                            x_try[d] = x_try[d] - step\n                            x_try = reflect_then_clamp(x_try)\n                        fv = float(func(x_try))\n                        evals += 1\n                        if fv < f_work:\n                            # opportunistic extra probe in same sense\n                            if evals < self.budget:\n                                # probe further along same signed move\n                                direction = np.sign(x_try[d] - x_work[d])\n                                x_try2 = x_try.copy()\n                                x_try2[d] = x_try2[d] + direction * step\n                                x_try2 = reflect_then_clamp(x_try2)\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < fv:\n                                    x_try, fv = x_try2, fv2\n                            step_vec = x_try - x_work\n                            if np.linalg.norm(step_vec) > 0:\n                                success_steps.append(step_vec.copy())\n                                if len(success_steps) > self.success_hist_len:\n                                    success_steps.pop(0)\n                            x_work = x_try\n                            f_work = fv\n                            moved = True\n                            local_improved = True\n                            if f_work < f_best:\n                                f_best = f_work\n                                x_best = x_work.copy()\n                                gens_since_improve = 0\n\n                    if not moved:\n                        step *= self.step_shrink\n                    # continue while loop as long as possible\n\n                # inject improvement into population\n                if local_improved:\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_work.copy()\n                    f[worst_idx] = f_work\n                    gens_since_improve = 0\n                else:\n                    # if still stagnating, perform mild jittered restarts of half population\n                    if gens_since_improve >= self.local_stagn_gen:\n                        half = max(1, pop // 2)\n                        for k in range(half):\n                            if evals >= self.budget:\n                                break\n                            jitter = rng.randn(self.dim) * (0.05 * (ub - lb))\n                            newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                            fv = float(func(newx))\n                            evals += 1\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = newx\n                            f[worst_idx] = fv\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = newx.copy()\n                                gens_since_improve = 0\n\n            # safe-sync best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finished (budget exhausted or loop exit)\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveDirectionalDE scored 0.517 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "bb3480f9-49d6-486a-8da6-7beaf8ccece9", "operator": null, "metadata": {"aucs": [0.17737058964394148, 0.1727363992486024, 0.6733126685937044, 0.9572261346790697, 0.5594138369106942, 0.8485916493653631, 0.2806355219411498, 0.4070900227461558, 0.9180584918493324, 0.1722749969035272]}, "task_prompt": ""}
{"id": "0036d492-3bca-4804-9874-6c8db9466663", "fitness": 0.704092836488441, "name": "HybridOPCMADE", "description": "HybridOPCMADE is a hybrid search that keeps a compact CMA core (mean m, covariance C with Cholesky/ SPD fixes, and global sigma initialized to 0.25·mean_range) while sampling about half the offspring from Gaussian CMA proposals and half from an operator pool (archive-driven DE, local trust-scaled Gaussian, elite-mix, and heavy-tailed Lévy jumps). The operator pool is managed with an archive of elites and exponentially decayed operator credits to bias selection toward successful operators, and each population member has a per-individual trust radius that expands on success and shrinks on failure to enable localized exploration. Updates use rank-mu recombination to compute a new mean and a weighted normalized-deltas covariance update with a small floor blend (cov_lr ~0.21) to avoid collapse, and sigma is adapted by a smoothed success-rate (1/5th-like) while stagnation detection triggers Lévy escapes or reseeding around the best/center. Practical safeguards include budget-aware sequential evaluation, reflect/clamp boundary handling, population size scaling with log(dim), archive size proportional to dim, and regular SPD enforcement for numerical stability.", "code": "import numpy as np\n\nclass HybridOPCMADE:\n    \"\"\"\n    HybridOPCMADE: Operator-pooled compact CMA core mixed with archive-driven DE proposals.\n\n    Main idea:\n      - Maintain compact CMA core (mean m, covariance C, global sigma).\n      - Each iteration sample roughly half Gaussian CMA proposals and half operator-driven proposals\n        (archive-driven differential, local gaussian scaled by trust radii, elite-mix, or Levy jumps).\n      - Credit operators with an exponential decay and expand/shrink per-individual trust radii based on success.\n      - Update mean by rank-weighted recombination and covariance by weighted normalized deltas (rank-mu).\n      - Smoothed success-rate controls sigma (1/5th-like); occasional Levy escapes and re-centering on stagnation.\n      - Strict budget-aware sequential evaluation, bound reflect/clamp, and SPD safeguards.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop_base=None,\n                 cov_lr=0.21,\n                 sigma_adapt_rate=0.23,\n                 success_target=0.2,\n                 trust_init_frac=0.12,\n                 trust_expand=1.15,\n                 trust_shrink=0.85,\n                 archive_factor=4,\n                 levy_prob=0.22):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.pop_base = pop_base\n        self.cov_lr = float(cov_lr)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.success_target = float(success_target)\n        self.trust_init_frac = float(trust_init_frac)\n        self.trust_expand = float(trust_expand)\n        self.trust_shrink = float(trust_shrink)\n        self.archive_size = min(40, max(5, int(archive_factor * self.dim)))\n        self.levy_prob = float(levy_prob)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        mean_range = float(np.mean(span))\n        max_bound = float(np.max(span))\n\n        # adaptive small population\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # initialize a modest population (mirrored-opposition like for diversity)\n        pop = max(lam, 12)\n        pop = min(pop, max(2, self.budget))\n        half = (pop + 1) // 2\n        X = np.empty((pop, self.dim), dtype=float)\n        center = 0.5 * (lb + ub)\n        for i in range(half):\n            u = rng.rand(self.dim)\n            X[i] = lb + u * (ub - lb)\n            j = i + half\n            if j < pop:\n                X[j] = 2.0 * center - X[i]\n        X += rng.randn(pop, self.dim) * 1e-6\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        evals = 0\n        # evaluate an initial batch to seed mean and archive\n        initial_batch = min(pop, max(4, lam))\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(initial_batch):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        if evals >= self.budget:\n            best_idx = int(np.nanargmin(f[:initial_batch]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # initialize mean from top-half of evaluated\n        valid_idx = np.where(np.isfinite(f))[0]\n        if valid_idx.size == 0:\n            m = 0.5 * (lb + ub)\n        else:\n            mu0 = max(1, valid_idx.size // 2)\n            order0 = np.argsort(f[valid_idx])\n            elites0 = X[valid_idx][order0[:mu0]]\n            weights0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n            weights0 = np.maximum(weights0, 0.0)\n            if weights0.sum() <= 0:\n                weights0 = np.ones_like(weights0)\n            weights0 = weights0 / weights0.sum()\n            m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance and sigma\n        C = np.diag(((span / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-12, 0.25 * mean_range)\n\n        # trust radii per-population individual\n        init_radius = max(1e-12, self.trust_init_frac * mean_range)\n        radius = np.full(pop, init_radius, dtype=float)\n\n        # operator pool: 0=archive_de,1=local_gauss,2=elite_mix,3=levy (gaussian core not counted here - it's half)\n        n_ops = 4\n        op_credit = np.ones(n_ops, dtype=float)\n\n        # archive of elites\n        archive_X = []\n        archive_f = []\n\n        # incorporate initial evaluated points into archive and compute best\n        f_best = np.inf\n        x_best = None\n        for i in range(initial_batch):\n            if np.isfinite(f[i]):\n                # add to archive\n                if len(archive_f) < self.archive_size:\n                    archive_X.append(X[i].copy())\n                    archive_f.append(float(f[i]))\n                else:\n                    worst_idx = int(np.argmax(archive_f))\n                    if f[i] < archive_f[worst_idx]:\n                        archive_X[worst_idx] = X[i].copy()\n                        archive_f[worst_idx] = float(f[i])\n                if f[i] < f_best:\n                    f_best = float(f[i])\n                    x_best = X[i].copy()\n\n        # state\n        p_succ = float(self.success_target)\n        stagn_iters = 0\n        iter_count = 0\n\n        # helpers\n        def chol_safe(Cmat):\n            eps = 1e-12 * np.maximum(np.diag(Cmat), 1.0)\n            try:\n                A = np.linalg.cholesky(Cmat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(Cmat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        def reflect_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        def op_probabilities():\n            tot = np.sum(op_credit)\n            if tot <= 0:\n                return np.full(n_ops, 1.0 / n_ops)\n            probs = op_credit / tot\n            probs = np.maximum(probs, 1e-6)\n            probs = probs / probs.sum()\n            return probs\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu = max(1, lam_iter // 2)\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            if weights.sum() <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / weights.sum()\n            W = weights.reshape(-1, 1)\n\n            A = chol_safe(C)\n\n            # compose candidate pool\n            n_gauss = lam_iter // 2\n            n_ops_prop = lam_iter - n_gauss\n\n            Xcand = np.empty((lam_iter, self.dim), dtype=float)\n            cand_origin = np.array([''] * lam_iter)\n            cand_base = np.full(lam_iter, -1, dtype=int)  # index of base individual for trust mapping\n\n            # 1) Gaussian CMA proposals\n            if n_gauss > 0:\n                Z = rng.normal(size=(n_gauss, self.dim))\n                Y = Z @ (A.T)\n                Xg = m + sigma * Y\n                Xg = np.minimum(np.maximum(Xg, lb), ub)\n                Xcand[:n_gauss] = Xg\n                cand_origin[:n_gauss] = 'gauss'\n\n            # 2) operator-driven proposals (archive-DE, local-gauss, elite-mix, levy)\n            probs = op_probabilities()\n            for i in range(n_ops_prop):\n                idx = n_gauss + i\n                op = rng.choice(n_ops, p=probs)\n                cand_origin[idx] = f'op{op}'\n                # pick a base index in population for trust radius scaling\n                base_i = rng.randint(0, pop)\n                cand_base[idx] = base_i\n                xi = X[base_i].copy()\n                if op == 0:\n                    # archive-driven differential: prefer archive if available, fallback to population diffs\n                    if len(archive_X) >= 3:\n                        a, b = rng.choice(len(archive_X), size=2, replace=False)\n                        anchor = archive_X[rng.randint(len(archive_X))]\n                        diff = archive_X[a] - archive_X[b]\n                        F = 0.8 * (0.5 + 0.5 * rng.rand())\n                        trial = anchor + F * diff + rng.normal(scale=0.3 * sigma, size=self.dim)\n                    else:\n                        # fallback: differential from population\n                        idxs = [j for j in range(pop) if j != base_i]\n                        if len(idxs) >= 2:\n                            a, b = rng.choice(idxs, size=2, replace=False)\n                            F = 0.8\n                            trial = X[base_i] + F * (X[a] - X[b]) + rng.normal(scale=0.3 * sigma, size=self.dim)\n                        else:\n                            trial = xi + rng.normal(scale=sigma, size=self.dim)\n                elif op == 1:\n                    # local gaussian around base scaled by trust radius\n                    scale = max(1e-12, radius[base_i])\n                    trial = xi + rng.randn(self.dim) * (scale * (0.3 + 0.7 * rng.rand()))\n                elif op == 2:\n                    # elite mix: recombine with a random elite if available\n                    if len(archive_X) >= 1:\n                        elite = archive_X[rng.randint(len(archive_X))]\n                    else:\n                        elite = m\n                    alpha = 0.3 + 0.7 * rng.rand()\n                    trial = xi + alpha * (elite - xi) + rng.randn(self.dim) * 0.15 * radius[base_i]\n                else:\n                    # levy heavy-tailed jump anchored on best or xi\n                    center = x_best if (x_best is not None and rng.rand() < 0.8) else xi\n                    scale = 0.6 * mean_range * (0.5 + rng.rand() * 0.5)\n                    jump = rng.standard_cauchy(self.dim) * scale * 0.6\n                    trial = center + jump\n\n                trial = reflect_clamp(trial)\n                Xcand[idx] = trial\n\n            # Evaluate candidates sequentially and budget-aware; track per-origin success\n            f_cand = np.full(lam_iter, np.inf, dtype=float)\n            prev_archive_median = np.median(np.array(archive_f)) if len(archive_f) > 0 else np.inf\n            # keep track of whether any candidate improved global best at time of evaluation\n            local_successes = np.zeros(n_ops, dtype=float)\n            tries = np.zeros(n_ops, dtype=float)\n\n            for i in range(lam_iter):\n                if evals >= self.budget:\n                    break\n                x_try = Xcand[i]\n                fv = float(func(x_try))\n                f_cand[i] = fv\n                evals += 1\n\n                # update archive\n                if len(archive_f) < self.archive_size:\n                    archive_X.append(x_try.copy())\n                    archive_f.append(float(fv))\n                else:\n                    worst_idx = int(np.argmax(archive_f))\n                    if fv < archive_f[worst_idx]:\n                        archive_X[worst_idx] = x_try.copy()\n                        archive_f[worst_idx] = float(fv)\n\n                # immediate best update\n                improved_now = False\n                if fv < f_best:\n                    f_best = float(fv)\n                    x_best = x_try.copy()\n                    improved_now = True\n                    stagn_iters = 0\n                else:\n                    stagn_iters += 0  # not increment here; handled later\n\n                # credit accounting\n                origin = cand_origin[i]\n                if origin.startswith('op'):\n                    op_idx = int(origin[2:])\n                    tries[op_idx] += 1.0\n                    # consider success if improved over previous archive median or improved global best now\n                    if (fv <= prev_archive_median) or improved_now:\n                        local_successes[op_idx] += 1.0\n                # count gaussian proposals as operator 1 for crediting local radii logic (not to op_credit)\n                # (we only credit op pool here)\n\n            # selection and recombination\n            # ensure we only consider evaluated candidates\n            valid_mask = np.isfinite(f_cand)\n            if not np.any(valid_mask):\n                break\n            valid_idxs = np.where(valid_mask)[0]\n            # select top-mu among evaluated subset\n            order = np.argsort(f_cand[valid_idxs])\n            sel_idxs = valid_idxs[order[:min(mu, len(order))]]\n            X_mu = Xcand[sel_idxs]\n            f_mu = f_cand[sel_idxs]\n\n            # compute new mean and weighted covariance from selected deltas (normalized)\n            m_new = (weights[:len(sel_idxs)].reshape(-1, 1) * X_mu[:len(weights)].copy()).sum(axis=0)\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            W_eff = weights[:len(sel_idxs)].reshape(-1, 1)\n            weighted_cov = (deltas * W_eff).T @ deltas if deltas.shape[0] > 0 else np.zeros((self.dim, self.dim))\n\n            # covariance update with small floor blend to avoid collapse\n            floor = np.diag(((span / 30.0) ** 2).clip(min=1e-12))\n            C = (1.0 - self.cov_lr) * C + self.cov_lr * weighted_cov + 1e-12 * np.eye(self.dim)\n            C = 0.985 * C + 0.015 * floor\n            # SPD fix\n            vals, vecs = np.linalg.eigh(C)\n            vals = np.clip(vals, 1e-16, None)\n            C = (vecs * vals) @ vecs.T\n\n            # update mean\n            m = m_new.copy()\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # operator credit update (decay + add successes)\n            decay = 0.9\n            op_credit = op_credit * decay + local_successes * (1.0 - decay)\n            op_credit = np.maximum(op_credit, 1e-8)\n\n            # update trust radii: expand for bases that produced successful ops, shrink otherwise\n            # map successes back to base indices approx: expand random members proportional to successes\n            total_succ = int(np.sum(local_successes))\n            if total_succ > 0:\n                n_expand = min(pop, 1 + total_succ)\n                for jj in rng.choice(pop, size=n_expand, replace=False):\n                    radius[jj] = min(radius[jj] * self.trust_expand, mean_range)\n            else:\n                # mild shrink of a few\n                for jj in rng.choice(pop, size=min(pop, 2), replace=False):\n                    radius[jj] = max(radius[jj] * self.trust_shrink, 1e-12)\n\n            # step-size adaptation via smoothed success-rate (approx 1/5th rule)\n            # estimate succ_frac as fraction of candidates better than prev_archive_median\n            succ_frac = np.sum((np.isfinite(f_cand)) & (f_cand <= prev_archive_median)) / max(1, np.sum(np.isfinite(f_cand)))\n            p_succ = 0.9 * p_succ + 0.1 * succ_frac\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = float(np.clip(sigma, 1e-12, 2.0 * max_bound))\n\n            # stagnation detection: if best hasn't improved for many iterations, trigger escapes\n            # track stagn_iters by counting generations without improvement (approx)\n            # We consider a generation as \"no improvement\" if none of batch improved previous median significantly\n            if np.sum((np.isfinite(f_cand)) & (f_cand < prev_archive_median)) > 0:\n                stagn_iters = 0\n            else:\n                stagn_iters += 1\n\n            # on stagnation, do Levy escape or reseed\n            if stagn_iters * lam_iter >= max(8, int(0.02 * self.budget)):\n                if rng.rand() < self.levy_prob and len(archive_X) > 0 and evals < self.budget:\n                    anchor = archive_X[rng.randint(len(archive_X))]\n                    jump_scale = max(0.5 * mean_range, sigma * 4.0)\n                    jump = rng.standard_cauchy(self.dim) * jump_scale\n                    x_jump = reflect_clamp(anchor + jump)\n                    if evals < self.budget:\n                        fj = float(func(x_jump))\n                        evals += 1\n                        # add to archive\n                        if len(archive_f) < self.archive_size:\n                            archive_X.append(x_jump.copy())\n                            archive_f.append(float(fj))\n                        else:\n                            widx = int(np.argmax(archive_f))\n                            if fj < archive_f[widx]:\n                                archive_X[widx] = x_jump.copy()\n                                archive_f[widx] = float(fj)\n                        if fj < f_best:\n                            f_best = float(fj)\n                            x_best = x_jump.copy()\n                            m = x_jump.copy()\n                            sigma = max(sigma, 0.4 * mean_range)\n                            C = np.diag(((span / 6.0) ** 2).clip(min=1e-12))\n                            stagn_iters = 0\n                        else:\n                            # mild nudge toward best if not improved\n                            if x_best is not None:\n                                m = 0.8 * m + 0.2 * x_best\n                            sigma = min(2.0 * max_bound, sigma * 1.4)\n                else:\n                    # isotropic reseed around best or center\n                    if x_best is not None:\n                        jitter = rng.randn(self.dim) * (0.08 * mean_range)\n                        m = reflect_clamp(x_best + jitter)\n                    else:\n                        m = reflect_clamp(center + rng.randn(self.dim) * (0.2 * mean_range))\n                    C = np.diag(((span / 5.0) ** 2).clip(min=1e-12))\n                    sigma = max(sigma, 0.25 * mean_range)\n                    radius *= 0.9\n                    stagn_iters = 0\n\n            # safety SPD enforcement occasionally\n            if iter_count % 11 == 0:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-16, None)\n                C = (vecs * vals) @ vecs.T\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridOPCMADE scored 0.704 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "bb3480f9-49d6-486a-8da6-7beaf8ccece9", "operator": null, "metadata": {"aucs": [0.22938739552333587, 0.18900175327950053, 0.8872611697575834, 0.9465164178802841, 0.9054491660105853, 0.9074862855731062, 0.31013831239997514, 0.8742183110126898, 0.9029124643949671, 0.8885570890523817]}, "task_prompt": ""}
{"id": "3b099c09-b6f0-478c-a088-c5e5e14bccdd", "fitness": 0.4459025396768005, "name": "PCGASS", "description": "The algorithm maintains a small population with per-individual adaptive scalar step-sizes (sigma) initialized to init_step_frac=0.25 of the search range and adjusted multiplicatively (step_expand=1.25 on success, step_shrink=0.80 on failure) to balance exploration and exploitation. It records a bounded memory of successful displacement vectors (mem_size ≈ mem_size_factor*dim, default 4×dim) and computes a weighted PCA (SVD) to define low-dimensional elliptical subspaces (subspace_k_frac≈0.3) for directed sampling, while also including complementary operators: isotropic Gaussian, sparse coordinate probes, elite-directed moves, and heavy-tailed Lévy jumps. Operator selection is adaptive (op_w updated with decay op_decay≈0.85 using per-generation success rates), and the method adds opportunistic extra steps along successful displacements, periodic localized exploitation around the best, and stagnation-handling soft restarts/orthogonal nudges; bounds are handled by a reflect-then-clamp rule and strict budget accounting is enforced throughout.", "code": "import numpy as np\n\nclass PCGASS:\n    \"\"\"\n    Principal-component Guided Adaptive Subspace Search (PCGASS)\n\n    Key ideas:\n    - Maintain a small population with per-individual adaptive scalar step-sizes.\n    - Keep a short memory of successful displacement vectors and compute a PCA\n      (SVD) to identify promising low-dimensional subspaces for elliptical sampling.\n    - Operators: PCA-elliptical sampling, isotropic Gaussian, coordinate-wise probes,\n                 elite recombination, and Lévy restarts from the best.\n    - Operator selection uses adaptive weights updated by smoothed success counts.\n    - Opportunistic extra step along successful displacement direction.\n    - Periodic localized exploitation around the best and orthogonalized nudges\n      (soft restarts) when stagnating.\n    - Strict budget accounting; reflect-then-clamp bound handling.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop=None,\n                 init_step_frac=0.25,\n                 min_step_frac=1e-6,\n                 step_expand=1.25,\n                 step_shrink=0.80,\n                 mem_size_factor=4,\n                 subspace_k_frac=0.3,\n                 op_decay=0.85,\n                 levy_prob=0.07,\n                 local_period=20,\n                 stagn_limit=40,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop\n        self.init_step_frac = float(init_step_frac)\n        self.min_step_frac = float(min_step_frac)\n        self.step_expand = float(step_expand)\n        self.step_shrink = float(step_shrink)\n        self.mem_size = max(4, int(mem_size_factor * self.dim))\n        self.subspace_k_frac = float(subspace_k_frac)\n        self.op_decay = float(op_decay)\n        self.levy_prob = float(levy_prob)\n        self.local_period = int(local_period)\n        self.stagn_limit = int(stagn_limit)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds (BBOB style)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, float(lb), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, float(ub), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size heuristic\n        if self.pop_base is None:\n            pop = max(6, min(int(4 + self.dim // 2), self.budget))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # initialization: latin-like spread (simple uniform + jitter)\n        X = np.empty((pop, self.dim), dtype=float)\n        for i in range(pop):\n            u = rng.rand(self.dim)\n            X[i] = lb + u * (ub - lb)\n        # small stratified jitter to break symmetry\n        X += (rng.randn(pop, self.dim) * 1e-4 * (ub - lb))\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially (respect budget)\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        # If budget exhausted, return best seen\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # scale measures\n        space_range = float(np.mean(ub - lb))\n        init_step = max(1e-12, self.init_step_frac * space_range)\n        min_step = max(1e-12, self.min_step_frac * space_range)\n        sigma = np.full(pop, init_step, dtype=float)  # per-individual scalar step-size\n\n        # memory of successful displacement vectors (centered on zero), with weights\n        D = []      # list of displacement vectors\n        Dw = []     # associated weights (improvement magnitude)\n\n        # operator pool: 0 PCA-elliptical, 1 isotropic Gaussian, 2 coordinate probe,\n        # 3 elite recombination, 4 levy_restart\n        n_ops = 5\n        op_w = np.ones(n_ops, dtype=float)  # weights for selection\n        # helper to compute op probabilities\n        def op_probs():\n            w = np.maximum(op_w, 1e-12)\n            return w / np.sum(w)\n\n        # helper: reflect once then clamp\n        def reflect_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # helper: compute PCA directions from D (weighted)\n        def compute_pca_topk(D_list, Dw_list, k):\n            if len(D_list) < 2:\n                return None, None  # not enough memory\n            M = np.vstack(D_list)  # n_mem x dim\n            W = np.asarray(Dw_list, dtype=float)\n            # weight rows\n            W = (W - np.min(W)) + 1e-8 if np.ptp(W) > 0 else np.ones_like(W)\n            sqrtW = np.sqrt(W)[:, None]\n            A = (sqrtW * M)  # weighted matrix\n            try:\n                U, S, Vt = np.linalg.svd(A, full_matrices=False)\n            except np.linalg.LinAlgError:\n                return None, None\n            # Vt: rows are principal directions, S are singular values\n            V = Vt.T  # dim x r\n            topk = min(k, V.shape[1])\n            return V[:, :topk], S[:topk]\n\n        # helper: pick elites\n        def elite_indices():\n            k = max(2, int(np.ceil(0.2 * pop)))\n            return np.argsort(f)[:k]\n\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        # operator success tracking per generation\n        op_success = np.zeros(n_ops, dtype=float)\n        op_try = np.zeros(n_ops, dtype=float)\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n            op_success[:] = 0.0\n            op_try[:] = 0.0\n\n            order = np.argsort(f)\n            elites = order[:max(2, int(np.ceil(0.2 * pop)))]\n\n            # compute PCA once per generation\n            k = max(1, int(self.subspace_k_frac * self.dim))\n            V_top, S_top = compute_pca_topk(D, Dw, k)\n\n            # iterate individuals in random order\n            idxs = rng.permutation(pop)\n            probs = op_probs()\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fi = float(f[ii])\n\n                # choose operator\n                op_idx = rng.choice(n_ops, p=probs)\n                op_try[op_idx] += 1.0\n\n                trial = None\n\n                # 0: PCA-elliptical: sample in subspace spanned by top PCA directions (ellipsoidal)\n                if op_idx == 0 and V_top is not None:\n                    # sample coefficients proportional to singular values\n                    coeffs = rng.randn(V_top.shape[1])\n                    # scale by singular values S_top (normalize by max)\n                    s_scale = (S_top / (S_top[0] + 1e-12))\n                    coeffs = coeffs * s_scale\n                    trial = xi + (V_top @ coeffs) * (0.9 * sigma[ii])\n\n                # 1: isotropic gaussian local\n                if op_idx == 1:\n                    trial = xi + rng.randn(self.dim) * sigma[ii]\n\n                # 2: coordinate probe (sparse large changes on subset of dims)\n                if op_idx == 2:\n                    n_coords = max(1, self.dim // 3)\n                    coords = rng.choice(self.dim, size=n_coords, replace=False)\n                    delta = np.zeros(self.dim)\n                    delta[coords] = rng.randn(n_coords) * (2.0 * sigma[ii])\n                    trial = xi + delta\n\n                # 3: elite recombination: move toward a random elite mean with small noise\n                if op_idx == 3:\n                    elite_idx = int(rng.choice(elites))\n                    alpha = 0.3 + 0.7 * rng.rand()  # [0.3,1.0]\n                    trial = xi + alpha * (X[elite_idx] - xi) + rng.randn(self.dim) * (0.2 * sigma[ii])\n\n                # 4: levy restart: heavy-tailed jump centered at x_best or xi (escape)\n                if op_idx == 4:\n                    center = x_best if rng.rand() < 0.8 else xi\n                    # scale larger than normal sigma to escape; include space_range factor\n                    scale = max(1e-12, 2.5 * np.mean(sigma) + 0.05 * space_range)\n                    # standard Cauchy vector\n                    jump = rng.standard_cauchy(self.dim) * scale\n                    trial = center + jump\n\n                if trial is None:\n                    trial = xi.copy()\n\n                # reflect and clamp\n                trial = reflect_clamp(trial)\n\n                # budget check\n                if evals >= self.budget:\n                    break\n\n                # evaluate\n                fv = float(func(trial))\n                evals += 1\n\n                # selection\n                if fv <= fi:\n                    # accept\n                    X[ii] = trial\n                    f[ii] = fv\n                    op_success[op_idx] += 1.0\n\n                    # compute displacement and weight\n                    disp = trial - xi\n                    imp = max(0.0, fi - fv) + 1e-12  # improvement magnitude\n                    # store in memory (bounded)\n                    D.append(disp)\n                    Dw.append(imp)\n                    if len(D) > self.mem_size:\n                        # drop oldest\n                        D.pop(0)\n                        Dw.pop(0)\n\n                    # expand step-size modestly\n                    sigma[ii] = min(max(sigma[ii] * self.step_expand, min_step), space_range)\n\n                    # opportunistic extra step along disp direction\n                    if np.linalg.norm(disp) > 0 and evals < self.budget:\n                        extra_frac = 0.2 + 0.7 * rng.rand()\n                        extra = trial + extra_frac * disp\n                        extra = reflect_clamp(extra)\n                        fv2 = float(func(extra))\n                        evals += 1\n                        if fv2 < f[ii]:\n                            X[ii] = extra\n                            f[ii] = fv2\n                            # expand step some more\n                            sigma[ii] = min(sigma[ii] * (1.0 + 0.05 * extra_frac), space_range)\n\n                    # update global best\n                    if f[ii] < f_best:\n                        f_best = float(f[ii])\n                        x_best = X[ii].copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n\n                else:\n                    # reject -> shrink step-size\n                    sigma[ii] = max(sigma[ii] * self.step_shrink, min_step)\n\n                # early stop check\n                if evals >= self.budget:\n                    break\n\n            # update operator weights by decay + normalized success fraction\n            success_rates = op_success / np.maximum(op_try, 1.0)\n            # smoothed update: higher success increases weight\n            for j in range(n_ops):\n                op_w[j] = op_w[j] * self.op_decay + success_rates[j] * (1.0 - self.op_decay) * np.sum(op_w)\n            # ensure positivity and normalize will happen via op_probs next loop\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n            else:\n                gens_since_improve = 0\n\n            # periodic local exploitation around best\n            if gen % self.local_period == 0 and evals < self.budget:\n                local_sigma = max(min_step, 0.6 * np.mean(sigma))\n                shrink = 0.5\n                iter_local = 0\n                while local_sigma >= min_step and evals < self.budget and iter_local < 5:\n                    n_samples = min(6 + self.dim // 2, self.budget - evals)\n                    for _ in range(int(n_samples)):\n                        if evals >= self.budget:\n                            break\n                        cand = x_best + rng.randn(self.dim) * local_sigma\n                        cand = reflect_clamp(cand)\n                        fv = float(func(cand))\n                        evals += 1\n                        if fv < f_best:\n                            f_best = fv\n                            x_best = cand.copy()\n                            # replace worst individual with this candidate\n                            worst = int(np.argmax(f))\n                            X[worst] = cand.copy()\n                            f[worst] = fv\n                            sigma[worst] = max(sigma[worst] * 0.9, min_step)\n                            gens_since_improve = 0\n                    local_sigma *= shrink\n                    iter_local += 1\n\n            # stagnation handling: orthogonal nudges / soft restart\n            if gens_since_improve >= self.stagn_limit and evals < self.budget:\n                n_nudge = pop // 2\n                # compute an orthonormal basis from PCA memory if available\n                V_top2, _ = compute_pca_topk(D, Dw, min(self.dim, max(1, int(self.subspace_k_frac * self.dim))))\n                for _ in range(n_nudge):\n                    if evals >= self.budget:\n                        break\n                    idx_replace = int(np.argmax(f))\n                    # create candidate by combining best + small projection in PCA subspace + isotropic jitter\n                    if V_top2 is not None:\n                        coeffs = rng.randn(V_top2.shape[1]) * (0.8 * np.mean(sigma))\n                        candidate = x_best + (V_top2 @ coeffs) + rng.randn(self.dim) * (0.2 * np.mean(sigma))\n                    else:\n                        candidate = x_best + rng.randn(self.dim) * (0.8 * np.mean(sigma))\n                    candidate = reflect_clamp(candidate)\n                    fv = float(func(candidate))\n                    evals += 1\n                    X[idx_replace] = candidate\n                    f[idx_replace] = fv\n                    sigma[idx_replace] = init_step\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = candidate.copy()\n                        gens_since_improve = 0\n                # slightly diversify operator weights to encourage exploration\n                op_w = op_w * (0.5 + 0.5 * rng.rand(n_ops))\n\n            # final safeguard: update best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # done\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm PCGASS scored 0.446 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "98b5d309-59bb-49ef-9442-6831b47dfff9", "operator": null, "metadata": {"aucs": [0.1398386103521556, 0.17136367808058417, 0.9270847877113675, 0.968883569370238, 0.20216537167050508, 0.9808602928016106, 0.27553568892576497, 0.35055894494420436, 0.2961011030690609, 0.14663334984251342]}, "task_prompt": ""}
{"id": "8f95fb78-15ea-44b8-84a6-3449e156bdb8", "fitness": 0.31825759356634364, "name": "EDAS", "description": "The algorithm starts with a Latin‑hypercube–like stratified initialization and a small jittered population (size from a log heuristic) to ensure wide initial coverage within bounds. It uses five diverse operators (centroid-direction, single‑coordinate search, barycenter recombination, Student‑t heavy jumps, and a momentum step) with an empirical-Bayesian operator selection (op_succ/op_try priors, softmax with temperature) and exponential decay (op_decay=0.95) to favor historically successful moves. Each individual carries adaptive state (per‑individual radius and a velocity vector) with multiplicative radius adaptation (expand_mult=1.25, shrink_mult=0.75, min_radius small), momentum updates/damping, occasional opportunistic continuation evaluations, and heavier Levy‑style jumps (levy_scale_frac=0.6) for exploration. Boundary handling is reflect‑then‑clamp, and global control includes periodic localized refinement around the best (local_period=30), soft partial restarts on stagnation (stagn_thresh=40), worst‑replacement on improvement, and strict budget accounting so func calls never exceed the given budget.", "code": "import numpy as np\n\nclass EDAS:\n    \"\"\"\n    Ensemble Directional Adaptive Search (EDAS)\n\n    Key ideas / differences from the provided algorithm:\n    - Uses Latin-Hypercube-like wide initialization (via stratified uniform) instead of mirrored-opposition.\n    - Five operators (centroid-direction, coordinate search, barycenter recombination,\n      Student-t heavy-tail jumps, and momentum-based steps) rather than four.\n    - Operator selection via empirical Bayesian success-rate estimator:\n      success_rate = (successes + 0.5) / (tries + 1.0), with light exponential decay of counts.\n      This is different from an un-decayed credit vector or a simple decay-only scheme.\n    - Per-individual multiplicative radius adaptation with different expansion/shrink multipliers.\n    - Maintains a per-individual velocity (momentum) that is used by one operator and is adapted on acceptance.\n    - Periodic localized refinement and partial soft restarts, but with different shrinking and restart scales.\n    - Strict budget accounting: func calls never exceed self.budget.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 init_radius_frac=0.18,    # slightly smaller initial radius fraction\n                 min_radius_frac=1e-6,\n                 expand_mult=1.25,         # more aggressive expansion\n                 shrink_mult=0.75,         # stronger shrinkage on failures\n                 op_decay=0.95,            # decay for op counts (different from 0.9)\n                 local_period=30,\n                 stagn_thresh=40,\n                 levy_scale_frac=0.6,      # heavier jumps than original\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.init_radius_frac = float(init_radius_frac)\n        self.min_radius_frac = float(min_radius_frac)\n        self.expand_mult = float(expand_mult)\n        self.shrink_mult = float(shrink_mult)\n        self.op_decay = float(op_decay)\n        self.local_period = int(local_period)\n        self.stagn_thresh = int(stagn_thresh)\n        self.levy_scale_frac = float(levy_scale_frac)\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # Bounds (assume func provides .bounds.lb / ub)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        # handle scalar bounds\n        if lb.size == 1:\n            lb = np.full(self.dim, float(lb), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, float(ub), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size heuristic (different)\n        if self.pop_base is None:\n            pop = max(8, int(4 + 1.5 * np.log(max(2, self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # Latin-hypercube-like stratified initialization for coverage\n        X = np.empty((pop, self.dim), dtype=float)\n        # create stratified points per dimension\n        for d in range(self.dim):\n            perm = rng.permutation(pop) + rng.rand(pop)\n            pts = (perm / float(pop))\n            X[:, d] = lb[d] + pts * (ub[d] - lb[d])\n        # small jitter\n        X += rng.randn(pop, self.dim) * 1e-6 * (ub - lb)\n        # clamp\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # Evaluate initial population sequentially, respecting budget\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # trust radii (per-individual) relative to mean range\n        range_mean = float(np.mean(ub - lb))\n        init_radius = max(1e-12, self.init_radius_frac * range_mean)\n        min_radius = max(1e-12, self.min_radius_frac * range_mean)\n        radius = np.full(pop, init_radius, dtype=float)\n\n        # per-individual velocity for momentum operator\n        velocity = np.zeros((pop, self.dim), dtype=float)\n\n        # operator bookkeeping: we implement 5 operators (0..4)\n        n_ops = 5\n        # maintain exponentially-decayed try/success counts (start with small prior)\n        op_try = np.full(n_ops, 1.0, dtype=float)     # prior pseudo-count\n        op_succ = np.full(n_ops, 0.5, dtype=float)    # prior pseudo-success\n        # helper to get operator probabilities from empirical Bayes-style success rates\n        def op_probabilities(temperature=0.6):\n            # compute empirical success rate with Beta prior smoothing\n            rates = (op_succ + 0.5) / (op_try + 1.0)\n            # map to positive weights and softmax with temperature\n            exps = np.exp(np.log(rates + 1e-12) / max(1e-12, temperature))\n            w = exps / np.sum(exps)\n            return w\n\n        # reflect-then-clamp as in original but implemented slightly differently\n        def reflect_clamp(x):\n            x_rc = x.copy()\n            # reflect across each violated bound once\n            below = x_rc < lb\n            if np.any(below):\n                x_rc[below] = lb[below] + (lb[below] - x_rc[below])\n            above = x_rc > ub\n            if np.any(above):\n                x_rc[above] = ub[above] - (x_rc[above] - ub[above])\n            # final clamp\n            x_rc = np.minimum(np.maximum(x_rc, lb), ub)\n            return x_rc\n\n        # helper Student-t scaled\n        def student_t_step(scale, df=3.0):\n            # sample from standard Student's t (using normal/chi2) for vector\n            # Using numpy's standard_t if available\n            return rng.standard_t(df, size=self.dim) * scale\n\n        # helper to pick elite indices\n        def elites_indices(k_frac=0.25):\n            k = max(2, int(np.ceil(k_frac * pop)))\n            return np.argsort(f)[:k]\n\n        # track best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        # main optimization loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # compute operator probabilities\n            probs = op_probabilities()\n\n            # per-generation try/success counts (to be decayed into op_try/op_succ)\n            gen_try = np.zeros(n_ops, dtype=float)\n            gen_succ = np.zeros(n_ops, dtype=float)\n\n            # iterate individuals in random order\n            order = rng.permutation(pop)\n            # recompute elites for some operators\n            elites = elites_indices(k_frac=0.25)\n\n            for ii in order:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fi = float(f[ii])\n\n                # choose operator\n                op = rng.choice(n_ops, p=probs)\n                gen_try[op] += 1.0\n\n                trial = None\n\n                # Operator 0: centroid-direction (move toward centroid of elites scaled)\n                if op == 0:\n                    centroid = np.mean(X[elites], axis=0)\n                    alpha = 0.15 + 0.85 * rng.rand()  # [0.15,1.0]\n                    # direction from xi to centroid, plus small gaussian\n                    trial = xi + alpha * (centroid - xi) + rng.randn(self.dim) * 0.08 * radius[ii]\n\n                # Operator 1: coordinate-search (single-coordinate perturbation)\n                elif op == 1:\n                    trial = xi.copy()\n                    coord = rng.randint(self.dim)\n                    step = rng.randn() * radius[ii] * (1.0 + rng.rand() * 0.5)\n                    trial[coord] += step\n                    # small multi-coordinate probability\n                    if rng.rand() < 0.2:\n                        other_coords = rng.choice(self.dim, size=max(1, self.dim//10), replace=False)\n                        trial[other_coords] += rng.randn(other_coords.size) * 0.2 * radius[ii]\n\n                # Operator 2: barycenter recombination between two elites\n                elif op == 2:\n                    a, b = rng.choice(elites, size=2, replace=False)\n                    w = 0.2 + 0.8 * rng.rand()  # bias toward one elite\n                    trial = xi + w * (X[a] - xi) + (1.0 - w) * (X[b] - xi) + rng.randn(self.dim) * 0.12 * radius[ii]\n\n                # Operator 3: Student-t heavy jump (centered at xi or sometimes at best)\n                elif op == 3:\n                    scale = self.levy_scale_frac * radius[ii] * (0.8 + 0.8 * rng.rand())\n                    center = x_best if rng.rand() < 0.6 else xi\n                    trial = center + student_t_step(scale, df=3.0)\n\n                # Operator 4: momentum step (uses per-individual velocity)\n                elif op == 4:\n                    mom_coef = 0.6 + 0.3 * rng.rand()  # [0.6,0.9]\n                    trial = xi + mom_coef * velocity[ii] + rng.randn(self.dim) * 0.6 * radius[ii]\n\n                # ensure candidate exists\n                if trial is None:\n                    trial = xi.copy()\n\n                # reflect and clamp\n                trial = reflect_clamp(trial)\n\n                # evaluate if budget available\n                if evals >= self.budget:\n                    break\n                fv = float(func(trial))\n                evals += 1\n\n                # accept/reject with radius adaptation and velocity update\n                if fv <= fi:\n                    # accept\n                    X[ii] = trial\n                    f[ii] = fv\n                    gen_succ[op] += 1.0\n                    # expand radius (bounded by range_mean)\n                    radius[ii] = min(radius[ii] * self.expand_mult, range_mean)\n                    # update velocity (momentum-like)\n                    disp = trial - xi\n                    velocity[ii] = 0.65 * velocity[ii] + 0.35 * disp\n                    # opportunistic small continuation step along disp (but with small prob to preserve budget)\n                    if np.linalg.norm(disp) > 0 and rng.rand() < 0.25 and evals < self.budget:\n                        extra_frac = 0.5 * rng.rand() + 0.1\n                        extra = trial + extra_frac * disp\n                        extra = reflect_clamp(extra)\n                        fv2 = float(func(extra))\n                        evals += 1\n                        if fv2 < f[ii]:\n                            X[ii] = extra\n                            f[ii] = fv2\n                            # further increase radius mildly\n                            radius[ii] = min(radius[ii] * (1.0 + 0.06 * extra_frac), range_mean)\n                            # update velocity\n                            velocity[ii] = 0.65 * velocity[ii] + 0.35 * (extra - trial)\n                    # global best update\n                    if f[ii] < f_best:\n                        f_best = float(f[ii])\n                        x_best = X[ii].copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # reject: shrink radius and damp velocity\n                    radius[ii] = max(radius[ii] * self.shrink_mult, min_radius)\n                    velocity[ii] *= 0.85  # damp on failure\n\n                # budget check\n                if evals >= self.budget:\n                    break\n\n            # end individuals loop\n\n            # decay and merge per-generation stats into running op_try/op_succ\n            op_try = op_try * self.op_decay + gen_try\n            op_succ = op_succ * self.op_decay + gen_succ\n\n            # stagnation accounting\n            if not improved_in_gen:\n                gens_since_improve += 1\n            else:\n                gens_since_improve = 0\n\n            # periodic localized refinement around best (different schedule)\n            if gen % self.local_period == 0:\n                local_sigma = max(min_radius, 0.5 * np.median(radius))\n                local_iters = 0\n                while local_sigma >= min_radius and evals < self.budget and local_iters < 5:\n                    n_samples = min(6 + self.dim//2, self.budget - evals)\n                    for _ in range(int(n_samples)):\n                        if evals >= self.budget:\n                            break\n                        cand = x_best + rng.randn(self.dim) * local_sigma\n                        cand = reflect_clamp(cand)\n                        fv = float(func(cand))\n                        evals += 1\n                        if fv < f_best:\n                            f_best = fv\n                            x_best = cand.copy()\n                            # replace worst member\n                            worst = int(np.argmax(f))\n                            X[worst] = cand.copy()\n                            f[worst] = fv\n                            radius[worst] = max(radius[worst] * 0.7, min_radius)\n                            velocity[worst] = 0.0\n                            gens_since_improve = 0\n                    local_sigma *= 0.55\n                    local_iters += 1\n\n            # soft partial restart if still stagnating (different nudging scale)\n            if gens_since_improve >= self.stagn_thresh and evals < self.budget:\n                n_nudge = max(1, pop // 3)\n                for _ in range(n_nudge):\n                    if evals >= self.budget:\n                        break\n                    # replace worst with sample around best but with larger sigma relative to range_mean\n                    worst = int(np.argmax(f))\n                    jitter_scale = 0.25 * range_mean * (0.5 + rng.rand())\n                    candidate = x_best + rng.randn(self.dim) * jitter_scale\n                    candidate = reflect_clamp(candidate)\n                    fv = float(func(candidate))\n                    evals += 1\n                    X[worst] = candidate\n                    f[worst] = fv\n                    radius[worst] = init_radius\n                    velocity[worst] = 0.0\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = candidate.copy()\n                        gens_since_improve = 0\n                # slightly perturb surviving individuals' velocities and radii\n                velocity *= 0.9\n                radius = np.maximum(radius * 0.9 + init_radius * 0.1, min_radius)\n\n            # ensure best is in sync with population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finished, return best\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EDAS scored 0.318 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "98b5d309-59bb-49ef-9442-6831b47dfff9", "operator": null, "metadata": {"aucs": [0.1206022732511397, 0.1469636290658881, 0.5623479014589431, 0.5471734628705148, 0.18046488772719516, 0.8022513119687238, 0.22527964930255095, 0.21450853811573967, 0.22856728195008236, 0.15441699995265878]}, "task_prompt": ""}
{"id": "f7faa692-c449-4300-a568-393bbe6d9f42", "fitness": "-inf", "name": "MASS", "description": "MASS is a small-population, hybrid heuristic that seeds diversity via mirrored-opposition sampling and then evolves per-individual, per-dimension search scales (sigma) and momentum vectors to balance local exploitation and directional persistence. It adaptively multiplies sigmas (sigma_init_frac=0.15, sigma_min=1e-6, sigma_max_frac=2.0) using a CSA/Adagrad-like rule and opportunistic micro-steps, while momentum_beta=0.7 retains useful directions and soft restarts fight stagnation. A four-operator pool (anisotropic local Gaussian, PCA-subspace sampling from an elite displacement archive, centroid-guided recombination, and occasional heavy‑tailed Lévy jumps with levy_prob≈0.07) is selected via decaying credit scores (op_credit_decay≈0.92) updated by observed success ratios. Practical touches include an elite archive (archive_size=40) with periodic PCA (pca_refresh=10) to propose low-dimensional moves, reflect-then-clamp bounds handling, and strict budget accounting for all function evaluations.", "code": "import numpy as np\n\nclass MASS:\n    \"\"\"\n    Momentum Adaptive Subspace Search (MASS)\n\n    Key ideas:\n    - Small population with mirrored-opposition seeding for initial coverage.\n    - Each individual has per-dimension step-sizes (sigma) and a momentum vector (m).\n    - Operator pool: anisotropic local Gaussian, PCA-subspace sampling from an elite archive,\n      centroid-guided recombination, and occasional heavy-tailed Lévy jumps.\n    - Operator selection adapts via credits with exponential decay.\n    - Per-dimension sigma adapted multiplicatively (inspired by CSA/Adagrad ideas).\n    - Periodic covariance (PCA) calculated from an archive of elite displacements to propose\n      efficient subspace directions.\n    - Reflect-then-clamp bounds handling. Strict budget accounting.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 p_elite_frac=0.25,\n                 sigma_init_frac=0.15,\n                 sigma_min=1e-6,\n                 sigma_max_frac=2.0,\n                 op_credit_decay=0.92,\n                 momentum_beta=0.7,\n                 archive_size=40,\n                 pca_refresh=10,\n                 levy_prob=0.07,\n                 levy_scale_frac=1.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n\n        self.pop_base = pop_base\n        self.p_elite_frac = float(p_elite_frac)\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.sigma_min = float(sigma_min)\n        self.sigma_max_frac = float(sigma_max_frac)\n        self.op_credit_decay = float(op_credit_decay)\n        self.momentum_beta = float(momentum_beta)\n        self.archive_size = int(archive_size)\n        self.pca_refresh = int(pca_refresh)\n        self.levy_prob = float(levy_prob)\n        self.levy_scale_frac = float(levy_scale_frac)\n\n    def __call__(self, func):\n        rng = np.random.RandomState()  # independent RNG\n\n        # bounds (works with scalars or arrays)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, float(lb), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, float(ub), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size heuristic (small population favored)\n        if self.pop_base is None:\n            pop = max(8, int(np.round(4 + 1.5 * np.log(max(2, self.dim)))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # mirrored-opposition seeding\n        half = (pop + 1) // 2\n        X = np.empty((pop, self.dim), dtype=float)\n        center = 0.5 * (lb + ub)\n        for i in range(half):\n            u = rng.rand(self.dim)\n            X[i] = lb + u * (ub - lb)\n            j = i + half\n            if j < pop:\n                X[j] = 2.0 * center - X[i]\n        # small jitter\n        X += rng.randn(pop, self.dim) * 1e-4 * (ub - lb)\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # scales and sigma initialisation (per-dimension)\n        ranges = ub - lb\n        range_mean = float(np.mean(ranges))\n        sigma_init = max(1e-12, self.sigma_init_frac * ranges)  # vector per-dim\n        sigma_max = np.maximum(self.sigma_min, self.sigma_max_frac * ranges)\n        sigma = np.tile(sigma_init, (pop, 1))  # (pop, dim)\n\n        # momentum per-individual\n        momentum = np.zeros((pop, self.dim), dtype=float)\n\n        # operator pool credits (4 operators)\n        n_ops = 4\n        op_credit = np.ones(n_ops, dtype=float)\n\n        def op_probs():\n            tot = np.sum(op_credit)\n            if tot <= 0:\n                return np.full(n_ops, 1.0 / n_ops)\n            return op_credit / tot\n\n        # reflect then clamp\n        def reflect_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # simple cauchy step\n        def cauchy_vec(scale_vec):\n            # scale_vec can be scalar or (dim,)\n            return rng.standard_cauchy(self.dim) * scale_vec\n\n        # archive of elite samples (for PCA)\n        archive_X = []\n        archive_disp = []  # store displacement vectors relative to current best / local parent\n        archive_f = []\n\n        # track best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        # statistics for credit updates\n        op_try = np.zeros(n_ops, dtype=float)\n        op_success = np.zeros(n_ops, dtype=float)\n\n        # PCA cached\n        pca_evecs = np.eye(self.dim)\n        pca_evals = np.ones(self.dim)\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n            order = np.argsort(f)\n            elites = order[:max(2, int(np.ceil(self.p_elite_frac * pop)))]\n            probs = op_probs()\n            op_try[:] = 0.0\n            op_success[:] = 0.0\n\n            # shuffle individuals\n            order_proc = rng.permutation(pop)\n            for ii in order_proc:\n                if evals >= self.budget:\n                    break\n                xi = X[ii].copy()\n                fi = float(f[ii])\n\n                # choose operator, with small extra prob for Levy global jump\n                if rng.rand() < self.levy_prob:\n                    op_idx = 3  # levy jump override occasionally\n                else:\n                    op_idx = int(rng.choice(n_ops, p=probs))\n                op_try[op_idx] += 1.0\n\n                # produce trial\n                if op_idx == 0:\n                    # anisotropic local gaussian using per-dimension sigmas and momentum bias\n                    noise = rng.randn(self.dim) * sigma[ii]\n                    trial = xi + 0.6 * momentum[ii] + noise\n                elif op_idx == 1:\n                    # PCA-subspace sampling: sample mainly along top k eigenvectors (exploit archive structure)\n                    # pick top-k based on explained variance (k >=1)\n                    k = min(max(1, int(np.ceil(0.12 * self.dim))), self.dim)\n                    # project random gaussian onto top k eigenvectors with scaled variances\n                    z = np.zeros(self.dim)\n                    # draw coefficients for top-k\n                    coeffs = rng.randn(k) * np.sqrt(pca_evals[:k] + 1e-12)\n                    # assemble vector\n                    z[:k] = coeffs\n                    # map back using eigenvectors\n                    step = pca_evecs[:, :k].dot(z[:k])\n                    # scale step by average sigma magnitude\n                    avg_sigma = np.mean(sigma[ii])\n                    trial = xi + 0.9 * step * (avg_sigma / (np.linalg.norm(step) + 1e-12))\n                elif op_idx == 2:\n                    # centroid-guided recombination: move toward centroid of randomly selected elites plus anisotropic perturbation\n                    sel = rng.choice(elites, size=min(len(elites), max(2, int(1 + rng.rand() * len(elites)))), replace=False)\n                    centroid = np.mean(X[sel], axis=0)\n                    w = 0.3 + 0.7 * rng.rand()  # weight toward centroid\n                    trial = xi + w * (centroid - xi) + rng.randn(self.dim) * (0.5 * sigma[ii])\n                elif op_idx == 3:\n                    # heavy-tailed Lévy/Cauchy jump centered on best with random directional scaling\n                    scale = self.levy_scale_frac * np.mean(sigma[ii])\n                    center = x_best if rng.rand() < 0.8 else xi\n                    trial = center + cauchy_vec(scale)\n\n                # ensure valid candidate and clamp\n                trial = reflect_clamp(trial)\n\n                # evaluate trial if budget allows\n                if evals >= self.budget:\n                    break\n                fv = float(func(trial))\n                evals += 1\n\n                success = False\n                # selection: accept if better\n                if fv <= fi:\n                    success = True\n                    X[ii] = trial\n                    f[ii] = fv\n\n                    # compute displacement and update momentum (EMA)\n                    disp = trial - xi\n                    if np.all(np.isfinite(disp)):\n                        momentum[ii] = self.momentum_beta * momentum[ii] + (1.0 - self.momentum_beta) * disp\n\n                    # multiplicative sigma adaptation per-dimension\n                    # increase where improvements occurred along positive displacement, shrink otherwise\n                    # We'll use a simple rule: sigma <- sigma * exp(eta*(normalized_gain - target))\n                    # where normalized_gain is clipped directional improvement magnitude\n                    eta = 0.12  # learning rate\n                    # directional gain per-dim approximated by abs(disp)/ (sigma + eps)\n                    eps = 1e-12\n                    norm_gain = np.minimum(3.0, np.abs(disp) / (sigma[ii] + eps))\n                    # target success indicator ~1 so we multiply; if disp small, shrink; if large, expand\n                    sigma[ii] = sigma[ii] * np.exp(eta * (norm_gain - 0.5))\n                    # clamp sigma within sensible bounds\n                    sigma[ii] = np.minimum(np.maximum(sigma[ii], self.sigma_min), sigma_max)\n\n                    # update archive: store displacement relative to xi (or relative to best) with its fitness\n                    if len(archive_X) < self.archive_size:\n                        archive_X.append(trial.copy())\n                        archive_disp.append(disp.copy())\n                        archive_f.append(fv)\n                    else:\n                        # replace worst archived or random replacement biased by fitness\n                        worst_idx = int(np.argmax(np.array(archive_f)))\n                        if fv < archive_f[worst_idx]:\n                            archive_X[worst_idx] = trial.copy()\n                            archive_disp[worst_idx] = disp.copy()\n                            archive_f[worst_idx] = fv\n\n                    op_success[op_idx] += 1.0\n\n                    # opportunistic micro-step: try small farther step along disp\n                    if np.linalg.norm(disp) > 1e-12 and evals < self.budget:\n                        extra_frac = 0.12 + 0.6 * rng.rand()\n                        extra = trial + extra_frac * disp\n                        extra = reflect_clamp(extra)\n                        fv2 = float(func(extra))\n                        evals += 1\n                        if fv2 < f[ii]:\n                            X[ii] = extra\n                            f[ii] = fv2\n                            # also adjust sigma a little upward on success\n                            sigma[ii] = np.minimum(sigma[ii] * (1.0 + 0.05 * extra_frac), sigma_max)\n                            op_success[op_idx] += 0.3  # partial credit for extra success\n                    # track global best\n                    if f[ii] < f_best:\n                        f_best = float(f[ii])\n                        x_best = X[ii].copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # failure: shrink sigma moderately along dimensions with large proposed steps\n                    shrink_factor = 0.85\n                    sigma[ii] = np.maximum(sigma[ii] * shrink_factor, self.sigma_min)\n                    # reduce momentum slightly to avoid repeated bad directions\n                    momentum[ii] *= 0.9\n\n                # budget check\n                if evals >= self.budget:\n                    break\n\n            # end pop loop\n\n            # operator credit update (decay old credits, add normalized successes)\n            # smoothing: add successes scaled by fraction of tries (avoid overcrediting)\n            success_ratio = np.zeros_like(op_success)\n            with np.errstate(divide='ignore', invalid='ignore'):\n                success_ratio = np.where(op_try > 0, op_success / (op_try + 1e-12), 0.0)\n            # decay and update\n            op_credit = op_credit * self.op_credit_decay + (success_ratio + 1e-6)\n\n            # update archive PCA every pca_refresh gens\n            if gen % self.pca_refresh == 0 and len(archive_disp) >= 2:\n                D = np.vstack(archive_disp)\n                # center displacements\n                Dc = D - np.mean(D, axis=0, keepdims=True)\n                # covariance (diagonal or full depending on size)\n                try:\n                    C = np.cov(Dc, rowvar=False)\n                    # eigen-decomposition (small dims ok)\n                    evals_eig, evecs = np.linalg.eigh(C + 1e-12 * np.eye(self.dim))\n                    # sort descending\n                    idx = np.argsort(evals_eig)[::-1]\n                    pca_evals = np.maximum(evals_eig[idx], 0.0)\n                    pca_evecs = evecs[:, idx]\n                    # normalize eigenvalues for sampling stability\n                    if np.sum(pca_evals) > 0:\n                        pca_evals = pca_evals / (np.mean(pca_evals) + 1e-12)\n                    else:\n                        pca_evals = np.ones_like(pca_evals)\n                except np.linalg.LinAlgError:\n                    pca_evecs = np.eye(self.dim)\n                    pca_evals = np.ones(self.dim)\n\n            # if generation produced no improvement, increase stagnation counter\n            if not improved_in_gen:\n                gens_since_improve += 1\n            else:\n                gens_since_improve = 0\n\n            # soft restart if strongly stagnating: reinitialize a fraction of population around best with diversity\n            if gens_since_improve >= max(8, 2 + int(1.5 * np.log(self.dim))):\n                n_reinit = max(1, pop // 3)\n                for k in range(n_reinit):\n                    if evals >= self.budget:\n                        break\n                    idx_replace = int(np.argmax(f))\n                    # create a diversified candidate: mixture of gaussian around best and uniform jitter\n                    jitter = rng.randn(self.dim) * (0.8 * np.mean(sigma[idx_replace]))\n                    uniform_offset = (rng.rand(self.dim) - 0.5) * 0.2 * (ub - lb)\n                    candidate = x_best + jitter + uniform_offset\n                    candidate = reflect_clamp(candidate)\n                    fv = float(func(candidate))\n                    evals += 1\n                    X[idx_replace] = candidate.copy()\n                    f[idx_replace] = fv\n                    sigma[idx_replace] = np.tile(sigma_init, (1,))[0] if sigma_init.ndim == 1 else sigma_init.copy()\n                    momentum[idx_replace] = 0.0\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = candidate.copy()\n                        gens_since_improve = 0\n\n            # ensure best is tracked from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 97, in __call__, the following error occurred:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nOn line: sigma_init = max(1e-12, self.sigma_init_frac * ranges)  # vector per-dim", "error": "In the code, line 97, in __call__, the following error occurred:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\nOn line: sigma_init = max(1e-12, self.sigma_init_frac * ranges)  # vector per-dim", "parent_ids": "98b5d309-59bb-49ef-9442-6831b47dfff9", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "4f1dad32-d8e7-4e91-92a3-8f89bc17c650", "fitness": 0.2633947279974177, "name": "MOSAIC", "description": "MOSAIC is a small population-based heuristic that initializes a diverse population with Latin‑Hypercube sampling and maintains per‑individual, per‑dimension step scales (initialized from init_scale_frac and bounded by min_scale) to allow anisotropic local moves. It selects among five complementary operators (directional line probes toward the current best, adaptive gaussian local perturbations, elite recombination, heavy‑tailed Student‑t jumps for basin escape scaled by levy_scale_frac, and coordinate‑focused tweaks) using an UCB‑style score plus eps_greedy exploration (ucb_c, eps_explore) to balance exploitation and exploration. Success-driven adaptation expands scales along moved dimensions and failures shrink them (expand_factor, shrink_factor), with opportunistic extra probes and strict reflect‑then‑clamp boundary handling to respect bounds and exploit promising directions. Long‑term control uses periodic local intensification around the best (local_period), stagnation‑triggered soft restarts (stagn_thresh), a pop size heuristic based on dim/budget, and strict budget accounting for all function calls.", "code": "import numpy as np\n\nclass MOSAIC:\n    \"\"\"\n    MOSAIC: Multi-Operator Step-scale Adaptive Search for continuous black-box optimization.\n\n    Key high-level ingredients (and main tunable parameters):\n      - pop_size (pop): population size (heuristic based on dim and budget)\n      - init_scale_frac: initial per-dimension step scale as fraction of range_mean\n      - min_scale: minimum per-dimension scale\n      - expand_factor, shrink_factor: multiplicative updates to scales on success/failure\n      - levy_scale_frac: scale for heavy-tailed (Student-t) jumps relative to range_mean\n      - ucb_c: exploration constant for UCB-like operator selection\n      - p_frac: fraction for selecting elites\n      - local_period: how often to run concentrated local sampling around best\n      - stagn_thresh: stagnation threshold (generations without improvement) triggers intensification\n      - eps_explore: small epsilon for random operator exploration (epsilon-greedy)\n    The algorithm enforces strict budget accounting and respects func.bounds.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop=None,\n                 p_frac=0.2,\n                 init_scale_frac=0.15,\n                 min_scale=1e-6,\n                 expand_factor=1.25,\n                 shrink_factor=0.7,\n                 levy_scale_frac=0.6,\n                 ucb_c=1.2,\n                 local_period=30,\n                 stagn_thresh=45,\n                 eps_explore=0.08):\n        self.budget = int(budget)\n        self.dim = int(dim)\n\n        # tunables / algorithm parameters\n        self.pop = pop\n        self.p_frac = float(p_frac)\n        self.init_scale_frac = float(init_scale_frac)\n        self.min_scale = float(min_scale)\n        self.expand_factor = float(expand_factor)\n        self.shrink_factor = float(shrink_factor)\n        self.levy_scale_frac = float(levy_scale_frac)\n        self.ucb_c = float(ucb_c)\n        self.local_period = int(local_period)\n        self.stagn_thresh = int(stagn_thresh)\n        self.eps_explore = float(eps_explore)\n\n    def __call__(self, func):\n        rng = np.random.RandomState()  # reproducible local RNG if desired\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, float(lb), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, float(ub), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        range_vec = ub - lb\n        range_mean = float(np.mean(range_vec))\n        # population heuristic (different from the provided algorithm)\n        if self.pop is None:\n            # slightly larger pop for small dims, more dependence on dim\n            pop = max(6, int(np.ceil(4 + 3.0 * np.log(max(2, self.dim)))))\n        else:\n            pop = int(self.pop)\n        pop = min(pop, max(2, self.budget))  # cannot exceed budget\n\n        evals = 0\n\n        # --- Initialization: Latin-Hypercube style sampling to differ from mirrored-opposition ---\n        X = np.empty((pop, self.dim), dtype=float)\n        # simple LHS: for each dimension, split into pop strata and permute\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (perm + rng.rand(pop)) / float(pop)\n            X[:, d] = lb[d] + strata * (ub[d] - lb[d])\n        # small jitter\n        X += (rng.randn(pop, self.dim) * 1e-6 * range_vec)\n        # clamp\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # Evaluate initial population (sequential) with strict budget checks\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        if evals >= self.budget:\n            best_i = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_i])\n            self.x_opt = X[best_i].copy()\n            return self.f_opt, self.x_opt\n\n        # per-individual per-dimension step scales (vectorized) - different from scalar radii\n        init_scale = max(1e-12, self.init_scale_frac * range_mean)\n        # start with small random variability across dims\n        step_scales = np.maximum(self.min_scale,\n                                 init_scale * (1.0 + 0.2 * rng.randn(pop, self.dim)))\n\n        # operator pool: 5 operators (directional line probe, gaussian local, elite mix,\n        # heavy-tailed jump, coordinate-focused perturb)\n        n_ops = 5\n        # operator statistics for UCB-like selection: mean reward, tries\n        op_mean_reward = np.zeros(n_ops, dtype=float)  # running average improvement magnitude\n        op_tries = np.zeros(n_ops, dtype=float) + 1e-6  # small nonzero to avoid div-by-zero\n        total_tries = 0.0\n\n        # helper: reflect-then-clamp bounce same as original (single reflection)\n        def reflect_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        # helper heavy tail: Student-t with flexible df (~1.5) to mimic Levy-like heavy tails\n        def student_t_step(df, scale):\n            # RandomState has standard_t\n            return rng.standard_t(df, size=self.dim) * scale\n\n        # elites\n        def elite_indices():\n            k = max(2, int(np.ceil(self.p_frac * pop)))\n            return np.argsort(f)[:k]\n\n        # bookkeeping best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            order = np.argsort(f)\n            elites = order[:max(2, int(np.ceil(self.p_frac * pop)))]\n\n            # update selection scores (UCB-like)\n            total_tries += 0.0  # ensure defined\n            total_tries = op_tries.sum()\n            ucb_scores = op_mean_reward + self.ucb_c * np.sqrt(np.log(1.0 + total_tries) / (op_tries + 1e-12))\n\n            # iterate individuals in random order\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fi = float(f[ii])\n\n                # select operator with epsilon-greedy + UCB scores\n                if rng.rand() < self.eps_explore:\n                    op_idx = int(rng.randint(n_ops))\n                else:\n                    op_idx = int(np.argmax(ucb_scores))\n\n                op_tries[op_idx] += 1.0\n                total_tries += 1.0\n\n                candidate = xi.copy()\n                reward = 0.0  # improvement fi - f_new if any\n\n                # 0: directional_line: probe along x_best - xi with a small discrete line-scan\n                if op_idx == 0:\n                    d = x_best - xi\n                    nd = np.linalg.norm(d)\n                    if nd <= 1e-12:\n                        # fallback to gaussian local\n                        candidate = xi + rng.randn(self.dim) * step_scales[ii]\n                    else:\n                        # scale base step by per-dim average\n                        base_scale = max(self.min_scale, np.mean(step_scales[ii]))\n                        # probe a small set of fractions along the direction (including overshoot)\n                        fractions = np.array([0.4, 0.9, 1.5]) * (base_scale / nd)\n                        best_probe_value = fi\n                        best_probe = xi.copy()\n                        for frac in fractions:\n                            if evals >= self.budget:\n                                break\n                            probe = xi + frac * d\n                            probe = reflect_clamp(probe)\n                            fv = float(func(probe))\n                            evals += 1\n                            if fv < best_probe_value:\n                                best_probe_value = fv\n                                best_probe = probe.copy()\n                        # accept best probe if improved, otherwise keep xi\n                        if best_probe_value < fi:\n                            candidate = best_probe\n                            # small opportunistic extra along same direction (single extra eval)\n                            if evals < self.budget:\n                                disp = best_probe - xi\n                                extra = best_probe + 0.6 * disp\n                                extra = reflect_clamp(extra)\n                                fv2 = float(func(extra))\n                                evals += 1\n                                if fv2 < best_probe_value:\n                                    candidate = extra\n                                    best_probe_value = fv2\n                            reward = fi - best_probe_value\n\n                # 1: gaussian_local: isotropic gaussian using per-dim scales (vectorized)\n                elif op_idx == 1:\n                    # scale each dimension by its step_scale\n                    sigma = step_scales[ii] * (0.6 + 0.8 * rng.rand(self.dim))\n                    candidate = xi + rng.randn(self.dim) * sigma\n\n                # 2: elite_mix: convex recombination of two elites + small gaussian\n                elif op_idx == 2:\n                    if elites.size >= 2:\n                        a, b = rng.choice(elites, size=2, replace=False)\n                    else:\n                        a = b = elites[0]\n                    w = rng.rand()\n                    mix = w * X[a] + (1 - w) * X[b]\n                    # bias toward elites but keep some individuality\n                    alpha = 0.6 + 0.4 * rng.rand()\n                    candidate = xi + alpha * (mix - xi) + rng.randn(self.dim) * 0.12 * np.mean(step_scales[ii])\n\n                # 3: heavy_t_jump: student-t jump centered mostly on best to escape basins\n                elif op_idx == 3:\n                    df = 1.8  # heavy tail degree (different from pure Cauchy)\n                    scale = self.levy_scale_frac * np.maximum(np.mean(step_scales[ii]), range_mean * 0.02)\n                    center = x_best if rng.rand() < 0.8 else xi\n                    candidate = center + student_t_step(df, scale)\n\n                # 4: coord_focus: perturb random subset of coordinates proportionally to their local scales\n                elif op_idx == 4:\n                    # choose fraction of coordinates to change\n                    kcoords = max(1, int(np.ceil(0.15 * self.dim)))\n                    coords = rng.choice(self.dim, size=kcoords, replace=False)\n                    candidate = xi.copy()\n                    for d in coords:\n                        s = step_scales[ii, d] * (0.8 + 0.8 * rng.rand())\n                        candidate[d] += rng.randn() * s\n                # ensure bounded\n                candidate = reflect_clamp(candidate)\n\n                # if the operator already performed multiple internal evaluations (directional_line),\n                # reward may be set; otherwise evaluate candidate now\n                if reward == 0.0:\n                    if evals >= self.budget:\n                        break\n                    fv = float(func(candidate))\n                    evals += 1\n                    if fv < fi:\n                        reward = fi - fv\n                    else:\n                        reward = 0.0\n\n                # selection: accept if improved (strictly smaller)\n                # Note: in directional_line we might already have candidate and fv not stored; ensure fetch\n                # We will recompute candidate's f if needed (safe guards)\n                accept = False\n                # Try to obtain candidate's fitness (if not computed in directional_line scenario)\n                # To avoid double evaluation, we will check whether candidate equals a previous probe by comparing f array,\n                # but simpler: we can assume we have fv variable if reward computed (fv = fi - reward) maybe not available.\n                # For simplicity and strict accounting we will recompute if reward>0 and not having fv in scope:\n                # However we kept fv when evaluating candidate above; ensure fv exists.\n                try:\n                    fv  # use existing fv\n                except NameError:\n                    # If fv not defined, compute now (but protect by budget)\n                    if evals >= self.budget:\n                        break\n                    fv = float(func(candidate))\n                    evals += 1\n                # Accept-if-improved\n                if fv < fi - 1e-15:\n                    X[ii] = candidate\n                    f[ii] = fv\n                    accept = True\n                    # adapt per-dimension step scales: expand where we moved noticeably\n                    disp = candidate - xi\n                    move_abs = np.abs(disp)\n                    # expand dims with significant movement, slightly shrink others less\n                    mask = move_abs > (0.5 * np.mean(step_scales[ii]))\n                    step_scales[ii, mask] = np.maximum(step_scales[ii, mask] * self.expand_factor, self.min_scale)\n                    step_scales[ii, ~mask] = np.maximum(step_scales[ii, ~mask] * (1.0 + 0.15 * (rng.rand() - 0.5)), self.min_scale)\n                    # opportunistic single extra along disp direction\n                    if np.linalg.norm(disp) > 1e-12 and evals < self.budget:\n                        extra = candidate + 0.4 * disp\n                        extra = reflect_clamp(extra)\n                        fv2 = float(func(extra))\n                        evals += 1\n                        if fv2 < f[ii]:\n                            X[ii] = extra\n                            f[ii] = fv2\n                            # enlarge scales a bit more\n                            step_scales[ii] = np.maximum(step_scales[ii] * (1.0 + 0.05), self.min_scale)\n                else:\n                    # failure -> shrink scales moderately\n                    step_scales[ii] = np.maximum(step_scales[ii] * self.shrink_factor, self.min_scale)\n\n                # compute numeric reward used for operator statistics:\n                # If improved we have reward = fi - new_f (positive), else zero\n                if 'fv' in locals():\n                    op_reward = max(0.0, fi - float(f[ii]))\n                else:\n                    op_reward = 0.0\n\n                # update operator running average reward (simple exponential smoothing)\n                alpha = 0.2\n                op_mean_reward[op_idx] = (1.0 - alpha) * op_mean_reward[op_idx] + alpha * op_reward\n\n                # update best if needed\n                if f[ii] < f_best:\n                    f_best = float(f[ii])\n                    x_best = X[ii].copy()\n                    improved_in_gen = True\n                    gens_since_improve = 0\n\n                # cleanup local fv variable for next iteration to avoid stale usage\n                if 'fv' in locals():\n                    del fv\n\n                # enforce budget protection\n                if evals >= self.budget:\n                    break\n\n            # end for individuals\n\n            # update UCB scores for next generation\n            total_tries = op_tries.sum()\n            ucb_scores = op_mean_reward + self.ucb_c * np.sqrt(np.log(1.0 + total_tries) / (op_tries + 1e-12))\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n            else:\n                gens_since_improve = 0\n\n            # periodic localized intensification around current best (different schedule)\n            if (gen % self.local_period == 0) or (gens_since_improve >= self.stagn_thresh):\n                # small diagonal sampling around x_best using median step scales across population\n                median_scales = np.median(step_scales, axis=0)\n                local_sigma = np.maximum(self.min_scale, 0.7 * median_scales)\n                # number of samples limited by budget and dim\n                n_local = min(30 + self.dim, self.budget - evals)\n                for s in range(int(n_local)):\n                    if evals >= self.budget:\n                        break\n                    cand = x_best + rng.randn(self.dim) * (local_sigma * (0.4 + 0.8 * rng.rand(self.dim)))\n                    cand = reflect_clamp(cand)\n                    fv = float(func(cand))\n                    evals += 1\n                    if fv < f_best:\n                        f_best = float(fv)\n                        x_best = cand.copy()\n                        # inject into population replacing worst\n                        worst = int(np.argmax(f))\n                        X[worst] = cand.copy()\n                        f[worst] = fv\n                        # set its scales near median\n                        step_scales[worst] = np.maximum(median_scales * 0.8, self.min_scale)\n                        gens_since_improve = 0\n\n            # if severe stagnation, do a soft restart (nudge worst individuals toward best with diverse jitter)\n            if gens_since_improve >= self.stagn_thresh and evals < self.budget:\n                n_nudge = max(1, pop // 2)\n                for k in range(n_nudge):\n                    if evals >= self.budget:\n                        break\n                    idx_replace = int(np.argmax(f))\n                    # jitter scale proportional to range_mean but tempered by median scales\n                    jitter_scale = 0.18 * range_mean * (0.5 + rng.rand())\n                    candidate = x_best + rng.randn(self.dim) * (jitter_scale * (0.5 + 0.5 * rng.rand(self.dim)))\n                    candidate = reflect_clamp(candidate)\n                    fv = float(func(candidate))\n                    evals += 1\n                    X[idx_replace] = candidate\n                    f[idx_replace] = fv\n                    step_scales[idx_replace] = np.maximum(init_scale * 0.8, self.min_scale)\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = candidate.copy()\n                        gens_since_improve = 0\n\n            # ensure best tracked from population (safety)\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MOSAIC scored 0.263 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "98b5d309-59bb-49ef-9442-6831b47dfff9", "operator": null, "metadata": {"aucs": [0.07967057653554288, 0.15705326259763674, 0.3752917245544576, 0.4197648759854553, 0.2636519031016685, 0.3968165084418962, 0.2557575013962702, 0.3131682772154397, 0.22559644995273764, 0.14717620019307243]}, "task_prompt": ""}
{"id": "3c1f7b96-51af-4ff9-97e0-fdf53288bf2f", "fitness": 0.4397167037402781, "name": "HybridAdaptivePoolRefine", "description": "HybridAdaptivePoolRefine is a hybrid DE-style optimizer that mixes a small, iteration-friendly population (pop ≈ max(12, 4+3·log(dim))) with a 4-operator pool (current-to-pbest, diff-to-best, Gaussian local, heavy‑tailed Cauchy/Levy jump) and credit-driven operator selection (op_credit with decay op_credit_decay=0.88) to bias successful operators. It uses jDE-style self-adaptation for F and CR (tau_F/tau_CR = 0.12, F initialized around 0.5, CR uniform) plus per-individual trust radii (init_radius_frac=0.18, min_radius_frac tiny) that expand/shrink (radius_expand=1.15, radius_shrink=0.85) based on success, and scales heavy tails with levy_scale_frac=0.6. Initialization is stratified mirrored‑opposition with small jitter to cover the bounds, and a reflect_clamp boundary handler prevents out-of-bounds behavior; successful moves trigger opportunistic extra probes along the displacement for quick refinement. Periodic and stagnation-triggered intensification (local_period=20, local_stagn_gen=30) applies a Hooke–Jeeves coordinate search followed by progressive Gaussian trust-region sampling and soft restarts (nudge half the population around the best) to balance global exploration and local exploitation.", "code": "import numpy as np\n\nclass HybridAdaptivePoolRefine:\n    \"\"\"\n    HybridAdaptivePoolRefine\n    - Combines a credit-driven operator pool (current-to-pbest, diff-to-best, gaussian_local, levy/cauchy jump)\n      with jDE-style F/CR self-adaptation, per-individual trust radii, and periodic Hooke-Jeeves + progressive Gaussian\n      local refinement around the global best. Opportunistic extra probes on success and soft restarts on stagnation.\n    One-line idea: credit-steered multi-operator DE + trust radii + periodic coordinate/Gaussian refinement.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 p_frac=0.2,\n                 tau_F=0.12, tau_CR=0.12,\n                 F_min=0.05, F_max=0.95,\n                 init_radius_frac=0.18, min_radius_frac=1e-6,\n                 radius_expand=1.15, radius_shrink=0.85,\n                 levy_scale_frac=0.6,\n                 local_period=20, local_stagn_gen=30,\n                 initial_step_frac=0.20, step_shrink=0.5, min_step_frac=1e-4,\n                 op_credit_decay=0.88,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.p_frac = float(p_frac)\n        self.tau_F = float(tau_F)\n        self.tau_CR = float(tau_CR)\n        self.F_min = float(F_min)\n        self.F_max = float(F_max)\n        self.init_radius_frac = float(init_radius_frac)\n        self.min_radius_frac = float(min_radius_frac)\n        self.radius_expand = float(radius_expand)\n        self.radius_shrink = float(radius_shrink)\n        self.levy_scale_frac = float(levy_scale_frac)\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.initial_step_frac = float(initial_step_frac)\n        self.step_shrink = float(step_shrink)\n        self.min_step_frac = float(min_step_frac)\n        self.op_credit_decay = float(op_credit_decay)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size heuristic (small to allow many iterations)\n        if self.pop_base is None:\n            pop = max(12, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # initialize quasi-uniform mirrored-opposition + stratification\n        X = np.empty((pop, self.dim), dtype=float)\n        # stratified per-dimension base for half, mirror for remainder\n        half = (pop + 1) // 2\n        center = 0.5 * (lb + ub)\n        for i in range(half):\n            # stratified sample across dimensions\n            u = rng.rand(self.dim)\n            X[i] = lb + u * (ub - lb)\n            j = i + half\n            if j < pop:\n                X[j] = 2.0 * center - X[i]\n        # jitter small to break symmetry\n        X += (rng.randn(pop, self.dim) * 1e-3 * (ub - lb))\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-individual control: F and CR (jDE-style) and trust radii\n        F = np.clip(0.5 + 0.1 * rng.randn(pop), self.F_min, self.F_max)\n        CR = np.clip(rng.rand(pop), 0.0, 1.0)\n        range_mean = float(np.mean(ub - lb))\n        init_radius = max(1e-12, self.init_radius_frac * range_mean)\n        min_radius = max(1e-12, self.min_radius_frac * range_mean)\n        radius = np.full(pop, init_radius, dtype=float)\n\n        # operator pool: 0=current-to-pbest,1=diff-to-best,2=gaussian_local,3=levy_jump\n        n_ops = 4\n        op_credit = np.ones(n_ops, dtype=float)\n\n        def op_probs():\n            s = np.sum(op_credit)\n            if s <= 0:\n                return np.full(n_ops, 1.0 / n_ops)\n            return op_credit / s\n\n        def reflect_clamp(x):\n            x_ref = x.copy()\n            below = x_ref < lb\n            if np.any(below):\n                x_ref[below] = lb[below] + (lb[below] - x_ref[below])\n            above = x_ref > ub\n            if np.any(above):\n                x_ref[above] = ub[above] - (x_ref[above] - ub[above])\n            x_ref = np.minimum(np.maximum(x_ref, lb), ub)\n            return x_ref\n\n        def cauchy_step(scale):\n            return rng.standard_cauchy(self.dim) * scale\n\n        # track best\n        bi = int(np.argmin(f))\n        f_best = float(f[bi])\n        x_best = X[bi].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        # bookkeeping for op credits per generation\n        op_try = np.zeros(n_ops, dtype=float)\n        op_success = np.zeros(n_ops, dtype=float)\n\n        # helper to update op credits\n        def update_op_credit(old_credit, successes, decay):\n            new = old_credit * decay + successes * (1.0 - decay) * (1.0 + 0.5)\n            new = np.maximum(new, 1e-8)\n            return new\n\n        # helper to pick p-best pool indices\n        def pbest_pool():\n            k = max(2, int(np.ceil(self.p_frac * pop)))\n            return np.argsort(f)[:k]\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            order = np.argsort(f)\n            p_pool = order[:max(2, int(np.ceil(self.p_frac * pop)))]\n\n            op_try[:] = 0.0\n            op_success[:] = 0.0\n            probs = op_probs()\n\n            # iterate individuals in random order\n            for ii in rng.permutation(pop):\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fi = float(f[ii])\n\n                # self-adapt F and CR jDE-style\n                if rng.rand() < self.tau_F:\n                    F[ii] = np.clip(0.5 * (1.0 + 0.5 * rng.randn()), self.F_min, self.F_max)\n                if rng.rand() < self.tau_CR:\n                    CR[ii] = rng.rand()\n\n                # pick operator by credit-proportional sampling (soft)\n                op_idx = rng.choice(n_ops, p=probs)\n                op_try[op_idx] += 1.0\n\n                trial = xi.copy()\n\n                # operator implementations\n                if op_idx == 0:\n                    # current-to-pbest/1 (mix of greedy and diversity)\n                    pidx = int(rng.choice(p_pool))\n                    # pick two others distinct\n                    others = [j for j in range(pop) if j not in (ii, pidx)]\n                    if len(others) >= 2:\n                        r1, r2 = rng.choice(others, size=2, replace=False)\n                    elif len(others) == 1:\n                        r1 = others[0]; r2 = ii\n                    else:\n                        r1 = r2 = ii\n                    vi = xi + F[ii] * (X[pidx] - xi) + F[ii] * (X[r1] - X[r2])\n                    # binomial crossover style mask using CR[ii]\n                    jrand = rng.randint(self.dim)\n                    mask = rng.rand(self.dim) < CR[ii]\n                    mask[jrand] = True\n                    trial = np.where(mask, vi, xi)\n\n                elif op_idx == 1:\n                    # diff-to-best: directional move toward best plus differential perturbation\n                    others = [j for j in range(pop) if j != ii]\n                    if len(others) >= 2:\n                        a, b = rng.choice(others, size=2, replace=False)\n                    else:\n                        a = b = ii\n                    beta = 0.05 + 0.9 * rng.rand()  # [0.05,0.95]\n                    trial = xi + beta * (x_best - xi) + beta * (X[a] - X[b])\n\n                elif op_idx == 2:\n                    # gaussian_local around xi scaled by radius\n                    scale = radius[ii]\n                    trial = xi + rng.randn(self.dim) * (scale * (0.4 + 0.6 * rng.rand()))\n\n                elif op_idx == 3:\n                    # heavy-tailed escape: cauchy/levy jump centered on best with some probability\n                    scale = self.levy_scale_frac * radius[ii]\n                    center = x_best if rng.rand() < 0.8 else xi\n                    trial = center + cauchy_step(scale)\n\n                # reflect and clamp\n                trial = reflect_clamp(trial)\n\n                # budget check\n                if evals >= self.budget:\n                    break\n\n                # evaluate\n                fv = float(func(trial))\n                evals += 1\n\n                accepted = False\n                if fv <= fi:\n                    # accept\n                    accepted = True\n                    X[ii] = trial\n                    f[ii] = fv\n                    # expand radius a bit\n                    radius[ii] = min(radius[ii] * self.radius_expand, range_mean)\n                    op_success[op_idx] += 1.0\n\n                    # opportunistic extra probe along displacement\n                    disp = trial - xi\n                    if np.linalg.norm(disp) > 0 and evals < self.budget:\n                        extra_frac = 0.25 + 0.7 * rng.rand()\n                        extra = trial + extra_frac * disp\n                        extra = reflect_clamp(extra)\n                        fv2 = float(func(extra))\n                        evals += 1\n                        if fv2 < f[ii]:\n                            X[ii] = extra\n                            f[ii] = fv2\n                            # additional radius reward\n                            radius[ii] = min(radius[ii] * (1.0 + 0.06 * extra_frac), range_mean)\n\n                    # update global best\n                    if f[ii] < f_best:\n                        f_best = float(f[ii])\n                        x_best = X[ii].copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # failure -> shrink radius\n                    radius[ii] = max(radius[ii] * self.radius_shrink, min_radius)\n\n                # end per-individual\n\n                if evals >= self.budget:\n                    break\n\n            # update operator credits\n            op_credit = update_op_credit(op_credit, op_success, self.op_credit_decay)\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n            else:\n                gens_since_improve = 0\n\n            # periodic / stagnation-triggered local intensification around x_best\n            if gen % self.local_period == 0 or gens_since_improve >= self.local_stagn_gen:\n                remaining = self.budget - evals\n                if remaining <= 0:\n                    break\n\n                # Hooke-Jeeves style coordinate search (cheap)\n                step = max(1e-12, self.initial_step_frac * np.mean(ub - lb))\n                min_step = max(1e-12, self.min_step_frac * np.mean(ub - lb))\n                if gens_since_improve >= self.local_stagn_gen:\n                    step *= 1.8  # try to escape\n                x_work = x_best.copy()\n                f_work = f_best\n                local_improved = False\n\n                while step >= min_step and (self.budget - evals) > 0:\n                    moved = False\n                    for d in range(self.dim):\n                        if evals >= self.budget:\n                            break\n                        # try plus\n                        xt = x_work.copy()\n                        xt[d] = xt[d] + step\n                        if xt[d] > ub[d]:\n                            xt[d] = ub[d]\n                        if np.allclose(xt, x_work):\n                            xt[d] = x_work[d] - step\n                            if xt[d] < lb[d]:\n                                xt[d] = lb[d]\n                        xt = reflect_clamp(xt)\n                        fv = float(func(xt)); evals += 1\n                        if fv < f_work:\n                            x_work = xt.copy(); f_work = fv; moved = True; local_improved = True\n                            if fv < f_best:\n                                f_best = fv; x_best = xt.copy(); gens_since_improve = 0\n                            # opportunistic extra probe\n                            if evals < self.budget:\n                                xt2 = x_work.copy()\n                                xt2[d] = np.minimum(np.maximum(xt2[d] + step, lb[d]), ub[d])\n                                xt2 = reflect_clamp(xt2)\n                                fv2 = float(func(xt2)); evals += 1\n                                if fv2 < f_work:\n                                    x_work, f_work = xt2.copy(), fv2\n                                    if fv2 < f_best:\n                                        f_best = fv2; x_best = xt2.copy(); gens_since_improve = 0\n                        else:\n                            # try minus\n                            if evals >= self.budget:\n                                break\n                            xt = x_work.copy()\n                            xt[d] = x_work[d] - step\n                            if xt[d] < lb[d]:\n                                xt[d] = lb[d]\n                            xt = reflect_clamp(xt)\n                            fv = float(func(xt)); evals += 1\n                            if fv < f_work:\n                                x_work = xt.copy(); f_work = fv; moved = True; local_improved = True\n                                if fv < f_best:\n                                    f_best = fv; x_best = xt.copy(); gens_since_improve = 0\n                    if not moved:\n                        step *= self.step_shrink\n                    # continue while budget remains\n                    if evals >= self.budget:\n                        break\n\n                if local_improved:\n                    # inject into population replacing worst\n                    worst = int(np.argmax(f))\n                    X[worst] = x_work.copy(); f[worst] = f_work\n                    radius[worst] = max(radius[worst] * 0.9, min_radius)\n                    gens_since_improve = 0\n                else:\n                    # progressive Gaussian local sampling (trust-region style)\n                    local_sigma = max(min_radius, 0.5 * np.mean(radius))\n                    local_shrink = 0.5\n                    iter_local = 0\n                    while local_sigma >= min_radius and evals < self.budget and iter_local < 6:\n                        n_samples = int(min(6 + self.dim // 2, self.budget - evals))\n                        for _ in range(n_samples):\n                            if evals >= self.budget:\n                                break\n                            cand = x_best + rng.randn(self.dim) * local_sigma\n                            cand = reflect_clamp(cand)\n                            fv = float(func(cand)); evals += 1\n                            if fv < f_best:\n                                f_best = fv; x_best = cand.copy(); gens_since_improve = 0\n                                # inject candidate into population\n                                worst = int(np.argmax(f))\n                                X[worst] = cand.copy(); f[worst] = fv\n                                radius[worst] = max(radius[worst] * 0.85, min_radius)\n                        # if improved recently, sample a few more at same sigma\n                        iter_local += 1\n                        local_sigma *= local_shrink\n\n                    # if still stagnating, soft restart: nudge half population around best\n                    if gens_since_improve >= self.local_stagn_gen:\n                        n_nudge = pop // 2\n                        for k in range(n_nudge):\n                            if evals >= self.budget:\n                                break\n                            idx_replace = int(np.argmax(f))\n                            jitter_scale = 0.06 * (ub - lb) * (0.5 + rng.rand(self.dim))\n                            cand = x_best + rng.randn(self.dim) * jitter_scale\n                            cand = reflect_clamp(cand)\n                            fv = float(func(cand)); evals += 1\n                            X[idx_replace] = cand; f[idx_replace] = fv\n                            radius[idx_replace] = init_radius\n                            if fv < f_best:\n                                f_best = fv; x_best = cand.copy(); gens_since_improve = 0\n\n            # safety update: take best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi]); x_best = X[bi].copy(); gens_since_improve = 0\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptivePoolRefine scored 0.440 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "98b5d309-59bb-49ef-9442-6831b47dfff9", "operator": null, "metadata": {"aucs": [0.15347880970473737, 0.20498006467411511, 0.6727103139445296, 0.9886178340106915, 0.33588176678998494, 0.8709026431064844, 0.2872593401410459, 0.4544923579005493, 0.26590534008191036, 0.16293856704873189]}, "task_prompt": ""}
{"id": "abecda72-6197-4c1d-8cd3-8451b5bb8714", "fitness": 0.44407415923257226, "name": "MAEDS", "description": "The algorithm is an ensemble-based adaptive search that samples candidates from a multivariate Gaussian whose covariance is updated as a blend of rank-mu (weighted recombination of top offspring) and a small rank-one term built from a slowly updated evolution path (c_cov small, cov_memory ~0.75, path_decay ~0.9) to keep a mix of stable memory and directional adaptation. Step-size (sigma) is adapted by an exponential rule driven by a smoothed success-rate p_succ (alpha_success small, success_target ~0.25, sigma_adapt_rate moderate) with a dimensionality scaling to avoid overly aggressive changes in high-D. Several auxiliary, budget-aware operators are used for exploration/exploitation: low-rank subspace modeling built from archive differences and local linear least-squares to propose descent steps, mirrored directional probes to estimate directional derivatives and take quasi-gradient steps, and occasional heavy‑tailed global jumps for diversification; all evaluations are clamped to bounds and performed sequentially to strictly respect the budget. Robustness features include an elite archive, conservative restarts when stagnation is detected (shrink sigma, re-center, reset covariance and inject nudges), Cholesky/eigen fallback to ensure SPD sampling, and heuristics for population size and initial covariance tuned to the problem span.", "code": "import numpy as np\n\nclass MAEDS:\n    \"\"\"\n    Model-Assisted Ensemble Directional Search (MAEDS)\n\n    One-line idea:\n      Ensemble sampling from an adaptive covariance with an evolution path,\n      combined with occasional low-rank subspace models and mirrored directional probes,\n      adaptive sigma via smoothed success-rate, and conservative local restarts.\n\n    Key parameters (sane defaults; tunable):\n      - budget, dim (required)\n      - pop_base: base population size (if None, use sqrt(dim)-style heuristic)\n      - c_cov: small rank-one weight for path term when updating covariance\n      - cov_memory: memory factor for previous covariance (0..1)\n      - path_decay: decay for evolution path accumulation\n      - sigma_adapt_rate: multiplicative step-size adaptation intensity\n      - success_target: target success rate for sigma adaptation\n      - alpha_success: smoothing factor for success-rate\n      - stagnation_frac: fraction of budget to consider stagnation for conservative restart\n      - p_model/p_dir/p_global: probabilities to attempt subspace model, mirrored directional, or global jump\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, pop_base=None, rng_seed=None,\n                 c_cov=0.12, cov_memory=0.75, path_decay=0.9,\n                 sigma_adapt_rate=0.35, success_target=0.25, alpha_success=0.15,\n                 stagnation_frac=0.06,\n                 p_model=0.40, p_dir=0.35, p_global=0.25):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.rng_seed = rng_seed\n\n        self.c_cov = float(c_cov)\n        self.cov_memory = float(cov_memory)\n        self.path_decay = float(path_decay)\n\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.success_target = float(success_target)\n        self.alpha_success = float(alpha_success)\n\n        self.stagnation_frac = float(stagnation_frac)\n        self.stagnation_threshold = max(5, int(self.stagnation_frac * max(1, self.budget)))\n\n        # probabilities for auxiliary moves (they are attempted opportunistically)\n        self.p_model = float(p_model)\n        self.p_dir = float(p_dir)\n        self.p_global = float(p_global)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds handling\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        min_diag = 1e-12\n\n        # population size heuristic\n        if self.pop_base is None:\n            lam = max(8, int(6 + 4 * np.sqrt(max(1, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        evals = 0\n\n        # Initial sampling: quasi-uniform small ensemble to bootstrap mean and covariance\n        init_batch = min(lam, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([float(func(x)) for x in X0])\n        evals += init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # weights for initial mean: top half log-biased\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(np.arange(mu0, 0, -1) + 0.6)\n        w0 = np.maximum(w0, 0.0)\n        w0 = w0 / np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance: diagonal, modest\n        C = np.diag(((span / 6.0) ** 2).clip(min=min_diag))\n\n        # initial sigma\n        sigma = max(1e-12, 0.20 * avg_span)\n\n        # evolution path and success smoothing\n        p_c = np.zeros(self.dim, dtype=float)\n        p_succ = 0.2\n        stagn_count = 0\n        iter_count = 0\n\n        # elite archive: keep sorted (f,x)\n        archive = []\n        def archive_insert(fx, x):\n            # maintain archive sorted and capped\n            archive.append((float(fx), x.copy()))\n            archive.sort(key=lambda t: t[0])\n            maxk = max(3, min(12, 4 + self.dim // 2))\n            while len(archive) > maxk:\n                archive.pop()\n\n        archive_insert(f_best, x_best)\n\n        # helper: ensure SPD for sampling\n        def chol_or_eig(M):\n            eps = 1e-12 * np.maximum(np.diag(M), 1.0)\n            try:\n                A = np.linalg.cholesky(M + np.diag(eps))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(M)\n                vals = np.clip(vals, min_diag, None)\n                A = (vecs * np.sqrt(vals)).T\n            return A\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu = max(1, lam_iter // 2)\n\n            # recompute log-biased weights\n            ranks = np.arange(1, mu + 1)\n            weights = np.log(mu + 0.5) - np.log(ranks + 0.2)\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # sampling from C via Cholesky or eigen fallback\n            A = chol_or_eig(C)\n\n            # propose lam_iter candidates (but evaluate sequentially to strictly respect budget)\n            Z = rng.normal(size=(lam_iter, self.dim))\n            Y = Z @ (A.T)\n            Xcand = m.reshape(1, -1) + sigma * Y\n            # clamp per candidate\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates sequentially\n            fc = np.full(lam_iter, np.inf, dtype=float)\n            for i in range(lam_iter):\n                if evals >= self.budget:\n                    break\n                xi = Xcand[i]\n                fi = float(func(xi))\n                fc[i] = fi\n                evals += 1\n                # update archive as we go\n                if fi < f_best:\n                    f_best = fi\n                    x_best = xi.copy()\n                    archive_insert(fi, xi)\n\n            # if no evals (budget exhausted), break\n            if np.all(np.isinf(fc)):\n                break\n\n            # generation best\n            gen_best_idx = int(np.nanargmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                # Should have updated above, but keep consistent\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                archive_insert(f_best, x_best)\n                improved = True\n                stagn_count = 0\n            else:\n                # if any candidate improved over previous m or over best?\n                if gen_best_f < float(np.inf) and gen_best_f < f_best:\n                    f_best = gen_best_f\n                    x_best = gen_best_x.copy()\n                    archive_insert(f_best, x_best)\n                    improved = True\n                    stagn_count = 0\n                else:\n                    stagn_count += 1\n\n            # recombine to get new mean from top mu of the generation (using weights)\n            valid_idx = np.argsort(fc)[:mu]\n            X_mu = Xcand[valid_idx]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized steps\n            deltas = (X_mu - m) / (sigma + 1e-20)   # shape (mu, dim)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas\n\n            # update evolution path and covariance (blend rank-mu and rank-one)\n            y_w = (m_new - m) / (sigma + 1e-20)\n            p_c = self.path_decay * p_c + (1.0 - self.path_decay) * y_w\n            rank_one = np.outer(p_c, p_c)\n\n            C_new = (self.cov_memory * C +\n                     (1.0 - self.cov_memory) * ((1.0 - self.c_cov) * weighted_cov + self.c_cov * rank_one))\n            # symmetric and add tiny jitter\n            C = 0.5 * (C_new + C_new.T)\n            diagC = np.diag(C)\n            jitter = 1e-12 * np.maximum(diagC, 1.0)\n            C += np.diag(jitter)\n\n            # accept new mean\n            m = m_new\n\n            # success smoothing and sigma adaptation (scale down effect with sqrt(dim) a bit)\n            p_succ = (1.0 - self.alpha_success) * p_succ + self.alpha_success * float(improved)\n            dim_scale = 1.0 + 0.5 * np.sqrt(max(1, self.dim))\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target) / dim_scale)\n            # clamp sigma\n            sigma = float(np.clip(sigma, 1e-12, 2.0 * np.max(span)))\n\n            # Opportunistic auxiliary actions, budget-aware:\n            # choose an auxiliary op with probabilities but only if some budget left\n            if evals < self.budget:\n                op = rng.rand()\n                # 1) low-rank subspace modeling (like AMDS) using recent archive points\n                if op < self.p_model and len(archive) >= 3 and (self.budget - evals) >= 4:\n                    # pick a small k and build linear model in random subspace spanned by archive diffs\n                    k = min(self.dim, max(1, min(3, len(archive) - 1)))\n                    # build basis from top archive differences\n                    base = archive[0][1].copy()\n                    diffs = np.vstack([archive[i+1][1] - archive[0][1] for i in range(min(len(archive)-1, k))])\n                    # if diffs are degenerate, use random vectors\n                    if np.linalg.matrix_rank(diffs) < 1:\n                        U = np.linalg.qr(rng.randn(self.dim, k))[0][:, :k]\n                    else:\n                        # orthonormalize diffs\n                        try:\n                            Q, _ = np.linalg.qr(diffs.T)\n                            U = Q[:, :k]\n                        except Exception:\n                            U = np.linalg.qr(rng.randn(self.dim, k))[0][:, :k]\n                    # create small design in subspace\n                    sigma_loc = max(1e-12, 0.8 * sigma)\n                    s = min(max(4, 2 + 2 * k), self.budget - evals)\n                    Z = rng.uniform(-1.0, 1.0, size=(s, k))\n                    Xs = np.array([np.minimum(np.maximum(base + (U @ (sigma_loc * z)).reshape(-1), lb), ub) for z in Z])\n                    fvals = []\n                    for xi in Xs:\n                        if evals >= self.budget:\n                            break\n                        fi = float(func(xi))\n                        evals += 1\n                        fvals.append(fi)\n                        archive_insert(fi, xi)\n                    if len(fvals) >= max(1, k):\n                        fvals = np.asarray(fvals, dtype=float)\n                        Z_used = Z[:len(fvals), :]\n                        A_mat = np.concatenate([np.ones((len(fvals), 1)), Z_used], axis=1)\n                        try:\n                            sol, *_ = np.linalg.lstsq(A_mat, fvals, rcond=None)\n                            g_sub = sol[1:]\n                            g_full = (U @ g_sub).astype(float)\n                            gnorm = np.linalg.norm(g_full)\n                            if gnorm > 1e-12:\n                                step_scale = sigma_loc * (1.0 + 0.3 * rng.standard_cauchy() * 0.1)\n                                proposed = base - step_scale * g_full / gnorm\n                                proposed = np.minimum(np.maximum(proposed, lb), ub)\n                                if evals < self.budget:\n                                    fp = float(func(proposed))\n                                    evals += 1\n                                    archive_insert(fp, proposed)\n                                    if fp < f_best:\n                                        f_best = fp; x_best = proposed.copy()\n                                        # success\n                                        sigma = min(2.0 * np.max(span), sigma * 1.2)\n                                        p_succ = min(1.0, p_succ + 0.05)\n                                    else:\n                                        sigma = max(1e-12, sigma * 0.85)\n                                        p_succ = max(0.0, p_succ - 0.03)\n                        except Exception:\n                            # if LS fails, do nothing\n                            pass\n\n                # 2) mirrored directional probes (central differences) guided by archive differences\n                elif op < self.p_model + self.p_dir and (self.budget - evals) >= 2:\n                    # choose up to d directions (budget-limited)\n                    remaining = self.budget - evals\n                    max_d = min(4, self.dim)\n                    d = min(max_d, max(1, remaining // 2))\n                    # build directions from archive differences preferentially\n                    directions = []\n                    if len(archive) >= 2 and rng.rand() < 0.8:\n                        for i in range(min(d, len(archive)-1)):\n                            v = archive[i+1][1] - archive[0][1]\n                            nrm = np.linalg.norm(v)\n                            if nrm > 1e-12:\n                                directions.append(v / nrm)\n                    while len(directions) < d:\n                        v = rng.randn(self.dim)\n                        v = v / (np.linalg.norm(v) + 1e-12)\n                        directions.append(v)\n                    # perform mirrored probes and assemble gradient estimate\n                    grad_est = np.zeros(self.dim, dtype=float)\n                    used = 0\n                    center = archive[0][1].copy() if len(archive) > 0 else m.copy()\n                    center_f = float(archive[0][0]) if len(archive) > 0 else np.inf\n                    for v in directions:\n                        if evals + 2 > self.budget:\n                            break\n                        delta = sigma * (0.6 + 0.8 * rng.rand())\n                        xp = np.minimum(np.maximum(center + delta * v, lb), ub)\n                        xn = np.minimum(np.maximum(center - delta * v, lb), ub)\n                        fp = float(func(xp)); evals += 1\n                        fn = float(func(xn)); evals += 1\n                        archive_insert(fp, xp); archive_insert(fn, xn)\n                        ddir = (fp - fn) / (2.0 * delta)\n                        grad_est += ddir * v\n                        used += 2\n                    if used > 0:\n                        gnorm = np.linalg.norm(grad_est)\n                        if gnorm < 1e-12:\n                            # small exploratory step\n                            proposed = center + 0.5 * sigma * rng.randn(self.dim)\n                        else:\n                            proposed = center - (0.9 * sigma) * grad_est / gnorm\n                        proposed = np.minimum(np.maximum(proposed, lb), ub)\n                        if evals < self.budget:\n                            fp = float(func(proposed)); evals += 1\n                            archive_insert(fp, proposed)\n                            if fp < f_best:\n                                f_best = fp; x_best = proposed.copy()\n                                sigma = min(2.0 * np.max(span), sigma * 1.15)\n                                p_succ = min(1.0, p_succ + 0.04)\n                            else:\n                                sigma = max(1e-12, sigma * 0.88)\n                                p_succ = max(0.0, p_succ - 0.02)\n\n                # 3) global heavy-tailed jump (diversification)\n                else:\n                    if evals >= self.budget:\n                        continue\n                    base = archive[0][1] if len(archive) > 0 and rng.rand() < 0.8 else rng.uniform(lb, ub)\n                    c = float(np.clip(rng.standard_cauchy(), -50, 50))\n                    anis = (0.15 + 0.85 * rng.rand()) * (span + 1e-12)\n                    jump = c * (0.4 + 0.6 * rng.rand()) * anis * rng.randn(self.dim)\n                    proposed = np.minimum(np.maximum(base + jump, lb), ub)\n                    fp = float(func(proposed)); evals += 1\n                    archive_insert(fp, proposed)\n                    if fp < f_best:\n                        f_best = fp; x_best = proposed.copy()\n                        sigma = min(2.0 * np.max(span), sigma * 1.25)\n                        p_succ = min(1.0, p_succ + 0.06)\n                    else:\n                        sigma = max(1e-12, sigma * 0.9)\n                        p_succ = max(0.0, p_succ - 0.03)\n\n            # conservative restart if stagnating heavily\n            if stagn_count * lam >= self.stagnation_threshold and evals < self.budget:\n                stagn_count = 0\n                # shrink sigma and re-center near best with jitter, reset covariance to smaller isotropic\n                sigma *= (0.25 + 0.6 * rng.rand())  # shrink to 0.25..0.85\n                m = x_best.copy()\n                C = np.diag(((span / 8.0) ** 2).clip(min=min_diag))\n                p_c = np.zeros_like(p_c)\n                # increase ensemble a bit for exploration (but keep sensible)\n                lam = min(max(4, lam + 2), max(4, self.budget))\n                # small uniform injections around best\n                nudges = min(4, max(1, int(self.dim / 3)))\n                for _ in range(nudges):\n                    if evals >= self.budget:\n                        break\n                    jitter = (0.06 * span) * rng.randn(self.dim)\n                    nx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                    nf = float(func(nx)); evals += 1\n                    archive_insert(nf, nx)\n                    if nf < f_best:\n                        f_best = nf; x_best = nx.copy()\n\n            # maintain best from archive\n            if len(archive) > 0:\n                if archive[0][0] < f_best:\n                    f_best = float(archive[0][0])\n                    x_best = archive[0][1].copy()\n\n            # safety: break if no budget left\n            if evals >= self.budget:\n                break\n\n        # finalize best\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MAEDS scored 0.444 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "98b5d309-59bb-49ef-9442-6831b47dfff9", "operator": null, "metadata": {"aucs": [0.1450807012309463, 0.1595535857299124, 0.38044117138554745, 0.39643172706796304, 0.8056863867952209, 0.6834516359698775, 0.279370043677152, 0.48344018542136535, 0.9351035821974435, 0.1721825728502937]}, "task_prompt": ""}
{"id": "9db3e635-30b5-43a4-b3e2-6c6d7fa8b1d4", "fitness": 0.3851003712587369, "name": "DTATR", "description": "The algorithm keeps an elite archive of evaluated points and a compact directional memory D (orthonormalized via QR) built from recent successful step vectors to focus search in promising low-rank subspaces. Proposals come from a triangulation operator (barycentric center from a Dirichlet-like draw, difference vectors augmented by D, and heavy-tailed Student‑t coefficients in the reduced subspace) and a complementary archive-biased DE-like operator (lognormal F around 0.6, high CR crossover, plus occasional directional jitter), with rare global Cauchy/Levy jumps for escapes. A multiplicative trust radius r (init ~0.3·mean(bounds)) is adaptively updated from a smoothed success probability (target ~0.25, r_adapt ~0.18), and stagnation triggers either heavy escapes (levy_prob ~0.07) or mild restarts; all proposals are clamped to box bounds and evaluations strictly respect the budget. Directional memory is refreshed by a recency-weighted SVD of buffered successful steps and smoothed into D (alpha ~0.25), while the archive uses elite replacement (size ~max(20,6·dim)) and initial seeding (~min(pop*2,5% budget)).", "code": "import numpy as np\n\nclass DTATR:\n    \"\"\"\n    Directional Triangulation Adaptive Trust-Region (DTATR)\n\n    Key ideas:\n    - Maintain an archive of evaluated points (with elite bias). Build a low-rank directional memory\n      (D) from recent successful step vectors and orthonormalize it; use D as a subspace to propose\n      concentrated moves (cheap local searches).\n    - Triangulation proposals: pick a small simplex of archive elites, form a random barycentric\n      center (Dirichlet weights) and sample along orthogonalized difference directions (Student-t\n      coefficients) scaled by a trust-region radius r.\n    - A complementary DE-like operator mixes archive vectors with lognormal-F and gaussian CR.\n    - Adaptive trust radius r is adjusted from smoothed success rate; directional memory is updated\n      from successful steps with exponential forgetting.\n    - Occasional heavy-tailed global jumps (multivariate Cauchy / Lévy-like) on stagnation.\n    - All proposals are clamped to problem bounds and the func() is not called beyond budget.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop=20, dir_dim=None, init_radius=None,\n                 success_target=0.25, r_adapt=0.18,\n                 archive_size=None, stagnation_trigger=None,\n                 levy_prob=0.07):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.rng = np.random.RandomState(seed)\n        # population (candidates per generation)\n        self.pop = int(max(4, pop))\n        # size of directional memory (subspace dimension)\n        self.dir_dim = int(dir_dim) if dir_dim is not None else max(2, min(self.dim, self.dim // 2))\n        self.init_radius = init_radius  # will be set relative to bounds if None\n        self.success_target = float(success_target)\n        self.r_adapt = float(r_adapt)  # adaptation rate for trust radius\n        self.levy_prob = float(levy_prob)\n        self.archive_size = int(archive_size) if archive_size is not None else max(20, 6 * self.dim)\n        self.stagnation_trigger = int(stagnation_trigger) if stagnation_trigger is not None else max(20, int(0.02 * self.budget))\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # Respect bounds from func; many BBOB problems use [-5,5]\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        bounds_scale = ub - lb\n        center_bounds = 0.5 * (ub + lb)\n\n        # initialize radius\n        if self.init_radius is None:\n            r = 0.3 * np.mean(bounds_scale)  # fairly large to begin\n        else:\n            r = float(self.init_radius)\n\n        # bookkeeping\n        evals = 0\n        f_best = np.inf\n        x_best = rng.uniform(lb, ub, size=self.dim)\n\n        # initial seeding: fill an initial archive with some random points\n        n_init = min(self.pop * 2, max(4, int(0.05 * self.budget)))\n        n_init = min(n_init, self.budget)\n        X_init = rng.uniform(lb, ub, size=(n_init, self.dim))\n        f_init = np.empty(n_init, dtype=float)\n        for i in range(n_init):\n            f_init[i] = float(func(X_init[i]))\n        evals += n_init\n\n        # archive: keep up to archive_size samples, with replacements for worse\n        archive_X = X_init.copy()\n        archive_f = f_init.copy()\n\n        def archive_add(x, fx):\n            nonlocal archive_X, archive_f\n            if len(archive_f) < self.archive_size:\n                archive_X = np.vstack([archive_X, x.reshape(1, -1)])\n                archive_f = np.concatenate([archive_f, np.array([fx])])\n            else:\n                worst = int(np.argmax(archive_f))\n                if fx < archive_f[worst]:\n                    archive_X[worst] = x\n                    archive_f[worst] = fx\n\n        # set initial best\n        ib = int(np.argmin(archive_f))\n        f_best = float(archive_f[ib])\n        x_best = archive_X[ib].copy()\n\n        # directional memory D: orthonormal basis columns (dim x k)\n        k = max(1, min(self.dir_dim, self.dim))\n        D = np.zeros((self.dim, k))\n        # keep a small circular buffer of recent successful displacements to update D\n        success_buffer = []\n\n        # adaptive success smoothing\n        p_succ = self.success_target\n\n        # stagnation counter\n        stagn = 0\n        gen = 0\n\n        # helper: orthonormalize vectors (skinny QR)\n        def orthonormalize(V):\n            if V.size == 0:\n                return np.zeros((self.dim, 0))\n            Q, R = np.linalg.qr(V, mode='reduced')\n            # Ensure deterministic sign for stability\n            diag = np.sign(np.diag(R))\n            diag[diag == 0] = 1.0\n            Q = Q * diag\n            return Q\n\n        # helper: get sorted archive indices (elite bias)\n        def sorted_archive():\n            idx = np.argsort(archive_f)\n            return idx, archive_X[idx], archive_f[idx]\n\n        # sample a triangulation proposal\n        def triangulation_proposal(r_local):\n            # pick t points as a simplex (t = min(1 + k, 1 + dim_of_D or 3))\n            idx, sX, sf = sorted_archive()\n            t = min(3 + min(k, 2), len(sX))\n            t = max(2, t)\n            # choose a small set biased to elites: sample without replacement from top-M\n            topM = max(t, int(0.3 * len(sX)))\n            topM = min(topM, len(sX))\n            chosen = rng.choice(topM, size=t, replace=False)\n            verts = sX[chosen]  # t x dim\n            # barycentric center weights from symmetric Dirichlet (alpha=0.8 to allow concentration)\n            alpha = 0.8\n            w = rng.gamma(alpha, 1.0, size=t)\n            w = w / np.sum(w)\n            center = (w.reshape(-1, 1) * verts).sum(axis=0)\n            # form difference vectors (t-1 vectors)\n            diffs = (verts[1:] - verts[0]).T  # dim x (t-1)\n            # augment with directional memory D to form proposal subspace (combine recent diffs and D)\n            if D.shape[1] > 0:\n                concat = np.hstack([diffs, D])  # dim x p\n            else:\n                concat = diffs\n            if concat.size == 0:\n                # fallback isotropic\n                z = rng.standard_t(df=3.0, size=self.dim)\n                perturb = z / (np.sqrt(np.mean(z**2)) + 1e-12)  # normalize energy, keep heavy tails\n                x = center + r_local * perturb\n                return np.minimum(np.maximum(x, lb), ub)\n            # orthonormal directions\n            Q = orthonormalize(concat)\n            # we will sample coefficients in that reduced subspace from student-t (df small => heavy tails)\n            df = 3.0\n            coeffs = rng.standard_t(df=df, size=Q.shape[1])\n            # scale coefficients: give stronger weight to directions that are differences (first diffs)\n            scaling = np.ones_like(coeffs)\n            scaling[:diffs.shape[1]] *= 1.2\n            scaling[diffs.shape[1]:] *= 0.9\n            coeffs = coeffs * scaling\n            # normalize coefficient vector length then scale by r_local\n            norm = np.sqrt(np.sum(coeffs**2)) + 1e-12\n            coeffs = coeffs / norm * rng.uniform(0.2, 1.0) * r_local\n            perturb = Q @ coeffs\n            x = center + perturb\n            return np.minimum(np.maximum(x, lb), ub)\n\n        # sample a DE-like proposal (archive-biased)\n        def de_proposal(r_local):\n            idx, sX, sf = sorted_archive()\n            n = len(sX)\n            if n < 3:\n                # fallback gaussian local\n                z = rng.normal(size=self.dim)\n                x = x_best + z * (0.6 * r_local)\n                return np.minimum(np.maximum(x, lb), ub)\n            # pick three distinct indices with elite bias (roulette on rank)\n            probs = np.linspace(1.0, 0.2, n)\n            probs = probs / probs.sum()\n            a, b, c = rng.choice(n, size=3, replace=False, p=probs)\n            xa, xb, xc = sX[a], sX[b], sX[c]\n            # sample F as lognormal around 0.6 (heavy-ish tail but positive)\n            F = np.exp(rng.normal(loc=np.log(0.6), scale=0.35))\n            F = float(np.clip(F, 0.05, 1.2))\n            donor = xa + F * (xb - xc)\n            # crossover with best or with a barycenter\n            if rng.rand() < 0.6:\n                target = x_best\n            else:\n                # small barycenter of two elites\n                i1, i2 = rng.choice(min(n, max(4, int(0.15 * n))), size=2, replace=False)\n                target = 0.6 * sX[i1] + 0.4 * sX[i2]\n            CR = float(np.clip(rng.normal(loc=0.9, scale=0.12), 0.0, 1.0))\n            mask = rng.rand(self.dim) < CR\n            if not np.any(mask):\n                mask[rng.randint(self.dim)] = True\n            trial = np.where(mask, donor, target)\n            # add a small directional perturbation along D if available\n            if D.shape[1] > 0 and rng.rand() < 0.6:\n                q = rng.randn(D.shape[1])\n                q = q / (np.linalg.norm(q) + 1e-12)\n                trial += (D @ q) * (0.6 * r_local)\n            # jitter\n            trial += rng.normal(scale=0.08 * np.maximum(bounds_scale, 1.0), size=self.dim)\n            return np.minimum(np.maximum(trial, lb), ub)\n\n        # main loop: create batches of proposals and evaluate until budget exhausted\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            n_cand = min(self.pop, remaining)\n            Xcand = np.empty((n_cand, self.dim), dtype=float)\n            # dynamic local radius: sometimes sample locally around x_best, sometimes around archive barycenters\n            for i in range(n_cand):\n                # choose operator\n                op = rng.rand()\n                local_r = r * (1.0 + 0.4 * rng.randn())  # small multiplicative noise\n                local_r = float(np.clip(local_r, 1e-12, 2.0 * np.max(bounds_scale)))\n                if op < 0.55:\n                    Xcand[i] = triangulation_proposal(local_r)\n                elif op < 0.95:\n                    Xcand[i] = de_proposal(local_r)\n                else:\n                    # rare global heavy-tailed probe (Cauchy-style)\n                    scale = 2.0 * np.mean(bounds_scale)\n                    z = rng.standard_cauchy(size=self.dim)\n                    # clamp extraordinarily large values\n                    z = np.clip(z, -1e3, 1e3)\n                    x = x_best + z * scale * rng.uniform(0.5, 1.5)\n                    Xcand[i] = np.minimum(np.maximum(x, lb), ub)\n\n            # evaluate candidates (guard budget)\n            f_cand = np.empty(n_cand, dtype=float)\n            for i in range(n_cand):\n                if evals >= self.budget:\n                    f_cand[i] = np.inf\n                    continue\n                f_cand[i] = float(func(Xcand[i]))\n                evals += 1\n\n            # update archive with candidates\n            for i in range(n_cand):\n                archive_add(Xcand[i].copy(), float(f_cand[i]))\n\n            # check best improvement in this batch\n            batch_best_idx = int(np.argmin(f_cand))\n            batch_best_f = float(f_cand[batch_best_idx])\n            batch_best_x = Xcand[batch_best_idx].copy()\n\n            improved = False\n            if batch_best_f < f_best:\n                f_best = batch_best_f\n                x_best = batch_best_x.copy()\n                improved = True\n                stagn = 0\n            else:\n                stagn += 1\n\n            # selection heuristic for \"successful steps\" to update D:\n            # any candidate that improved over its nearest archive neighbor is considered successful\n            # (this is a heuristic to get meaningful step vectors)\n            for i in range(n_cand):\n                # find nearest in archive excluding itself (use L2)\n                if len(archive_X) == 0:\n                    continue\n                dists = np.sum((archive_X - Xcand[i])**2, axis=1)\n                # if candidate is the best among archive (same point), skip\n                nearest_idx = int(np.argmin(dists))\n                if f_cand[i] + 1e-12 < archive_f[nearest_idx]:\n                    # step vector from neighbor -> candidate\n                    step = Xcand[i] - archive_X[nearest_idx]\n                    if np.linalg.norm(step) > 1e-12:\n                        success_buffer.append(step)\n                        # cap buffer length\n                        if len(success_buffer) > 4 * k:\n                            success_buffer.pop(0)\n\n            # update D from success_buffer with exponential forgetting\n            if len(success_buffer) > 0:\n                V = np.vstack(success_buffer).T  # dim x m\n                # weighted by recency (recent steps more important)\n                mvals = np.arange(1, V.shape[1] + 1)\n                weights = (mvals / mvals.sum()).reshape(1, -1)\n                Wmat = V * weights\n                # compute principal components roughly via SVD on weighted V\n                try:\n                    U, S, _ = np.linalg.svd(Wmat, full_matrices=False)\n                    # take top-k left singular vectors scaled by singular values\n                    ktake = min(k, U.shape[1])\n                    Dnew = U[:, :ktake] * (S[:ktake] / (S[:ktake].max() + 1e-12))\n                except Exception:\n                    # fallback orthonormalize of V\n                    Dnew = orthonormalize(V)[:, :k]\n                # smooth update: D = (1 - alpha) * D + alpha * Dnew (prolong memory)\n                alpha = 0.25\n                # ensure shapes\n                if Dnew.shape[1] < k:\n                    # pad with zeros columns\n                    pad = np.zeros((self.dim, k - Dnew.shape[1]))\n                    Dnew = np.hstack([Dnew, pad])\n                D = D * (1.0 - alpha) + Dnew[:, :k] * alpha\n                # re-orthonormalize D\n                D = orthonormalize(D)[:, :k]\n\n            # adapt trust radius r based on smoothed success\n            p_succ = 0.9 * p_succ + 0.1 * float(improved)\n            r = float(r * np.exp(self.r_adapt * (p_succ - self.success_target)))\n            # clamp r to [tiny, fraction of domain]\n            r = float(np.clip(r, 1e-12, 1.5 * np.max(bounds_scale)))\n\n            # stagnation handling\n            if stagn >= self.stagnation_trigger:\n                # rare heavy escape with probability levy_prob\n                if rng.rand() < self.levy_prob:\n                    # multivariate Cauchy jump around a randomly chosen elite\n                    idx, sX, sf = sorted_archive()\n                    elite_count = max(3, min(len(sX), int(0.1 * len(sX))))\n                    anchor = sX[rng.randint(elite_count)]\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = np.clip(z, -1e3, 1e3)\n                    jump_scale = max(0.8 * np.mean(bounds_scale), r * 5.0)\n                    x_jump = anchor + z * jump_scale\n                    x_jump = np.minimum(np.maximum(x_jump, lb), ub)\n                    if evals < self.budget:\n                        fj = float(func(x_jump))\n                        evals += 1\n                        archive_add(x_jump.copy(), fj)\n                        if fj < f_best:\n                            f_best = fj\n                            x_best = x_jump.copy()\n                            r = max(r, 0.6 * np.mean(bounds_scale))\n                            stagn = 0\n                else:\n                    # mild restart: shrink to region around best but perturb mean\n                    jitter = rng.normal(scale=0.12 * np.maximum(bounds_scale, 1.0), size=self.dim)\n                    center_restart = x_best + jitter\n                    center_restart = np.minimum(np.maximum(center_restart, lb), ub)\n                    # sample few exploratory points around center and evaluate up to budget/20\n                    n_probe = min(4, max(1, (self.budget - evals) // 200))\n                    for _ in range(n_probe):\n                        if evals >= self.budget:\n                            break\n                        x = center_restart + rng.normal(scale=0.6 * r, size=self.dim)\n                        x = np.minimum(np.maximum(x, lb), ub)\n                        fval = float(func(x))\n                        evals += 1\n                        archive_add(x.copy(), fval)\n                        if fval < f_best:\n                            f_best = fval\n                            x_best = x.copy()\n                            stagn = 0\n                            r = max(r, 0.4 * np.mean(bounds_scale))\n                # reset some memory but keep directional memory softly\n                p_succ = self.success_target\n                stagn = 0\n                # weaken success buffer slightly to forget old directions\n                if len(success_buffer) > 0:\n                    success_buffer = success_buffer[-max(1, len(success_buffer)//2):]\n\n        # finish\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DTATR scored 0.385 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "396683fe-ad29-4f0c-b4bb-bd141f4a9657", "operator": null, "metadata": {"aucs": [0.17240267812029442, 0.2207653741163308, 0.6081072399303877, 0.41599822371544937, 0.35568750683159833, 0.5309568842648837, 0.33253421045950093, 0.35441181067251704, 0.3227242855729796, 0.5374154989034274]}, "task_prompt": ""}
{"id": "b89cdd6b-c16a-4aa1-b6fe-56dc10d44fea", "fitness": 0.7281377078865251, "name": "OrthoMirroredDEt", "description": "The design is a hybrid population-based optimizer that splits each generation between orthogonalized mirrored Gaussian sampling and an adaptive rand/1/bin Differential Evolution (DE) branch, using a population size lam ~ 4+3*sqrt(dim) with an archive of diverse points (archive_size = min(40,max(6,3*dim)). The Gaussian arm generates orthonormal directions via QR and produces mirrored proposal pairs mapped through a learned covariance A (C->A) to reduce variance and diversify directions, with sigma initialized to 0.18*avg_scale and strongly adapted multiplicatively (sigma_adapt_rate=0.30) toward a low success_target (0.20). The DE arm uses Student-t sampling for F (df=3 centered at F_base=0.7), normally-distributed CR around CR_base=0.7, elite-biased archive selection and anisotropic jitter in principal axes to combine global jumps and local search. Covariance is learned very slowly (cov_lr=0.02) from linear rank weights plus a heavy rank-one correction, with eigen regularization (max_eig_ratio=1e4, min_eig_scale=1e-10) and stagnation controls that trigger orthogonal Lévy-style escapes (levy_prob=0.15) or partial restarts to reintroduce diversity.", "code": "import numpy as np\n\nclass OrthoMirroredDEt:\n    \"\"\"\n    OrthoMirroredDEt:\n    - Hybrid optimizer combining:\n        * Orthogonalized mirrored Gaussian sampling (variance reduction via paired mirrors\n          and direction diversification via QR orthogonalization)\n        * Adaptive rand/1/bin Differential Evolution with Student-t sampling for F\n        * Learned covariance shaping with slow learning rate and rank-one correction\n        * Linear rank weights (different from exponential/log weights)\n        * Per-generation archive to preserve diversity\n        * Orthogonal Lévy-style escapes and mild partial restarts on stagnation\n    Main tunable parameters (defaults chosen to be different from the provided reference):\n      - cov_lr = 0.02             # much slower covariance learning\n      - sigma_adapt_rate = 0.30   # stronger multiplicative sigma adaptation\n      - success_target = 0.20     # lower success target\n      - archive_size = min(40, max(6, 3 * dim))\n      - stagnation_iters = max(12, int(0.04 * budget))\n      - levy_prob = 0.15\n      - F_base = 0.7\n      - CR_base = 0.7\n      - max_eig_ratio = 1e4\n      - min_eig_scale = 1e-10\n    Note: This class respects func.bounds.lb/ub. The implementation ensures not to call\n    func() more times than self.budget.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None, pop_base=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.pop_base = pop_base\n\n        # Algorithm parameters (chosen to be different from the provided algorithm)\n        self.cov_lr = 0.02\n        self.sigma_adapt_rate = 0.30\n        self.success_target = 0.20\n        self.archive_size = min(40, max(6, 3 * self.dim))\n        self.stagnation_iters = max(12, int(0.04 * self.budget))\n        self.levy_prob = 0.15\n        self.F_base = 0.7\n        self.CR_base = 0.7\n        self.max_eig_ratio = 1e4\n        self.min_eig_scale = 1e-10\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # Respect provided bounds (Many BBOB uses [-5,5])\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        bounds_scale = (ub - lb)\n        avg_scale = np.mean(bounds_scale)\n\n        # adaptive population size (different formula to reference)\n        if self.pop_base is None:\n            lam = max(6, int(4 + 3.0 * np.sqrt(max(1, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        evals = 0\n\n        # initial uniform seeding\n        init_n = min(lam, self.budget - evals)\n        X = rng.uniform(lb, ub, size=(init_n, self.dim))\n        fvals = np.array([func(x) for x in X])\n        evals += init_n\n\n        best_idx = int(np.argmin(fvals))\n        f_best = float(fvals[best_idx])\n        x_best = X[best_idx].copy()\n\n        # Archive to store diverse points\n        archive_X = X.copy()\n        archive_f = fvals.copy()\n        def archive_add(x, fx):\n            nonlocal archive_X, archive_f\n            if len(archive_f) < self.archive_size:\n                archive_X = np.vstack([archive_X, x.reshape(1, -1)])\n                archive_f = np.concatenate([archive_f, np.array([fx])])\n            else:\n                worst = int(np.argmax(archive_f))\n                if fx < archive_f[worst]:\n                    archive_X[worst] = x\n                    archive_f[worst] = fx\n\n        # compute initial mean using linear decreasing rank weights on top half\n        mu0 = max(1, init_n // 2)\n        order0 = np.argsort(fvals)\n        elites0 = X[order0[:mu0]]\n        # linear decreasing weights: w_i ~ (mu - i)\n        ranks = np.arange(mu0)\n        weights0 = (mu0 - ranks).astype(float)\n        weights0 /= weights0.sum()\n        m = (weights0.reshape(-1,1) * elites0).sum(axis=0)\n\n        # initial covariance: diagonal scaled to domain (different divisor)\n        C = np.diag(((bounds_scale / 5.0) ** 2).clip(min=1e-18))\n        sigma = 0.18 * avg_scale\n        sigma = max(sigma, 1e-12)\n\n        # strategy state\n        p_succ = self.success_target\n        stagn_iters = 0\n\n        # helper: eigen-based sqrt transform (A) such that A @ A.T = C\n        def sqrt_A_from_C(Cmat):\n            vals, vecs = np.linalg.eigh(Cmat)\n            vals_clipped = np.clip(vals, self.min_eig_scale, None)\n            # enforce condition number\n            if vals_clipped.max() / vals_clipped.min() > self.max_eig_ratio:\n                max_allowed = vals_clipped.min() * self.max_eig_ratio\n                vals_clipped = np.minimum(vals_clipped, max_allowed)\n            A = (vecs * np.sqrt(vals_clipped)).T\n            return A, vals_clipped, vecs\n\n        # helper: orthogonalize normal draws to diversify directions\n        def orthonormalize_rows(Z):\n            # Z shape (k, dim) -> produce orthonormal rows via QR on Z^T\n            # If k > dim, we will only produce dim orthonormal directions.\n            k = Z.shape[0]\n            if k == 0:\n                return Z\n            # Compute Q with shape (dim, dim)\n            Q, _ = np.linalg.qr(Z.T, mode='reduced')\n            # Q columns are orthonormal; produce k row directions by taking first k columns transposed\n            k_eff = min(k, Q.shape[1])\n            rows = Q[:, :k_eff].T\n            # If k > k_eff, pad with independent normals\n            if k > k_eff:\n                extra = rng.normal(size=(k - k_eff, Z.shape[1]))\n                return np.vstack([rows, extra])\n            return rows\n\n        # main loop\n        iteration = 0\n        while evals < self.budget:\n            iteration += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu = max(1, lam_iter // 2)\n\n            # linear rank weights for this generation\n            ranks = np.arange(mu)\n            weights = (mu - ranks).astype(float)\n            weights /= weights.sum()\n\n            # compute transform A\n            A, eigs, eigvecs = sqrt_A_from_C(C)\n\n            # split between orthogonal mirrored gaussians and DE trials\n            n_gauss = lam_iter // 2\n            n_de = lam_iter - n_gauss\n            Xcand = np.empty((lam_iter, self.dim), dtype=float)\n\n            # 1) orthogonalized mirrored Gaussian proposals\n            if n_gauss > 0:\n                # produce k normal directions (k = ceil(n_gauss/2))\n                k_dirs = (n_gauss + 1) // 2\n                Z = rng.normal(size=(k_dirs, self.dim))\n                # orthonormalize directions (rows)\n                dirs = orthonormalize_rows(Z)  # shape (k_dirs, dim)\n                # map directions through A (introduce learned covariance)\n                mapped = dirs @ (A.T)\n                # scale by sigma and create mirrored pairs\n                proposals = m.reshape(1,-1) + sigma * mapped\n                mirrors = 2.0 * m.reshape(1,-1) - proposals\n                # fill Xcand with alternating proposal and mirror\n                idx = 0\n                for j in range(k_dirs):\n                    if idx >= n_gauss: break\n                    Xcand[idx] = np.minimum(np.maximum(proposals[j], lb), ub)\n                    idx += 1\n                    if idx >= n_gauss: break\n                    Xcand[idx] = np.minimum(np.maximum(mirrors[j], lb), ub)\n                    idx += 1\n\n            # 2) DE rand/1/bin proposals with Student-t F sampling and target mixture\n            if n_de > 0:\n                # prepare sorted archive biased to elites for selection\n                if len(archive_f) >= 3:\n                    idxs_sorted = np.argsort(archive_f)\n                    sorted_X = archive_X[idxs_sorted]\n                else:\n                    sorted_X = archive_X\n\n                for i in range(n_de):\n                    # sample F from scaled Student-t (df=3) centered at F_base\n                    df = 3.0\n                    t = rng.standard_t(df)\n                    F = float(self.F_base + 0.12 * t)\n                    F = float(np.clip(F, 0.15, 1.0))\n                    # sample CR from bounded Beta-like sampling by transforming uniform\n                    CR = float(np.clip(rng.normal(loc=self.CR_base, scale=0.20), 0.0, 1.0))\n\n                    if len(sorted_X) < 3:\n                        # fallback gaussian\n                        z = rng.normal(size=self.dim)\n                        y = z @ (A.T)\n                        trial = m + sigma * y\n                    else:\n                        # select three distinct indices biased: choose one from top half, two others random\n                        topk = max(2, len(sorted_X)//3)\n                        idx1 = rng.randint(0, topk)\n                        idx2, idx3 = rng.choice(len(sorted_X), size=2, replace=False)\n                        xr = sorted_X[idx1]\n                        xa = sorted_X[idx2]\n                        xb = sorted_X[idx3]\n                        mutant = xr + F * (xa - xb)\n                        # target is either current mean, a random elite, or the best with small prob\n                        r = rng.rand()\n                        if r < 0.4:\n                            target = m\n                        elif r < 0.9:\n                            target = sorted_X[rng.randint(len(sorted_X))]\n                        else:\n                            target = sorted_X[0]  # best\n                        # binomial crossover\n                        mask = rng.rand(self.dim) < CR\n                        if not np.any(mask):\n                            mask[rng.randint(self.dim)] = True\n                        trial = np.where(mask, mutant, target)\n                        # jitter: anisotropic Gaussian with scale proportional to eigen-spectrum\n                        jitter_scale = 0.25 * sigma\n                        # produce jitter in principal axes\n                        eps = rng.normal(size=self.dim)\n                        trial += (eps @ (A.T)) * jitter_scale\n\n                    Xcand[n_gauss + i] = np.minimum(np.maximum(trial, lb), ub)\n\n            # evaluate candidates (ensure not exceeding budget)\n            f_cand = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                if evals >= self.budget:\n                    # fill remaining with inf (shouldn't happen because lam_iter <= remaining)\n                    f_cand[i] = np.inf\n                    continue\n                x = Xcand[i]\n                f_cand[i] = float(func(x))\n                evals += 1\n\n            # update archive with new candidates\n            for i in range(lam_iter):\n                archive_add(Xcand[i].copy(), float(f_cand[i]))\n\n            # generation best\n            gen_best_idx = int(np.argmin(f_cand))\n            gen_best_f = float(f_cand[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n                stagn_iters = 0\n            else:\n                stagn_iters += 1\n\n            # selection: choose top-mu candidates to form new elite set\n            order = np.argsort(f_cand)\n            X_mu = Xcand[order[:mu]]\n\n            # recompute weighted mean (linear weights)\n            m_new = (weights.reshape(-1,1) * X_mu).sum(axis=0)\n\n            # covariance update: use normalized deltas and slow learning\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            W = weights.reshape(-1,1)\n            weighted_cov = (deltas * W).T @ deltas  # (dim x dim)\n            mean_shift = ((m_new - m) / max(sigma, 1e-20)).reshape(-1,1)\n            rank_one = (mean_shift @ mean_shift.T) * 0.8  # heavier rank-one weight than reference\n\n            C = (1.0 - self.cov_lr) * C + self.cov_lr * (weighted_cov + rank_one)\n\n            # eigen regularization relative to domain scale\n            vals, vecs = np.linalg.eigh(C)\n            min_eig = max(self.min_eig_scale, (avg_scale * 5e-4) ** 2)\n            vals = np.clip(vals, min_eig, None)\n            max_allowed = vals.min() * self.max_eig_ratio\n            vals = np.minimum(vals, max_allowed)\n            C = (vecs * vals) @ vecs.T\n\n            # update mean\n            m = m_new.copy()\n\n            # step-size adaptation: multiplicative update with stronger adapt rate and different smoothing\n            p_succ = 0.7 * p_succ + 0.3 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = float(np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale)))\n\n            # stagnation handling: orthogonal Lévy-style escapes or partial restarts\n            if stagn_iters >= self.stagnation_iters and evals < self.budget:\n                stagn_iters = 0\n                # reset p_succ smoothing\n                p_succ = self.success_target\n                if rng.rand() < self.levy_prob:\n                    # orthogonal heavy-tailed jump: build orthonormal directions and combine a few with Levy-like magnitudes\n                    k = min(self.dim, max(2, int(np.ceil(self.dim / 3.0))))\n                    Z = rng.normal(size=(k, self.dim))\n                    dirs = orthonormalize_rows(Z)\n                    # generate heavy-tailed scales with inverse-gamma-like behaviour using chi-square\n                    scales = []\n                    for _ in range(k):\n                        v = max(1e-6, rng.chisquare(2.0))\n                        scales.append( (rng.standard_t(2.0) * avg_scale * 0.6) / np.sqrt(v/2.0) )\n                    scales = np.array(scales)\n                    jump = (scales.reshape(-1,1) * dirs).sum(axis=0)\n                    anchor = x_best.copy()\n                    x_jump = anchor + jump\n                    x_jump = np.minimum(np.maximum(x_jump, lb), ub)\n                    # evaluate\n                    if evals < self.budget:\n                        fj = float(func(x_jump))\n                        evals += 1\n                        archive_add(x_jump.copy(), fj)\n                        if fj < f_best:\n                            f_best = fj\n                            x_best = x_jump.copy()\n                            m = x_jump.copy()\n                            # inject covariance to explore around new anchor\n                            C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-18))\n                            sigma = max(sigma, 0.25 * avg_scale)\n                            stagn_iters = 0\n                        else:\n                            # rotate covariance slightly by random orthonormal transform to encourage new directions\n                            R, _ = np.linalg.qr(rng.normal(size=(self.dim, self.dim)))\n                            C = R @ C @ R.T\n                            # moderate increase of small eigenvalues\n                            vals, vecs = np.linalg.eigh(C)\n                            vals = np.maximum(vals, min_eig)\n                            vals *= 1.25\n                            C = (vecs * vals) @ vecs.T\n                else:\n                    # partial mild restart: re-center mean near a convex blend of best and random elite\n                    if len(archive_f) > 0:\n                        idx = rng.randint(len(archive_f))\n                        anchor = archive_X[idx]\n                    else:\n                        anchor = x_best\n                    alpha = rng.rand() * 0.5 + 0.25\n                    m = alpha * x_best + (1.0 - alpha) * anchor + rng.normal(scale=0.06 * avg_scale, size=self.dim)\n                    m = np.minimum(np.maximum(m, lb), ub)\n                    # shrink covariance modestly\n                    C = np.diag(((bounds_scale / 8.0) ** 2).clip(min=1e-18))\n                    sigma = max(sigma, 0.22 * avg_scale)\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm OrthoMirroredDEt scored 0.728 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "396683fe-ad29-4f0c-b4bb-bd141f4a9657", "operator": null, "metadata": {"aucs": [0.2777289019668533, 0.17579896217463886, 0.9181974189391979, 0.9634174145637797, 0.9150406884180352, 0.9380802564324057, 0.3461304228390172, 0.8946754946262645, 0.9294994824323852, 0.922808036472674]}, "task_prompt": ""}
{"id": "29cf71bd-5e95-415e-ba88-5ca4da235b27", "fitness": "-inf", "name": "ClusteredAdaptiveDirectionalSearch", "description": "The algorithm maintains multiple local niches (K clusters) each with a center, local covariance, momentum and an adaptive trust-radius, plus a global archive of top points; population size lam and K are chosen from the problem dimension and budget to balance coverage and per-cluster sampling. Candidate generation mixes directed exploitation (momentum + direction to global best), local Gaussian sampling via an eigendecomposed covariance, orthogonal jitter, mirrored proposals for variance reduction, niche recombination between cluster centers, and occasional heavy-tailed (Levy-like) jumps for bold exploration, with all candidates clamped to the problem bounds. Adaptation is online: covariances are updated by elite-weighted exponential moving averages (cov_lr), momentum is softly nudged toward successful local steps, and trust radii are increased or decreased according to smoothed success rates (success_target, trust_lr); eigenvalue clamping and max_eig_ratio ensure numerical stability. The method is budget-aware (batch proposal/evaluation), assigns candidates to nearest clusters for local updates, and uses stagnation-detected heavy-tailed probes and archive-based re-centering to escape local optima.", "code": "import numpy as np\n\nclass ClusteredAdaptiveDirectionalSearch:\n    \"\"\"\n    Clustered Adaptive Directional Search (CADS)\n\n    Key ideas:\n    - Maintain a modest population split into K clusters (local niches).\n    - Each cluster keeps a center, local covariance, momentum (preferred direction) and a trust-radius.\n    - Proposals mix: directional moves toward global/cluster-best, local Gaussian (via eigendecomposed covariance),\n      orthogonal jitter (to explore subspaces), mirrored partner for variance reduction, and occasional Levy jumps\n      on stagnation.\n    - Clusters adapt covariances via elite-weighted rank updates and soft momentum updates.\n    - Trust radii increase/decrease according to per-cluster success rates to balance exploration/exploitation.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop_base=None,\n                 cov_lr=0.12,    # learning rate for local covariances\n                 trust_lr=0.18,  # adaptation speed for trust radius\n                 success_target=0.22,\n                 levy_prob=0.08,\n                 max_eig_ratio=1e5):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.pop_base = pop_base\n        self.cov_lr = float(cov_lr)\n        self.trust_lr = float(trust_lr)\n        self.success_target = float(success_target)\n        self.levy_prob = float(levy_prob)\n        self.max_eig_ratio = float(max_eig_ratio)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds handling (support scalar or vector bounds)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        bounds_scale = (ub - lb)\n        avg_scale = float(np.mean(bounds_scale))\n\n        # population size\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3.0 * np.sqrt(max(1, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # number of clusters (niches)\n        K = max(2, int(np.clip(np.round(np.sqrt(lam)), 2, lam // 2 + 1)))\n\n        # initialize population uniformly (consume up to lam or budget)\n        evals = 0\n        init_n = min(lam, max(2, self.budget - evals))\n        X = rng.uniform(lb, ub, size=(init_n, self.dim))\n        f = np.array([func(x) for x in X])\n        evals += init_n\n\n        # global best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        # archive of top points (size ~ 4*dim or 50 whichever smaller)\n        archive_size = min(4 * self.dim + 5, max(20, lam * 2))\n        archive_X = X.copy()\n        archive_f = f.copy()\n\n        def archive_add(xp, fp):\n            nonlocal archive_X, archive_f\n            if archive_f.size < archive_size:\n                archive_X = np.vstack([archive_X, xp.reshape(1, -1)])\n                archive_f = np.concatenate([archive_f, np.array([fp])])\n            else:\n                worst = int(np.argmax(archive_f))\n                if fp < archive_f[worst]:\n                    archive_X[worst] = xp\n                    archive_f[worst] = fp\n\n        # initial clustering: simple round-robin into K groups\n        groups = [[] for _ in range(K)]\n        for i in range(X.shape[0]):\n            groups[i % K].append(i)\n\n        # cluster state initialization\n        cluster_centers = np.zeros((K, self.dim), dtype=float)\n        cluster_cov = np.zeros((K, self.dim, self.dim), dtype=float)\n        cluster_trust = np.full(K, 0.25 * avg_scale, dtype=float)  # adaptable search radius per cluster\n        cluster_momentum = np.zeros((K, self.dim), dtype=float)\n        cluster_success = np.zeros(K, dtype=float)  # smoothed success rate\n        cluster_count = np.zeros(K, dtype=int)\n\n        # helper: safe eigen sqrt transform A s.t. A @ A.T = C\n        def eig_sqrt(Cmat):\n            vals, vecs = np.linalg.eigh(Cmat)\n            vals = np.clip(vals, 1e-20, None)\n            # enforce condition-number limit\n            minv = vals.min()\n            if minv <= 0:\n                minv = 1e-20\n            max_allowed = minv * self.max_eig_ratio\n            vals = np.minimum(vals, max_allowed)\n            A = (vecs * np.sqrt(vals)).T\n            return A, vals, vecs\n\n        # initialize clusters from assigned members\n        for k in range(K):\n            idxs = groups[k]\n            if len(idxs) == 0:\n                # sample center randomly\n                center = rng.uniform(lb, ub, size=self.dim)\n                Ck = np.diag((0.4 * bounds_scale) ** 2)\n            else:\n                pts = X[idxs]\n                center = pts.mean(axis=0)\n                # covariance: empirical + isotropic floor\n                if pts.shape[0] > 1:\n                    Ck = np.cov(pts, rowvar=False)\n                else:\n                    Ck = np.diag(((0.5 * bounds_scale) ** 2).clip(min=1e-16))\n                # regularize to domain scale\n                Ck += np.eye(self.dim) * (1e-6 * avg_scale ** 2)\n            cluster_centers[k] = center\n            cluster_cov[k] = Ck\n            cluster_count[k] = len(idxs)\n\n        # main loop: generate proposals batch-wise until budget exhausted\n        gen_iter = 0\n        stagn_counter = 0\n        max_stagn = max(15, int(0.02 * self.budget))\n\n        while evals < self.budget:\n            gen_iter += 1\n            # decide how many proposals this generation (cap to remaining evals)\n            lam_iter = min(lam, self.budget - evals)\n            # distribute proposals across clusters proportionally to cluster size + 1\n            sizes = np.maximum(cluster_count, 1)\n            props = sizes / sizes.sum()\n            n_per_cluster = (props * lam_iter).astype(int)\n            # ensure at least one candidate per cluster when possible\n            rem = lam_iter - n_per_cluster.sum()\n            # distribute remainder to clusters with largest trust\n            order_tr = np.argsort(-cluster_trust)\n            for i in range(rem):\n                n_per_cluster[order_tr[i % K]] += 1\n\n            Xcand = np.zeros((lam_iter, self.dim), dtype=float)\n            cand_idx = 0\n\n            # compute global best direction and optionally top few anchors for Levy\n            anchors_idx = np.argsort(archive_f) if archive_f.size > 0 else np.array([], dtype=int)\n            top_anchor = archive_X[anchors_idx[0]] if archive_f.size > 0 else x_best\n\n            for k in range(K):\n                nk = int(n_per_cluster[k])\n                if nk <= 0:\n                    continue\n                Ck = cluster_cov[k]\n                A_k, eigvals_k, eigvecs_k = eig_sqrt(Ck)\n                center = cluster_centers[k]\n                trust = float(cluster_trust[k])\n                mom = cluster_momentum[k]\n                # compute a unit directional exploit vector: mix momentum and global-best direction\n                dir_to_best = x_best - center\n                if np.linalg.norm(dir_to_best) > 0:\n                    dir_to_best = dir_to_best / np.linalg.norm(dir_to_best)\n                else:\n                    dir_to_best = rng.normal(size=self.dim)\n                    dir_to_best /= np.linalg.norm(dir_to_best)\n                dir_vec = 0.6 * (mom / (np.linalg.norm(mom) + 1e-12)) + 0.4 * dir_to_best\n                if np.linalg.norm(dir_vec) < 1e-12:\n                    dir_vec = dir_to_best\n                dir_vec = dir_vec / (np.linalg.norm(dir_vec) + 1e-12)\n\n                # pre-generate orthonormal basis with dir_vec as first basis vector\n                # produce an orthonormal basis using Householder-like approach (cheap)\n                e1 = dir_vec.copy()\n                # generate random vector and orthogonalize a few for jitter basis\n                rand_mat = rng.normal(size=(self.dim, min(3, self.dim - 1)))\n                # orthogonalize columns to e1\n                for j in range(rand_mat.shape[1]):\n                    v = rand_mat[:, j]\n                    v -= e1 * (e1 @ v)\n                    normv = np.linalg.norm(v)\n                    if normv < 1e-12:\n                        v = rng.normal(size=self.dim)\n                        v -= e1 * (e1 @ v)\n                        normv = np.linalg.norm(v) + 1e-12\n                    rand_mat[:, j] = v / normv\n\n                for j in range(nk):\n                    # choose mechanism type by probability\n                    r = rng.rand()\n                    if r < 0.55:\n                        # Directional + local Gaussian + orthogonal jitter + mirrored with probability 0.5\n                        alpha = rng.normal(loc=0.9, scale=0.25)  # directional strength\n                        alpha = float(np.clip(alpha, -2.0, 2.0))\n                        gauss_scale = rng.lognormal(mean=np.log(0.6), sigma=0.6)  # positive\n                        gauss_scale = float(np.clip(gauss_scale, 0.05, 3.0))\n                        ortho_scale = rng.normal(loc=0.2, scale=0.15)\n                        ortho_scale = float(max(0.0, ortho_scale))\n\n                        # sample multivariate Gaussian via A_k\n                        z = rng.normal(size=self.dim)\n                        local_part = (A_k.T @ z)  # shaped so that cov(local_part) ~ Ck\n\n                        ortho_part = np.zeros(self.dim)\n                        # combine a few orthonormal jitter directions\n                        for col in range(rand_mat.shape[1]):\n                            coef = rng.normal(scale=ortho_scale)\n                            ortho_part += coef * rand_mat[:, col]\n\n                        step = alpha * trust * dir_vec + gauss_scale * trust * local_part + trust * ortho_part\n                        # mirrored with 40% prob\n                        if rng.rand() < 0.4:\n                            cand = center - step\n                        else:\n                            cand = center + step\n\n                    elif r < 0.85:\n                        # recombination between cluster centers (niche crossover)\n                        partner = cluster_centers[rng.randint(K)]\n                        beta = rng.beta(a=2.0, b=2.0)\n                        mix = beta * center + (1 - beta) * partner\n                        # small local exploration around mix\n                        z = rng.normal(size=self.dim)\n                        local_part = (A_k.T @ z) * 0.6 * trust\n                        cand = mix + local_part\n                    else:\n                        # occasional bold Levy-like jump (long tail) centered at an archive anchor or center\n                        if rng.rand() < self.levy_prob and archive_f.size > 0:\n                            anchor = archive_X[rng.randint(archive_X.shape[0])]\n                            # multivariate-t style via normal / sqrt(gamma/df)\n                            df = rng.choice([1.5, 2.0, 3.0])\n                            gamma = max(1e-10, rng.chisquare(df))\n                            z = rng.normal(size=self.dim)\n                            jump_scale = max(0.8 * avg_scale, 1.2 * trust)\n                            jump = z / np.sqrt(gamma / df) * jump_scale\n                            cand = anchor + jump\n                        else:\n                            # fallback small Gaussian\n                            z = rng.normal(size=self.dim)\n                            cand = center + (A_k.T @ z) * 0.8 * trust\n\n                    # clamp within bounds\n                    cand = np.minimum(np.maximum(cand, lb), ub)\n                    Xcand[cand_idx] = cand\n                    cand_idx += 1\n                    if cand_idx >= lam_iter:\n                        break\n                if cand_idx >= lam_iter:\n                    break\n\n            # evaluate candidates sequentially (ensure budget)\n            f_cand = np.full(lam_iter, np.inf, dtype=float)\n            for i in range(lam_iter):\n                if evals >= self.budget:\n                    break\n                xi = Xcand[i]\n                fi = float(func(xi))\n                f_cand[i] = fi\n                evals += 1\n                # update archive on the fly\n                archive_add(xi.copy(), fi)\n                # update global best\n                if fi < f_best:\n                    f_best = fi\n                    x_best = xi.copy()\n                    stagn_counter = 0\n                # else stagn increment afterwards\n\n            # if no new better found in this batch\n            if np.min(f_cand) >= f_best:\n                stagn_counter += 1\n            else:\n                stagn_counter = 0\n\n            # Assign candidates to clusters: by nearest cluster center (Euclidean)\n            if cand_idx == 0:\n                # no candidates (shouldn't happen) -> break\n                break\n            actual_cand = Xcand[:cand_idx]\n            actual_fcand = f_cand[:cand_idx]\n            # for robustness, if some f_cand remained inf (not evaluated due to budget), ignore them\n            valid_mask = np.isfinite(actual_fcand)\n            actual_cand = actual_cand[valid_mask]\n            actual_fcand = actual_fcand[valid_mask]\n            if actual_cand.shape[0] == 0:\n                break\n\n            # find nearest center\n            dists = np.linalg.norm(actual_cand[:, None, :] - cluster_centers[None, :, :], axis=2)  # (n_cand, K)\n            assigned_k = np.argmin(dists, axis=1)\n\n            # For each cluster, update with assigned candidates\n            for k in range(K):\n                inds = np.where(assigned_k == k)[0]\n                if inds.size == 0:\n                    # decay success slightly and continue\n                    cluster_success[k] = 0.98 * cluster_success[k]\n                    continue\n                # combine cluster's current members (we don't store explicit members except counts)\n                # We'll update center by soft elite-weighted average between previous center and new good candidates\n                cand_pts = actual_cand[inds]\n                cand_vals = actual_fcand[inds]\n                # compute weights by softmax of negative fitness (lower is better)\n                rank = np.argsort(cand_vals)\n                top_n = max(1, min(3, len(rank)))\n                elites = cand_pts[rank[:top_n]]\n                elites_vals = cand_vals[rank[:top_n]]\n                # softmax weights on neg-fitness scaled\n                scaled = - (elites_vals - elites_vals.min() + 1e-12) / (np.std(elites_vals) + 1e-12)\n                w = np.exp(scaled - scaled.max())\n                w = w / w.sum()\n                new_center = (w.reshape(-1, 1) * elites).sum(axis=0)\n                # blend with old center\n                blend = 0.6\n                center_old = cluster_centers[k].copy()\n                cluster_centers[k] = blend * center_old + (1.0 - blend) * new_center\n\n                # covariance update: empirical from elites deltas (normalized)\n                deltas = elites - center_old\n                if deltas.shape[0] > 0:\n                    emp_cov = np.cov(deltas, rowvar=False) if deltas.shape[0] > 1 else np.atleast_2d(deltas).T @ np.atleast_2d(deltas)\n                    # scale cov to trust radius squared\n                    emp_cov = emp_cov + np.eye(self.dim) * (1e-12 * avg_scale ** 2)\n                    # exponential moving update\n                    cluster_cov[k] = (1.0 - self.cov_lr) * cluster_cov[k] + self.cov_lr * emp_cov\n                    # enforce eigen clamps relative to domain\n                    vals, vecs = np.linalg.eigh(cluster_cov[k])\n                    mineig = max(1e-18, (avg_scale * 1e-4) ** 2)\n                    vals = np.clip(vals, mineig, None)\n                    max_allowed = vals.min() * self.max_eig_ratio\n                    vals = np.minimum(vals, max_allowed)\n                    cluster_cov[k] = (vecs * vals) @ vecs.T\n\n                # momentum update: if best candidate improved cluster center direction, nudge momentum\n                best_local_idx = rank[0]\n                step_dir = elites[best_local_idx] - center_old\n                if np.linalg.norm(step_dir) > 1e-12:\n                    step_dir_unit = step_dir / (np.linalg.norm(step_dir) + 1e-12)\n                    cluster_momentum[k] = 0.75 * cluster_momentum[k] + 0.25 * step_dir_unit\n\n                # success measure: if any candidate improved global best or improved center locally (fitness decreased)\n                improved_local = np.any(cand_vals < np.min(archive_f)) if archive_f.size > 0 else False\n                # Also if any cand better than previous center value approximated via min archive in vicinity:\n                # Use local success if best candidate is reasonably good vs median archive\n                local_success = float(np.mean(cand_vals) < (np.median(archive_f) if archive_f.size > 0 else f_best + 1.0))\n                # smoothed cluster success\n                cluster_success[k] = 0.85 * cluster_success[k] + 0.15 * (1.0 if local_success else 0.0)\n\n                # trust radius adaptation\n                if cluster_success[k] > self.success_target:\n                    cluster_trust[k] = float(np.minimum(cluster_trust[k] * (1.0 + self.trust_lr), 1.5 * avg_scale))\n                else:\n                    cluster_trust[k] = float(np.maximum(cluster_trust[k] * (1.0 - self.trust_lr), 1e-6))\n\n                # update cluster counts (soft)\n                cluster_count[k] = int(max(1, cluster_count[k] * 0.9 + inds.size * 0.1))\n\n            # update archive arrays (already updated online) ensure shapes consistent\n            if archive_f.size > archive_size:\n                idxs = np.argsort(archive_f)[:archive_size]\n                archive_X = archive_X[idxs].copy()\n                archive_f = archive_f[idxs].copy()\n\n            # Occasionally (low probability) perform a global shrink/expand on cluster trusts to diversify\n            if rng.rand() < 0.06:\n                scale = rng.uniform(0.7, 1.4)\n                cluster_trust = np.clip(cluster_trust * scale, 1e-8, 2.0 * avg_scale)\n\n            # stagnation handling: if many gens without improvement, perform targeted Levy restarts around global best\n            if stagn_counter >= max_stagn and evals < self.budget:\n                stagn_counter = 0\n                # perform a few heavy-tailed probes around best and around some archive anchors\n                probes = min(6, self.budget - evals)\n                for p in range(probes):\n                    df = rng.choice([1.0, 1.5, 2.0])\n                    gamma = max(1e-8, rng.chisquare(df))\n                    z = rng.normal(size=self.dim)\n                    jump_scale = (1.2 + rng.rand()) * avg_scale\n                    xj = x_best + z / np.sqrt(gamma / df) * jump_scale\n                    xj = np.minimum(np.maximum(xj, lb), ub)\n                    fj = float(func(xj))\n                    evals += 1\n                    archive_add(xj.copy(), fj)\n                    if fj < f_best:\n                        f_best = fj\n                        x_best = xj.copy()\n                # inflate trusts modestly to escape\n                cluster_trust = np.clip(cluster_trust * 1.6, 1e-8, 3.0 * avg_scale)\n                # re-center some clusters around good anchors from archive\n                if archive_f.size > 2:\n                    idxs = np.argsort(archive_f)[:min(3, archive_f.size)]\n                    for i, idxa in enumerate(idxs):\n                        cluster_centers[i % K] = archive_X[idxa].copy()\n                        cluster_cov[i % K] = np.diag(((0.3 * bounds_scale) ** 2).clip(min=1e-16))\n                        cluster_momentum[i % K] = np.zeros(self.dim)\n\n        # end loop\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 345, in __call__, the following error occurred:\nIndexError: index 3 is out of bounds for axis 0 with size 3\nOn line: step_dir = elites[best_local_idx] - center_old", "error": "In the code, line 345, in __call__, the following error occurred:\nIndexError: index 3 is out of bounds for axis 0 with size 3\nOn line: step_dir = elites[best_local_idx] - center_old", "parent_ids": "396683fe-ad29-4f0c-b4bb-bd141f4a9657", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "4c65bfa9-37cf-4ffb-a238-a804e54fc248", "fitness": 0.2229164438416864, "name": "OrthogonalMirroredDE", "description": "The algorithm is a hybrid global search that mixes orthogonalized, mirrored Gaussian probes (QR-derived near-orthonormal directions scaled by an eigendecomposed learned covariance) with adaptive rand‑to‑best style Differential Evolution offspring, filling a population each generation by a tunable gaussian/DE ratio. Covariance and mean are learned from a linear-decreasing-weighted elite set (weighted recombination plus a rank-one mean-shift term) with an intentionally large cov learning rate and eigen-regularization to enforce stability; initial C and sigma are set relative to domain scale. DE control parameters are sampled from heavy-tailed/log-normal (F) and Beta(2,2)-based (CR) distributions to encourage occasional large moves, binomial crossover is used, and an archive with nearest-replacement and diversity turnover supplies parents and anchors. Online step-size adaptation uses an exponential rule toward a 0.20 success target (fast sigma_adapt_rate), and explicit stagnation handling triggers Cauchy/large probes, eigen-inflation or mild restarts to escape plateaus.", "code": "import numpy as np\n\nclass OrthogonalMirroredDE:\n    \"\"\"\n    OrthogonalMirroredDE (OMED)\n    - Hybrid: orthogonalized mirrored Gaussian sampling + adaptive Differential Evolution (rand-to-best style).\n    - Learns a covariance from rank-weighted elites and uses it to shape Gaussian probes (via eigendecomposition).\n    - Different parameter/equation choices from typical hybrids:\n      * linear decreasing weights for elites (instead of exponential/log)\n      * orthogonalization of Gaussian directions (via QR) before applying covariance transform\n      * F sampled via a log-normal / Pareto-like multiplicative heavy-tail (different heavy-tail equation)\n      * CR sampled from a Beta(2,2) around a base (different distribution than normal)\n      * adaptive cov learning-rate that depends on recent improvement\n      * archive replacement favors diversity (nearest-replacement strategy)\n      * step-size adaptation with different smoothing constants and multiplicative rule\n      * stagnation handling: targeted eigen-inflation or directional large-Cauchy probes\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None, pop_base=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        # algorithm knobs (intentionally different choices)\n        self.pop_base = pop_base\n        self.cov_lr = 0.30                # faster covariance learning than the provided reference (was 0.10)\n        self.sigma_adapt_rate = 0.22      # different adaptation coefficient\n        self.success_target = 0.20        # different target success rate\n        self.archive_size = min(100, max(10, 8 * self.dim))  # larger archive and different scaling\n        self.stagnation_iters = max(10, int(0.02 * self.budget))\n        self.levy_prob = 0.20             # more frequent heavy probes on stagnation\n        self.F_base = 0.7                 # different F base\n        self.CR_base = 0.8                # different CR base\n        self.max_eig_ratio = 1e4\n        self.min_eig_scale = 1e-14\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds (honor func.bounds)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        bounds_scale = (ub - lb)\n        mean_domain_scale = float(np.mean(bounds_scale))\n\n        # adaptive population size (different formula)\n        if self.pop_base is None:\n            lam = max(6, int(4 + 3.0 * np.sqrt(max(1, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        evals = 0\n        # initial seeding\n        init_n = min(lam, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(init_n, self.dim))\n        f0 = np.array([float(func(x)) for x in X0])\n        evals += init_n\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # archive arrays\n        archive_X = X0.copy()\n        archive_f = f0.copy()\n\n        def archive_add(x, fx):\n            nonlocal archive_X, archive_f\n            x = x.reshape(1, -1)\n            fx = float(fx)\n            if archive_f.size < self.archive_size:\n                archive_X = np.vstack([archive_X, x])\n                archive_f = np.concatenate([archive_f, np.array([fx])])\n            else:\n                # replace the archive member nearest to x if new fx is better than that member;\n                # otherwise occasionally replace the worst to keep diversity.\n                dists = np.linalg.norm(archive_X - x, axis=1)\n                nearest = int(np.argmin(dists))\n                worst = int(np.argmax(archive_f))\n                if fx < archive_f[nearest]:\n                    archive_X[nearest] = x\n                    archive_f[nearest] = fx\n                else:\n                    # small probability to replace the worst even if worse (preserve some turnover)\n                    if rng.rand() < 0.05:\n                        archive_X[worst] = x\n                        archive_f[worst] = fx\n\n        # initialize mean using linear decreasing weights over top half\n        mu0 = max(1, init_n // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        ranks = np.arange(mu0)\n        weights0 = (mu0 - ranks).astype(float)  # linear decreasing\n        weights0 /= weights0.sum()\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance isotropic relative to domain but different divisor\n        C = np.diag(((bounds_scale / 8.0) ** 2).clip(min=1e-16))\n        # initial step-size\n        sigma = 0.15 * mean_domain_scale\n        sigma = max(sigma, 1e-12)\n\n        # state\n        p_succ = self.success_target\n        stagn_iters = 0\n\n        # helper: build transform A such that A @ A.T = C\n        def cov_transform(Cmat):\n            vals, vecs = np.linalg.eigh(Cmat)\n            vals = np.clip(vals, self.min_eig_scale, None)\n            # bound condition number\n            minval = vals.min()\n            if minval <= 0:\n                minval = max(self.min_eig_scale, 1e-16)\n                vals = np.clip(vals, minval, None)\n            max_allowed = minval * self.max_eig_ratio\n            vals = np.minimum(vals, max_allowed)\n            A = (vecs * np.sqrt(vals)).T\n            return A, vals, vecs\n\n        # main loop\n        iter_count = 0\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            # choose mu smaller proportionally (different)\n            mu = max(1, lam_iter // 3)\n\n            # linear decreasing weights for elites\n            ranks = np.arange(mu)\n            weights = (mu - ranks).astype(float)\n            weights = weights / weights.sum()\n\n            # get transform\n            A, eigvals, eigvecs = cov_transform(C)\n\n            # candidate composition: more Gaussian probes than DE (different mix)\n            n_gauss = int(np.ceil(0.6 * lam_iter))\n            n_de = lam_iter - n_gauss\n            Xcand = np.empty((lam_iter, self.dim), dtype=float)\n\n            # 1) orthogonalized mirrored Gaussian proposals\n            if n_gauss > 0:\n                # create an orthonormal set of directions using QR of a random square matrix\n                # then take first n_gauss rows (ensures near-orthogonality among directions)\n                G = rng.normal(size=(self.dim, self.dim))\n                Q, _ = np.linalg.qr(G)\n                # If n_gauss > dim, we will reuse orthonormal directions with independent normals\n                orth_dirs = Q.T  # shape (dim, dim) each row is a direction\n                # generate n_gauss direction scalars and combine\n                for i in range(n_gauss):\n                    dir_vec = orth_dirs[i % orth_dirs.shape[0]]\n                    # create a scalar normal for direction, and small orthogonal noise\n                    alpha = rng.normal()\n                    noise = rng.normal(scale=0.3, size=self.dim)\n                    z = alpha * dir_vec + 0.2 * noise\n                    y = z @ (A.T)\n                    xg = m + sigma * y\n                    xg = np.minimum(np.maximum(xg, lb), ub)\n                    # mirrored\n                    xm = 2.0 * m - xg\n                    xm = np.minimum(np.maximum(xm, lb), ub)\n                    # alternate placement between xg and xm to fill slots\n                    if i % 2 == 0:\n                        Xcand[i] = xg\n                    else:\n                        Xcand[i] = xm\n\n            # 2) adaptive DE proposals (rand-to-best style, different mutation)\n            if n_de > 0:\n                # ensure some sorted archive for pull toward better solutions\n                if archive_f.size >= 3:\n                    idx_sort = np.argsort(archive_f)\n                    sorted_X = archive_X[idx_sort]\n                    sorted_f = archive_f[idx_sort]\n                else:\n                    sorted_X = archive_X\n                    sorted_f = archive_f\n\n                for i in range(n_de):\n                    # sample F with multiplicative log-normal heavy-tail around F_base\n                    # this makes occasional large F values possible (different equation)\n                    F = self.F_base * np.exp(rng.normal(scale=0.6))\n                    F = float(np.clip(F, 0.08, 1.2))\n                    # sample CR from a Beta distribution centered around CR_base (different from normal)\n                    cr_raw = rng.beta(2.0, 2.0)\n                    CR = float(np.clip(0.1 + 0.9 * cr_raw * self.CR_base, 0.0, 1.0))\n\n                    # choose a target vector: either a random archive member or the mean\n                    if sorted_X.shape[0] >= 3:\n                        # select distinct indices\n                        idxs = rng.choice(sorted_X.shape[0], size=3, replace=False)\n                        xr = sorted_X[idxs[0]]\n                        xa = sorted_X[idxs[1]]\n                        xb = sorted_X[idxs[2]]\n                        # select a base individual randomly (mix mean and an archive member)\n                        if rng.rand() < 0.6:\n                            base = m\n                        else:\n                            base = sorted_X[rng.randint(sorted_X.shape[0])]\n                        # rand-to-best style: base + F*(best - xr) + F*(xa - xb)\n                        mutant = base + F * (x_best - xr) + F * (xa - xb)\n                    else:\n                        # fallback gaussian\n                        z = rng.normal(size=self.dim)\n                        y = z @ (A.T)\n                        mutant = m + sigma * y\n\n                    # binomial crossover with at least one gene\n                    mask = rng.rand(self.dim) < CR\n                    if not np.any(mask):\n                        mask[rng.randint(self.dim)] = True\n                    # target vector: either mean or a sampled archive member\n                    if rng.rand() < 0.5 and sorted_X.shape[0] > 0:\n                        target = sorted_X[rng.randint(sorted_X.shape[0])]\n                    else:\n                        target = m\n                    trial = np.where(mask, mutant, target)\n                    # small jitter relative to bounds\n                    trial += rng.normal(scale=0.15 * mean_domain_scale * (0.5 + rng.rand()), size=self.dim)\n                    # clamp\n                    Xcand[n_gauss + i] = np.minimum(np.maximum(trial, lb), ub)\n\n            # evaluate candidates (respect budget)\n            f_cand = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                if evals >= self.budget:\n                    f_cand[i] = np.inf\n                    continue\n                f_cand[i] = float(func(Xcand[i]))\n                evals += 1\n\n            # update archive\n            for i in range(lam_iter):\n                archive_add(Xcand[i].copy(), float(f_cand[i]))\n\n            # generation best\n            gen_best_idx = int(np.argmin(f_cand))\n            gen_best_f = float(f_cand[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n                stagn_iters = 0\n            else:\n                stagn_iters += 1\n\n            # selection: take top-mu for covariance update and mean computation\n            order = np.argsort(f_cand)\n            X_mu = Xcand[order[:mu]]\n\n            # recompute weighted mean\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # compute normalized deltas and weighted covariance (different scalings)\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas  # dim x dim\n\n            # rank-one from mean shift (different coefficient)\n            mean_shift = ((m_new - m) / max(sigma, 1e-20)).reshape(-1, 1)\n            rank_one = (mean_shift @ mean_shift.T) * 0.7\n\n            # adaptive cov learning-rate depending on whether we improved\n            cov_lr_eff = self.cov_lr * (1.6 if improved else 0.6)\n            cov_lr_eff = float(np.clip(cov_lr_eff, 1e-6, 0.9))\n            C = (1.0 - cov_lr_eff) * C + cov_lr_eff * (weighted_cov + rank_one)\n\n            # eigen-regularize: set min eig relative to domain variance and cap condition-number\n            vals, vecs = np.linalg.eigh(C)\n            min_eig = max(self.min_eig_scale, (0.5 * np.std(bounds_scale)) ** 2 * 1e-4)\n            vals_clipped = np.clip(vals, min_eig, None)\n            max_allowed = vals_clipped.min() * self.max_eig_ratio\n            vals_clipped = np.minimum(vals_clipped, max_allowed)\n            C = (vecs * vals_clipped) @ vecs.T\n\n            # commit new mean\n            m = m_new.copy()\n\n            # step-size adaptation: different smoothing and multiplicative update\n            p_succ = 0.9 * p_succ + 0.1 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = float(np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale)))\n\n            # stagnation handling\n            if stagn_iters >= self.stagnation_iters and evals < self.budget:\n                stagn_iters = 0\n                # with some probability perform a large Cauchy probe (heavy-tailed)\n                if rng.rand() < self.levy_prob:\n                    # pick an anchor among top archive members\n                    idx_sort = np.argsort(archive_f)\n                    topK = min(len(idx_sort), max(3, self.dim))\n                    anchor = archive_X[idx_sort[rng.randint(topK)]]\n                    # Cauchy-like large step: sample standard Cauchy per-dim scaled by domain\n                    step = rng.standard_cauchy(size=self.dim) * (0.6 * mean_domain_scale)\n                    x_probe = anchor + step\n                    x_probe = np.minimum(np.maximum(x_probe, lb), ub)\n                    if evals < self.budget:\n                        fp = float(func(x_probe))\n                        evals += 1\n                        archive_add(x_probe.copy(), fp)\n                        if fp < f_best:\n                            f_best = fp\n                            x_best = x_probe.copy()\n                            m = x_probe.copy()\n                            sigma = max(sigma, 0.4 * mean_domain_scale)\n                            # reset C to moderately-sized isotropic around domain\n                            C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-16))\n                            p_succ = self.success_target\n                            continue\n                    # if no improvement, inflate small eigenvalues moderately\n                    vals, vecs = np.linalg.eigh(C)\n                    vals = np.maximum(vals, min_eig)\n                    vals *= 1.4\n                    C = (vecs * vals) @ vecs.T\n                    # nudge mean towards best\n                    m = 0.8 * m + 0.2 * x_best\n                    sigma = min(2.0 * np.max(bounds_scale), sigma * 1.3)\n                else:\n                    # milder directional restart around a random good archive member\n                    if archive_f.size > 0:\n                        anchor = archive_X[rng.randint(archive_X.shape[0])]\n                    else:\n                        anchor = x_best\n                    jitter = rng.normal(scale=0.12 * mean_domain_scale, size=self.dim)\n                    m = np.minimum(np.maximum(anchor + jitter, lb), ub)\n                    C = np.diag(((bounds_scale / 7.0) ** 2).clip(min=1e-16))\n                    sigma = max(sigma, 0.22 * mean_domain_scale)\n                    p_succ = self.success_target\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm OrthogonalMirroredDE scored 0.223 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "396683fe-ad29-4f0c-b4bb-bd141f4a9657", "operator": null, "metadata": {"aucs": [0.14860988207793013, 0.18001562806329008, 0.28890076749857496, 0.2937576475113213, 0.25491405210976026, 0.24653876376438089, 0.22817081180838927, 0.22867098547294062, 0.2183145039475557, 0.14127139616272089]}, "task_prompt": ""}
{"id": "f536ead1-8780-4ea0-8b45-27f77045f57b", "fitness": 0.8042007621996786, "name": "BanditHybridCMADE", "description": "The algorithm is a hybrid CMA-/DE-style heuristic that mixes covariance-shaped mirrored Gaussian proposals, archive-driven DE rand/1/bin trials, and heavy-tailed (Cauchy / multivariate-t) jumps to balance local search and global escapes. Operator mixture weights are adapted with an EWMA \"bandit-like\" success signal so more successful operators are sampled more often, while the mean is updated by rank-weighted recombination and the covariance by a blended empirical estimate with a small floor and eigen-regularization to avoid collapse or ill-conditioning. Step-size sigma follows a smoothed success-rate rule (1/5th-style) and stagnation triggers either large heavy-tailed probes or mild restarts/eigen-inflation to escape local optima, with a top-k archive used both for DE parents and anchors for heavy probes. Practical safeguards include box clipping, budget-aware population sizing, mirrored pair generation for efficient sampling, and conservative parameter choices (e.g., small cov_lr, capped condition number, limited sigma range) to keep the method stable across many affine/noiseless BBOB functions.", "code": "import numpy as np\n\nclass BanditHybridCMADE:\n    \"\"\"\n    BanditHybridCMADE: hybrid optimizer for continuous box-bounded problems.\n\n    Main ideas:\n      - Maintain CMA-like state (mean m, covariance C, global step sigma).\n      - Propose candidates from a mix of operators: mirrored Gaussian (covariance-shaped),\n        archive-driven DE rand/1/bin, and heavy-tailed Cauchy/Student-t jumps.\n      - Adapt operator mixture weights with an EWMA \"bandit-like\" success signal so\n        the more useful operators are used more often.\n      - Update mean by rank-weighted recombination and adapt covariance from selected deltas.\n      - Step-size sigma adapts via a smoothed success-rate (1/5th style) and restarts / eigen-inflation\n        / heavy-tailed probes escape stagnation.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n\n        # population and archive settings\n        self.pop_base = None\n        self.lambda_base = None  # computed on first call if None\n        self.archive_size = min(60, max(10, 6 * self.dim))\n\n        # learning rates / controls\n        self.cov_lr = 0.18\n        self.sigma_adapt_rate = 0.22\n        self.success_target = 0.20\n        self.p_succ_alpha = 0.10  # smoothing weight (used when updating p_succ)\n        self.op_weight_alpha = 0.12  # EWMA update for operator weights\n\n        # stagnation / escape\n        self.stagnation_iters = max(10, int(0.04 * self.budget))\n        self.levy_prob = 0.20\n        self.min_eig = 1e-12\n        self.max_cond = 1e8\n\n        # differential params\n        self.F_base = 0.7\n        self.CR_base = 0.9\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        bounds_scale = ub - lb\n\n        # adaptive population size\n        if self.lambda_base is None:\n            self.lambda_base = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        lam = min(self.lambda_base, max(2, self.budget))\n\n        # initial seeding\n        evals = 0\n        init_n = min(lam, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(init_n, self.dim))\n        f0 = np.array([float(func(x)) for x in X0])\n        evals += init_n\n\n        # best-known\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # archive (top-k)\n        archive_X = X0.copy()\n        archive_f = f0.copy()\n\n        def archive_add(x, fx):\n            nonlocal archive_X, archive_f\n            fx = float(fx)\n            if archive_f.size < self.archive_size:\n                archive_X = np.vstack([archive_X, x.reshape(1, -1)])\n                archive_f = np.concatenate([archive_f, np.array([fx])])\n            else:\n                worst = int(np.argmax(archive_f))\n                if fx < archive_f[worst]:\n                    archive_X[worst] = x\n                    archive_f[worst] = fx\n\n        # initialize mean via log-rank weighted recombination of top-half seeds\n        mu0 = max(1, init_n // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        weights0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        weights0 = np.maximum(weights0, 0.0)\n        weights0 = weights0 / np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance and sigma\n        C = np.diag(((bounds_scale / 5.0) ** 2).clip(min=self.min_eig))\n        sigma = 0.22 * np.mean(bounds_scale)\n        sigma = max(sigma, 1e-12)\n\n        # state\n        p_succ = self.success_target\n        stagn_iters = 0\n        iter_count = 0\n\n        # operator list and weights (gauss, de, heavy)\n        ops = ['gauss', 'de', 'heavy']\n        op_weights = np.array([0.5, 0.35, 0.15], dtype=float)\n\n        # helpers\n        def chol_safe(Cmat):\n            # eigh sqrt with clipping & condition number control\n            vals, vecs = np.linalg.eigh(Cmat)\n            vals = np.clip(vals, self.min_eig, None)\n            # enforce condition number\n            minv = vals.min()\n            if vals.max() / max(minv, 1e-30) > self.max_cond:\n                max_allowed = minv * self.max_cond\n                vals = np.minimum(vals, max_allowed)\n            A = (vecs * np.sqrt(vals)).T\n            return A, vals, vecs\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu = max(1, lam_iter // 2)\n\n            # recompute rank weights (log-weights)\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # safe decomposition\n            A, _, _ = chol_safe(C)\n\n            # decide how many candidates per operator by proportional sampling of op_weights\n            probs = op_weights / op_weights.sum()\n            # draw counts via multinomial but ensure total = lam_iter\n            counts = rng.multinomial(lam_iter, probs)\n            n_gauss, n_de, n_heavy = counts.tolist()\n\n            # Build candidate buffer\n            Xcand = np.empty((lam_iter, self.dim), dtype=float)\n            cand_op_index = []  # operator index for each candidate in order\n            idx = 0\n\n            # 1) mirrored covariance-shaped Gaussian proposals\n            if n_gauss > 0:\n                # produce mirrored pairs to fill n_gauss slots\n                # generate n_gauss normals and mirror about mean; that's simple and effective\n                Z = rng.normal(size=(n_gauss, self.dim))\n                Y = Z @ (A.T)\n                Xg = m + sigma * Y\n                Xg_mirror = 2.0 * m - Xg\n                for i in range(n_gauss):\n                    cand = Xg[i] if (i % 2 == 0) else Xg_mirror[i]\n                    cand = np.minimum(np.maximum(cand, lb), ub)\n                    Xcand[idx] = cand\n                    cand_op_index.append(0)\n                    idx += 1\n\n            # 2) archive-driven DE rand/1/bin proposals\n            if n_de > 0:\n                # ensure an archive to sample from\n                if archive_f.size < 3:\n                    # fallback to gaussian proposals\n                    for i in range(n_de):\n                        z = rng.normal(size=self.dim)\n                        y = z @ (A.T)\n                        cand = m + sigma * y\n                        cand = np.minimum(np.maximum(cand, lb), ub)\n                        Xcand[idx] = cand\n                        cand_op_index.append(1)\n                        idx += 1\n                else:\n                    # sort archive by fitness to bias selection\n                    idx_sort = np.argsort(archive_f)\n                    sorted_X = archive_X[idx_sort]\n                    for i in range(n_de):\n                        # sample F and CR from heavy / normal distributions\n                        F = float(np.clip(rng.standard_cauchy() * 0.12 + self.F_base, 0.2, 1.0))\n                        CR = float(np.clip(rng.normal(loc=self.CR_base, scale=0.12), 0.0, 1.0))\n                        # pick three distinct individuals (rand/1)\n                        ids = rng.choice(len(sorted_X), size=3, replace=False)\n                        xr, xa, xb = sorted_X[ids[0]], sorted_X[ids[1]], sorted_X[ids[2]]\n                        mutant = xr + F * (xa - xb)\n                        # target vector chosen between m and a random elite\n                        if rng.rand() < 0.6:\n                            target = m\n                        else:\n                            target = sorted_X[rng.randint(len(sorted_X))]\n                        mask = rng.rand(self.dim) < CR\n                        if not np.any(mask):\n                            mask[rng.randint(self.dim)] = True\n                        trial = np.where(mask, mutant, target)\n                        # add small gaussian jitter proportional to sigma\n                        trial += rng.normal(scale=0.25 * sigma, size=self.dim)\n                        trial = np.minimum(np.maximum(trial, lb), ub)\n                        Xcand[idx] = trial\n                        cand_op_index.append(1)\n                        idx += 1\n\n            # 3) heavy-tailed anchored proposals (Cauchy or multivariate-t)\n            if n_heavy > 0:\n                # pick anchors from the top part of archive or best\n                if archive_f.size > 0:\n                    idx_sort = np.argsort(archive_f)\n                    topK = min(len(idx_sort), max(3, self.dim))\n                    anchors = archive_X[idx_sort[:topK]]\n                else:\n                    anchors = np.array([m])\n                for i in range(n_heavy):\n                    anchor = anchors[rng.randint(len(anchors))]\n                    # use Cauchy for heavy tails\n                    scale = max(0.4 * np.mean(bounds_scale), sigma * 2.5)\n                    jump = rng.standard_cauchy(size=self.dim) * scale\n                    trial = anchor + jump\n                    trial = np.minimum(np.maximum(trial, lb), ub)\n                    Xcand[idx] = trial\n                    cand_op_index.append(2)\n                    idx += 1\n\n            # At this point idx == lam_iter\n            assert idx == lam_iter\n\n            # Evaluate candidates (sequentially) without exceeding budget\n            f_cand = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                if evals >= self.budget:\n                    f_cand[i] = np.inf\n                else:\n                    f_cand[i] = float(func(Xcand[i]))\n                    evals += 1\n\n            # update archive with all candidates\n            for i in range(lam_iter):\n                archive_add(Xcand[i].copy(), f_cand[i])\n\n            # generation best\n            gen_best_idx = int(np.argmin(f_cand))\n            gen_best_f = float(f_cand[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            # update global best and stagnation\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n                stagn_iters = 0\n            else:\n                stagn_iters += 1\n\n            # update operator weights from operator successes: if any candidate from op improved the best in this gen, reward it\n            # also reward ops that produced any candidate better than the previous generation median (weak success)\n            op_success = np.zeros(len(ops), dtype=float)\n            gen_median = np.median(f_cand)\n            for i in range(lam_iter):\n                opi = cand_op_index[i]\n                if f_cand[i] < gen_median:\n                    op_success[opi] += 1.0\n                if f_cand[i] < f_best:  # note f_best already updated, this condition rarely true; we also check improved flag\n                    op_success[opi] += 1.0\n            # Normalize by counts to avoid bias\n            counts_arr = np.array([cand_op_index.count(i) for i in range(len(ops))], dtype=float)\n            denom = np.maximum(counts_arr, 1.0)\n            op_score = op_success / denom\n            # EWMA update of op_weights: increase weights multiplicatively toward op_score\n            # Convert op_score to additive boost\n            op_weights = (1.0 - self.op_weight_alpha) * op_weights + self.op_weight_alpha * (0.5 + op_score)\n            # keep positive\n            op_weights = np.maximum(op_weights, 1e-6)\n\n            # selection: pick top-mu candidates to update mean and covariance\n            order = np.argsort(f_cand)\n            X_mu = Xcand[order[:mu]]\n\n            # recompute mean by rank-weighted recombination\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # deltas normalized by sigma\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas\n\n            # covariance update with blending + small floor\n            floor = np.diag(((bounds_scale / 25.0) ** 2).clip(min=self.min_eig))\n            C = (1.0 - self.cov_lr) * C + self.cov_lr * weighted_cov + 1e-12 * np.eye(self.dim)\n            # blend a little with floor to avoid collapse\n            C = 0.985 * C + 0.015 * floor\n\n            # eigen-regularize to enforce condition number limit\n            vals, vecs = np.linalg.eigh(C)\n            vals = np.clip(vals, self.min_eig, None)\n            minval = vals.min()\n            if (vals.max() / max(minval, 1e-30)) > self.max_cond:\n                max_allowed = minval * self.max_cond\n                vals = np.minimum(vals, max_allowed)\n                C = (vecs * vals) @ vecs.T\n\n            # update mean\n            m = m_new.copy()\n\n            # step-size adaptation via smoothed success-rate\n            p_succ = (1.0 - self.p_succ_alpha) * p_succ + self.p_succ_alpha * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = float(np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale)))\n\n            # stagnation handling: heavy-tailed probe or restart/eigen-inflation\n            if stagn_iters >= self.stagnation_iters and evals < self.budget:\n                if rng.rand() < self.levy_prob:\n                    # heavy-tailed anchored probe (multivariate-t style)\n                    if archive_f.size > 0:\n                        idx_sort = np.argsort(archive_f)\n                        anchor = archive_X[idx_sort[rng.randint(min(len(idx_sort), max(3, self.dim)))]]\n                    else:\n                        anchor = m\n                    df = 2.0\n                    gamma = max(1e-8, rng.chisquare(df))\n                    z = rng.normal(size=self.dim)\n                    scale = max(0.5 * np.mean(bounds_scale), sigma * 4.0)\n                    jump = z / np.sqrt(gamma / df) * scale\n                    x_jump = np.minimum(np.maximum(anchor + jump, lb), ub)\n                    if evals < self.budget:\n                        fj = float(func(x_jump))\n                        evals += 1\n                        archive_add(x_jump.copy(), fj)\n                        if fj < f_best:\n                            f_best = fj\n                            x_best = x_jump.copy()\n                            m = x_jump.copy()\n                            sigma = max(sigma, 0.5 * np.mean(bounds_scale))\n                            # reset covariance moderately\n                            C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=self.min_eig))\n                            stagn_iters = 0\n                else:\n                    # mild restart / eigen-inflation and re-center near best\n                    jitter = rng.normal(scale=0.06 * np.maximum(bounds_scale, 1.0), size=self.dim)\n                    m = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                    # inflate small eigenvalues a bit\n                    vals, vecs = np.linalg.eigh(C)\n                    vals = np.maximum(vals, self.min_eig)\n                    vals *= 1.3\n                    C = (vecs * vals) @ vecs.T\n                    sigma = max(sigma, 0.28 * np.mean(bounds_scale))\n                    stagn_iters = 0\n                # slightly reset operator weights to encourage exploration\n                op_weights = 0.8 * op_weights + 0.2 * np.array([0.5, 0.35, 0.15])\n                # reset p_succ modestly\n                p_succ = self.success_target * 0.7\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm BanditHybridCMADE scored 0.804 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "396683fe-ad29-4f0c-b4bb-bd141f4a9657", "operator": null, "metadata": {"aucs": [0.24952295439687877, 0.62821898011998, 0.8930565398878556, 0.9572412895200375, 0.9229718425237258, 0.9374296758159903, 0.6994174804278863, 0.9035169782906451, 0.929316259870953, 0.9213156211428344]}, "task_prompt": ""}
{"id": "9329d801-d079-4121-b21e-bec3ceb9f32d", "fitness": 0.35625335511927136, "name": "MAPAS", "description": "1) MAPAS mixes two complementary search modes — a momentum-covariance antithetic sampler (MCAS-style) for steady global search and small Hooke–Jeeves pattern local searches for polishing — while keeping a small elite archive to bias updates and trigger jittered restarts.  \n2) It maintains a Gaussian search model (mean m, covariance C, step-size sigma) with momentum v and a per-dimension scale s_diag, updating m from weighted elites, adapting C by a mixture of an EMA weighted covariance and a rank‑one outer product (controlled by cov_update and rank1), and smoothing s_diag by an EMA; antithetic paired normal draws plus a directional perturbation from v drive efficient, low-variance sampling.  \n3) To escape basins and preserve exploration it uses heavy‑tailed Cauchy-like jumps from elites, occasional uniform injections, an adaptive global_jump_prob based on archive spread, and budget-aware jittered restarts on stagnation; sigma is adapted by a smoothed success rate to balance exploration/exploitation.  \n4) The implementation is budget-aware (an eval wrapper never exceeds budget), uses lam0/archive_size sizing tied to problem dimension, clips candidates to bounds, supports seeding, and constrains local pattern searches via local_budget_frac so all mechanisms are lightweight and controlled.", "code": "import numpy as np\n\nclass MAPAS:\n    \"\"\"\n    Momentum-Archive Patterned Adaptive Sampler (MAPAS)\n\n    Main ideas:\n    - MCAS-like antithetic momentum + covariance sampling for steady exploration/exploitation.\n    - Maintain a small elite archive; bias sampling and jittered restarts around elites.\n    - APLS-inspired heavy-tailed Cauchy-like jumps from elites to escape basins.\n    - Occasional Hooke-Jeeves style local pattern search polishing on promising candidates.\n    - Budget-aware eval wrapper and adaptive switching of global/local moves based on archive diversity.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop_base=None,\n                 cov_update=0.18,\n                 rank1=0.06,\n                 mom_beta=0.8,\n                 s_diag_beta=0.6,\n                 sigma_adapt_rate=0.22,\n                 success_target=0.2,\n                 archive_size=None,\n                 global_jump_prob=0.18,\n                 local_budget_frac=0.04):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.pop_base = pop_base\n        self.cov_update = float(cov_update)\n        self.rank1 = float(rank1)\n        self.mom_beta = float(mom_beta)\n        self.s_diag_beta = float(s_diag_beta)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.success_target = float(success_target)\n        self.archive_size = archive_size\n        self.global_jump_prob = float(global_jump_prob)\n        self.local_budget_frac = float(local_budget_frac)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # parse bounds (func.bounds.lb/ub may be scalar or arrays)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        diag_span = np.maximum(span, 1e-12)\n\n        # population base\n        if self.pop_base is None:\n            lam0 = max(6, int(3 + 2 * np.log(max(2, self.dim))))\n        else:\n            lam0 = int(self.pop_base)\n        lam0 = min(lam0, max(2, self.budget))\n\n        # archive size\n        if self.archive_size is None:\n            archive_k = max(3, min(10, lam0))\n        else:\n            archive_k = int(self.archive_size)\n\n        # state\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x) sorted by f asc\n\n        # initial sampling: small quasi-uniform batch to seed mean, covariance, archive\n        batch0 = min(lam0, max(4, int(0.2 * lam0)))\n        X0 = rng.uniform(lb, ub, size=(batch0, self.dim))\n        f0 = []\n        for i in range(batch0):\n            if evals >= self.budget:\n                break\n            fi = func(X0[i])\n            evals += 1\n            f0.append(float(fi))\n            # update best/archive\n            if fi < f_best:\n                f_best = float(fi)\n                x_best = X0[i].copy()\n            archive.append((float(fi), X0[i].copy()))\n        # sort archive and trim\n        archive.sort(key=lambda t: t[0])\n        if len(archive) > archive_k:\n            archive = archive[:archive_k]\n\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n\n        # initialize mean, covariance, sigma similar to MCAS\n        if len(archive) > 0:\n            # mean is weighted average of top half of initial archive or initial samples\n            topn = max(1, len(archive) // 2)\n            elites = np.stack([a[1] for a in archive[:topn]])\n            weights = np.log(topn + 0.5) - np.log(np.arange(1, topn + 1))\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n            m = (weights.reshape(-1, 1) * elites).sum(axis=0)\n        else:\n            m = rng.uniform(lb, ub)\n\n        bounds_scale = (ub - lb)\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.18 * np.mean(bounds_scale))\n\n        # additional momentum/scales\n        v = np.zeros(self.dim, dtype=float)\n        s_diag = np.ones(self.dim, dtype=float)\n        p_succ = 0.2\n        stagn_iter = 0\n        stagnation_threshold = max(5, int(0.03 * self.budget))\n\n        # budget-aware eval wrapper\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = float(func(x))\n            evals += 1\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # archive insertion\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # Hooke-Jeeves-style local search used occasionally (budget-limited)\n        def local_pattern_search(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = np.asarray(x_start, dtype=float).copy()\n            base_f = float(f_start)\n            # initial step proportional to avg_span but not too large\n            step0 = 0.3 * avg_span\n            steps = np.full(self.dim, step0, dtype=float)\n            shrink = 0.5\n            pattern_factor = 1.4\n            local_used = 0\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_used < local_budget and iters < iter_limit and np.any(steps > 1e-9):\n                iters += 1\n                improved = False\n                probe = base.copy()\n                probe_f = base_f\n                for i in range(self.dim):\n                    if local_used >= local_budget or evals >= self.budget:\n                        break\n                    # plus\n                    xp = probe.copy()\n                    xp[i] = np.minimum(xp[i] + steps[i], ub[i])\n                    res = eval_and_record(xp)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < probe_f:\n                        probe = xp.copy()\n                        probe_f = fp\n                        improved = True\n                        continue\n                    # minus\n                    xn = probe.copy()\n                    xn[i] = np.maximum(xn[i] - steps[i], lb[i])\n                    res = eval_and_record(xn)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < probe_f:\n                        probe = xn.copy()\n                        probe_f = fn\n                        improved = True\n                # pattern\n                if improved and local_used < local_budget and evals < self.budget:\n                    direction = probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_and_record(xp)\n                        local_used += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = probe.copy()\n                                base_f = probe_f\n                    else:\n                        base = probe.copy()\n                        base_f = probe_f\n                else:\n                    steps *= shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # utility: heavy-tailed Cauchy-like jump generator, clipped to bounds\n        def heavy_jump(center, scale):\n            direction = rng.randn(self.dim)\n            direction /= (np.linalg.norm(direction) + 1e-12)\n            step_length = rng.standard_cauchy()\n            step_length = np.clip(step_length, -1e3, 1e3)\n            step = direction * (scale * avg_span * (0.4 + 0.6 * rng.rand()))\n            return np.minimum(np.maximum(center + step_length * step, lb), ub)\n\n        # main loop: alternate momentum-covariance antithetic sampling, heavy jumps, and local polishes\n        attempt = 0\n        max_attempts = max(1, self.budget // max(1, lam0))\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            # adapt global jump prob slightly based on archive spread\n            if len(archive) >= 2:\n                spread = np.linalg.norm(archive[0][1] - archive[-1][1])\n                if spread < 0.02 * avg_span:\n                    self.global_jump_prob = min(0.7, self.global_jump_prob + 0.03)\n                else:\n                    self.global_jump_prob = max(0.05, self.global_jump_prob * 0.995)\n\n            # decide operation\n            op = rng.rand()\n            # allocate a small local budget for pattern searches when invoked\n            max_local = min(max(3, int(self.local_budget_frac * self.budget)), remaining - 1) if remaining > 1 else 0\n\n            # 1) global heavy-tailed jump (from an elite) with low probability to escape\n            if op < self.global_jump_prob and len(archive) > 0:\n                if rng.rand() < 0.85:\n                    center = archive[0][1]\n                    center_f = archive[0][0]\n                else:\n                    idx = rng.randint(0, len(archive))\n                    center = archive[idx][1]\n                    center_f = archive[idx][0]\n                cand = heavy_jump(center, scale=max(0.2, 0.8 * (1.0 - attempt / max(1, max_attempts))))\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, x_cand = res\n                # if promising, do a small local polish\n                if max_local > 0 and f_cand <= (archive[0][0] if len(archive) > 0 else np.inf) * 1.08:\n                    local_budget = min(remaining - 1, max_local * 3)\n                    local_budget = max(1, local_budget)\n                    f_after, x_after = local_pattern_search(x_cand, f_cand, local_budget)\n                    # continue loop\n                continue\n\n            # 2) momentum-covariance antithetic sampling (MCAS-style) as main workhorse\n            # determine lam for this round\n            lam = min(lam0, remaining)\n            lam = max(2 if remaining >= 2 else 1, lam)\n            half = lam // 2\n            # ensure SPD covariance for sampling\n            eps_diag = 1e-12 * np.maximum(np.diag(C), 1.0)\n            try:\n                A = np.linalg.cholesky(C + np.diag(eps_diag))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n\n            # antithetic draws\n            Zpos = rng.normal(size=(half, self.dim))\n            Z = np.vstack([Zpos, -Zpos])\n            if lam % 2 == 1:\n                Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n\n            # directional momentum perturbation\n            vlen = np.linalg.norm(v) + 1e-20\n            v_unit = v / vlen if vlen > 0 else np.zeros_like(v)\n            dir_strength = 0.8 * (vlen / (1.0 + vlen))\n            s_scalar = rng.normal(scale=dir_strength, size=(Z.shape[0], 1))\n            Y = Z @ A.T\n            Y = Y + s_scalar * v_unit.reshape(1, -1)\n            Y = Y * s_diag.reshape(1, -1)\n            Xcand = m + sigma * Y\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates sequentially to respect budget\n            fc = np.full(Xcand.shape[0], np.nan, dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                fi = float(func(Xcand[i]))\n                evals += 1\n                fc[i] = fi\n                # update best/archive inline\n                if fi < f_best:\n                    f_best = fi\n                    x_best = Xcand[i].copy()\n                if len(archive) < archive_k or fi < archive[-1][0]:\n                    archive.append((fi, Xcand[i].copy()))\n                    archive.sort(key=lambda t: t[0])\n                    if len(archive) > archive_k:\n                        archive.pop()\n\n            # truncate if some not evaluated\n            valid_mask = np.isfinite(fc)\n            if not np.any(valid_mask):\n                break\n            Xcand = Xcand[valid_mask]\n            fc = fc[valid_mask]\n            lam_actual = fc.shape[0]\n            mu = max(1, lam_actual // 2)\n            # select elites and compute normalized deltas\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            # weights\n            w = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            w = np.maximum(w, 0.0)\n            if np.sum(w) <= 0:\n                w = np.ones_like(w)\n            w = w / np.sum(w)\n            W = w.reshape(-1, 1)\n\n            # compute deltas in normalized coords\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            if deltas.shape[0] > 0:\n                weighted_cov = (deltas * W).T @ deltas\n                delta_mean = (W * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # update momentum, covariance, s_diag, mean, sigma\n            v = self.mom_beta * v + (1.0 - self.mom_beta) * delta_mean\n            rank_one = np.outer(v, v)\n            c_cov = float(self.cov_update)\n            c1 = float(self.rank1)\n            # mixture update\n            C = (1.0 - c_cov - c1) * C + c_cov * weighted_cov + c1 * rank_one\n            C = 0.5 * (C + C.T) + np.diag(np.maximum(np.diag(C), 1e-18))\n            # update s_diag EMA\n            if deltas.shape[0] > 0:\n                stat = np.mean(deltas ** 2, axis=0)\n            else:\n                stat = 1e-6 * np.ones(self.dim)\n            s_diag = (self.s_diag_beta * s_diag +\n                      (1.0 - self.s_diag_beta) * np.sqrt(stat + 1e-20))\n            s_diag = np.clip(s_diag, 0.2, 5.0)\n            # update mean\n            # compute weighted mean of elites\n            if X_mu.shape[0] > 0:\n                if X_mu.shape[0] != W.shape[0]:\n                    mu_eff = X_mu.shape[0]\n                    w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if np.sum(w_eff) <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff = w_eff / np.sum(w_eff)\n                    W_eff = w_eff.reshape(-1, 1)\n                    m_new = (W_eff * X_mu).sum(axis=0)\n                else:\n                    m_new = (W * X_mu).sum(axis=0)\n                m = m_new.copy()\n            # sigma adaptation by smoothed success-rate\n            gen_best_f = np.min(fc)\n            improved = gen_best_f < f_best  # note: f_best was updated inline, but improved detection still meaningful\n            # more precise improved detection:\n            improved = np.min(fc) < f_best or (x_best is not None and np.min(fc) == f_best)\n            # update smoothed success\n            p_succ = 0.85 * p_succ + 0.15 * float(np.min(fc) < f_best)\n            # adapt sigma\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n            # opportunistic local polish around best candidate occasionally\n            if attempt % 7 == 0 and max_local > 0 and x_best is not None:\n                # do small local pattern search around current best\n                res = local_pattern_search(x_best, f_best, max_local)\n                if res is not None:\n                    f_after, x_after = res\n                    if f_after < f_best:\n                        f_best = f_after\n                        x_best = x_after.copy()\n                        # inject into archive\n                        if len(archive) < archive_k or f_after < archive[-1][0]:\n                            archive.append((f_after, x_after.copy()))\n                            archive.sort(key=lambda t: t[0])\n                            if len(archive) > archive_k:\n                                archive.pop()\n\n            # stagnation handling: jittered restarts from elites\n            if stagn_iter >= stagnation_threshold and evals < self.budget:\n                stagn_iter = 0\n                if x_best is not None:\n                    jitter = 0.12 * avg_span * rng.randn(self.dim)\n                    m = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                else:\n                    m = rng.uniform(lb, ub)\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                sigma = max(sigma, 0.5 * np.mean(bounds_scale))\n                v = np.zeros_like(v)\n                s_diag = np.ones_like(s_diag)\n                # small uniform injections\n                if evals < self.budget:\n                    xu = rng.uniform(lb, ub)\n                    eval_and_record(xu)\n\n            # update stagn counters based on recent improvements (recompute best from archive)\n            if len(archive) > 0:\n                if archive[0][0] < f_best:\n                    f_best = archive[0][0]\n                    x_best = archive[0][1].copy()\n                    stagn_iter = 0\n                else:\n                    stagn_iter += 1\n\n            # uniform injection occasionally to maintain exploration\n            if (attempt % 19) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                eval_and_record(xu)\n\n            # break if budget exhausted\n            if evals >= self.budget:\n                break\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n\n        self.f_opt = float(f_best) if f_best is not None else np.inf\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MAPAS scored 0.356 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "396683fe-ad29-4f0c-b4bb-bd141f4a9657", "operator": null, "metadata": {"aucs": [0.13040249286436667, 0.14626643216839874, 0.5459824567342637, 0.46348243266198763, 0.23685453688982894, 0.990944338763471, 0.26592760986025565, 0.41392412045730487, 0.19831151384978085, 0.17043761694305593]}, "task_prompt": ""}
{"id": "34f20b7a-648f-4036-b494-17f189ab405b", "fitness": 0.4472785792919508, "name": "DSES", "description": "The algorithm learns a compact orthonormal search subspace U (via SVD/PCA on recent elites and normalized deltas) and a small low‑rank memory R of recent normalized step directions, then samples mostly inside that subspace with a small isotropic component while occasionally doing full‑space global mirrored (antithetic) sampling to reduce variance. Population and recombination use soft exponential rank weights and a heuristic lambda scaling with dimension/budget, with mirrored pairs and anti‑symmetry to stabilize estimates and an initial bootstrap of elites; sampling mixes subspace draws (p_sub≈0.8), isotropic noise (iso_frac≈0.18) and occasional line searches (prob≈0.12). Step‑size sigma is adapted multiplicatively from a smoothed success probability (p_succ, alpha≈0.16) using a tanh mapping tempered by sqrt(k) and sensitivity eta_sigma≈0.26, and the subspace dimension k is gently expanded or shrunk stochastically to balance exploration/exploitation. Robustness comes from conservative stagnation detection (threshold ≈max(8,0.04*budget)) that triggers a restart which shrinks sigma, jitters the mean toward the best point, re‑initializes U and clears memory, while keeping bounds clamping and numerical safeguards.", "code": "import numpy as np\n\nclass DSES:\n    \"\"\"\n    Directional Subspace Ensemble Search (DSES)\n\n    Main ideas:\n      - Maintain a compact orthonormal subspace U (derived from PCA of recent elites)\n        and a small recent-direction memory (low-rank set) R. Most candidates are\n        sampled inside the learned subspace (low variance) with a small isotropic\n        component for exploration; some candidates are global isotropic.\n      - Use antithetic (mirrored) sampling in the subspace to reduce variance.\n      - Adapt sigma multiplicatively using a smoothed success probability with a\n        novel normalization based on subspace dimension; adjust sampling balance\n        between subspace vs global over time.\n      - Occasionally perform cheap directional line-searches along top directions\n        discovered from PCA or memory to exploit elongated valleys.\n      - Conservative restarts re-seed the subspace and memory, shrink sigma and\n        re-center near best found point to escape stagnation.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 subspace_frac=0.35,      # fraction of dim to use as subspace\n                 mem_size=6,              # number of recent direction vectors to remember\n                 eta_sigma=0.26,          # step-size adaptation sensitivity\n                 success_target=0.25,     # desired success rate\n                 p_succ_alpha=0.16,       # smoothing for success probability\n                 iso_frac=0.18,           # isotropic noise fraction relative to sigma\n                 line_search_prob=0.12,   # probability to do directional line-search\n                 initial_sigma_frac=0.25, # initial sigma fraction of bounds range\n                 random_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.subspace_frac = float(subspace_frac)\n        self.mem_size = int(mem_size)\n        self.eta_sigma = float(eta_sigma)\n        self.success_target = float(success_target)\n        self.p_succ_alpha = float(p_succ_alpha)\n        self.iso_frac = float(iso_frac)\n        self.line_search_prob = float(line_search_prob)\n        self.initial_sigma_frac = float(initial_sigma_frac)\n        self.random_seed = random_seed\n\n        # stagnation threshold: conservative fraction of budget or minimum\n        self.stagnation_threshold = max(8, int(max(1, 0.04 * self.budget)))\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.random_seed)\n\n        # bounds support scalar or per-dim arrays\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = np.maximum(ub - lb, 1e-8)\n\n        # population size heuristic (different flavor than original)\n        if self.pop_base is None:\n            self.lambda_ = max(8, int(6 + 4.0 * np.log1p(self.dim)))\n        else:\n            self.lambda_ = int(self.pop_base)\n        self.lambda_ = min(self.lambda_, max(2, self.budget))\n\n        # bootstrap initial samples (small but > dim if possible)\n        init_batch = min(max(self.lambda_ * 2, self.dim + 4), max(1, self.budget // 12))\n        if init_batch < 1:\n            init_batch = min(self.budget, max(1, self.dim + 1))\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals = init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # weighted initial mean (soft exponential rank weighting)\n        order0 = np.argsort(f0)\n        mu0 = max(2, init_batch // 3)\n        elites0 = X0[order0[:mu0]]\n        ranks = np.arange(mu0)\n        weights0 = np.exp(-ranks / max(1.0, (mu0 / 2.0)))\n        weights0 = weights0 / np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial sigma relative to bounds\n        sigma = max(1e-12, self.initial_sigma_frac * np.mean(bounds_scale))\n\n        # initialize subspace U (dim x k orthonormal) via PCA on elites\n        k = max(1, min(self.dim, int(np.ceil(self.subspace_frac * self.dim))))\n        # compute PCA on centered elites\n        D = (elites0 - m)\n        if D.shape[0] >= 1:\n            # compute small SVD on D (mu0 x dim)\n            try:\n                # compute covariance in sample space (mu0 x mu0) if mu0 < dim\n                if D.shape[0] < self.dim:\n                    U_small, svals, Vt = np.linalg.svd(D, full_matrices=False)\n                    comps = Vt[:k].T  # dim x k\n                else:\n                    Uc, svals, Vt = np.linalg.svd(D, full_matrices=False)\n                    comps = Vt[:k].T\n                # Orthonormalize\n                U = np.array(comps, dtype=float)\n                if U.shape[1] < k:\n                    # pad with random orthonormal vectors\n                    extra = k - U.shape[1]\n                    Rextra = rng.randn(self.dim, extra)\n                    # Gram-Schmidt\n                    for i in range(Rextra.shape[1]):\n                        v = Rextra[:, i]\n                        for j in range(U.shape[1]):\n                            v = v - (U[:, j].dot(v)) * U[:, j]\n                        nrm = np.linalg.norm(v)\n                        if nrm < 1e-12:\n                            v = rng.randn(self.dim)\n                            nrm = np.linalg.norm(v)\n                        Rextra[:, i] = v / nrm\n                    U = np.hstack([U, Rextra])\n                else:\n                    # ensure orthonormal columns\n                    q, _ = np.linalg.qr(U)\n                    U = q[:, :k]\n            except Exception:\n                # fallback random orthonormal\n                Q, _ = np.linalg.qr(rng.randn(self.dim, k))\n                U = Q[:, :k]\n        else:\n            Q, _ = np.linalg.qr(rng.randn(self.dim, k))\n            U = Q[:, :k]\n\n        # memory of recent normalized direction vectors (v_i) with weights\n        R_vecs = []  # list of arrays shape (dim,)\n        R_w = []     # weights (float) for randomness magnitude\n\n        # smoothed success probability\n        p_succ = self.success_target\n\n        # stagnation counter\n        stagn_count = 0\n\n        # small numeric floor\n        min_diag = 1e-16\n\n        # main loop\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam = min(self.lambda_, remaining)\n            lam = max(1, lam)\n\n            # mu recombination\n            mu = max(1, lam // 2)\n            ranks = np.arange(mu)\n            weights = np.exp(-ranks / max(1.0, (mu / 2.0)))\n            weights = weights / np.sum(weights)\n\n            # choose sampling mode: mostly subspace, sometimes global\n            p_sub = 0.80\n            use_subspace = rng.rand() < p_sub\n\n            Xcand = []\n            # number of mirrored pairs\n            npairs = lam // 2\n\n            if use_subspace and k >= 1:\n                # generate subspace mirrored samples\n                # draw Z in R^{npairs x k}\n                if npairs > 0:\n                    Z = rng.normal(size=(npairs, k))\n                    # map to ambient: Y = U @ Z.T -> dim x npairs\n                    Y = (U @ Z.T).T  # shape (npairs, dim)\n                    # incorporate low-rank memory R if present: sample coefficients\n                    if len(R_vecs) > 0:\n                        Rmat = np.vstack(R_vecs)  # r x dim\n                        rw = np.array(R_w)\n                        # draw coefficients per pair from N(0, rw)\n                        coeffs = rng.normal(scale=np.sqrt(np.maximum(rw, 1e-12)), size=(npairs, len(R_w)))\n                        # sum to get contributions shape (npairs, dim)\n                        Rcontrib = coeffs @ Rmat  # (npairs, dim)\n                        Y = Y + Rcontrib\n                    # add small isotropic noise component\n                    eps = rng.normal(size=(npairs, self.dim)) * self.iso_frac\n                    Y = Y + eps\n                    X_plus = m + sigma * Y\n                    X_minus = m - sigma * Y\n                    Xcand.extend(X_plus.tolist())\n                    Xcand.extend(X_minus.tolist())\n\n                # if odd one left\n                if lam % 2 == 1:\n                    z = rng.normal(size=(k,))\n                    y = U @ z\n                    # memory contribution\n                    if len(R_vecs) > 0:\n                        coeff = rng.normal(scale=np.sqrt(np.maximum(R_w, 1e-12)))\n                        # coeff is vector len r, dot with Rmat\n                        Rmat = np.vstack(R_vecs)\n                        y = y + coeff.dot(Rmat)\n                    y = y + rng.normal(size=self.dim) * self.iso_frac\n                    Xcand.append((m + sigma * y).tolist())\n\n            else:\n                # global isotropic mirrored sampling in ambient space\n                if npairs > 0:\n                    Z = rng.normal(size=(npairs, self.dim))\n                    X_plus = m + sigma * Z\n                    X_minus = m - sigma * Z\n                    Xcand.extend(X_plus.tolist())\n                    Xcand.extend(X_minus.tolist())\n                if lam % 2 == 1:\n                    z = rng.normal(size=(self.dim,))\n                    Xcand.append((m + sigma * z).tolist())\n\n            Xcand = np.asarray(Xcand, dtype=float)[:lam]\n\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # occasionally perform a very cheap directional line-search (few extra evals)\n            do_line = (rng.rand() < self.line_search_prob) and (remaining > lam + 2)\n            line_candidates = []\n            if do_line:\n                # choose top direction: first try top PCA dir (first column of U), else memory top\n                if U.shape[1] >= 1:\n                    dir_vec = U[:, 0].copy()\n                elif len(R_vecs) >= 1:\n                    dir_vec = R_vecs[0].copy()\n                else:\n                    dir_vec = rng.randn(self.dim)\n                dir_vec = dir_vec / (np.linalg.norm(dir_vec) + 1e-12)\n                # choose step multipliers\n                tvals = np.array([0.5, 1.0, 2.0])\n                # create plus and minus, but respect remaining budget\n                for t in tvals:\n                    if evals + len(line_candidates) + len(Xcand) >= self.budget:\n                        break\n                    xc = m + sigma * (t * dir_vec)\n                    xc = np.minimum(np.maximum(xc, lb), ub)\n                    line_candidates.append(xc)\n                    xc2 = m - sigma * (t * dir_vec)\n                    line_candidates.append(np.minimum(np.maximum(xc2, lb), ub))\n                # truncate if over budget\n                max_line = max(0, self.budget - evals - len(Xcand))\n                if max_line < len(line_candidates):\n                    line_candidates = line_candidates[:max_line]\n\n            # Merge line candidates after main batch to keep counts simple (we evaluate sequentially)\n            all_candidates = list(Xcand) + list(line_candidates)\n            all_candidates = np.asarray(all_candidates, dtype=float)\n            n_all = all_candidates.shape[0]\n            if n_all == 0:\n                break\n\n            # evaluate candidates sequentially and maintain best\n            fc = np.empty(n_all, dtype=float)\n            for i in range(n_all):\n                # check not exceeding budget\n                if evals >= self.budget:\n                    # mark remaining as inf\n                    fc[i:] = np.inf\n                    break\n                fc[i] = float(func(all_candidates[i]))\n                evals += 1\n                if fc[i] < f_best:\n                    f_best = float(fc[i])\n                    x_best = all_candidates[i].copy()\n\n            # consider only first lam as generation candidates for recombination (line-search results handled separately)\n            gen_n = min(lam, n_all)\n            fc_gen = fc[:gen_n]\n            X_gen = all_candidates[:gen_n]\n\n            # generation best and improvement\n            gen_best_idx = int(np.argmin(fc_gen))\n            gen_best_f = float(fc_gen[gen_best_idx])\n            gen_best_x = X_gen[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                # this case already handled above when evaluating; leave flag for sigma update\n                improved = True\n                stagn_count = 0\n            else:\n                # also check whether any of the line searches improved global best\n                if n_all > gen_n and np.min(fc[gen_n:]) < f_best:\n                    improved = True\n                    stagn_count = 0\n                else:\n                    stagn_count += 1\n\n            # recombine to get new mean using top mu of generation\n            order = np.argsort(fc_gen)\n            X_mu = X_gen[order[:mu]]\n            # weights already computed\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized steps in sigma units (for subspace PCA and memory)\n            deltas = (X_mu - m) / (sigma + 1e-20)   # shape (mu, dim)\n\n            # update PCA subspace U via SVD on deltas (small matrix)\n            try:\n                if deltas.shape[0] >= 1:\n                    # center deltas\n                    D = deltas - deltas.mean(axis=0, keepdims=True)\n                    # SVD\n                    Uc, svals, Vt = np.linalg.svd(D, full_matrices=False)\n                    comps = Vt[:k].T  # dim x k\n                    # orthonormalize\n                    Q, _ = np.linalg.qr(comps)\n                    U = Q[:, :k]\n                else:\n                    # small random perturbation\n                    Q, _ = np.linalg.qr(rng.randn(self.dim, k))\n                    U = Q[:, :k]\n            except Exception:\n                Q, _ = np.linalg.qr(rng.randn(self.dim, k))\n                U = Q[:, :k]\n\n            # update recent-direction memory R: add weighted normalized step (m_new - m)/sigma\n            step = (m_new - m) / (sigma + 1e-20)\n            step_norm = np.linalg.norm(step)\n            if step_norm > 1e-14:\n                v_new = step / step_norm\n                # weight proportional to magnitude of step\n                w_new = min(1.0, step_norm)\n                # push to front\n                R_vecs.insert(0, v_new.copy())\n                R_w.insert(0, w_new)\n                # truncate\n                if len(R_vecs) > self.mem_size:\n                    R_vecs = R_vecs[:self.mem_size]\n                    R_w = R_w[:self.mem_size]\n\n            # accept new mean\n            m = m_new\n\n            # update smoothed success probability and adapt sigma multiplicatively\n            p_succ = (1.0 - self.p_succ_alpha) * p_succ + self.p_succ_alpha * float(improved)\n            # new logistic-like scaling with normalization by sqrt(k) to temper subspace effect\n            denom = 1.0 + 0.5 * np.sqrt(max(1, k))\n            delta = p_succ - self.success_target\n            # mapping using tanh for smoothing extremes\n            adj = np.tanh(3.0 * delta)\n            scale = np.exp(self.eta_sigma * (adj / denom))\n            sigma *= float(scale)\n\n            # clamp sigma sensibly relative to bounds\n            max_sigma = 3.0 * np.max(bounds_scale)\n            min_sigma = 1e-12\n            sigma = float(np.clip(sigma, min_sigma, max_sigma))\n\n            # occasional gentle expansion or contraction of subspace size depending on success\n            if rng.rand() < 0.06:\n                if p_succ > self.success_target and k < self.dim:\n                    # expand\n                    k = min(self.dim, k + 1)\n                    # pad U with random orthonormal vector\n                    extra = rng.randn(self.dim)\n                    # orthogonalize\n                    for j in range(U.shape[1]):\n                        extra = extra - (U[:, j].dot(extra)) * U[:, j]\n                    extra = extra / (np.linalg.norm(extra) + 1e-12)\n                    U = np.hstack([U, extra.reshape(-1, 1)])\n                elif p_succ < self.success_target and k > 1:\n                    # shrink\n                    k = max(1, k - 1)\n                    U = U[:, :k]\n\n            # Restart / re-seed on stagnation\n            if stagn_count >= self.stagnation_threshold and evals < self.budget:\n                stagn_count = 0\n                # strong shrink of sigma and small random jitter of mean near best\n                sigma *= (0.12 + 0.32 * rng.rand())  # between ~0.12 and 0.44\n                jitter_scale = 0.04 * bounds_scale * (0.5 + rng.rand(self.dim))\n                m = x_best + rng.randn(self.dim) * jitter_scale\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset subspace to random orthonormal basis of new k\n                k = max(1, int(np.ceil(self.subspace_frac * self.dim)))\n                Q, _ = np.linalg.qr(rng.randn(self.dim, k))\n                U = Q[:, :k]\n                # clear recent memory\n                R_vecs = []\n                R_w = []\n                # slightly increase lambda to promote diversity\n                self.lambda_ = min(self.lambda_ + 1, max(2, self.budget))\n                # continue without counting extra eval (we already used budget for evaluations)\n                continue\n\n        # done\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DSES scored 0.447 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b9f441db-49d8-4b32-a128-01ee67b1316b", "operator": null, "metadata": {"aucs": [0.16059707027646974, 0.17335210602372608, 0.3516996367607276, 0.9880136975477273, 0.2919516898576273, 0.8353935185667837, 0.2892552869009041, 0.5267761848094183, 0.6804752846511519, 0.17527131752497227]}, "task_prompt": ""}
{"id": "4f5bc64e-6d81-48dd-af21-de4ebb7eb47c", "fitness": 0.42250208019299007, "name": "AMCS", "description": "AMCS maintains a recombination mean and samples mirrored (antithetic) Gaussian steps (with tiny uniform jitter) using a matrix square-root of a learned covariance C (population size ≈ 4+4·√dim, initial bootstrap and strict bound clamping). Covariance learning uses an EMA accumulator S (cov_beta) of the rank‑mu sample covariance plus a moderated rank‑one outer product of an evolution path p (path_decay, c_cov), gently writing increments into C with alpha_c and applying Ledoit‑style shrinkage (shrink_alpha) toward a diagonal prior derived from the problem bounds for robustness and numeric stability. Step‑size sigma is initialized relative to the bounds (sigma_init_frac), adapted by a smoothed success‑rate controller (p_succ with p_succ_alpha toward success_target) using a softened tanh multiplicative update scaled by eta_sigma and dimension, and clipped to sensible bounds. To escape stagnation (stagnation_threshold ≈ max(6,0.04·budget)) the algorithm increases sigma, recenters the mean near the best with randomized jitter, partially resets C/S and the path, and modestly raises population size to trade exploration for exploitation.", "code": "import numpy as np\n\nclass AMCS:\n    \"\"\"\n    Adaptive Mirror Covariance Search (AMCS)\n\n    One-line idea:\n      Use mirrored (antithetic) Gaussian sampling around a recombination mean,\n      keep a compact covariance estimate via exponential moving averaging (EMA)\n      of rank-mu covariance combined with a directional evolution path, apply\n      Ledoit-style shrinkage toward a diagonal prior, and adapt sigma via a\n      softened success-difference multiplicative rule. On stagnation increase\n      exploration (broader restart) rather than immediately collapsing.\n    \n    Main algorithm parameters (tunable):\n      - lambda_ (population size): default ~ 4 + 4*sqrt(dim)\n      - sigma: global step-size, initialized as sigma_init_frac * mean(range)\n      - c_cov: weight of rank-one (path) vs rank-mu mixing in added information\n      - cov_beta: EMA decay for the sample covariance accumulator (S)\n      - alpha_c: how fast C incorporates S+rank-one each generation\n      - shrink_alpha: shrinkage toward diagonal prior (Ledoit-like)\n      - eta_sigma: sensitivity for multiplicative sigma update\n      - success_target, p_succ_alpha: success-rate smoothing and target\n      - path_decay: evolution path memory decay\n      - stagnation_threshold: when to trigger a broader restart\n    \"\"\"\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 c_cov=0.05,            # rank-one mixing in covariance increment\n                 cov_beta=0.72,         # EMA for sample covariance accumulator S\n                 alpha_c=0.18,          # how much new info (S+rank-one) writes into C each gen\n                 shrink_alpha=0.25,     # Ledoit-like shrink toward diagonal prior\n                 sigma_init_frac=0.20,  # initial sigma relative to bounds range\n                 eta_sigma=0.40,        # sigma adaptation sensitivity (different mapping)\n                 success_target=0.25,   # desired success rate for sigma controller\n                 p_succ_alpha=0.12,     # smoothing for success probability\n                 path_decay=0.88,       # evolution path decay\n                 random_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.c_cov = float(c_cov)\n        self.cov_beta = float(cov_beta)\n        self.alpha_c = float(alpha_c)\n        self.shrink_alpha = float(shrink_alpha)\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.eta_sigma = float(eta_sigma)\n        self.success_target = float(success_target)\n        self.p_succ_alpha = float(p_succ_alpha)\n        self.path_decay = float(path_decay)\n        self.random_seed = random_seed\n\n        # stagnation threshold (a few generations, scaled with budget)\n        self.stagnation_threshold = max(6, int(0.04 * self.budget))\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.random_seed)\n\n        # handle bounds (func.bounds.lb/ub may be scalar or arrays)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        bounds_scale = np.maximum(bounds_scale, 1e-8)\n\n        # population size: different heuristic than EDCAS (sqrt scaling)\n        if self.pop_base is None:\n            self.lambda_ = max(4, int(4 + 4.0 * np.sqrt(self.dim)))\n        else:\n            self.lambda_ = int(self.pop_base)\n        self.lambda_ = min(self.lambda_, max(2, self.budget))\n\n        # bootstrap initial batch (a bit larger than lambda for robust init)\n        init_batch = min(max(self.lambda_ * 3, self.dim + 4), max(1, self.budget // 12 + 1))\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals = init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initial mean: weighted average with soft-linear weights (less extreme than exponential)\n        order0 = np.argsort(f0)\n        mu0 = max(1, init_batch // 3)\n        elites0 = X0[order0[:mu0]]\n        ranks0 = np.arange(mu0)\n        weights0 = (mu0 - ranks0).astype(float)\n        weights0 = np.maximum(weights0, 0.0)\n        weights0 /= np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # prior diagonal variance from bounds (different constant than original)\n        prior_var = (bounds_scale / 5.0) ** 2  # slightly wider prior than EDCAS\n\n        # initialize covariance C as diagonal prior but a bit inflated to encourage exploration\n        C = np.diag((prior_var * 1.2).copy())\n\n        # S: EMA accumulator for sample covariance (start from C)\n        S = C.copy()\n\n        # evolution path (directional memory)\n        p = np.zeros(self.dim, dtype=float)\n\n        # initial sigma relative to bounds\n        sigma = max(1e-12, self.sigma_init_frac * np.mean(bounds_scale))\n\n        # small numerical floor\n        min_diag = 1e-18\n\n        # smoothed success probability\n        p_succ = float(self.success_target)\n\n        # stagnation counter\n        stagn_count = 0\n\n        # main loop\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam = min(self.lambda_, remaining)\n            lam = max(1, lam)\n\n            # recombination mu and weights: moderately top-heavy but smoother\n            mu = max(1, lam // 2)\n            ranks = np.arange(mu)\n            # softer exponential than original: denominator scales with mu*0.9\n            weights = np.exp(-ranks / max(1.0, (mu * 0.9)))\n            weights = weights / np.sum(weights)\n\n            # ensure SPD for C\n            try:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, min_diag, None)\n                sqrt_vals = np.sqrt(vals)\n                B = vecs * sqrt_vals.reshape(1, -1)  # B such that B @ B.T = C\n            except Exception:\n                B = np.eye(self.dim) * np.sqrt(np.maximum(np.diag(C), min_diag))\n\n            # Antithetic (mirrored) sampling with a tiny stratified uniform jitter\n            Xcand = []\n            to_make = lam\n            npairs = to_make // 2\n            if npairs > 0:\n                Z = rng.normal(size=(npairs, self.dim))\n                Y = Z @ B  # shape (npairs, dim)\n                # small uniform stratified jitter relative to bounds to preserve exploration\n                jitter = (rng.rand(npairs, self.dim) - 0.5) * (0.01 * bounds_scale)\n                X_plus = m + sigma * Y + jitter\n                X_minus = m - sigma * Y - jitter\n                Xcand.extend(X_plus.tolist())\n                Xcand.extend(X_minus.tolist())\n            if to_make % 2 == 1:\n                z = rng.normal(size=(self.dim,))\n                y = z @ B\n                jit = (rng.rand(self.dim) - 0.5) * (0.01 * bounds_scale)\n                Xcand.append((m + sigma * y + jit).tolist())\n\n            Xcand = np.asarray(Xcand, dtype=float)[:lam]\n\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates individually to count evaluations exactly\n            fc = np.empty(lam, dtype=float)\n            for i in range(lam):\n                fc[i] = float(func(Xcand[i]))\n            evals += lam\n\n            # generation best and update global best\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # recombine to get new mean\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized steps in sigma units\n            deltas = (X_mu - m) / (sigma + 1e-20)   # shape (mu, dim)\n\n            # weighted sample covariance (rank-mu estimate)\n            W = weights.reshape(-1, 1)\n            sample_cov = (deltas * W).T @ deltas\n\n            # EMA accumulator update for sample covariance (S)\n            S = self.cov_beta * S + (1.0 - self.cov_beta) * sample_cov\n\n            # update evolution path p (directional memory)\n            y_w = (m_new - m) / (sigma + 1e-20)\n            p = self.path_decay * p + (1.0 - self.path_decay) * y_w\n\n            # rank-one from path (directional)\n            rank_one = np.outer(p, p)\n\n            # combine increments: add S and a moderated rank-one, then write into C gently\n            increment = S + self.c_cov * rank_one\n            C_temp = (1.0 - self.alpha_c) * C + self.alpha_c * increment\n\n            # Ledoit-style shrink toward diagonal prior (mean-scaled target)\n            shrink_target = np.diag(prior_var.mean() * np.ones(self.dim))\n            C = (1.0 - self.shrink_alpha) * C_temp + self.shrink_alpha * shrink_target\n\n            # symmetrize and add tiny jitter for numeric stability\n            C = 0.5 * (C + C.T)\n            diagC = np.diag(C)\n            jitter = 1e-14 * np.maximum(diagC, 1.0)\n            C += np.diag(jitter)\n\n            # ensure positive definiteness\n            vals = np.linalg.eigvalsh(C)\n            if np.min(vals) <= 0:\n                C += np.eye(self.dim) * (abs(np.min(vals)) + min_diag)\n\n            # accept new mean\n            m = m_new\n\n            # update smoothed success probability\n            p_succ = (1.0 - self.p_succ_alpha) * p_succ + self.p_succ_alpha * float(improved)\n\n            # sigma adaptation (different mapping than EDCAS):\n            # use a softened proportional term capped by tanh and scaled down by dimension\n            diff = p_succ - self.success_target\n            # soften with tanh and scale by a dimension-dependent denominator\n            denom = 1.0 + np.sqrt(float(self.dim)) / 6.0\n            factor = np.exp(self.eta_sigma * np.tanh(3.0 * diff) / denom)\n            sigma *= float(factor)\n\n            # sensible sigma bounds relative to problem scale\n            max_sigma = 3.0 * np.max(bounds_scale)\n            min_sigma = 1e-14\n            sigma = float(np.clip(sigma, min_sigma, max_sigma))\n\n            # conservative but explorative restart on stagnation:\n            # instead of collapsing sigma, broaden search and re-center around a random neighborhood of the best\n            if stagn_count >= self.stagnation_threshold and evals < self.budget:\n                stagn_count = 0\n                # modestly increase sigma to escape local traps\n                sigma *= (1.6 + 0.9 * rng.rand())  # factor in [1.6, 2.5]\n                # center mean near best with randomized offset (wider than EDCAS)\n                jitter_scale = 0.12 * bounds_scale * (0.3 + rng.rand(self.dim))\n                m = x_best + rng.randn(self.dim) * jitter_scale\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset C to a slightly contracted diagonal prior (keep some structure)\n                C = np.diag((prior_var * (0.8 + 0.4 * rng.rand())).clip(min=min_diag))\n                # reset S to C and damp path\n                S = C.copy()\n                p *= 0.25\n                # increase population moderately (explore more) but do not exceed remaining budget\n                self.lambda_ = min(self.lambda_ + 2, max(2, remaining))\n                continue\n\n        # done\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AMCS scored 0.423 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b9f441db-49d8-4b32-a128-01ee67b1316b", "operator": null, "metadata": {"aucs": [0.26669316873850635, 0.1770425986555879, 0.4329789730859285, 0.9644568102499524, 0.3980439354384059, 0.48463330242984204, 0.3439620162003242, 0.3941373147138342, 0.40001034477668695, 0.36306233764083273]}, "task_prompt": ""}
{"id": "384aacc3-3587-4153-ac33-40b04f8217cc", "fitness": 0.24530544005159677, "name": "ASLS", "description": "The algorithm learns a compact adaptive search subspace from a rolling memory of recent successful normalized steps (mem_S) using SVD and then samples anisotropic Gaussian steps inside that low-dimensional basis mixed with isotropic noise (alpha ~0.85) while using antithetic pairing to reduce variance. It supplements local Gaussian search with occasional heavy-tailed Lévy-like Cauchy jumps (levy_prob ≈ 0.06) and differential-style mutations (diff_prob ≈ 0.10) to escape basins, and it initializes from a small uniform batch with exponential-ranked recombination weights to form a reliable starting mean. Per-dimension diagonal variance (diag_var) and a global step-size sigma are adapted online — diag_var via squared normalized mean steps (diag_adapt_alpha) and sigma via a smoothed success probability p_succ (p_succ_alpha) mapped through a tanh-like gain (eta_sigma) — while sigma and diag are clipped relative to the problem bounds. To avoid stagnation the code performs focused restarts (shrinking sigma/diag and recentering around the best), occasional greedy local refinements, and budget-aware population sizing so the method stays robust across dimensions and evaluation limits.", "code": "import numpy as np\n\nclass ASLS:\n    \"\"\"\n    Adaptive Subspace Lévy Search (ASLS)\n\n    One-line idea:\n      Learn a compact subspace from recent successful step directions and sample\n      anisotropic Gaussian steps inside that subspace plus isotropic noise,\n      occasionally perform heavy-tailed Lévy jumps and differential-like\n      mutations; adapt per-dimension scaling (diagonal), sigma (global step),\n      and restart focused around the best if stagnation occurs.\n\n    Notes:\n      - __init__(self, budget, dim, ...) required by harness.\n      - func.bounds.lb / ub supported as scalar or per-dimension arrays.\n      - This implementation ensures func() is called at most self.budget times.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 init_sigma_frac=0.25,\n                 levy_prob=0.06,\n                 diff_prob=0.10,\n                 mem_size=24,\n                 subspace_dim=3,\n                 eta_sigma=0.35,\n                 success_target=0.28,\n                 p_succ_alpha=0.15,\n                 diag_adapt_alpha=0.12,\n                 stagn_tol_factor=0.06,\n                 random_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.init_sigma_frac = float(init_sigma_frac)\n        self.levy_prob = float(levy_prob)\n        self.diff_prob = float(diff_prob)\n        self.mem_size = int(mem_size)\n        self.subspace_dim = max(1, int(subspace_dim))\n        self.eta_sigma = float(eta_sigma)\n        self.success_target = float(success_target)\n        self.p_succ_alpha = float(p_succ_alpha)\n        self.diag_adapt_alpha = float(diag_adapt_alpha)\n        self.stagnation_threshold = max(8, int(max(1, stagn_tol_factor * self.budget)))\n        self.random_seed = random_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.random_seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = np.maximum(ub - lb, 1e-8)\n\n        # population size heuristic\n        if self.pop_base is None:\n            lam = max(6, int(6 + 5.5 * np.log1p(self.dim)))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # small initial sampling to get a starting point and initial diag scale\n        init_batch = min(max(lam * 2, self.dim + 2), max(10, self.budget // 20 + 1))\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals = init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initial mean: weighted average of top third\n        order0 = np.argsort(f0)\n        mu0 = max(1, init_batch // 3)\n        elites0 = X0[order0[:mu0]]\n        ranks = np.arange(mu0)\n        # smoother exponential emphasis\n        weights0 = np.exp(-ranks / max(1.0, mu0 / 4.0))\n        weights0 /= np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # diagonal scaling: start with bounds-derived variance but slightly conservative\n        diag_var = ((bounds_scale * 0.5) ** 2)  # start medium spread\n        diag_var = np.maximum(diag_var, 1e-12)\n        sqrt_diag = np.sqrt(diag_var)\n\n        # global sigma\n        sigma = max(1e-12, self.init_sigma_frac * np.mean(bounds_scale))\n\n        # memory of normalized successful steps (rows are steps)\n        mem_S = np.zeros((0, self.dim), dtype=float)\n\n        # smoothed success probability\n        p_succ = self.success_target\n\n        stagn_count = 0\n\n        # main loop\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam_gen = min(lam, remaining)\n            lam_gen = max(1, lam_gen)\n\n            # build recombination weights (ranked exponential)\n            mu = max(1, lam_gen // 2)\n            ranks = np.arange(mu)\n            weights = np.exp(-ranks / max(1.0, (mu / 3.0)))\n            weights /= np.sum(weights)\n\n            # determine sampling strategy per candidate\n            Xcand = np.empty((lam_gen, self.dim), dtype=float)\n            # Prepare subspace basis from mem_S via SVD (if enough memory)\n            k = min(self.subspace_dim, mem_S.shape[0], self.dim)\n            if k >= 1:\n                # center mem_S\n                S_center = mem_S - np.mean(mem_S, axis=0, keepdims=True)\n                try:\n                    U_s, svals, Vt = np.linalg.svd(S_center, full_matrices=False)\n                    # top-k principal directions: Vt[:k]\n                    basis = Vt[:k]  # shape (k, dim)\n                except Exception:\n                    basis = None\n            else:\n                basis = None\n\n            # prepare antithetic pairs when possible (gives lower variance)\n            use_antithetic = (lam_gen % 2 == 0)\n\n            i = 0\n            while i < lam_gen:\n                do_levy = (rng.rand() < self.levy_prob)\n                do_diff = (rng.rand() < self.diff_prob) and (evals + (lam_gen - i) > 0)\n                if do_diff and evals > 0 and remaining > 0:\n                    # differential mutation style candidate: best + F*(xr1 - xr2)\n                    # sample two random offsets within bounds\n                    xr1 = rng.uniform(lb, ub)\n                    xr2 = rng.uniform(lb, ub)\n                    F = 0.6 + 0.6 * rng.rand()\n                    cand = x_best + F * (xr1 - xr2)\n                    cand = np.minimum(np.maximum(cand, lb), ub)\n                    Xcand[i] = cand\n                    i += 1\n                    continue\n\n                if do_levy:\n                    # heavy-tailed jump using scaled Cauchy (approx Lévy-like)\n                    # sample Cauchy and clip extreme extremes (but keep heavy tail)\n                    z = rng.standard_cauchy(size=self.dim)\n                    # temper the extremes\n                    z = np.clip(z, -10.0, 10.0)\n                    step = sigma * (0.8 * z) * sqrt_diag  # scale per-dimension\n                    cand = m + step\n                    cand = np.minimum(np.maximum(cand, lb), ub)\n                    Xcand[i] = cand\n                    i += 1\n                    # mirrored counterpart for antithetic if desired\n                    if use_antithetic and i < lam_gen:\n                        Xcand[i] = np.minimum(np.maximum(m - step, lb), ub)\n                        i += 1\n                    continue\n\n                # anisotropic Gaussian in learned subspace + isotropic noise\n                if basis is not None:\n                    # sample coefficients in subspace\n                    coeffs = rng.randn(k)\n                    lr_vec = coeffs @ basis  # shape (dim,)\n                else:\n                    lr_vec = np.zeros(self.dim)\n\n                iso = rng.randn(self.dim)\n                # mixing weights (favor learned subspace if available)\n                alpha = 0.85 if basis is not None else 0.0\n                z = alpha * lr_vec + (1.0 - alpha) * iso\n                # normalize z to unit RMS to keep scales interpretable (avoid blow-up)\n                z_rms = np.sqrt(np.mean(z ** 2)) + 1e-12\n                z = z / z_rms\n\n                step = sigma * (sqrt_diag * z)\n                # antithetic pairing\n                Xcand[i] = np.minimum(np.maximum(m + step, lb), ub)\n                i += 1\n                if use_antithetic and i < lam_gen:\n                    Xcand[i] = np.minimum(np.maximum(m - step, lb), ub)\n                    i += 1\n\n            # Evaluate candidates (one by one to track budget exactly)\n            fc = np.empty(lam_gen, dtype=float)\n            for j in range(lam_gen):\n                fc[j] = float(func(Xcand[j]))\n            evals += lam_gen\n\n            # generation-best\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # recombine to get new mean (weighted over top mu)\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized step used for memory and diag adaptation\n            y = (m_new - m) / (sigma + 1e-20)  # relative in sigma units\n            # adapt diagonal variance estimate from this step (on squared normalized step)\n            step_var_est = y ** 2\n            diag_var = (1.0 - self.diag_adapt_alpha) * diag_var + self.diag_adapt_alpha * (step_var_est * (sigma ** 2) + 1e-12)\n            sqrt_diag = np.sqrt(np.maximum(diag_var, 1e-16))\n\n            # update memory S with normalized successful directions (store y)\n            # we only push the weighted average step when the generation improved or best-of-gen diff\n            # also push if top candidate improved over mean (diversify)\n            push_step = y\n            mem_S = np.vstack([mem_S, push_step.reshape(1, -1)])\n            if mem_S.shape[0] > self.mem_size:\n                # drop oldest\n                mem_S = mem_S[-self.mem_size:]\n\n            # compute success smoothing and sigma adaptation\n            p_succ = (1.0 - self.p_succ_alpha) * p_succ + self.p_succ_alpha * float(improved)\n            delta = p_succ - self.success_target\n            # map delta through smooth logistic-ish: small changes near target, saturate at extremes\n            adj = np.tanh(3.0 * delta)\n            # scale depending on dimension (milder for bigger dims)\n            dim_fac = 1.0 + 0.2 * np.log1p(self.dim)\n            scale = np.exp(self.eta_sigma * adj / dim_fac)\n            sigma *= float(scale)\n            # clip sigma sensibly relative to bounds\n            sigma = float(np.clip(sigma, 1e-12, 3.0 * np.max(bounds_scale)))\n\n            # accept new mean\n            m = m_new\n\n            # if improvement found, optionally refine by local short-step exploration (greedy)\n            if improved and (evals < self.budget):\n                # try a small local step along best direction\n                local_step = 0.5 * sigma * rng.randn(self.dim) * sqrt_diag\n                x_local = np.minimum(np.maximum(x_best + local_step, lb), ub)\n                f_local = float(func(x_local))\n                evals += 1\n                if f_local < f_best:\n                    f_best = f_local\n                    x_best = x_local.copy()\n\n            # focused restart if stagnation prolonged\n            if stagn_count >= self.stagnation_threshold and evals < self.budget:\n                stagn_count = 0\n                # compress sigma and diag to focus search near the best, but add a small randomization\n                sigma *= (0.12 + 0.35 * rng.rand())  # shrink to [0.12,0.47] times current\n                diag_var = diag_var * (0.25 + 0.5 * rng.rand(self.dim))  # shrink diag\n                diag_var = np.maximum(diag_var, 1e-16)\n                sqrt_diag = np.sqrt(diag_var)\n                # recenter mean near best with small jitter (bounded)\n                jitter = 0.04 * bounds_scale * (0.5 + rng.rand(self.dim))\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset memory but keep some diversity\n                keep = max(0, mem_S.shape[0] // 3)\n                if keep > 0:\n                    mem_S = mem_S[-keep:]\n                else:\n                    mem_S = np.zeros((0, self.dim), dtype=float)\n                # increase population slightly to explore more after restart\n                lam = min(lam + 2, max(2, self.budget))\n                # small reset of p_succ to target\n                p_succ = self.success_target\n                continue\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ASLS scored 0.245 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b9f441db-49d8-4b32-a128-01ee67b1316b", "operator": null, "metadata": {"aucs": [0.17692109775243647, 0.16718455647344843, 0.26336436694387744, 0.2835972215503375, 0.2691299827599575, 0.2896661788559356, 0.23593410706485973, 0.28215981268272283, 0.3347133571503743, 0.15038371928201832]}, "task_prompt": ""}
{"id": "4bd02dec-2752-4148-bb94-2409ce316ff3", "fitness": 0.8071391333402238, "name": "ODS", "description": "The algorithm performs an \"Orthogonal Directional Search\": it represents the search distribution as a diagonal variance vector (diagC) plus a small low-rank set of recent normalized step directions (Dvecs), and generates antithetic samples around a recombined mean to exploit both per-coordinate scales and informative linear directions. Sampling uses z * sqrt(diagC) plus a linear combination of stored directions, clamps to bounds, and evaluates a population whose size is a light heuristic (lambda ≈ 4 + 2·sqrt(dim)); the initial mean is a softmax-weighted combination of a small initial batch. Adaptation is twofold: per-coordinate variances are updated by exponential smoothing of empirical squared standardized steps (diag_alpha ≈ 0.18), while step-size adapts additively on log(sigma) via a smoothed success probability (p_succ_alpha ≈ 0.2, eta_sigma ≈ 0.18, success_target ≈ 0.25). Directional memory is kept low-rank (rank_size default 4) with decay (rank_decay ≈ 0.85) and Gram–Schmidt-style orthonormalization to reduce redundancy, and a stagnation-based restart increases sigma, jitters the mean around the best-so-far and clears memory to encourage exploration.", "code": "import numpy as np\n\nclass ODS:\n    \"\"\"\n    Orthogonal Directional Search (ODS)\n\n    One-line idea:\n      Use orthogonalized antithetic samples built from a diagonal variance model\n      plus a small low-rank set of directional vectors (recent successful steps),\n      adapt per-coordinate variances via exponential smoothing, update a compact\n      directional memory (rank vectors), and adapt step-size on the log scale\n      using a smoothed success probability.\n\n    Main tunable parameters (accessible through __init__):\n      - pop_base: optional explicit population size; otherwise a heuristic growing with sqrt(dim)\n      - sigma_init_frac: initial sigma relative to average bounds range\n      - eta_sigma: sensitivity of additive log-sigma adaptation (different equation than original)\n      - success_target: desired success rate for sigma controller\n      - p_succ_alpha: smoothing for success probability\n      - diag_alpha: smoothing for per-coordinate variance estimate (diagonal covariance)\n      - rank_decay: decay for stored direction vectors (how fast old directions fade)\n      - rank_size: how many directional vectors to keep (low-rank part)\n      - random_seed: to make runs reproducible\n\n    Differences to EDCAS (high level):\n      - population heuristic ~ 4 + 2*sqrt(dim) (not 6+6*log1p(dim))\n      - covariance is maintained as a diagonal variance vector + explicit low-rank direction vectors;\n        sampling composes a diagonal-scaled isotropic part with a linear combination of stored directions\n      - step-size adaptation updates log(sigma) additively (log_sigma += eta*(p_succ - target))\n        rather than using a tanh mapping in the exponent\n      - direction memory updated via decay + Gram-Schmidt-like re-orthogonalization\n      - restart increases sigma (exploratory) and clears directional memory (contrasts with conservative shrink)\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 sigma_init_frac=0.25,\n                 eta_sigma=0.18,\n                 success_target=0.25,\n                 p_succ_alpha=0.2,\n                 diag_alpha=0.18,\n                 rank_decay=0.85,\n                 rank_size=4,\n                 random_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.eta_sigma = float(eta_sigma)\n        self.success_target = float(success_target)\n        self.p_succ_alpha = float(p_succ_alpha)\n        self.diag_alpha = float(diag_alpha)\n        self.rank_decay = float(rank_decay)\n        self.rank_size = int(rank_size)\n        self.random_seed = random_seed\n\n        # stagnation threshold (iterations without improvement); slightly different heuristic\n        self.stagnation_threshold = max(8, int(max(1, 0.04 * self.budget)))\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.random_seed)\n\n        # bounds handling (supports scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        bounds_scale = np.maximum(bounds_scale, 1e-8)\n        mean_range = float(np.mean(bounds_scale))\n\n        # population size heuristic: gentle growth with sqrt(dim) (different from original)\n        if self.pop_base is None:\n            self.lambda_ = max(4, int(4 + 2.0 * np.sqrt(self.dim)))\n        else:\n            self.lambda_ = int(self.pop_base)\n        self.lambda_ = min(self.lambda_, max(2, self.budget))\n\n        # initialization batch: ensure we evaluate at least a few points\n        init_batch = min(max(self.lambda_ * 2, self.dim + 2), max(1, self.budget // 10))\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals = init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # weighted initial mean (top third) but with a different weighting scheme (softmax on negative rank)\n        order0 = np.argsort(f0)\n        mu0 = max(1, init_batch // 3)\n        elites0 = X0[order0[:mu0]]\n        ranks0 = np.arange(mu0)\n        weights0 = np.exp(-ranks0 / max(1.0, (mu0 / 2.0)))\n        weights0 = weights0 / np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # diagonal per-coordinate variance prior (tighter than naive)\n        prior_var = (bounds_scale / 6.0) ** 2\n        diagC = (prior_var * 0.9).clip(min=1e-16)  # vector of variances\n\n        # low-rank directional memory: list of direction vectors (each shape (dim,))\n        Dvecs = []  # recent successful normalized steps (in sigma units)\n\n        # initial sigma relative to bounds (larger than original to encourage exploration initially)\n        sigma = max(1e-12, self.sigma_init_frac * mean_range)\n        log_sigma = np.log(max(1e-12, sigma))\n\n        # smoothed success probability\n        p_succ = self.success_target\n\n        # stagnation counter\n        stagn_count = 0\n\n        # small numeric floor\n        eps = 1e-20\n\n        # helper for Gram-Schmidt-like orthogonalization of Dvecs\n        def orthonormalize_list(vecs):\n            if len(vecs) == 0:\n                return []\n            Q = []\n            for v in vecs:\n                w = v.copy()\n                for q in Q:\n                    w = w - np.dot(w, q) * q\n                norm = np.linalg.norm(w)\n                if norm > 1e-12:\n                    Q.append(w / norm)\n                # else drop near-zero direction\n            return Q\n\n        # main optimization loop\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam = min(self.lambda_, remaining)\n            lam = max(1, lam)  # ensure at least one sample\n\n            # recombination weights for new mean (different decay exponent)\n            mu = max(1, lam // 2)\n            ranks = np.arange(mu)\n            weights = np.exp(- (ranks ** 1.1) / max(1.0, (mu * 0.9)))\n            weights = weights / np.sum(weights)\n\n            # build samples using antithetic pairs and orthogonalized low-rank directions\n            Xcand = []\n            npairs = lam // 2\n            # precompute diagonal sqrt\n            sqrt_diag = np.sqrt(np.maximum(diagC, 1e-30))\n            # stack Dvecs into matrix for fast linear combination\n            if len(Dvecs) > 0:\n                Dmat = np.vstack(Dvecs)  # shape (r, dim)\n            else:\n                Dmat = None\n\n            for _ in range(npairs):\n                z = rng.randn(self.dim)\n                # low-rank contribution: sample coefficients ~ N(0,1) for each direction\n                if Dmat is not None:\n                    coeffs = rng.randn(Dmat.shape[0])\n                    low_rank = coeffs @ Dmat   # linear combination of stored directions\n                else:\n                    low_rank = 0.0\n                y = z * sqrt_diag + low_rank\n                Xcand.append((m + np.exp(log_sigma) * y).tolist())\n                Xcand.append((m - np.exp(log_sigma) * y).tolist())\n\n            if lam % 2 == 1:\n                z = rng.randn(self.dim)\n                if Dmat is not None:\n                    coeffs = rng.randn(Dmat.shape[0])\n                    low_rank = coeffs @ Dmat\n                else:\n                    low_rank = 0.0\n                y = z * sqrt_diag + low_rank\n                Xcand.append((m + np.exp(log_sigma) * y).tolist())\n\n            Xcand = np.asarray(Xcand, dtype=float)[:lam]\n\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates one-by-one\n            fc = np.empty(lam, dtype=float)\n            for i in range(lam):\n                fc[i] = float(func(Xcand[i]))\n            evals += lam\n\n            # generation best and update global best\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # recombine to produce new mean\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized steps (in sigma units)\n            deltas = (X_mu - m) / (np.exp(log_sigma) + eps)   # shape (mu, dim)\n\n            # update diagonal variances: exponential moving average of empirical variance from deltas\n            emp_var = np.mean(deltas ** 2, axis=0) + 1e-16\n            diagC = (1.0 - self.diag_alpha) * diagC + self.diag_alpha * emp_var\n            diagC = np.maximum(diagC, 1e-20)\n\n            # update directional memory:\n            # take the primary displacement y_w and insert into Dvecs after normalization and decay\n            y_w = (m_new - m) / (np.exp(log_sigma) + eps)\n            # normalize by standard deviation per coordinate to encourage scale invariance\n            normalized_y = y_w / (np.sqrt(diagC) + 1e-16)\n            # Scale new direction to unit length in the transformed coordinate\n            norm_y = np.linalg.norm(normalized_y)\n            if norm_y > 1e-12:\n                dir_new = normalized_y / norm_y\n                # decay existing directions\n                Dvecs = [self.rank_decay * v for v in Dvecs]\n                # append new direction\n                Dvecs.append(dir_new)\n                # trim and orthonormalize to keep them informative\n                if len(Dvecs) > self.rank_size:\n                    Dvecs = Dvecs[-self.rank_size:]\n                # optional Gram-Schmidt style orthonormalization to reduce redundancy\n                Dvecs = orthonormalize_list(Dvecs)\n                # ensure kept at most rank_size\n                if len(Dvecs) > self.rank_size:\n                    Dvecs = Dvecs[:self.rank_size]\n            else:\n                # still decay old directions if new one is negligible\n                Dvecs = [self.rank_decay * v for v in Dvecs]\n                # remove too small vectors\n                Dvecs = [v for v in Dvecs if np.linalg.norm(v) > 1e-12]\n\n            # update smoothed success probability\n            p_succ = (1.0 - self.p_succ_alpha) * p_succ + self.p_succ_alpha * float(improved)\n\n            # additive update on log(sigma) (different equation than original: direct additive log-space)\n            log_sigma += self.eta_sigma * (p_succ - self.success_target)\n            # enforce sigma bounds relative to problem\n            sigma = np.exp(log_sigma)\n            max_sigma = 3.0 * np.max(bounds_scale)\n            min_sigma = 1e-12\n            if sigma > max_sigma:\n                sigma = max_sigma\n                log_sigma = np.log(sigma)\n            if sigma < min_sigma:\n                sigma = min_sigma\n                log_sigma = np.log(sigma)\n\n            # accept new mean\n            m = m_new\n\n            # restart on stagnation, but here we take a more explorative action:\n            # clear directional memory and increase sigma moderately to escape\n            if stagn_count >= self.stagnation_threshold and evals < self.budget:\n                stagn_count = 0\n                # increase sigma randomly between 1.5x and 3.0x to allow larger jumps\n                factor = 1.5 + 1.5 * rng.rand()\n                log_sigma = np.log(min(max_sigma, np.exp(log_sigma) * factor))\n                # center mean near global best but add controlled noise\n                jitter_scale = 0.10 * bounds_scale * (0.2 + rng.rand(self.dim))\n                m = x_best + rng.randn(self.dim) * jitter_scale\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset diagonal to somewhat larger local variance\n                diagC = (prior_var * (0.8 + 0.8 * rng.rand(self.dim))).clip(min=1e-20)\n                # clear directional memory\n                Dvecs = []\n                # slightly increase lambda to diversify samples next generations\n                self.lambda_ = min(self.lambda_ + 1, max(2, self.budget))\n                # continue to next generation without further updates this iteration\n                continue\n\n        # done\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ODS scored 0.807 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b9f441db-49d8-4b32-a128-01ee67b1316b", "operator": null, "metadata": {"aucs": [0.24421423715044988, 0.9486953848878806, 0.921083449633754, 0.9675364519849522, 0.9320120013395637, 0.9421854824861777, 0.32067274904983223, 0.9202647825938611, 0.9416105297268922, 0.9331162645488741]}, "task_prompt": ""}
{"id": "e028da2e-4c76-480b-b2b8-796d1be3ea73", "fitness": 0.7872045368559208, "name": "MESA", "description": "MESA combines antithetic (mirrored) sampling for low-variance candidate generation with log‑biased rank‑mu recombination and a rank‑one evolution path to capture directional momentum, producing a blended covariance update (c_cov and cov_memory control rank‑one vs rank‑mu and temporal smoothing). Covariance is regularized with a Ledoit‑style shrinkage toward a diagonal prior derived from the problem bounds (shrink_alpha and prior_var = (bounds/6)^2), and robust SPD handling (eigen clipping/jitter) keeps C well‑conditioned. Step‑size (sigma) is adapted by a smoothed success rate with tanh scaling and dimension‑aware damping (p_succ_alpha, eta_sigma) and the population size is chosen heuristically from dim/log/sqrt, with candidates clamped to bounds. Stagnation triggers alternating diversify/intensify restarts (inflating or shrinking sigma, resetting C, occasional micro‑local refinement around the best) to balance global exploration and local exploitation.", "code": "import numpy as np\n\nclass MESA:\n    \"\"\"\n    Mirror-Ensemble Shrinkage Adaptation (MESA)\n\n    Key features:\n      - Antithetic (mirrored) sampling for low-variance candidate generation.\n      - Rank-mu weighted covariance + rank-one evolution path (p_c).\n      - Ledoit-style shrinkage toward a diagonal prior based on bounds.\n      - Robust SPD handling (eigen clipping / jitter).\n      - Smoothed success-rate sigma adaptation with tanh scaling, dimension-aware.\n      - Adaptive population size, and alternating diversify/intensify restarts with occasional micro-local refinement.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 c_cov=0.14,\n                 cov_memory=0.72,\n                 shrink_alpha=0.32,\n                 sigma_init_frac=0.2,\n                 eta_sigma=0.38,\n                 success_target=0.2,\n                 p_succ_alpha=0.18,\n                 path_decay=0.88,\n                 stagnation_frac=0.06,\n                 random_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.c_cov = float(c_cov)\n        self.cov_memory = float(cov_memory)\n        self.shrink_alpha = float(shrink_alpha)\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.eta_sigma = float(eta_sigma)\n        self.success_target = float(success_target)\n        self.p_succ_alpha = float(p_succ_alpha)\n        self.path_decay = float(path_decay)\n        self.stagnation_frac = float(stagnation_frac)\n        self.random_seed = random_seed\n\n        # thresholds derived\n        self.stagnation_threshold = max(6, int(self.stagnation_frac * max(1, self.budget)))\n        # ensure some sensible bounds for internals\n        self.min_eig = 1e-12\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.random_seed)\n\n        # bounds handling\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = np.maximum(ub - lb, 1e-12)\n        prior_var = (bounds_scale / 6.0) ** 2  # diagonal shrinkage target\n\n        # adaptive population heuristic: mix log and sqrt growth\n        if self.pop_base is None:\n            lam = max(8, int(6 + 3 * np.log1p(self.dim) + 1.5 * np.sqrt(max(1, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n        self.lambda_ = lam\n\n        # bootstrap: initial uniform sampling to form initial mean and best\n        evals = 0\n        init_batch = min(self.lambda_, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initial mean: weighted top-half with log-like bias\n        mu = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu]]\n        ranks0 = np.arange(1, mu + 1)\n        weights0 = np.log(mu + 0.5) - np.log(ranks0 + 0.1)\n        weights0 = np.maximum(weights0, 0.0)\n        if np.sum(weights0) <= 0:\n            weights0 = np.ones_like(weights0)\n        weights0 = weights0 / np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance and sigma\n        C = np.diag(prior_var.copy())\n        sigma = max(1e-12, self.sigma_init_frac * np.mean(bounds_scale))\n\n        # internal state\n        p_c = np.zeros(self.dim, dtype=float)\n        p_succ = float(self.success_target)\n        stagn_count = 0\n        iter_count = 0\n        restart_mode = 0  # 0 -> diversify next, 1 -> intensify next\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam = min(self.lambda_, remaining)\n            mu = max(1, lam // 2)\n\n            # recompute rank-mu weights (log-biased)\n            ranks = np.arange(1, mu + 1)\n            weights = np.log(mu + 0.5) - np.log(ranks + 0.2)\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n\n            # ensure SPD: eigen-decompose and clip\n            try:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, self.min_eig, None)\n                sqrt_vals = np.sqrt(vals)\n                B = (vecs * sqrt_vals.reshape(1, -1))  # so that B @ B.T = C\n            except Exception:\n                # fallback\n                B = np.diag(np.sqrt(np.maximum(np.diag(C), self.min_eig)))\n\n            # Antithetic sampling: generate lam candidates using mirrored pairs\n            Xcand = []\n            pairs = lam // 2\n            if pairs > 0:\n                Z = rng.normal(size=(pairs, self.dim))\n                Y = Z @ B\n                X_plus = m + sigma * Y\n                X_minus = m - sigma * Y\n                Xcand.extend(X_plus.tolist())\n                Xcand.extend(X_minus.tolist())\n            if lam % 2 == 1:\n                z = rng.normal(size=(self.dim,))\n                y = z @ B\n                Xcand.append((m + sigma * y).tolist())\n\n            Xcand = np.asarray(Xcand, dtype=float)[:lam]\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates\n            fc = np.empty(lam, dtype=float)\n            for i in range(lam):\n                fc[i] = float(func(Xcand[i]))\n            evals += lam\n\n            # generation best and update global best\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # recombine to get new mean\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized steps (sigma-units) relative to current mean m\n            deltas = (X_mu - m) / (sigma + 1e-20)  # shape (mu, dim)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas  # (dim, dim)\n\n            # evolution path update (directional momentum)\n            y_w = (m_new - m) / (sigma + 1e-20)\n            p_c = self.path_decay * p_c + (1.0 - self.path_decay) * y_w\n            rank_one = np.outer(p_c, p_c)\n\n            # combine rank-mu and rank-one, with cov_memory blending\n            new_info = (1.0 - self.c_cov) * weighted_cov + self.c_cov * rank_one\n            C_new = (1.0 - self.cov_memory) * C + self.cov_memory * new_info\n\n            # Ledoit-style shrinkage toward diagonal prior\n            shrink_target = np.diag(prior_var)\n            C = (1.0 - self.shrink_alpha) * C_new + self.shrink_alpha * shrink_target\n\n            # symmetrize and eigen-clipping jitter\n            C = 0.5 * (C + C.T)\n            vals, vecs = np.linalg.eigh(C)\n            min_allowed = self.min_eig\n            if np.min(vals) < min_allowed:\n                vals = np.clip(vals, min_allowed, None)\n                C = (vecs * np.sqrt(vals).reshape(1, -1)) @ (vecs * np.sqrt(vals).reshape(1, -1)).T\n\n            # accept new mean\n            m = m_new\n\n            # success smoothing and sigma adaptation (dimension-aware)\n            p_succ = (1.0 - self.p_succ_alpha) * p_succ + self.p_succ_alpha * float(improved)\n            # map success diff through tanh for robustness, scale down by sqrt(dim)\n            delta_s = p_succ - self.success_target\n            dim_scale = 1.0 + 0.5 * np.sqrt(max(1, self.dim))\n            scale = np.exp(self.eta_sigma * np.tanh(3.0 * delta_s) / dim_scale)\n            sigma *= float(scale)\n            # clamp sigma\n            sigma = float(np.clip(sigma, 1e-12, 3.0 * np.max(bounds_scale)))\n\n            # stagnation handling: alternate diversify / intensify behavior\n            if stagn_count * max(1, lam) >= self.stagnation_threshold and evals < self.budget:\n                stagn_count = 0\n                if restart_mode == 0:\n                    # Diversify: inflate sigma, jitter around best moderately, slightly increase lambda\n                    sigma = max(sigma, 0.6 * np.mean(bounds_scale))\n                    jitter = 0.6 * sigma * (0.5 + 0.5 * rng.rand(self.dim))\n                    m = x_best + rng.randn(self.dim) * jitter\n                    m = np.minimum(np.maximum(m, lb), ub)\n                    # reset covariance to isotropic moderate spread\n                    C = np.diag(((bounds_scale / 5.0) ** 2).clip(min=self.min_eig))\n                    # increase population slightly to boost exploration\n                    self.lambda_ = min(self.lambda_ + 2, max(2, self.budget))\n                else:\n                    # Intensify: shrink sigma, reset covariance to a local diagonal, do a short micro-local search around x_best\n                    sigma *= (0.12 + 0.38 * rng.rand())  # shrink strongly\n                    jitter_scale = 0.05 * bounds_scale * (0.5 + rng.rand(self.dim))\n                    m = x_best + rng.randn(self.dim) * jitter_scale\n                    m = np.minimum(np.maximum(m, lb), ub)\n                    C = np.diag(((bounds_scale / 10.0) ** 2).clip(min=self.min_eig))\n                    # micro-local refinement: use a few cheap trials around current best\n                    rem = self.budget - evals\n                    local_n = min(rem, max(2, int(max(4, 0.008 * self.budget))))\n                    if local_n > 0:\n                        Zloc = rng.normal(size=(local_n, self.dim))\n                        Yloc = Zloc @ (np.linalg.cholesky(C + np.eye(self.dim) * 1e-14).T)\n                        Xloc = x_best + (0.6 * sigma) * Yloc\n                        Xloc = np.minimum(np.maximum(Xloc, lb), ub)\n                        for i in range(local_n):\n                            fval = float(func(Xloc[i]))\n                            evals += 1\n                            if fval < f_best:\n                                f_best = fval\n                                x_best = Xloc[i].copy()\n                                # slightly nudge m toward new best\n                                m = 0.6 * m + 0.4 * x_best\n                                stagn_count = 0\n                                p_succ = min(1.0, p_succ + 0.05)\n                                # update C minorly using this successful step\n                                step = (x_best - m) / (sigma + 1e-20)\n                                C = 0.95 * C + 0.05 * np.outer(step, step)\n                                # if budget exhausted break\n                                if evals >= self.budget:\n                                    break\n                # flip restart mode\n                restart_mode = 1 - restart_mode\n                # continue main loop\n                continue\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MESA scored 0.787 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b9f441db-49d8-4b32-a128-01ee67b1316b", "operator": null, "metadata": {"aucs": [0.3005322137410882, 0.9316694167058069, 0.868206741031215, 0.9475252167926258, 0.8944338699587302, 0.9081985231116327, 0.3401139887175644, 0.8832551237666987, 0.8981458016948296, 0.8999644730390164]}, "task_prompt": ""}
{"id": "81deb2e2-83d6-4daf-a25f-fcb6c770e80d", "fitness": 0.40798152939579435, "name": "HybridEnsembleDirectional", "description": "The design is a compact CMA-style ensemble that maintains and samples around a learned mean with a small, log-scaled population and a weighted rank-mu recombination (initial mean from top-half elites, log-weights) to drive the search. Covariance is updated by blending long-memory past covariance (cov_memory=0.72, relatively large) with a modest rank-one/path term (c_cov=0.14, path_decay=0.92) and a moderate initial isotropic sigma (sigma = 0.18 * avg_span) that is adapted by a smoothed success rate (alpha=0.15, sigma_adapt_rate=0.24) targeting p_succ≈0.2. To boost robustness and exploration it adds mirrored directional probes (p_probe=0.12) to obtain gradient-like corrections, occasional heavy-tailed Cauchy injections (p_heavy=0.06) for long jumps, and opportunistic restarts/jitter when stagnation accumulates (~stagnation_frac=0.06 of budget). Practical safeguards include strict budget accounting, box clamping, Cholesky decomposition with eigen‑fallback for SPD enforcement, small numerical jitter on diagonals, and final opportunistic mean evaluation.", "code": "import numpy as np\n\nclass HybridEnsembleDirectional:\n    \"\"\"\n    HybridEnsembleDirectional:\n      - Compact mean-based ensemble sampling like CMA-style but with AEDS-style\n        covariance memory blending and an evolution path (rank-one) term.\n      - Smoothed success-rate (1/5-like) multiplicative sigma adaptation.\n      - Occasional mirrored directional probes (x +/- delta*v) to provide gradient-like nudges.\n      - Heavy-tailed injections and opportunistic restarts on stagnation.\n      - Robust numerical safeguards (Cholesky + eigen fallback), strict budget accounting,\n        and box clamping.\n    One-line idea: Ensemble sampling around a learned mean with blended rank-mu + path covariance,\n      success-smoothed sigma control and directional probes to drive robust, budget-aware search.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, pop_base=None, random_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        # covariance / path / sigma tuning\n        self.c_cov = 0.14          # learning rate for rank-mu vs path blend\n        self.cov_memory = 0.72     # memory for previous covariance\n        self.path_decay = 0.92     # evolution path decay\n        self.sigma_adapt_rate = 0.24\n        self.success_target = 0.20\n        self.p_probe = 0.12        # probability each iter to perform mirrored probes\n        self.p_heavy = 0.06        # chance for heavy-tailed injection\n        self.stagnation_frac = 0.06\n        self.random_seed = random_seed\n\n        # derived\n        self.stagnation_threshold = max(5, int(self.stagnation_frac * max(1, self.budget)))\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.random_seed)\n\n        # bounds (support scalar or vector)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        # population size small to allow many iterations\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # initialize via a small uniform batch to set mean and best\n        evals = 0\n        init_batch = min(lam, max(4, int(2 * lam)))\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.empty(init_batch, dtype=float)\n        for i in range(init_batch):\n            if evals >= self.budget:\n                break\n            f0[i] = float(func(X0[i])); evals += 1\n        if evals == 0:\n            # ensure at least one evaluation\n            x0 = rng.uniform(lb, ub)\n            f0 = np.array([float(func(x0))])\n            X0 = np.array([x0])\n            evals = 1\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # weighted initial mean from top-half like DACS\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w = np.maximum(w, 0.0)\n        w = w / np.sum(w)\n        m = (w.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance diagonal moderate\n        C = np.diag(((span / 6.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-12, 0.18 * avg_span)  # modest initial step\n\n        # strategy state\n        p_succ = 0.2\n        alpha = 0.15  # smoothing for success (like AEDS)\n        p_c = np.zeros(self.dim, dtype=float)  # evolution path\n        stagn_count = 0\n        iter_count = 0\n\n        # safeguard small diag\n        min_diag = 1e-12\n\n        # helper: ensure SPD decomposition\n        def chol_or_eig(mat):\n            # returns A such that A^T A = mat\n            eps = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, min_diag, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        # small heavy-tailed scalar bounded\n        def heavy_scalar():\n            s = rng.standard_cauchy()\n            return float(np.clip(s, -50.0, 50.0))\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu = max(1, lam_iter // 2)\n\n            # recompute weights\n            ranks = np.arange(1, mu + 1)\n            weights = np.log(mu + 0.5) - np.log(ranks + 0.2)\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n\n            # ensure SPD\n            A = chol_or_eig(C)\n\n            # sample lam_iter candidates N(m, sigma^2 C)\n            Z = rng.normal(size=(lam_iter, self.dim))\n            Y = Z @ (A.T)    # N(0,C)\n            Xcand = m + sigma * Y\n            # clamp\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates\n            fc = np.empty(lam_iter, dtype=float)\n            for i in range(lam_iter):\n                if evals >= self.budget:\n                    fc[i:] = np.inf\n                    break\n                fc[i] = float(func(Xcand[i])); evals += 1\n\n            # update generation and global best\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # recombine top-mu into new mean\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # normalized steps\n            deltas = (X_mu - m) / (sigma + 1e-20)  # (mu, dim)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas  # rank-mu estimate\n\n            # update evolution path from weighted mean step\n            y_w = (m_new - m) / (sigma + 1e-20)\n            p_c = self.path_decay * p_c + (1.0 - self.path_decay) * y_w\n            rank_one = np.outer(p_c, p_c)\n\n            # blend covariance: keep memory of previous C, add rank-mu and small rank-one\n            C_new = (self.cov_memory * C +\n                     (1.0 - self.cov_memory) * ((1.0 - self.c_cov) * weighted_cov + self.c_cov * rank_one))\n            # symmetrize and safeguard\n            C = 0.5 * (C_new + C_new.T)\n            diagC = np.diag(C)\n            jitter = 1e-12 * np.maximum(diagC, 1.0)\n            C += np.diag(jitter)\n\n            # accept new mean\n            m = m_new\n\n            # mirrored directional probes occasionally to get gradient-like nudge\n            if (rng.rand() < self.p_probe) and (self.budget - evals) >= 2:\n                # pick 1-2 probe directions from top differences\n                kdir = 1 if self.dim < 20 else min(2, max(1, self.dim // 20))\n                grad_est = np.zeros(self.dim, dtype=float)\n                used = 0\n                for kd in range(kdir):\n                    # pick random direction from recent elite step or gaussian\n                    if mu >= 2 and rng.rand() < 0.7:\n                        v = X_mu[min(kd + 1, X_mu.shape[0]-1)] - X_mu[0]\n                    else:\n                        v = rng.randn(self.dim)\n                    nrm = np.linalg.norm(v)\n                    if nrm < 1e-12:\n                        continue\n                    v = v / nrm\n                    delta = sigma * (0.8 + 0.6 * rng.rand())\n                    xp = np.minimum(np.maximum(m + delta * v, lb), ub)\n                    xn = np.minimum(np.maximum(m - delta * v, lb), ub)\n                    if evals + 2 > self.budget:\n                        break\n                    fp = float(func(xp)); evals += 1\n                    fn = float(func(xn)); evals += 1\n                    ddir = (fp - fn) / (2.0 * delta)\n                    grad_est += ddir * v\n                    used += 1\n                if used > 0:\n                    # propose a small correction to mean opposite to gradient\n                    gnorm = np.linalg.norm(grad_est)\n                    if gnorm > 1e-12:\n                        step = -0.9 * sigma * grad_est / gnorm\n                        m_try = np.minimum(np.maximum(m + step, lb), ub)\n                        if evals < self.budget:\n                            f_try = float(func(m_try)); evals += 1\n                            if f_try < f_best:\n                                f_best = f_try\n                                x_best = m_try.copy()\n                                improved = True\n                                stagn_count = 0\n                            # accept mean if better than current mean surrogate (use gen_best as proxy)\n                            if f_try < gen_best_f:\n                                m = m_try\n\n            # occasional heavy-tailed injection to diversify\n            if rng.rand() < self.p_heavy and evals < self.budget:\n                c = heavy_scalar()\n                jump = c * 0.08 * span * rng.randn(self.dim)\n                inj = np.minimum(np.maximum(x_best + jump, lb), ub)\n                f_inj = float(func(inj)); evals += 1\n                if f_inj < f_best:\n                    f_best = f_inj\n                    x_best = inj.copy()\n                    improved = True\n                    stagn_count = 0\n                # incorporate injection into covariance via a tiny rank update\n                diff = (inj - m) / (sigma + 1e-20)\n                C += 0.005 * np.outer(diff, diff)\n\n            # success smoothing and sigma adaptation (1/5-like)\n            p_succ = (1.0 - alpha) * p_succ + alpha * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            # clamp sigma\n            sigma = float(np.clip(sigma, 1e-12, 2.0 * np.max(span)))\n\n            # opportunistic restart on stagnation (inflate sigma and jitter mean)\n            if stagn_count * lam_iter >= self.stagnation_threshold and evals < self.budget:\n                stagn_count = 0\n                # 40% chance conservative shrink (exploit), else inflate (explore)\n                if rng.rand() < 0.4:\n                    sigma *= (0.35 + 0.35 * rng.rand())  # shrink\n                else:\n                    sigma *= (1.5 + 1.5 * rng.rand())   # inflate\n                # re-center near best with small jitter\n                jitter = 0.06 * span * (0.5 + rng.rand(self.dim))\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset covariance to moderate isotropic\n                C = np.diag(((span / 8.0) ** 2).clip(min=1e-12))\n                # small nudge to path\n                p_c *= 0.5\n                continue\n\n            # If budget nearly exhausted, consider evaluating current mean candidate\n            if evals < self.budget:\n                # opportunistically evaluate mean sample to possibly improve best\n                m_sample = np.minimum(np.maximum(m, lb), ub)\n                fm = float(func(m_sample)); evals += 1\n                if fm < f_best:\n                    f_best = fm\n                    x_best = m_sample.copy()\n                    improved = True\n                    stagn_count = 0\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridEnsembleDirectional scored 0.408 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b9f441db-49d8-4b32-a128-01ee67b1316b", "operator": null, "metadata": {"aucs": [0.17129984781528396, 0.17853939010962017, 0.5047368600178274, 0.9023242709662516, 0.47081584034553503, 0.5528471627863181, 0.2609517279861726, 0.41964346999717594, 0.4445859794356868, 0.17407074449807192]}, "task_prompt": ""}
{"id": "7a4a8e7a-619c-406e-b6dc-04ff93ea359e", "fitness": 0.32085820439701923, "name": "AnnealedSubspaceCoop", "description": "Annealed Subspace Cooperative Search runs a small cooperative population (pop ~ 6+1.8*sqrt(dim) but capped by budget) with per-agent trust radii (scaled to domain mean) and per-agent momentum, using a reflect-with-damping boundary handler and strict budget accounting. It learns a low-dimensional adaptive subspace online via Oja updates (k=1–2 principal vectors) and uses that subspace to project estimated gradients and to produce anisotropic jitter/restarts. Multiple complementary operators are mixed: isotropic Student-t heavy-tailed global jumps (df=5) for exploration, momentum-guided local perturbations for exploitation, and surrogate quasi-Newton-like steps computed from a ridge-regression gradient estimate built from an archive; trust radii are annealed/expanded on success and contracted on failure. An archive (capped) supports the surrogate and targeted reinitialization when stagnation is detected, while periodic focused quasi-Newton attempts from the current best refine solutions.", "code": "import numpy as np\n\nclass AnnealedSubspaceCoop:\n    \"\"\"\n    Annealed Subspace Cooperative Search (novel heuristic)\n\n    Key ideas:\n    - Small cooperative population with per-agent trust radii and momentum.\n    - Online Oja-rule to maintain 1-2 principal directions (adaptive subspace).\n    - Global heavy-tailed Student-t jumps, tempered by per-agent trust radii.\n    - Low-cost local quasi-Newton-like step computed by linear ridge regression of the archive\n      (estimates gradient) and applied projected into the learned subspace.\n    - Trust-region annealing: successful moves expand radius, failures shrink it.\n    - Archive-based restarts / targeted reinitialization when stagnation detected.\n    - Strict budget accounting (func calls) and reflect-with-damping boundary handling.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop=None,\n                 sigma0=0.25,         # initial relative step scale (fraction of domain)\n                 elite_frac=0.25,\n                 student_df=5,        # degrees of freedom for Student-t heavy tails\n                 oja_lr=0.08,         # Oja learning rate for online principal vector\n                 trust_init=0.5,      # initial trust radius as fraction of domain\n                 trust_inc=1.25,      # multiply on success\n                 trust_dec=0.7,       # multiply on failure\n                 min_trust=1e-3,\n                 max_trust=2.0,\n                 ridge_lambda=1e-6,\n                 stagn_limit=40,\n                 max_archive=800):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop = pop\n        self.sigma0 = float(sigma0)\n        self.elite_frac = float(elite_frac)\n        self.student_df = float(student_df)\n        self.oja_lr = float(oja_lr)\n        self.trust_init = float(trust_init)\n        self.trust_inc = float(trust_inc)\n        self.trust_dec = float(trust_dec)\n        self.min_trust = float(min_trust)\n        self.max_trust = float(max_trust)\n        self.ridge_lambda = float(ridge_lambda)\n        self.stagn_limit = int(stagn_limit)\n        self.max_archive = int(max_archive)\n\n    def __call__(self, func):\n        rng = np.random.RandomState()  # isolated RNG\n\n        # try to read bounds, otherwise default [-5,5]^d\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        domain_scale = ub - lb\n        domain_mean_scale = float(np.mean(domain_scale))\n\n        # population size heuristic different from original: scale with sqrt(dim) but cap by budget\n        if self.pop is None:\n            pop = int(max(6, min(6 + int(1.8 * np.sqrt(self.dim)), max(6, self.budget // 30))))\n        else:\n            pop = int(self.pop)\n        pop = max(2, min(pop, self.budget))\n\n        # reflect-with-damping boundary handler (reflect but shrink overshoot)\n        def reflect_damp(x):\n            x = np.asarray(x, dtype=float).copy()\n            low = lb\n            high = ub\n            # for coordinates out of bounds, reflect and damp half the overshoot\n            below = x < low\n            if np.any(below):\n                x[below] = low[below] + 0.5 * (low[below] - x[below])\n            above = x > high\n            if np.any(above):\n                x[above] = high[above] - 0.5 * (x[above] - high[above])\n            # final clamp to ensure feasibility\n            np.minimum(np.maximum(x, low), high, out=x)\n            return x\n\n        # Student-t sampler (multivariate isotropic)\n        def student_t_vector(df, scale):\n            # vector drawn from isotropic Student-t with df degrees of freedom and overall scale\n            z = rng.randn(self.dim)\n            # for vector scaling, draw chi2 scalar\n            chi2 = rng.chisquare(df)\n            factor = np.sqrt(df / max(1e-12, chi2))\n            return z * factor * scale\n\n        # initialize population with stratified jitter (but different pattern to prior)\n        # create a coarse grid then jitter: tries to spread points but with block structure\n        X = np.zeros((pop, self.dim), dtype=float)\n        blocks = max(1, int(np.ceil(pop ** (1.0 / max(1, self.dim)))))\n        for i in range(pop):\n            for d in range(self.dim):\n                frac = ((i + 0.5) / float(pop))\n                X[i, d] = lb[d] + frac * (ub[d] - lb[d])\n        # jitter proportional to domain and sigma0\n        X += (rng.rand(pop, self.dim) - 0.5) * 2.0 * self.sigma0 * domain_scale\n        # clamp\n        for i in range(pop):\n            X[i] = reflect_damp(X[i])\n\n        # state arrays\n        f = np.full(pop, np.inf, dtype=float)\n        evals = 0\n\n        # evaluate initial population sequentially\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        # if no budget left, return best found\n        if evals >= self.budget:\n            bi = int(np.argmin(f))\n            self.f_opt = float(f[bi]); self.x_opt = X[bi].copy()\n            return self.f_opt, self.x_opt\n\n        # per-agent trust radius (as fraction of domain mean scale)\n        trust = np.full(pop, self.trust_init * domain_mean_scale, dtype=float)\n\n        # per-agent momentum (simple exponential smoothing of steps)\n        momentum = np.zeros((pop, self.dim), dtype=float)\n        mom_beta = 0.6\n\n        # archive for surrogate construction\n        archive_X = X.copy()\n        archive_f = f.copy()\n\n        # Oja principal vector(s) initialization (we keep two orthonormal vectors)\n        k_oja = min(2, self.dim)\n        oja_V = np.zeros((k_oja, self.dim), dtype=float)\n        # initialize random orthonormal basis\n        if self.dim > 0:\n            A = rng.randn(self.dim, k_oja)\n            Q, _ = np.linalg.qr(A)\n            oja_V[:, :] = Q.T[:k_oja, :]\n\n        # tracking\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n        gens_without_improve = 0\n        gen = 0\n\n        # helper to add to archive with cap (keep best)\n        def add_archive(x_new, f_new):\n            nonlocal archive_X, archive_f\n            archive_X = np.vstack([archive_X, x_new[np.newaxis, :]])\n            archive_f = np.concatenate([archive_f, np.array([f_new], dtype=float)])\n            if archive_X.shape[0] > self.max_archive:\n                order = np.argsort(archive_f)\n                keep = order[:self.max_archive]\n                archive_X = archive_X[keep]\n                archive_f = archive_f[keep]\n\n        # helper: build linear surrogate gradient estimate around weighted mean of top archive points\n        def estimate_linear_gradient(max_points= min(50, max(10, self.dim * 3))):\n            # uses ridge regression: f ≈ f0 + g^T (x - m)\n            if archive_X.shape[0] < 3:\n                return None, None  # not enough data\n            # choose up to max_points best archive samples\n            order = np.argsort(archive_f)\n            K = min(len(order), max_points)\n            Xs = archive_X[order[:K]]\n            fs = archive_f[order[:K]]\n            m = Xs.mean(axis=0)\n            Z = Xs - m  # K x d\n            y = fs - fs.mean()  # center values\n            # solve (Z^T Z + lambda I) g = Z^T y\n            ZZ = np.dot(Z.T, Z)\n            lhs = ZZ + self.ridge_lambda * np.eye(self.dim)\n            rhs = np.dot(Z.T, y)\n            try:\n                g = np.linalg.solve(lhs, rhs)\n                return g, m\n            except np.linalg.LinAlgError:\n                return None, m\n\n        # main loop: each generation we attempt updates for each agent\n        while evals < self.budget:\n            gen += 1\n            improved = False\n\n            # ranking and elites\n            order = np.argsort(f)\n            elite_count = max(2, int(np.ceil(self.elite_frac * pop)))\n            elite_idx = order[:elite_count]\n\n            # estimate gradient once per generation (cheap-ish)\n            g_est, g_center = estimate_linear_gradient()  # may be None\n\n            # for each agent, decide one of several operators\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                x = X[ii].copy()\n                fx = float(f[ii])\n\n                # choose operator probabilities adaptively: prefer local steps for small trust\n                # compute normalized trust in [0,1]\n                norm_tr = (trust[ii] / (domain_mean_scale + 1e-12))\n                p_local = float(np.clip(0.3 * (1.0 - norm_tr) + 0.2, 0.05, 0.7))\n                p_newton = float(np.clip(0.25 * (1.0 - norm_tr), 0.0, 0.5))\n                r = rng.rand()\n\n                candidate = None\n\n                # 1) Student-t heavy-tailed global exploration scaled by trust radius (long jumps)\n                if r < 0.35:\n                    # scale = trust[ii] but allow occasional center-on-best\n                    center = x if rng.rand() < 0.8 else x_best\n                    # draw isotropic student-t vector\n                    step = student_t_vector(self.student_df, scale=trust[ii])\n                    cand = reflect_damp(center + step)\n                    candidate = cand\n\n                # 2) Momentum-guided local perturbation (PSO-inspired)\n                elif r < 0.35 + 0.25:\n                    # sample gaussian perturbation proportional to trust and sigma0\n                    noise_scale = trust[ii] * (0.8 + 0.4 * rng.rand())\n                    step = rng.randn(self.dim) * (noise_scale / (domain_mean_scale + 1e-12)) * domain_scale\n                    # update momentum and propose\n                    momentum[ii] = mom_beta * momentum[ii] + (1.0 - mom_beta) * step\n                    cand = reflect_damp(x + momentum[ii])\n                    candidate = cand\n\n                # 3) Surrogate projected quasi-Newton-like step (only if gradient estimate available)\n                else:\n                    if g_est is not None:\n                        # project gradient into Oja subspace spanned by oja_V\n                        if k_oja >= 1:\n                            # compute projection matrix P\n                            P = np.dot(oja_V.T, oja_V)  # k x d times d x k -> k x k? careful: oja_V is k x d\n                            # Actually oja_V is k x d, so project g onto rows:\n                            # obtain basis vectors b_j = oja_V[j]\n                            basis = oja_V.copy()  # k x d\n                            # coefficients c_j = g dot b_j\n                            c = np.dot(basis, g_est)  # k\n                            g_proj = np.dot(c, basis)  # sum_j c_j * basis_j -> shape d\n                        else:\n                            g_proj = g_est.copy()\n                        # propose step length using curvature heuristic: step = -H_inv * g_proj\n                        # approximate diagonal Hessian from local curvature: use small finite differences from archive\n                        # use simple damping: step = -alpha * g_proj, alpha proportional to trust\n                        alpha = 0.6 * (trust[ii] / (domain_mean_scale + 1e-12))\n                        cand = reflect_damp(x - alpha * (g_proj / (np.linalg.norm(g_proj) + 1e-12)) * domain_mean_scale)\n                        candidate = cand\n                    else:\n                        # fallback small gaussian\n                        candidate = reflect_damp(x + rng.randn(self.dim) * (0.12 * domain_scale))\n\n                # evaluate candidate if available\n                if candidate is None:\n                    candidate = x.copy()\n                if evals >= self.budget:\n                    break\n                f_c = float(func(candidate)); evals += 1\n\n                # selection: accept if better\n                if f_c < fx:\n                    # success: update position, archive, trust expansion, update Oja using improvement vector\n                    X[ii] = candidate\n                    f[ii] = f_c\n                    add_archive(candidate, f_c)\n                    # expand trust for this agent\n                    trust[ii] = float(min(self.max_trust * domain_mean_scale, trust[ii] * self.trust_inc))\n                    # update momentum slightly towards accepted step\n                    momentum[ii] = 0.8 * momentum[ii] + 0.2 * (candidate - x)\n                    # update Oja vectors with the improvement direction (centered)\n                    delta = (candidate - x_best)\n                    if np.linalg.norm(delta) > 1e-12:\n                        for j in range(k_oja):\n                            v = oja_V[j]\n                            # Oja update: v <- v + lr * ((delta * (v^T delta)) - (v * (v^T v)))\n                            # simplified stable Oja for unit vectors:\n                            proj = np.dot(v, delta)\n                            v_new = v + self.oja_lr * (delta * proj - (proj ** 2) * v)\n                            # renormalize\n                            nrm = np.linalg.norm(v_new) + 1e-12\n                            oja_V[j] = v_new / nrm\n                        # re-orthogonalize small basis\n                        if k_oja > 1:\n                            Q, _ = np.linalg.qr(oja_V.T)\n                            oja_V = Q.T[:k_oja, :]\n                    # update best\n                    if f_c < f_best:\n                        f_best = f_c\n                        x_best = candidate.copy()\n                        gens_without_improve = 0\n                        improved = True\n                else:\n                    # failure: reduce trust for this agent, small momentum decay\n                    trust[ii] = float(max(self.min_trust * domain_mean_scale, trust[ii] * self.trust_dec))\n                    momentum[ii] *= 0.8\n                    # still record candidate in archive occasionally if not too bad (diversify)\n                    if f_c < np.median(archive_f):\n                        add_archive(candidate, f_c)\n\n            # end per-agent loop\n\n            if not improved:\n                gens_without_improve += 1\n            else:\n                gens_without_improve = 0\n\n            # Periodic focused local exploitation: attempt 1-3 cheap quasi-Newton steps from best\n            if (gen % 10 == 0) or (gens_without_improve >= self.stagn_limit // 2):\n                if evals >= self.budget:\n                    break\n                # rebuild gradient estimate\n                g_est, g_center = estimate_linear_gradient(max_points= min(40, max(10, self.dim*2)))\n                if g_est is not None:\n                    # project into top Oja vector to reduce noise\n                    if k_oja >= 1:\n                        basis = oja_V.copy()\n                        c = np.dot(basis, g_est)\n                        g_proj = np.dot(c, basis)\n                    else:\n                        g_proj = g_est.copy()\n                    # propose sequence of decreasing step lengths\n                    alphas = [1.0, 0.5, 0.2]\n                    improved_local = False\n                    for a in alphas:\n                        if evals >= self.budget:\n                            break\n                        alpha = a * 0.9 * (np.median(trust) / (domain_mean_scale + 1e-12))\n                        x_try = reflect_damp(x_best - alpha * (g_proj / (np.linalg.norm(g_proj) + 1e-12)) * domain_mean_scale)\n                        f_try = float(func(x_try)); evals += 1\n                        if f_try < f_best:\n                            f_best = f_try\n                            x_best = x_try.copy()\n                            add_archive(x_try, f_try)\n                            # inject into worst agent\n                            worst = int(np.argmax(f))\n                            X[worst] = x_try.copy()\n                            f[worst] = f_try\n                            trust[worst] = max(trust[worst], 0.5 * np.median(trust))\n                            improved_local = True\n                            break\n                    if improved_local:\n                        gens_without_improve = 0\n\n            # strong stagnation handling: targeted reinitialization of worst agents around best in Oja subspace\n            if gens_without_improve >= self.stagn_limit:\n                # reinitialize 1/3 worst agents around best using anisotropic jitter along Oja vectors\n                n_reinit = max(1, pop // 3)\n                worst_order = np.argsort(f)[-n_reinit:]\n                for idx in worst_order:\n                    if evals >= self.budget:\n                        break\n                    # build anisotropic jitter: larger along principal components\n                    if k_oja >= 1:\n                        coeffs = rng.randn(k_oja) * (0.4 * domain_mean_scale)\n                        jitter = np.zeros(self.dim)\n                        for j in range(k_oja):\n                            jitter += coeffs[j] * oja_V[j]\n                        # add small isotropic noise\n                        jitter += rng.randn(self.dim) * (0.08 * domain_mean_scale)\n                    else:\n                        jitter = rng.randn(self.dim) * (0.2 * domain_mean_scale)\n                    x_new = reflect_damp(x_best + jitter)\n                    f_new = float(func(x_new)); evals += 1\n                    X[idx] = x_new\n                    f[idx] = f_new\n                    trust[idx] = self.trust_init * domain_mean_scale\n                    add_archive(x_new, f_new)\n                    if f_new < f_best:\n                        f_best = f_new\n                        x_best = x_new.copy()\n                        gens_without_improve = 0\n\n            # sync best from population if any agent improved unnoticed\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_without_improve = 0\n\n            # global maintenance: cap archive size and occasionally shrink trust radii (anneal)\n            if archive_X.shape[0] > self.max_archive:\n                order_arch = np.argsort(archive_f)\n                keep = order_arch[:self.max_archive]\n                archive_X = archive_X[keep]\n                archive_f = archive_f[keep]\n            # mild annealing: slowly reduce median trust to favor exploitation over time\n            if gen % 20 == 0:\n                median_trust = np.median(trust)\n                trust *= 0.995  # slow decay\n\n            # early exit if budget exhausted\n            if evals >= self.budget:\n                break\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AnnealedSubspaceCoop scored 0.321 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "93890e17-e490-4bd2-83de-00a7a8d5b2b0", "operator": null, "metadata": {"aucs": [0.1118791276778256, 0.18266535472123102, 0.5444623803359917, 0.6553296478148442, 0.22720967260077884, 0.6108000726105504, 0.2419592640044238, 0.24532975145000924, 0.22697798924973978, 0.16196878350479793]}, "task_prompt": ""}
{"id": "21010622-cabd-4125-8f1d-e3db3b4b4d6c", "fitness": 0.31002650843076457, "name": "AdaptiveStudentTGuidedEvolution", "description": "The design mixes multi-scale exploration and exploitation: a small population (scaled with log(dim)) is initialized by scrambled Latin-hypercube sampling with anisotropic jitter and uses toroidal wrapping to handle box bounds. Candidate generation is an operator blend (student-t heavy tails around current/elite, an adaptive DE-style current-to-pbest with Cauchy-like F, and covariance-guided sampling around weighted elites) so the search combines rare long jumps, differential recombination, and correlated local sampling. Adaptation is per-individual via sigma multiplied on success/failure (tau_success/tau_failure), an elite/archive for selection and sample-covariance estimation, and an EWMA covariance update (cov_memory) to bias sampling; lightweight coordinate local search (local_period, local_probes) and targeted diversification on long stagnation provide exploitation/refinement and recovery. The implementation is budget-aware (never exceeds self.budget), uses mild regularization for numerical stability, and exposes tunable probabilities (p_student,p_de,p_cov), student_df, sigma0 and other knobs to balance exploration vs. exploitation.", "code": "import numpy as np\n\nclass AdaptiveStudentTGuidedEvolution:\n    \"\"\"\n    Adaptive Student-t Guided Evolution (novel heuristic)\n\n    Main ideas / parameters (high level):\n    - budget, dim: required\n    - pop: small population size (auto-scaled with dim if None)\n    - operator mix: probabilities for Student-t heavy jumps, DE-style recombination, and covariance-guided sampling\n      (p_student, p_de, p_cov)\n    - student_df: degrees of freedom for Student-t (low df -> heavier tails)\n    - sigma0: initial per-individual relative step scale (fraction of domain)\n    - tau_success, tau_failure: multiplicative factors for sigma update on success/failure\n    - elite_frac: fraction of population used to form elite archive and covariance\n    - cov_memory: EWMA weight for updating global covariance estimate\n    - local_period: frequency (generations) of lightweight coordinate local search\n    - local_probes: maximum extra evaluations during local search\n    - bounds handling: toroidal wrap (modulo) in box [lb,ub] to promote exploration across boundaries\n    \"\"\"\n\n    def __init__(self,\n                 budget=10000,\n                 dim=10,\n                 pop=None,\n                 p_student=0.35,\n                 p_de=0.45,\n                 p_cov=0.20,\n                 student_df=3.0,\n                 sigma0=0.18,\n                 tau_success=1.08,\n                 tau_failure=0.97,\n                 elite_frac=0.2,\n                 cov_memory=0.18,\n                 local_period=25,\n                 local_probes=5,\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop = pop  # if None, will be computed\n        self.p_student = float(p_student)\n        self.p_de = float(p_de)\n        self.p_cov = float(p_cov)\n        self.student_df = float(student_df)\n        self.sigma0 = float(sigma0)\n        self.tau_success = float(tau_success)\n        self.tau_failure = float(tau_failure)\n        self.elite_frac = float(elite_frac)\n        self.cov_memory = float(cov_memory)\n        self.local_period = int(local_period)\n        self.local_probes = int(local_probes)\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # Bounds (prefer func.bounds if present)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        domain_scale = ub - lb  # vector\n        avg_scale = float(np.mean(domain_scale))\n\n        # population sizing rule (distinct from prior art)\n        if self.pop is None:\n            # modest, slightly grows with log(dim)\n            pop = max(6, int(4 + np.ceil(3.0 * np.log(max(2, self.dim)))))\n        else:\n            pop = int(self.pop)\n        pop = min(pop, max(2, self.budget))  # cannot exceed budget\n        pop = max(2, pop)\n\n        # toroidal wrap bounds handler (different from reflect-then-clamp)\n        def wrap_into_box(x):\n            x = np.asarray(x, dtype=float)\n            width = ub - lb\n            # modulo on floats: put into [0, width), then shift\n            return lb + np.mod(x - lb, width)\n\n        # initialize population with scrambled Latin Hypercube-like sampling\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + rng.rand(pop)) / float(pop)\n            X[:, d] = lb[d] + strata[perm] * (ub[d] - lb[d])\n        # small anisotropic jitter (different formula)\n        jitter = (rng.randn(pop, self.dim) * 0.08) * (domain_scale / max(avg_scale, 1e-12))\n        X = wrap_into_box(X + jitter)\n\n        f = np.full(pop, np.inf, dtype=float)\n        evals = 0\n\n        # evaluate initial population sequentially\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        # per-individual sigma (relative to average domain scale)\n        sigma = np.full(pop, self.sigma0, dtype=float)\n\n        # maintain an elite archive and an adaptive covariance matrix (EWMA)\n        archive_X = X.copy()\n        archive_f = f.copy()\n        # initialize covariance as isotropic scaled identity\n        cov = np.eye(self.dim) * ( (avg_scale * 0.5) ** 2 + 1e-8 )\n\n        # tracking best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        gen = 0\n        gens_since_improve = 0\n\n        # helper to add to archive and keep it bounded\n        def archive_add(x_new, f_new):\n            nonlocal archive_X, archive_f\n            archive_X = np.vstack([archive_X, x_new[np.newaxis, :]])\n            archive_f = np.concatenate([archive_f, np.array([f_new], dtype=float)])\n            max_archive = max(6 * pop, 50)\n            if archive_X.shape[0] > max_archive:\n                order = np.argsort(archive_f)\n                keep = order[:max_archive]\n                archive_X = archive_X[keep]\n                archive_f = archive_f[keep]\n\n        # helper: sample multivariate Student-t with given covariance and df\n        def sample_student_t(mean, cov_mat, df, scale_factor):\n            # sample z ~ N(0, cov_mat), then divide by sqrt(chi2/df)\n            # produce vector = mean + scale_factor * z / sqrt(g/df)\n            # compute cholesky\n            try:\n                L = np.linalg.cholesky(cov_mat + 1e-12 * np.eye(self.dim))\n            except np.linalg.LinAlgError:\n                # fallback to diagonal\n                L = np.diag(np.sqrt(np.diag(cov_mat) + 1e-12))\n            z = rng.randn(self.dim)\n            z = L.dot(z)\n            g = rng.chisquare(df) if df > 0 else 1.0\n            denom = np.sqrt(g / df) if df > 0 else 1.0\n            return mean + (scale_factor * z / denom)\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # ranking and elites\n            order = np.argsort(f)\n            elite_count = max(2, int(np.ceil(self.elite_frac * pop)))\n            elite_idx = order[:elite_count]\n\n            # produce candidates: iterate individuals in random order\n            for ii in rng.permutation(pop):\n                if evals >= self.budget:\n                    break\n\n                x_i = X[ii].copy()\n                f_i = float(f[ii])\n\n                # choose operator by probabilities (normalized if needed)\n                probs = np.array([self.p_student, self.p_de, self.p_cov], dtype=float)\n                probs = probs / np.sum(probs)\n                op = rng.choice(3, p=probs)\n\n                candidate = None\n\n                if op == 0:\n                    # Student-t heavy jump around current or around sampled elite\n                    center = x_i if rng.rand() < 0.6 else archive_X[rng.randint(archive_X.shape[0])]\n                    # local scale factor depends on individual's sigma and avg scale\n                    scale_factor = sigma[ii] * avg_scale\n                    # sample from multivariate student-t with current covariance\n                    candidate = sample_student_t(center, cov, max(self.student_df, 0.5), scale_factor)\n                    candidate = wrap_into_box(candidate)\n\n                elif op == 1:\n                    # Adaptive DE-style recombination with Cauchy-distributed F (different param)\n                    # \"current-to-pbest\" with adaptive F drawn from a Cauchy with median F_m approx 0.6\n                    p = max(1, int(np.ceil(0.15 * pop)))\n                    pbest = X[rng.choice(order[:p])]\n                    # pick two random distinct others\n                    choices = [j for j in range(pop) if j != ii]\n                    if len(choices) >= 2:\n                        r1, r2 = rng.choice(choices, size=2, replace=False)\n                    else:\n                        r1 = r2 = ii\n                    # sample F from a truncated Cauchy centered at 0.6\n                    u = rng.rand()\n                    # inverse transform of standard Cauchy with location=0.6, scale=0.1\n                    F = 0.6 + 0.1 * np.tan(np.pi * (u - 0.5))\n                    F = np.clip(F, 0.05, 1.2)\n                    # recombination\n                    v = x_i + F * (pbest - x_i) + 0.5 * (X[r1] - X[r2])\n                    # binomial crossover\n                    mask = rng.rand(self.dim) < 0.5\n                    mask[rng.randint(self.dim)] = True\n                    candidate = x_i.copy()\n                    candidate[mask] = v[mask]\n                    # add small gaussian perturbation\n                    candidate += rng.randn(self.dim) * (0.02 * avg_scale * sigma[ii])\n                    candidate = wrap_into_box(candidate)\n\n                else:\n                    # covariance-guided sampling: sample near a weighted mean of elites using EWMA-cov\n                    # compute weighted elite mean (weights by softmax of negative fitness)\n                    elites = archive_X[ np.argsort(archive_f)[:max(elite_count, 4)] ]\n                    if elites.shape[0] == 0:\n                        center = x_i\n                    else:\n                        # weight by relative quality\n                        ef = np.array([np.mean(archive_f)] * elites.shape[0])  # stable fallback\n                        try:\n                            ef = archive_f[np.argsort(archive_f)[:elites.shape[0]]]\n                        except Exception:\n                            ef = np.linspace(1.0, 0.1, elites.shape[0])\n                        scores = np.exp(- (ef - np.min(ef)) / (1e-12 + np.std(ef)))\n                        w = scores / (np.sum(scores) + 1e-12)\n                        center = np.dot(w, elites)\n                    # sample multivariate normal using cov but scale by individual's sigma\n                    try:\n                        L = np.linalg.cholesky(cov + 1e-12 * np.eye(self.dim))\n                        z = L.dot(rng.randn(self.dim))\n                    except np.linalg.LinAlgError:\n                        z = rng.randn(self.dim) * np.sqrt(np.diag(cov) + 1e-12)\n                    candidate = wrap_into_box(center + z * (0.8 * sigma[ii]))\n                    # small directed bias toward global best with small prob\n                    if rng.rand() < 0.25:\n                        candidate = wrap_into_box(candidate + 0.12 * (x_best - center) * rng.rand())\n\n                # evaluate candidate (respect budget)\n                if evals >= self.budget:\n                    break\n                f_cand = float(func(candidate))\n                evals += 1\n\n                # success => replace and adapt sigma; failure => adapt sigma differently\n                if f_cand < f_i:\n                    X[ii] = candidate\n                    f[ii] = f_cand\n                    archive_add(candidate, f_cand)\n                    sigma[ii] = min(2.0, sigma[ii] * self.tau_success)\n                    improved_in_gen = True\n                    gens_since_improve = 0\n                    if f_cand < f_best:\n                        f_best = f_cand\n                        x_best = candidate.copy()\n                else:\n                    # slightly decrease sigma on failure\n                    sigma[ii] = max(1e-6, sigma[ii] * self.tau_failure)\n\n                # update covariance estimate using EWMA with the successful moves (rank-1 approx)\n                # compute delta from center (use candidate if better than archived mean)\n                # Here we perform a lightweight rank-1 covariance adaptation using candidate and current mean\n                # to keep differences from the original algorithm (no PCA power iterations)\n                # Use only a fraction of archive to compute a sample cov\n                if archive_X.shape[0] >= 4:\n                    # compute local sample covariance of best-K archive entries\n                    k = min(max(4, elite_count), archive_X.shape[0])\n                    idxs = np.argsort(archive_f)[:k]\n                    sample = archive_X[idxs]\n                    sample_mean = np.mean(sample, axis=0)\n                    Z = sample - sample_mean\n                    sample_cov = (Z.T @ Z) / max(1.0, Z.shape[0])\n                    # EWMA update to cov (keeps memory)\n                    cov = (1.0 - self.cov_memory) * cov + self.cov_memory * sample_cov\n                    # mild regularization\n                    cov += 1e-10 * np.eye(self.dim)\n\n            # generation end\n            if not improved_in_gen:\n                gens_since_improve += 1\n            else:\n                gens_since_improve = 0\n\n            # periodic light coordinate local-search around best\n            if (gen % self.local_period == 0) and (evals < self.budget):\n                probes_left = min(self.local_probes, self.budget - evals)\n                # pick a small set of coordinates to probe (distinct)\n                coords = rng.choice(self.dim, size=min(self.dim, probes_left), replace=False)\n                local_best_x = x_best.copy()\n                local_best_f = f_best\n                probes_done = 0\n                for c in coords:\n                    if probes_done >= probes_left or evals >= self.budget:\n                        break\n                    # simple three-point bracket along coordinate (step proportional to median sigma)\n                    step = max(1e-8, 0.02 * domain_scale[c] * np.median(sigma))\n                    x_p = wrap_into_box(local_best_x.copy()); x_p[c] += step\n                    x_m = wrap_into_box(local_best_x.copy()); x_m[c] -= step\n                    f_p = float(func(x_p)); evals += 1; probes_done += 1\n                    if evals >= self.budget:\n                        break\n                    f_m = float(func(x_m)); evals += 1; probes_done += 1\n                    # try midpoint if promising direction\n                    if f_p < local_best_f or f_m < local_best_f:\n                        # move best local point\n                        if f_p < f_m:\n                            local_best_x = x_p\n                            local_best_f = f_p\n                        else:\n                            local_best_x = x_m\n                            local_best_f = f_m\n                    # if we still have budget and improvement happened, try smaller step further\n                    if local_best_f < f_best and probes_done < probes_left and evals < self.budget:\n                        # attempt a smaller refinement step along same coordinate\n                        refine = 0.5 * step\n                        x_r = wrap_into_box(local_best_x.copy()); x_r[c] += np.sign(local_best_x[c] - x_best[c]) * refine\n                        f_r = float(func(x_r)); evals += 1; probes_done += 1\n                        if f_r < local_best_f:\n                            local_best_x = x_r\n                            local_best_f = f_r\n\n                # inject local improvement into population\n                if local_best_f < f_best:\n                    worst = int(np.argmax(f))\n                    X[worst] = local_best_x.copy()\n                    f[worst] = local_best_f\n                    archive_add(local_best_x, local_best_f)\n                    f_best = local_best_f\n                    x_best = local_best_x.copy()\n                    gens_since_improve = 0\n\n            # ensure global best synced with population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n            # mild diversification if long stagnation (> 10 * local_period)\n            if gens_since_improve > 10 * max(1, self.local_period):\n                # nudge half of population around the best with larger sigma\n                nudge_count = max(1, pop // 2)\n                for k in range(nudge_count):\n                    if evals >= self.budget:\n                        break\n                    jitter = (rng.randn(self.dim) * 0.12) * (domain_scale / max(avg_scale, 1e-12))\n                    x_new = wrap_into_box(x_best + jitter)\n                    f_new = float(func(x_new)); evals += 1\n                    # replace a random poor individual\n                    worsts = np.argsort(f)[-max(1, pop // 3):]\n                    ridx = rng.choice(worsts)\n                    X[ridx] = x_new\n                    f[ridx] = f_new\n                    archive_add(x_new, f_new)\n                    if f_new < f_best:\n                        f_best = f_new\n                        x_best = x_new.copy()\n                        gens_since_improve = 0\n\n            if evals >= self.budget:\n                break\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveStudentTGuidedEvolution scored 0.310 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "93890e17-e490-4bd2-83de-00a7a8d5b2b0", "operator": null, "metadata": {"aucs": [0.11955722460389095, 0.16625214404767374, 0.21626023053285015, 0.9376450270070456, 0.1652649579898532, 0.8157022753736399, 0.20766187729320984, 0.18338525712826814, 0.15952078797786629, 0.12901530235334813]}, "task_prompt": ""}
{"id": "b4762e3e-ad15-4254-879e-09f3b97d2cdc", "fitness": "-inf", "name": "AdaptiveSubspaceTrust", "description": "The algorithm maintains a small, dimension-aware cooperative population (pop ≈ max(8, 6+2√dim)) initialized by a Latin-hypercube-like scheme and uses strict budget accounting and reflect-then-clamp boundary handling to stay within [-5,5]^d. Each individual carries an absolute trust radius (init_radius default 0.25·mean(domain)) that is jittered stochastically, used to scale Gaussian local steps (exploit) and to limit model steps, while truncated Cauchy long jumps (heavy tails) provide rare global exploration. A model-based operator (default ~35% chance) builds a low-dimensional PCA subspace (up to subspace_dim) from a weighted nearest-point archive (archive_mul·pop capacity) and fits a ridge-regularized separable quadratic (a + g^T s + 0.5 ∑h_i s_i^2) to propose s* = −g/h reconstructed and clamped by trust radius. Acceptance is elitist (replace if better) with curvature-aware trust adaptation (rho = actual/predicted improvement) to grow/shrink radii, occasional diversity-driven worst replacements, and stagnation handling via radius inflation and targeted re-seeding near the current best.", "code": "import numpy as np\n\nclass AdaptiveSubspaceTrust:\n    \"\"\"\n    Adaptive Subspace Trust (novel heuristic)\n    - Small cooperative population (dimension-aware) with per-individual trust radii.\n    - Mixed global moves: Gaussian local sampling, truncated Cauchy jumps (heavy tails), and\n      model-based subspace quadratic proposals built from a small elite archive.\n    - Subspace quadratic model: fit f(s) ≈ a + g^T s + 0.5 * sum(h_i * s_i^2) in a k-dim PCA subspace\n      using ridge least-squares on nearest archive points; propose s* = -g / h (clamped by trust radius).\n    - Curvature-aware acceptance and trust radius adaptation: increase radius on successful model steps,\n      shrink on poor agreement between predicted and actual improvements.\n    - Reflect-then-clamp boundary handling, strict budget accounting.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 seed=None,\n                 p_gauss=0.45,    # gaussian local sampling\n                 p_cauchy=0.2,    # heavy-tailed long jumps\n                 p_model=0.35,    # model-based subspace proposals\n                 init_radius=0.25,# initial trust radius as fraction of domain mean\n                 subspace_dim=3,  # max subspace dim for local quadratic model\n                 archive_mul=6,   # archive size multiplier relative to pop\n                 stagn_threshold=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.seed = seed\n        # operator probabilities (should sum to 1; they will be normalized)\n        self.p_gauss = p_gauss\n        self.p_cauchy = p_cauchy\n        self.p_model = p_model\n        # trust region / model params\n        self.init_radius = float(init_radius)\n        self.subspace_dim = int(max(1, subspace_dim))\n        self.archive_mul = int(max(3, archive_mul))\n        self.stagn_threshold = stagn_threshold if stagn_threshold is not None else max(30, int(3 + 0.3 * self.dim))\n\n        # normalize operator probs later if needed\n\n    def __call__(self, func):\n        # isolated RNG\n        rng = np.random.RandomState(self.seed)\n\n        # bounds (Many Affine BBOB: default -5..5 but honor func.bounds if present)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size (dimension-aware small cooperative pop)\n        if self.pop_base is None:\n            pop = max(8, int(np.ceil(6 + 2.0 * np.sqrt(self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        # normalize operator probabilities\n        probs = np.array([self.p_gauss, self.p_cauchy, self.p_model], dtype=float)\n        if probs.sum() <= 0:\n            probs = np.array([0.5, 0.25, 0.25])\n        probs /= probs.sum()\n        p_gauss, p_cauchy, p_model = probs.tolist()\n\n        # domain scaling helpers\n        domain_scale = ub - lb\n        domain_mean = float(np.mean(domain_scale))\n        # reflect then clamp boundary handler\n        def reflect_clamp(x):\n            x = np.asarray(x, dtype=float).copy()\n            low = lb\n            high = ub\n            # reflect once\n            below = x < low\n            if np.any(below):\n                x[below] = low[below] + (low[below] - x[below])\n            above = x > high\n            if np.any(above):\n                x[above] = high[above] - (x[above] - high[above])\n            # final clamp\n            np.minimum(np.maximum(x, low), high, out=x)\n            return x\n\n        # truncated Cauchy sampler for heavy tails\n        def truncated_cauchy(scale, size):\n            u = rng.rand(*size)\n            s = np.tan(np.pi * (u - 0.5))\n            s = np.clip(s, -1e3, 1e3)\n            return scale * s\n\n        # Latin-hypercube-like initialization\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / float(pop)\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # small jitter to break regularity\n        X += (rng.rand(pop, self.dim) - 0.5) * 0.5 * (domain_scale) / max(1.0, self.dim)\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        f = np.full(pop, np.inf, dtype=float)\n        evals = 0\n\n        # evaluate initial population sequentially (strict budget)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        if evals >= self.budget:\n            best_idx = int(np.nanargmin(f))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-individual trust radii (absolute scale)\n        radius = np.full(pop, self.init_radius * domain_mean, dtype=float)\n        # keep archive of good samples\n        archive_X = X.copy()\n        archive_f = f.copy()\n        max_archive = max(10, self.archive_mul * pop)\n\n        def archive_add(x_new, f_new):\n            nonlocal archive_X, archive_f\n            archive_X = np.vstack([archive_X, x_new[np.newaxis, :]])\n            archive_f = np.concatenate([archive_f, np.array([f_new], dtype=float)])\n            if archive_X.shape[0] > max_archive:\n                order = np.argsort(archive_f)\n                keep = order[:max_archive]\n                archive_X = archive_X[keep]\n                archive_f = archive_f[keep]\n\n        # tracking best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n        gen = 0\n        gens_since_improve = 0\n\n        # convenience for normalized distances\n        def normed_dist(a, b):\n            # scaled Euclidean distance dividing by domain scales to be affine-aware\n            diff = (a - b) / (domain_scale + 1e-16)\n            return np.linalg.norm(diff)\n\n        # main loop with strict budget accounting\n        while evals < self.budget:\n            gen += 1\n            improved = False\n\n            # rank and elites\n            order = np.argsort(f)\n            elite_count = max(2, int(np.ceil(0.2 * pop)))\n            elite_idx = order[:elite_count]\n\n            # one generation: try one proposal per individual in random order\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                x_i = X[ii].copy()\n                f_i = float(f[ii])\n\n                # small probabilistic adaptation of radius\n                if rng.rand() < 0.12:\n                    radius[ii] *= np.exp(0.2 * rng.randn())\n                    radius[ii] = np.clip(radius[ii], 1e-6 * domain_mean, 2.0 * domain_mean)\n\n                # choose operator\n                r = rng.rand()\n                candidate = None\n\n                # 1) Gaussian local sampling (exploit)\n                if r < p_gauss:\n                    scale = radius[ii] / (np.sqrt(self.dim) + 1e-12)\n                    step = rng.randn(self.dim) * (scale * (domain_scale / domain_mean))\n                    candidate = reflect_clamp(x_i + step)\n\n                # 2) truncated Cauchy long jump (explore)\n                elif r < p_gauss + p_cauchy:\n                    scale = max(radius[ii], 0.5 * domain_mean)\n                    step = truncated_cauchy(scale, (self.dim,))\n                    step = step * (domain_scale / domain_mean)\n                    candidate = reflect_clamp(x_i + step)\n\n                # 3) Model-based subspace quadratic proposal (curvature-aware)\n                else:\n                    # Need some archive points to fit model\n                    if archive_X.shape[0] >= (1 + 2 * min(self.subspace_dim, archive_X.shape[0] - 1)):\n                        # select nearest samples to x_i to build local model\n                        distances = np.array([normed_dist(x_i, xa) for xa in archive_X])\n                        # select nsamples = at least 1 + 2*k (for 1 + k + k parameters)\n                        k = min(self.subspace_dim, max(1, archive_X.shape[0] - 1))\n                        nsamples = min( max(1 + 2 * k, 1), archive_X.shape[0] )\n                        idx_sel = np.argsort(distances)[:nsamples]\n                        Sx = archive_X[idx_sel]\n                        Sf = archive_f[idx_sel]\n                        # center at weighted mean (weights exponential by distance)\n                        dsel = distances[idx_sel]\n                        weights = np.exp(- (dsel / (1e-12 + np.median(dsel) + 1e-6))**2 )\n                        weights = weights + 1e-6\n                        W = weights / weights.sum()\n                        m = np.sum(Sx * W[:, None], axis=0)\n                        # build PCA subspace B (k vectors)\n                        Z = Sx - m\n                        # small regularization in covariance\n                        C = np.dot((W[:, None] * Z).T, Z) / max(1e-12, np.sum(W))\n                        # compute top-k eigenvectors via SVD\n                        try:\n                            U, svals, Vt = np.linalg.svd(C)\n                            B = U[:, :k]  # shape (dim, k)\n                        except Exception:\n                            # fallback random orthonormal directions\n                            B = rng.randn(self.dim, k)\n                            for j in range(k):\n                                for t in range(j):\n                                    B[:, j] -= np.dot(B[:, j], B[:, t]) * B[:, t]\n                                norm = np.linalg.norm(B[:, j])\n                                if norm == 0:\n                                    B[:, j] = rng.randn(self.dim)\n                                    norm = np.linalg.norm(B[:, j])\n                                B[:, j] /= (norm + 1e-16)\n\n                        # coordinates of selected samples in subspace\n                        Scoords = np.dot((Sx - m), B)  # shape (nsamples, k)\n                        # construct design matrix for parameters [a, g (k), h (k)] using column-wise:\n                        # phi = [1, s1, s2, ..., 0.5*s1^2, 0.5*s2^2, ...]\n                        phi_list = []\n                        for sj in Scoords:\n                            row = np.concatenate([ [1.0], sj, 0.5 * (sj**2) ])\n                            phi_list.append(row)\n                        Phi = np.vstack(phi_list)  # nsamples x (1+2k)\n                        y = Sf  # use raw function values (no centering)\n                        # ridge solve for stability\n                        ridge = 1e-8 * np.eye(Phi.shape[1])\n                        try:\n                            # normal equations: p = (Phi^T Phi + ridge)^{-1} Phi^T y\n                            A = np.dot(Phi.T, Phi) + ridge\n                            b = np.dot(Phi.T, y)\n                            p = np.linalg.solve(A, b)\n                        except Exception:\n                            # fallback to least squares\n                            p, *_ = np.linalg.lstsq(Phi, y, rcond=None)\n                            if p is None:\n                                candidate = reflect_clamp(x_i + 0.02 * domain_scale * rng.randn(self.dim))\n                                # skip the rest of model logic\n                                p = None\n\n                        if p is not None:\n                            a = p[0]\n                            g = p[1:1 + k]\n                            h = p[1 + k:1 + 2 * k]\n                            # enforce mild positive curvature for stable minimizer\n                            h = h + 1e-6 * np.sign(h)\n                            # avoid zero curvature entries\n                            min_h = 1e-6 * max(1.0, np.mean(np.abs(h)))\n                            # make curvature positive (if h_i negative, add damp)\n                            for idxh in range(len(h)):\n                                if h[idxh] == 0:\n                                    h[idxh] = min_h\n                                # push to positive definite-ish by adding positive ridge\n                                if h[idxh] < min_h:\n                                    h[idxh] = min_h\n\n                            # predicted minimizer in subspace: s* = -g / h (element-wise)\n                            s_star = -g / (h + 1e-16)\n                            # reconstruct candidate and clamp by trust radius\n                            x_pred = m + np.dot(B, s_star)\n                            # limit step size from x_i: do not jump further than 3 * radius[ii] in Euclidean scaled space\n                            max_step = 3.0 * radius[ii]\n                            step_vec = x_pred - x_i\n                            step_norm = np.linalg.norm(step_vec / (domain_scale + 1e-16))\n                            if step_norm > 0:\n                                if step_norm * domain_mean > max_step:\n                                    step_vec = step_vec * ( (max_step / (step_norm * domain_mean)) )\n                                    x_pred = x_i + step_vec\n                            candidate = reflect_clamp(x_pred)\n                    else:\n                        # not enough archive points: fallback to Gaussian small step\n                        scale = 0.6 * radius[ii] / (np.sqrt(self.dim) + 1e-12)\n                        candidate = reflect_clamp(x_i + rng.randn(self.dim) * (scale * (domain_scale / domain_mean)))\n\n                # Evaluate candidate if defined and budget allows\n                if candidate is None:\n                    candidate = x_i.copy()\n                if evals >= self.budget:\n                    break\n                f_cand = float(func(candidate))\n                evals += 1\n\n                # selection: accept if better than parent\n                replaced = False\n                if f_cand < f_i:\n                    X[ii] = candidate\n                    f[ii] = f_cand\n                    archive_add(candidate, f_cand)\n                    replaced = True\n                    if f_cand < f_best:\n                        f_best = f_cand\n                        x_best = candidate.copy()\n                        improved = True\n                        gens_since_improve = 0\n\n                    # if candidate came from model operator, attempt trust update\n                    if (r >= p_gauss + p_cauchy) and replaced:\n                        # compute predicted improvement if we used a model: compare model predicted value at s_star vs a\n                        # approximate predicted_improve = f_i - f_model_pred (we lack exact model for f at x_i; use nearest sample mean)\n                        # To be conservative, compute rho ~ actual_improve / max(predicted_improve, tiny)\n                        # We'll use predicted_improve approx = abs(f_i - a)\n                        # (This is heuristic to adapt trust radius)\n                        # Increase trust if actual improvement is a decent fraction of predicted.\n                        # Because we did not always compute 'a' globally, we use archive mean near x_i\n                        # This block is best-effort; guard with try/except for safety\n                        try:\n                            # approximate local baseline as weighted archive mean near x_i\n                            if archive_X.shape[0] >= 3:\n                                dists = np.array([normed_dist(x_i, xa) for xa in archive_X])\n                                sel = np.argsort(dists)[:min(6, archive_X.shape[0])]\n                                baseline = np.mean(archive_f[sel])\n                            else:\n                                baseline = f_i\n                            predicted_improve = max(1e-12, baseline - f_cand)\n                            actual_improve = max(0.0, f_i - f_cand)\n                            rho = actual_improve / predicted_improve\n                            if rho > 0.75:\n                                radius[ii] = min(radius[ii] * 1.25, 2.0 * domain_mean)\n                            elif rho < 0.2:\n                                radius[ii] = max(radius[ii] * 0.6, 1e-6 * domain_mean)\n                        except Exception:\n                            pass\n\n                else:\n                    # Not improved: occasional replacement of worst with candidate to preserve diversity when candidate is very different\n                    # but keep budget-conscious and conservative: only do this with small prob if candidate is far from population\n                    if rng.rand() < 0.02:\n                        # measure distinctness\n                        dmean = np.mean([normed_dist(candidate, X[j]) for j in range(pop)])\n                        if dmean > 0.5 * np.mean(domain_scale) / (domain_mean + 1e-16):\n                            worst = int(np.argmax(f))\n                            X[worst] = candidate.copy()\n                            f[worst] = f_cand\n                            archive_add(candidate, f_cand)\n\n                # update best from population occasionally\n                if f_cand < f_best:\n                    f_best = f_cand\n                    x_best = candidate.copy()\n                    gens_since_improve = 0\n                    improved = True\n\n            # end for individuals\n\n            if not improved:\n                gens_since_improve += 1\n\n            # stagnation handling: partial re-seeding / radius inflation\n            if gens_since_improve >= self.stagn_threshold:\n                # inflate some radii and inject few randoms near best\n                n_inject = max(1, pop // 4)\n                for k in range(n_inject):\n                    if evals >= self.budget:\n                        break\n                    idx_replace = rng.choice(pop)\n                    # create a sample near best with moderate jitter proportional to domain\n                    jitter = (rng.randn(self.dim) * 0.08 * domain_scale)\n                    x_new = reflect_clamp(x_best + jitter)\n                    f_new = float(func(x_new))\n                    evals += 1\n                    X[idx_replace] = x_new\n                    f[idx_replace] = f_new\n                    radius[idx_replace] = max(radius[idx_replace], 0.8 * domain_mean)\n                    archive_add(x_new, f_new)\n                    if f_new < f_best:\n                        f_best = f_new\n                        x_best = x_new.copy()\n                        gens_since_improve = 0\n                        improved = True\n                # also slightly increase all radii to encourage exploration\n                radius *= 1.15\n                radius = np.clip(radius, 1e-6 * domain_mean, 3.0 * domain_mean)\n                # reset stagnation counter partially to allow recovery\n                gens_since_improve = max(0, gens_since_improve - 5)\n\n            # keep archive bounded\n            if archive_X.shape[0] > max_archive:\n                order_a = np.argsort(archive_f)\n                keep = order_a[:max_archive]\n                archive_X = archive_X[keep]\n                archive_f = archive_f[keep]\n\n            # sync best with population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n            # final budget check early exit\n            if evals >= self.budget:\n                break\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 277, in __call__, the following error occurred:\nValueError: shapes (2,2) and (3,) not aligned: 2 (dim 1) != 3 (dim 0)\nOn line: x_pred = m + np.dot(B, s_star)", "error": "In the code, line 277, in __call__, the following error occurred:\nValueError: shapes (2,2) and (3,) not aligned: 2 (dim 1) != 3 (dim 0)\nOn line: x_pred = m + np.dot(B, s_star)", "parent_ids": "93890e17-e490-4bd2-83de-00a7a8d5b2b0", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "c72b7d3a-5dde-4b45-9be5-fea1a4709f3b", "fitness": 0.4418546324126721, "name": "SEDS", "description": "The algorithm mixes multi-scale exploration and directed exploitation: stratified (LHS-like) initialization with modest jitter and domain-aware, coordinate-wise scaling is combined with per-individual adaptive sigmas, occasional long tempered-Cauchy jumps for rare global moves, DE-style directed recombination for population-driven moves, and PCA-guided sampling along top principal directions (power-iteration computed from an archive/elite set) for focused multi-scale search. Key parameter choices bias behavior toward structured exploitation: a modest population size (pop ≈ 4+3√dim), low long-jump probability (p_cauchy=0.15), moderate DE mixing (p_de=0.40) and slightly higher PCA-guided sampling (p_pca=0.45), more frequent sigma adaptation (tau_sigma=0.25) with a small initial sigma (0.05), a conservative elite fraction (20%) and an archive (bounded) to concentrate PCA and elites. Boundary handling uses a reflect-then-clamp operator and all steps are scaled by the per-coordinate domain to respect anisotropy; the tempered Cauchy is truncated for numerical safety. Budget-awareness is enforced by guarded, low-cost local probes: periodic PCA-directed finite-difference derivative and curvature estimates determine adaptive line-like probes (limited probe budget) and opportunistic injections into the population, plus mild reseeding around the best point on stagnation to preserve diversity. Replacement is primarily greedy but occasionally replaces the worst to maintain exploration, and archive pruning keeps memory bounded.", "code": "import numpy as np\n\nclass SEDS:\n    \"\"\"\n    Scaled Ensemble Directional Search (SEDS)\n\n    Main idea (one-liner): Mix multi-scale Gaussian exploration, tempered Cauchy long jumps,\n    DE-style directed recombination, and PCA-guided directional exploitation with conservative,\n    budget-aware local probes.\n\n    Main tunable parameters (defaults chosen differently from the provided algorithm):\n      - pop formula: pop = max(6, int(4 + 3*sqrt(dim)))  # different scaling of pop\n      - op probabilities: p_cauchy=0.15, p_de=0.4, p_pca=0.45\n      - sigma adaptation: tau_sigma = 0.25 (more frequent), sigma_init = 0.05 (smaller initial)\n      - elite_frac = 0.20 (top 20% used for PCA)\n      - local_period = 20 (more frequent local exploitation)\n      - stagn_threshold = 20 (trigger earlier)\n      - power_iters = 8 (PCA power iterations)\n      - archive_max = 5*pop\n      - max_dir_probes = 8 (slightly larger local probing budget)\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 p_cauchy=0.15,\n                 p_de=0.40,\n                 p_pca=0.45,\n                 tau_sigma=0.25,\n                 sigma_init=0.05,\n                 elite_frac=0.20,\n                 local_period=20,\n                 stagn_threshold=20,\n                 max_dir_probes=8,\n                 power_iters=8,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.p_cauchy = float(p_cauchy)\n        self.p_de = float(p_de)\n        self.p_pca = float(p_pca)\n        self.tau_sigma = float(tau_sigma)\n        self.sigma_init = float(sigma_init)\n        self.elite_frac = float(elite_frac)\n        self.local_period = int(local_period)\n        self.stagn_threshold = int(stagn_threshold)\n        self.max_dir_probes = int(max_dir_probes)\n        self.power_iters = int(power_iters)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds: Many-affine BBOB uses [-5,5]^dim but respect func.bounds if provided\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size (different formula)\n        if self.pop_base is None:\n            pop = max(6, int(np.ceil(4 + 3.0 * np.sqrt(self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        # domain scale\n        domain_scale = ub - lb\n        mean_dom = np.mean(domain_scale)\n\n        # reflect-then-clamp bounds handling\n        def reflect_clamp(x):\n            x = np.asarray(x, dtype=float).copy()\n            low = lb\n            high = ub\n            below = x < low\n            if np.any(below):\n                x[below] = low[below] + (low[below] - x[below])\n            above = x > high\n            if np.any(above):\n                x[above] = high[above] - (x[above] - high[above])\n            np.minimum(np.maximum(x, low), high, out=x)\n            return x\n\n        # tempered Cauchy generator (truncated)\n        def tempered_cauchy(scale):\n            u = rng.rand(self.dim)\n            s = np.tan(np.pi * (u - 0.5))\n            s = np.clip(s, -1e2, 1e2)\n            return scale * s\n\n        # initialize population using stratified sampling (LHS-like), with different jitter amplitude\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / float(pop)\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter less strongly than original: jitter amplitude ~ 0.25 * domain/dim\n        X += (rng.rand(pop, self.dim) - 0.5) * 0.25 * (domain_scale) / max(1.0, np.sqrt(self.dim))\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        f = np.full(pop, np.inf, dtype=float)\n        evals = 0\n\n        # evaluate initial population sequentially\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        if evals >= self.budget:\n            best_idx = int(np.nanargmin(f))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-individual scale (relative)\n        sigma = np.full(pop, self.sigma_init, dtype=float)\n\n        # archive to collect elites and recent good points\n        archive_X = X.copy()\n        archive_f = f.copy()\n        archive_max = max(5 * pop, pop + 20)\n\n        def archive_add(x_new, f_new):\n            nonlocal archive_X, archive_f\n            archive_X = np.vstack([archive_X, x_new[np.newaxis, :]])\n            archive_f = np.concatenate([archive_f, np.array([f_new], dtype=float)])\n            if archive_X.shape[0] > archive_max:\n                order = np.argsort(archive_f)\n                keep = order[:archive_max]\n                archive_X = archive_X[keep]\n                archive_f = archive_f[keep]\n\n        # tracking best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n        gen = 0\n        gens_since_improve = 0\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            order = np.argsort(f)\n            elite_count = max(2, int(np.ceil(self.elite_frac * pop)))\n            elite_idx = order[:elite_count]\n\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                x_i = X[ii].copy()\n                f_i = float(f[ii])\n\n                # sigma adaptation (more frequent, slightly larger multiplicative jumps)\n                if rng.rand() < self.tau_sigma:\n                    sigma[ii] *= np.exp(0.2 * rng.randn() + 0.02 * (rng.rand() - 0.5))\n                    sigma[ii] = np.clip(sigma[ii], 1e-7, 2.5)\n\n                r = rng.rand()\n                candidate = None\n\n                # 1) tempered Cauchy long jump (low prob)\n                if r < self.p_cauchy:\n                    center = x_i if rng.rand() < 0.6 else x_best\n                    scale = (0.8 + rng.rand() * 1.5) * sigma[ii] * mean_dom\n                    step = tempered_cauchy(scale)\n                    # coordinate-wise scaling by domain\n                    step = step * (domain_scale / mean_dom)\n                    candidate = reflect_clamp(center + step)\n\n                else:\n                    # 2) DE-style directed mixing\n                    if r < self.p_cauchy + self.p_de:\n                        p = max(1, int(np.ceil(0.15 * pop)))\n                        pbest = X[rng.choice(order[:p])]\n                        choices = [j for j in range(pop) if j != ii]\n                        if len(choices) >= 2:\n                            r1, r2 = rng.choice(choices, size=2, replace=False)\n                        else:\n                            r1 = r2 = ii\n                        F1 = 0.7\n                        F2 = 0.45\n                        v = x_i + F1 * (pbest - x_i) + F2 * (X[r1] - X[r2])\n                        # anisotropic Gaussian noise scaled by coordinate domain and sigma\n                        v = v + (rng.randn(self.dim) * (0.9 + rng.rand()) * sigma[ii] * domain_scale)\n                        candidate = reflect_clamp(v)\n\n                    else:\n                        # 3) PCA-guided multi-scale sampling\n                        # Build PCA direction(s) from archive (or elite)\n                        if archive_X.shape[0] >= 4:\n                            a_order = np.argsort(archive_f)\n                            topk = min(max(3, elite_count), archive_X.shape[0])\n                            Z = archive_X[a_order[:topk]] - np.mean(archive_X[a_order[:topk]], axis=0)\n                            C = np.dot(Z.T, Z) / max(1.0, Z.shape[0])\n                            # power iteration to get top 2 eigenvectors (deflate)\n                            v1 = rng.randn(self.dim)\n                            for _ in range(self.power_iters):\n                                v1 = np.dot(C, v1)\n                                nrm = np.linalg.norm(v1)\n                                if nrm == 0:\n                                    break\n                                v1 /= nrm\n                            # deflate\n                            C2 = C - np.outer(np.dot(C, v1), v1)\n                            v2 = rng.randn(self.dim)\n                            for _ in range(max(3, self.power_iters // 2)):\n                                v2 = np.dot(C2, v2)\n                                nrm = np.linalg.norm(v2)\n                                if nrm == 0:\n                                    break\n                                v2 /= nrm\n                            pc1 = v1 / (np.linalg.norm(v1) + 1e-16)\n                            pc2 = v2 / (np.linalg.norm(v2) + 1e-16)\n                        else:\n                            pc1 = rng.randn(self.dim); pc1 /= np.linalg.norm(pc1)\n                            pc2 = rng.randn(self.dim); pc2 /= np.linalg.norm(pc2)\n\n                        # sample along combination of principal directions with multi-scale coefficients\n                        center = X[rng.choice(elite_idx)]\n                        scales = np.array([1.0, 0.5, 0.25])\n                        coeffs = (rng.randn(3) * (sigma[ii] * mean_dom)) * (0.5 + rng.rand(3))\n                        # combine pc1, pc2 and isotropic component\n                        step = coeffs[0] * pc1 + coeffs[1] * pc2 + coeffs[2] * (rng.randn(self.dim) / np.sqrt(self.dim))\n                        # scale per-coordinate by domain_scale\n                        step = step * (domain_scale / mean_dom)\n                        candidate = reflect_clamp(center + step)\n\n                if candidate is None:\n                    candidate = x_i.copy()\n\n                if evals >= self.budget:\n                    break\n                f_cand = float(func(candidate)); evals += 1\n\n                # greedy replacement\n                if f_cand < f_i:\n                    X[ii] = candidate\n                    f[ii] = f_cand\n                    archive_add(candidate, f_cand)\n                    if f_cand < f_best:\n                        f_best = f_cand\n                        x_best = candidate.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    # weak replacement of worst occasionally to preserve exploratory diversity\n                    if rng.rand() < 0.03:\n                        worst = int(np.argmax(f))\n                        if f_cand < f[worst]:\n                            X[worst] = candidate.copy()\n                            f[worst] = f_cand\n                            archive_add(candidate, f_cand)\n                            if f_cand < f_best:\n                                f_best = f_cand\n                                x_best = candidate.copy()\n                                improved_in_gen = True\n                                gens_since_improve = 0\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # Periodic PCA-directed local exploitation with guarded probes (budget-aware)\n            if (gen % self.local_period == 0) or (gens_since_improve >= self.stagn_threshold):\n                if evals >= self.budget:\n                    break\n\n                # Build PCA from archive or elites\n                try:\n                    use_data = archive_X if archive_X.shape[0] >= 5 else X[order[:max(4, elite_count)]]\n                    M = np.mean(use_data, axis=0)\n                    Z = use_data - M\n                    C = np.dot(Z.T, Z) / max(1.0, Z.shape[0])\n                    v = rng.randn(self.dim)\n                    for _ in range(self.power_iters):\n                        v = np.dot(C, v)\n                        nrm = np.linalg.norm(v)\n                        if nrm == 0:\n                            break\n                        v /= nrm\n                    pc = v / (np.linalg.norm(v) + 1e-16)\n                except Exception:\n                    pc = rng.randn(self.dim)\n                    pc /= np.linalg.norm(pc)\n\n                # finite-difference three-point estimate (cost 2 or 3 evals)\n                eps = max(1e-9, 5e-4 * mean_dom * max(1e-3, np.median(sigma)))\n                probes_done = 0\n                if evals + 2 <= self.budget:\n                    x_fwd = reflect_clamp(x_best + eps * pc)\n                    x_bwd = reflect_clamp(x_best - eps * pc)\n                    f_fwd = float(func(x_fwd)); evals += 1\n                    f_bwd = float(func(x_bwd)); evals += 1\n                    probes_done += 2\n                    deriv = (f_fwd - f_bwd) / (2.0 * eps)\n                    # curvature proxy\n                    curv = (f_fwd + f_bwd - 2.0 * f_best) / (eps * eps + 1e-18)\n\n                    # propose a step in negative derivative direction, scale adaptively using curvature\n                    if abs(deriv) > 1e-14:\n                        step0 = (0.5 / (1.0 + np.abs(curv))) * mean_dom * (0.3 + 0.7 * sigma.mean())\n                        alphas = [1.0, 0.6, 0.3, 0.15]\n                        improved_local = False\n                        best_local_x = x_best.copy()\n                        best_local_f = f_best\n                        for a in alphas:\n                            if probes_done >= self.max_dir_probes or evals >= self.budget:\n                                break\n                            step = -np.sign(deriv) * a * step0\n                            x_try = reflect_clamp(x_best + step * pc)\n                            f_try = float(func(x_try)); evals += 1\n                            probes_done += 1\n                            if f_try < best_local_f:\n                                best_local_f = f_try\n                                best_local_x = x_try.copy()\n                                improved_local = True\n                                # opportunistic extra probe forward (if budget allows)\n                                if probes_done < self.max_dir_probes and evals < self.budget:\n                                    x_try2 = reflect_clamp(x_try + 0.6 * step * pc)\n                                    f_try2 = float(func(x_try2)); evals += 1\n                                    probes_done += 1\n                                    if f_try2 < best_local_f:\n                                        best_local_f = f_try2\n                                        best_local_x = x_try2.copy()\n                                break\n                        if improved_local:\n                            # inject into population replacing worst\n                            worst = int(np.argmax(f))\n                            X[worst] = best_local_x.copy()\n                            f[worst] = best_local_f\n                            archive_add(best_local_x, best_local_f)\n                            if best_local_f < f_best:\n                                f_best = best_local_f\n                                x_best = best_local_x.copy()\n                                gens_since_improve = 0\n                                improved_in_gen = True\n\n                # If stagnation persists, partially re-seed population around best (mild restart)\n                if (not improved_in_gen) and (gens_since_improve >= self.stagn_threshold):\n                    n_reseed = max(1, pop // 4)\n                    for k in range(n_reseed):\n                        if evals >= self.budget:\n                            break\n                        jitter = (0.08 + 0.05 * rng.rand()) * domain_scale * rng.randn(self.dim)\n                        x_new = reflect_clamp(x_best + jitter)\n                        f_new = float(func(x_new)); evals += 1\n                        # replace a random worse-than-median individual if possible\n                        med = np.median(f)\n                        candidates = np.where(f > med)[0]\n                        if candidates.size == 0:\n                            replace_idx = int(np.argmax(f))\n                        else:\n                            replace_idx = int(rng.choice(candidates))\n                        X[replace_idx] = x_new\n                        f[replace_idx] = f_new\n                        archive_add(x_new, f_new)\n                        if f_new < f_best:\n                            f_best = f_new\n                            x_best = x_new.copy()\n                            gens_since_improve = 0\n                            improved_in_gen = True\n\n            # sync best with population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n            if evals >= self.budget:\n                break\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SEDS scored 0.442 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "93890e17-e490-4bd2-83de-00a7a8d5b2b0", "operator": null, "metadata": {"aucs": [0.2325842835996913, 0.1607868087665152, 0.482402525967608, 0.9102336720194831, 0.31285990552520215, 0.7378337798080242, 0.23842170011972452, 0.5289049517475427, 0.6555589598088575, 0.15895973676407216]}, "task_prompt": ""}
{"id": "86a7276a-82d1-432e-8d9f-6addd63b3313", "fitness": 0.38645219246973533, "name": "HybridAdaptiveLevyDE_PCA", "description": "The algorithm uses a small, dimension-aware quasi-uniform (LHS-like) population with per-individual self-adaptive DE parameters (F, CR) and step-size sigma (F_init=0.6, CR_init=0.5, sigma_init=0.08; tau_* control adaptation rates) to balance exploration and exploitation. It evolves solutions via a mixture of three operators — heavy-tailed Lévy/Cauchy jumps, DE-style current-to-pbest/1 recombination, and PCA-projected sampling from an elite/archive set — with bandit-style softmax weighting (initial p_init = (0.25,0.5,0.25)) and soft decay of operator scores to remain adaptive. An elite archive (trimmed periodically) supplies data for a cheap power-iteration PCA direction used both as a sampling bias and for periodic local improvement: centered finite-difference + guarded line-search and a Hooke–Jeeves coordinate search triggered by stagnation, plus stagnation-driven jitter/diversification. Implementation is budget-aware (strict eval counting), uses reflect-then-clamp bounds handling, opportunistic injection of improvements into the population, and lightweight computational primitives (small pop, limited PCA iterations) to suit noisy-free BBOB budget constraints.", "code": "import numpy as np\n\nclass HybridAdaptiveLevyDE_PCA:\n    \"\"\"\n    HybridAdaptiveLevyDE_PCA:\n    - Small quasi-uniform population with per-individual self-adaptive DE/F/CR and sigma.\n    - Operator mixture: Lévy/Cauchy jumps, DE-style directed recombination, PCA-projected sampling.\n    - Elite archive for PCA; cheap power-iteration PCA and guarded low-cost directional / coordinate local searches.\n    - Bandit-style adaptive operator probabilities (softmax on recent successes).\n    - Reflect-then-clamp bounds handling, strict budget accounting, and injection of improvements.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 p_init=(0.25, 0.5, 0.25),   # initial operator mixture: (levy, de, pca)\n                 tau_F=0.1, tau_CR=0.1, tau_sigma=0.12,\n                 F_init=0.6, CR_init=0.5, sigma_init=0.08,\n                 local_period=20, stagn_threshold=30,\n                 coord_initial_frac=0.18, coord_shrink=0.5, coord_min_frac=1e-4,\n                 max_pca_powerits=8,\n                 random_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.p_init = tuple(p_init)\n        self.tau_F = float(tau_F)\n        self.tau_CR = float(tau_CR)\n        self.tau_sigma = float(tau_sigma)\n        self.F_init = float(F_init)\n        self.CR_init = float(CR_init)\n        self.sigma_init = float(sigma_init)\n        self.local_period = int(local_period)\n        self.stagn_threshold = int(stagn_threshold)\n        self.coord_initial_frac = float(coord_initial_frac)\n        self.coord_shrink = float(coord_shrink)\n        self.coord_min_frac = float(coord_min_frac)\n        self.max_pca_powerits = int(max_pca_powerits)\n        self.random_seed = random_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.random_seed)\n\n        # Bounds: if not present, assume [-5,5]\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        lb = lb.astype(float)\n        ub = ub.astype(float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # population size small and dimension-aware\n        if self.pop_base is None:\n            pop = max(8, int(np.ceil(4 + 3 * np.log(max(2, self.dim)))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        # reflect-then-clamp\n        def reflect_clamp(x):\n            x = np.asarray(x, dtype=float).copy()\n            low, high = lb, ub\n            below = x < low\n            if np.any(below):\n                x[below] = low[below] + (low[below] - x[below])\n            above = x > high\n            if np.any(above):\n                x[above] = high[above] - (x[above] - high[above])\n            np.minimum(np.maximum(x, low), high, out=x)\n            return x\n\n        # truncated Cauchy (Levy-like) generator\n        def cauchy_vec(scale):\n            # standard Cauchy via tan(pi*(u-0.5)), truncated\n            u = rng.rand(self.dim)\n            s = np.tan(np.pi * (u - 0.5))\n            s = np.clip(s, -1e3, 1e3)\n            return scale * s\n\n        # quasi-uniform LHS-like init\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / float(pop)\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # small jitter to break regularity\n        X += (rng.rand(pop, self.dim) - 0.5) * 0.5 * (ub - lb) / max(1.0, self.dim)\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        f = np.full(pop, np.inf, dtype=float)\n        evals = 0\n\n        # sequentially evaluate initial population (budget-aware)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-individual DE params and sigma (self-adaptive)\n        F = np.full(pop, self.F_init, dtype=float)\n        CR = np.full(pop, self.CR_init, dtype=float)\n        sigma = np.full(pop, self.sigma_init, dtype=float)\n\n        # archive for elites\n        archive_X = X.copy()\n        archive_f = f.copy()\n\n        # operator success scores for bandit weighting (levy, de, pca)\n        op_scores = np.array(self.p_init, dtype=float) + 1e-6\n        op_counts = np.ones(3, dtype=float) * 1e-6\n\n        # tracking\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n        gen = 0\n        gens_since_improve = 0\n\n        # helper to add to archive and trim\n        def archive_add(x_new, f_new):\n            nonlocal archive_X, archive_f\n            archive_X = np.vstack([archive_X, x_new[np.newaxis, :]])\n            archive_f = np.concatenate([archive_f, np.array([f_new], dtype=float)])\n            max_archive = max(4 * pop, pop + 10)\n            if archive_X.shape[0] > max_archive:\n                order = np.argsort(archive_f)\n                keep = order[:max_archive]\n                archive_X = archive_X[keep]\n                archive_f = archive_f[keep]\n\n        # helper for principal eigenvector via power iteration on centered data\n        def principal_dir(data, powerits=6):\n            if data.shape[0] < 2:\n                v = rng.randn(self.dim)\n                v /= (np.linalg.norm(v) + 1e-16)\n                return v\n            Z = data - np.mean(data, axis=0)\n            C = np.dot(Z.T, Z) / max(1.0, Z.shape[0])\n            v = rng.randn(self.dim)\n            for _ in range(powerits):\n                v = np.dot(C, v)\n                n = np.linalg.norm(v)\n                if n <= 0:\n                    break\n                v /= n\n            v /= (np.linalg.norm(v) + 1e-16)\n            return v\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            # compute softmax operator probabilities based on scores\n            tempscale = 1.0\n            probs = np.exp(op_scores / tempscale)\n            probs /= np.sum(probs) + 1e-16\n            p_levy, p_de, p_pca = probs\n\n            # rank and elite indices\n            order = np.argsort(f)\n            elite_count = max(2, int(np.ceil(0.2 * pop)))\n            elite_idx = order[:elite_count]\n\n            # iterate individuals in random order\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fi = float(f[ii])\n\n                # self-adapt DE and sigma occasionally\n                if rng.rand() < self.tau_F:\n                    F[ii] = np.clip(0.4 + 0.3 * rng.randn(), 0.05, 1.0)\n                if rng.rand() < self.tau_CR:\n                    CR[ii] = np.clip(rng.rand(), 0.0, 1.0)\n                if rng.rand() < self.tau_sigma:\n                    sigma[ii] *= np.exp(0.08 * rng.randn())\n                    sigma[ii] = np.clip(sigma[ii], 1e-6, 1.0)\n\n                # choose operator by probs\n                r = rng.rand()\n                op_idx = 0\n                if r < p_levy:\n                    op_idx = 0\n                elif r < p_levy + p_de:\n                    op_idx = 1\n                else:\n                    op_idx = 2\n\n                candidate = None\n\n                # Operator 0: Lévy/Cauchy jump (heavy-tailed) around xi or x_best\n                if op_idx == 0:\n                    center = xi if rng.rand() < 0.75 else x_best\n                    scale = sigma[ii] * np.mean(ub - lb)\n                    step = cauchy_vec(scale)\n                    # coordinate-wise scale by domain\n                    step = step * ((ub - lb) / np.mean(ub - lb))\n                    candidate = reflect_clamp(center + step)\n\n                # Operator 1: DE-style current-to-pbest/1 with binomial crossover\n                elif op_idx == 1:\n                    # p-best selection\n                    pnum = max(2, int(np.ceil(0.15 * pop)))\n                    ppool = order[:pnum]\n                    pbest = X[rng.choice(ppool)]\n                    # choose r1,r2 distinct\n                    choices = [j for j in range(pop) if j != ii]\n                    if len(choices) >= 2:\n                        r1, r2 = rng.choice(choices, size=2, replace=False)\n                    else:\n                        r1 = r2 = ii\n                    v = xi + F[ii] * (pbest - xi) + F[ii] * (X[r1] - X[r2])\n                    # binomial crossover\n                    jrand = rng.randint(self.dim)\n                    mask = (rng.rand(self.dim) < CR[ii])\n                    mask[jrand] = True\n                    trial = np.where(mask, v, xi)\n                    # small Gaussian jitter scaled by sigma\n                    trial = trial + rng.randn(self.dim) * sigma[ii] * (ub - lb)\n                    candidate = reflect_clamp(trial)\n\n                # Operator 2: PCA-projected sampling from archive elites\n                else:\n                    # select top archive or elite subset\n                    if archive_X.shape[0] >= 4:\n                        a_order = np.argsort(archive_f)\n                        topk = min(max(4, elite_count), archive_X.shape[0])\n                        data = archive_X[a_order[:topk]]\n                        pc = principal_dir(data, powerits=self.max_pca_powerits)\n                    else:\n                        # fallback use elite population\n                        data = X[elite_idx]\n                        pc = principal_dir(data, powerits=2)\n                    center = X[rng.choice(elite_idx)]\n                    length = sigma[ii] * np.mean(ub - lb) * (0.5 + rng.rand() * 2.0)\n                    step = (rng.randn() * length) * pc\n                    candidate = reflect_clamp(center + step)\n\n                # evaluate candidate if budget allows\n                if candidate is None:\n                    candidate = xi.copy()\n                if evals >= self.budget:\n                    break\n                fc = float(func(candidate))\n                evals += 1\n\n                # selection and operator success bookkeeping\n                if fc < fi:\n                    X[ii] = candidate\n                    f[ii] = fc\n                    archive_add(candidate, fc)\n                    op_scores[op_idx] += 1.0  # reward success\n                    op_counts[op_idx] += 1.0\n                    if fc < f_best:\n                        f_best = fc\n                        x_best = candidate.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    op_counts[op_idx] += 1.0\n                    # small penalty/decay to op_scores to forget stale operators\n                    op_scores *= 0.999\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # Periodic cheap PCA-directed finite-difference + guarded line-search (few evals)\n            if (gen % self.local_period == 0) or (gens_since_improve >= self.stagn_threshold):\n                if evals >= self.budget:\n                    break\n                # build PCA from archive or current elites\n                try:\n                    use_data = archive_X if archive_X.shape[0] >= 6 else X[order[:max(4, elite_count)]]\n                    pc1 = principal_dir(use_data, powerits=min(self.max_pca_powerits, 12))\n                except Exception:\n                    pc1 = rng.randn(self.dim)\n                    pc1 /= (np.linalg.norm(pc1) + 1e-16)\n                # centered finite difference (two evals) if budget allows\n                eps = max(1e-8, 1e-3 * np.linalg.norm(ub - lb) * np.median(sigma))\n                if evals + 2 <= self.budget:\n                    x_fwd = reflect_clamp(x_best + eps * pc1)\n                    x_bwd = reflect_clamp(x_best - eps * pc1)\n                    f_fwd = float(func(x_fwd)); evals += 1\n                    f_bwd = float(func(x_bwd)); evals += 1\n                    deriv = (f_fwd - f_bwd) / (2.0 * eps)\n                    # propose conservative line-search step in negative derivative direction\n                    if abs(deriv) > 1e-12:\n                        step0 = (1.0 / (1.0 + abs(deriv))) * np.mean(ub - lb) * 0.15\n                        alphas = [1.0, 0.5, 0.25, 0.125]\n                        probes = 0\n                        best_local_x = x_best.copy()\n                        best_local_f = f_best\n                        improved_local = False\n                        for a in alphas:\n                            if evals >= self.budget:\n                                break\n                            step = -np.sign(deriv) * a * step0\n                            x_try = reflect_clamp(x_best + step * pc1)\n                            f_try = float(func(x_try)); evals += 1\n                            probes += 1\n                            if f_try < best_local_f:\n                                best_local_f = f_try\n                                best_local_x = x_try.copy()\n                                improved_local = True\n                                # opportunistic extension\n                                if evals < self.budget:\n                                    x_try2 = reflect_clamp(x_try + step * pc1)\n                                    f_try2 = float(func(x_try2)); evals += 1\n                                    if f_try2 < best_local_f:\n                                        best_local_f = f_try2\n                                        best_local_x = x_try2.copy()\n                                break\n                            if probes >= 6:\n                                break\n                        if improved_local:\n                            worst = int(np.argmax(f))\n                            X[worst] = best_local_x.copy()\n                            f[worst] = best_local_f\n                            archive_add(best_local_x, best_local_f)\n                            if best_local_f < f_best:\n                                f_best = best_local_f\n                                x_best = best_local_x.copy()\n                                gens_since_improve = 0\n                                improved_in_gen = True\n\n                # Hooke-Jeeves style coordinate search if still stagnating (cheap and limited)\n                if (not improved_in_gen) and (gens_since_improve >= self.stagn_threshold // 2):\n                    remaining = self.budget - evals\n                    if remaining > 0:\n                        step = max(1e-12, self.coord_initial_frac * np.mean(ub - lb))\n                        min_step = max(1e-12, self.coord_min_frac * np.mean(ub - lb))\n                        x_work = x_best.copy()\n                        f_work = f_best\n                        while step >= min_step and (self.budget - evals) > 0:\n                            moved = False\n                            for d in range(self.dim):\n                                if evals >= self.budget:\n                                    break\n                                # try positive\n                                x_try = x_work.copy()\n                                x_try[d] = min(ub[d], x_try[d] + step)\n                                if np.allclose(x_try, x_work):\n                                    x_try[d] = max(lb[d], x_work[d] - step)\n                                f_try = float(func(x_try)); evals += 1\n                                if f_try < f_work:\n                                    x_work = x_try\n                                    f_work = f_try\n                                    moved = True\n                                    if f_try < f_best:\n                                        f_best = f_try\n                                        x_best = x_try.copy()\n                                        gens_since_improve = 0\n                                    # opportunistic extra probe\n                                    if evals < self.budget:\n                                        x_try2 = x_work.copy()\n                                        x_try2[d] = min(ub[d], x_try2[d] + step)\n                                        f_try2 = float(func(x_try2)); evals += 1\n                                        if f_try2 < f_work:\n                                            x_work = x_try2\n                                            f_work = f_try2\n                                            if f_try2 < f_best:\n                                                f_best = f_try2\n                                                x_best = x_try2.copy()\n                                                gens_since_improve = 0\n                                else:\n                                    # try negative if positive failed\n                                    if evals >= self.budget:\n                                        break\n                                    x_try = x_work.copy()\n                                    x_try[d] = max(lb[d], x_work[d] - step)\n                                    f_try = float(func(x_try)); evals += 1\n                                    if f_try < f_work:\n                                        x_work = x_try\n                                        f_work = f_try\n                                        moved = True\n                                        if f_try < f_best:\n                                            f_best = f_try\n                                            x_best = x_try.copy()\n                                            gens_since_improve = 0\n                            if not moved:\n                                step *= self.coord_shrink\n                            # guard: limit number of coordinate steps to preserve budget\n                            if (self.budget - evals) <= 0:\n                                break\n                        if f_work < np.max(f):\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = x_work.copy()\n                            f[worst_idx] = f_work\n                            archive_add(x_work, f_work)\n                            if f_work < f_best:\n                                f_best = f_work\n                                x_best = x_work.copy()\n                                gens_since_improve = 0\n                                improved_in_gen = True\n\n                # mild diversification if very stagnant\n                if (not improved_in_gen) and (gens_since_improve >= self.stagn_threshold):\n                    nudge_count = max(1, pop // 3)\n                    for k in range(nudge_count):\n                        if evals >= self.budget:\n                            break\n                        jitter = 0.06 * (ub - lb) * rng.randn(self.dim)\n                        x_new = reflect_clamp(x_best + jitter)\n                        f_new = float(func(x_new)); evals += 1\n                        # replace some worse-than-median individual\n                        med = np.median(f)\n                        candidates = np.where(f > med)[0]\n                        if candidates.size == 0:\n                            replace_idx = int(np.argmax(f))\n                        else:\n                            replace_idx = int(rng.choice(candidates))\n                        X[replace_idx] = x_new\n                        f[replace_idx] = f_new\n                        archive_add(x_new, f_new)\n                        if f_new < f_best:\n                            f_best = f_new\n                            x_best = x_new.copy()\n                            gens_since_improve = 0\n                            improved_in_gen = True\n\n            # synchronize best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n            # soft decay of operator scores to remain adaptive\n            op_scores *= 0.995\n\n            # exit early if budget exhausted\n            if evals >= self.budget:\n                break\n\n        # final result\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HybridAdaptiveLevyDE_PCA scored 0.386 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "93890e17-e490-4bd2-83de-00a7a8d5b2b0", "operator": null, "metadata": {"aucs": [0.10646409776807819, 0.14755365853704627, 0.48311862140446926, 0.9865139187084434, 0.3649575780134109, 0.7099197804929975, 0.2819971209946228, 0.36960448176439353, 0.24445882012803077, 0.1699338468858611]}, "task_prompt": ""}
{"id": "95f3994c-9e78-49cc-9f41-c03e4caf883f", "fitness": 0.0, "name": "CentroidLevyPatternDE", "description": "CentroidLevyPatternDE is a hybrid, budget-aware DE that combines a small quasi‑uniform population with SHADE‑style parameter memory (H default 10, Lehmer mean updates for F and weighted mean for CR) to keep adaptive F/CR while allowing many generations. Mutation is centroid‑directed (xi + F*(centroid-xi) + F*(xr1-xr2)) plus small Gaussian jitter to bias search toward promising regions, and an elite archive is maintained for mirrored probes, mirrored injections, jittered restarts, and as anchors for heavy‑tailed Lévy/Cauchy global jumps (levy_prob default 0.03) to escape basins. The algorithm uses budget‑aware Hooke–Jeeves local pattern search around top points (local_budget_frac default 0.04), reflect‑then‑clamp boundary handling, and adaptive global_jump_prob based on archive clustering to increase exploration when elites cluster. Additional pragmatic choices include stratified initialization per dimension for coverage, small population sizing (~2*sqrt(dim)+4), periodic mirrored Gaussian probes and stagnation reseeding, and keeping an archive of limited size to prioritise elite replacement.", "code": "import numpy as np\n\nclass CentroidLevyPatternDE:\n    \"\"\"\n    Centroid-LevyPatternDE\n\n    - Small quasi-uniform population with SHADE-like memory for F/CR.\n    - Mutation: centroid-directed + differential term (xi + F*(centroid-xi) + F*(xr1-xr2)).\n    - Maintain an elite archive used for mirrored probes, jittered restarts and heavy-tailed jumps.\n    - Occasional Lévy/Cauchy global jumps from archive elites to escape basins.\n    - Budget-aware Hooke-Jeeves style local pattern search around promising points.\n    - Mirrored Gaussian probes for variance reduction and adaptive global-jump probability when archive clusters.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, pop_base=None,\n                 H=10, p_frac=0.2, local_budget_frac=0.04,\n                 levy_prob=0.03, mirror_prob=0.08, rng_seed=None,\n                 archive_size=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.H = max(1, int(H))\n        self.p_frac = float(p_frac)\n        self.local_budget_frac = float(local_budget_frac)\n        self.levy_prob = float(levy_prob)\n        self.mirror_prob = float(mirror_prob)\n        self.rng_seed = rng_seed\n        self.archive_size = archive_size\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds handling (respect func bounds)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = ub - lb\n        avg_span = float(np.mean(bounds_scale))\n\n        # population size (small to allow many generations)\n        if self.pop_base is None:\n            pop = max(8, int(2 * np.sqrt(max(1, self.dim)) + 4))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # quasi-uniform initialization (per-dim stratified)\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # small jitter\n        X += (rng.rand(pop, self.dim) - 0.5) * (0.4 * bounds_scale / max(1.0, self.dim))\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.empty(pop, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # SHADE-like memory\n        H = self.H\n        mem_F = np.full(H, 0.5, dtype=float)\n        mem_CR = np.full(H, 0.5, dtype=float)\n        mem_pos = 0\n\n        # per-individual placeholders\n        F_pop = np.clip(0.5 + 0.1 * rng.randn(pop), 0.05, 0.95)\n        CR_pop = np.clip(rng.rand(pop), 0.0, 1.0)\n\n        # archive (elite set)\n        if self.archive_size is None:\n            archive_size = max(3, min(12, pop))\n        else:\n            archive_size = int(self.archive_size)\n        archive_X = X.copy()\n        archive_f = f.copy()\n\n        def archive_add(xvec, fx):\n            nonlocal archive_X, archive_f\n            if archive_f.size < archive_size:\n                archive_X = np.vstack([archive_X, xvec.reshape(1, -1)])\n                archive_f = np.concatenate([archive_f, np.array([fx])])\n            else:\n                worst = int(np.argmax(archive_f))\n                if fx < archive_f[worst]:\n                    archive_X[worst] = xvec.copy()\n                    archive_f[worst] = fx\n\n        # fill archive to size with current population (trim or keep)\n        if archive_f.size > archive_size:\n            order = np.argsort(archive_f)[:archive_size]\n            archive_X = archive_X[order].copy()\n            archive_f = archive_f[order].copy()\n\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n\n        # helper: reflect then clamp as in No.5\n        def reflect_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        # Hooke-Jeeves like local pattern search (budget-aware)\n        def local_pattern_search(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive_X, archive_f\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            # initial per-dim steps proportional to bounds\n            step = 0.25 * bounds_scale\n            step = np.maximum(step, 1e-12)\n            shrink = 0.6\n            pattern_factor = 1.5\n            local_used = 0\n            # iterate until budget or steps small\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_used < local_budget and iters < iter_limit and np.any(step > 1e-12):\n                iters += 1\n                improved = False\n                probe = base.copy()\n                probe_f = base_f\n                order = list(range(self.dim))\n                rng.shuffle(order)\n                for i in order:\n                    if local_used >= local_budget or evals >= self.budget:\n                        break\n                    # positive\n                    xp = probe.copy()\n                    xp[i] += step[i]\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    fv = float(func(xp))\n                    evals += 1\n                    local_used += 1\n                    if fv < probe_f:\n                        probe = xp.copy()\n                        probe_f = fv\n                        improved = True\n                        step[i] *= 1.2\n                        continue\n                    # negative\n                    xn = probe.copy()\n                    xn[i] -= step[i]\n                    xn = np.minimum(np.maximum(xn, lb), ub)\n                    fv2 = float(func(xn))\n                    evals += 1\n                    local_used += 1\n                    if fv2 < probe_f:\n                        probe = xn.copy()\n                        probe_f = fv2\n                        improved = True\n                        step[i] *= 1.2\n                # pattern move\n                if improved and local_used < local_budget and evals < self.budget:\n                    direction = probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        fv = float(func(xp))\n                        evals += 1\n                        local_used += 1\n                        if fv < probe_f:\n                            base = xp.copy()\n                            base_f = fv\n                        else:\n                            base = probe.copy()\n                            base_f = probe_f\n                    else:\n                        base = probe.copy()\n                        base_f = probe_f\n                else:\n                    step *= shrink\n                if evals >= self.budget:\n                    break\n            # update archive with final base\n            archive_add(base.copy(), base_f)\n            if base_f < f_best:\n                f_best = base_f\n                x_best = base.copy()\n            return base_f, base\n\n        gen = 0\n        gens_since_improve = 0\n        success_steps = []\n\n        # adaptive global jump probability, increased when archive clustered\n        global_jump_prob = 0.02\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            improved_in_gen = False\n\n            # ranking and centroid\n            order = np.argsort(f)\n            pnum = max(2, int(np.ceil(self.p_frac * pop)))\n            p_pool = order[:pnum]\n            centroid = np.mean(X[p_pool], axis=0)\n\n            # prepare success lists for memory update\n            succ_F = []\n            succ_CR = []\n            succ_w = []\n\n            # occasionally perform mirrored Gaussian probes around centroid or best\n            if (rng.rand() < self.mirror_prob) and remaining > 1:\n                # generate mirrored pair centered at centroid or best\n                anchor = centroid if rng.rand() < 0.5 else x_best\n                A = np.eye(self.dim)  # simple isotropic mirror via normal\n                Z = rng.normal(size=(2, self.dim))\n                cand1 = anchor + 0.15 * avg_span * Z[0]\n                cand2 = 2.0 * anchor - cand1\n                cand1 = np.minimum(np.maximum(cand1, lb), ub)\n                cand2 = np.minimum(np.maximum(cand2, lb), ub)\n                # evaluate both if budget allows\n                if evals < self.budget:\n                    fv1 = float(func(cand1))\n                    evals += 1\n                    archive_add(cand1.copy(), fv1)\n                    if fv1 < f_best:\n                        f_best = fv1; x_best = cand1.copy(); improved_in_gen = True; gens_since_improve = 0\n                if evals < self.budget:\n                    fv2 = float(func(cand2))\n                    evals += 1\n                    archive_add(cand2.copy(), fv2)\n                    if fv2 < f_best:\n                        f_best = fv2; x_best = cand2.copy(); improved_in_gen = True; gens_since_improve = 0\n\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                # sample memory index and parameters (SHADE-like)\n                mem_i = rng.randint(H)\n                # sample F from Cauchy around mem_F[mem_i], robustified\n                attempts = 0\n                Fi = None\n                while attempts < 7:\n                    Fi = mem_F[mem_i] + 0.1 * rng.standard_cauchy()\n                    if Fi > 1e-6 and np.isfinite(Fi):\n                        break\n                    attempts += 1\n                if Fi is None or not np.isfinite(Fi):\n                    Fi = 0.5\n                Fi = float(np.clip(Fi, 0.01, 1.0))\n                CRi = float(np.clip(mem_CR[mem_i] + 0.1 * rng.randn(), 0.0, 1.0))\n                F_pop[ii] = Fi\n                CR_pop[ii] = CRi\n\n                # pick r1, r2 distinct from ii\n                pool = [j for j in range(pop) if j != ii]\n                if len(pool) >= 2:\n                    r1, r2 = rng.choice(pool, size=2, replace=False)\n                elif len(pool) == 1:\n                    r1 = r2 = pool[0]\n                else:\n                    r1 = r2 = ii\n\n                xi = X[ii].copy()\n                xr1 = X[r1].copy()\n                xr2 = X[r2].copy()\n\n                # decide to perform a heavy-tailed global jump instead of ordinary mutation\n                do_levy = (rng.rand() < self.levy_prob) or (rng.rand() < global_jump_prob and archive_f.size > 0)\n                if do_levy and archive_f.size > 0 and remaining > 0:\n                    # choose anchor from elite archive biased to best\n                    choose_best = rng.rand() < 0.8\n                    if choose_best:\n                        anchor = archive_X[np.argmin(archive_f)].copy()\n                    else:\n                        idxa = int(rng.randint(0, archive_f.size))\n                        anchor = archive_X[idxa].copy()\n                    # heavy-tailed step: Cauchy scaled by avg_span and random anisotropy\n                    step_len = rng.standard_cauchy()\n                    step_len = np.clip(step_len, -1e3, 1e3)\n                    anis = 0.3 + 0.7 * rng.rand()\n                    direction = rng.randn(self.dim)\n                    nd = np.linalg.norm(direction) + 1e-12\n                    direction /= nd\n                    scale = max(0.03, 0.5 * (1.0 - float(evals) / max(1, self.budget)))  # focus over time\n                    mutant = anchor + step_len * direction * (scale * avg_span * anis)\n                    vi = mutant\n                else:\n                    # centroid-directed mutation\n                    vi = xi + Fi * (centroid - xi) + Fi * (xr1 - xr2)\n\n                # occasional small Gaussian jitter to maintain exploration\n                vi += rng.normal(scale=0.02 * avg_span, size=self.dim)\n\n                # binomial crossover\n                jrand = rng.randint(self.dim)\n                mask = rng.rand(self.dim) < CRi\n                mask[jrand] = True\n                trial = np.where(mask, vi, xi)\n                trial = reflect_clamp(trial)\n\n                # ensure we don't exceed budget\n                if evals >= self.budget:\n                    break\n                fv = float(func(trial))\n                evals += 1\n\n                # archive add\n                archive_add(trial.copy(), fv)\n\n                # selection\n                if fv <= f[ii]:\n                    # success: replace and record\n                    old_f = f[ii]\n                    step_vec = trial - X[ii]\n                    if np.linalg.norm(step_vec) > 0:\n                        success_steps.append(step_vec.copy())\n                        if len(success_steps) > 2 * self.dim:\n                            success_steps.pop(0)\n                    X[ii] = trial.copy()\n                    f[ii] = fv\n                    succ_F.append(Fi)\n                    succ_CR.append(CRi)\n                    # weight by improvement amount (use positive improvement)\n                    w = max(1e-12, abs(old_f - fv))\n                    succ_w.append(w)\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = trial.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # SHADE-like memory update (Lehmer mean for F)\n            if len(succ_F) > 0:\n                sF = np.asarray(succ_F)\n                sCR = np.asarray(succ_CR)\n                sw = np.asarray(succ_w)\n                if sw.sum() > 0:\n                    w = sw / sw.sum()\n                else:\n                    w = np.ones_like(sw) / len(sw)\n                numer = np.sum(w * (sF ** 2))\n                denom = np.sum(w * sF) + 1e-12\n                new_mF = numer / denom\n                new_mCR = np.sum(w * sCR)\n                mem_F[mem_pos] = 0.9 * mem_F[mem_pos] + 0.1 * float(np.clip(new_mF, 1e-3, 1.0))\n                mem_CR[mem_pos] = 0.9 * mem_CR[mem_pos] + 0.1 * float(np.clip(new_mCR, 0.0, 1.0))\n                mem_pos = (mem_pos + 1) % H\n\n            # occasional budget-aware Hooke-Jeeves local refinements around best or a good archive member\n            if (gen % max(8, int(8 - self.dim / 10)) == 0) and (evals < self.budget):\n                # allocate a small local budget fraction\n                local_alloc = min(int(self.local_budget_frac * self.budget), max(2, self.budget - evals - 1))\n                if local_alloc > 0:\n                    # pick start point: sometimes best, else a top archive member\n                    if rng.rand() < 0.8 or archive_f.size == 0:\n                        start_x = x_best.copy()\n                        start_f = f_best\n                    else:\n                        idxa = int(rng.randint(0, archive_f.size))\n                        start_x = archive_X[idxa].copy()\n                        start_f = float(archive_f[idxa])\n                    # jitter small amount to avoid exact repeats\n                    jitter = (rng.randn(self.dim) * 0.03 * avg_span)\n                    start_x = np.minimum(np.maximum(start_x + jitter, lb), ub)\n                    # evaluate start_x if needed\n                    if evals < self.budget:\n                        start_f = float(func(start_x))\n                        evals += 1\n                        archive_add(start_x.copy(), start_f)\n                        if start_f < f_best:\n                            f_best = start_f; x_best = start_x.copy(); gens_since_improve = 0\n                    # perform local search\n                    f_after, x_after = local_pattern_search(start_x, start_f, local_alloc)\n                    # inject improvement\n                    if f_after < np.max(f):\n                        worst_idx = int(np.argmax(f))\n                        X[worst_idx] = x_after.copy()\n                        f[worst_idx] = f_after\n\n            # adjust global_jump_prob based on archive clustering\n            if archive_f.size >= 2:\n                # measure diversity between best and worst archive member\n                diversity = np.linalg.norm(archive_X[np.argmin(archive_f)] - archive_X[np.argmax(archive_f)])\n                if diversity < 1e-12 + 0.02 * avg_span:\n                    global_jump_prob = min(0.25, global_jump_prob + 0.02)\n                else:\n                    global_jump_prob = max(0.01, global_jump_prob * 0.995)\n\n            # occasional mirrored injection to maintain diversity\n            if (gen % 17) == 0 and evals < self.budget:\n                anchor = x_best.copy() if rng.rand() < 0.7 else centroid\n                z = rng.normal(size=self.dim)\n                cand = anchor + 0.18 * avg_span * z\n                cand_mirror = 2.0 * anchor - cand\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                cand_mirror = np.minimum(np.maximum(cand_mirror, lb), ub)\n                if evals < self.budget:\n                    fv = float(func(cand)); evals += 1; archive_add(cand.copy(), fv)\n                    if fv < f_best: f_best = fv; x_best = cand.copy(); gens_since_improve = 0\n                if evals < self.budget:\n                    fv2 = float(func(cand_mirror)); evals += 1; archive_add(cand_mirror.copy(), fv2)\n                    if fv2 < f_best: f_best = fv2; x_best = cand_mirror.copy(); gens_since_improve = 0\n\n            # periodic stagnation reseed: jitter half population around best\n            if gens_since_improve > max(30, int(0.03 * self.budget)) and evals < self.budget:\n                half = max(1, pop // 2)\n                for k in range(half):\n                    if evals >= self.budget:\n                        break\n                    jitter = rng.randn(self.dim) * (0.06 * bounds_scale)\n                    newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                    fv = float(func(newx))\n                    evals += 1\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = newx.copy()\n                    f[worst_idx] = fv\n                    archive_add(newx.copy(), fv)\n                    if fv < f_best:\n                        f_best = fv; x_best = newx.copy(); gens_since_improve = 0\n\n            # sync best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n\n        # finish\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CentroidLevyPatternDE scored 0.000 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "93890e17-e490-4bd2-83de-00a7a8d5b2b0", "operator": null, "metadata": {"aucs": [0]}, "task_prompt": ""}
{"id": "4ed544b1-f90e-4f66-9add-6e6d96fc009c", "fitness": "-inf", "name": "ELTR", "description": "The optimizer maintains a Gaussian search distribution parameterized by a mean m, global scale sigma and a cheap low-rank+diagonal covariance (orthonormal low-rank factor U of default small rank, per-coordinate residual v) so it can generate correlated anisotropic samples with low cost (pop_base scales weakly with dim, arch_size ≈ 4*dim, buffer_size ≈ 8*rank). It fits a local quadratic model by weighted ridge regression on features [dx, 0.5 dx^2] from a FIFO archive to estimate a linear term and diagonal Hessian, then proposes curvature-aware Newton-like trust-region steps clipped by an adaptive radius rho (trust_init=0.6·span, trust_expand=1.2, trust_shrink=0.7). Successful normalized steps are stored in a buffer and periodically analyzed by SVD/PCA (pca_period=7) to update U and eigen-energies w (with smoothing), while archive recombination, differential-like blends and occasional global long-leaps (leap_prob≈0.03) provide exploration and escape from traps; restarts inflate sigma and reset low-rank structure when stagnation is detected. Adaptation and selection use a smoothed success probability (EMA p_smooth≈0.9, sigma_adapt_rate≈0.25) to multiplicatively change sigma, softmax-biased selection among candidates, a decaying uphill-acceptance temperature T, and strict bound clamping.", "code": "import numpy as np\n\nclass ELTR:\n    \"\"\"\n    Ensemble Low-Rank Trust-region & Recombination Optimizer (ELTR)\n\n    Main ideas / novel mechanisms:\n    - Maintain a mean m and a global scale sigma, plus a low-rank covariance factor U (dim x r)\n      and a diagonal residual variance v. Samples are drawn as m + sigma*(diag(sqrt(v))*eps_d + U*(sqrt(w)*eps_r)),\n      yielding cheap correlated anisotropic sampling with tunable rank.\n    - Maintain a recent FIFO archive and fit a local quadratic model (linear term g and diagonal Hessian diagH)\n      by weighted ridge regression using features [x-m, 0.5*(x-m)**2]. Use that to propose curvature-aware\n      trust-region steps: step = -H^{-1} g clipped to current trust radius rho.\n    - Keep a buffer of recent \"successful normalized steps\" and periodically compute the top-r PCA directions\n      (SVD on the buffer) to update U and associated eigen-energies w (cheap rotation update).\n    - Use archive recombination (convex mixtures and differential-like moves) and occasional stochastic long-leaps\n      (global jumps) to escape local traps.\n    - Adaptive sigma via smoothed success rate (multiplicative updates), adaptive trust radius rho,\n      and opportunistic restart when stagnation is detected.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop_base=None, rank=3, arch_size=None, buffer_size=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # algorithm hyperparameters (sensible defaults, some adapt automatically)\n        self.rank = int(min(rank, dim))  # low-rank approximation rank\n        self.pop_base = pop_base if pop_base is not None else max(8, int(5 + 1.2 * np.log(max(2, dim))))\n        self.arch_size = arch_size if arch_size is not None else max(4 * dim, 30)\n        self.buffer_size = buffer_size if buffer_size is not None else max(8 * self.rank, 3 * self.rank + 10)\n\n        # adaptation params\n        self.succ_target = 0.25\n        self.sigma_adapt_rate = 0.25   # exponent base\n        self.p_smooth = 0.9            # EMA for success probability\n        self.trust_shrink = 0.7\n        self.trust_expand = 1.2\n        self.trust_init = 0.6\n        self.trust_min = 1e-6\n        self.trust_max = 5.0\n\n        # PCA update cadence and other safety\n        self.pca_period = 7\n        self.diag_reg = 1e-8\n        self.s_min = 1e-4\n        self.s_max = 5.0\n\n        # stagnation and restart\n        self.stagn_frac = 0.06\n        self.restart_inflate = 1.8\n\n        # long-leap frequency\n        self.leap_prob = 0.03\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds (func provides .bounds with lb, ub scalars or arrays)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # initialize mean m in bounds, sigma relative to bounds\n        bounds_scale = (ub - lb)\n        avg_span = np.mean(bounds_scale)\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(1e-8, 0.12 * avg_span)\n\n        # low-rank factor U (columns are orthonormal directions), eigen-energies w, diag residual v\n        r = self.rank\n        if r > 0:\n            # start with small random orthonormal base\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :r]\n            w = np.full(r, 0.15)  # energies of low-rank directions\n        else:\n            U = np.zeros((self.dim, 0))\n            w = np.array([])\n\n        # diagonal residual variance (per-coordinate)\n        v = np.full(self.dim, 0.3)\n        # small per-coordinate EMA scale for normalization\n        s = np.ones(self.dim)\n\n        # archive and buffers\n        X_arch = []\n        f_arch = []\n        buffer_steps = []  # stores normalized steps (rows) for PCA\n\n        # initialize: seed with a small population to populate archive\n        evals = 0\n        init_pop = min(self.pop_base, max(6, self.budget // 60))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(f)\n\n        # ensure at least one point\n        if len(f_arch) == 0:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(f)\n\n        # best so far\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # smoothed success rate and temperature-like parameter (for acceptance)\n        p_succ = 0.2\n        T = 0.6 * avg_span  # scale of uphill tolerance (not probability temperature in energy units)\n\n        # trust region radius\n        rho = self.trust_init * avg_span\n\n        # stagnation detection\n        stagn_limit = max(5, int(self.stagn_frac * self.budget))\n        stagn_count = 0\n\n        gen = 0\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            lam = max(1, lam)\n\n            candidates = []\n            c_types = []\n\n            # 1) Low-rank correlated Gaussian sampling (majority)\n            n_gauss = max(1, int(0.55 * lam))\n            if n_gauss > 0:\n                # sample diagonal noise\n                eps_d = rng.randn(n_gauss, self.dim) * np.sqrt(np.maximum(v, self.diag_reg))\n                # low-rank contribution\n                if r > 0 and U.shape[1] > 0:\n                    eps_r = rng.randn(n_gauss, r) * np.sqrt(np.maximum(w, self.diag_reg))\n                    low = eps_r @ U.T\n                else:\n                    low = np.zeros((n_gauss, self.dim))\n                Xg = m.reshape(1, -1) + sigma * (eps_d + low)\n                candidates.extend(Xg.tolist())\n                c_types.extend(['gauss'] * Xg.shape[0])\n\n            # 2) Trust-region (curvature-aware) proposals from local quadratic fit\n            quad_proposed = 0\n            if len(X_arch) >= max(6, self.dim // 4):\n                # Build features F = [dx, 0.5*dx^2] to estimate linear term g and diagonal Hessian diagH\n                X_arr = np.asarray(X_arch)\n                f_arr = np.asarray(f_arch)\n                # center at current mean m\n                dx = X_arr - m.reshape(1, -1)\n                # weights: favor near and good points\n                dist = np.linalg.norm(dx / (np.sqrt(v + 1e-12)), axis=1)\n                wdist = np.exp(-0.8 * dist)\n                frank = np.exp(-1.0 * (f_arr - np.min(f_arr)) / (np.ptp(f_arr) + 1e-12))\n                weights = wdist * (0.5 + 0.5 * frank)\n                W = np.sqrt(weights).reshape(-1, 1)\n\n                # design matrix: [dx, 0.5*dx^2] shape (n, 2*dim)\n                X_design = np.hstack([dx, 0.5 * (dx ** 2)])\n                y = (f_arr - np.min(f_arr))  # reduce scale by best known in archive\n\n                # ridge regularization\n                reg = 1e-6\n                try:\n                    A = (W * X_design).T @ (W * X_design) + reg * np.eye(X_design.shape[1])\n                    b = (W * X_design).T @ (W * y)\n                    theta = np.linalg.solve(A, b)\n                    g_est = theta[:self.dim].copy()\n                    diagH_est = np.abs(theta[self.dim:])  # force non-negative curvature\n                    # form an approximate inverse diag\n                    Hinv = 1.0 / (diagH_est + 1e-6)\n                    # proposed Newton-like step\n                    step = - Hinv * g_est\n                    # clip step to trust-region rho\n                    step_norm = np.linalg.norm(step)\n                    max_step = max(1e-12, rho)\n                    if step_norm > max_step:\n                        step = step * (max_step / step_norm)\n                    x_trust = m + step\n                    candidates.append(x_trust)\n                    c_types.append('trust')\n                    quad_proposed += 1\n\n                    # also propose a damped step (half-step) and a randomized perturbed trust step\n                    x_trust2 = m + 0.5 * step + 0.6 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, 1e-12))\n                    candidates.append(x_trust2)\n                    c_types.append('trust')\n\n                    quad_proposed += 1\n                except np.linalg.LinAlgError:\n                    # skip if ill-conditioned\n                    pass\n\n            # 3) Archive recombinations (convex blends and differential moves)\n            n_recomb = lam - len(candidates)\n            for _ in range(n_recomb):\n                if len(X_arch) >= 3:\n                    # fitness-biased selection\n                    f_arr = np.asarray(f_arch)\n                    probs = (np.max(f_arr) - f_arr + 1e-12)\n                    probs = probs / np.sum(probs)\n                    a_idx, b_idx = rng.choice(len(X_arch), size=2, replace=False, p=probs)\n                    a = X_arch[a_idx]\n                    b = X_arch[b_idx]\n                    alpha = rng.rand()\n                    xrec = alpha * a + (1 - alpha) * b\n                    # differential-like extra direction: pick third\n                    c_idx = rng.choice(len(X_arch))\n                    c = X_arch[c_idx]\n                    diff = (a - b)\n                    xrec = xrec + 0.5 * rng.rand() * diff + 0.4 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, 1e-12))\n                    candidates.append(xrec)\n                    c_types.append('recomb')\n                else:\n                    # random fallback\n                    candidates.append(rng.uniform(lb, ub, size=self.dim))\n                    c_types.append('recomb')\n\n            # 4) occasional long leap (global exploration)\n            if rng.rand() < self.leap_prob and remaining - len(candidates) > 0:\n                leap = rng.uniform(lb, ub, size=self.dim)\n                candidates.append(leap)\n                c_types.append('leap')\n\n            # clamp candidates to bounds\n            Xcand = np.asarray([np.minimum(np.maximum(np.array(x), lb), ub) for x in candidates])\n            fc = np.full(Xcand.shape[0], np.inf)\n\n            # Evaluate sequentially until budget exhausted\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                x = Xcand[i]\n                f = float(func(x))\n                evals += 1\n                fc[i] = f\n\n                # update archive FIFO\n                X_arch.append(x.copy())\n                f_arch.append(f)\n                if len(X_arch) > self.arch_size:\n                    del X_arch[0]\n                    del f_arch[0]\n\n                # update global best\n                if f < f_best:\n                    f_best = f\n                    x_best = x.copy()\n                    stagn_count = 0\n                else:\n                    stagn_count += 1\n\n            # cut invalid evaluations if budget ended\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                c_types = [c_types[i] for i in range(len(c_types)) if valid[i]]\n\n            if fc.size == 0:\n                break\n\n            # choose candidate(s) to influence mean: biased by softmax of negative objective (favor low f)\n            fmin_local = np.min(fc)\n            scores = np.exp(- (fc - fmin_local) / (np.std(fc) + 1e-12))\n            probs = scores / np.sum(scores)\n            chosen_idx = rng.choice(len(Xcand), p=probs)\n            chosen_x = Xcand[chosen_idx].copy()\n            chosen_f = float(fc[chosen_idx])\n\n            # acceptance rule: accept if improves best or with probability exp(-(f - f_ref)/T)\n            # use a reference f_ref that is the better of current global best and local min to avoid double-counting\n            f_ref = min(f_best, np.min(fc))\n            delta = chosen_f - f_ref\n            accept = False\n            if chosen_f <= f_best:\n                accept = True\n            else:\n                # probabilistic uphill acceptance with gaussian-like scale T\n                if T > 1e-12 and rng.rand() < np.exp(-max(0.0, delta) / (T + 1e-12)):\n                    accept = True\n\n            if accept:\n                # move mean moderately toward chosen_x, step-size depends on type\n                if c_types[chosen_idx] == 'trust':\n                    eta = 0.35\n                elif c_types[chosen_idx] == 'gauss':\n                    eta = 0.18\n                elif c_types[chosen_idx] == 'recomb':\n                    eta = 0.22\n                else:\n                    eta = 0.15\n                m = (1.0 - eta) * m + eta * chosen_x\n            else:\n                # exploratory perturbation\n                m = m + 0.08 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, 1e-12))\n                # keep in bounds\n                m = np.minimum(np.maximum(m, lb), ub)\n\n            # compute normalized steps for all evaluated candidates in this generation\n            # normalized in units of sigma and sqrt(v) to capture anisotropy\n            denom = sigma * np.sqrt(np.maximum(v, 1e-12))\n            deltas_norm = (Xcand - m.reshape(1, -1)) / (denom.reshape(1, -1))\n\n            # update per-coordinate EMA s (scale for normalization)\n            stat = np.mean(np.abs(deltas_norm), axis=0)\n            alpha = 0.75\n            s = alpha * s + (1 - alpha) * (stat + 1e-12)\n            s = np.clip(s, self.s_min, self.s_max)\n\n            # record good normalized steps (improving candidates relative to f_best or local best)\n            success_mask = (fc <= (fmin_local + 1e-12))  # local successes in this batch\n            # include some of the chosen even if not best\n            success_mask[chosen_idx] = True\n            for i in range(len(deltas_norm)):\n                if success_mask[i]:\n                    buffer_steps.append(deltas_norm[i].copy())\n                    if len(buffer_steps) > self.buffer_size:\n                        del buffer_steps[0]\n\n            # Periodic PCA / low-rank update from buffer\n            if (gen % self.pca_period == 0) and len(buffer_steps) >= max(3, self.rank):\n                B = np.asarray(buffer_steps)  # shape (k, dim)\n                # center rows\n                Bc = B - np.mean(B, axis=0, keepdims=True)\n                try:\n                    # SVD on Bc: Bc = U_s S Vt ; Vt rows are principal directions in dim-space\n                    U_s, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    # top-r directions\n                    r_eff = min(self.rank, Vt.shape[0])\n                    if r_eff > 0:\n                        U_new = Vt[:r_eff].T  # dim x r_eff\n                        # energies from singular values, scale to variance units\n                        eig_energy = (S_s[:r_eff] ** 2) / max(1, Bc.shape[0] - 1)\n                        # small smoothing with previous U/w if shapes match\n                        if U.shape[1] == r_eff:\n                            U = 0.8 * U + 0.2 * U_new\n                            w = 0.7 * w + 0.3 * (eig_energy / (np.mean(eig_energy) + 1e-12))\n                        else:\n                            # replace directly if shapes differ\n                            U = U_new\n                            w = eig_energy / (np.mean(eig_energy) + 1e-12)\n                        # clip energies\n                        w = np.clip(w, 1e-4, 5.0)\n                        # adjust residual diagonal v to keep total variance balanced:\n                        explained = np.sum(w)\n                        total_var_target = np.mean(np.var(Bc, axis=0) + 1e-6)\n                        # heuristically set v to fill remainder of variance (uniformly)\n                        rem = max(1e-6, total_var_target - explained / max(1, r_eff))\n                        v = 0.6 * v + 0.4 * np.clip(rem * np.ones(self.dim), 1e-6, 4.0)\n                except np.linalg.LinAlgError:\n                    # ignore PCA update this round\n                    pass\n\n            # adaptation of sigma based on smoothed success\n            gen_success = float(np.any(success_mask))\n            p_succ = self.p_smooth * p_succ + (1.0 - self.p_smooth) * gen_success\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            # clip sigma reasonable\n            sigma = np.clip(sigma, 1e-10, 3.0 * avg_span)\n\n            # adapt trust region rho using simple rule: if trust proposals improved, expand, else shrink\n            if 'trust' in [c_types[i] for i in range(len(c_types)) if success_mask[i]]:\n                rho = min(self.trust_max, rho * self.trust_expand)\n            else:\n                rho = max(self.trust_min, rho * self.trust_shrink)\n\n            # temperature decay (for uphill acceptance)\n            T *= 0.995\n            T = max(1e-8, T)\n\n            # opportunistic restart if stagnation\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # jump around best with inflated sigma and reset low-rank & buffers\n                jitter = max(0.06 * avg_span, 0.6 * sigma)\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                sigma = max(sigma * self.restart_inflate, 0.2 * avg_span)\n                rho = max(rho, 0.8 * avg_span)\n                # reset low-rank\n                if self.rank > 0:\n                    A = rng.randn(self.dim, self.rank)\n                    Q, _ = np.linalg.qr(A)\n                    U = Q[:, :self.rank]\n                    w = np.full(self.rank, 0.2)\n                v = np.full(self.dim, 0.4)\n                buffer_steps = []\n                # cool down or bump temperature\n                T = max(T, 0.5 * avg_span)\n\n        # finalize best\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 193, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x_trust = m + step", "error": "In the code, line 193, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x_trust = m + step", "parent_ids": "ab6afe0d-0bde-4d10-b826-cc3e4f5b876d", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "740ac775-4bf2-4c3a-b8b8-617781555491", "fitness": "-inf", "name": "DMAS", "description": "DMAS samples in a rotated coordinate system (orthonormal Q) with per-coordinate multiplicative scales and a relatively large initial sigma, where Q is initialized slightly random and periodically perturbed toward recent successful step covariances then re-orthonormalized by QR for stability. Adaptation uses an additive update on log-sigma toward a success target (sigma_log_lr and succ_target), high-EMA smoothing of per-coordinate scales (momentum_beta) with clipping (coord_scale_clip), and clamped sigma bounds plus a restart inflation factor (restart_inflate) to avoid collapse. Variation mixes rotated axis-scaled Gaussian draws, directional probes derived from a simple pseudo-gradient fit to recent archive entries, and differential-style recombination from the FIFO archive (arch_size ≈ 2*dim), while selection uses an exponential rank-weighted mean of the top-k elites and a Metropolis-style acceptance controlled by a linearly decaying temperature. Algorithmic pragmatics favor small-to-moderate population (pop_base ~ sqrt(dim)), a compact archive, stagnation detection (stagnation_frac) that triggers best-centered restarts with jitter, and many numerical safeguards (QR fallback, clipping, regularization) for robust BBOB-style continuous optimization.", "code": "import numpy as np\n\nclass DMAS:\n    \"\"\"\n    Directional Memory Adaptive Search (DMAS)\n\n    Key ideas (differences vs. the provided AMGRE):\n    - Different scaling rules: larger initial sigma, log-sigma additive adaptation (instead of pure multiplicative exponent),\n      and a different target success rate.\n    - Smaller archive (2*dim) and a population size that grows with sqrt(dim) instead of log(dim).\n    - Rotation is updated by adding a small low-rank alignment matrix and re-orthonormalizing with QR\n      (different rotation equation/mechanism vs. incremental Givens-plane updates).\n    - Per-coordinate scales use a higher EMA momentum and wider clipping bounds.\n    - Rank-weighted mean update using the top-k elites (instead of a single chosen parent weighted by 1/f).\n    - Directional probes built from recent archive differences (pseudo-gradients) but simpler weighting.\n    - Linear temperature decay and different stagnation / restart heuristics.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # Algorithm hyper-parameters (intentionally different choices from AMGRE)\n        # Population scales with sqrt(dim) (not log)\n        self.pop_base = max(6, int(8 + np.sqrt(max(1, self.dim))))\n        # Archive is smaller: ~2*dim (not 4*dim)\n        self.arch_size = max(8, 2 * self.dim)\n        # success target for sigma (slightly higher)\n        self.succ_target = 0.25\n        # log-sigma additive learning rate (different update equation)\n        self.sigma_log_lr = 0.25\n        # small rotation perturb magnitude (different from rotation_rate)\n        self.rotation_perturb = 0.06\n        # EMA momentum for coordinate scales (more inertia)\n        self.momentum_beta = 0.85\n        # coordinate scaling clipping bounds (different)\n        self.coord_scale_clip = (0.05, 8.0)\n        # sigma min and relative max\n        self.min_sigma = 1e-12\n        self.max_sigma_scale = 3.0\n        # temperature schedule (linear decay)\n        self.temp_start = 2.0\n        self.temp_end = 1e-4\n        # stagnation criteria (different fraction)\n        self.stagnation_frac = 0.03\n        self.restart_inflate = 2.0\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # Bounds handling; Many Affine BBOB uses [-5,5]; func provides bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # initialize mean and scales based on bounds\n        bounds_scale = (ub - lb)\n        m = rng.uniform(lb, ub, size=self.dim)\n        # larger initial sigma than AMGRE\n        sigma = max(1e-10, 0.25 * np.mean(bounds_scale))\n        # maintain log-sigma for additive update\n        log_sigma = np.log(max(sigma, 1e-12))\n        # orthonormal rotation matrix Q (start slightly randomized, not identity)\n        A0 = np.eye(self.dim) + 0.08 * rng.randn(self.dim, self.dim)\n        try:\n            Q, _ = np.linalg.qr(A0)\n        except Exception:\n            Q = np.eye(self.dim)\n        # per-coordinate scales in rotated space\n        coord_scale = np.ones(self.dim) * 0.8\n        coord_scale = np.clip(coord_scale, *self.coord_scale_clip)\n\n        # archive (FIFO)\n        X_arch = []\n        f_arch = []\n\n        # seed with a small initial population to populate archive\n        evals = 0\n        init_pop = min(self.pop_base, max(6, self.budget // 60))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(f)\n\n        # ensure at least one eval\n        if len(f_arch) == 0:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(f)\n\n        # best so far\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # temperature (linear decay progress variable)\n        T0 = self.temp_start\n        Tend = self.temp_end\n        T = float(T0)\n\n        # stagnation detection\n        stagn_count = 0\n        stagn_limit = max(5, int(self.stagnation_frac * self.budget))\n\n        gen = 0\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            lam = max(1, int(lam))\n\n            # try to compute a simple pseudo-gradient from archive differences (recent best deltas)\n            grad = None\n            if len(X_arch) >= 4:\n                # take last up to arch_size entries\n                X_arr = np.asarray(X_arch[-self.arch_size:])\n                f_arr = np.asarray(f_arch[-self.arch_size:])\n                # choose K best recent by value and recency weighting\n                recency = np.arange(X_arr.shape[0])[::-1]  # recent indices larger\n                rec_w = 1.0 + 0.5 * (recency / (recency.max() + 1.0))\n                # value-based weight (lower f -> higher weight)\n                rank_w = np.exp(-2.0 * (f_arr - np.min(f_arr)) / (np.ptp(f_arr) + 1e-12))\n                w = rec_w * rank_w\n                # fit linear model f ≈ a + g·(x - m) with weighted LS (small regularization)\n                Xc = X_arr - m.reshape(1, -1)\n                W = np.sqrt(w).reshape(-1, 1)\n                y = (f_arr - np.min(f_arr))\n                reg = 1e-6 * np.eye(self.dim)\n                try:\n                    A = (W * Xc).T @ (W * Xc) + reg\n                    b = (W * Xc).T @ (W * y)\n                    g_est = np.linalg.solve(A, b)\n                    grad = g_est\n                except np.linalg.LinAlgError:\n                    grad = None\n\n            # Candidate generation\n            candidates = []\n            types = []\n\n            # 1) rotated, axis-scaled Gaussian samples (primary)\n            n_gauss = max(1, int(0.65 * lam))\n            Z = rng.normal(size=(n_gauss, self.dim))\n            # apply per-coordinate scaling in rotated space (elementwise multiplication)\n            Z_scaled = Z * coord_scale.reshape(1, -1)\n            # transform from rotated coordinates to original: Q @ z\n            Xg = m.reshape(1, -1) + np.exp(log_sigma) * (Z_scaled @ Q.T)\n            for row in Xg:\n                candidates.append(row)\n                types.append('gauss')\n\n            # 2) directional probes using pseudo-gradient if available\n            if grad is not None and len(candidates) < lam:\n                gnorm = np.linalg.norm(grad) + 1e-20\n                # build direction in original space via rotation Q (tweak different mapping)\n                d_rot = grad / gnorm\n                # map to original coordinates by Q.T (different sign convention)\n                dir_vec = Q.T @ d_rot\n                # produce short and long probes along -dir_vec (minimization)\n                short = m - 0.9 * np.exp(log_sigma) * dir_vec\n                longp = m - 3.0 * np.exp(log_sigma) * dir_vec\n                candidates.append(np.minimum(np.maximum(short, lb), ub))\n                types.append('dir_probe')\n                if len(candidates) < lam:\n                    candidates.append(np.minimum(np.maximum(longp, lb), ub))\n                    types.append('dir_probe')\n\n            # 3) differential-style recombination from archive (mutation + crossover)\n            n_recomb = lam - len(candidates)\n            for _ in range(n_recomb):\n                if len(X_arch) >= 3:\n                    a, b, c = rng.choice(len(X_arch), size=3, replace=False)\n                    xa = X_arch[a]\n                    xb = X_arch[b]\n                    xc = X_arch[c]\n                    F = 0.7  # differential factor (different choice)\n                    mutant = xa + F * (xb - xc)\n                    # small rotated perturbation\n                    z = rng.normal(scale=0.6, size=self.dim) * coord_scale\n                    mutant = mutant + 0.4 * np.exp(log_sigma) * (z @ Q.T)\n                    mutant = np.minimum(np.maximum(mutant, lb), ub)\n                    candidates.append(mutant)\n                    types.append('recomb')\n                else:\n                    xrand = rng.uniform(lb, ub, size=self.dim)\n                    candidates.append(xrand)\n                    types.append('recomb')\n\n            # Evaluate candidates sequentially until budget exhausted\n            Xcand = np.asarray(candidates)\n            fc = np.full(Xcand.shape[0], np.inf)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                x = Xcand[i]\n                # evaluate\n                fval = float(func(x))\n                evals += 1\n                fc[i] = fval\n\n                # add to archive\n                X_arch.append(x.copy())\n                f_arch.append(fval)\n                if len(X_arch) > self.arch_size:\n                    # FIFO drop\n                    del X_arch[0]\n                    del f_arch[0]\n\n                # update immediate best\n                if fval < f_best:\n                    f_best = fval\n                    x_best = x.copy()\n                    stagn_count = 0\n                else:\n                    stagn_count += 1\n\n            # truncate arrays if budget cut mid-eval\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n            if fc.size == 0:\n                break\n\n            # Rank-based selection: take top-mu and compute weighted mean (different selection equation)\n            mu = max(1, int(0.2 * Xcand.shape[0]))\n            idx_sorted = np.argsort(fc)\n            elites_idx = idx_sorted[:mu]\n            elite_x = Xcand[elites_idx]\n            elite_f = fc[elites_idx]\n            # rank weights: higher weight to better rank (exponential on rank)\n            ranks = np.arange(mu)\n            weights = np.exp(-0.6 * ranks)\n            weights = weights / np.sum(weights)\n            # weighted mean move (rank-weighted update)\n            new_mean = np.sum(elite_x * weights.reshape(-1, 1), axis=0)\n\n            # acceptance: Metropolis-style acceptance for mean move (with linear temperature)\n            delta = np.mean(elite_f) - f_best  # improvement indicator (avg elite vs global best)\n            # acceptance prob for uphill\n            accept_prob = 1.0 if delta <= 0 else np.exp(-delta / (T + 1e-12))\n            if rng.rand() < accept_prob:\n                # move fully towards new_mean with factor depending on improvement\n                move_coeff = 0.35 if np.min(elite_f) < f_best else 0.15\n                m = (1.0 - move_coeff) * m + move_coeff * new_mean\n            else:\n                # small exploratory jitter in rotated frame\n                m = m + 0.06 * np.exp(log_sigma) * (rng.randn(self.dim) @ Q.T)\n                m = np.minimum(np.maximum(m, lb), ub)\n\n            # compute rotated normalized steps for statistics: u = Q @ ((x - m)/sigma)  (different orientation)\n            sigma_curr = float(np.exp(log_sigma))\n            deltas = (Xcand - m.reshape(1, -1)) / (sigma_curr + 1e-20)\n            deltas_rot = deltas @ Q.T  # shape (pop, dim)\n\n            # update per-coordinate scales: EMA of mean abs rotated steps (different beta)\n            stat = np.mean(np.abs(deltas_rot), axis=0)\n            coord_scale = self.momentum_beta * coord_scale + (1.0 - self.momentum_beta) * (stat + 1e-12)\n            coord_scale = np.clip(coord_scale, self.coord_scale_clip[0], self.coord_scale_clip[1])\n\n            # rotation update: form small alignment matrix from successful step covariances and QR\n            # collect successful (improving) steps in rotated coordinates\n            success_mask = (fc < f_best + 1e-16)\n            if np.any(success_mask):\n                S = np.zeros((self.dim, self.dim))\n                good_deltas = deltas_rot[success_mask]\n                # low-rank outer-product alignment (different equation)\n                for gd in good_deltas:\n                    S += np.outer(gd, gd)\n                # normalize and scale small\n                if np.linalg.norm(S) > 0:\n                    S = S / (np.linalg.norm(S) + 1e-20)\n                    # perturb current Q with Q + eps * Q * S (keeps it close but moves towards covariance)\n                    perturb = self.rotation_perturb * (Q @ S)\n                    Q_try = Q + perturb\n                    # re-orthonormalize by QR for stability (different approach than Givens)\n                    try:\n                        Q_new, _ = np.linalg.qr(Q_try)\n                        Q = Q_new\n                    except np.linalg.LinAlgError:\n                        # fallback to small random orthonormal\n                        B = np.eye(self.dim) + 0.01 * rng.randn(self.dim, self.dim)\n                        try:\n                            Q, _ = np.linalg.qr(B)\n                        except Exception:\n                            Q = np.eye(self.dim)\n\n            # sigma adaptation using additive update on log-sigma (different equation)\n            gen_success = float(np.any(fc < f_best + 1e-16))\n            # smooth success estimate with simple exponential smoothing (short memory)\n            # use alpha depending on population (smaller pop -> slower smoothing)\n            alpha = 0.15\n            # store a simple running p_succ locally per generation (not stored between runs intentionally)\n            if gen == 1:\n                p_succ = gen_success\n            else:\n                p_succ = (1.0 - alpha) * p_succ + alpha * gen_success\n            # additive log-sigma update (different equation)\n            log_sigma += self.sigma_log_lr * (p_succ - self.succ_target)\n            sigma_curr = float(np.exp(log_sigma))\n            # clamp sigma\n            sigma_curr = np.clip(sigma_curr, self.min_sigma, self.max_sigma_scale * np.max(bounds_scale))\n            log_sigma = np.log(max(sigma_curr, 1e-30))\n\n            # Temperature linear decay based on fraction of budget used (different schedule)\n            frac = min(1.0, evals / max(1.0, self.budget))\n            T = max(Tend, T0 * (1.0 - frac))\n\n            # opportunistic restart if stagnated (different behavior)\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # restart centered around current best with stronger jitter\n                jitter_scale = max(0.12 * np.mean(bounds_scale), 0.8 * np.exp(log_sigma))\n                m = x_best + rng.randn(self.dim) * jitter_scale\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reinitialize rotation to random orthonormal and broaden sigma\n                B = np.eye(self.dim) + 0.2 * rng.randn(self.dim, self.dim)\n                try:\n                    Q, _ = np.linalg.qr(B)\n                except Exception:\n                    Q = np.eye(self.dim)\n                coord_scale = np.ones(self.dim)\n                sigma_curr = max(np.exp(log_sigma) * self.restart_inflate, 0.3 * np.mean(bounds_scale))\n                log_sigma = np.log(max(sigma_curr, 1e-12))\n                # shrink archive but keep the best\n                keep = max(1, len(X_arch) // 6)\n                X_arch = X_arch[-keep:]\n                f_arch = f_arch[-keep:]\n                # small temperature bump\n                T = min(T0, T * 1.8)\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 170, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: short = m - 0.9 * np.exp(log_sigma) * dir_vec", "error": "In the code, line 170, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: short = m - 0.9 * np.exp(log_sigma) * dir_vec", "parent_ids": "ab6afe0d-0bde-4d10-b826-cc3e4f5b876d", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "c6ca5b46-43ac-4074-8c7a-afb4a755fc64", "fitness": 0.10071314385609562, "name": "SPT", "description": "The SPT algorithm mixes focused principal-subspace probing with global diversification: it maintains a mean m and a trust-scale sigma (initialized ~0.12·mean(bounds)), learns top principal components from an EWMA covariance (cov_ema_alpha≈0.15, pcs updated every ~dim/3) and generates candidates by subspace Gaussian probes (≈60% of proposals, k = min(4, dim//6)), Levy/Cauchy long jumps (≈15%), and archive recombinations, with archive size scaling ~O(dim). It fits a cheap diagonal quadratic surrogate when enough points exist (≈2·dim+5 samples) to produce an analytic trust-region step and a predicted improvement used to compute a rho = actual/predicted to adapt sigma (trust_inflate=1.5, trust_deflate=0.6), drive acceptance decisions, and push very poor directions into a small taboo list (tabu_len=6) that penalizes re-aligned proposals. Covariance is updated by EWMA of successful/selected steps to steer subspace learning, and the method includes opportunistic restarts on stagnation, bound clamping, FIFO archive maintenance, and small randomized moves to retain exploration.", "code": "import numpy as np\n\nclass SPT:\n    \"\"\"\n    Subspace-Probing Trust (SPT)\n\n    Main ideas / novel mechanisms:\n    - Maintain a mean m, a trust-scale sigma (like trust-region radius) and an EWMA covariance\n      used to extract principal subspaces (incremental PCA) for focused probes.\n    - Fit a local diagonal-quadratic surrogate (when enough archive points exist) to compute\n      an analytic trust-region descent step and a predicted improvement; use predicted vs actual\n      improvement (rho) to adapt sigma (trust-region style).\n    - Mix proposal generators: principal-subspace Gaussian probes, diagonal-quadratic trust steps,\n      Levy (Cauchy) long jumps for escapes, and archive recombinations.\n    - Maintain a small directional \"taboo\" list of recently unhelpful normalized directions and\n      penalize proposals aligned with them to encourage orthogonal exploration.\n    - Use EWMA of successful step outer-products to update the covariance cheaply (no large-memory\n      covariance accumulation), and recompute top principal components occasionally.\n    - Opportunistic restarts if stagnation observed.\n\n    Designed for bounded continuous black-box minimization (works with Many Affine BBOB noiseless tests).\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop_base=None, arch_size=None, cov_ema_alpha=0.15,\n                 trust_inflate=1.5, trust_deflate=0.6, tabu_len=6):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.rng = np.random.RandomState(rng_seed)\n\n        # population and archive sizes (scale with dim modestly)\n        self.pop_base = pop_base if pop_base is not None else max(6, int(4 + 1.2 * np.sqrt(max(2, dim))))\n        self.arch_size = arch_size if arch_size is not None else max(6 + 4 * dim, 20)\n\n        # EWMA covariance updating weight for principal subspace learning\n        self.cov_ema_alpha = float(cov_ema_alpha)\n\n        # trust-region adaptation multipliers\n        self.trust_inflate = float(trust_inflate)\n        self.trust_deflate = float(trust_deflate)\n\n        # taboo list length for discouraging repeated bad directions\n        self.tabu_len = int(tabu_len)\n\n        # numeric & bounds helpers\n        self.min_sigma = 1e-8\n        self.max_sigma = 10.0\n        self.p_momentum = 0.85  # momentum for smoothing measured improvement ratio\n        self.stagnation_frac = 0.06\n        self.restart_scale = 0.5\n\n    def __call__(self, func):\n        # read bounds (Many Affine BBOB uses [-5,5] but keep general)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # initial mean and sigma (trust radius)\n        m = self.rng.uniform(lb, ub, size=self.dim)\n        bounds_scale = np.maximum(ub - lb, 1e-12)\n        sigma = max(1e-8, 0.12 * np.mean(bounds_scale))\n\n        # archive (FIFO)\n        X_arch = []\n        f_arch = []\n\n        # seed with small initial population\n        evals = 0\n        init_pop = min(self.pop_base, max(6, self.budget // 50))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x = self.rng.uniform(lb, ub, size=self.dim)\n            fx = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(fx)\n\n        if len(f_arch) == 0:\n            x = self.rng.uniform(lb, ub, size=self.dim)\n            fx = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(fx)\n\n        # best so far\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # EWMA covariance for principal components, start small isotropic\n        C_ema = np.eye(self.dim) * (sigma ** 2)\n        pcs = np.eye(self.dim)  # principal components (columns)\n        pcs_update_every = max(7, self.dim // 3)\n\n        # diagonal quadratic surrogate params (a + g·d + 0.5 * diag(h) * d^2)\n        quad_available = False\n        quad_g = np.zeros(self.dim)\n        quad_h = np.ones(self.dim) * 1e-6\n        quad_a = 0.0\n\n        # directional taboo: list of normalized vectors to avoid (recently harmful directions)\n        tabu = []\n\n        # smoothing for improvement ratio (used for sigma adaptation stamina)\n        rho_smoothed = 0.5\n\n        # stagnation detection\n        stagn_counter = 0\n        stagn_limit = max(5, int(self.stagnation_frac * self.budget))\n\n        gen = 0\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n\n            # recompute principal components occasionally from C_ema\n            if (gen % pcs_update_every) == 0:\n                try:\n                    # symmetric eigen-decomposition (C_ema is symmetric)\n                    vals, vecs = np.linalg.eigh((C_ema + C_ema.T) * 0.5)\n                    # sort descending\n                    idxs = np.argsort(vals)[::-1]\n                    pcs = vecs[:, idxs]\n                except np.linalg.LinAlgError:\n                    pcs = np.eye(self.dim)\n\n            lam = min(self.pop_base, remaining)\n            lam = max(1, int(lam))\n\n            candidates = []\n            propose_types = []\n            meta_pred = []  # predicted improvements when available (for trust step)\n\n            # propose: principal-subspace Gaussian probes (majority)\n            n_sub = max(1, int(0.6 * lam))\n            # choose top-k components (k adaptive, small)\n            k = max(1, min(self.dim, int(max(1, min(4, max(1, self.dim // 6))))))\n            U = pcs[:, :k]  # shape (dim,k)\n            # sample coefficients in subspace with scaled gaussian\n            for _ in range(n_sub):\n                z_sub = self.rng.randn(k) * (0.8 + 0.6 * self.rng.rand())\n                orth_noise = self.rng.randn(self.dim) * 0.12  # small orth complement noise\n                step = (U @ z_sub) + orth_noise\n                x = m + sigma * step\n                candidates.append(x)\n                propose_types.append('subspace_gauss')\n                meta_pred.append(None)\n\n            # propose: diagonal-quadratic trust step (if surrogate available or try to fit)\n            # try to fit diagonal quadratic from archive if enough points\n            if len(X_arch) >= min(2 * self.dim + 5, self.arch_size):\n                # build design matrix: constant, linear, squared (diagonal Hessian)\n                Xa = np.asarray(X_arch[-self.arch_size:])\n                Fa = np.asarray(f_arch[-self.arch_size:])\n                D = Xa - m.reshape(1, -1)\n                # features: constant, D[:,i], D[:,i]**2\n                n_samples = D.shape[0]\n                Phi = np.ones((n_samples, 1 + 2 * self.dim))\n                Phi[:, 1:1 + self.dim] = D\n                Phi[:, 1 + self.dim:] = 0.5 * (D ** 2)  # include 0.5 factor for Hessian diag\n                # ridge regularized least squares\n                lam_reg = 1e-6\n                try:\n                    sol, *_ = np.linalg.lstsq(Phi.T @ Phi + lam_reg * np.eye(Phi.shape[1]),\n                                              Phi.T @ Fa, rcond=None)\n                    quad_a = float(sol[0])\n                    quad_g = sol[1:1 + self.dim].copy()\n                    quad_h = np.maximum(sol[1 + self.dim:], 1e-9)  # ensure positive-ish diag\n                    quad_available = True\n                except Exception:\n                    quad_available = False\n\n            if quad_available:\n                # predicted (unconstrained) minimizer in local coordinates: d* = -g / h\n                d_star = -quad_g / (quad_h + 1e-16)\n                # constrain length to trust radius (sigma)\n                norm_ds = np.linalg.norm(d_star)\n                if norm_ds > 1.2 * sigma:\n                    d_star = d_star * (1.2 * sigma / (norm_ds + 1e-20))\n                # candidate and predicted improvement\n                x_ts = m + d_star\n                pred_imp = (quad_g @ d_star + 0.5 * (quad_h * (d_star ** 2)).sum())  # negative if descent\n                candidates.append(x_ts)\n                propose_types.append('quad_trust')\n                meta_pred.append(-pred_imp)  # predicted positive improvement (if pred_imp negative)\n                # also try a smaller step along d_star\n                candidates.append(m + 0.6 * d_star)\n                propose_types.append('quad_trust_small')\n                meta_pred.append(-0.6 * pred_imp)\n\n            # propose: Levy (Cauchy) long jumps for escape\n            n_levy = max(1, int(0.15 * lam))\n            for _ in range(n_levy):\n                # standard Cauchy heavy tail scaled by sigma and bounds\n                jump = np.random.standard_cauchy(self.dim) if hasattr(np.random, \"standard_cauchy\") else self.rng.standard_cauchy(self.dim)\n                scale = (0.8 + 1.5 * self.rng.rand()) * sigma * (np.mean(bounds_scale) / (np.mean(bounds_scale) + 1e-12))\n                x = m + scale * (jump / (np.linalg.norm(jump) + 1e-12))\n                candidates.append(x)\n                propose_types.append('levy')\n                meta_pred.append(None)\n\n            # propose: archive recombinations\n            n_rec = lam - len(candidates)\n            for _ in range(n_rec):\n                if len(X_arch) >= 2:\n                    # biased pick by fitness (softmax on negative f)\n                    f_arr = np.asarray(f_arch)\n                    scores = - (f_arr - np.min(f_arr))\n                    # stable softmax\n                    scores = np.exp((scores - np.max(scores)) / (np.std(scores) + 1e-9))\n                    idx = self.rng.choice(len(X_arch), size=2, replace=False, p=scores / (np.sum(scores) + 1e-12))\n                    a = X_arch[idx[0]]\n                    b = X_arch[idx[1]]\n                    alpha = self.rng.rand()\n                    xrec = alpha * a + (1.0 - alpha) * b\n                    # small subspace perturbation\n                    z = self.rng.randn(k) * 0.5\n                    xrec = xrec + 0.6 * sigma * (U @ z)\n                    candidates.append(xrec)\n                    propose_types.append('recomb')\n                    meta_pred.append(None)\n                else:\n                    xrand = self.rng.uniform(lb, ub, size=self.dim)\n                    candidates.append(xrand)\n                    propose_types.append('rand')\n                    meta_pred.append(None)\n\n            # clamp to bounds\n            Xcand = np.asarray([np.minimum(np.maximum(x, lb), ub) for x in candidates])\n\n            # evaluate sequentially until budget\n            n_eval = Xcand.shape[0]\n            fvals = np.full(n_eval, np.inf)\n            pred_list = [None] * n_eval\n            actual_improv = [None] * n_eval\n\n            for i in range(n_eval):\n                if evals >= self.budget:\n                    break\n                x = Xcand[i]\n                fx = float(func(x))\n                evals += 1\n                fvals[i] = fx\n\n                # update archive FIFO\n                X_arch.append(x.copy())\n                f_arch.append(fx)\n                if len(X_arch) > self.arch_size:\n                    del X_arch[0]\n                    del f_arch[0]\n\n                # record predicted improvement when available\n                pred = meta_pred[i]\n                pred_list[i] = pred\n\n                # measure actual improvement relative to current m estimate modeled by f(m) ~ min archive or quad a\n                # use best-so-far as global anchor\n                if pred is not None:\n                    # actual improvement = f(m) - f(x) approximated by (f_best - fx) but f_best maybe better than m\n                    actual = max(0.0, max(0.0, (f_best - fx)))\n                    actual_improv[i] = actual\n                else:\n                    actual_improv[i] = None\n\n                # update best-so-far\n                if fx < f_best:\n                    f_best = fx\n                    x_best = x.copy()\n                    stagn_counter = 0\n                else:\n                    stagn_counter += 1\n\n            # trim evaluated candidates\n            valid = np.isfinite(fvals)\n            if not np.any(valid):\n                break\n            Xcand = Xcand[valid]\n            fvals = fvals[valid]\n            pred_list = [meta_pred[i] for i in range(len(candidates)) if valid[i]]\n            propose_types = [propose_types[i] for i in range(len(candidates)) if valid[i]]\n\n            # select best candidate in this generation\n            best_idx = int(np.argmin(fvals))\n            gen_best_x = Xcand[best_idx].copy()\n            gen_best_f = float(fvals[best_idx])\n\n            # compute normalized steps (unitless) for updates\n            deltas = (Xcand - m) / (sigma + 1e-20)\n            norms = np.linalg.norm(deltas, axis=1) + 1e-20\n\n            # apply taboo penalty: if a candidate aligns strongly with a taboo vector, reduce its attractiveness\n            penalties = np.ones(len(Xcand))\n            for tvec in tabu:\n                # compute abs cosine similarity\n                sims = np.abs((deltas @ tvec) / (norms + 1e-20))\n                # penalize candidates with sim > 0.85\n                penalties[sims > 0.85] *= 0.25\n\n            # pick an index to move mean toward: use fitness-weighted softmax scaled by penalties\n            inv_f = - (fvals - np.min(fvals))  # higher is better\n            # stabilize and softmax\n            smax = np.exp((inv_f - np.max(inv_f)) / (np.std(inv_f) + 1e-9)) * penalties\n            if np.sum(smax) <= 0:\n                probs = np.ones(len(smax)) / len(smax)\n            else:\n                probs = smax / np.sum(smax)\n            chosen_idx = int(self.rng.choice(len(Xcand), p=probs))\n            chosen_x = Xcand[chosen_idx]\n            chosen_f = fvals[chosen_idx]\n\n            # acceptance logic: trust-ratio when quad_pred available\n            accepted = False\n            pred_val = pred_list[chosen_idx]\n            if pred_val is not None:\n                # predicted improvement (positive if expected descent)\n                predicted = pred_val\n                actual = max(0.0, f_best - chosen_f)\n                # compute rho\n                if predicted <= 0:\n                    rho = 0.0\n                else:\n                    rho = actual / (predicted + 1e-12)\n                # smooth rho\n                rho_smoothed = self.p_momentum * rho_smoothed + (1 - self.p_momentum) * rho\n                # trust update decisions\n                if rho > 0.6:\n                    accepted = True\n                    sigma = min(self.max_sigma, sigma * self.trust_inflate)\n                elif rho < 0.15:\n                    # reject mean update but record direction as taboo-like\n                    accepted = False\n                    sigma = max(self.min_sigma, sigma * self.trust_deflate)\n                else:\n                    accepted = True\n                # penalty-based taboo insertion for very low rho\n                if rho < 0.05:\n                    dirn = (chosen_x - m)\n                    nrm = np.linalg.norm(dirn) + 1e-20\n                    if nrm > 1e-12:\n                        v = dirn / nrm\n                        tabu.insert(0, v)\n                        if len(tabu) > self.tabu_len:\n                            tabu.pop()\n            else:\n                # fallback acceptance: accept if improves or with small prob for uphill to diversify\n                if chosen_f <= f_best or self.rng.rand() < 0.02:\n                    accepted = True\n                else:\n                    accepted = False\n\n            # move mean m towards chosen_x if accepted\n            if accepted:\n                # step size scaled by candidate norm: larger for strong improvements\n                step_scale = 0.4 if chosen_f < f_best else 0.15\n                m = (1 - step_scale) * m + step_scale * chosen_x\n            else:\n                # mild exploration: small perturbation\n                m = m + 0.08 * sigma * (self.rng.randn(self.dim))\n\n            # update EWMA covariance using successful steps (those that improved global best)\n            for i in range(len(Xcand)):\n                if fvals[i] <= f_best:\n                    d = (Xcand[i] - m)\n                    # outer product update (small scalar weight)\n                    C_ema = (1 - self.cov_ema_alpha) * C_ema + self.cov_ema_alpha * np.outer(d, d)\n\n            # also update using the chosen candidate direction even if not improving (soft)\n            d_ch = (chosen_x - m)\n            C_ema = (1 - 0.5 * self.cov_ema_alpha) * C_ema + (0.5 * self.cov_ema_alpha) * np.outer(d_ch, d_ch)\n\n            # occasional small reconditioning to avoid singularities\n            if gen % 41 == 0:\n                C_ema = (C_ema + C_ema.T) * 0.5 + 1e-8 * np.eye(self.dim)\n\n            # update quadratic surrogate availability if many new points (try re-fit next iter automatically)\n\n            # stagnation & opportunistic restart\n            if stagn_counter >= stagn_limit and evals < self.budget:\n                stagn_counter = 0\n                # restart around best with jitter proportional to bounds\n                jitter = self.restart_scale * np.mean(bounds_scale) * (0.5 + self.rng.rand())\n                m = x_best + self.rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                sigma = max(sigma * 1.2, 0.08 * np.mean(bounds_scale))\n                # reset covariance & taboo to encourage fresh search\n                C_ema = np.eye(self.dim) * (sigma ** 2)\n                pcs = np.eye(self.dim)\n                tabu = []\n                # keep only the best part of archive\n                keep = max(1, len(X_arch) // 5)\n                X_arch = X_arch[-keep:]\n                f_arch = f_arch[-keep:]\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SPT scored 0.101 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ab6afe0d-0bde-4d10-b826-cc3e4f5b876d", "operator": null, "metadata": {"aucs": [0.04755423426601035, 0.12818414755308094, 0.16786303149737036, 0.09748764611929317, 0.11262416050340252, 0.12558805348852908, 0.07194837836828794, 0.09893448026184681, 0.07119485732853803, 0.08575244917459712]}, "task_prompt": ""}
{"id": "30bf78db-c73c-4a8d-9939-6d8f114b121a", "fitness": 0.20427051839065485, "name": "PARDIS", "description": "PARDIS mixes rotated-Gaussian exploration with PCA-directed line probes and archive-based recombinations: a learned rotation matrix R (from PCA on recent/archive points) is used to generate most candidates while per-axis RMS scales (axis_rms, rms_beta=0.85) modulate step lengths in the rotated coordinates. The algorithm adapts global step-size sigma multiplicatively toward a target success rate (sigma_adapt_rate=0.15, succ_target=0.25) and incrementally blends new principal axes into R (rotation_update_rate=0.20) to capture problem-aligned directions. Candidates are chosen by a softmax-over-fitness scheme and accepted via an annealed Metropolis-like rule (T starting at 0.8 and decaying), with strict bounds clipping and rank-biased archive sampling for recombination. Robustness features include a FIFO archive for PCA/statistics, opportunistic restarts on stagnation (inflating sigma and jittering the mean), and conservative parameter defaults (pop_base, arch_size) to work across varied dimensions.", "code": "import numpy as np\n\nclass PARDIS:\n    \"\"\"\n    PARDIS: Principal-Axis Rotational Directional Search\n\n    Main idea (one line): combine PCA-learned rotation of the search space with RMS-like per-axis scaling\n    and directional line probes along principal components, mixing rotated-Gaussian exploration and\n    archive recombination with an annealed Metropolis acceptance rule.\n\n    Key algorithm parameters (tuned different from AMGRE):\n      - pop_base: baseline population per generation (≈ 5 + 2 * sqrt(dim), min 8)\n      - arch_size: archive length for PCA and local statistics (≈ 40 + 3*dim, capped moderately)\n      - sigma: global step-size, multiplicatively adapted with sigma_adapt_rate (lower than AMGRE)\n      - sigma_adapt_rate: 0.15 (smaller, smoother multiplicative adaptation)\n      - succ_target: 0.25 (target success rate)\n      - rotation_update_rate: 0.20 (scale of PCA rotation updates, larger than AMGRE but applied via smooth PCA)\n      - rms_beta: 0.85 (RMS smoothing for per-axis scales)\n      - coord_scale_clip: (0.05, 8.0)\n      - temp_start/temp_end/temp_decay: annealing schedule (temp_decay slightly faster)\n      - stagnation_frac and restart_inflate similar idea but different constants\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop_base=None, arch_size=None,\n                 sigma_adapt_rate=0.15, succ_target=0.25,\n                 rotation_update_rate=0.20, rms_beta=0.85):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # adaptive defaults (different formulas from AMGRE)\n        self.pop_base = pop_base if pop_base is not None else max(8, int(5 + 2.0 * np.sqrt(max(2, dim))))\n        self.arch_size = arch_size if arch_size is not None else min(max(40 + 3 * dim, 20), 8 * dim)\n        self.succ_target = succ_target\n        self.sigma_adapt_rate = sigma_adapt_rate\n        self.rotation_update_rate = rotation_update_rate\n        self.rms_beta = rms_beta\n        self.coord_scale_clip = (0.05, 8.0)\n        self.min_sigma = 1e-12\n        self.max_sigma_scale = 3.0\n        self.temp_start = 0.8\n        self.temp_end = 1e-4\n        self.temp_decay = 0.990\n        self.stagnation_frac = 0.04\n        self.restart_inflate = 1.5\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds handling (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # initialize mean and sigma from bounds (robust)\n        bounds_scale = (ub - lb)\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(1e-8, 0.12 * np.mean(bounds_scale))  # slightly different base fraction\n\n        # rotation matrix (learned via PCA on recent step vectors)\n        R = np.eye(self.dim)\n\n        # per-axis RMS-style scales in rotated coordinates\n        axis_rms = np.ones(self.dim)\n\n        # archive for recent evaluated points (FIFO)\n        X_arch = []\n        f_arch = []\n\n        # seed small initial population (ensuring at least some data)\n        evals = 0\n        init_pop = min(self.pop_base, max(6, self.budget // 60))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(f)\n\n        if len(f_arch) == 0:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(f)\n\n        # track best\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # smoothed success rate and temperature\n        p_succ = 0.25\n        T = float(self.temp_start)\n\n        # stagnation detection\n        stagn_count = 0\n        stagn_limit = max(5, int(self.stagnation_frac * self.budget))\n\n        gen = 0\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            lam = max(1, lam)\n\n            # compute PCA on most recent step vectors (if enough archived points)\n            pca_topvecs = None\n            if len(X_arch) >= max(3, self.dim // 4):\n                X_arr = np.asarray(X_arch)\n                # center by the median to reduce outlier influence\n                center = np.median(X_arr, axis=0)\n                S = X_arr - center\n                # compute covariance on S (small regularization)\n                C = (S.T @ S) / max(1, S.shape[0]) + 1e-8 * np.eye(self.dim)\n                # eigen-decomposition for principal axes\n                try:\n                    eigvals, eigvecs = np.linalg.eigh(C)\n                    # sort descending\n                    idxs = np.argsort(eigvals)[::-1]\n                    eigvals = eigvals[idxs]\n                    eigvecs = eigvecs[:, idxs]\n                    pca_topvecs = (eigvals, eigvecs)\n                except np.linalg.LinAlgError:\n                    pca_topvecs = None\n\n            # propose candidates: mixture of rotated Gaussian, PCA-directed probes, and recombinations\n            candidates = []\n            types = []\n\n            # A: rotated Gaussian majority\n            n_gauss = max(1, int(0.65 * lam))\n            Z = rng.normal(size=(n_gauss, self.dim))\n            # scale each axis by RMS smoothing and small extra jitter\n            Z = Z * (axis_rms.reshape(1, -1))\n            Xg = m.reshape(1, -1) + sigma * (Z @ R.T)\n            candidates.extend(Xg.tolist())\n            types.extend(['gauss'] * Xg.shape[0])\n\n            # B: PCA directional line probes (use top 1-2 principal axes)\n            if pca_topvecs is not None and remaining - len(candidates) > 0:\n                eigvals, eigvecs = pca_topvecs\n                # consider up to two top axes (if meaningful)\n                n_axes = min(2, eigvecs.shape[1])\n                for k in range(n_axes):\n                    if remaining - len(candidates) <= 0:\n                        break\n                    axis = eigvecs[:, k]\n                    # propose along + and - directions with varying lengths\n                    for factor in (1.0, 2.2):\n                        if remaining - len(candidates) <= 0:\n                            break\n                        step_len = sigma * (1.2 if factor == 1.0 else 2.0) * (1.0 + 0.5 * np.tanh(eigvals[k]))\n                        xprobe = m + factor * step_len * axis\n                        candidates.append(xprobe)\n                        types.append('pca_probe')\n\n            # C: archive recombinations + small rotated perturbation\n            n_recomb = lam - len(candidates)\n            for _ in range(n_recomb):\n                if len(X_arch) >= 2:\n                    # bias selection toward better archive members by rank-probabilities\n                    f_arr = np.asarray(f_arch)\n                    ranks = np.argsort(np.argsort(f_arr))  # lower f -> lower rank\n                    probs = (len(f_arr) - ranks) + 1e-3\n                    probs = probs / np.sum(probs)\n                    i1 = rng.choice(len(X_arch), p=probs)\n                    i2 = rng.choice(len(X_arch), p=probs)\n                    a = X_arch[i1]\n                    b = X_arch[i2]\n                    alpha = rng.beta(1.5, 1.5)\n                    xrec = alpha * a + (1.0 - alpha) * b\n                    # rotated small mutation\n                    z = rng.normal(scale=0.9, size=self.dim) * axis_rms\n                    xrec = xrec + 0.5 * sigma * (z @ R.T)\n                    candidates.append(xrec)\n                    types.append('recomb')\n                else:\n                    xrand = rng.uniform(lb, ub, size=self.dim)\n                    candidates.append(xrand)\n                    types.append('recomb')\n\n            # clip to bounds\n            Xcand = np.asarray([np.minimum(np.maximum(np.array(x), lb), ub) for x in candidates])\n\n            # Evaluate sequentially, respecting budget\n            fc = np.full(Xcand.shape[0], np.inf)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                x = Xcand[i]\n                f = float(func(x))\n                fc[i] = f\n                evals += 1\n                # update archive FIFO\n                X_arch.append(x.copy())\n                f_arch.append(f)\n                if len(X_arch) > self.arch_size:\n                    del X_arch[0]\n                    del f_arch[0]\n                # immediate best update\n                if f < f_best:\n                    f_best = f\n                    x_best = x.copy()\n                    stagn_count = 0\n                else:\n                    stagn_count += 1\n\n            # shrink to evaluated set\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n            if fc.size == 0:\n                break\n\n            # selection: pick a candidate for mean update using softmax of negative f (better f higher weight)\n            scores = np.max(fc) - fc + 1e-12\n            probs = np.exp(scores / (np.std(scores) + 1e-12))  # emphasis on better samples\n            probs = probs / np.sum(probs)\n            chosen_idx = rng.choice(len(Xcand), p=probs)\n            chosen_x = Xcand[chosen_idx]\n            chosen_f = fc[chosen_idx]\n\n            # acceptance: Metropolis-like, using annealed temperature T\n            delta = chosen_f - f_best\n            accept = False\n            if chosen_f <= f_best:\n                accept = True\n            else:\n                prob_accept = np.exp(-max(0.0, delta) / (T + 1e-12))\n                if rng.rand() < prob_accept:\n                    accept = True\n\n            if accept:\n                # step strength depends on improvement magnitude\n                if chosen_f < f_best:\n                    eta = 0.30\n                else:\n                    eta = 0.14\n                m = (1.0 - eta) * m + eta * chosen_x\n            else:\n                # small exploratory jitter in rotated coordinates\n                m = m + 0.06 * sigma * (rng.normal(size=self.dim) @ R.T)\n                m = np.minimum(np.maximum(m, lb), ub)\n\n            # compute normalized rotated steps for statistics: u = R*(x - m)/sigma in rotated coordinates\n            deltas_rot = ((Xcand - m.reshape(1, -1)) / (sigma + 1e-20)) @ R.T\n\n            # success indicator: any candidate improved global best\n            gen_success = float(np.any(fc < f_best + 1e-16))\n            # update p_succ (smoother update than AMGRE)\n            p_succ = 0.92 * p_succ + 0.08 * gen_success\n\n            # update global sigma multiplicatively with different rate\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, self.min_sigma, self.max_sigma_scale * np.max(bounds_scale))\n\n            # update axis_rms (RMS of absolute rotated steps) using RMS-beta smoothing\n            stat = np.mean(np.abs(deltas_rot), axis=0)\n            axis_rms = self.rms_beta * axis_rms + (1.0 - self.rms_beta) * (stat + 1e-12)\n            axis_rms = np.clip(axis_rms, self.coord_scale_clip[0], self.coord_scale_clip[1])\n\n            # rotation learning via PCA on successful relative moves (cheap incremental approximation)\n            try:\n                # collect recent successful step vectors (relative to previous mean)\n                # pick best half of recent archive as \"successful\" by fitness relative to median\n                if len(X_arch) >= 4:\n                    X_arr = np.asarray(X_arch)\n                    f_arr = np.asarray(f_arch)\n                    med = np.median(f_arr)\n                    good_idx = np.where(f_arr <= med)[0]\n                    if good_idx.size >= 2:\n                        S = (X_arr[good_idx] - np.mean(X_arr[good_idx], axis=0))\n                        # small covariance of good moves\n                        Cg = (S.T @ S) / max(1, S.shape[0]) + 1e-8 * np.eye(self.dim)\n                        # compute top eigenvectors (fast approximate via eigh)\n                        eigvals, eigvecs = np.linalg.eigh(Cg)\n                        idxs = np.argsort(eigvals)[::-1]\n                        eigvecs = eigvecs[:, idxs]\n                        # blend new principal axes into R smoothly\n                        blend = min(1.0, self.rotation_update_rate)\n                        # form new basis candidate Q (orthonormal eigenvectors)\n                        Q = eigvecs\n                        # rotate current R towards Q: simple column blending + re-orthonormalize\n                        R = (1.0 - blend) * R + blend * Q\n                        # re-orthonormalize\n                        Qr, _ = np.linalg.qr(R)\n                        R = Qr\n            except Exception:\n                R = np.eye(self.dim)\n\n            # temperature decay\n            T = max(self.temp_end, T * (self.temp_decay ** 1.0))\n\n            # opportunistic restart on stagnation\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                jitter = max(0.04 * np.mean(bounds_scale), 0.6 * sigma)\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                R = np.eye(self.dim)\n                axis_rms = np.ones(self.dim)\n                sigma = max(sigma * self.restart_inflate, 0.18 * np.mean(bounds_scale))\n                # partially clear archive to encourage new directions\n                keep = max(1, len(X_arch) // 3)\n                X_arch = X_arch[-keep:]\n                f_arch = f_arch[-keep:]\n                T = min(1.0, T * 1.8)\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm PARDIS scored 0.204 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ab6afe0d-0bde-4d10-b826-cc3e4f5b876d", "operator": null, "metadata": {"aucs": [0.08801199910590107, 0.1971987928630754, 0.2649824238207076, 0.23761391931148823, 0.19725459290767589, 0.2766122779729051, 0.21895544252121646, 0.2178554477374427, 0.20622417680390015, 0.13799611086223607]}, "task_prompt": ""}
{"id": "0253847f-96c3-4193-85ea-47a93b706198", "fitness": "-inf", "name": "HAMR", "description": "HAMR is a hybrid, CMA-like continuous optimizer that combines antithetic Gaussian sampling with a learned normalized covariance C, a directional momentum v, per-coordinate multiplicative scales s_diag and a lightweight rotation matrix R; it seeds C and sigma from the search bounds (C ~ (bounds/4)^2, sigma ~0.2·mean(bounds)) and uses a modest, dimension-dependent population lam0 with log-linear recombination weights. Covariance adaptation is a convex mixture of rank‑mu updates (c_cov, here moderate ~0.18) and a smaller rank‑one term built from an EMA momentum (mom_beta ~0.8, c_rank1 ~0.06), while s_diag is tracked by EMA (scale_beta ~0.6) of absolute rotated steps and R is nudged by small Givens rotations (rotation_rate ~0.1) with occasional re‑orthonormalization. Sampling biases include antithetic pairs transformed by the Cholesky of C rotated by R, multiplicative per-coordinate scaling, and an additive momentum bias; if a FIFO archive has enough points HAMR computes a weighted local linear surrogate to append 1–2 directed gradient probes. Control and robustness come from multiplicative sigma adaptation driven by a smoothed success probability (sigma_adapt_rate and succ_target), probabilistic simulated‑annealing acceptance to allow uphill moves, boundary clamping, opportunistic restarts on stagnation, and several tunable safeguards (min/max sigma, archive size, stagnation fraction).", "code": "import numpy as np\n\nclass HAMR:\n    \"\"\"\n    Hybrid Adaptive Momentum-Rotation (HAMR)\n\n    Key ideas:\n      - Maintain mean m, covariance C, global sigma, directional momentum v, per-coordinate scales s_diag and a lightweight rotation R.\n      - Sample antithetic Gaussian candidates, bias samples along momentum, scale per-coordinate magnitudes, and optionally probe along an archive-derived pseudo-gradient.\n      - Update covariance as a mixture of rank-mu and rank-one momentum outer product, update momentum and s_diag by EMA, adapt sigma by smoothed success-rate, use simulated-annealing acceptance, and opportunistic restarts on stagnation.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # tunables (sensible defaults)\n        self.pop_base = None\n        self.c_cov = 0.18          # rank-mu learning rate\n        self.c_rank1 = 0.06        # rank-one momentum weight\n        self.mom_beta = 0.8        # momentum EMA\n        self.scale_beta = 0.6      # per-coordinate scale EMA\n        self.sigma_adapt_rate = 0.25\n        self.succ_target = 0.2\n        self.rotation_rate = 0.10\n        self.arch_size = None      # if None, set to ~4*dim\n        self.stagnation_frac = 0.04\n        self.min_sigma = 1e-12\n        self.max_sigma_scale = 3.0\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = ub - lb\n        # population size (modest, dimension dependent)\n        if self.pop_base is None:\n            lam0 = max(6, int(4 + 2 * np.log(max(2, self.dim))))\n        else:\n            lam0 = int(self.pop_base)\n        lam0 = min(lam0, max(2, self.budget))\n\n        # archive length\n        if self.arch_size is None:\n            arch_size = max(4 * self.dim, 20)\n        else:\n            arch_size = int(self.arch_size)\n\n        # initial small batch to seed\n        evals = 0\n        batch0 = min(lam0, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(batch0, self.dim))\n        f0 = np.empty(batch0, dtype=float)\n        for i in range(batch0):\n            f0[i] = func(X0[i])\n            evals += 1\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # mean initialized as weighted average of top-half\n        mu0 = max(1, batch0 // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 = w0 / np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # covariance and sigma initial\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.2 * np.mean(bounds_scale))\n\n        # additional state\n        v = np.zeros(self.dim, dtype=float)       # directional momentum (normalized coords)\n        s_diag = np.ones(self.dim, dtype=float)   # per-coordinate multiplicative scaling\n        R = np.eye(self.dim)                      # light rotation (columns basis)\n        p_succ = 0.2\n        stagn_count = 0\n        stagn_limit = max(5, int(self.stagnation_frac * self.budget))\n\n        # archive for surrogate gradient (FIFO)\n        X_arch = []\n        f_arch = []\n\n        # seed archive with initial points\n        for i in range(batch0):\n            X_arch.append(X0[i].copy())\n            f_arch.append(float(f0[i]))\n        # ensure at least one\n        if len(f_arch) == 0:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(f)\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n\n        # main loop\n        while evals < self.budget:\n            remaining = self.budget - evals\n            lam = min(lam0, remaining)\n            lam = max(2 if remaining >= 2 else 1, lam)  # prefer at least 2 for antithetic\n\n            mu = max(1, lam // 2)\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n            W = weights.reshape(-1, 1)\n\n            # ensure SPD for C with jitter, compute chol\n            eps_diag = 1e-12 * np.maximum(np.diag(C), 1.0)\n            A = None\n            try:\n                A = np.linalg.cholesky(C + np.diag(eps_diag))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n\n            # build rotated chol to bias basis: A_rot = A @ R  (columns rotated)\n            A_rot = A @ R\n\n            # antithetic sampling: draw half and mirror\n            half = lam // 2\n            Zpos = rng.normal(size=(half, self.dim))\n            Z = np.vstack([Zpos, -Zpos])\n            if lam % 2 == 1:\n                Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n\n            # transform to correlated samples\n            Y = Z @ A_rot.T  # shape (lam, dim)\n\n            # add per-coordinate multiplicative scaling in sample coordinates\n            Y = Y * s_diag.reshape(1, -1)\n\n            # directional momentum perturbation (normalized)\n            vlen = np.linalg.norm(v) + 1e-20\n            if vlen > 0:\n                v_unit = v / vlen\n            else:\n                v_unit = np.zeros_like(v)\n            dir_strength = 0.7 * (vlen / (1.0 + vlen))\n            s_scalar = rng.normal(scale=dir_strength, size=(Y.shape[0], 1))\n            Y = Y + s_scalar * v_unit.reshape(1, -1)\n\n            # generate optional archive-surrogate probe (1 or 2 points) if archive is informative\n            # compute a cheap local surrogate gradient if we have enough archive points\n            grad = None\n            if len(X_arch) >= min(6, self.dim + 1):\n                X_arr = np.asarray(X_arch[-min(len(X_arch), arch_size):])\n                f_arr = np.asarray(f_arch[-min(len(X_arch), arch_size):])\n                # center at m\n                Xc = X_arr - m.reshape(1, -1)\n                # weight by proximity and fitness\n                dnorm = np.linalg.norm(Xc / (sigma + 1e-20), axis=1)\n                wdist = np.exp(-0.5 * dnorm)\n                frange = np.ptp(f_arr) + 1e-12\n                wrank = np.exp(-0.6 * (f_arr - np.min(f_arr)) / frange)\n                w = wdist * (0.5 * wrank + 0.5)\n                Wsq = np.sqrt(w).reshape(-1, 1)\n                y = (f_arr - np.min(f_arr))\n                try:\n                    A_lin = (Wsq * Xc).T @ (Wsq * Xc) + 1e-6 * np.eye(self.dim)\n                    b_lin = (Wsq * Xc).T @ (Wsq * y)\n                    grad = np.linalg.solve(A_lin, b_lin)\n                except np.linalg.LinAlgError:\n                    grad = None\n\n            # map Y to candidates Xcand = m + sigma * Y (clamped later)\n            Xcand = m.reshape(1, -1) + sigma * Y\n\n            # if grad available and there is room, append 1-2 directed probes\n            probes = []\n            if grad is not None and (remaining - Xcand.shape[0]) > 0:\n                gnorm = np.linalg.norm(grad) + 1e-20\n                probe_len = 1.2 * sigma * min(2.5, sigma / (np.mean(bounds_scale) + 1e-20))\n                x1 = m - probe_len * (grad / gnorm)\n                probes.append(x1)\n                if (remaining - Xcand.shape[0] - 1) > 0:\n                    x2 = m - 2.2 * probe_len * (grad / gnorm)\n                    probes.append(x2)\n                if len(probes) > 0:\n                    Xcand = np.vstack([Xcand, np.asarray(probes)])\n\n            # clamp to bounds\n            Xcand = np.minimum(np.maximum(Xcand, lb.reshape(1, -1)), ub.reshape(1, -1))\n\n            # evaluate sequentially with budget guard\n            ncand = Xcand.shape[0]\n            fc = np.full(ncand, np.inf)\n            for i in range(ncand):\n                if evals >= self.budget:\n                    break\n                x = Xcand[i]\n                fval = float(func(x))\n                fc[i] = fval\n                evals += 1\n\n                # update archive FIFO\n                X_arch.append(x.copy())\n                f_arch.append(fval)\n                if len(X_arch) > arch_size:\n                    del X_arch[0]\n                    del f_arch[0]\n\n                # update global best\n                if fval < f_best:\n                    f_best = fval\n                    x_best = x.copy()\n                    stagn_count = 0\n                else:\n                    stagn_count += 1\n\n            # truncate arrays for unevaluated slots\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                ncand = fc.shape[0]\n                if ncand == 0:\n                    break\n\n            # selection: pick elites by fc\n            order = np.argsort(fc)\n            mu_eff = min(mu, ncand)\n            X_mu = Xcand[order[:mu_eff]]\n\n            # compute normalized deltas (in sample coords) relative to current m\n            deltas = (X_mu - m.reshape(1, -1)) / (sigma + 1e-20)\n\n            # weighted covariance in normalized coords\n            if deltas.shape[0] > 0:\n                if deltas.shape[0] != weights.shape[0]:\n                    # recompute small-ensemble weights\n                    mu_eff2 = deltas.shape[0]\n                    w_eff = np.log(mu_eff2 + 0.5) - np.log(np.arange(1, mu_eff2 + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if np.sum(w_eff) <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff = w_eff / np.sum(w_eff)\n                    Wd = w_eff.reshape(-1, 1)\n                    weighted_cov = (deltas * Wd).T @ deltas\n                    delta_mean = (Wd * deltas).sum(axis=0)\n                else:\n                    weighted_cov = (deltas * W).T @ deltas\n                    delta_mean = (W * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # update momentum\n            v = self.mom_beta * v + (1.0 - self.mom_beta) * delta_mean\n\n            # rank-one from momentum (in normalized sample coords)\n            rank_one = np.outer(v, v)\n\n            # covariance update (in normalized coords)\n            c_cov = float(self.c_cov)\n            c1 = float(self.c_rank1)\n            keep = max(0.0, 1.0 - c_cov - c1)\n            C = keep * C + c_cov * weighted_cov + c1 * rank_one\n            # symmetrize and ensure SPD\n            C = 0.5 * (C + C.T) + np.diag(np.maximum(np.diag(C), 1e-18))\n\n            # update per-coordinate scale (EMA of absolute rotated normalized steps)\n            # compute deltas in rotated basis (approx): u = deltas @ R.T\n            if deltas.shape[0] > 0:\n                deltas_rot = deltas @ R.T\n                stat = np.mean(np.abs(deltas_rot), axis=0)\n            else:\n                stat = 1e-6 * np.ones(self.dim)\n            s_diag = self.scale_beta * s_diag + (1.0 - self.scale_beta) * (stat + 1e-12)\n            s_diag = np.clip(s_diag, 0.08, 6.0)\n\n            # update rotation R using small Givens rotations toward best normalized directions\n            try:\n                # pick top improving candidate indices (best + chosen)\n                top_indices = [order[0]] if ncand > 0 else []\n                if len(top_indices) > 0:\n                    for idx_try in top_indices:\n                        if 0 <= idx_try < ncand:\n                            u = ((Xcand[idx_try] - m) / (sigma + 1e-20))\n                            if np.linalg.norm(u) > 1e-12:\n                                # identify two coordinates with largest absolute rotated components\n                                urot = u @ R.T\n                                p, q = np.argsort(np.abs(urot))[-2:]\n                                if p != q:\n                                    up = np.dot(urot, np.eye(self.dim)[p])\n                                    uq = np.dot(urot, np.eye(self.dim)[q])\n                                    theta = self.rotation_rate * (uq / (abs(up) + abs(uq) + 1e-12))\n                                    c = np.cos(theta)\n                                    srot = np.sin(theta)\n                                    G = np.eye(self.dim)\n                                    G[[p, p, q, q], [p, q, p, q]] = [c, -srot, srot, c]\n                                    R = R @ G\n                                    # occasional re-orthonormalize\n                                    if (evals % 71) == 0:\n                                        try:\n                                            Q, _ = np.linalg.qr(R)\n                                            R = Q\n                                        except np.linalg.LinAlgError:\n                                            R = np.eye(self.dim)\n            except Exception:\n                R = np.eye(self.dim)\n\n            # choose a candidate to try moving mean towards (fitness-weighted)\n            fshift = fc - np.min(fc) + 1e-12\n            invw = 1.0 / fshift\n            probs = invw / np.sum(invw)\n            chosen_idx = int(rng.choice(ncand, p=probs))\n            chosen_x = Xcand[chosen_idx]\n            chosen_f = fc[chosen_idx]\n\n            # acceptance with simulated annealing like temperature based on sigma and scale\n            temp = max(1e-6, sigma / (np.mean(bounds_scale) + 1e-20))\n            delta_f = chosen_f - f_best\n            accept = False\n            if chosen_f <= f_best:\n                accept = True\n            else:\n                # allow uphill with probability\n                if rng.rand() < np.exp(-max(0.0, delta_f) / (temp + 1e-12)):\n                    accept = True\n\n            if accept:\n                eta = 0.3 if chosen_f < f_best else 0.12\n                m = (1.0 - eta) * m + eta * chosen_x\n            else:\n                # small exploratory drift\n                m = m + 0.03 * sigma * (rng.randn(self.dim) @ R.T)\n                # clamp\n                m = np.minimum(np.maximum(m, lb), ub)\n\n            # update smoothed success probability and adapt sigma multiplicatively\n            gen_success = float(np.any(fc < f_best + 1e-16))\n            p_succ = 0.85 * p_succ + 0.15 * gen_success\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, self.min_sigma, self.max_sigma_scale * np.max(bounds_scale))\n\n            # opportunistic restart if stagnated\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # restart around best if available\n                if np.isfinite(f_best):\n                    jitter_scale = max(0.08 * np.mean(bounds_scale), 0.5 * sigma)\n                    m = x_best + rng.randn(self.dim) * jitter_scale\n                else:\n                    m = rng.uniform(lb, ub, size=self.dim)\n                m = np.minimum(np.maximum(m, lb), ub)\n                # reset covariance, rotation, scales, momentum\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                R = np.eye(self.dim)\n                s_diag = np.ones(self.dim)\n                v = np.zeros(self.dim)\n                sigma = max(sigma * 1.6, 0.2 * np.mean(bounds_scale))\n                # trim archive to encourage new directions\n                keep = max(1, len(X_arch) // 4)\n                X_arch = X_arch[-keep:]\n                f_arch = f_arch[-keep:]\n                continue\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 193, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x1 = m - probe_len * (grad / gnorm)", "error": "In the code, line 193, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x1 = m - probe_len * (grad / gnorm)", "parent_ids": "ab6afe0d-0bde-4d10-b826-cc3e4f5b876d", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "83ccfc20-cbe4-4522-bb39-b99a4824c6a9", "fitness": 0.4011916042717706, "name": "MPjDE_DiagDirectional", "description": "The algorithm uses a compact, quasi‑uniform (Latin‑like) initialization with a small population (pop_min=12) and jDE-style self-adaptive F/CR (tau1/tau2≈0.12, F clipped in [0.05,0.9]) so mutation strengths adapt per individual while keeping a bias toward p-best/current-to-pbest strategies (strategy_mix_prob=0.08 is low, so rand/1 is rare). Each individual maintains an isotropic sigma (sigma_init_frac≈0.22 of problem scale, with tiny sigma_min and adaptive increase/decrease driven by a windowed success history) and trials combine DE mutation + a mean-pull term (alpha_mean=0.6, a fairly strong attraction to the population mean) plus Gaussian jitter; occasional opposition sampling (opposition_prob≈0.12) and tau_sigma_reset introduce exploratory diversity. Successful step vectors are recorded and their SVD principal direction drives periodic directional line probes, while a budget‑aware randomized coordinate‑descent local search (local_period≈14, local_init_frac≈0.18, shrink factor 0.5) performs opportunistic multi-step refinements around the best solution. Boundary handling uses reflect-then-clamp, improvements are injected by replacing the worst, stagnation triggers jittered partial restarts, and all operations are strictly budget‑aware to never exceed the given evaluation limit.", "code": "import numpy as np\n\nclass MPjDE_DiagDirectional:\n    \"\"\"\n    Mean-Pulled jDE with Diagonal Adaptive Directional Local Search (MPjDE_Dir)\n\n    Key features:\n      - Small quasi-uniform (Latin-like) initial population and jDE-style self-adaptive F/CR.\n      - Per-individual isotropic sigma that adapts from a windowed success history (increase/decrease multipliers).\n      - Mean-pull bias: trial = xi + alpha_mean*(pop_mean - xi) + DE_mutation + Gaussian(sigma_i).\n      - Opposition sampling occasionally evaluated additionally.\n      - Maintain short success_steps history -> SVD principal direction used for directional line probes.\n      - Periodic budget-aware randomized coordinate descent around global best with shrinking steps.\n      - Mild stagnation-driven jittered restarts and strict budget accounting.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop_min=12,\n                 p_frac=0.2,\n                 tau1=0.12, tau2=0.12,\n                 F_min=0.05, F_max=0.9,\n                 strategy_mix_prob=0.08,\n                 sigma_init_frac=0.22, sigma_min_frac=1e-5, sigma_max_frac=1.2,\n                 window_len=12, decrease_factor=0.92, increase_factor=1.07, tau_sigma_reset=0.04,\n                 alpha_mean=0.6,\n                 opposition_prob=0.12,\n                 local_period=14, local_stagn_gen=30,\n                 local_init_frac=0.18, local_shrink=0.5, local_min_frac=1e-5,\n                 success_hist_len=12,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.pop_min = int(pop_min)\n        self.p_frac = float(p_frac)\n        self.tau1 = float(tau1)\n        self.tau2 = float(tau2)\n        self.F_min = float(F_min)\n        self.F_max = float(F_max)\n        self.strategy_mix_prob = float(strategy_mix_prob)\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.sigma_min_frac = float(sigma_min_frac)\n        self.sigma_max_frac = float(sigma_max_frac)\n        self.window_len = int(window_len)\n        self.decrease_factor = float(decrease_factor)\n        self.increase_factor = float(increase_factor)\n        self.tau_sigma_reset = float(tau_sigma_reset)\n        self.alpha_mean = float(alpha_mean)\n        self.opposition_prob = float(opposition_prob)\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.local_init_frac = float(local_init_frac)\n        self.local_shrink = float(local_shrink)\n        self.local_min_frac = float(local_min_frac)\n        self.success_hist_len = int(success_hist_len)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        range_mean = float(np.mean(span))\n        eps = 1e-12\n\n        # population size (compact)\n        pop = max(self.pop_min, int(4 + 3 * np.log(max(2, self.dim))))\n        pop = min(pop, max(2, self.budget))\n\n        evals = 0\n\n        # Latin-like stratified initialization with jitter\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        jitter_scale = 0.35 * range_mean / max(1.0, self.dim)\n        X += (rng.rand(pop, self.dim) - 0.5) * jitter_scale\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population sequentially\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            f[i] = float(func(X[i]))\n            evals += 1\n\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:i+1]))\n            self.f_opt = float(f[best_idx])\n            self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # jDE style F and CR\n        F = np.clip(0.5 + 0.12 * rng.randn(pop), self.F_min, self.F_max)\n        CR = np.clip(rng.rand(pop), 0.0, 1.0)\n\n        # per-individual sigma (isotropic)\n        sigma = np.full(pop, max(eps, self.sigma_init_frac * range_mean), dtype=float)\n        sigma_min = max(eps, self.sigma_min_frac * range_mean)\n        sigma_max = max(eps, self.sigma_max_frac * range_mean)\n\n        # success-history window for sigma adaptation\n        win = max(1, self.window_len)\n        success_hist = np.zeros((pop, win), dtype=np.int8)\n        hist_pos = 0\n\n        # success_steps history for directional probes (SVD)\n        success_steps = []\n\n        # tracking best\n        best_idx = int(np.argmin(f))\n        f_best = float(f[best_idx])\n        x_best = X[best_idx].copy()\n        gen = 0\n        gens_since_improve = 0\n\n        def reflect_then_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            pop_mean = np.mean(X, axis=0)\n            order = rng.permutation(pop)\n            gen_success = np.zeros(pop, dtype=np.int8)\n\n            for ii in order:\n                if evals >= self.budget:\n                    break\n\n                # jDE-style adaptation of F and CR\n                if rng.rand() < self.tau1:\n                    F[ii] = np.clip(0.5 * (1.0 + 0.6 * rng.randn()), self.F_min, self.F_max)\n                if rng.rand() < self.tau2:\n                    CR[ii] = rng.rand()\n\n                xi = X[ii].copy()\n\n                # occasional sigma reset\n                if rng.rand() < self.tau_sigma_reset:\n                    sigma[ii] = rng.rand() * (sigma_max - sigma_min) + sigma_min\n\n                # choose mutation: mostly current-to-pbest/1, small chance rand/1\n                if rng.rand() < self.strategy_mix_prob:\n                    # rand/1\n                    pool = [j for j in range(pop) if j != ii]\n                    if len(pool) >= 3:\n                        r1, r2, r3 = rng.choice(pool, size=3, replace=False)\n                        mutant = X[r1] + F[ii] * (X[r2] - X[r3])\n                    else:\n                        mutant = xi + F[ii] * (rng.randn(self.dim) * range_mean * 0.01)\n                else:\n                    # current-to-pbest/1\n                    pnum = max(2, int(np.ceil(self.p_frac * pop)))\n                    idxs_sorted = np.argsort(f)\n                    p_pool = idxs_sorted[:pnum]\n                    pbest_idx = int(rng.choice(p_pool))\n                    pool = [j for j in range(pop) if j not in (ii, pbest_idx)]\n                    if len(pool) >= 2:\n                        r1, r2 = rng.choice(pool, size=2, replace=False)\n                    else:\n                        r1 = r2 = ii\n                    xp = X[pbest_idx]\n                    xr1 = X[r1]\n                    xr2 = X[r2]\n                    mutant = xi + F[ii] * (xp - xi) + F[ii] * (xr1 - xr2)\n\n                # mean pull and gaussian perturbation scaled by sigma[ii]\n                pull = self.alpha_mean * (pop_mean - xi)\n                gauss = rng.randn(self.dim) * sigma[ii]\n\n                # trial candidate before crossover\n                trial_base = mutant + pull + gauss\n\n                # binomial crossover\n                jrand = rng.randint(self.dim)\n                mask = rng.rand(self.dim) < CR[ii]\n                mask[jrand] = True\n                trial = np.where(mask, trial_base, xi)\n                trial = reflect_then_clamp(trial)\n\n                # opposition sampling occasionally\n                candidates = [trial]\n                if rng.rand() < self.opposition_prob:\n                    opp = lb + ub - trial\n                    opp += rng.randn(self.dim) * (0.01 * range_mean)\n                    opp = reflect_then_clamp(opp)\n                    candidates.append(opp)\n\n                # opportunistic evaluation: evaluate candidates in order and pick best within budget\n                best_local_x = None\n                best_local_f = np.inf\n                for cand in candidates:\n                    if evals >= self.budget:\n                        break\n                    fv = float(func(cand))\n                    evals += 1\n                    if fv < best_local_f:\n                        best_local_f = fv\n                        best_local_x = cand.copy()\n\n                # selection\n                if best_local_f <= f[ii]:\n                    step_vec = best_local_x - X[ii]\n                    if np.linalg.norm(step_vec) > 0:\n                        success_steps.append(step_vec.copy())\n                        if len(success_steps) > self.success_hist_len:\n                            success_steps.pop(0)\n                    X[ii] = best_local_x\n                    f[ii] = best_local_f\n                    gen_success[ii] = 1\n                    if best_local_f < f_best:\n                        f_best = best_local_f\n                        x_best = best_local_x.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    gen_success[ii] = 0\n\n            # update success history circularly\n            success_hist[:, hist_pos] = gen_success\n            hist_pos = (hist_pos + 1) % win\n\n            # adapt sigma per individual\n            success_rate = np.sum(success_hist, axis=1) / float(win)\n            for i in range(pop):\n                if success_rate[i] > 0.25:\n                    sigma[i] = max(sigma_min, sigma[i] * self.decrease_factor)\n                elif success_rate[i] < 0.15:\n                    sigma[i] = min(sigma_max, sigma[i] * self.increase_factor)\n                # small jitter to maintain diversity\n                if rng.rand() < 0.015:\n                    sigma[i] = np.clip(sigma[i] * (1.0 + 0.05 * rng.randn()), sigma_min, sigma_max)\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # Periodic directional local probes guided by SVD of success steps\n            if gen % max(1, int(self.local_period // 2)) == 0 and len(success_steps) >= 2 and evals < self.budget:\n                # compute principal direction\n                try:\n                    S = np.vstack(success_steps)\n                    S_centered = S - S.mean(axis=0, keepdims=True)\n                    _, _, vh = np.linalg.svd(S_centered, full_matrices=False)\n                    pr_dir = vh[0]\n                    nrm = np.linalg.norm(pr_dir)\n                    if nrm > 0:\n                        pr_dir = pr_dir / nrm\n                    else:\n                        pr_dir = None\n                except Exception:\n                    pr_dir = None\n\n                if pr_dir is not None:\n                    step = max(eps, 0.5 * np.mean(sigma)) * (1.0 + 0.6 * rng.rand())\n                    # try both signs with opportunistic extra probe\n                    for sign in (+1.0, -1.0):\n                        if evals >= self.budget:\n                            break\n                        x_try = x_best + sign * step * pr_dir\n                        x_try = reflect_then_clamp(x_try)\n                        fv = float(func(x_try))\n                        evals += 1\n                        if fv < f_best:\n                            # extra probe further along direction\n                            if evals < self.budget:\n                                x_try2 = x_try + sign * step * pr_dir\n                                x_try2 = reflect_then_clamp(x_try2)\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < fv:\n                                    x_try, fv = x_try2, fv2\n                            # accept\n                            step_vec = x_try - x_best\n                            if np.linalg.norm(step_vec) > 0:\n                                success_steps.append(step_vec.copy())\n                                if len(success_steps) > self.success_hist_len:\n                                    success_steps.pop(0)\n                            x_best = x_try.copy()\n                            f_best = float(fv)\n                            # inject improvement into population (replace worst)\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = x_best.copy()\n                            f[worst_idx] = f_best\n                            gens_since_improve = 0\n\n            # Periodic or stagnation-driven randomized coordinate-descent local refinement around best\n            if gen % self.local_period == 0 or gens_since_improve >= self.local_stagn_gen:\n                remaining = self.budget - evals\n                if remaining <= 0:\n                    break\n\n                step = max(eps, self.local_init_frac * range_mean)\n                min_step = max(eps, self.local_min_frac * range_mean)\n                if gens_since_improve >= self.local_stagn_gen:\n                    step *= 2.0\n\n                local_improved = False\n                x_work = x_best.copy()\n                f_work = f_best\n\n                # randomized coordinate descent with opportunistic extensions\n                while step >= min_step and (self.budget - evals) > 0:\n                    moved = False\n                    dims_order = list(range(self.dim))\n                    rng.shuffle(dims_order)\n                    for d in dims_order:\n                        if evals >= self.budget:\n                            break\n                        # try plus\n                        x_try = x_work.copy()\n                        x_try[d] = min(ub[d], x_try[d] + step)\n                        if np.allclose(x_try, x_work):\n                            # try minus if plus did nothing\n                            x_try[d] = max(lb[d], x_work[d] - step)\n                        x_try = reflect_then_clamp(x_try)\n                        fv = float(func(x_try))\n                        evals += 1\n                        if fv < f_work:\n                            # opportunistic probe further along same direction\n                            if evals < self.budget:\n                                x_try2 = x_try.copy()\n                                x_try2[d] = np.minimum(np.maximum(x_try2[d] + step, lb[d]), ub[d])\n                                x_try2 = reflect_then_clamp(x_try2)\n                                fv2 = float(func(x_try2))\n                                evals += 1\n                                if fv2 < fv:\n                                    x_try, fv = x_try2, fv2\n                            step_vec = x_try - x_work\n                            if np.linalg.norm(step_vec) > 0:\n                                success_steps.append(step_vec.copy())\n                                if len(success_steps) > self.success_hist_len:\n                                    success_steps.pop(0)\n                            x_work = x_try.copy()\n                            f_work = fv\n                            moved = True\n                            local_improved = True\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = x_work.copy()\n                                gens_since_improve = 0\n                        else:\n                            # try opposite\n                            if evals >= self.budget:\n                                break\n                            x_try = x_work.copy()\n                            x_try[d] = max(lb[d], x_work[d] - step)\n                            x_try = reflect_then_clamp(x_try)\n                            fv = float(func(x_try))\n                            evals += 1\n                            if fv < f_work:\n                                step_vec = x_try - x_work\n                                if np.linalg.norm(step_vec) > 0:\n                                    success_steps.append(step_vec.copy())\n                                    if len(success_steps) > self.success_hist_len:\n                                        success_steps.pop(0)\n                                x_work = x_try.copy()\n                                f_work = fv\n                                moved = True\n                                local_improved = True\n                                if fv < f_best:\n                                    f_best = fv\n                                    x_best = x_work.copy()\n                                    gens_since_improve = 0\n                    if not moved:\n                        step *= self.local_shrink\n\n                # inject local improvement\n                if local_improved:\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_work.copy()\n                    f[worst_idx] = f_work\n                    gens_since_improve = 0\n                else:\n                    # stagnation mild restart: jitter half population around best\n                    if gens_since_improve >= self.local_stagn_gen:\n                        half = max(1, pop // 2)\n                        for k in range(half):\n                            if evals >= self.budget:\n                                break\n                            jitter = rng.randn(self.dim) * (0.12 * range_mean)\n                            newx = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                            fv = float(func(newx))\n                            evals += 1\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = newx\n                            f[worst_idx] = fv\n                            sigma[worst_idx] = max(sigma_min, min(sigma_max, 0.6 * np.mean(sigma)))\n                            if fv < f_best:\n                                f_best = fv\n                                x_best = newx.copy()\n                                gens_since_improve = 0\n\n            # ensure best sync from population\n            current_best_idx = int(np.argmin(f))\n            if f[current_best_idx] < f_best:\n                f_best = float(f[current_best_idx])\n                x_best = X[current_best_idx].copy()\n                gens_since_improve = 0\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MPjDE_DiagDirectional scored 0.401 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ab6afe0d-0bde-4d10-b826-cc3e4f5b876d", "operator": null, "metadata": {"aucs": [0.12536754603315015, 0.19097188312770585, 0.4306326842948147, 0.989144377368976, 0.36182736432497553, 0.8476516231548707, 0.27823116840344186, 0.38394621233167336, 0.25230185147710105, 0.15184133220099671]}, "task_prompt": ""}
{"id": "a502e03b-784f-4102-999b-4f644b5096d8", "fitness": 0.16857684332803777, "name": "ADSE_Mirror", "description": "The algorithm builds anisotropic antithetic (mirrored) sampling: each pair x± = m ± step uses a low‑rank orthonormal subspace D (rank default ≈ dim/4) scaled by direction energies p plus per‑coordinate residual noise s to form steps, with occasional long random jumps and strict bound clipping. Global scale sigma is initialized to 0.15·avg_span and adapted multiplicatively via a smoothed success probability (EMA smooth_p=0.9, target succ_target=0.25, sigma_adapt_rate=0.30, capped by sigma_max_mult), while the mean is updated with momentum (momentum_beta=0.7) and trust‑radius clipping (4·sigma·sqrt(dim)) and allows probabilistic uphill acceptance scaled by sigma·avg_span. The algorithm reassigns variance to productive directions by computing directional_gains from mirrored pair outcomes and applying a softmax/smoothing to p, and periodically refreshes D and p via PCA/SVD on buffered successful normalized steps (pca_period default 10), with small random rotations to maintain exploration and per‑coordinate s updated from median absolute normalized steps. Robustness measures include a FIFO archive (arch_size ≈ max(6·dim,40)), population sizing (pop_base ≈ max(8,6+0.8 ln dim)), stagnation detection and opportunistic restarts (stagn_thresh_frac, restart_infl=1.6) plus numerical safeguards (diag_reg, min/max dir energies, sigma_min) to stabilize optimization.", "code": "import numpy as np\n\nclass ADSE_Mirror:\n    \"\"\"\n    Adaptive Directional Subspace Evolution with Mirrored Sampling\n\n    Key ideas:\n    - Maintain mean `m`, global scale `sigma`, a low-rank subspace D (dim x r) with\n      direction weights `p` (energies) and per-coordinate residual scales `s`.\n    - Use antithetic / mirrored paired sampling x+ = m + step and x- = m - step to\n      reduce sampling variance and produce directional improvement estimates.\n    - Accumulate directional \"gain\" statistics from mirrored pairs to reallocate\n      variance (softmax of gains) into productive low-rank directions.\n    - Periodically refresh subspace via PCA/SVD on collected successful step vectors.\n    - Use momentum-inspired update to the mean and multiplicative sigma adaptation\n      controlled by smoothed success probability.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 rank=None, pop_base=None, arch_size=None, pca_period=10):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.rng = np.random.RandomState(self.rng_seed)\n\n        # structural settings\n        self.rank = int(rank) if rank is not None else max(1, min(self.dim, max(1, self.dim // 4)))\n        self.pop_base = pop_base if pop_base is not None else max(8, int(6 + 0.8 * np.log(max(2, self.dim))))\n        self.arch_size = arch_size if arch_size is not None else max(6 * self.dim, 40)\n        self.pca_period = int(pca_period)\n\n        # adaptation hyperparameters\n        self.succ_target = 0.25\n        self.smooth_p = 0.9     # EMA for success probability\n        self.sigma_adapt_rate = 0.30\n        self.sigma_min = 1e-9\n        self.sigma_max_mult = 3.0\n        self.lr_mean = 0.25     # base learning rate to move mean toward promising points\n        self.momentum_beta = 0.7\n\n        # subspace & regularization\n        self.diag_reg = 1e-8\n        self.min_dir_energy = 1e-4\n        self.max_dir_energy = 10.0\n\n        # stagnation\n        self.stagn_thresh_frac = 0.05\n        self.restart_infl = 1.6\n\n        # exploration\n        self.long_jump_prob = 0.04\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds: prefer func.bounds if present, else default [-5,5]\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize mean uniformly in bounds\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # initial global scale\n        sigma = max(1e-12, 0.15 * avg_span)\n\n        # low-rank orthonormal subspace D and direction energies p\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            D = Q[:, :r].copy()\n            p = np.ones(r)  # relative energies (will be softmax-rescaled)\n        else:\n            D = np.zeros((self.dim, 0))\n            p = np.array([])\n\n        # per-coordinate residual scales (for orthogonal noise)\n        s = np.full(self.dim, 0.35)\n\n        # momentum term for mean updates\n        mom = np.zeros(self.dim)\n\n        # archives: store evaluated points and values\n        X_arch = []\n        f_arch = []\n\n        # buffers for successful normalized steps (for PCA)\n        success_steps = []  # raw step vectors (normalized by sigma)\n\n        # initialize with a few random samples\n        evals = 0\n        init_pop = min(self.pop_base, max(6, int(self.budget // 80)))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # adaptive controllers\n        p_succ = 0.2\n        stagn_limit = max(5, int(self.stagn_thresh_frac * self.budget))\n        stagn_counter = 0\n\n        gen = 0\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            # ensure even for mirrored pairs: we will consume pairs where possible\n            if lam % 2 == 1 and lam > 1:\n                lam -= 1\n\n            # candidate storage for batch (for bookkeeping, but decisions are made via mirrored pairs)\n            cand_X = []\n            cand_f = []\n            cand_types = []\n\n            # statistics for this generation\n            gen_success = False\n            pair_count = 0\n            directional_gains = np.zeros(r) if r > 0 else np.array([])\n\n            # mirrored sampling loop: generate lam/2 pairs (each pair consumes 2 evaluations)\n            pairs = lam // 2\n            for _ in range(pairs):\n                if evals + 2 > self.budget:\n                    break\n\n                # draw subspace coefficients and diag noise\n                if r > 0:\n                    z_r = rng.randn(r) * np.sqrt(np.maximum(p, self.diag_reg))  # scale by sqrt of energies\n                    low = D.dot(z_r)  # dim vector\n                else:\n                    low = np.zeros(self.dim)\n\n                z_d = rng.randn(self.dim) * s  # per-coordinate residual\n                step = sigma * (low + z_d)     # full step vector\n\n                # mirrored pair\n                x_plus = m + step\n                x_minus = m - step\n\n                # occasionally long leap (global random)\n                if rng.rand() < self.long_jump_prob:\n                    x_plus = rng.uniform(lb, ub, size=self.dim)\n                # clip into bounds\n                x_plus = np.minimum(np.maximum(x_plus, lb), ub)\n                x_minus = np.minimum(np.maximum(x_minus, lb), ub)\n\n                # evaluate both\n                f_plus = float(func(x_plus))\n                f_minus = float(func(x_minus))\n                evals += 2\n\n                # store in archive\n                X_arch.append(x_plus.copy())\n                f_arch.append(f_plus)\n                X_arch.append(x_minus.copy())\n                f_arch.append(f_minus)\n                # keep FIFO\n                while len(X_arch) > self.arch_size:\n                    del X_arch[0]\n                    del f_arch[0]\n\n                cand_X.extend([x_plus.copy(), x_minus.copy()])\n                cand_f.extend([f_plus, f_minus])\n                cand_types.extend(['mirror', 'mirror'])\n\n                # update global best and stagnation\n                improved = False\n                if f_plus < f_best:\n                    f_best = f_plus\n                    x_best = x_plus.copy()\n                    improved = True\n                    stagn_counter = 0\n                if f_minus < f_best:\n                    f_best = f_minus\n                    x_best = x_minus.copy()\n                    improved = True\n                    stagn_counter = 0\n                if not improved:\n                    stagn_counter += 1\n\n                # compute directional scalar gain from this pair:\n                # Use symmetric difference (f_minus - f_plus) along step to estimate directional derivative:\n                # If moving +step reduces f (f_plus < f_minus) then direction low+diag noise is promising.\n                # Gain magnitude = max(0, (f_minus - f_plus)) normalized by step norm.\n                pair_count += 1\n                delt = f_minus - f_plus  # positive means +step better than -step\n                # normalized step direction in subspace coordinates for attribution\n                step_norm = np.linalg.norm(step) + 1e-12\n                step_unit = step / step_norm\n\n                # attribute gain to subspace components by projecting step_unit onto D\n                if r > 0:\n                    proj = D.T.dot(step_unit)  # length r\n                    # reward each direction by absolute projection * positive gain\n                    reward = np.maximum(0.0, delt) * np.abs(proj)\n                    directional_gains += reward\n\n                # record successful steps normalized by sigma for PCA buffer if improvement occurs\n                if (f_plus <= f_best + 1e-12) or (f_minus <= f_best + 1e-12) or (delt > 0):\n                    # normalized steps (w.r.t sigma)\n                    success_steps.append((step / (sigma + 1e-12)).copy())\n                    # keep buffer length bounded\n                    if len(success_steps) > max(40, self.arch_size // 2):\n                        del success_steps[0]\n\n                # store pair results\n                gen_success = gen_success or (improved or (delt > 0))\n\n            # if there is remaining one eval (when lam was odd), do a single gaussian-like sample\n            if evals < self.budget and lam % 2 == 1:\n                if evals + 1 > self.budget:\n                    pass\n                else:\n                    # single exploratory gaussian sample using current anisotropic model\n                    if r > 0:\n                        zr = rng.randn(r) * np.sqrt(np.maximum(p, self.diag_reg))\n                        low = D.dot(zr)\n                    else:\n                        low = np.zeros(self.dim)\n                    zd = rng.randn(self.dim) * s\n                    step = sigma * (low + zd)\n                    x = m + step\n                    if rng.rand() < self.long_jump_prob:\n                        x = rng.uniform(lb, ub, size=self.dim)\n                    x = np.minimum(np.maximum(x, lb), ub)\n                    f_x = float(func(x))\n                    evals += 1\n                    X_arch.append(x.copy())\n                    f_arch.append(f_x)\n                    while len(X_arch) > self.arch_size:\n                        del X_arch[0]\n                        del f_arch[0]\n                    cand_X.append(x.copy())\n                    cand_f.append(f_x)\n                    cand_types.append('single')\n                    if f_x < f_best:\n                        f_best = f_x\n                        x_best = x.copy()\n                        gen_success = True\n                        stagn_counter = 0\n                    else:\n                        stagn_counter += 1\n                    # keep step for PCA if it helped\n                    if f_x <= f_best + 1e-12:\n                        success_steps.append((step / (sigma + 1e-12)).copy())\n                        if len(success_steps) > max(40, self.arch_size // 2):\n                            del success_steps[0]\n\n            # choose candidate(s) to influence mean:\n            # Favor the top fraction by softmax on negative objective relative to local min\n            if len(cand_f) == 0:\n                break\n            f_array = np.asarray(cand_f)\n            fmin_local = f_array.min()\n            # stability: scale by standard deviation\n            fstd = float(np.std(f_array) + 1e-12)\n            scores = np.exp(-(f_array - fmin_local) / fstd)\n            probs = scores / np.sum(scores)\n            # pick one winner (could be extended to multiple)\n            win_idx = rng.choice(len(cand_X), p=probs)\n            winner = np.asarray(cand_X[win_idx]).copy()\n            winner_f = float(cand_f[win_idx])\n            win_type = cand_types[win_idx]\n\n            # acceptance: if winner improves global best or probabilistic acceptance based on scaled difference\n            accept = False\n            if winner_f <= f_best:\n                accept = True\n            else:\n                # soft uphill acceptance with scale equal to sigma * avg_span\n                uphill_scale = max(1e-12, sigma * avg_span)\n                if rng.rand() < np.exp(-max(0.0, winner_f - f_best) / (uphill_scale + 1e-12)):\n                    accept = True\n\n            # compute mean update delta based on winner and type; incorporate momentum\n            if accept:\n                if win_type == 'mirror':\n                    # mirror winners deserve stronger trust-step\n                    eta = 0.35\n                elif win_type == 'single':\n                    eta = 0.20\n                else:\n                    eta = 0.18\n\n                delta = winner - m\n                # damp/clip delta to avoid large jumps (trust radius proportional to sigma*sqrt(dim))\n                trust_radius = max(1e-12, 4.0 * sigma * np.sqrt(self.dim))\n                delta_norm = np.linalg.norm(delta)\n                if delta_norm > trust_radius:\n                    delta = delta * (trust_radius / (delta_norm + 1e-12))\n                # momentum update\n                mom = self.momentum_beta * mom + (1.0 - self.momentum_beta) * delta\n                m = m + eta * mom\n                # keep in bounds\n                m = np.minimum(np.maximum(m, lb), ub)\n            else:\n                # exploratory jitter if not accepted\n                jitter = 0.06 * avg_span\n                m = m + jitter * rng.randn(self.dim)\n                m = np.minimum(np.maximum(m, lb), ub)\n                # decay momentum\n                mom = mom * (1.0 - (1.0 - self.momentum_beta) * 0.5)\n\n            # compute success indicator for this generation (improvement or positive directional signals)\n            gen_success_flag = bool(gen_success)\n            p_succ = self.smooth_p * p_succ + (1.0 - self.smooth_p) * float(gen_success_flag)\n\n            # adapt sigma multiplicatively\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, self.sigma_min, self.sigma_max_mult * avg_span)\n\n            # adapt per-coordinate residuals s slightly from observed normalized steps\n            if len(success_steps) > 0:\n                B = np.asarray(success_steps)  # shape (k, dim)\n                # use median absolute normalized step as indicator\n                med = np.median(np.abs(B), axis=0)\n                s = 0.8 * s + 0.2 * np.clip(med, 1e-4, 3.0)\n\n            # redistribute energy in D based on directional_gains\n            if r > 0 and np.sum(directional_gains) > 1e-12:\n                # softmax of gains to set new p (with smoothing)\n                g = directional_gains\n                g = g - g.max()\n                p_new = np.exp(g / (np.std(g) + 1e-12))\n                p_new = p_new / (np.sum(p_new) + 1e-12)\n                # smooth update\n                p = 0.85 * p + 0.15 * (p_new * (np.sum(p) + 1e-12))\n                # clamp\n                p = np.clip(p, self.min_dir_energy, self.max_dir_energy)\n\n            # Periodic PCA refresh of D using recent success_steps\n            if (gen % self.pca_period == 0) and len(success_steps) >= max(3, r):\n                B = np.asarray(success_steps)\n                # center rows\n                Bc = B - np.mean(B, axis=0, keepdims=True)\n                try:\n                    # compute top-r right singular vectors (principal directions in space)\n                    U_s, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        D_new = Vt[:r_eff].T  # dim x r_eff\n                        # compute energies from singular values\n                        eigs = (S_s[:r_eff] ** 2) / max(1, Bc.shape[0] - 1)\n                        # normalize energies to sum ~ current sum to avoid abrupt variance changes\n                        if D.shape[1] == r_eff:\n                            # align sign by dot product\n                            for k in range(r_eff):\n                                if np.dot(D[:, k], D_new[:, k]) < 0:\n                                    D_new[:, k] *= -1.0\n                            D = 0.75 * D + 0.25 * D_new\n                            p = 0.7 * p + 0.3 * (eigs / (np.mean(eigs) + 1e-12))\n                        else:\n                            D = D_new\n                            p = eigs / (np.mean(eigs) + 1e-12)\n                        p = np.clip(p, self.min_dir_energy, self.max_dir_energy)\n                        # slightly reduce residual variance s in directions explained by D\n                        explained = np.sum(p)\n                        s = np.clip(0.9 * s, 1e-4, 4.0)\n                except np.linalg.LinAlgError:\n                    # skip PCA this round\n                    pass\n\n            # occasional small random rotation/reflection of subspace to maintain exploration\n            if r > 0 and rng.rand() < 0.06:\n                Qr = rng.randn(r, r)\n                try:\n                    Qr_orth, _ = np.linalg.qr(Qr)\n                    D = D.dot(Qr_orth)  # rotate basis in subspace\n                except Exception:\n                    pass\n\n            # opportunistic restart when stagnation is detected\n            if stagn_counter >= stagn_limit and evals < self.budget:\n                stagn_counter = 0\n                # perturb mean around the best seen, inflate sigma and reset some statistics\n                jitter = max(0.04 * avg_span, 0.6 * sigma)\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                sigma = max(sigma * self.restart_infl, 0.25 * avg_span)\n                # reset subspace somewhat\n                if r > 0:\n                    A = rng.randn(self.dim, r)\n                    Q, _ = np.linalg.qr(A)\n                    D = Q[:, :r]\n                    p = np.full(r, np.mean(p) if p.size else 1.0)\n                s = np.full(self.dim, 0.35)\n                success_steps = []\n                mom = np.zeros(self.dim)\n                # chance to do a few random evaluations near best to reseed\n                for _ in range(min(6, self.budget - evals)):\n                    x = x_best + 0.08 * avg_span * rng.randn(self.dim)\n                    x = np.minimum(np.maximum(x, lb), ub)\n                    f = float(func(x))\n                    evals += 1\n                    X_arch.append(x.copy())\n                    f_arch.append(f)\n                    if f < f_best:\n                        f_best = f\n                        x_best = x.copy()\n                    if evals >= self.budget:\n                        break\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ADSE_Mirror scored 0.169 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "4ed544b1-f90e-4f66-9add-6e6d96fc009c", "operator": null, "metadata": {"aucs": [0.0907514632816252, 0.15251998400657973, 0.2532989978627722, 0.18455309996583824, 0.17321732992936667, 0.19831320445932366, 0.1838195443748265, 0.16894844688286748, 0.14629237154365227, 0.13405399097352577]}, "task_prompt": ""}
{"id": "04d6aabb-e1f5-4bd2-8a09-7c43b2a3ef2d", "fitness": "-inf", "name": "SAME", "description": "The optimizer uses antithetic (mirrored) low‑rank correlated sampling (P, e, diagonal v) plus occasional Cauchy/Levy long jumps (levy_prob) to balance efficient directed exploration and heavy‑tailed escapes, with mirror_frac ≈ 0.6 and an initially large sigma (0.25·avg_span) to favor exploration. Step‑size adaptation is CSA‑like: a running normalized path s_path (c_s, s_target, expected_norm) multiplicatively updates sigma (with damping c_damp and clamps sigma_min/sigma_max_mult) and triggers restart_inflate when stagnation is detected. The mean is updated with momentum (momentum=0.6) and type‑dependent learning rates (eta_base), while a FIFO archive plus tournament recombination and occasional local quasi‑Newton regression produce diverse candidate proposals. Periodic PCA on a buffer of successful normalized steps refits the low‑rank subspace and energies (pca_period, pca_smooth, buffer_size), v is nudged from buffer statistics, and a decaying temperature gives small uphill acceptance to maintain robustness.", "code": "import numpy as np\n\nclass SAME:\n    \"\"\"\n    Subspace-Adaptive Mirror Ensemble optimizer (SAME)\n\n    Main idea (one-line above): antithetic (mirrored) low-rank correlated sampling,\n    cumulative-step-adaptation (CSA)-like sigma updates, momentum-aided mean updates,\n    periodic subspace (PCA) re-fitting from a success buffer, tournament-based recombination,\n    and occasional Lévy/Cauchy long-jumps for escape.\n\n    Main tunable parameters (listed here for clarity; different defaults than the ELTR example):\n    - pop: base population size per generation (default scales mildly with dim)\n    - rank: low-rank subspace dimensionality for correlated sampling\n    - archive_size: FIFO archive of evaluated points used for recombination\n    - buffer_size: buffer of recent successful normalized steps for subspace update\n    - mirror_frac: fraction of population generated as mirrored antithetic pairs\n    - levy_prob: probability of generating a Lévy / Cauchy long jump (heavy-tail exploration)\n    - c_s: CSA path learning rate (controls how sigma adapts)\n    - s_target: CSA target path length (expected_norm scaled)\n    - momentum: momentum weight applied to mean updates\n    - pca_period: how often (generations) to recompute subspace from buffer\n    - restart_inflate: factor to inflate sigma on restart\n    - stagn_frac: fraction of budget to trigger restart\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=None, rank=4, archive_size=None, buffer_size=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        # population & subspace\n        self.pop = pop if pop is not None else max(10, int(6 + 1.6 * np.log(max(2, dim))))\n        self.rank = int(min(rank, dim))\n        # sizes\n        self.archive_size = archive_size if archive_size is not None else max(8 * dim, 40)\n        self.buffer_size = buffer_size if buffer_size is not None else max(12 * self.rank, 3 * self.rank + 12)\n        # sampling / exploration\n        self.mirror_frac = 0.6          # fraction of pop created as mirrored pairs\n        self.levy_prob = 0.04           # occasional heavy-tail jumps\n        # CSA-like step-size adaptation (different from ELTR's EMA multiplicative)\n        self.c_s = 0.18                 # path update rate\n        self.s_target = 0.9             # target normalized path length\n        self.c_damp = 10.0              # damping factor in sigma update exponent\n        # momentum for mean updates\n        self.momentum = 0.6\n        self.eta_base = 0.22            # base mean learning rate (modified by type)\n        # PCA cadence / restart\n        self.pca_period = 11\n        self.pca_smooth = 0.25\n        self.restart_inflate = 2.0\n        self.stagn_frac = 0.05\n        # safety & clamps\n        self.v_min = 1e-6\n        self.sigma_min = 1e-10\n        self.sigma_max_mult = 6.0      # multiplied by average span\n        # Random generator\n        self._rng = np.random.RandomState(self.rng_seed)\n\n    def __call__(self, func):\n        rng = self._rng\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = (ub - lb)\n        avg_span = np.mean(bounds_scale)\n\n        # initialize mean uniformly in bounds, sigma larger than ELTR default for more exploration\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(1e-8, 0.25 * avg_span)  # somewhat more exploratory initially\n\n        # low-rank orthonormal basis P and energies e (variance along subspace directions)\n        r = self.rank\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            P = Q[:, :r]\n            e = np.full(r, 0.12)  # small initial energies\n        else:\n            P = np.zeros((self.dim, 0))\n            e = np.array([])\n\n        # diagonal residual variance\n        v = np.full(self.dim, 0.45)\n\n        # archive and success buffer (normalized steps)\n        X_arch = []\n        f_arch = []\n        buffer_steps = []\n\n        # momentum term for mean updates\n        mom = np.zeros(self.dim)\n\n        # initialize archive with a small diverse set\n        evals = 0\n        init_pop = min(self.pop, max(8, int(self.budget // 80)))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        # ensure at least one eval\n        if len(f_arch) == 0:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        # best so far\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # CSA-path scalar (normalized)\n        s_path = 0.0\n        # expected norm of N(0,I) in dim to normalize lengths (approximation)\n        d = float(self.dim)\n        expected_norm = np.sqrt(d) * (1.0 - 1.0 / (4.0 * d) + 1.0 / (21.0 * d ** 2))\n\n        # stagnation/rest parameters\n        stagn_limit = max(6, int(self.stagn_frac * self.budget))\n        stagn_count = 0\n\n        gen = 0\n        # simple temperature-like uphill acceptance that decays quickly\n        T = 0.4 * avg_span\n\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop, remaining)\n            lam = max(1, lam)\n\n            candidates = []\n            c_types = []\n\n            # number of mirrored antithetic samples\n            n_mirror = int(np.round(self.mirror_frac * lam / 2.0))  # pairs -> counts of pairs\n            # generate mirrored low-rank correlated samples (antithetic)\n            for _ in range(n_mirror):\n                # sample low-rank coordinates and diagonal noise\n                if r > 0:\n                    z_r = rng.randn(r) * np.sqrt(np.maximum(e, 1e-12))\n                    low = P @ z_r\n                else:\n                    low = 0.0\n                z_d = rng.randn(self.dim) * np.sqrt(np.maximum(v, self.v_min))\n                step = z_d + low\n                x_plus = m + sigma * step\n                x_minus = m - sigma * step\n                candidates.append(x_plus)\n                c_types.append('mirror')\n                if len(candidates) < lam:\n                    candidates.append(x_minus)\n                    c_types.append('mirror')\n\n            # remaining slots: recombination, trust-like local step, or levy jumps\n            while len(candidates) < lam:\n                roll = rng.rand()\n                # occasional Lévy/Cauchy long jump to escape basins\n                if roll < self.levy_prob:\n                    # Cauchy (heavy tail) centered at mean\n                    cauchy = rng.standard_cauchy(self.dim) * (2.0 * sigma)\n                    xlev = m + cauchy\n                    candidates.append(xlev)\n                    c_types.append('levy')\n                    continue\n\n                # recombination via tournament-like selection from archive\n                if len(X_arch) >= 3 and rng.rand() < 0.6:\n                    # pick tournaments of size 3 (rank-based)\n                    idxs = rng.choice(len(X_arch), size=3, replace=False)\n                    fsel = np.array([f_arch[i] for i in idxs])\n                    # pick two best of three to recombine\n                    sorted_idx = idxs[np.argsort(fsel)[:2]]\n                    a = X_arch[sorted_idx[0]]\n                    b = X_arch[sorted_idx[1]]\n                    alpha = rng.rand()\n                    base = alpha * a + (1.0 - alpha) * b\n                    # small differential perturbation using third\n                    c_idx = rng.choice(len(X_arch))\n                    c = X_arch[c_idx]\n                    diff = 0.3 * (a - c)\n                    noise = 0.6 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, self.v_min))\n                    xrec = base + diff + noise\n                    candidates.append(xrec)\n                    c_types.append('recomb')\n                    continue\n\n                # local curvature-like (diagonal approx) step using a tiny ridge regression if enough archive\n                if len(X_arch) >= max(10, self.dim // 3) and rng.rand() < 0.35:\n                    X_arr = np.asarray(X_arch)\n                    f_arr = np.asarray(f_arch)\n                    dx = X_arr - m.reshape(1, -1)\n                    # use simple weighted linear regression to estimate gradient\n                    weights = np.exp(-np.linalg.norm(dx, axis=1) / (0.8 * (sigma + 1e-12)))\n                    W = np.sqrt(weights).reshape(-1, 1)\n                    X_design = dx\n                    y = (f_arr - np.min(f_arr))\n                    reg = 1e-6\n                    try:\n                        A = (W * X_design).T @ (W * X_design) + reg * np.eye(self.dim)\n                        b = (W * X_design).T @ (W * y)\n                        g_est = np.linalg.solve(A, b)\n                        # damped quasi-Newton diagonal inverse: invert approximate diag by squared grads\n                        diag_inv = 1.0 / (0.5 + np.abs(g_est))\n                        step = - diag_inv * g_est\n                        # clip by scaled sigma*avg_span\n                        max_step = max(1e-12, 1.2 * sigma * np.sqrt(self.dim))\n                        nrm = np.linalg.norm(step)\n                        if nrm > max_step:\n                            step = step * (max_step / nrm)\n                        x_trust = m + step\n                        candidates.append(x_trust)\n                        c_types.append('local')\n                        continue\n                    except np.linalg.LinAlgError:\n                        # fallback to random if regression fails\n                        xrand = m + 0.8 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, self.v_min))\n                        candidates.append(xrand)\n                        c_types.append('gauss')\n                        continue\n\n                # default correlated gaussian (no mirror)\n                if r > 0:\n                    z_r = rng.randn(r) * np.sqrt(np.maximum(e, 1e-12))\n                    low = P @ z_r\n                else:\n                    low = 0.0\n                z_d = rng.randn(self.dim) * np.sqrt(np.maximum(v, self.v_min))\n                xg = m + sigma * (z_d + low)\n                candidates.append(xg)\n                c_types.append('gauss')\n\n            # clamp to bounds\n            Xcand = np.asarray([np.minimum(np.maximum(x, lb), ub) for x in candidates])\n            fc = np.full(Xcand.shape[0], np.inf)\n\n            # evaluate sequentially\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                x = Xcand[i]\n                fval = float(func(x))\n                evals += 1\n                fc[i] = fval\n\n                # update archive FIFO\n                X_arch.append(x.copy())\n                f_arch.append(fval)\n                if len(X_arch) > self.archive_size:\n                    del X_arch[0]\n                    del f_arch[0]\n\n                # update global best\n                if fval < f_best:\n                    f_best = fval\n                    x_best = x.copy()\n                    stagn_count = 0\n                else:\n                    stagn_count += 1\n\n            # if no valid evaluations done, exit\n            valid_mask = np.isfinite(fc)\n            if not np.any(valid_mask):\n                break\n            Xcand = Xcand[valid_mask]\n            fc = fc[valid_mask]\n            c_types = [c_types[i] for i in range(len(c_types)) if valid_mask[i]]\n\n            # selection: rank-based tournament inside this batch (favor bests)\n            order = np.argsort(fc)\n            topk = max(1, int(0.15 * len(fc)))\n            selected_idx = order[:topk]\n            # pick one candidate to influence mean biased towards best-of-batch but with some chance\n            # Use tournament selection among a few\n            tour_size = min(3, len(selected_idx))\n            tour = rng.choice(selected_idx, size=tour_size, replace=False)\n            chosen_idx = int(tour[np.argmin(fc[tour])])\n            chosen_x = Xcand[chosen_idx].copy()\n            chosen_f = float(fc[chosen_idx])\n\n            # acceptance rule: accept if improves best or with small uphill prob proportional to T\n            accept = False\n            if chosen_f <= f_best:\n                accept = True\n            else:\n                if T > 1e-12 and rng.rand() < np.exp(-(chosen_f - f_best) / (T + 1e-12)):\n                    accept = True\n\n            # compute normalized step for buffer: relative to sigma and sqrt(v)\n            denom = sigma * np.sqrt(np.maximum(v, self.v_min))\n            deltas_norm = (Xcand - m.reshape(1, -1)) / denom.reshape(1, -1)\n\n            # success mask: those that are among topk or improve best\n            success_mask = np.zeros(len(fc), dtype=bool)\n            success_mask[selected_idx] = True\n            success_mask = success_mask | (fc <= f_best + 1e-12)\n            # ensure chosen one is considered for adaptation\n            success_mask[chosen_idx] = True\n\n            # record normalized successful steps into buffer\n            for i in range(len(deltas_norm)):\n                if success_mask[i]:\n                    buffer_steps.append(deltas_norm[i].copy())\n                    if len(buffer_steps) > self.buffer_size:\n                        del buffer_steps[0]\n\n            # mean update: momentum + step toward chosen candidate\n            if accept:\n                # type-specific learning rate\n                typ = c_types[chosen_idx]\n                if typ == 'local':\n                    eta = self.eta_base * 1.4\n                elif typ == 'mirror':\n                    eta = self.eta_base * 1.0\n                elif typ == 'recomb':\n                    eta = self.eta_base * 1.1\n                elif typ == 'levy':\n                    eta = self.eta_base * 0.6\n                else:\n                    eta = self.eta_base\n\n                step = chosen_x - m\n                mom = self.momentum * mom + (1.0 - self.momentum) * step\n                m = m + eta * mom\n            else:\n                # small exploratory perturbation to mean\n                m = m + 0.06 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, self.v_min))\n                # decay momentum a bit\n                mom = 0.7 * mom\n\n            # keep mean in bounds\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # PCA/subspace update periodically (different smoothing than ELTR)\n            if (gen % self.pca_period == 0) and len(buffer_steps) >= max(4, self.rank):\n                B = np.asarray(buffer_steps)  # (k, dim)\n                Bc = B - np.mean(B, axis=0, keepdims=True)\n                try:\n                    # compute small covariance in feature space and SVD\n                    U_s, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    r_eff = min(self.rank, Vt.shape[0])\n                    if r_eff > 0:\n                        P_new = Vt[:r_eff].T  # dim x r_eff\n                        eig_energy = (S_s[:r_eff] ** 2) / max(1, Bc.shape[0] - 1)\n                        # smooth update towards new principal directions\n                        if P.shape[1] == r_eff:\n                            P = (1.0 - self.pca_smooth) * P + self.pca_smooth * P_new\n                            # re-orthogonalize\n                            Q, _ = np.linalg.qr(P)\n                            P = Q[:, :r_eff]\n                            e = (1.0 - self.pca_smooth) * e + self.pca_smooth * (eig_energy / (np.mean(eig_energy) + 1e-12))\n                        else:\n                            P = P_new\n                            e = eig_energy / (np.mean(eig_energy) + 1e-12)\n                        # clip energies and keep residual variance roughly balanced\n                        e = np.clip(e, 1e-5, 6.0)\n                        explained = np.sum(e)\n                        total_var_target = max(1e-6, np.mean(np.var(Bc, axis=0) + 1e-6))\n                        rem = max(1e-6, total_var_target - explained / max(1, r_eff))\n                        v = 0.5 * v + 0.5 * np.clip(rem * np.ones(self.dim), 1e-6, 8.0)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # adapt sigma with CSA-like rule using the chosen step length (if chosen accepted)\n            # compute normalized length of the accepted step (if any)\n            if accept:\n                step_norm = np.linalg.norm((chosen_x - m) / (sigma + 1e-12))\n                # normalized relative to expected norm:\n                normed = step_norm / (expected_norm + 1e-12)\n                s_path = (1.0 - self.c_s) * s_path + self.c_s * normed\n                # update sigma multiplicatively via exponential of (s_path - s_target) scaled by damping\n                sigma = sigma * np.exp((s_path - self.s_target) / self.c_damp)\n            else:\n                # small decay if no improvement\n                sigma = sigma * (1.0 - 0.02 * (1.0 / max(1, gen)))\n\n            # clip sigma\n            sigma = np.clip(sigma, self.sigma_min, self.sigma_max_mult * avg_span)\n\n            # adapt residual v slightly based on observed magnitudes in buffer\n            if len(buffer_steps) > 0:\n                mag = np.mean(np.var(np.asarray(buffer_steps), axis=0))\n                # nudge v towards observed residual variance (scale)\n                v = 0.85 * v + 0.15 * np.clip(mag * np.ones(self.dim), 1e-8, 10.0)\n\n            # temperature decay for uphill acceptance (faster than ELTR)\n            T *= 0.987\n            T = max(T, 1e-8)\n\n            # opportunistic restart on stagnation\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # jump around best with Lévy plus reset subspace\n                levy = rng.standard_cauchy(self.dim) * (1.2 * sigma)\n                m = x_best + levy\n                m = np.minimum(np.maximum(m, lb), ub)\n                sigma = max(sigma * self.restart_inflate, 0.35 * avg_span)\n                # reset subspace with new random orthonormal basis\n                if self.rank > 0:\n                    A = rng.randn(self.dim, self.rank)\n                    Q, _ = np.linalg.qr(A)\n                    P = Q[:, :self.rank]\n                    e = np.full(self.rank, 0.18)\n                v = np.full(self.dim, 0.45)\n                buffer_steps = []\n                mom = np.zeros(self.dim)\n                # slightly boost path to encourage exploration\n                s_path = 0.0\n                T = max(T, 0.6 * avg_span)\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 225, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,18) \nOn line: x_trust = m + step", "error": "In the code, line 225, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,18) \nOn line: x_trust = m + step", "parent_ids": "4ed544b1-f90e-4f66-9add-6e6d96fc009c", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "a5572c00-29f6-4263-8e30-2eb6e99323a3", "fitness": 0.16494864414680435, "name": "ADME", "description": "ADME maintains a Gaussian search model with a central mean m, global step-size sigma (initialized to 0.25 of the average variable span and adapted by an EMA success controller), a per-coordinate residual variance v (~0.5), and a compact low-rank directional memory B (dim x r) with energies w (initialized ~0.4) that encodes correlated search directions. It probes the black box with three structured mechanisms — low-rank correlated Gaussian samples (using v and B*w), antithetic directional probe pairs that estimate directional gradients and curvatures (delta_frac ~0.9) to produce Newton-like trust-constrained steps, and elite recombination/leaps for exploration — while strictly counting evaluations against the budget. Successful normalized step vectors are buffered and periodically summarized by PCA/SVD (pca_period=8, buffer_size ≈ 8*r) to rebuild and smooth B and its energies, plus a “variance-sink” to down-weight directions showing inconsistent gradient signs. Acceptance moves update the mean with momentum and type-dependent learning rates, while rho (trust radius) expands/shrinks multiplicatively, sigma adapts via p_succ vs target (0.2), and simple stagnation-triggered restarts diversify search around elites.", "code": "import numpy as np\n\nclass ADME:\n    \"\"\"\n    Adaptive Directional Memory Ensemble (ADME)\n\n    Main ideas:\n    - Maintain a mean m and global scale sigma, plus a compact orthonormal directional memory B (dim x r)\n      with direction energies w and a diagonal residual variance v. This yields cheap correlated probing.\n    - Use antithetic directional probes (evaluate m+delta*d and m-delta*d) to produce inexpensive directional\n      gradient estimates and second-difference curvature signals. These inform Newton-like and directional steps.\n    - Maintain a small elite set (best-so-far points) and recombine elites for exploratory proposals.\n    - Adapt sigma via an EMA success-rate controller and reduce variance (\"variance-sink\") on directions\n      that show inconsistent signs of directional gradient (i.e., noisy or non-repeatable directions).\n    - Periodically rebuild directional memory B from a buffer of successful normalized steps (PCA/SVD),\n      but with additional damping to avoid rapid oscillations.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 rank=None, pop_base=None, init_pop=None,\n                 elite_size=6, buffer_size=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n\n        # algorithm choices / defaults\n        self.rank = int(rank) if rank is not None else max(1, min(6, self.dim // 2))\n        self.pop_base = pop_base if pop_base is not None else max(8, int(6 + 0.7 * np.log(max(2, self.dim))))\n        self.init_pop = init_pop if init_pop is not None else min(max(6, 2 * self.dim), max(6, self.budget // 100))\n        self.elite_size = int(min(elite_size, max(2, self.init_pop)))\n        self.buffer_size = buffer_size if buffer_size is not None else max(12, 8 * self.rank)\n\n        # adaptation constants\n        self.success_target = 0.2\n        self.sigma_adapt_rate = 0.3  # exponent multiplier\n        self.p_smooth = 0.88         # EMA for success rate\n        self.trust_shrink = 0.7\n        self.trust_expand = 1.25\n        self.trust_init = 0.5\n        self.trust_min = 1e-6\n        self.trust_max = 5.0\n\n        # damping and smoothing\n        self.B_smooth = 0.85\n        self.w_smooth = 0.7\n\n        # antithetic probe scale relative to sigma\n        self.delta_frac = 0.9\n\n        # variance sink factor (reduce energy on conflicting directions)\n        self.variance_sink = 0.6\n\n        # PCA cadence\n        self.pca_period = 8\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds: func.bounds.lb / ub may be scalar or arrays\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        # initialize mean in bounds\n        m = rng.uniform(lb, ub, size=self.dim)\n        # starting sigma relative to search range\n        sigma = max(1e-8, 0.25 * avg_span)\n\n        # directional memory: orthonormal B (dim x r) and energies w\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()\n            w = np.full(r, 0.4)\n        else:\n            B = np.zeros((self.dim, 0))\n            w = np.array([])\n\n        # residual per-coordinate variance\n        v = np.full(self.dim, 0.5)   # positive residual variance\n        # momentum for mean updates\n        mom = np.zeros(self.dim)\n\n        # archive: list of (x, f) tuples, keep FIFO up to some size, plus elite list\n        archive_X = []\n        archive_f = []\n        elite_X = []\n        elite_f = []\n\n        # buffer for successful normalized steps (used to recompute B via PCA)\n        buffer_steps = []\n\n        evals = 0\n        # initial seeding evaluations\n        for _ in range(self.init_pop):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            archive_X.append(x0.copy()); archive_f.append(f0)\n        if len(archive_f) == 0:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            archive_X.append(x0.copy()); archive_f.append(f0)\n\n        # set best\n        idx_best = int(np.argmin(archive_f))\n        f_best = float(archive_f[idx_best])\n        x_best = archive_X[idx_best].copy()\n        # populate initial elites (take best ones)\n        order = np.argsort(archive_f)\n        for i in order[:self.elite_size]:\n            elite_X.append(archive_X[i].copy()); elite_f.append(archive_f[i])\n\n        # trust radius\n        rho = self.trust_init * avg_span\n\n        # smoothed success rate\n        p_succ = 0.2\n\n        gen = 0\n        # we may need to evaluate occasionally the baseline f(m) for antithetic curvature computing\n        f_m_cached = None\n\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            lam = max(1, lam)\n\n            candidates = []   # list of arrays\n            c_types = []      # string tags\n\n            # 1) Low-rank correlated Gaussian probes (most candidates)\n            n_gauss = int(0.5 * lam)\n            if n_gauss > 0:\n                # diagonal noise\n                eps_d = rng.randn(n_gauss, self.dim) * np.sqrt(np.maximum(v, 1e-12))\n                if r > 0:\n                    eps_r = rng.randn(n_gauss, r) * np.sqrt(np.maximum(w, 1e-12))\n                    low = eps_r @ B.T\n                else:\n                    low = 0.0\n                Xg = m.reshape(1, -1) + sigma * (eps_d + low)\n                for i in range(Xg.shape[0]):\n                    x = np.minimum(np.maximum(Xg[i], lb), ub)\n                    candidates.append(x)\n                    c_types.append('gauss')\n\n            # 2) Antithetic directional probes: cheap gradient-like along stored directions or random ones\n            # each antithetic uses 2 evaluations; limit by remaining budget\n            max_antithetic_pairs = int(0.25 * lam)\n            if max_antithetic_pairs > 0:\n                pairs_done = 0\n                use_dirs = []\n                # choose directions from B preferentially by energy, else random\n                if r > 0 and np.sum(w) > 0:\n                    probs_dirs = w / (np.sum(w) + 1e-12)\n                else:\n                    probs_dirs = None\n                while pairs_done < max_antithetic_pairs and evals + 2 <= self.budget:\n                    # choose direction: either a B column (by energy) or a random Gaussian\n                    if r > 0 and rng.rand() < 0.8:\n                        idx = rng.choice(r, p=(probs_dirs if probs_dirs is not None else None))\n                        d = B[:, idx].copy()\n                    else:\n                        d = rng.randn(self.dim)\n                        d /= (np.linalg.norm(d) + 1e-12)\n                    # probe distance\n                    delta = self.delta_frac * sigma * (0.8 + 0.4 * rng.rand())\n                    x_plus = np.minimum(np.maximum(m + delta * d, lb), ub)\n                    f_plus = float(func(x_plus)); evals += 1\n                    # ensure we don't exceed budget for second eval\n                    if evals >= self.budget:\n                        # record plus as candidate and break\n                        candidates.append(x_plus); c_types.append('ant_plus')\n                        break\n                    x_minus = np.minimum(np.maximum(m - delta * d, lb), ub)\n                    f_minus = float(func(x_minus)); evals += 1\n\n                    # estimate directional gradient and curvature\n                    g_dir = (f_plus - f_minus) / (2.0 * delta + 1e-12)\n                    h_dir = (f_plus + f_minus - (2.0 * (f_m_cached if f_m_cached is not None else np.min(archive_f)))) / (delta ** 2 + 1e-12)\n\n                    # form a probe step: negative directional gradient scaled by curvature if positive\n                    # If curvature is positive and reliable, do approximate Newton step along d:\n                    if h_dir > 1e-8:\n                        step_mag = - g_dir / (h_dir + 1e-12)\n                    else:\n                        # fallback to scaled gradient descent\n                        step_mag = -0.8 * g_dir\n\n                    # clamp step magnitude to trust radius\n                    step_mag = np.sign(step_mag) * min(abs(step_mag), rho)\n                    x_trust = m + step_mag * d\n                    x_trust = np.minimum(np.maximum(x_trust, lb), ub)\n                    candidates.append(x_trust); c_types.append('ant_trust')\n\n                    # also include the two probe endpoints for potential improvements\n                    candidates.append(x_plus); c_types.append('ant_plus')\n                    candidates.append(x_minus); c_types.append('ant_minus')\n\n                    # update some bookkeeping\n                    pairs_done += 1\n                    # collect directional info for variance sink\n                    use_dirs.append((d.copy(), g_dir))\n                    # optionally cache f(m) when feasible for curvature next loop\n                    if f_m_cached is None and evals < self.budget:\n                        # evaluate f(m) once cheaply if budget allows\n                        f_m_cached = float(func(m)); evals += 1\n                        archive_X.append(m.copy()); archive_f.append(f_m_cached)\n                        # don't let archive grow unbounded here; will be trimmed below\n\n                # apply variance-sink: reduce energy of directions that show inconsistent signs across recent probes\n                if len(use_dirs) > 0 and r > 0:\n                    # align sign of gradient with direction basis and penalize inconsistent directions\n                    signs = np.array([np.sign(gd) for (_d, gd) in use_dirs])\n                    # if mixture of signs (both + and -), it's inconsistent\n                    if np.any(signs > 0) and np.any(signs < 0):\n                        # reduce energies of all B directions orthogonal to average probe\n                        # compute average probe direction\n                        avg_d = np.mean([_d for (_d, _gd) in use_dirs], axis=0)\n                        avg_d /= (np.linalg.norm(avg_d) + 1e-12)\n                        # projections on basis\n                        proj = np.abs(B.T @ avg_d)  # length r\n                        # sink energies where projection is small (i.e., B directions not aligned)\n                        sink_mask = proj < 0.35\n                        if np.any(sink_mask):\n                            w[sink_mask] *= (1.0 - self.variance_sink * 0.5)\n\n            # 3) Elite recombinations (crossover + gaussian)\n            n_recomb = max(0, lam - len(candidates) - 2)\n            for _ in range(n_recomb):\n                if len(elite_X) >= 2:\n                    i1, i2 = rng.choice(len(elite_X), size=2, replace=False)\n                    a = elite_X[i1]; b = elite_X[i2]\n                    alpha = rng.rand()\n                    xrec = alpha * a + (1.0 - alpha) * b\n                    xrec += 0.6 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, 1e-12))\n                    xrec = np.minimum(np.maximum(xrec, lb), ub)\n                    candidates.append(xrec); c_types.append('recomb')\n                else:\n                    xrand = rng.uniform(lb, ub)\n                    candidates.append(xrand); c_types.append('rand')\n\n            # 4) Occasional long jump: global uniform (small prob)\n            if rng.rand() < 0.05 and evals < self.budget:\n                xlong = rng.uniform(lb, ub, size=self.dim)\n                candidates.append(xlong); c_types.append('leap')\n\n            # ensure candidate count is reasonable and clamp\n            Xcand = np.asarray([np.minimum(np.maximum(x, lb), ub) for x in candidates])\n            fc = np.full(Xcand.shape[0], np.inf)\n\n            # Evaluate candidates sequentially until budget used\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                x = Xcand[i]\n                f = float(func(x)); evals += 1\n                fc[i] = f\n                # append to archive FIFO\n                archive_X.append(x.copy()); archive_f.append(f)\n                if len(archive_X) > max(200, 6 * self.dim):\n                    del archive_X[0]; del archive_f[0]\n                # update best & elites\n                if f < f_best:\n                    f_best = f; x_best = x.copy()\n                    # insert into elite list\n                    elite_X.append(x.copy()); elite_f.append(f)\n                    # keep elites sorted\n                    order = np.argsort(elite_f)\n                    elite_X = [elite_X[i] for i in order[:self.elite_size]]\n                    elite_f = [elite_f[i] for i in order[:self.elite_size]]\n                else:\n                    # maybe replace a worse elite occasionally\n                    if len(elite_X) < self.elite_size:\n                        elite_X.append(x.copy()); elite_f.append(f)\n                    else:\n                        # if better than worst elite, replace\n                        worst_idx = int(np.argmax(elite_f))\n                        if f < elite_f[worst_idx]:\n                            elite_X[worst_idx] = x.copy(); elite_f[worst_idx] = f\n\n            # Remove un-evaluated candidates if budget ended\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]; fc = fc[valid]\n                c_types = [c_types[i] for i in range(len(c_types)) if valid[i]]\n\n            if fc.size == 0:\n                break\n\n            # scoring and selection: softmax over negative f (favor small f)\n            fmin_local = np.min(fc)\n            fstd = np.std(fc) + 1e-12\n            scores = np.exp(- (fc - fmin_local) / fstd)\n            probs = scores / (np.sum(scores) + 1e-12)\n            chosen_idx = rng.choice(len(Xcand), p=probs)\n            chosen_x = Xcand[chosen_idx].copy()\n            chosen_f = float(fc[chosen_idx])\n\n            # acceptance rule: prefer improvement, else accept probabilistically with T scaled by sigma*avg_span\n            T = 0.6 * sigma * avg_span\n            accept = False\n            if chosen_f <= f_best:\n                accept = True\n            else:\n                if T > 1e-12 and rng.rand() < np.exp(-(chosen_f - f_best) / (T + 1e-12)):\n                    accept = True\n\n            m_old = m.copy()\n            # move mean toward chosen_x with inertia depending on type\n            if accept:\n                if c_types[chosen_idx] in ('ant_trust', 'ant_plus', 'ant_minus'):\n                    eta = 0.42\n                elif c_types[chosen_idx] == 'gauss':\n                    eta = 0.18\n                elif c_types[chosen_idx] == 'recomb':\n                    eta = 0.28\n                elif c_types[chosen_idx] == 'leap':\n                    eta = 0.12\n                else:\n                    eta = 0.2\n                # momentum update\n                step = (chosen_x - m)\n                mom = 0.7 * mom + 0.3 * step\n                m = m + eta * step + 0.1 * mom\n            else:\n                # unsuccessful: a small exploratory jitter in a principal direction\n                jitter = 0.06 * sigma\n                if r > 0 and rng.rand() < 0.6:\n                    # pick one B direction randomly weighted by w\n                    idxb = rng.choice(r, p=(w / (np.sum(w) + 1e-12)))\n                    dirj = B[:, idxb]\n                else:\n                    dirj = rng.randn(self.dim)\n                    dirj /= (np.linalg.norm(dirj) + 1e-12)\n                m = m + jitter * dirj * (0.8 + 0.4 * rng.rand())\n\n            # keep mean in bounds\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # compute normalized deltas of evaluated candidates relative to new mean\n            denom = sigma * np.sqrt(np.maximum(v, 1e-12))\n            deltas_norm = (Xcand - m.reshape(1, -1)) / (denom.reshape(1, -1))\n            # update per-coordinate normalization scale optionally (not necessary but helpful)\n            stat = np.mean(np.abs(deltas_norm), axis=0)\n            s_alpha = 0.7\n            # small per-coordinate scale s (not stored externally, but used for buffer standardization)\n            # append successful normalized steps to buffer: those that improved local min or were chosen\n            success_mask = (fc <= (fmin_local + 1e-12))\n            # ensure chosen is counted\n            success_mask[chosen_idx] = True\n            for i in range(len(deltas_norm)):\n                if success_mask[i]:\n                    buffer_steps.append(deltas_norm[i].copy())\n                    if len(buffer_steps) > self.buffer_size:\n                        del buffer_steps[0]\n\n            # Periodic PCA / low-rank update (recompute B and w from buffer)\n            if (gen % self.pca_period == 0) and len(buffer_steps) >= max(3, r):\n                Bmat = np.asarray(buffer_steps)\n                Bc = Bmat - np.mean(Bmat, axis=0, keepdims=True)\n                try:\n                    U_s, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        B_new = Vt[:r_eff].T  # dim x r_eff\n                        energies = (S_s[:r_eff] ** 2) / max(1, Bc.shape[0] - 1)\n                        # normalize energies to unit mean to avoid scale drift\n                        energies = energies / (np.mean(energies) + 1e-12)\n                        # smooth update in B and w\n                        if B.shape[1] == r_eff:\n                            B = self.B_smooth * B + (1.0 - self.B_smooth) * B_new\n                            # re-orthonormalize B to avoid drift\n                            Q, _ = np.linalg.qr(B)\n                            B = Q[:, :r_eff]\n                            w = self.w_smooth * w + (1.0 - self.w_smooth) * energies\n                        else:\n                            B = B_new\n                            w = energies.copy()\n                        # clip & positivity\n                        w = np.clip(w, 1e-4, 10.0)\n                        # adjust residual diagonal variance v to keep total variance balanced heuristically\n                        explained = np.sum(w)\n                        total_var_target = np.mean(np.var(Bc, axis=0) + 1e-6)\n                        rem = max(1e-6, total_var_target - explained / max(1, r_eff))\n                        v = 0.55 * v + 0.45 * np.clip(rem * np.ones(self.dim), 1e-6, 4.0)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # Adapt sigma by EMA of generation success indicator\n            gen_success = float(np.any(success_mask))\n            p_succ = self.p_smooth * p_succ + (1.0 - self.p_smooth) * gen_success\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, 1e-10, 3.0 * avg_span)\n\n            # adapt trust radius using whether any accepted candidate was a trust-like (ant_trust)\n            accepted_trust = False\n            if success_mask.any():\n                for i in range(len(success_mask)):\n                    if success_mask[i] and c_types[i] in ('ant_trust', 'trust'):\n                        accepted_trust = True\n                        break\n            if accepted_trust:\n                rho = min(self.trust_max, rho * self.trust_expand)\n            else:\n                rho = max(self.trust_min, rho * self.trust_shrink)\n\n            # opportunistic restart if no improvement for many evals\n            # simple stagnation: if best hasn't improved in a fraction of budget,\n            # inject a diversified restart around the elite center\n            stagn_window = max(50, int(0.05 * self.budget))\n            if len(archive_f) >= stagn_window:\n                recent_best = np.min(archive_f[-stagn_window:])\n                if abs(recent_best - f_best) < 1e-12:\n                    # randomize around one of elites\n                    if len(elite_X) > 0:\n                        center = elite_X[rng.randint(len(elite_X))]\n                    else:\n                        center = x_best\n                    jitter = max(0.06 * avg_span, 0.8 * sigma)\n                    m = np.minimum(np.maximum(center + jitter * rng.randn(self.dim), lb), ub)\n                    sigma = max(sigma * 1.7, 0.12 * avg_span)\n                    rho = max(rho, 0.8 * avg_span)\n                    # reset some memory\n                    v = np.full(self.dim, 0.5)\n                    if r > 0:\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :r]\n                        w = np.full(r, 0.4)\n                    buffer_steps = []\n                    # consume no evals here (just a heuristic shake)\n\n            # clear f_m_cached occasionally to keep freshness\n            f_m_cached = None\n\n        # finalize best\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ADME scored 0.165 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "4ed544b1-f90e-4f66-9add-6e6d96fc009c", "operator": null, "metadata": {"aucs": [0.10174232430671659, 0.18617339334933336, 0.20099086507673958, 0.15243976341047671, 0.1533808950282357, 0.18433914470254642, 0.20870849372984623, 0.17766527921364716, 0.15665975550182087, 0.1273865271486807]}, "task_prompt": ""}
{"id": "cc7c73fd-eba1-4703-8738-81b5e3af56c8", "fitness": "-inf", "name": "SALT", "description": "SALT combines a learned low-rank search subspace U (rank ≈ dim/4) with a diagonal residual variance v so sampling mixes correlated Gaussian steps in the subspace and independent per-coordinate noise, and U is updated online from a buffer of recent normalized successful steps via an Oja-like incremental rule with periodic QR re-orthonormalization. It uses an archive FIFO (size ≈ 4·dim) for fitness-biased recombination and a simple weighted linear regression on archive points to produce trust-region gradient steps, with a trust radius rho (initially large: 0.8·span) that expands on trust successes and shrinks otherwise. Exploration is bolstered by occasional heavy-tailed (Cauchy/Levy-like) leaps (prob ≈ 0.04, scale 0.9·span), opportunistic restarts on stagnation, and a softmax-based candidate selection plus an uphill acceptance probability controlled by a decaying temperature T. Global step-size sigma is multiplicatively adapted with a relatively aggressive rate (sigma_adapt_rate=0.5) using a smoothed success EMA (p_smooth=0.85, target succ≈0.2), while other ergonomic choices (pop scaling ~sqrt(dim), large buffer and archive sizes, and per-component normalization s) stabilize learning and sampling.", "code": "import numpy as np\n\nclass SALT:\n    \"\"\"\n    SALT: Subspace-Adaptive Levy Trust\n\n    Main idea (one-line): Maintain a compact low-rank search subspace learned from recent\n    successful normalized steps (via an Oja-like incremental update), combine correlated\n    low-rank Gaussian sampling with subspace-aware trust steps and heavy-tailed Levy leaps,\n    adapt global step-size multiplicatively from a smoothed success rate, and use archive-based\n    recombination for exploration.\n\n    Principal algorithm parameters (defaults intentionally different from the provided ELTR):\n      - rank: effective low-rank subspace size (default ~ dim//4, at least 1)\n      - pop_base: number of candidate evaluations per generation (default scales with sqrt(dim))\n      - arch_size: FIFO archive size (default 4*dim)\n      - buffer_size: buffer of normalized successful steps used for subspace learning (default 12*rank)\n      - pca_period: cadence (in generations) to orthonormalize / re-evaluate subspace (default 5)\n      - sigma_adapt_rate: exponent multiplier for multiplicative sigma adaptation (default 0.5)\n      - succ_target: target success probability for sigma adaptation (default 0.2)\n      - p_smooth: EMA smoothing for success probability (default 0.85)\n      - trust_init_frac: initial trust radius fraction of domain span (default 0.8)\n      - trust_expand/shrink: trust radius multipliers on success/failure (1.15 / 0.6)\n      - leap_prob: probability of heavy-tailed Levy leap per generation (default 0.04)\n      - levy_scale: scale of Levy jumps relative to domain span (default 0.9)\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 rank=None, pop_base=None, arch_size=None, buffer_size=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # parameter choices intentionally different from ELTR\n        self.rank = int(rank if rank is not None else max(1, min(self.dim, self.dim // 4)))\n        self.pop_base = int(pop_base if pop_base is not None else max(8, int(4 + 2.0 * np.sqrt(self.dim))))\n        self.arch_size = int(arch_size if arch_size is not None else max(4 * self.dim, 30))\n        self.buffer_size = int(buffer_size if buffer_size is not None else max(8 * self.rank, 12 * self.rank))\n\n        # adaptation / trust / learning parameters (different values)\n        self.succ_target = 0.20\n        self.sigma_adapt_rate = 0.5   # stronger multiplicative response\n        self.p_smooth = 0.85\n        self.trust_expand = 1.15\n        self.trust_shrink = 0.6\n        self.trust_init_frac = 0.8\n        self.trust_min = 1e-6\n        self.trust_max = 6.0\n\n        self.pca_period = 5\n        self.eta_oja = 0.12  # Oja update learning rate\n        self.leap_prob = 0.04\n        self.levy_scale = 0.9\n\n        # safety / clipping\n        self.diag_reg = 1e-8\n        self.s_min = 1e-5\n        self.s_max = 10.0\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # Obtain bounds if present, otherwise assume [-5, 5] per BBOB\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n            if lb.size == 1:\n                lb = np.full(self.dim, lb.item(), dtype=float)\n            if ub.size == 1:\n                ub = np.full(self.dim, ub.item(), dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        # initial mean uniformly in bounds\n        m = rng.uniform(lb, ub, size=self.dim)\n        bounds_scale = (ub - lb)\n        avg_span = float(np.mean(bounds_scale))\n        # initial sigma different: bit larger to encourage exploration\n        sigma = max(1e-8, 0.18 * avg_span)\n\n        # low-rank factor U (orthonormal columns), energies w (per-subspace variance), diagonal residual v\n        r = max(0, min(self.rank, self.dim))\n        if r > 0:\n            A = rng.randn(self.dim, r) * 0.5\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :r]\n            w = np.full(r, 0.12)\n        else:\n            U = np.zeros((self.dim, 0))\n            w = np.array([])\n\n        # diagonal residual variance (per-coordinate)\n        v = np.full(self.dim, 0.35)\n\n        # normalization EMA for normalized steps\n        s = np.ones(self.dim)\n\n        # archive and buffers (FIFO)\n        X_arch = []\n        f_arch = []\n        buffer_steps = []\n\n        # seed archive with a small random population (but fewer than in ELTR)\n        evals = 0\n        init_pop = min(self.pop_base, max(6, self.budget // 80))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x = rng.uniform(lb, ub)\n            f = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(f)\n\n        if len(f_arch) == 0:\n            x = rng.uniform(lb, ub)\n            f = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(f)\n\n        # track best\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # success smoothing and temperature-like parameter for uphill acceptance (small)\n        p_succ = 0.15\n        T = 0.5 * avg_span\n\n        # trust region radius\n        rho = max(self.trust_min, self.trust_init_frac * avg_span)\n\n        gen = 0\n        stagn_count = 0\n        stagn_limit = max(6, int(0.04 * self.budget))\n\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            lam = max(1, lam)\n\n            candidates = []\n            c_types = []\n\n            # 1) Low-rank correlated sampling (major share)\n            n_gauss = max(1, int(0.60 * lam))\n            if n_gauss > 0:\n                # diagonal component\n                eps_d = rng.randn(n_gauss, self.dim) * np.sqrt(np.maximum(v, self.diag_reg))\n                if r > 0 and U.shape[1] > 0:\n                    eps_r = rng.randn(n_gauss, r) * np.sqrt(np.maximum(w, self.diag_reg))\n                    low = eps_r @ U.T\n                else:\n                    low = np.zeros((n_gauss, self.dim))\n                Xg = m.reshape(1, -1) + sigma * (eps_d + low)\n                candidates.extend(Xg.tolist())\n                c_types.extend(['gauss'] * n_gauss)\n\n            # 2) Subspace-aware trust steps using archive-based linear estimate\n            # compute a weighted linear model (no Hessian) centered at m, similar spirit but simpler\n            if len(X_arch) >= max(6, self.dim // 6):\n                X_arr = np.asarray(X_arch)\n                f_arr = np.asarray(f_arch)\n                dx = X_arr - m.reshape(1, -1)\n                # prefer nearby & good points\n                scaled = dx / (np.sqrt(v + 1e-12))\n                dist = np.linalg.norm(scaled, axis=1)\n                wdist = np.exp(-0.9 * dist)\n                fitness = np.exp(-1.0 * (f_arr - np.min(f_arr)) / (np.ptp(f_arr) + 1e-12))\n                weights = (0.6 * wdist + 0.4 * fitness)\n                W = np.sqrt(weights).reshape(-1, 1)\n                # linear regression for gradient estimate (ridge)\n                X_design = dx\n                y = (f_arr - np.min(f_arr))\n                try:\n                    A = (W * X_design).T @ (W * X_design) + 1e-6 * np.eye(self.dim)\n                    b = (W * X_design).T @ (W * y)\n                    g_est = np.linalg.solve(A, b)\n                    # project gradient into learned subspace and its complement\n                    if r > 0 and U.shape[1] > 0:\n                        proj_sub = U @ (U.T @ g_est)\n                        proj_rest = g_est - proj_sub\n                    else:\n                        proj_sub = np.zeros_like(g_est)\n                        proj_rest = g_est.copy()\n                    # subspace step: more aggressive along subspace (trust-aware)\n                    step_sub = - (rho / (1.0 + np.linalg.norm(proj_sub))) * proj_sub\n                    step_rest = - 0.5 * (rho / (1.0 + np.linalg.norm(proj_rest))) * proj_rest\n                    step = step_sub + step_rest\n                    # clip to rho\n                    sn = np.linalg.norm(step)\n                    if sn > rho and sn > 0:\n                        step = step * (rho / sn)\n                    x_trust = m + step\n                    candidates.append(x_trust)\n                    c_types.append('trust')\n                    # also propose a partial trust + noise\n                    x_trust2 = m + 0.5 * step + 0.7 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, 1e-12))\n                    candidates.append(x_trust2)\n                    c_types.append('trust')\n                except np.linalg.LinAlgError:\n                    pass  # skip trust step if regression fails\n\n            # 3) Archive recombinations (mirrored blends)\n            n_recomb = lam - len(candidates)\n            for _ in range(n_recomb):\n                if len(X_arch) >= 3:\n                    # fitness biased selection but using rank transform\n                    f_arr = np.asarray(f_arch)\n                    ranks = np.argsort(np.argsort(f_arr))  # 0 best\n                    probs = (len(f_arr) - ranks).astype(float)\n                    probs = np.maximum(probs, 1e-12)\n                    probs = probs / np.sum(probs)\n                    a_idx, b_idx = rng.choice(len(X_arch), size=2, replace=False, p=probs)\n                    a = X_arch[a_idx]\n                    b = X_arch[b_idx]\n                    # mirrored convex blend to encourage exploration around midpoints\n                    alpha = rng.rand()\n                    mid = alpha * a + (1 - alpha) * b\n                    # mirror around mean occasionally\n                    if rng.rand() < 0.3:\n                        xrec = 2.0 * mid - m + 0.3 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, 1e-12))\n                    else:\n                        c_idx = rng.choice(len(X_arch))\n                        c = X_arch[c_idx]\n                        xrec = mid + 0.4 * (a - b) + 0.35 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, 1e-12))\n                    candidates.append(xrec)\n                    c_types.append('recomb')\n                else:\n                    candidates.append(rng.uniform(lb, ub))\n                    c_types.append('recomb')\n\n            # 4) Occasional heavy-tailed Levy leap for strong exploration\n            if rng.rand() < self.leap_prob and remaining - len(candidates) > 0:\n                # approximate Levy by Cauchy scaled; clip to bounds after\n                levy = m + (self.levy_scale * avg_span) * np.random.standard_cauchy(self.dim)\n                # mix with uniform to keep within domain\n                if rng.rand() < 0.5:\n                    levy = 0.6 * levy + 0.4 * rng.uniform(lb, ub)\n                candidates.append(levy)\n                c_types.append('levy')\n\n            # clamp candidates to bounds and evaluate sequentially\n            Xcand = np.asarray([np.minimum(np.maximum(np.array(x), lb), ub) for x in candidates])\n            fc = np.full(Xcand.shape[0], np.inf)\n\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                x = Xcand[i]\n                f = float(func(x))\n                evals += 1\n                fc[i] = f\n                # update archive FIFO\n                X_arch.append(x.copy())\n                f_arch.append(f)\n                if len(X_arch) > self.arch_size:\n                    del X_arch[0]\n                    del f_arch[0]\n                # update global best\n                if f < f_best:\n                    f_best = f\n                    x_best = x.copy()\n                    stagn_count = 0\n                else:\n                    stagn_count += 1\n\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                c_types = [c_types[i] for i in range(len(c_types)) if valid[i]]\n\n            if fc.size == 0:\n                break\n\n            # select candidate to influence decision via softmax (temperature based)\n            fmin_local = np.min(fc)\n            temp = np.std(fc) if np.std(fc) > 1e-12 else (0.1 * avg_span)\n            scores = np.exp(- (fc - fmin_local) / (temp + 1e-12))\n            probs = scores / np.sum(scores)\n            chosen_idx = rng.choice(len(Xcand), p=probs)\n            chosen_x = Xcand[chosen_idx].copy()\n            chosen_f = float(fc[chosen_idx])\n\n            # acceptance rule: deterministic improvement or probabilistic uphill\n            f_ref = min(f_best, np.min(fc))\n            delta = chosen_f - f_ref\n            accept = False\n            if chosen_f <= f_best:\n                accept = True\n            else:\n                if T > 1e-12 and rng.rand() < np.exp(-max(0.0, delta) / (T + 1e-12)):\n                    accept = True\n\n            # adjust mean m based on candidate type with different step sizes than ELTR\n            if accept:\n                if c_types[chosen_idx] == 'trust':\n                    eta = 0.45\n                elif c_types[chosen_idx] == 'gauss':\n                    eta = 0.22\n                elif c_types[chosen_idx] == 'recomb':\n                    eta = 0.30\n                elif c_types[chosen_idx] == 'levy':\n                    eta = 0.10\n                else:\n                    eta = 0.18\n                m = (1.0 - eta) * m + eta * chosen_x\n            else:\n                # small exploratory perturbation\n                m = m + 0.06 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, 1e-12))\n                m = np.minimum(np.maximum(m, lb), ub)\n\n            # normalized deltas (in units of sigma and sqrt(v))\n            denom = sigma * np.sqrt(np.maximum(v, 1e-12))\n            deltas_norm = (Xcand - m.reshape(1, -1)) / (denom.reshape(1, -1) + 1e-12)\n\n            # update normalization s (EMA)\n            stat = np.mean(np.abs(deltas_norm), axis=0)\n            alpha = 0.7\n            s = alpha * s + (1 - alpha) * (stat + 1e-12)\n            s = np.clip(s, self.s_min, self.s_max)\n\n            # record successful normalized steps: those that are best in local batch or the accepted one\n            success_mask = (fc <= (fmin_local + 1e-12))\n            success_mask[chosen_idx] = True\n            for i in range(len(deltas_norm)):\n                if success_mask[i]:\n                    buffer_steps.append(deltas_norm[i].copy())\n                    if len(buffer_steps) > self.buffer_size:\n                        del buffer_steps[0]\n\n            # Oja-like incremental subspace learning from buffer: faster small updates and orthonormalize periodically\n            if len(buffer_steps) > 0:\n                # pick a few recent samples for stochastic Oja update\n                k = min(len(buffer_steps), max(1, int(0.3 * len(buffer_steps))))\n                picks = rng.choice(len(buffer_steps), size=k, replace=False)\n                for idx in picks:\n                    xvec = buffer_steps[idx].reshape(-1, 1)  # dim x 1\n                    # project current U update: U <- U + eta * (x x^T U) then orthonormalize columns\n                    if r > 0:\n                        # compute outer product times current U\n                        delta = (xvec @ (xvec.T @ U))  # dim x r\n                        U += self.eta_oja * delta\n                        # re-orthonormalize U\n                        try:\n                            Q, _ = np.linalg.qr(U)\n                            U = Q[:, :r]\n                        except np.linalg.LinAlgError:\n                            # fallback: randomize a bit\n                            A = rng.randn(self.dim, r) * 0.01\n                            Q, _ = np.linalg.qr(A)\n                            U = Q[:, :r]\n                # update energy estimates w as variance of projections of buffer on U\n                if r > 0 and len(buffer_steps) >= r:\n                    B = np.asarray(buffer_steps)\n                    proj = B @ U  # (k x r)\n                    varproj = np.var(proj, axis=0) + 1e-12\n                    # smooth energies\n                    w = 0.85 * w + 0.15 * (varproj / (np.mean(varproj) + 1e-12))\n                    w = np.clip(w, 1e-5, 6.0)\n\n            # adapt sigma multiplicatively based on smoothed success probability\n            gen_success = float(np.any(success_mask))\n            p_succ = self.p_smooth * p_succ + (1.0 - self.p_smooth) * gen_success\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, 1e-10, 4.0 * avg_span)\n\n            # adapt trust radius: expand if a trust candidate succeeded in this generation, else shrink\n            trust_success = False\n            for i in range(len(c_types)):\n                if c_types[i] == 'trust' and valid is not None and i < len(valid) and success_mask[i]:\n                    trust_success = True\n                    break\n            if trust_success:\n                rho = min(self.trust_max, rho * self.trust_expand)\n            else:\n                rho = max(self.trust_min, rho * self.trust_shrink)\n\n            # temperature decay for uphill acceptance (faster decay than ELTR)\n            T *= 0.990\n            T = max(1e-8, T)\n\n            # opportunistic restart if stagnation\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                jitter = max(0.05 * avg_span, 0.8 * sigma)\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                sigma = max(sigma * 1.6, 0.15 * avg_span)\n                rho = max(rho, 0.7 * avg_span)\n                # reinitialize low-rank subspace mildly\n                if r > 0:\n                    A = rng.randn(self.dim, r) * 0.2\n                    Q, _ = np.linalg.qr(A)\n                    U = Q[:, :r]\n                    w = np.full(r, 0.18)\n                v = 0.5 * np.ones(self.dim)\n                buffer_steps = []\n                T = max(T, 0.4 * avg_span)\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 198, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x_trust = m + step", "error": "In the code, line 198, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x_trust = m + step", "parent_ids": "4ed544b1-f90e-4f66-9add-6e6d96fc009c", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "e18c4718-9112-4545-8b4c-a14a244c35b4", "fitness": "-inf", "name": "HALRME", "description": "The algorithm maintains a compact search state (mean m, global scale sigma, a low‑rank orthonormal basis U with per‑axis energies w, a diagonal residual variance v, coordinate scaling s_diag, an EMA momentum vector, a FIFO archive and a recent-step buffer) with conservative structural choices (rank ≈ ceil(log(dim)), pop_base ≈ 4+1.2·log(dim), arch_size = 8·dim, buffer_size = 8·rank). Sampling mixes antithetic Gaussian draws decomposed into low‑rank + diagonal noise (variance reduction via mirrored draws), coordinate‑wise scaling, a momentum bias, archive recombinations/differential blends and rare global leaps, while a linear trust‑region probe built from the archive provides directed exploitation when enough data exists. Adaptation is driven by PCA on buffered successful normalized steps (pca_period=8) to update U and energies, EMA updates for momentum (mom_beta=0.85) and s_diag (s_diag_beta=0.6), and multiplicative sigma adaptation from a smoothed success rate (sigma_adapt_rate=0.25, succ_target=0.2) with clipping and a small min_sigma. Selection uses softmax weighting on negative objectives with occasional uphill acceptance, and opportunistic restarts on stagnation (restart_frac≈0.06, inflate sigma ≈1.8) to rebalance exploration and exploitation.", "code": "import numpy as np\n\nclass HALRME:\n    \"\"\"\n    Hybrid Adaptive Low-Rank Momentum Explorer (HALRME)\n\n    Main ideas:\n    - Maintain mean m, global scale sigma, low-rank orthonormal factor U and diagonal residual variances v.\n    - Keep an archive and a buffer of recent successful normalized steps for PCA-driven subspace updates.\n    - Generate candidates from: (a) low-rank+diag antithetic Gaussian samples with momentum bias and coordinate scaling,\n      (b) surrogate trust-region (linear surrogate) probes when archive suffices, (c) archive recombinations/differential blends,\n      plus occasional global leaps.\n    - Update sigma multiplicatively with a smoothed success rate; update low-rank subspace periodically via SVD on buffer steps;\n      update momentum as EMA of normalized successful steps; restart opportunistically on stagnation.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # sampling / adaptation defaults\n        self.rank = max(1, min(4, int(np.ceil(np.log(max(2, self.dim)) + 0.5))))  # small rank\n        self.pop_base = max(6, int(4 + 1.2 * np.log(max(2, self.dim))))\n        self.arch_size = max(8 * self.dim, 30)\n        self.buffer_size = max(8 * self.rank, 20)\n        self.pca_period = 8\n\n        # adaptation hyperparameters\n        self.sigma_adapt_rate = 0.25\n        self.succ_target = 0.2\n        self.p_smooth = 0.9\n        self.mom_beta = 0.85\n        self.s_diag_beta = 0.6\n        self.min_sigma = 1e-9\n\n        # exploration controls\n        self.leap_prob = 0.03\n        self.restart_frac = 0.06\n        self.restart_inflate = 1.8\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds support (scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize state\n        evals = 0\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(1e-8, 0.12 * avg_span)\n\n        r = min(self.rank, self.dim)\n        # initial low-rank orthonormal directions\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :r].copy()\n            w = np.full(r, 0.12)  # energies for low-rank dims\n        else:\n            U = np.zeros((self.dim, 0))\n            w = np.array([])\n\n        # diagonal residual variance (per-dim)\n        v = np.full(self.dim, 0.4)\n        s_diag = np.ones(self.dim)  # coordinate-wise multiplicative scaling (EMA tracked)\n        momentum = np.zeros(self.dim)\n\n        # archive and buffers\n        X_arch = []\n        f_arch = []\n        buffer_steps = []\n\n        # seed with a small initial population\n        init_pop = min(self.pop_base, max(6, self.budget // 60))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        if len(f_arch) == 0:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        # best so far\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # adaptation state\n        p_succ = 0.2\n        stagn_limit = max(5, int(self.restart_frac * self.budget))\n        stagn_count = 0\n        gen = 0\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            lam = max(1, lam)\n\n            candidates = []\n            c_types = []\n\n            # 1) Trust-region / surrogate linear probe (if archive big enough)\n            if len(X_arch) >= max(6, self.dim // 3):\n                # Build a weighted linear surrogate (f ~ a + g·(x - m))\n                X_arr = np.asarray(X_arch)\n                f_arr = np.asarray(f_arch)\n                dx = X_arr - m.reshape(1, -1)\n                # distances normalized by sigma and v\n                denom = sigma * np.sqrt(np.maximum(v, 1e-12))\n                dist = np.linalg.norm(dx / denom.reshape(1, -1), axis=1)\n                wdist = np.exp(-0.6 * dist)\n                # fitness weight favoring good points\n                if np.ptp(f_arr) > 1e-12:\n                    wrank = np.exp(-0.8 * (f_arr - np.min(f_arr)) / (np.ptp(f_arr)))\n                else:\n                    wrank = np.ones_like(f_arr)\n                weights = wdist * (0.4 + 0.6 * wrank)\n                W = np.sqrt(weights).reshape(-1, 1)\n                # solve ridge for gradient\n                try:\n                    A = (W * dx).T @ (W * dx) + 1e-6 * np.eye(self.dim)\n                    b = (W * dx).T @ (W * (f_arr - np.min(f_arr)))\n                    g_est = np.linalg.solve(A, b)\n                    # propose Newton-like step along -g_est (approx); clip to trust radius\n                    Hdiag = 1e-2 + np.maximum(np.mean(weights) * 0.1, 0.0)  # soft diag regularizer\n                    step = - g_est / (Hdiag + 1e-12)\n                    max_step = max(1e-12, 0.6 * avg_span)\n                    norm_step = np.linalg.norm(step)\n                    if norm_step > max_step:\n                        step = step * (max_step / norm_step)\n                    x_trust = m + step\n                    candidates.append(np.minimum(np.maximum(x_trust, lb), ub))\n                    c_types.append('trust')\n                    # also damped trust\n                    candidates.append(np.minimum(np.maximum(m + 0.5 * step, lb), ub))\n                    c_types.append('trust')\n                except np.linalg.LinAlgError:\n                    pass\n\n            # 2) Low-rank + diag antithetic Gaussian samples with momentum & coord scaling\n            half = max(1, lam // 2)\n            # draw base normals for half, mirror them for antithetic\n            Zpos = rng.normal(size=(half, self.dim))\n            Z = np.vstack([Zpos, -Zpos])\n            if (lam % 2) == 1:\n                Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n            # apply coordinate scaling\n            Z = Z * s_diag.reshape(1, -1)\n            # low-rank contribution\n            if U.shape[1] > 0:\n                # transform: project Z onto low-rank directions scaled by sqrt energies\n                eps_r = rng.normal(size=(Z.shape[0], U.shape[1])) * np.sqrt(np.maximum(w.reshape(1, -1), 1e-12))\n                low_contrib = eps_r @ U.T\n            else:\n                low_contrib = np.zeros((Z.shape[0], self.dim))\n            # diag part\n            eps_d = rng.normal(size=(Z.shape[0], self.dim)) * np.sqrt(np.maximum(v.reshape(1, -1), 1e-12))\n            Y = low_contrib + eps_d + Z  # combine\n            # add a small directional bias from momentum in normalized coords\n            mlen = np.linalg.norm(momentum) + 1e-20\n            if mlen > 0:\n                v_unit = momentum / mlen\n                bias_strength = 0.6 * (mlen / (1.0 + mlen))\n                s_scalar = rng.normal(scale=bias_strength, size=(Y.shape[0], 1))\n                Y = Y + s_scalar * v_unit.reshape(1, -1)\n            Xg = m.reshape(1, -1) + sigma * Y\n            # clamp and append up to lam candidates (but keep trust proposals if any)\n            for i in range(Xg.shape[0]):\n                if len(candidates) >= lam:\n                    break\n                candidates.append(np.minimum(np.maximum(Xg[i], lb), ub))\n                c_types.append('gauss')\n\n            # 3) Archive recombinations to fill up candidates\n            while len(candidates) < lam:\n                if len(X_arch) >= 3:\n                    f_arr = np.asarray(f_arch)\n                    probs = (np.max(f_arr) - f_arr + 1e-12)\n                    probs = probs / np.sum(probs)\n                    a_idx, b_idx = rng.choice(len(X_arch), size=2, replace=False, p=probs)\n                    a = X_arch[a_idx]; b = X_arch[b_idx]\n                    alpha = rng.rand()\n                    xrec = alpha * a + (1 - alpha) * b\n                    # differential perturbation from a third point\n                    c_idx = rng.randint(len(X_arch))\n                    c = X_arch[c_idx]\n                    diff = (a - b)\n                    xrec = xrec + 0.4 * rng.rand() * diff + 0.4 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, 1e-12))\n                    candidates.append(np.minimum(np.maximum(xrec, lb), ub))\n                    c_types.append('recomb')\n                else:\n                    candidates.append(rng.uniform(lb, ub, size=self.dim))\n                    c_types.append('recomb')\n\n            # 4) occasional global leap\n            if rng.rand() < self.leap_prob and len(candidates) < lam and remaining - len(candidates) > 0:\n                candidates.append(rng.uniform(lb, ub, size=self.dim))\n                c_types.append('leap')\n\n            # Evaluate candidates sequentially with budget guard\n            Xcand = np.asarray(candidates)\n            fc = np.full(Xcand.shape[0], np.inf)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    break\n                x = Xcand[i]\n                try:\n                    fval = float(func(x))\n                except Exception:\n                    fval = np.inf\n                fc[i] = fval\n                evals += 1\n\n                # update archive FIFO\n                X_arch.append(x.copy())\n                f_arch.append(fval)\n                if len(X_arch) > self.arch_size:\n                    del X_arch[0]; del f_arch[0]\n\n                # update global best\n                if fval < f_best:\n                    f_best = fval\n                    x_best = x.copy()\n                    stagn_count = 0\n                else:\n                    stagn_count += 1\n\n            # truncate if budget ended\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                c_types = [c_types[i] for i in range(len(c_types)) if valid[i]]\n                if fc.size == 0:\n                    break\n\n            # scoring: softmax on negative objective (favor low f)\n            fmin_local = np.min(fc)\n            # avoid zero std bug\n            std_fc = np.std(fc)\n            if std_fc < 1e-12:\n                std_fc = 1.0\n            scores = np.exp(-(fc - fmin_local) / (std_fc + 1e-12))\n            probs = scores / np.sum(scores)\n            chosen_idx = rng.choice(len(Xcand), p=probs)\n            chosen_x = Xcand[chosen_idx].copy()\n            chosen_f = float(fc[chosen_idx])\n\n            # acceptance: accept if improves global best or probabilistic uphill\n            accept = False\n            if chosen_f <= f_best:\n                accept = True\n            else:\n                T = max(1e-8, 0.5 * avg_span)  # scale parameter for uphill acceptance\n                if rng.rand() < np.exp(-max(0.0, chosen_f - fmin_local) / (T + 1e-12)):\n                    accept = True\n\n            if accept:\n                # move mean moderately toward chosen_x depending on type\n                typ = c_types[chosen_idx]\n                if typ == 'trust':\n                    eta = 0.36\n                elif typ == 'gauss':\n                    eta = 0.18\n                elif typ == 'recomb':\n                    eta = 0.22\n                else:\n                    eta = 0.15\n                m = (1.0 - eta) * m + eta * chosen_x\n                # shrink a bit sigma if good (implicit via p_succ update later)\n            else:\n                # exploratory perturbation\n                m = m + 0.06 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, 1e-12))\n                m = np.minimum(np.maximum(m, lb), ub)\n\n            # compute normalized deltas for successful candidates to update momentum / buffer\n            denom = sigma * np.sqrt(np.maximum(v, 1e-12))\n            deltas_norm = (Xcand - m.reshape(1, -1)) / denom.reshape(1, -1)\n\n            # define local success mask: those improving local min (fc <= fmin_local + eps)\n            eps = 1e-12\n            success_mask = (fc <= (fmin_local + eps))\n            # also ensure chosen candidate is considered\n            success_mask[chosen_idx] = True\n\n            # accumulate buffer steps and update momentum as EMA of mean normalized successful step\n            if np.any(success_mask):\n                succ_steps = deltas_norm[success_mask]\n                step_mean = np.mean(succ_steps, axis=0)\n                momentum = self.mom_beta * momentum + (1 - self.mom_beta) * step_mean\n                for row in succ_steps:\n                    buffer_steps.append(row.copy())\n                # keep buffer size\n                if len(buffer_steps) > self.buffer_size:\n                    buffer_steps = buffer_steps[-self.buffer_size:]\n            else:\n                # small decay of momentum\n                momentum *= self.mom_beta\n\n            # update coordinate-wise s_diag (EMA of sqrt mean squared normalized steps)\n            stat = np.mean((deltas_norm ** 2), axis=0) if deltas_norm.size > 0 else np.ones(self.dim) * 1e-6\n            s_diag = self.s_diag_beta * s_diag + (1.0 - self.s_diag_beta) * np.sqrt(stat + 1e-20)\n            s_diag = np.clip(s_diag, 0.2, 6.0)\n\n            # periodic PCA on buffer to update U and energies w\n            if (gen % self.pca_period == 0) and len(buffer_steps) >= max(3, r):\n                B = np.asarray(buffer_steps)\n                Bc = B - np.mean(B, axis=0, keepdims=True)\n                try:\n                    U_s, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        U_new = Vt[:r_eff].T  # dim x r_eff\n                        eig_energy = (S_s[:r_eff] ** 2) / max(1, Bc.shape[0] - 1)\n                        # smooth update\n                        if U.shape[1] == r_eff:\n                            U = 0.85 * U + 0.15 * U_new\n                            w = 0.75 * w + 0.25 * (eig_energy / (np.mean(eig_energy) + 1e-12))\n                        else:\n                            U = U_new\n                            w = eig_energy / (np.mean(eig_energy) + 1e-12)\n                        w = np.clip(w, 1e-4, 5.0)\n                        # adjust residual diag v to keep variance balanced (heuristic)\n                        explained = np.sum(w)\n                        tot = np.mean(np.var(Bc, axis=0) + 1e-6)\n                        rem = max(1e-6, tot - explained / max(1, r_eff))\n                        v = 0.8 * v + 0.2 * np.clip(rem * np.ones(self.dim), 1e-6, 4.0)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # sigma adaptation via smoothed success rate\n            gen_success = float(np.any(success_mask))\n            p_succ = self.p_smooth * p_succ + (1.0 - self.p_smooth) * gen_success\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, self.min_sigma, 4.0 * avg_span)\n\n            # opportunistic restart on stagnation\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # restart around best with jitter\n                jitter = max(0.05 * avg_span, 0.5 * sigma)\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                sigma = max(sigma * self.restart_inflate, 0.18 * avg_span)\n                # reinit low-rank & buffers\n                if r > 0:\n                    A = rng.randn(self.dim, r)\n                    Q, _ = np.linalg.qr(A)\n                    U = Q[:, :r]\n                    w = np.full(r, 0.15)\n                v = np.full(self.dim, 0.4)\n                momentum = np.zeros(self.dim)\n                buffer_steps = []\n                s_diag = np.ones(self.dim)\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 150, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x_trust = m + step", "error": "In the code, line 150, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,6) \nOn line: x_trust = m + step", "parent_ids": "4ed544b1-f90e-4f66-9add-6e6d96fc009c", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "4294cd05-04cc-4659-844f-cbe70d402db7", "fitness": 0.15710568143407191, "name": "AMAS", "description": "AMAS is a hybrid heuristic that mixes antithetic momentum‑covariance sampling (an MCAS‑style core) with occasional low‑rank subspace surrogate exploitation, mirrored directional probes seeded from an elite archive, and clipped Cauchy heavy‑tailed restarts to balance exploration and escape stagnation. The distribution is adapted online via a momentum vector v, a small rank‑one contribution (rank1=0.06) and a rank‑mu covariance learning rate (cov_lr=0.16), plus coordinate‑wise EMA scaling s_diag (s_diag_beta=0.6) and a chol_safe SPD factorization for robust sampling. Subspace operations build orthonormal bases from archive differences or random QR and fit a linear model by least squares to estimate a descent direction, while mirrored central differences around the weighted mean m use a trust_radius that expands/shrinks on success/failure (trust_expand=1.25, trust_shrink=0.6). The algorithm is budget‑aware (adaptive batch sizes, archive limited by archive_size_factor), enforces bounds clipping, adapts sigma with a success target (sigma_adapt_rate=0.25, success_target=0.2), and injects uniform or heavy‑tailed jumps when stagnation is detected.", "code": "import numpy as np\n\nclass AMAS:\n    \"\"\"\n    AMAS: Antithetic Momentum + Adaptive Subspace\n\n    Main idea:\n      - Antithetic sampling with momentum, covariance and coordinate-wise scaling (MCAS-style)\n      - Occasionally perform mirrored directional probes (x +/- delta*v) seeded from archive diffs\n      - Occasionally build a low-rank linear surrogate in a random small subspace to estimate a gradient\n      - Adaptive sigma and trust_radius (expand on success, shrink on failure), archive-driven centers,\n        and Cauchy heavy-tailed restarts to escape stagnation.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n\n        # hyper-parameters (sensible defaults)\n        self.pop_base = None\n        self.cov_lr = 0.16       # rank-mu learning rate\n        self.rank1 = 0.06        # momentum rank-one weight\n        self.mom_beta = 0.82     # momentum EMA\n        self.s_diag_beta = 0.6   # EMA for coordinate scales\n        self.sigma_adapt_rate = 0.25\n        self.success_target = 0.2\n        self.trust_init_frac = 0.25\n        self.trust_expand = 1.25\n        self.trust_shrink = 0.6\n        self.subspace_prob = 0.28\n        self.directional_prob = 0.36\n        self.heavy_prob = 0.36\n        self.archive_size_factor = 4  # archive size ~ factor * dim\n        self.min_sigma = 1e-12\n        self.max_sigma_scale = 3.0\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds handling (support scalar or arrays)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        diag_span = np.maximum(span, 1e-12)\n\n        # budget-aware initial sample\n        evals = 0\n        # initial small batch to seed states\n        init_batch = min(max(6, 2 * self.dim), max(1, self.budget // 20))\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.empty(init_batch, dtype=float)\n        for i in range(init_batch):\n            if evals >= self.budget:\n                f0[i] = np.inf\n                continue\n            f0[i] = func(X0[i])\n            evals += 1\n\n        # best-known\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # archive (sorted by f ascending): keep small elite set\n        archive_k = max(4, min(12, int(self.archive_size_factor * self.dim)))\n        archive = []\n        for i in range(init_batch):\n            if not np.isfinite(f0[i]):\n                continue\n            archive.append((float(f0[i]), X0[i].copy()))\n        archive.sort(key=lambda t: t[0])\n        if len(archive) > archive_k:\n            archive = archive[:archive_k]\n\n        # initialize distribution state\n        # mean m = weighted average of top-half\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 = w0 / np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        bounds_scale = span\n        # initial covariance moderate isotropic\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.18 * np.mean(bounds_scale))\n        # trust radius for subspace/directional ops\n        trust_radius = max(1e-8, self.trust_init_frac * np.mean(bounds_scale))\n        trust_min = 1e-8\n        trust_max = 2.0 * np.max(bounds_scale)\n\n        # additional state\n        v = np.zeros(self.dim, dtype=float)     # momentum in normalized coordinates\n        s_diag = np.ones(self.dim, dtype=float) # coordinate-wise scaling\n        p_succ = self.success_target\n        stagn_iter = 0\n        stagn_threshold = max(5, int(0.04 * self.budget))\n        attempt = 0\n\n        # helpers\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # archive insert\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        def heavy_tail_scalar():\n            s = rng.standard_cauchy()\n            return float(np.clip(s, -1e2, 1e2))\n\n        def random_subspace(k):\n            Y = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(Y)\n            return Q[:, :k]\n\n        # SPD factor for sampling\n        def chol_safe(Cmat):\n            eps = 1e-12 * np.maximum(np.diag(Cmat), 1.0)\n            try:\n                A = np.linalg.cholesky(Cmat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(Cmat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        # main loop\n        while evals < self.budget:\n            attempt += 1\n            remaining = self.budget - evals\n            # adapt population base\n            if self.pop_base is None:\n                lam0 = max(6, int(3 + 2 * np.log(max(2, self.dim))))\n            else:\n                lam0 = int(self.pop_base)\n            lam = min(lam0, remaining)\n            if remaining >= 2:\n                lam = max(2, lam)  # ensure antithetic pairs when possible\n\n            # choose operation type: subspace model, mirrored directional, or antithetic sampling / heavy-tail\n            op = rng.rand()\n            success = False\n\n            # 1) Low-rank subspace model exploitation (AMDS-style)\n            # ensure we have budget for sampling several points (at least 4)\n            if op < self.subspace_prob and remaining >= 4:\n                # choose subspace dimension\n                k = min(self.dim, max(1, int(min(4, max(1, self.dim // 4)))))\n                # pick random subspace (sometimes biased by archive PCA)\n                if len(archive) >= 3 and rng.rand() < 0.5:\n                    # use differences from top elites to build subspace\n                    base = archive[0][1]\n                    diffs = []\n                    for t in range(1, min(len(archive), k+3)):\n                        diffs.append(archive[t][1] - base)\n                    if len(diffs) >= k:\n                        D = np.stack(diffs[:k], axis=1)\n                        # QR to orthonormalize\n                        try:\n                            Q, _ = np.linalg.qr(D)\n                            U = Q[:, :k]\n                        except Exception:\n                            U = random_subspace(k)\n                    else:\n                        U = random_subspace(k)\n                else:\n                    U = random_subspace(k)\n\n                sigma_sub = trust_radius\n                # design size: ensure more samples than k\n                s = min( max(2 + 2*k, k+1), remaining )\n                # sample coefficients in [-1,1]\n                Z = rng.uniform(-1.0, 1.0, size=(s, k)).astype(float)\n                Xs = np.asarray([m + (Z[i] @ (sigma_sub * U.T)) for i in range(s)])\n                # clip\n                for i in range(s):\n                    Xs[i] = np.minimum(np.maximum(Xs[i], lb), ub)\n                # evaluate planned points (budget guarded)\n                fvals = []\n                evaled = 0\n                for i in range(s):\n                    if evals >= self.budget:\n                        break\n                    res = eval_and_record(Xs[i])\n                    if res is None:\n                        break\n                    fi, xi = res\n                    fvals.append(fi)\n                    evaled += 1\n                if len(fvals) >= max(1, k):\n                    fvals = np.asarray(fvals, dtype=float)\n                    Z_used = Z[: len(fvals), :]\n                    A = np.concatenate([np.ones((len(fvals), 1)), Z_used], axis=1)\n                    # least squares fit\n                    try:\n                        sol, *_ = np.linalg.lstsq(A, fvals, rcond=None)\n                        g_sub = sol[1:]\n                        g_full = (U @ g_sub).astype(float)\n                        gnorm = np.linalg.norm(g_full)\n                        if gnorm > 1e-12:\n                            step_scale = sigma_sub * (0.9 + 0.2 * heavy_tail_scalar() * 0.05)\n                            proposed = m - (step_scale * g_full / (gnorm + 1e-12))\n                        else:\n                            proposed = m + rng.normal(scale=sigma_sub * 0.5, size=self.dim)\n                        proposed = np.minimum(np.maximum(proposed, lb), ub)\n                        res = eval_and_record(proposed)\n                        if res is None:\n                            break\n                        fprop, xprop = res\n                        if fprop < f_best:\n                            success = True\n                            trust_radius = min(trust_max, trust_radius * self.trust_expand)\n                        else:\n                            trust_radius = max(trust_min, trust_radius * self.trust_shrink)\n                    except Exception:\n                        trust_radius = max(trust_min, trust_radius * self.trust_shrink)\n\n            # 2) Mirrored directional exploitation (central differences along archive-seeded directions)\n            elif op < self.subspace_prob + self.directional_prob and remaining >= 2:\n                # choose number of mirrored directions d (1..min(4,dim))\n                max_d = min(4, self.dim)\n                # budget-aware: each direction uses 2 evals\n                d = min(max_d, max(1, remaining // 2))\n                # build directions: prefer archive differences\n                directions = []\n                if len(archive) >= 2 and rng.rand() < 0.8:\n                    # differences between top elites\n                    top = archive[0][1]\n                    for i in range(1, min(len(archive), d+1)):\n                        v = archive[i][1] - top\n                        nrm = np.linalg.norm(v)\n                        if nrm > 1e-12:\n                            directions.append(v / nrm)\n                # fill remaining with randoms\n                while len(directions) < d:\n                    v = rng.randn(self.dim)\n                    v = v / (np.linalg.norm(v) + 1e-12)\n                    directions.append(v)\n                grad_est = np.zeros(self.dim, dtype=float)\n                used = 0\n                for v in directions:\n                    if evals + 2 > self.budget:\n                        break\n                    delta = trust_radius * (0.7 + 0.8 * rng.rand())  # (0.7..1.5)*trust\n                    xp = np.minimum(np.maximum(m + delta * v, lb), ub)\n                    xn = np.minimum(np.maximum(m - delta * v, lb), ub)\n                    res1 = eval_and_record(xp)\n                    if res1 is None:\n                        break\n                    res2 = eval_and_record(xn)\n                    if res2 is None:\n                        break\n                    fp, _ = res1\n                    fn, _ = res2\n                    ddir = (fp - fn) / (2.0 * delta)\n                    grad_est += ddir * v\n                    used += 2\n                if used > 0:\n                    gnorm = np.linalg.norm(grad_est)\n                    if gnorm < 1e-12:\n                        step = trust_radius * rng.randn(self.dim) * 0.25\n                    else:\n                        step = - (trust_radius * 0.9) * grad_est / gnorm\n                    proposed = np.minimum(np.maximum(m + step, lb), ub)\n                    res = eval_and_record(proposed)\n                    if res is not None:\n                        fprop, xprop = res\n                        if fprop < f_best:\n                            success = True\n                            trust_radius = min(trust_max, trust_radius * self.trust_expand)\n                        else:\n                            trust_radius = max(trust_min, trust_radius * self.trust_shrink)\n\n            # 3) Antithetic momentum-covariance sampling with occasional heavy-tailed jump (MCAS-style core)\n            else:\n                # small fraction of time perform heavy-tailed restart/jump\n                if rng.rand() < 0.12 and remaining >= 1:\n                    # heavy-tailed jump anchored at best or random archive elite\n                    if len(archive) > 0 and rng.rand() < 0.8:\n                        anchor = archive[0][1].copy()\n                    else:\n                        anchor = rng.uniform(lb, ub)\n                    c = heavy_tail_scalar()\n                    anis = (0.2 + 0.8 * rng.rand()) * diag_span\n                    jump = c * (0.6 + 0.8 * rng.rand()) * anis * rng.randn(self.dim)\n                    proposed = np.minimum(np.maximum(anchor + jump, lb), ub)\n                    res = eval_and_record(proposed)\n                    if res is None:\n                        break\n                    fj, xj = res\n                    if fj < f_best:\n                        success = True\n                        # reset local trust radius upward to explore around new area\n                        trust_radius = min(trust_max, max(trust_radius, 0.6 * np.mean(bounds_scale)))\n                    else:\n                        success = False\n                else:\n                    # antithetic sampling\n                    # ensure SPD for C\n                    A = chol_safe(C)\n                    half = lam // 2\n                    if half <= 0:\n                        # fallback single sample\n                        Z = rng.normal(size=(1, self.dim))\n                        Y = Z @ A.T\n                        Y = Y * s_diag.reshape(1, -1)\n                        Xcand = m + sigma * Y\n                    else:\n                        Zpos = rng.normal(size=(half, self.dim))\n                        Z = np.vstack([Zpos, -Zpos])\n                        if lam % 2 == 1:\n                            Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n                        Y = Z @ A.T\n                        # add momentum-directed perturbation\n                        vlen = np.linalg.norm(v) + 1e-20\n                        if vlen > 0:\n                            v_unit = v / vlen\n                        else:\n                            v_unit = np.zeros_like(v)\n                        dir_strength = 0.8 * (vlen / (1.0 + vlen))\n                        s_scalar = rng.normal(scale=dir_strength, size=(Y.shape[0], 1))\n                        Y = Y + (s_scalar * v_unit.reshape(1, -1))\n                        Y = Y * s_diag.reshape(1, -1)\n                        Xcand = m + sigma * Y\n                    # clip and evaluate sequentially (budget guarded)\n                    Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n                    # evaluate\n                    n_cand = Xcand.shape[0]\n                    fc = np.full(n_cand, np.inf, dtype=float)\n                    for i in range(n_cand):\n                        if evals >= self.budget:\n                            break\n                        fc[i] = func(Xcand[i])\n                        evals += 1\n                        # update best on the fly\n                        if fc[i] < f_best:\n                            f_best = float(fc[i])\n                            x_best = Xcand[i].copy()\n                    # if evaluated some, update archive and distribution state below\n                    # incorporate evaluations into archive\n                    for i in range(n_cand):\n                        if not np.isfinite(fc[i]):\n                            continue\n                        if len(archive) < archive_k or fc[i] < archive[-1][0]:\n                            archive.append((float(fc[i]), Xcand[i].copy()))\n                    # trim archive\n                    archive.sort(key=lambda t: t[0])\n                    if len(archive) > archive_k:\n                        archive = archive[:archive_k]\n                    # set flags for success if any candidate improved\n                    if n_cand > 0 and np.min(fc) < f_best:\n                        # handled above: f_best updated on the fly\n                        success = True\n                    else:\n                        # define improvement relative to previous m evaluation: check archive closeness\n                        if len(archive) > 0 and archive[0][0] < f_best:\n                            # this is a weak criterion; we conservatively set success if new best was found earlier\n                            success = False\n                        else:\n                            success = False\n\n                    # compute elites among evaluated candidates to update m/C/v/s_diag\n                    if n_cand > 0:\n                        # select mu elites\n                        mu = max(1, min(n_cand // 2, n_cand))\n                        order = np.argsort(fc)\n                        X_mu = Xcand[order[:mu]]\n                        # weights\n                        w = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n                        w = np.maximum(w, 0.0)\n                        if np.sum(w) <= 0:\n                            w = np.ones_like(w)\n                        w = w / np.sum(w)\n                        W = w.reshape(-1, 1)\n                        m_new = (W * X_mu).sum(axis=0)\n                        # normalized deltas in sample coordinates (y = (x - m) / sigma)\n                        deltas = (X_mu - m) / (sigma + 1e-20)\n                        # weighted covariance from elites\n                        weighted_cov = (deltas * W).T @ deltas\n                        delta_mean = (W * deltas).sum(axis=0)\n                        # update momentum\n                        v = self.mom_beta * v + (1.0 - self.mom_beta) * delta_mean\n                        # rank-one from momentum\n                        rank_one = np.outer(v, v)\n                        c_cov = float(self.cov_lr)\n                        c1 = float(self.rank1)\n                        # update covariance in normalized coords then scale by sigma^2\n                        C = (1.0 - c_cov - c1) * C + c_cov * weighted_cov + c1 * rank_one\n                        # symmetry and positivity\n                        C = 0.5 * (C + C.T) + np.diag(np.maximum(np.diag(C), 1e-18))\n                        # coordinate-wise scale EMA\n                        if deltas.shape[0] > 0:\n                            stat = np.mean(deltas**2, axis=0)\n                        else:\n                            stat = 1e-6 * np.ones(self.dim)\n                        s_diag = (self.s_diag_beta * s_diag +\n                                  (1.0 - self.s_diag_beta) * np.sqrt(stat + 1e-20))\n                        s_diag = np.clip(s_diag, 0.15, 6.0)\n                        # update mean\n                        m = m_new.copy()\n                        # success considered if any candidate improved global best\n                        improved = np.min(fc) < f_best\n                        # adapt sigma using observed improvement (we used on-the-fly update of f_best)\n                        p_succ = 0.85 * p_succ + 0.15 * float(np.min(fc) < f_best)\n                        # but ensure adaptation uses earlier 'success' variable status:\n                        # to be conservative use success flag computed earlier\n                        # adjust sigma multiplicatively\n                        sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n                        sigma = np.clip(sigma, self.min_sigma, self.max_sigma_scale * np.max(bounds_scale))\n\n            # end of op handling\n\n            # if not in antithetic block (mirrored/subspace/heavy), we may have left some updates undone; do common updates here:\n            # general sigma adaptation when a step produced a new best recently:\n            # we track success as whether f_best was improved in this iteration via direct comparison using archive top\n            # A simple heuristic: if last few archive updates lowered best, treat as success (already handled above)\n            # adjust sigma slightly on success/failure if not already adjusted\n            # (keep conservative safe defaults)\n            # Also nudge trust radius if long stagnation observed\n            if success:\n                trust_radius = min(trust_max, trust_radius * self.trust_expand)\n                p_succ = 0.9 * p_succ + 0.1 * 1.0\n                sigma = min(self.max_sigma_scale * np.max(bounds_scale), sigma * 1.08)\n                stagn_iter = 0\n            else:\n                trust_radius = max(trust_min, trust_radius * self.trust_shrink)\n                p_succ = 0.9 * p_succ + 0.1 * 0.0\n                sigma = max(self.min_sigma, sigma * 0.98)\n                stagn_iter += 1\n\n            # occasional uniform injection to keep exploration\n            if attempt % 37 == 0 and evals < self.budget:\n                xr = rng.uniform(lb, ub)\n                ev = eval_and_record(xr)\n                if ev is None:\n                    break\n\n            # opportunistic heavy-tailed escape if stagnating\n            if stagn_iter >= stagn_threshold and evals < self.budget:\n                stagn_iter = 0\n                # heavy-tailed jump anchored on best or random elite\n                if len(archive) > 0 and rng.rand() < 0.85:\n                    anchor = archive[0][1]\n                else:\n                    anchor = rng.uniform(lb, ub)\n                c = heavy_tail_scalar()\n                scale = max(0.5 * np.mean(bounds_scale), sigma * 2.0)\n                jump = rng.standard_cauchy(size=self.dim) * scale * np.clip(c, -50, 50)\n                xj = np.minimum(np.maximum(anchor + jump, lb), ub)\n                res = eval_and_record(xj)\n                if res is None:\n                    break\n                fj, xj = res\n                if fj < f_best:\n                    # reset distribution near new area\n                    m = xj.copy()\n                    sigma = max(sigma, 0.5 * np.mean(bounds_scale))\n                    C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                    v = np.zeros_like(v)\n                    s_diag = np.ones_like(s_diag)\n\n            # limit trust radius to reasonable bounds\n            trust_radius = np.clip(trust_radius, trust_min, trust_max)\n\n            # safety break if budget exhausted\n            if evals >= self.budget:\n                break\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AMAS scored 0.157 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "4ed544b1-f90e-4f66-9add-6e6d96fc009c", "operator": null, "metadata": {"aucs": [0.08146087419352221, 0.1515899743075967, 0.2207616782340116, 0.15517611594281422, 0.162068479472403, 0.16784687362629358, 0.18143902049343585, 0.17779597633614186, 0.1537884460184329, 0.11912937571606719]}, "task_prompt": ""}
{"id": "b0e7fc8a-1fa8-4e80-8412-4a023fed929e", "fitness": 0.1745549717547097, "name": "MAGES", "description": "MAGES maintains a low‑rank orthonormal subspace B (default rank ≈ dim//6) with multiplicative direction energies e (updated by exponentiated, reward‑weighted contributions, energy_lr=0.25) to bias stochastic sampling toward productive directions, and it refreshes B via PCA on recent archive entries (archive_size ≈ max(6*dim,120), pca_refresh=12) to capture evolving structure. It combines subspace-guided Gaussian probes (pop≈16) with per‑coordinate residual noise s (EMA with s_lr=0.15) and multiscale steps (scales (0.3,1.0,3.0)), plus occasional Lévy‑like uniform jumps (levy_prob=0.03) and small orthonormal rotations to maintain global exploration and diversity. A cheap diagonal quadratic surrogate is fit in the subspace from recent evaluations to propose targeted minimizers, proposals are clipped to bounds, and energies and s are adapted from observed improvement per projected step; sigma is initialized as sigma0_mult*avg_span (sigma0_mult=0.2) and adjusted (shrink on success, grow on rejection). Robustness features include probabilistic uphill acceptance (temperature ∝ sigma), trust‑clipped mean updates, opportunistic restarts on stagnation (stagn_thresh_frac=0.06, restart_infl≈1.8), and FIFO archive management to stay within the evaluation budget.", "code": "import numpy as np\n\nclass MAGES:\n    \"\"\"\n    Multi-scale Adaptive Gradient Estimation & Subspace search (MAGES)\n\n    Key ideas (concise):\n    - Maintain a low-rank subspace B (dim x r) and multiplicative direction energies `e`\n      used to bias sampling toward productive directions.\n    - Keep an archive of recent evaluated points and build a cheap diagonal-quadratic\n      surrogate in the subspace to propose targeted steps.\n    - Multi-scale probing: sample steps at different relative scales (small/nominal/large).\n    - Occasional Levy-like long uniform jumps for global exploration.\n    - Update direction energies with exponentiated rewards derived from observed\n      improvement per unit projected step. Update per-coordinate residuals (diag noise)\n      with EMA of normalized step magnitudes.\n    - Opportunistic restarts when stagnation is detected.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 rank=None, pop=16, archive_size=None, surv_size=200,\n                 pca_refresh=12, multiscale=(0.3, 1.0, 3.0),\n                 levy_prob=0.03, energy_lr=0.25, s_lr=0.15,\n                 sigma0_mult=0.2, stagn_thresh_frac=0.06, restart_infl=1.8):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.rank = int(rank) if rank is not None else max(1, min(self.dim, max(1, self.dim // 6)))\n        self.pop = int(pop)\n        self.archive_size = archive_size if archive_size is not None else max(6 * self.dim, 120)\n        self.surv_size = int(surv_size)\n        self.pca_refresh = int(pca_refresh)\n        self.multiscale = tuple(multiscale)\n        self.levy_prob = float(levy_prob)\n        self.energy_lr = float(energy_lr)     # learning rate for multiplicative energy updates\n        self.s_lr = float(s_lr)               # EMA learning rate for per-coordinate residuals\n        self.sigma0_mult = float(sigma0_mult)\n        self.stagn_thresh_frac = float(stagn_thresh_frac)\n        self.restart_infl = float(restart_infl)\n\n        # safety clamps\n        self.min_energy = 1e-5\n        self.max_energy = 1e3\n        self.min_s = 1e-6\n        self.max_s = 10.0\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds (Many Affine BBOB uses -5..5 but accept func.bounds if given)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        # initialize mean uniformly\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # initial sigma\n        sigma = max(1e-12, self.sigma0_mult * avg_span)\n\n        # initialize low-rank orthonormal basis B (dim x r) and energies e\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()\n            e = np.ones(r)  # multiplicative energies (relative)\n        else:\n            B = np.zeros((self.dim, 0))\n            e = np.array([])\n\n        # per-coordinate residual noise scales\n        s = np.full(self.dim, 0.4)\n\n        # archive and evaluation bookkeeping\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # initial sampling to seed archive and best\n        seed_init = min(self.pop, max(4, int(self.budget // 200)))\n        for _ in range(seed_init):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        # ensure at least one eval\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # stagnation detection\n        stagn_limit = max(6, int(self.stagn_thresh_frac * self.budget))\n        stagn_counter = 0\n        gen = 0\n\n        # buffer used to compute surrogate (in subspace coords)\n        def fit_diag_quadratic(U, y):\n            # U: (k,r) projected coordinates, y: (k,) target values\n            # Fit model y ≈ c + g^T u + 0.5 * diag(h) * u^2 by least squares.\n            k, rloc = U.shape\n            # design matrix: [1, u1..ur, u1^2..ur^2]\n            X = np.ones((k, 1 + 2 * rloc))\n            X[:, 1:1 + rloc] = U\n            X[:, 1 + rloc:] = U ** 2\n            # regularize a bit\n            reg = 1e-8\n            try:\n                theta, *_ = np.linalg.lstsq(X, y, rcond=None)\n            except Exception:\n                # fallback\n                theta = np.zeros(1 + 2 * rloc)\n            c = float(theta[0])\n            g = theta[1:1 + rloc].astype(float)\n            hdiag = theta[1 + rloc:].astype(float)\n            # ensure Hessian diagonal not too small (regularize)\n            hdiag = np.sign(hdiag) * np.maximum(np.abs(hdiag), 1e-6)\n            return c, g, hdiag\n\n        while evals < self.budget:\n            gen += 1\n            # occasionally refresh subspace B via PCA on recent successful deltas\n            if (gen % self.pca_refresh == 0) and len(X_arch) >= max(3, r):\n                # use centered recent archive rows projected as deltas from mean\n                K = min(len(X_arch), self.surv_size)\n                Xr = np.asarray(X_arch[-K:])\n                Dmat = Xr - np.mean(Xr, axis=0, keepdims=True)\n                try:\n                    U_s, S_s, Vt = np.linalg.svd(Dmat, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        B_new = Vt[:r_eff].T\n                        # align sign to avoid flips\n                        for k2 in range(r_eff):\n                            if np.dot(B[:, k2], B_new[:, k2]) < 0:\n                                B_new[:, k2] *= -1.0\n                        # blend with old basis to avoid abrupt changes\n                        B = 0.8 * B + 0.2 * B_new\n                        # orthonormalize\n                        Q, _ = np.linalg.qr(B)\n                        B = Q[:, :r_eff]\n                        # shrink energies somewhat (conservative)\n                        if e.size > 0:\n                            e = 0.9 * e + 0.1 * (np.var(Dmat.dot(B), axis=0) + 1e-6)\n                            e = np.clip(e, self.min_energy, self.max_energy)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # For the current generation, create up to 'pop' proposals but ensure not to exceed budget\n            n_candidates = min(self.pop, max(1, self.budget - evals))\n            # choose strategy probabilities adaptively: more often use surrogate when archive is rich\n            use_surrogate_prob = 0.25 if len(X_arch) > max(20, r * 8) else 0.05\n            for _cand in range(n_candidates):\n                if evals >= self.budget:\n                    break\n\n                # decide strategy\n                coin = rng.rand()\n                candidate = None\n                cand_step = None\n                strategy = 'base'\n\n                # Levy-like long jump\n                if rng.rand() < self.levy_prob:\n                    candidate = rng.uniform(lb, ub, size=self.dim)\n                    strategy = 'levy'\n                # surrogate-based subspace minimizer\n                elif coin < use_surrogate_prob and r > 0 and len(X_arch) >= max(3, r + 2):\n                    # build surrogate in subspace using recent archive\n                    K = min(len(X_arch), self.surv_size)\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    # project delta from mean into subspace coords\n                    U = (Xr - m).dot(B)  # (K,r)\n                    # fit diagonal quadratic approx\n                    try:\n                        c_s, g_s, hdiag = fit_diag_quadratic(U, fr)\n                        # propose minimizer in subspace coordinates (element-wise)\n                        # avoid division by zero; hdiag positive/negative allowed -> step controlled\n                        u_star = -g_s / (hdiag + 1e-8)\n                        # scale down if huge\n                        u_norm = np.linalg.norm(u_star)\n                        max_u = 4.0 * sigma  # in B-coordinates scale ~ sigma\n                        if u_norm > max_u:\n                            u_star = u_star * (max_u / (u_norm + 1e-12))\n                        # create candidate\n                        candidate = m + B.dot(u_star)\n                        cand_step = B.dot(u_star)\n                        strategy = 'surrogate'\n                    except Exception:\n                        candidate = None\n\n                # subspace-guided stochastic probe (default)\n                if candidate is None:\n                    # pick scale from multiscale set\n                    scale = self.multiscale[rng.randint(len(self.multiscale))]\n                    # sample in r-dimensional energy-weighted space then map back\n                    if r > 0:\n                        # sample coefficients z_r ~ N(0,1) and scale by sqrt(e) multiplicatively\n                        z_r = rng.randn(r) * np.sqrt(np.maximum(e, 1e-12))\n                        low = B.dot(z_r)\n                    else:\n                        low = np.zeros(self.dim)\n                    # coordinate residual noise\n                    diag_noise = rng.randn(self.dim) * s\n                    step = scale * sigma * (low + diag_noise)\n                    # occasional reflection / small orthonormal rotation on step to diversify\n                    if rng.rand() < 0.08 and r > 0:\n                        # rotate coefficients a little\n                        R = rng.randn(r, r) * 0.03\n                        try:\n                            Qr, _ = np.linalg.qr(np.eye(r) + R)\n                            step = scale * sigma * (B.dot(Qr.dot(z_r)) + diag_noise)\n                        except Exception:\n                            pass\n                    candidate = m + step\n                    cand_step = step\n                    strategy = 'subspace'\n\n                # boundary clip and evaluate\n                candidate = np.minimum(np.maximum(candidate, lb), ub)\n                f_c = float(func(candidate))\n                evals += 1\n\n                # archive bookkeeping FIFO\n                X_arch.append(candidate.copy())\n                f_arch.append(f_c)\n                if len(X_arch) > self.archive_size:\n                    del X_arch[0]\n                    del f_arch[0]\n\n                improved = False\n                if f_c < f_best:\n                    f_best = f_c\n                    x_best = candidate.copy()\n                    improved = True\n                    stagn_counter = 0\n                else:\n                    stagn_counter += 1\n\n                # reward and energy update (multiplicative): compute projected step in B coordinates\n                if r > 0 and cand_step is not None:\n                    u_proj = B.T.dot(cand_step)  # r-vector\n                    u_norm = np.linalg.norm(u_proj) + 1e-12\n                    # reward: improvement per unit projected length (clamped)\n                    reward = max(0.0, (0.0 if len(f_arch) == 0 else (np.min(f_arch) - f_c))) / (sigma * u_norm + 1e-12)\n                    # if candidate improved generally (global improvement) boost reward\n                    if improved:\n                        reward += 0.2\n                    # multiplicative update using exponentiated gradient-like step\n                    # small smoothing to keep energies stable\n                    if np.any(u_proj != 0):\n                        # contribution per direction proportional to abs projection\n                        contrib = np.abs(u_proj) / (np.sum(np.abs(u_proj)) + 1e-12)\n                        # update energies: e <- e * exp(eta * contrib * reward)\n                        e = e * np.exp(self.energy_lr * reward * contrib)\n                        # re-normalize to keep scale moderate (geometric mean preserved)\n                        e = np.clip(e, self.min_energy, self.max_energy)\n\n                # update per-coordinate residual s via EMA of normalized absolute step components\n                if cand_step is not None:\n                    abs_step_norm = np.abs(cand_step) / (sigma + 1e-12)\n                    med_est = np.median(abs_step_norm)\n                    # scale component-wise by relative magnitude\n                    s = (1.0 - self.s_lr) * s + self.s_lr * np.clip(abs_step_norm, self.min_s, self.max_s)\n\n                # if candidate accepted as new mean (improve best) then nudge mean toward it,\n                # else sometimes probabilistically accept uphill with small probability\n                accept = False\n                if f_c <= f_best + 1e-12 and improved:\n                    accept = True\n                else:\n                    # probabilistic uphill acceptance with temperature proportional to sigma*avg_span\n                    T = max(1e-12, 0.6 * sigma * avg_span)\n                    if rng.rand() < np.exp(-max(0.0, f_c - f_best) / (T + 1e-12)):\n                        accept = True\n\n                if accept:\n                    # step to new mean with damped update: learning rate depends on strategy\n                    if strategy == 'surrogate':\n                        lr = 0.6\n                    elif strategy == 'levy':\n                        lr = 0.35\n                    elif strategy == 'subspace':\n                        lr = 0.28\n                    else:\n                        lr = 0.2\n                    delta = candidate - m\n                    # trust region clipping relative to sigma\n                    trust = 6.0 * sigma * np.sqrt(self.dim)\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                    # on acceptance, shrink sigma slightly (local refinement), else grow slowly\n                    sigma = max(1e-12, sigma * (0.92 if improved else 0.98))\n                else:\n                    # exploratory jitter if not accepted\n                    m = np.minimum(np.maximum(m + 0.03 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma = sigma * 1.01  # encourage exploration lightly\n\n                # small occasional rotation of B to maintain variety\n                if r > 0 and rng.rand() < 0.03:\n                    Qr = rng.randn(r, r) * 0.08\n                    try:\n                        Qr_orth, _ = np.linalg.qr(np.eye(r) + Qr)\n                        B = B.dot(Qr_orth)\n                        # re-orthonormalize\n                        Q2, _ = np.linalg.qr(B)\n                        B = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # opportunistic restart on stagnation\n                if stagn_counter >= stagn_limit and evals < self.budget:\n                    stagn_counter = 0\n                    # jitter mean around best known\n                    jitter = max(0.05 * avg_span, 0.6 * sigma)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma = max(sigma * self.restart_infl, 0.25 * avg_span)\n                    # reset energies and residuals partly\n                    if r > 0:\n                        e = np.ones(r) * np.median(e) if e.size else np.ones(r)\n                        # re-randomize B\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :r]\n                    s = np.full(self.dim, 0.4)\n                    # do a few reseed evaluations around best to refresh archive\n                    for _ in range(min(6, self.budget - evals)):\n                        x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                        f = float(func(x))\n                        evals += 1\n                        X_arch.append(x.copy())\n                        f_arch.append(f)\n                        if f < f_best:\n                            f_best = f\n                            x_best = x.copy()\n                        if len(X_arch) > self.archive_size:\n                            del X_arch[0]; del f_arch[0]\n                        if evals >= self.budget:\n                            break\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MAGES scored 0.175 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a502e03b-784f-4102-999b-4f644b5096d8", "operator": null, "metadata": {"aucs": [0.07653691398385609, 0.17068627707722872, 0.24010464023137135, 0.16481236028020985, 0.18034812994498073, 0.2094257713680594, 0.1883181756794331, 0.19114492011321782, 0.18725267209937857, 0.13691985676936125]}, "task_prompt": ""}
{"id": "c7c583e6-08e7-4974-a374-f9cd9282e355", "fitness": 0.1807910603010748, "name": "ARCBP", "description": "ARCBP drives search with mirrored (antithetic) paired probes and occasional single exploratory samples, using weighted recombination of the top subset (softmax-weighted) plus momentum and a trust-radius clip to update the mean rather than relying on a single winner, while keeping a FIFO archive and larger initial population for robust seeding.  \nA learnable low-rank orthonormal subspace D (dim × r) with direction energies p captures correlated moves (rank chosen as a sizable fraction of dim), p is reallocated by a temperature-decaying softmax on squared directional gains, per-coordinate residual scales s are adapted from the mean absolute normalized successful steps (with periodic PCA refresh and occasional random rotations), and many constants (larger arch_size/pop_base, smaller initial sigma, clipped energy ranges) bias conservative but informed searches.  \nGlobal scale is adapted additively in log-space from an EMA of success probability (higher succ_target and faster smoothing), heavy‑tailed Cauchy-like long jumps are used for escape, and stagnation triggers opportunistic restarts centered on the best solution with subspace reinitialization and local reseeding.", "code": "import numpy as np\n\nclass ARCBP:\n    \"\"\"\n    ARCBP: Adaptive Rotational Covariance with Bidirectional Probing\n\n    Main ideas (differences vs typical mirror-based sampler):\n    - Use mirrored (antithetic) paired probes to get directional signals, but update the mean\n      by weighted recombination of the top subset of evaluated candidates in each batch\n      (rather than a single winner).\n    - Maintain a low-rank orthonormal subspace D (dim x r) with direction energies p and\n      per-coordinate residual scales s. Energies are reallocated by a temperature-controlled\n      softmax of squared directional gains; the temperature decays over generations.\n    - Adapt global scale via an EMA on success probability but using a log-space adjustment\n      (different rate and baseline than the original algorithm).\n    - Per-coordinate residuals s are updated using mean absolute normalized steps (not median).\n    - Occasional heavy-tailed (Cauchy-like) long jumps to escape local traps.\n    - PCA refresh period, population sizing, stagnation detection and restarts with different\n      constants and safeguards.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 rank=None, pop_base=None, arch_size=None, pca_period=7):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n\n        # Structure: choose a slightly larger rank fraction than the provided algorithm\n        self.rank = int(rank) if rank is not None else max(1, min(self.dim, max(1, self.dim // 3)))\n        # Larger base population to leverage recombination\n        self.pop_base = pop_base if pop_base is not None else max(12, int(2 * self.dim))\n        # bigger archive\n        self.arch_size = arch_size if arch_size is not None else max(10 * self.dim, 50)\n        self.pca_period = int(pca_period)\n\n        # Adaptation hyperparameters (different from original)\n        self.succ_target = 0.30          # target success rate\n        self.smooth_p = 0.7              # EMA smoothing for success (faster adaptation)\n        self.sigma_adapt_gain = 0.18     # log-sigma adjustment gain\n        self.sigma_min = 1e-8\n        self.sigma_max_mult = 4.0\n        self.lr_mean_base = 0.45         # stronger recombination step size\n        self.momentum_beta = 0.5         # weaker momentum retention\n\n        # Subspace & numerical safeguards\n        self.diag_reg = 1e-8\n        self.min_dir_energy = 1e-5\n        self.max_dir_energy = 20.0\n\n        # Stagnation and restart (different thresholds)\n        self.stagn_thresh_frac = 0.02\n        self.restart_infl = 2.0\n\n        # Exploration: larger chance for heavy-tailed jumps\n        self.long_jump_prob = 0.08\n\n        # internal placeholders to expose after run\n        self.f_opt = None\n        self.x_opt = None\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize mean uniformly\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # initial sigma (different baseline)\n        sigma = max(1e-12, 0.12 * avg_span)   # slightly smaller initial global scale\n        log_sigma = np.log(max(sigma, 1e-12))\n\n        # low-rank orthonormal subspace D and direction energies p\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            D = Q[:, :r].copy()\n            p = np.ones(r) * 1.0\n        else:\n            D = np.zeros((self.dim, 0))\n            p = np.array([])\n\n        # per-coordinate residual scales\n        s = np.full(self.dim, 0.30)\n\n        # momentum for mean updates\n        mom = np.zeros(self.dim)\n\n        # archive and buffers\n        X_arch = []\n        f_arch = []\n        success_steps = []\n\n        # initialization evaluations (small seeding)\n        evals = 0\n        init_pop = min(self.pop_base, max(6, int(self.budget // 120)))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # adaptation trackers\n        p_succ = 0.15\n        stagn_limit = max(5, int(self.stagn_thresh_frac * self.budget))\n        stagn_counter = 0\n\n        gen = 0\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            # make lam even so mirrored pairing is consistent\n            if lam % 2 == 1 and lam > 1:\n                lam -= 1\n            if lam <= 0:\n                break\n\n            # storage for this generation\n            cand_X = []\n            cand_f = []\n            cand_types = []\n            gen_success = False\n            directional_gains = np.zeros(r) if r > 0 else np.array([])\n\n            # generate lam samples as mirrored pairs (lam must be even)\n            pairs = lam // 2\n            for _ in range(pairs):\n                if evals + 2 > self.budget:\n                    break\n\n                # draw low-rank coefficients with energies p (use sqrt of energies)\n                if r > 0:\n                    z_r = rng.randn(r) * np.sqrt(np.maximum(p, self.diag_reg))\n                    low = D.dot(z_r)\n                else:\n                    low = np.zeros(self.dim)\n\n                # diag residual\n                z_d = rng.randn(self.dim) * s\n                step = sigma * (low + z_d)\n\n                # mirrored probes\n                x_plus = m + step\n                x_minus = m - step\n\n                # occasional heavy-tailed long jump (Cauchy-like scaled)\n                if rng.rand() < self.long_jump_prob:\n                    # Cauchy: tan(pi*(u-0.5)); scaled\n                    u1 = rng.rand(self.dim)\n                    cauchy = np.tan(np.pi * (u1 - 0.5))\n                    jump = 0.2 * avg_span * cauchy\n                    x_plus = m + jump\n                # clip\n                x_plus = np.minimum(np.maximum(x_plus, lb), ub)\n                x_minus = np.minimum(np.maximum(x_minus, lb), ub)\n\n                # evaluate\n                f_plus = float(func(x_plus)); evals += 1\n                f_minus = float(func(x_minus)); evals += 1\n\n                # archive FIFO\n                X_arch.append(x_plus.copy()); f_arch.append(f_plus)\n                X_arch.append(x_minus.copy()); f_arch.append(f_minus)\n                while len(X_arch) > self.arch_size:\n                    del X_arch[0]; del f_arch[0]\n\n                cand_X.extend([x_plus.copy(), x_minus.copy()])\n                cand_f.extend([f_plus, f_minus])\n                cand_types.extend(['mirror', 'mirror'])\n\n                # update best and stagnation\n                improved = False\n                if f_plus < f_best:\n                    f_best = f_plus; x_best = x_plus.copy(); improved = True; stagn_counter = 0\n                if f_minus < f_best:\n                    f_best = f_minus; x_best = x_minus.copy(); improved = True; stagn_counter = 0\n                if not improved:\n                    stagn_counter += 1\n\n                # directional gain: square of positive delta weighted by projection squared\n                delt = f_minus - f_plus  # positive -> +step better\n                step_norm = np.linalg.norm(step) + 1e-12\n                step_unit = step / step_norm\n                if r > 0:\n                    proj = D.T.dot(step_unit)\n                    reward = np.maximum(0.0, delt) * (proj ** 2)\n                    directional_gains += reward\n\n                # record normalized successful steps (by sigma) when either member improves or delt>0\n                if (delt > 0) or (f_plus <= f_best + 1e-12) or (f_minus <= f_best + 1e-12):\n                    success_steps.append((step / (sigma + 1e-12)).copy())\n                    if len(success_steps) > max(40, self.arch_size // 2):\n                        del success_steps[0]\n\n                gen_success = gen_success or improved or (delt > 0)\n\n            # if an odd evaluation slot remains, take one exploratory sample (not mirrored)\n            if evals < self.budget and (self.pop_base % 2 == 1) and (remaining - lam) > 0:\n                if evals + 1 <= self.budget:\n                    if r > 0:\n                        zr = rng.randn(r) * np.sqrt(np.maximum(p, self.diag_reg))\n                        low = D.dot(zr)\n                    else:\n                        low = np.zeros(self.dim)\n                    zd = rng.randn(self.dim) * s\n                    step = sigma * (low + zd)\n                    x = m + step\n                    if rng.rand() < self.long_jump_prob:\n                        u1 = rng.rand(self.dim)\n                        cauchy = np.tan(np.pi * (u1 - 0.5))\n                        x = m + 0.2 * avg_span * cauchy\n                    x = np.minimum(np.maximum(x, lb), ub)\n                    f_x = float(func(x)); evals += 1\n                    X_arch.append(x.copy()); f_arch.append(f_x)\n                    while len(X_arch) > self.arch_size:\n                        del X_arch[0]; del f_arch[0]\n                    cand_X.append(x.copy()); cand_f.append(f_x); cand_types.append('single')\n                    if f_x < f_best:\n                        f_best = f_x; x_best = x.copy(); gen_success = True; stagn_counter = 0\n                    else:\n                        stagn_counter += 1\n                    if f_x <= f_best + 1e-12:\n                        success_steps.append((step / (sigma + 1e-12)).copy())\n                        if len(success_steps) > max(40, self.arch_size // 2):\n                            del success_steps[0]\n\n            # if no candidates (possible if budget exhausted), break\n            if len(cand_f) == 0:\n                break\n\n            # recombination: pick top-mu candidates (weighted by softmax on negative objective)\n            f_array = np.asarray(cand_f)\n            fmin_local = f_array.min()\n            fstd = float(np.std(f_array) + 1e-12)\n            scores = np.exp(-(f_array - fmin_local) / fstd)\n            probs = scores / (np.sum(scores) + 1e-12)\n\n            # choose a subset size mu (proportional to batch)\n            mu = max(1, int(max(1, len(cand_f) // 4)))\n            # sample mu indices without replacement proportional to probs\n            try:\n                chosen = rng.choice(len(cand_f), size=mu, replace=False, p=probs)\n            except Exception:\n                # fallback: take best mu by score\n                chosen = np.argsort(-scores)[:mu]\n\n            chosen_X = np.asarray([cand_X[i] for i in chosen])\n            chosen_f = np.asarray([cand_f[i] for i in chosen])\n            # weights by softmax of negative function values (sharper)\n            w = np.exp(-(chosen_f - chosen_f.min()) / (np.std(chosen_f) + 1e-12))\n            w = w / (np.sum(w) + 1e-12)\n\n            # compute weighted displacement (recombination step)\n            recomb = np.dot(w, (chosen_X - m))  # weighted average delta\n\n            # clip trust radius differently: smaller radius factor to be more conservative\n            trust_radius = max(1e-12, 3.0 * sigma * np.sqrt(self.dim))\n            recomb_norm = np.linalg.norm(recomb)\n            if recomb_norm > trust_radius:\n                recomb = recomb * (trust_radius / (recomb_norm + 1e-12))\n\n            # incorporate momentum and a generation-dependent learning rate (decays slowly)\n            gen_lr = self.lr_mean_base * (1.0 / (1.0 + gen * 0.003))\n            mom = self.momentum_beta * mom + (1.0 - self.momentum_beta) * recomb\n            m = m + gen_lr * mom\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # success update\n            p_succ = self.smooth_p * p_succ + (1.0 - self.smooth_p) * float(bool(gen_success))\n\n            # update sigma in log-space (different equation: additive on log sigma)\n            log_sigma += self.sigma_adapt_gain * (p_succ - self.succ_target)\n            sigma = float(np.exp(log_sigma))\n            sigma = float(np.clip(sigma, self.sigma_min, self.sigma_max_mult * avg_span))\n            log_sigma = np.log(max(sigma, 1e-12))\n\n            # adapt per-coordinate residuals s using mean absolute normalized steps (not median)\n            if len(success_steps) > 0:\n                B = np.asarray(success_steps)  # (k, dim)\n                mad = np.mean(np.abs(B), axis=0)\n                # mild smoothing and clipping\n                s = 0.75 * s + 0.25 * np.clip(mad, 1e-5, 4.0)\n\n            # redistribute energy in D via temperature-controlled softmax of squared gains\n            if r > 0 and np.sum(directional_gains) > 1e-12:\n                g = directional_gains.copy()\n                # temperature decays as gen increases\n                tau = max(0.08, 1.5 / (1.0 + gen / 40.0))\n                # stabilize\n                g = g - g.max()\n                expo = np.exp(g / (tau + 1e-12))\n                p_new = expo / (np.sum(expo) + 1e-12)\n                # scale to preserve total variance roughly\n                total_old = np.sum(p) + 1e-12\n                p_target = p_new * total_old\n                # smooth update with stronger inertia\n                p = 0.6 * p + 0.4 * p_target\n                p = np.clip(p, self.min_dir_energy, self.max_dir_energy)\n\n            # periodic PCA refresh with different smoothing constants\n            if (gen % self.pca_period == 0) and len(success_steps) >= max(3, r):\n                B = np.asarray(success_steps)\n                Bc = B - np.mean(B, axis=0, keepdims=True)\n                try:\n                    U_s, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        D_new = Vt[:r_eff].T  # dim x r_eff\n                        eigs = (S_s[:r_eff] ** 2) / max(1, Bc.shape[0] - 1)\n                        # align signs so basis doesn't flip\n                        if D.shape[1] == r_eff:\n                            for k in range(r_eff):\n                                if np.dot(D[:, k], D_new[:, k]) < 0:\n                                    D_new[:, k] *= -1.0\n                            D = 0.7 * D + 0.3 * D_new\n                            # combine energies softly, normalize to previous total\n                            total_old = np.sum(p) + 1e-12\n                            p = 0.6 * p + 0.4 * (eigs / (np.mean(eigs) + 1e-12) * total_old)\n                        else:\n                            D = D_new\n                            total_old = np.sum(p) + 1e-12\n                            p = (eigs / (np.mean(eigs) + 1e-12)) * total_old\n                        p = np.clip(p, self.min_dir_energy, self.max_dir_energy)\n                        # slightly reduce residual variance along explained dimensions\n                        s = np.clip(0.92 * s, 1e-6, 4.0)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # occasional random rotation with higher chance\n            if r > 0 and rng.rand() < 0.12:\n                Qr = rng.randn(r, r)\n                try:\n                    Qr_orth, _ = np.linalg.qr(Qr)\n                    D = D.dot(Qr_orth)\n                except Exception:\n                    pass\n\n            # opportunistic restart on stagnation\n            if stagn_counter >= stagn_limit and evals < self.budget:\n                stagn_counter = 0\n                # center near best but with a larger jitter\n                jitter = max(0.06 * avg_span, 0.8 * sigma)\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                sigma = max(sigma * self.restart_infl, 0.2 * avg_span)\n                log_sigma = np.log(max(sigma, 1e-12))\n                # reinitialize subspace\n                if r > 0:\n                    A = rng.randn(self.dim, r)\n                    Q, _ = np.linalg.qr(A)\n                    D = Q[:, :r]\n                    p = np.full(r, np.mean(p) if p.size else 1.0)\n                s = np.full(self.dim, 0.30)\n                success_steps = []\n                mom = np.zeros(self.dim)\n                # do a few local reseed evaluations around best to refresh archive\n                for _ in range(min(6, self.budget - evals)):\n                    x = x_best + 0.06 * avg_span * rng.randn(self.dim)\n                    x = np.minimum(np.maximum(x, lb), ub)\n                    f = float(func(x)); evals += 1\n                    X_arch.append(x.copy()); f_arch.append(f)\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n                    if evals >= self.budget:\n                        break\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ARCBP scored 0.181 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a502e03b-784f-4102-999b-4f644b5096d8", "operator": null, "metadata": {"aucs": [0.08897513188625283, 0.14719078570054334, 0.23017043613150356, 0.23404120135791973, 0.18749021586457704, 0.22008581921850312, 0.19974790226413375, 0.17964108256636047, 0.18522873925211825, 0.13533928876883616]}, "task_prompt": ""}
{"id": "b719a32a-cad3-411a-bdd6-7fce07f91ee5", "fitness": 0.16101144712953175, "name": "BLiSE", "description": "BLiSE maintains a low-rank orthonormal subspace U (default rank ≈ dim/3) with per-axis energies w and a per-coordinate residual scale s (initialized ~0.36) to split search into structured directional moves and isotropic noise; it samples mirrored antithetic pairs using heavy-tailed (Cauchy, truncated at 8) coefficients and occasional global random long jumps (probability ~0.035) to enable both local refinement and rare long leaps. A lightweight multi-armed bandit (one arm per subspace axis plus a residual arm) picks which direction to probe using an UCB-like score (mean reward + 0.7·bonus) and softmax selection, while positive directional outcomes are stored in a success buffer (size ≥80) and periodically analyzed by PCA/SVD every pca_period (12) to refresh U and reweight w. Global step-size sigma is multiplicatively adapted by an EMA success rate (smooth_p=0.88) toward succ_target=0.27 with rate 0.28, the mean is updated with momentum (beta=0.72) and trust-radius clipping, and the algorithm includes archive seeding, per-axis energy adaptation, occasional subspace rotations, and stagnation-triggered restarts (stagn_frac=0.04, restart_infl=1.8) to retain robustness across BBOB problems.", "code": "import numpy as np\n\nclass BLiSE:\n    \"\"\"\n    Bandit-guided Lévy Subspace Evolution (BLiSE)\n\n    Main ideas:\n    - Maintain a low-rank subspace U (dim x r) with axis energies `w`.\n    - Use mirrored (antithetic) paired sampling along a chosen axis (or residual)\n      with heavy-tailed coefficients (Cauchy/Truncated) to allow occasional long leaps.\n    - A lightweight multi-armed bandit (counts + cum. reward + UCB-style bonus) selects\n      which axis to sample next, concentrating effort on productive directions.\n    - Use mirrored pair outcome (f_minus - f_plus) as directional reward and also\n      collect successful normalized steps into a buffer. Periodic SVD/PCA on buffer\n      reconstitutes U and updates energies `w`.\n    - Global step-size sigma adapts multiplicatively from an EMA success ratio;\n      mean updates use momentum and trust-radius clipping; occasional restarts if stagnation.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 rank=None, pop=None, archive_size=None, pca_period=12):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n\n        # algorithmic sizes\n        self.rank = int(rank) if rank is not None else max(1, min(self.dim, max(1, self.dim // 3)))\n        self.pop = int(pop) if pop is not None else max(10, int(6 + 0.9 * np.log(max(2, self.dim))))\n        self.arch_size = int(archive_size) if archive_size is not None else max(6 * self.dim, 50)\n        self.pca_period = int(pca_period)\n\n        # adaptation hyperparameters\n        self.sigma_init_frac = 0.18\n        self.succ_target = 0.27\n        self.smooth_p = 0.88\n        self.sigma_adapt_rate = 0.28\n        self.sigma_min = 1e-8\n        self.sigma_max_mult = 4.0\n        self.momentum_beta = 0.72\n        self.mean_lr = 0.32\n\n        # bandit & sampling\n        self.bandit_epsilon = 1e-6\n        self.lévy_trunc = 8.0  # truncate heavy tail to avoid infinite steps\n        self.long_jump_prob = 0.035\n\n        # PCA / buffer\n        self.success_buffer_size = max(80, self.arch_size // 2)\n        self.pca_min_samples = max(4, self.rank)\n\n        # stagnation / restart\n        self.stagn_frac = 0.04\n        self.restart_infl = 1.8\n\n        # regularization\n        self.diag_reg = 1e-8\n        self.min_w = 1e-5\n        self.max_w = 50.0\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds (BBOB defaults are [-5,5], but allow func.bounds)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize mean and global sigma\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(self.sigma_min, self.sigma_init_frac * avg_span)\n\n        # low-rank orthonormal subspace U and axis energies w\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :r].copy()\n            w = np.ones(r)  # relative energies (will be normalized/reshaped)\n        else:\n            U = np.zeros((self.dim, 0))\n            w = np.array([])\n\n        # residual per-coordinate scales (orthogonal to subspace)\n        s = np.full(self.dim, 0.36)\n\n        # bandit arms: one per subspace axis plus one residual arm\n        arms = r + 1\n        counts = np.zeros(arms, dtype=float)\n        cum_rewards = np.zeros(arms, dtype=float)\n\n        # momentum for mean updates\n        mom = np.zeros(self.dim)\n\n        # archives and buffers\n        X_arch = []\n        f_arch = []\n        success_steps = []  # normalized steps (step/sigma) that produced positive directional signal\n\n        # initial seeding evaluations\n        evals = 0\n        init_pop = min(self.pop, max(6, int(self.budget // 100)))\n        for _ in range(init_pop):\n            if evals >= self.budget: break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # adaptive trackers\n        p_succ = 0.2\n        stagn_limit = max(6, int(self.stagn_frac * self.budget))\n        stagn_counter = 0\n\n        gen = 0\n        # main loop: draw paired samples until budget exhausted\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            # decide how many mirrored pairs to attempt this generation\n            lam = min(self.pop, remaining)\n            # ensure we use mirrored pairs where possible (each pair costs 2)\n            if lam % 2 == 1 and lam > 1:\n                lam -= 1\n            pairs = max(1, lam // 2)\n\n            gen_success = False\n            any_improved = False\n\n            for _pair in range(pairs):\n                if evals + 2 > self.budget:\n                    break\n\n                # pick an arm using a soft UCB / reward-proportional selection\n                total_counts = np.sum(counts) + 1.0\n                # compute UCB style score: mean reward + bonus\n                mean_reward = (cum_rewards / (counts + self.bandit_epsilon))\n                bonus = np.sqrt(2.0 * np.log(total_counts + 1.0) / (counts + self.bandit_epsilon))\n                # residual arm index is r (last arm)\n                arm_scores = mean_reward + 0.7 * bonus\n                # small randomness to encourage exploration\n                probs_core = np.exp((arm_scores - np.max(arm_scores)) / (np.std(arm_scores) + 1e-12))\n                probs = probs_core / (np.sum(probs_core) + 1e-12)\n                arm = int(rng.choice(arms, p=probs))\n\n                # sample coefficient from truncated Cauchy (heavy-tailed)\n                c = rng.standard_cauchy()\n                # truncate extreme tails to maintain numeric stability\n                c = float(np.clip(c, -self.lévy_trunc, self.lévy_trunc))\n\n                # construct directional step: along chosen axis or pure residual\n                if arm < r:\n                    axis = U[:, arm]\n                    # axis amplitude scaled by axis energy (w[arm]) and heavy tail c\n                    amp = c * np.sqrt(max(w[arm], self.min_w))\n                    low = axis * amp\n                else:\n                    # residual focused (no subspace direction)\n                    low = np.zeros(self.dim)\n\n                # add coordinate-wise isotropic residual\n                zd = rng.randn(self.dim) * s\n                step = sigma * (low + zd)\n\n                # mirrored pair\n                if rng.rand() < self.long_jump_prob:\n                    x_plus = rng.uniform(lb, ub, size=self.dim)\n                    x_minus = rng.uniform(lb, ub, size=self.dim)\n                else:\n                    x_plus = m + step\n                    x_minus = m - step\n\n                # clip to bounds\n                x_plus = np.minimum(np.maximum(x_plus, lb), ub)\n                x_minus = np.minimum(np.maximum(x_minus, lb), ub)\n\n                # evaluate both\n                f_plus = float(func(x_plus))\n                f_minus = float(func(x_minus))\n                evals += 2\n\n                # archive\n                X_arch.append(x_plus.copy()); f_arch.append(f_plus)\n                X_arch.append(x_minus.copy()); f_arch.append(f_minus)\n                while len(X_arch) > self.arch_size:\n                    del X_arch[0]; del f_arch[0]\n\n                # check improvements\n                improved_local = False\n                if f_plus < f_best:\n                    f_best = f_plus; x_best = x_plus.copy(); improved_local = True; stagn_counter = 0\n                if f_minus < f_best:\n                    f_best = f_minus; x_best = x_minus.copy(); improved_local = True; stagn_counter = 0\n                if not improved_local:\n                    stagn_counter += 1\n\n                # directional reward (positive when +step outperforms -step)\n                # positive reward means the \"+step\" direction looks promising\n                reward = max(0.0, f_minus - f_plus)\n                # attribute reward to the arm\n                counts[arm] += 1.0\n                cum_rewards[arm] += reward\n\n                # accumulate normalized step into success buffer if sign-positive or any improvement\n                step_norm = np.linalg.norm(step) + 1e-12\n                step_unit = step / step_norm\n                if (reward > 0.0) or improved_local:\n                    success_steps.append((step / (sigma + 1e-12)).copy())\n                    if len(success_steps) > self.success_buffer_size:\n                        success_steps.pop(0)\n\n                gen_success = gen_success or (reward > 0.0 or improved_local)\n                any_improved = any_improved or improved_local\n\n                # local adaptation of axis energy w based on reward (small multiplicative increase)\n                if arm < r:\n                    # a multiplicative reward-based tilt with damping\n                    delta_w = 0.12 * (reward / (1.0 + np.abs(f_best)))\n                    w[arm] = np.clip(w[arm] * (1.0 + delta_w), self.min_w, self.max_w)\n\n                # opportunistic small mean move if mirrored pair gives strong winner\n                # pick the better of the pair\n                if f_plus < f_minus:\n                    winner_x = x_plus; winner_f = f_plus; win_dir = +1\n                else:\n                    winner_x = x_minus; winner_f = f_minus; win_dir = -1\n\n                # accept if better than current mean or probabilistic SA acceptance scaled by sigma*avg_span\n                accept = False\n                # estimate \"current\" mean objective by evaluating nearest archived point (cheap): use f_best as proxy\n                # Accept if winner improves global best or with annealed probability\n                if winner_f <= f_best:\n                    accept = True\n                else:\n                    temperature = max(1e-12, sigma * avg_span * 0.8)\n                    if rng.rand() < np.exp(-max(0.0, winner_f - f_best) / (temperature + 1e-12)):\n                        accept = True\n\n                if accept:\n                    # compute delta and apply momentum + trust clipping\n                    delta = winner_x - m\n                    trust_radius = max(1e-12, 3.5 * sigma * np.sqrt(self.dim))\n                    dnorm = np.linalg.norm(delta)\n                    if dnorm > trust_radius:\n                        delta = delta * (trust_radius / (dnorm + 1e-12))\n                    mom = self.momentum_beta * mom + (1.0 - self.momentum_beta) * delta\n                    m = m + self.mean_lr * mom\n                    # keep mean in bounds\n                    m = np.minimum(np.maximum(m, lb), ub)\n                else:\n                    # small jitter to mean to encourage exploration\n                    jitter = 0.045 * avg_span\n                    m = m + jitter * rng.randn(self.dim)\n                    m = np.minimum(np.maximum(m, lb), ub)\n                    mom = mom * 0.85  # damp momentum\n\n            # update generation success EMA and adapt sigma\n            gen_success_flag = bool(gen_success)\n            p_succ = self.smooth_p * p_succ + (1.0 - self.smooth_p) * float(gen_success_flag)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = float(np.clip(sigma, self.sigma_min, self.sigma_max_mult * avg_span))\n\n            # adapt per-coordinate residuals s based on median absolute normalized steps in buffer\n            if len(success_steps) > 0:\n                B = np.asarray(success_steps)  # k x dim\n                med = np.median(np.abs(B), axis=0)\n                s = 0.78 * s + 0.22 * np.clip(med, 1e-5, 4.0)\n\n            # periodic PCA / SVD to refresh U and energies w using top-weighted recent steps\n            if (gen % self.pca_period == 0) and (len(success_steps) >= self.pca_min_samples):\n                B = np.asarray(success_steps)\n                # weight newer steps slightly more\n                k = B.shape[0]\n                weights = np.linspace(1.0, 1.0 + 0.6, k)\n                W = (weights / weights.sum())[:, None]\n                Bc = B - np.sum(W * B, axis=0, keepdims=True)\n                try:\n                    U_s, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        U_new = Vt[:r_eff].T  # dim x r_eff\n                        # form pseudo-variances from singular values (energy)\n                        eigs = (S_s[:r_eff] ** 2) / max(1, Bc.shape[0] - 1)\n                        # blend with existing U/w\n                        if U.shape[1] == r_eff:\n                            # align signs\n                            for j in range(r_eff):\n                                if np.dot(U[:, j], U_new[:, j]) < 0:\n                                    U_new[:, j] *= -1.0\n                            U = 0.65 * U + 0.35 * U_new\n                            w = 0.72 * w + 0.28 * (eigs / (np.mean(eigs) + 1e-12))\n                        else:\n                            U = U_new\n                            w = eigs / (np.mean(eigs) + 1e-12)\n                        w = np.clip(w, self.min_w, self.max_w)\n                        # attenuate residual variances a bit\n                        s = np.clip(0.92 * s, 1e-6, 4.0)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # small random orthonormal rotation within the subspace occasionally\n            if r > 0 and rng.rand() < 0.055:\n                Qr = rng.randn(r, r)\n                try:\n                    Qr_orth, _ = np.linalg.qr(Qr)\n                    U = U.dot(Qr_orth)\n                except Exception:\n                    pass\n\n            # stagnation-triggered restart\n            if stagn_counter >= stagn_limit and evals < self.budget:\n                stagn_counter = 0\n                # center around best with jitter, inflate sigma\n                jitter = max(0.05 * avg_span, 0.8 * sigma)\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                sigma = max(sigma * self.restart_infl, 0.3 * avg_span)\n                # reinitialize subspace moderately\n                if r > 0:\n                    A = rng.randn(self.dim, r)\n                    Q, _ = np.linalg.qr(A)\n                    U = Q[:, :r]\n                    # reset energies to mean of previous w if available\n                    w = np.full(r, np.mean(w) if w.size else 1.0)\n                s = np.full(self.dim, 0.36)\n                success_steps = []\n                mom = np.zeros(self.dim)\n                # do a few local reseed evaluations near global best\n                for _ in range(min(6, self.budget - evals)):\n                    x = x_best + 0.06 * avg_span * rng.randn(self.dim)\n                    x = np.minimum(np.maximum(x, lb), ub)\n                    f = float(func(x))\n                    evals += 1\n                    X_arch.append(x.copy()); f_arch.append(f)\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n                    if evals >= self.budget:\n                        break\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm BLiSE scored 0.161 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a502e03b-784f-4102-999b-4f644b5096d8", "operator": null, "metadata": {"aucs": [0.06552994237490484, 0.14326233652093434, 0.22502201880724781, 0.14585629955848112, 0.17026953996766603, 0.1934156193730181, 0.19215572371897227, 0.18126049916228903, 0.16346941877897048, 0.12987307303283346]}, "task_prompt": ""}
{"id": "683b67a6-2ad4-483b-b800-496ce3d85c51", "fitness": 0.282102847955885, "name": "CALE", "description": "CALE keeps a mean vector and coordinate-wise scales (sigma_coord) and generates batches by mixing coordinate-wise Gaussian mutations, occasional heavy-tailed Cauchy (Lévy-like) jumps, archive-based differential recombination, and guided moves from a small learned low-rank direction pool U (r ≈ dim/8), always clipped to the box bounds.  \nIt adapts each coordinate multiplicatively (adapt_lr=0.40) using a reward signal proportional to absolute relative motion on successful candidates, and updates the mean via soft weighted recombination of the batch plus momentum (mom_beta=0.55) with a trust-radius to avoid overly large jumps.  \nA FIFO archive and recent-success buffer feed periodic PCA-like updates of the direction pool (dir_update_period=12, dir_smooth=0.25) and set per-direction amplitudes lam tied to sigma magnitudes so guided directions reflect empirical successful steps.  \nPractical safeguards include initial uniform seeding, conservative population sizing, an adaptive Lévy probability (init 0.07, clipped to [0.01,0.35]) that increases under stagnation, opportunistic restarts around the best solution with inflated scales (restart_infl=1.8) and local reseeding, and clipping of scales to prevent degeneration.", "code": "import numpy as np\n\nclass CALE:\n    \"\"\"\n    CALE (Coordinate-wise Adaptive Lévy Explorer)\n\n    Key ideas (concise):\n    - Maintain a mean `m` and coordinate-wise step scales `sigma_coord`.\n    - Generate candidates by mixing (a) Gaussian coordinate-wise mutations, (b) occasional heavy-tailed Lévy-like (Cauchy) jumps,\n      and (c) occasional guided directional moves sampled from a small direction pool inferred from recent successes.\n    - Adapt each coordinate scale multiplicatively according to per-coordinate success rates (reward coordinates that contributed\n      to good candidates). Maintain a small low-rank direction pool (U, lam) estimated from recent successful step vectors.\n    - Update the mean by recombining top-performing candidates (soft weighted average) with momentum. Detect stagnation and restart\n      (near the best-so-far) with inflated scales and higher Lévy probability.\n    - Designed for box [-5,5] per problem spec (but respects func.bounds if present).\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop_size=None, init_scale_frac=0.20, target_success=0.25,\n                 adapt_lr=0.40, levy_prob=0.07, dir_pool_rank=None,\n                 dir_update_period=12, stagn_patience_frac=0.03):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n\n        # population size per generation (controls batch evaluations)\n        if pop_size is None:\n            self.pop_size = max(6, int(4 + 0.7 * np.log(max(2, dim))))\n        else:\n            self.pop_size = int(pop_size)\n\n        # initial coordinate-wise scale fraction of average span\n        self.init_scale_frac = float(init_scale_frac)\n\n        # multiplicative adaptation target / learning\n        self.target_success = float(target_success)\n        self.adapt_lr = float(adapt_lr)  # exponent multiplier coefficient\n\n        # heavy-tailed jump probability (Lévy-like via Cauchy)\n        self.levy_prob = float(levy_prob)\n        self.levy_prob_max = 0.35\n        self.levy_prob_min = 0.01\n\n        # low-rank direction pool\n        if dir_pool_rank is None:\n            # modest rank; different heuristic than original (smaller)\n            self.r = max(0, min(self.dim, max(1, self.dim // 8)))\n        else:\n            self.r = int(min(dir_pool_rank, self.dim))\n        self.dir_update_period = int(dir_update_period)\n        # smoothing for direction pool updates\n        self.dir_smooth = 0.25\n\n        # stagnation handling\n        self.stagn_patience = max(5, int(stagn_patience_frac * self.budget))\n        self.restart_infl = 1.8\n\n        # numerical/clipping bounds\n        self.sigma_min = 1e-8\n        self.sigma_max_mult = 4.0\n\n        # momentum for mean updates\n        self.mom_beta = 0.55\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # Extract bounds if available; otherwise default to [-5,5]\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize mean uniformly in bounds\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # initial coordinate-wise scales\n        sigma_coord = np.full(self.dim, max(self.sigma_min, self.init_scale_frac * avg_span))\n\n        # small low-rank direction pool (orthonormal basis U and per-direction scales lam)\n        if self.r > 0:\n            A = rng.randn(self.dim, self.r)\n            U, _ = np.linalg.qr(A)\n            U = U[:, :self.r].copy()\n            lam = np.full(self.r, 0.6 * np.mean(sigma_coord))  # direction amplitudes (not energies like original)\n        else:\n            U = np.zeros((self.dim, 0))\n            lam = np.array([])\n\n        # momentum\n        mom = np.zeros(self.dim)\n\n        # archive and buffers\n        X_arch = []\n        f_arch = []\n        success_steps = []  # store recent successful step vectors (raw steps, not normalized)\n        max_success_buf = max(40, 6 * self.dim)\n\n        # initial seed evaluations (small)\n        evals = 0\n        init_pop = min(self.pop_size, max(6, int(self.budget // 80)))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        # best-so-far\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # counters for stagnation\n        no_improve = 0\n\n        gen = 0\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam_pop = min(self.pop_size, remaining)\n\n            cand_X = []\n            cand_f = []\n            cand_steps = []\n\n            # per-coordinate success/attempt counters for this generation\n            coord_attempts = np.zeros(self.dim)\n            coord_rewards = np.zeros(self.dim)\n\n            # generate batch\n            for i in range(lam_pop):\n                # choose mutation mode\n                if rng.rand() < self.levy_prob:\n                    # Lévy-like via standard Cauchy samples (heavy tail)\n                    # scale coordinate-wise: multiply by sigma_coord\n                    # sample via tan(pi*(u-0.5))\n                    u = rng.rand(self.dim)\n                    cauchy = np.tan(np.pi * (u - 0.5))\n                    step = sigma_coord * cauchy\n                else:\n                    # Gaussian coordinate-wise mutation\n                    z = rng.randn(self.dim)\n                    step = sigma_coord * z\n\n                # occasionally mix in a guided direction from pool\n                if self.r > 0 and rng.rand() < 0.18 and len(success_steps) >= max(3, self.r):\n                    # draw a random combination of pool directions with small weights\n                    coeffs = rng.randn(self.r) * 0.8\n                    guided = U.dot(coeffs * (lam / (np.mean(lam) + 1e-12)))\n                    # mix guided direction with step\n                    step = 0.6 * step + 0.4 * guided\n\n                # small random recombination from archive: pick two best and add differential\n                if len(X_arch) >= 2 and rng.rand() < 0.12:\n                    # pick two top archive members (biased to better ones)\n                    sorted_idx = np.argsort(f_arch)\n                    a = X_arch[sorted_idx[0]]\n                    b = X_arch[sorted_idx[min(1, len(sorted_idx)-1)]]\n                    step = 0.5 * (a - b) + 0.5 * step\n\n                x = m + step\n                # clip\n                x = np.minimum(np.maximum(x, lb), ub)\n\n                f_x = float(func(x))\n                evals += 1\n\n                cand_X.append(x.copy())\n                cand_f.append(f_x)\n                cand_steps.append(step.copy())\n\n                # archive FIFO\n                X_arch.append(x.copy())\n                f_arch.append(f_x)\n                if len(X_arch) > max(6 * self.dim, 60):\n                    # keep archive bounded\n                    del X_arch[0]\n                    del f_arch[0]\n\n                # bookkeeping for best\n                improved = False\n                if f_x < f_best:\n                    f_best = f_x\n                    x_best = x.copy()\n                    improved = True\n                    no_improve = 0\n                if not improved:\n                    no_improve += 1\n\n                # attribute attempts and potential reward per coordinate:\n                # every coordinate considered \"attempted\" for this candidate (could weigh by abs step)\n                coord_attempts += 1.0\n                # mark reward if candidate is better than median of current batch so far\n                # we use a conservative online criterion: success if f_x <= current batch median (or improves global best)\n                median_threshold = np.median(np.asarray(cand_f))\n                is_success = 1.0 if (f_x <= median_threshold or f_x <= f_best) else 0.0\n                # reward coordinates proportionally to absolute relative motion in that coordinate\n                rel_move = np.abs(step) / (sigma_coord + 1e-12)\n                coord_rewards += is_success * rel_move\n\n                # keep recent success steps if success\n                if is_success > 0.5:\n                    success_steps.append(step.copy())\n                    if len(success_steps) > max_success_buf:\n                        del success_steps[0]\n\n                if evals >= self.budget:\n                    break\n\n            if len(cand_f) == 0:\n                break\n\n            # Per-coordinate multiplicative adaptation:\n            # success_rate per coordinate:\n            sr = coord_rewards / (coord_attempts + 1e-12)  # expected ~0..some\n            # normalize sr to [0,1] approximately by dividing by (mean(sr)+eps)\n            sr_norm = sr / (np.mean(sr) + 1e-12)\n            # transform into multiplicative factor: increase coords with high sr_norm above 1\n            # update rule: sigma_coord *= exp(adapt_lr * (sr_norm - 1) / (1 + sr_norm))\n            adapt_factor = np.exp(self.adapt_lr * (sr_norm - 1.0) / (1.0 + sr_norm))\n            sigma_coord = sigma_coord * adapt_factor\n            # clip coordinate scales to reasonable bounds\n            sigma_coord = np.clip(sigma_coord, self.sigma_min, self.sigma_max_mult * avg_span)\n\n            # Occasionally increase global exploration if many coordinates shrank to min\n            if np.mean(sigma_coord) < 0.02 * avg_span:\n                sigma_coord *= 1.12\n\n            # update low-rank direction pool from recent successful steps periodically\n            if self.r > 0 and (gen % self.dir_update_period == 0) and len(success_steps) >= max(4, self.r):\n                B = np.asarray(success_steps[-min(len(success_steps), 4 * self.r):])  # take recent window\n                # center rows\n                Bc = B - np.mean(B, axis=0, keepdims=True)\n                # compute covariance (dim x dim) but small sample -> use Bc.T @ Bc\n                C = np.dot(Bc.T, Bc) / max(1, Bc.shape[0] - 1)\n                # eigen-decomposition for top-r directions\n                try:\n                    vals, vecs = np.linalg.eigh(C)\n                    # select top r eigenvectors (largest eigenvalues)\n                    idx = np.argsort(vals)[::-1][:self.r]\n                    U_new = vecs[:, idx]\n                    vals_top = vals[idx]\n                    # set lam from sqrt of eigenvalues scaled to match sigma magnitudes\n                    lam_new = np.sqrt(np.maximum(vals_top, 1e-12))\n                    # smooth update\n                    U = (1.0 - self.dir_smooth) * U + self.dir_smooth * U_new\n                    # orthonormalize U quickly\n                    try:\n                        Q, _ = np.linalg.qr(U)\n                        U = Q[:, :self.r]\n                    except Exception:\n                        pass\n                    lam = (1.0 - self.dir_smooth) * lam + self.dir_smooth * lam_new\n                    # avoid degenerate small lam\n                    lam = np.clip(lam, 0.02 * np.mean(sigma_coord), 4.0 * np.mean(sigma_coord))\n                except np.linalg.LinAlgError:\n                    pass\n\n            # choose winners and update mean with momentum:\n            f_arr = np.asarray(cand_f)\n            x_arr = np.asarray(cand_X)\n            steps_arr = np.asarray(cand_steps)\n\n            # compute soft weights: better candidates get exponentially larger weight\n            fmin_local = float(f_arr.min())\n            fstd = float(np.std(f_arr) + 1e-12)\n            weights = np.exp(-(f_arr - fmin_local) / (fstd + 1e-12))\n            weights = weights / np.sum(weights)\n\n            # update mean towards weighted average of candidates (soft recombination)\n            winner_mean = np.sum((weights[:, None] * x_arr), axis=0)\n            delta = winner_mean - m\n            # clip by trust radius relative to mean of sigma_coord\n            trust_rad = 5.0 * (np.mean(sigma_coord) + 1e-12) * np.sqrt(self.dim)\n            norm_delta = np.linalg.norm(delta)\n            if norm_delta > trust_rad:\n                delta = delta * (trust_rad / (norm_delta + 1e-12))\n\n            # adaptive learning rate: stronger if batch produced many good candidates\n            batch_success_frac = float(np.mean(f_arr <= (np.median(f_arr) + 1e-12)))\n            lr = 0.25 * (0.6 + 0.8 * batch_success_frac)  # in (0.15, 0.85) roughly\n            # momentum update\n            mom = self.mom_beta * mom + (1.0 - self.mom_beta) * delta\n            m = m + lr * mom\n            # keep mean in bounds\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # occasionally accept direct move to best candidate to exploit\n            if rng.rand() < 0.06:\n                best_idx = int(np.argmin(f_arr))\n                m = x_arr[best_idx].copy()\n\n            # adapt global Lévy probability based on stagnation\n            if no_improve > max(3, self.stagn_patience // 4):\n                # more likely to perform Lévy when stagnating\n                self.levy_prob = min(self.levy_prob_max, self.levy_prob * 1.15 + 0.01)\n            else:\n                self.levy_prob = max(self.levy_prob_min, self.levy_prob * 0.97)\n\n            # opportunistic restart if prolonged stagnation\n            if no_improve >= self.stagn_patience and evals < self.budget:\n                no_improve = 0\n                # jump mean to vicinity of best and inflate coordinate scales\n                m = x_best + rng.randn(self.dim) * (self.restart_infl * np.mean(sigma_coord))\n                m = np.minimum(np.maximum(m, lb), ub)\n                sigma_coord = np.clip(sigma_coord * self.restart_infl, self.sigma_min, self.sigma_max_mult * avg_span)\n                # increase Lévy chance temporarily\n                self.levy_prob = min(self.levy_prob_max, self.levy_prob * 1.5)\n                # clear some buffers\n                success_steps = []\n                mom = np.zeros(self.dim)\n                # do small reseed evaluations around best to refill archive\n                reseed = min(6, self.budget - evals)\n                for _ in range(reseed):\n                    x = x_best + 0.06 * avg_span * rng.randn(self.dim)\n                    x = np.minimum(np.maximum(x, lb), ub)\n                    f = float(func(x))\n                    evals += 1\n                    X_arch.append(x.copy()); f_arch.append(f)\n                    if f < f_best:\n                        f_best = f\n                        x_best = x.copy()\n                    if evals >= self.budget:\n                        break\n\n            # safety: ensure we don't exceed budget (loop will exit accordingly)\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm CALE scored 0.282 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a502e03b-784f-4102-999b-4f644b5096d8", "operator": null, "metadata": {"aucs": [0.1418900012536587, 0.16502981874708245, 0.3448417872380448, 0.44106158248712224, 0.2846840960174325, 0.35369728187035254, 0.28383626336599277, 0.3108159293442956, 0.2862898477454485, 0.2088818714894205]}, "task_prompt": ""}
{"id": "a9cdd39e-cb85-4ddf-b5cb-79762e561611", "fitness": "-inf", "name": "HYBRID_MIRRORED_TRUST", "description": "The algorithm is a hybrid heuristic that combines antithetic (mirrored) paired sampling with a low‑rank orthonormal subspace U (rank ≈ max(1, dim//4)) plus a diagonal residual noise v and per‑coordinate scaling s, so most steps are generated as sigma*(U·zr + zd) and evaluated in mirrored pairs to gain directional information. Successful normalized steps are stored in a buffer and periodically SVD/PCA‑refreshed to update U and per‑direction energies p (smooth updates, p clipped), while simple per‑coordinate statistics (v, s) track local variances to shape sampling. Complementing sampling, a lightweight diagonal quadratic surrogate (ridge regression on [dx, 0.5 dx^2]) proposes Newton‑like trust steps inside an adaptive trust radius rho, and the mean is updated with momentum (beta≈0.72) plus soft acceptance; sigma is adapted multiplicatively via an EMA success rate (target ≈0.22, adapt rate ≈0.28). Exploration and robustness are enforced by archive recombination, occasional long random jumps, opportunistic small rotations of U, stochastic uphill acceptance, and stagnation restarts, with practical sizing choices (pop_base ~12, arch_size ~4*dim, buffer_max large) to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HYBRID_MIRRORED_TRUST:\n    \"\"\"\n    Hybrid Mirrored Low-Rank Trust (HMLT)\n\n    Key features:\n      - Antithetic (mirrored) paired sampling using a low-rank orthonormal subspace U (with energies p)\n        plus diagonal residual noise v to form steps; mirrored evaluations provide directional gains.\n      - PCA/SVD on a buffer of successful normalized steps refreshes U and direction energies p periodically.\n      - Lightweight diagonal quadratic surrogate (ridge) fit on a FIFO archive proposes Newton-like trust steps.\n      - Mean updates use momentum and soft acceptance; sigma adapts multiplicatively via an EMA success-rate.\n      - Archive recombination, occasional long random jumps, and opportunistic restarts for exploration.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # structural hyperparams\n        self.rank = max(1, min(self.dim, max(1, self.dim // 4)))\n        self.pop_base = max(12, int(6 + 1.0 * np.log(max(2, self.dim))))\n        self.arch_size = max(4 * self.dim, 40)\n        self.pca_period = 10\n        self.buffer_max = max(80, self.arch_size // 2)\n\n        # adaptation hyperparams\n        self.succ_target = 0.22\n        self.sigma_adapt_rate = 0.28\n        self.smooth_p = 0.92\n        self.momentum_beta = 0.72\n        self.min_sigma = 1e-10\n        self.sigma_max_mult = 3.0\n\n        # trust-region / surrogate\n        self.trust_init_mult = 0.6\n        self.trust_expand = 1.2\n        self.trust_shrink = 0.75\n        self.trust_min = 1e-6\n        self.diag_reg = 1e-8\n\n        # exploration\n        self.long_jump_prob = 0.03\n        self.restart_infl = 1.7\n        self.stagn_frac = 0.05\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # init mean and sigma\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(1e-8, 0.15 * avg_span)\n\n        # low-rank orthonormal basis U (dim x r) and energies p (variance per direction)\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :r].copy()\n            p = np.full(r, 0.2)\n        else:\n            U = np.zeros((self.dim, 0))\n            p = np.array([])\n\n        # diagonal residual variance (per-coordinate)\n        v = np.full(self.dim, 0.35)\n        # per-coordinate multiplicative scale for noise/shaping\n        s = np.ones(self.dim)\n\n        # archives and buffers\n        X_arch = []\n        f_arch = []\n        success_buffer = []  # normalized steps (step/sigma)\n\n        # initial seeding evaluations\n        evals = 0\n        init_pop = min(self.pop_base, max(6, self.budget // 60))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x))\n            evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        if len(f_arch) == 0:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        # best\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best]); x_best = X_arch[idx_best].copy()\n\n        # controllers\n        p_succ = 0.2\n        mom = np.zeros(self.dim)\n        gen = 0\n        stagn_limit = max(6, int(self.stagn_frac * self.budget))\n        stagn = 0\n        rho = self.trust_init_mult * avg_span\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            # ensure even number for mirrored pairs, leave room for trust/recombination\n            if lam % 2 == 1 and lam > 1:\n                lam -= 1\n            if lam <= 0:\n                break\n\n            cand_X = []\n            cand_f = []\n            cand_type = []\n\n            gen_success_flag = False\n            directional_gains = np.zeros(r) if r > 0 else np.array([])\n\n            # 1) mirrored paired sampling: pairs = lam//2\n            pairs = lam // 2\n            for _ in range(pairs):\n                if evals + 2 > self.budget:\n                    break\n\n                # sample in low-rank subspace\n                if r > 0:\n                    zr = rng.randn(r) * np.sqrt(np.maximum(p, self.diag_reg))\n                    low = U.dot(zr)\n                else:\n                    low = np.zeros(self.dim)\n\n                # diagonal residual noise\n                zd = rng.randn(self.dim) * np.sqrt(np.maximum(v, self.diag_reg)) * s\n\n                step = sigma * (low + zd)\n                x_plus = np.minimum(np.maximum(m + step, lb), ub)\n                x_minus = np.minimum(np.maximum(m - step, lb), ub)\n\n                # occasional long jump instead of + sample\n                if rng.rand() < self.long_jump_prob:\n                    x_plus = rng.uniform(lb, ub, size=self.dim)\n\n                # evaluate both\n                f_plus = float(func(x_plus)); f_minus = float(func(x_minus))\n                evals += 2\n\n                cand_X.extend([x_plus.copy(), x_minus.copy()])\n                cand_f.extend([f_plus, f_minus])\n                cand_type.extend(['mirror', 'mirror'])\n\n                # archive FIFO\n                X_arch.append(x_plus.copy()); f_arch.append(f_plus)\n                X_arch.append(x_minus.copy()); f_arch.append(f_minus)\n                while len(X_arch) > self.arch_size:\n                    del X_arch[0]; del f_arch[0]\n\n                # update global best\n                improved = False\n                if f_plus < f_best:\n                    f_best = f_plus; x_best = x_plus.copy(); improved = True\n                if f_minus < f_best:\n                    f_best = f_minus; x_best = x_minus.copy(); improved = True\n                if improved:\n                    gen_success_flag = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # directional gain for this pair\n                delt = f_minus - f_plus  # positive -> +step better\n                if r > 0 and delt > 0:\n                    step_norm = np.linalg.norm(step) + 1e-12\n                    step_unit = step / step_norm\n                    proj = np.abs(U.T.dot(step_unit))  # contribution per basis\n                    directional_gains += delt * proj\n\n                # record successful normalized steps to buffer\n                if (f_plus <= f_best + 1e-12) or (f_minus <= f_best + 1e-12) or (delt > 0):\n                    success_buffer.append((step / (sigma + 1e-12)).copy())\n                    if len(success_buffer) > self.buffer_max:\n                        del success_buffer[0]\n\n            # 2) occasional trust/quadratic proposals (1 or 2)\n            if evals < self.budget and len(X_arch) >= max(6, self.dim // 3):\n                # build diagonal quadratic surrogate by ridge on features [dx, 0.5 dx^2]\n                X_arr = np.asarray(X_arch)\n                f_arr = np.asarray(f_arch)\n                dx = X_arr - m.reshape(1, -1)\n                # weighting: near and good\n                dnorm = np.linalg.norm(dx / (np.sqrt(np.maximum(v, 1e-12))), axis=1)\n                wdist = np.exp(-0.6 * dnorm)\n                frank = np.exp(-1.0 * (f_arr - np.min(f_arr)) / (np.ptp(f_arr) + 1e-12))\n                w = wdist * (0.3 + 0.7 * frank)\n                W = np.sqrt(w).reshape(-1, 1)\n                X_design = np.hstack([dx, 0.5 * dx ** 2])\n                y = f_arr - np.min(f_arr)\n                reg = 1e-6\n                try:\n                    A = (W * X_design).T @ (W * X_design) + reg * np.eye(X_design.shape[1])\n                    b = (W * X_design).T @ (W * y)\n                    theta = np.linalg.solve(A, b)\n                    g_est = theta[:self.dim].copy()\n                    diagH = np.abs(theta[self.dim:]) + 1e-8\n                    # Newton-like step: -H^{-1} g\n                    step_diag = - g_est / (diagH + 1e-12)\n                    # clip to trust radius rho\n                    step_norm = np.linalg.norm(step_diag)\n                    max_step = max(self.trust_min, rho)\n                    if step_norm > max_step:\n                        step_diag = step_diag * (max_step / (step_norm + 1e-12))\n                    x_trust = np.minimum(np.maximum(m + step_diag, lb), ub)\n                    if evals < self.budget:\n                        f_trust = float(func(x_trust)); evals += 1\n                        cand_X.append(x_trust.copy()); cand_f.append(f_trust); cand_type.append('trust')\n                        X_arch.append(x_trust.copy()); f_arch.append(f_trust)\n                        while len(X_arch) > self.arch_size:\n                            del X_arch[0]; del f_arch[0]\n                        if f_trust < f_best:\n                            f_best = f_trust; x_best = x_trust.copy(); gen_success_flag = True; stagn = 0\n                        else:\n                            stagn += 1\n\n                    # also small damped trust + noise\n                    if evals < self.budget:\n                        x_trust2 = np.minimum(np.maximum(m + 0.5 * step_diag + 0.6 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, 1e-12)), lb), ub)\n                        f_trust2 = float(func(x_trust2)); evals += 1\n                        cand_X.append(x_trust2.copy()); cand_f.append(f_trust2); cand_type.append('trust')\n                        X_arch.append(x_trust2.copy()); f_arch.append(f_trust2)\n                        while len(X_arch) > self.arch_size:\n                            del X_arch[0]; del f_arch[0]\n                        if f_trust2 < f_best:\n                            f_best = f_trust2; x_best = x_trust2.copy(); gen_success_flag = True; stagn = 0\n                        else:\n                            stagn += 1\n                except np.linalg.LinAlgError:\n                    # skip surrogate\n                    pass\n\n            # 3) archive recombinations to fill a few slots if budget remains\n            slot_left = min(self.pop_base - len(cand_X), max(0, self.budget - evals))\n            for _ in range(slot_left):\n                if len(X_arch) >= 3 and evals < self.budget:\n                    f_arr = np.asarray(f_arch)\n                    probs = (np.max(f_arr) - f_arr + 1e-12)\n                    probs = probs / np.sum(probs)\n                    a, b = rng.choice(len(X_arch), size=2, replace=False, p=probs)\n                    alpha = rng.rand()\n                    xrec = alpha * X_arch[a] + (1 - alpha) * X_arch[b]\n                    # small low-rank perturbation\n                    if r > 0:\n                        zrec = rng.randn(r) * np.sqrt(np.maximum(p, self.diag_reg))\n                        xrec = xrec + 0.45 * sigma * (U.dot(zrec))\n                    xrec = np.minimum(np.maximum(xrec + 0.35 * sigma * rng.randn(self.dim) * np.sqrt(np.maximum(v, 1e-12)), lb), ub)\n                    frec = float(func(xrec)); evals += 1\n                    cand_X.append(xrec.copy()); cand_f.append(frec); cand_type.append('recomb')\n                    X_arch.append(xrec.copy()); f_arch.append(frec)\n                    while len(X_arch) > self.arch_size:\n                        del X_arch[0]; del f_arch[0]\n                    if frec < f_best:\n                        f_best = frec; x_best = xrec.copy(); gen_success_flag = True; stagn = 0\n                    else:\n                        stagn += 1\n\n            # ensure arrays\n            if len(cand_f) == 0:\n                break\n\n            f_array = np.asarray(cand_f)\n            X_array = np.asarray(cand_X)\n\n            # pick winner by softmax on negative objective (favor small f)\n            fmin_local = f_array.min()\n            fstd = float(np.std(f_array) + 1e-12)\n            scores = np.exp(-(f_array - fmin_local) / (fstd + 1e-12))\n            probs = scores / np.sum(scores)\n            win_idx = rng.choice(len(X_array), p=probs)\n            winner = X_array[win_idx].copy()\n            winner_f = float(f_array[win_idx])\n            wtype = cand_type[win_idx]\n\n            # acceptance: accept if improves global best or probabilistic uphill acceptance scaled by sigma*avg_span\n            accept = False\n            if winner_f <= f_best:\n                accept = True\n            else:\n                uphill_scale = max(1e-12, sigma * avg_span)\n                if rng.rand() < np.exp(-max(0.0, winner_f - f_best) / (uphill_scale + 1e-12)):\n                    accept = True\n\n            # update mean with momentum\n            if accept:\n                if wtype == 'trust':\n                    eta = 0.36\n                elif wtype == 'mirror':\n                    eta = 0.30\n                elif wtype == 'recomb':\n                    eta = 0.20\n                else:\n                    eta = 0.18\n                delta = winner - m\n                # clip by trust radius proportional to sigma * sqrt(dim)\n                trust_radius = max(1e-12, 4.0 * sigma * np.sqrt(self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > trust_radius:\n                    delta = delta * (trust_radius / (dn + 1e-12))\n                mom = self.momentum_beta * mom + (1.0 - self.momentum_beta) * delta\n                m = m + eta * mom\n                m = np.minimum(np.maximum(m, lb), ub)\n            else:\n                # jitter exploration\n                m = np.minimum(np.maximum(m + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                mom = mom * (1.0 - (1.0 - self.momentum_beta) * 0.5)\n\n            # compute normalized steps for candidates w.r.t current mean for statistics\n            denom = sigma * np.sqrt(np.maximum(v, 1e-12))\n            deltas_norm = (X_array - m.reshape(1, -1)) / (denom.reshape(1, -1))\n            stat = np.mean(np.abs(deltas_norm), axis=0)\n            # update v and s modestly\n            v = 0.85 * v + 0.15 * np.clip(np.var(deltas_norm, axis=0), 1e-6, 4.0)\n            s = 0.85 * s + 0.15 * np.clip(stat, 0.2, 5.0)\n\n            # update directional energies p from directional_gains if present\n            if r > 0 and np.sum(directional_gains) > 1e-12:\n                g = directional_gains\n                g = g - np.max(g)\n                # softmax-like allocation\n                denom_g = (np.std(g) + 1e-12)\n                p_new = np.exp(g / denom_g)\n                p_new = p_new / (np.sum(p_new) + 1e-12)\n                # smooth update and rescale to keep average similar\n                p = 0.80 * p + 0.20 * (p_new * np.sum(p))\n                p = np.clip(p, 1e-5, 8.0)\n\n            # periodic PCA refresh from success_buffer\n            if (gen % self.pca_period == 0) and len(success_buffer) >= max(3, r):\n                B = np.asarray(success_buffer)\n                Bc = B - np.mean(B, axis=0, keepdims=True)\n                try:\n                    U_s, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        U_new = Vt[:r_eff].T\n                        eigs = (S_s[:r_eff] ** 2) / max(1, Bc.shape[0] - 1)\n                        # align and smoothly update U and p\n                        if U.shape[1] == r_eff:\n                            # fix orientation\n                            for k in range(r_eff):\n                                if np.dot(U[:, k], U_new[:, k]) < 0:\n                                    U_new[:, k] *= -1.0\n                            U = 0.85 * U + 0.15 * U_new\n                            p = 0.75 * p + 0.25 * (eigs / (np.mean(eigs) + 1e-12))\n                        else:\n                            U = U_new\n                            p = eigs / (np.mean(eigs) + 1e-12)\n                        p = np.clip(p, 1e-5, 10.0)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # adapt sigma via smoothed success probability\n            gen_success = float(gen_success_flag)\n            p_succ = self.smooth_p * p_succ + (1.0 - self.smooth_p) * gen_success\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, self.min_sigma, self.sigma_max_mult * avg_span)\n\n            # adapt trust radius based on whether trust proposals improved\n            if 'trust' in [cand_type[i] for i in range(len(cand_type)) if cand_f[i] <= np.min(cand_f) + 1e-12]:\n                rho = min(5.0 * avg_span, rho * self.trust_expand)\n            else:\n                rho = max(self.trust_min, rho * self.trust_shrink)\n\n            # opportunistic small rotation of U occasionally to encourage exploration\n            if r > 0 and rng.rand() < 0.05:\n                Qr = rng.randn(r, r)\n                try:\n                    Qr_orth, _ = np.linalg.qr(Qr)\n                    U = U.dot(Qr_orth)\n                except Exception:\n                    pass\n\n            # opportunistic restart on stagnation\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                # jitter around best and inflate sigma, reset some statistics\n                jitter = max(0.04 * avg_span, 0.6 * sigma)\n                m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                sigma = max(sigma * self.restart_infl, 0.2 * avg_span)\n                rho = max(rho, 0.8 * avg_span)\n                if r > 0:\n                    A = rng.randn(self.dim, r); Q, _ = np.linalg.qr(A); U = Q[:, :r]\n                    p = np.full(r, np.mean(p) if p.size else 0.2)\n                v = np.full(self.dim, 0.35)\n                success_buffer = []\n                mom = np.zeros(self.dim)\n                # reseed a few evaluations near best\n                for _ in range(min(4, self.budget - evals)):\n                    x = np.minimum(np.maximum(x_best + 0.08 * avg_span * rng.randn(self.dim), lb), ub)\n                    f = float(func(x)); evals += 1\n                    X_arch.append(x.copy()); f_arch.append(f)\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n                    if evals >= self.budget:\n                        break\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 225, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,18) \nOn line: x_trust = np.minimum(np.maximum(m + step_diag, lb), ub)", "error": "In the code, line 225, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,18) \nOn line: x_trust = np.minimum(np.maximum(m + step_diag, lb), ub)", "parent_ids": "a502e03b-784f-4102-999b-4f644b5096d8", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "176b5ba5-f880-45ee-b90f-b8d4bbab9cfa", "fitness": 0.5714156519978623, "name": "MirrorLevyDE", "description": "The design is a hybrid, budget-aware evolutionary framework combining jDE-style self-adapting differential evolution (current-to-pbest/1 mutation with binomial crossover and per-individual F/CR adapted by tau1/tau2) with mirrored (antithetic) trial evaluations, an elite archive, and small population sized by a log heuristic. Initialization is stratified/quasi-uniform with light jitter, and feasibility is enforced by reflection; p-best selection uses a small p_frac (0.2) and pnum_min to bias searches toward good solutions. Global exploration is driven by occasional archive-guided Cauchy/Levy-like jumps (global_jump_prob ≈ 0.22) whose step scale is adaptively tuned from the population’s normalized spread (levy_alpha = 0.7, diversity_target = 0.30, initial levy_scale = 0.15·span), while mirrored trials around the population mean opportunistically inject antithetic diversity. Exploitation is supported by periodic budget-limited Hooke–Jeeves local searches (local_period = 20, local_budget_frac = 0.04) with pattern moves and shrinkage, and stagnation triggers opportunistic restarts that inflate levy_scale, jitter around the best, and mildly diversify the population to recover progress.", "code": "import numpy as np\n\nclass MirrorLevyDE:\n    \"\"\"\n    MirrorLevyDE: A compact current-to-pbest/1 jDE with mirrored (antithetic) trial evaluations,\n    Levy-guided global jumps whose scale adapts to the population normalized spread, periodic Hooke-Jeeves\n    local refinement, and opportunistic restarts on stagnation.\n    One-line: jDE + mirrored trials + spread-driven Levy scale + local pattern search for robust budget-aware continuous optimization.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # jDE adaptation probabilities\n        self.tau1 = 0.12\n        self.tau2 = 0.12\n        self.F_min = 0.05\n        self.F_max = 0.95\n\n        # population size heuristic\n        self.pop = max(12, int(4 + 3 * np.log(max(2, self.dim))))\n        self.pop = min(self.pop, max(2, self.budget))\n\n        # Levy/global-jump parameters\n        self.global_jump_prob = 0.22\n        self.levy_alpha = 0.7    # adaptation strength for Levy scale (higher -> faster)\n        self.diversity_target = 0.30  # desired normalized spread (like No.1)\n        self.levy_scale = None   # will initialize relative to span\n\n        # local search params (Hooke-Jeeves like)\n        self.local_period = 20\n        self.local_budget_frac = 0.04\n        self.initial_step_frac = 0.18\n        self.pattern_factor = 1.5\n        self.shrink = 0.6\n\n        # stagnation / restart\n        self.stagnation_limit_gens = max(12, int(0.03 * (self.budget / max(1, self.pop))))\n        self.restart_inflate = 3.0\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize Levy scale based on span\n        self.levy_scale = 0.15 * avg_span\n\n        # evaluation wrapper (budget-aware)\n        evals = 0\n        f_best = np.inf\n        x_best = None\n\n        def reflect_bounds(x):\n            x = x.copy()\n            below = x < lb\n            if np.any(below):\n                x[below] = lb[below] + (lb[below] - x[below])\n            above = x > ub\n            if np.any(above):\n                x[above] = ub[above] - (x[above] - ub[above])\n            x = np.minimum(np.maximum(x, lb), ub)\n            return x\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = reflect_bounds(x)\n            f = float(func(x))\n            evals += 1\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            return f, x\n\n        # quasi-uniform stratified initialization (like No.5)\n        X = np.empty((self.pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(self.pop)\n            strata = (np.arange(self.pop) + 0.5) / self.pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter small\n        X += (rng.rand(self.pop, self.dim) - 0.5) * (0.5 * span / max(1.0, self.dim))\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        # evaluate initial population\n        f = np.full(self.pop, np.inf, dtype=float)\n        for i in range(self.pop):\n            if evals >= self.budget:\n                break\n            res = eval_and_record(X[i])\n            if res is None:\n                break\n            f[i], X[i] = res\n\n        # ensure at least one evaluated point\n        if x_best is None:\n            while evals < self.budget:\n                res = eval_and_record(rng.uniform(lb, ub))\n                if res is None:\n                    break\n                break\n\n        # jDE F and CR arrays\n        F = np.clip(0.6 + 0.1 * rng.randn(self.pop), self.F_min, self.F_max)\n        CR = np.clip(rng.rand(self.pop), 0.0, 1.0)\n\n        # archive for elites\n        archive = []\n        archive_k = max(3, min(8, self.pop // 2))\n\n        def archive_add(xv, fv):\n            nonlocal archive\n            if len(archive) < archive_k:\n                archive.append((float(fv), xv.copy()))\n                archive.sort(key=lambda t: t[0])\n            else:\n                if fv < archive[-1][0]:\n                    archive[-1] = (float(fv), xv.copy())\n                    archive.sort(key=lambda t: t[0])\n\n        # incorporate initial evaluated individuals into archive\n        for i in range(self.pop):\n            if np.isfinite(f[i]):\n                archive_add(X[i], f[i])\n\n        gen = 0\n        gens_since_improve = 0\n        p_frac = 0.2\n        pnum_min = max(2, int(np.ceil(p_frac * self.pop)))\n\n        # Hooke-Jeeves local search (budget-limited)\n        def local_search(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            step0 = max(1e-12, self.initial_step_frac * avg_span * (0.8 + 0.4 * rng.rand()))\n            steps = np.full(self.dim, step0, dtype=float)\n            local_evals = 0\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_evals < local_budget and iters < iter_limit and np.any(steps > 1e-12):\n                iters += 1\n                improved = False\n                x_probe = base.copy()\n                x_probe_f = base_f\n                order = list(range(self.dim))\n                rng.shuffle(order)\n                for i in order:\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    # plus\n                    xp = x_probe.copy()\n                    xp[i] = min(xp[i] + steps[i], ub[i])\n                    res = eval_and_record(xp)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < x_probe_f:\n                        x_probe = xp.copy()\n                        x_probe_f = fp\n                        improved = True\n                        steps[i] *= (1.15 + 0.05 * rng.rand())\n                        continue\n                    # minus\n                    xn = x_probe.copy()\n                    xn[i] = max(xn[i] - steps[i], lb[i])\n                    res = eval_and_record(xn)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < x_probe_f:\n                        x_probe = xn.copy()\n                        x_probe_f = fn\n                        improved = True\n                        steps[i] *= (1.15 + 0.05 * rng.rand())\n                # pattern move\n                if improved and local_evals < local_budget and evals < self.budget:\n                    direction = x_probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + self.pattern_factor * direction\n                        xp = reflect_bounds(xp)\n                        res = eval_and_record(xp)\n                        local_evals += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < x_probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = x_probe.copy()\n                                base_f = x_probe_f\n                        else:\n                            base = x_probe.copy()\n                            base_f = x_probe_f\n                    else:\n                        base = x_probe.copy()\n                        base_f = x_probe_f\n                else:\n                    steps *= self.shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n            remaining = self.budget - evals\n\n            # measure population mean and normalized spread to adapt levy_scale\n            m = np.mean(X, axis=0)\n            # compute normalized RMS\n            y_all = (X - m) / (self.levy_scale + 1e-20)\n            norm_rms = np.sqrt(np.mean(np.sum(y_all ** 2, axis=1)) / max(1.0, float(self.dim)))\n            # adapt levy_scale towards diversity_target (mirrors No.1 adaptation)\n            self.levy_scale *= np.exp(self.levy_alpha * (self.diversity_target - norm_rms))\n            self.levy_scale = float(np.clip(self.levy_scale, 1e-12, 2.0 * np.max(span)))\n\n            # ranking and p-best pool\n            order = np.argsort(f)\n            p_pool = order[:max(pnum_min, 2)]\n\n            # randomized order update\n            idxs = rng.permutation(self.pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n\n                # jDE adaptation\n                if rng.rand() < self.tau1:\n                    F[ii] = np.clip(0.4 + 0.4 * rng.rand(), self.F_min, self.F_max)\n                if rng.rand() < self.tau2:\n                    CR[ii] = rng.rand()\n\n                # choose p-best\n                pbest_idx = int(rng.choice(p_pool))\n                # choose r1, r2 distinct\n                pool = [j for j in range(self.pop) if j not in (ii, pbest_idx)]\n                if len(pool) < 2:\n                    r1 = r2 = ii\n                else:\n                    r1, r2 = rng.choice(pool, size=2, replace=False)\n\n                xi = X[ii].copy()\n                xp = X[pbest_idx].copy()\n                xr1 = X[r1].copy()\n                xr2 = X[r2].copy()\n\n                # current-to-pbest/1 mutation\n                vi = xi + F[ii] * (xp - xi) + F[ii] * (xr1 - xr2)\n\n                # binomial crossover\n                jrand = rng.randint(self.dim)\n                mask = (rng.rand(self.dim) < CR[ii])\n                mask[jrand] = True\n                trial = np.where(mask, vi, xi)\n                trial = reflect_bounds(trial)\n\n                # Antithetic (mirrored) trial around population mean (if budget allows evaluate complementary mirror)\n                mirror = reflect_bounds(2.0 * m - trial)\n\n                # Evaluate primary trial\n                if evals < self.budget:\n                    res = eval_and_record(trial)\n                    if res is not None:\n                        fv, trial = res\n                        # accept if better or equal\n                        if fv <= f[ii]:\n                            X[ii] = trial.copy()\n                            f[ii] = fv\n                            improved_in_gen = True\n                            archive_add(trial, fv)\n                # Evaluate mirrored trial opportunistically if budget allows (and it's different)\n                if evals < self.budget and not np.allclose(mirror, trial):\n                    # prefer to evaluate mirror when less than ~10% budget left to keep exploring, or randomly 0.25 prob\n                    do_mirror = (remaining > 50 and rng.rand() < 0.35) or (remaining <= 50 and rng.rand() < 0.6)\n                    if do_mirror:\n                        res = eval_and_record(mirror)\n                        if res is not None:\n                            fm, mirror = res\n                            # place mirror into worst slot if good, or replace parent if better\n                            if fm < f[ii]:\n                                X[ii] = mirror.copy()\n                                f[ii] = fm\n                                improved_in_gen = True\n                                archive_add(mirror, fm)\n                            else:\n                                # possibly inject into population replacing worst\n                                worst_idx = int(np.argmax(f))\n                                if fm < f[worst_idx]:\n                                    X[worst_idx] = mirror.copy()\n                                    f[worst_idx] = fm\n                                    archive_add(mirror, fm)\n\n                remaining = self.budget - evals\n\n            # update global best and archive from current population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                improved_in_gen = True\n\n            if x_best is not None:\n                archive_add(x_best, f_best)\n\n            # Levy/global jump occasionally (archive-guided)\n            if len(archive) > 0 and rng.rand() < self.global_jump_prob and evals < self.budget:\n                center = archive[0][1] if rng.rand() < 0.75 else archive[rng.randint(len(archive))][1]\n                # Cauchy-like step scaled by adaptive levy_scale\n                direction = rng.randn(self.dim)\n                direction /= (np.linalg.norm(direction) + 1e-12)\n                step_length = rng.standard_cauchy()\n                step_length = np.clip(step_length, -1e3, 1e3)\n                step = direction * (self.levy_scale * (0.4 + 0.6 * rng.rand()))\n                cand = reflect_bounds(center + step_length * step)\n                res = eval_and_record(cand)\n                if res is not None:\n                    fc, cand = res\n                    archive_add(cand, fc)\n                    # if promising apply a small focused local search\n                    if fc <= (archive[0][0] if len(archive) > 0 else np.inf) * 1.08 and evals < self.budget:\n                        local_alloc = min(int(self.local_budget_frac * self.budget), self.budget - evals)\n                        local_alloc = max(1, local_alloc)\n                        f_after, x_after = local_search(cand, fc, local_alloc)\n                        # inject improvement into population\n                        if f_after < np.max(f):\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = x_after.copy()\n                            f[worst_idx] = f_after\n                            archive_add(x_after, f_after)\n                            if f_after < f_best:\n                                f_best = f_after\n                                x_best = x_after.copy()\n                                improved_in_gen = True\n\n            # Periodic or stagnation-triggered local search around best\n            if (gen % self.local_period == 0 or gens_since_improve >= self.stagnation_limit_gens) and evals < self.budget:\n                remaining = self.budget - evals\n                alloc = int(max(1, min(int(self.local_budget_frac * self.budget), remaining)))\n                # if strongly stagnating, increase local budget\n                if gens_since_improve >= self.stagnation_limit_gens:\n                    alloc = min(remaining, alloc * 3)\n                if x_best is not None:\n                    f_after, x_after = local_search(x_best, f_best, alloc)\n                    if f_after < f_best:\n                        # inject into population replacing worst\n                        worst_idx = int(np.argmax(f))\n                        X[worst_idx] = x_after.copy()\n                        f[worst_idx] = f_after\n                        f_best = f_after\n                        x_best = x_after.copy()\n                        archive_add(x_after, f_after)\n                        improved_in_gen = True\n\n            # adapt global_jump_prob based on archive diversity and normalized spread\n            if len(archive) >= 2:\n                diversity = np.linalg.norm(archive[0][1] - archive[-1][1])\n                if diversity < 0.01 * avg_span + 1e-12:\n                    self.global_jump_prob = min(0.65, self.global_jump_prob + 0.02)\n                else:\n                    self.global_jump_prob = max(0.05, self.global_jump_prob * 0.995)\n\n            # stagnation handling & opportunistic restart\n            if improved_in_gen:\n                gens_since_improve = 0\n            else:\n                gens_since_improve += 1\n\n            if gens_since_improve >= self.stagnation_limit_gens and evals < self.budget:\n                # opportunistic restart: inflate levy_scale, jitter around best, re-seed some population\n                gens_since_improve = 0\n                self.levy_scale *= self.restart_inflate\n                self.levy_scale = min(self.levy_scale, 1.0 * np.max(span))\n                if x_best is not None:\n                    for k in range(self.pop // 3):\n                        if evals >= self.budget:\n                            break\n                        jitter = rng.randn(self.dim) * (0.25 * self.levy_scale)\n                        newx = reflect_bounds(x_best + jitter)\n                        res = eval_and_record(newx)\n                        if res is not None:\n                            fv, newx = res\n                            # replace worst\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = newx.copy()\n                            f[worst_idx] = fv\n                            archive_add(newx, fv)\n                # also mildly diversify entire population by small gaussian\n                for i in range(self.pop):\n                    if evals >= self.budget:\n                        break\n                    X[i] = reflect_bounds(X[i] + rng.randn(self.dim) * (0.01 * np.max(span)))\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MirrorLevyDE scored 0.571 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a502e03b-784f-4102-999b-4f644b5096d8", "operator": null, "metadata": {"aucs": [0.10855580455432634, 0.1649984724913639, 0.7482922428096624, 0.9900951887429761, 0.9851323123068797, 0.9846649953146321, 0.25029906884613873, 0.4961144287652217, 0.8215649881592852, 0.16443901798813576]}, "task_prompt": ""}
{"id": "8f9b8432-bed7-423d-acbf-0d52d6028a4e", "fitness": 0.09083320292215584, "name": "DAPCA", "description": "DAPCA keeps a small orthonormal direction bank D with additive energies and a FIFO archive of recent evaluations, while also maintaining a global scale sigma0 (initialized as 0.18·avg_span) and per-dimension adaptive scales sigma_i driven by an RMS accumulator (rms_beta=0.92) so productive coordinates get larger relative steps. It mixes several cheap probing strategies with tuned probabilities — occasional heavy‑tailed Cauchy jumps (~4%), targeted diagonal quadratic surrogate minimizers fitted from recent archive points (~12%), short 1‑D quadratic line probes along high‑energy directions (~6%, using up to 4 evals), and directional or coordinate Gaussian probes as the default — with a small pop of candidates per generation. Learning mechanisms include additive energy updates for directions (alpha_e=0.25 with 0.999 decay), periodic SVD/Q refreshes and small random rotations of D, per‑success shrinkage of sigma0 (*0.90) and mild expansion on uphill acceptance, and trust‑clipped mean updates to avoid giant leaps. Acceptance is probabilistic (temperature T = 0.5·sigma0·avg_span) to allow uphill moves, and severe stagnation triggers local reseeding around the best point and reinitialization of directions to escape local minima.", "code": "import numpy as np\n\nclass DAPCA:\n    \"\"\"\n    Directional Adaptive Probing with Coordinated Adaptation (DAPCA)\n\n    Key ideas:\n    - Maintain a small bank of learned orthonormal search directions D with additive\n      energies (weights) to bias directional probes.\n    - Keep per-dimension adaptive scales (like RMS-adaptation) so coordinates that\n      appear productive get larger/smaller probing automatically.\n    - Archive recent evaluations and occasionally fit cheap diagonal quadratic\n      surrogates around promising centers to propose targeted minimizers.\n    - Occasional heavy-tail (Cauchy) jumps and short 1-D quadratic line probes along\n      principal successful directions to refine quickly with very few evaluations.\n    - Probabilistic uphill acceptance with temperature tied to current scale,\n      and conservative step/mean updates on acceptance.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=20, archive_size=None, dir_count=None,\n                 init_sigma_mult=0.18, rms_beta=0.92,\n                 dir_refresh=10, prob_target=0.12, prob_line=0.06,\n                 heavy_tail_prob=0.04, accept_temp_coeff=0.5,\n                 min_sigma=1e-8, max_sigma=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.archive_size = archive_size if archive_size is not None else max(6 * self.dim, 120)\n        self.dir_count = dir_count if dir_count is not None else max(1, self.dim // 8)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.rms_beta = float(rms_beta)\n        self.dir_refresh = int(dir_refresh)\n        self.prob_target = float(prob_target)\n        self.prob_line = float(prob_line)\n        self.heavy_tail_prob = float(heavy_tail_prob)\n        self.accept_temp_coeff = float(accept_temp_coeff)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds (default -5..5 if not provided)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial mean\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # initial global sigma and per-dim adaptive scales\n        sigma0 = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        sigma_i = np.full(self.dim, sigma0)          # per-dimension scale\n        v_rms = np.full(self.dim, 1e-6)              # RMS accumulator\n\n        # direction bank D (orthonormal) and additive energies (weights)\n        r = min(self.dir_count, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            D = Q[:, :r].copy()\n            d_energy = np.ones(r, dtype=float)       # additive energy (not multiplicative here)\n        else:\n            D = np.zeros((self.dim, 0))\n            d_energy = np.array([])\n\n        # archive FIFO\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # seeding: a small initial random probe set to populate archive\n        seed_init = min(self.pop * 2, max(6, int(self.budget // 200)))\n        for _ in range(seed_init):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        # ensure at least one eval\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(8, int(0.05 * self.budget))\n\n        # helper: diagonal quadratic fit around center C using K recent points\n        def fit_diag_quad_center(C, Xs, fs):\n            # fit per-dim y ≈ c + g_i * dx_i + 0.5*h_i * dx_i^2 (diagonal Hessian)\n            # Solve per-dim small least squares to extract g_i and h_i\n            K = Xs.shape[0]\n            dX = Xs - C[None, :]\n            # To keep simple and robust do separate 1D fits per coordinate\n            g = np.zeros(self.dim)\n            h = np.ones(self.dim) * 1e-6\n            # target is fs\n            y = fs\n            for j in range(self.dim):\n                uj = dX[:, j]\n                # design [1, u, u^2] with regularization\n                A = np.vstack([np.ones(K), uj, uj * uj]).T\n                # solve least squares with tiny ridge\n                try:\n                    theta, *_ = np.linalg.lstsq(A, y, rcond=None)\n                    # theta = [c_est, g_j, 0.5*h_j]\n                    g[j] = float(theta[1])\n                    h_est = float(theta[2]) * 2.0\n                    # regularize curvature\n                    if abs(h_est) < 1e-6:\n                        h_est = np.sign(h_est) * 1e-6 if h_est != 0 else 1e-6\n                    h[j] = h_est\n                except Exception:\n                    g[j] = 0.0\n                    h[j] = 1e-6\n            return g, h\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n\n            # refresh direction bank occasionally via recent successful steps\n            if (gen % self.dir_refresh == 0) and len(X_arch) >= max(4, r):\n                K = min(len(X_arch), self.archive_size)\n                Xr = np.asarray(X_arch[-K:])\n                # compute recent successful steps w.r.t. mean\n                M = np.mean(Xr, axis=0)\n                S = (Xr - M)\n                try:\n                    # principal components from SVD of centered archive\n                    U, Svals, Vt = np.linalg.svd(S, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        D_new = Vt[:r_eff].T\n                        # blend to avoid abrupt change\n                        D = 0.85 * D + 0.15 * D_new\n                        # orthonormalize\n                        Q, _ = np.linalg.qr(D)\n                        D = Q[:, :r_eff]\n                        # reset low-energy directions gently\n                        if d_energy.size > 0:\n                            d_energy = 0.9 * d_energy + 0.1 * (Svals[:r_eff] + 1e-6)\n                            d_energy = np.clip(d_energy, 1e-6, 1e6)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # how many candidates this gen\n            n_cand = min(self.pop, max(1, self.budget - evals))\n\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                # choose strategy\n                p = rng.rand()\n                x_cand = None\n                step = None\n                strategy = 'random'\n\n                # heavy-tail global jump (Cauchy) occasionally\n                if rng.rand() < self.heavy_tail_prob:\n                    z = rng.standard_cauchy(size=self.dim)\n                    # scale to reasonable magnitude\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    x_cand = m + sigma0 * 3.0 * z\n                    strategy = 'heavy'\n                # targeted cheap diagonal quadratic from recent promising center\n                elif p < self.prob_target and len(X_arch) >= 6:\n                    # pick center = best-of-recent subset\n                    K = min(len(X_arch), max(12, self.dim * 3))\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    # choose the cluster center as weighted mean of the top percentile\n                    topk = max(3, int(0.12 * K))\n                    ids = np.argsort(fr)[:topk]\n                    C = np.mean(Xr[ids], axis=0)\n                    # fit diagonal quadratic around C with a subset\n                    try:\n                        g_diag, h_diag = fit_diag_quad_center(C, Xr, fr)\n                        # propose minimizer: x* = C - g / h (elementwise)\n                        dx = - g_diag / (h_diag + 1e-12)\n                        # scale dx if too large relative to bound\n                        norm_dx = np.linalg.norm(dx)\n                        max_move = 4.0 * sigma0\n                        if norm_dx > max_move:\n                            dx = dx * (max_move / (norm_dx + 1e-12))\n                        x_cand = C + dx\n                        step = x_cand - m\n                        strategy = 'target'\n                    except Exception:\n                        x_cand = None\n                # 1-D quadratic probe along a good direction (uses up to 3 evals)\n                elif p < self.prob_target + self.prob_line and len(X_arch) >= 6 and r > 0:\n                    # pick a direction from D weighted by energies\n                    weights = d_energy / (np.sum(d_energy) + 1e-12)\n                    idx = rng.choice(r, p=weights)\n                    dvec = D[:, idx]\n                    # pick a center for probing (best recent)\n                    K = min(len(X_arch), max(8, self.dim * 2))\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    C = Xr[np.argmin(fr)].copy()\n                    # select three alphas: 0, +a, -a where a sampled\n                    a = sigma0 * max(0.6, rng.rand() * 2.5)\n                    pts = [C, np.minimum(np.maximum(C + a * dvec, lb), ub),\n                           np.minimum(np.maximum(C - a * dvec, lb), ub)]\n                    # ensure budget for 3 evals\n                    needed = 0\n                    for x in pts:\n                        # check if we've already evaluated exactly same point in archive (rare) skip counting\n                        needed += 1\n                    if evals + needed <= self.budget:\n                        fs = []\n                        for x in pts:\n                            fx = float(func(x)); evals += 1\n                            fs.append(fx)\n                            X_arch.append(x.copy()); f_arch.append(fx)\n                        # quadratic fit along alpha -> fit parabola f(alpha) with alphas [0,a,-a]\n                        # map to alphas [0, +a, -a] and use simple formula for vertex:\n                        f0, f1, f2 = fs[0], fs[1], fs[2]\n                        # Using symmetric points +a and -a: parabola f(0)=f0, f(a)=f1, f(-a)=f2\n                        # estimate curvature and minimizer alpha* = (a*(f2 - f1)) / (2*(f1 + f2 - 2*f0))\n                        denom = (f1 + f2 - 2.0 * f0)\n                        if abs(denom) > 1e-12:\n                            alpha_star = (a * (f2 - f1)) / (2.0 * denom)\n                            alpha_star = np.clip(alpha_star, -3.0 * a, 3.0 * a)\n                            x_star = np.minimum(np.maximum(C + alpha_star * dvec, lb), ub)\n                            f_star = float(func(x_star)); evals += 1\n                            X_arch.append(x_star.copy()); f_arch.append(f_star)\n                            x_cand = x_star\n                            step = x_cand - m\n                            strategy = 'line'\n                        else:\n                            # fallback to best of the three\n                            best_idx = int(np.argmin(fs))\n                            x_cand = pts[best_idx].copy()\n                            step = x_cand - m\n                            strategy = 'line_fallback'\n                    else:\n                        # not enough budget — fallback to a directional probe below\n                        x_cand = None\n\n                # directional Gaussian probe (default): sample along a random learned direction plus per-dim noise\n                if x_cand is None:\n                    if r > 0 and rng.rand() < 0.85:\n                        # pick direction with probability proportional to energies\n                        weights = d_energy / (np.sum(d_energy) + 1e-12)\n                        idx = rng.choice(r, p=weights)\n                        dvec = D[:, idx]\n                        # sample scalar z and per-dim jitter\n                        z = rng.randn() * 1.0\n                        jitter = rng.randn(self.dim) * sigma_i\n                        step = z * sigma0 * dvec + 0.8 * jitter\n                        x_cand = m + step\n                        strategy = 'dir_probe'\n                    else:\n                        # coordinate-wise adaptive Gaussian\n                        jitter = rng.randn(self.dim) * sigma_i\n                        step = jitter\n                        x_cand = m + step\n                        strategy = 'coord_probe'\n\n                # clip to bounds and evaluate\n                x_cand = np.minimum(np.maximum(x_cand, lb), ub)\n                # before calling func ensure not exceeding budget (line-probe used extra evals already)\n                if evals >= self.budget:\n                    break\n                f_c = float(func(x_cand)); evals += 1\n                X_arch.append(x_cand.copy()); f_arch.append(f_c)\n\n                # keep archive FIFO\n                if len(X_arch) > self.archive_size:\n                    del X_arch[0]; del f_arch[0]\n\n                improved = False\n                if f_c < f_best:\n                    f_best = f_c\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # compute a pseudo-gradient: negative improvement times normalized step (if step available)\n                if step is None:\n                    # compute step relative to mean\n                    step = x_cand - m\n\n                step_norm = np.linalg.norm(step) + 1e-12\n                # reward signal: (f_prev_best - f_c) clipped and scaled by step projection length\n                # use archive min as baseline\n                baseline = np.min(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                reward = raw_reward / (sigma0 * step_norm + 1e-12)\n\n                # update per-dim RMS and adaptive sigma_i (like Adam/RMSprop scale)\n                sq_norm = (step / (sigma0 + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq_norm\n                sigma_i = np.clip(sigma0 / (np.sqrt(v_rms) + 1e-8), self.min_sigma, self.max_sigma)\n\n                # update direction energies for the direction used (if any)\n                if r > 0 and strategy in ('dir_probe', 'line', 'line_fallback'):\n                    # find best-matching direction by projection\n                    projs = D.T.dot(step)\n                    abs_projs = np.abs(projs)\n                    if np.sum(abs_projs) > 0:\n                        idx = int(np.argmax(abs_projs))\n                        # additive update: energy <- energy + alpha * reward * normalized_proj\n                        alpha_e = 0.25\n                        contrib = abs_projs[idx] / (np.sum(abs_projs) + 1e-12)\n                        d_energy[idx] += alpha_e * reward * contrib\n                        # small decay to keep energies bounded\n                        d_energy *= 0.999\n                        d_energy = np.clip(d_energy, 1e-6, 1e6)\n\n                # if accepted as new mean (improves best) or probabilistic uphill acceptance\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    # temperature proportional to current sigma0 * avg_span\n                    T = max(1e-12, self.accept_temp_coeff * sigma0 * avg_span)\n                    if rng.rand() < np.exp(-max(0.0, f_c - f_best) / (T + 1e-12)):\n                        accept = True\n\n                if accept:\n                    # gentle update of mean towards x_cand depending on strategy\n                    if strategy in ('target',):\n                        lr = 0.75\n                    elif strategy in ('line', 'line_fallback'):\n                        lr = 0.55\n                    elif strategy in ('heavy',):\n                        lr = 0.3\n                    elif strategy in ('dir_probe',):\n                        lr = 0.28\n                    else:\n                        lr = 0.22\n                    delta = x_cand - m\n                    # trust clipping to avoid giant leaps\n                    trust = 6.0 * sigma0 * np.sqrt(self.dim)\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                    # on success, slightly decrease global sigma0 for refinement\n                    if improved:\n                        sigma0 = max(self.min_sigma, sigma0 * 0.90)\n                        # also slightly reduce RMS memory to allow adaptation to new scale\n                        v_rms *= 0.97\n                    else:\n                        # uphill accepted: increase exploration mildly\n                        sigma0 = min(self.max_sigma, sigma0 * 1.02)\n                else:\n                    # not accepted: small Gaussian jitter around mean to maintain exploration\n                    m = np.minimum(np.maximum(m + 0.01 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma0 = min(self.max_sigma, sigma0 * 1.007)\n\n                # occasional small rotation of D to maintain coverage\n                if r > 0 and rng.rand() < 0.03:\n                    R = rng.randn(r, r) * 0.06\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(r) + R)\n                        D = D.dot(Qr)\n                        Q2, _ = np.linalg.qr(D)\n                        D = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # opportunistic small local reseed if stagnation\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    # center near best with moderate jitter\n                    jitter = max(0.05 * avg_span, 0.8 * sigma0)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    # inflate sigma0 to escape\n                    sigma0 = min(self.max_sigma, sigma0 * 1.8)\n                    # refresh direction bank randomly\n                    if r > 0:\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        D = Q[:, :r]\n                        d_energy = np.ones(r)\n                    # add a few reseed evaluations around best\n                    reseed = min(6, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = float(func(x)); evals += 1\n                        X_arch.append(x.copy()); f_arch.append(fx)\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n                        if len(X_arch) > self.archive_size:\n                            del X_arch[0]; del f_arch[0]\n                        if evals >= self.budget:\n                            break\n\n            # end of generation\n\n        # store results\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DAPCA scored 0.091 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b0e7fc8a-1fa8-4e80-8412-4a023fed929e", "operator": null, "metadata": {"aucs": [0.1035933660665721, 0.1689062426998954, 0]}, "task_prompt": ""}
{"id": "4a84358e-9655-4695-bfb9-f8cfe3ca3fd6", "fitness": 0.19608495034708828, "name": "RAMP", "description": "RAMP maintains a low-rank search subspace B (rank ~ dim//4) with additive normalized direction weights w, a global mean m and step-size sigma, plus per-coordinate residual scales s to model anisotropic noise. It generates multiscale probes by sampling Gaussian steps inside the learned subspace combined with diagonal noise, occasionally performing heavy-tailed Cauchy “long jumps” and a ridge-regularized quadratic surrogate minimizer in subspace to propose directed moves. Learning is online from a FIFO archive: weighted PCA periodically refreshes B (favoring better points), w is adaptively updated by reward from projected steps, s is updated by EMA, and sigma is shrunk on success or slowly grown otherwise while mean updates are trust-clipped and probabilistically accepted (allowing uphill moves). To avoid stagnation the algorithm opportunistically restarts around the best point, reseeds local evaluations, and injects small random rotations to explore new subspace orientations.", "code": "import numpy as np\n\nclass RAMP:\n    \"\"\"\n    RAMP — Rotational Adaptive Multi-scale Probing\n\n    Main algorithmic ideas and (main) parameters:\n    - rank: low-rank subspace dimension (default ~ dim//4) stored as orthonormal basis B (dim x r).\n    - pop: number of candidate probes per generation (default 20).\n    - multiscale: relative scales for probes (default (0.2, 0.8, 2.5)).\n    - levy_prob: probability of a heavy-tailed long jump (Cauchy) (default 0.05).\n    - energy_lr: learning rate for additive direction-weight adaptations (default 0.12).\n    - s_lr: EMA learning rate for per-coordinate residual noise (default 0.05).\n    - pca_refresh: how often to refresh B from recent archive (default 8).\n    - sigma0_mult: initial sigma multiplier times avg_span (default 0.15).\n    - archive_size: number of recent evaluations retained (default 8*dim or 200).\n    - stagn_thresh_frac: fraction of budget to treat as stagnation window (default 0.05).\n    The algorithm differs from the provided one by using additive normalized weights (instead\n    of multiplicative energies), a Cauchy heavy-tailed long-jump, weighted PCA for basis refresh,\n    a ridge-regularized diagonal surrogate in the subspace, and different default hyper-parameters.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 rank=None, pop=20, archive_size=None, pca_refresh=8,\n                 multiscale=(0.2, 0.8, 2.5), levy_prob=0.05,\n                 energy_lr=0.12, s_lr=0.05, sigma0_mult=0.15,\n                 stagn_thresh_frac=0.05, restart_infl=2.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.rank = int(rank) if rank is not None else max(1, min(self.dim, max(1, self.dim // 4)))\n        self.pop = int(pop)\n        self.archive_size = archive_size if archive_size is not None else max(8 * self.dim, 200)\n        self.pca_refresh = int(pca_refresh)\n        self.multiscale = tuple(multiscale)\n        self.levy_prob = float(levy_prob)\n        self.energy_lr = float(energy_lr)\n        self.s_lr = float(s_lr)\n        self.sigma0_mult = float(sigma0_mult)\n        self.stagn_thresh_frac = float(stagn_thresh_frac)\n        self.restart_infl = float(restart_infl)\n\n        # safety clamps\n        self.min_w = 1e-8\n        self.min_s = 1e-6\n        self.max_s = 10.0\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds (Many Affine BBOB usually -5..5)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial mean randomly in bounds\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # initial sigma\n        sigma = max(1e-12, self.sigma0_mult * avg_span)\n\n        # low-rank orthonormal basis B and additive normalized weights w (sum-to-1)\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()\n            w = np.ones(r) / float(r)  # additive normalized direction weights\n        else:\n            B = np.zeros((self.dim, 0))\n            w = np.array([])\n\n        # per-coordinate residual noise scales\n        s = np.full(self.dim, 0.2)\n\n        # archive and bookkeeping\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # initial seeding to fill archive\n        seed_init = min(self.pop, max(4, int(self.budget // 150)))\n        for _ in range(seed_init):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # stagnation detection\n        stagn_limit = max(8, int(self.stagn_thresh_frac * self.budget))\n        stagn_counter = 0\n        gen = 0\n\n        def fit_ridge_diag_quadratic(U, y, ridge=1e-6):\n            # Fit y ≈ c + g^T u + 0.5 * diag(h) * u^2 with ridge regularization\n            k, rloc = U.shape\n            X = np.ones((k, 1 + 2 * rloc))\n            X[:, 1:1 + rloc] = U\n            X[:, 1 + rloc:] = U ** 2\n            # ridge by augmenting rows\n            reg_mat = ridge * np.eye(1 + 2 * rloc)\n            try:\n                # Solve normal equations with small ridge\n                XtX = X.T.dot(X) + reg_mat\n                Xty = X.T.dot(y)\n                theta = np.linalg.solve(XtX, Xty)\n            except Exception:\n                theta, *_ = np.linalg.lstsq(X, y, rcond=None)\n            c = float(theta[0])\n            g = theta[1:1 + rloc].astype(float)\n            hdiag = theta[1 + rloc:].astype(float)\n            # regularize hdiag magnitude to avoid tiny denominators\n            hdiag = np.sign(hdiag) * np.maximum(np.abs(hdiag), 1e-6)\n            return c, g, hdiag\n\n        while evals < self.budget:\n            gen += 1\n\n            # refresh B via weighted PCA on recent archive (weights favor better points)\n            if (gen % self.pca_refresh == 0) and len(X_arch) >= max(3, r):\n                K = min(len(X_arch), self.archive_size)\n                Xr = np.asarray(X_arch[-K:])\n                fr = np.asarray(f_arch[-K:])\n                # compute weights: better points get larger weight (softmin)\n                fmin = np.min(fr)\n                diff = fr - fmin\n                Tw = max(1e-8, 0.5 * np.std(fr) + 1e-8)\n                weights = np.exp(-diff / Tw)\n                weights = weights / (np.sum(weights) + 1e-12)\n                # weighted centered matrix\n                mean_w = np.sum(Xr * weights[:, None], axis=0)\n                D = (Xr - mean_w) * np.sqrt(weights[:, None])\n                try:\n                    # use SVD of D to get principal components\n                    U_s, S_s, Vt = np.linalg.svd(D, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        B_new = Vt[:r_eff].T\n                        # blend gently to avoid abrupt changes\n                        B = 0.7 * B + 0.3 * B_new\n                        Q, _ = np.linalg.qr(B)\n                        B = Q[:, :r_eff]\n                except np.linalg.LinAlgError:\n                    pass\n\n            n_candidates = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_candidates):\n                if evals >= self.budget:\n                    break\n\n                strategy = 'base'\n                candidate = None\n                cand_step = None\n\n                # heavy-tailed long jump via scaled Cauchy (levy-like)\n                if rng.rand() < self.levy_prob:\n                    # standard cauchy can be heavy; scale by avg_span and clamp\n                    c = rng.standard_cauchy(size=self.dim)\n                    # limit extremes\n                    c = np.tanh(c / 3.0)  # compress extreme tails but keep heavy-tailed nature\n                    candidate = m + 3.0 * avg_span * c\n                    candidate = np.minimum(np.maximum(candidate, lb), ub)\n                    strategy = 'cauchy'\n                    cand_step = candidate - m\n\n                # surrogate-based minimizer in subspace (ridge-regularized)\n                elif r > 0 and len(X_arch) >= max(6, r + 2) and rng.rand() < 0.12:\n                    K = min(len(X_arch), self.archive_size)\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    U = (Xr - m).dot(B)  # subspace coords\n                    try:\n                        c_s, g_s, hdiag = fit_ridge_diag_quadratic(U, fr, ridge=1e-5)\n                        # propose u* = -g / (hdiag + lambda) with damping\n                        lambda_reg = 1e-2 + 0.1 * np.mean(np.abs(hdiag))\n                        u_star = -g_s / (hdiag + lambda_reg)\n                        # clamp in subspace norm\n                        max_u = 5.0 * sigma\n                        u_norm = np.linalg.norm(u_star)\n                        if u_norm > max_u:\n                            u_star = u_star * (max_u / (u_norm + 1e-12))\n                        candidate = m + B.dot(u_star)\n                        candidate = np.minimum(np.maximum(candidate, lb), ub)\n                        cand_step = candidate - m\n                        strategy = 'surrogate'\n                    except Exception:\n                        candidate = None\n\n                # default: subspace-guided stochastic probe\n                if candidate is None:\n                    scale = self.multiscale[rng.randint(len(self.multiscale))]\n                    if r > 0:\n                        # sample z in subspace with per-direction std scaled by sqrt(w)\n                        z_r = rng.randn(r) * np.sqrt(np.maximum(w, self.min_w))\n                        low = B.dot(z_r)\n                    else:\n                        low = np.zeros(self.dim)\n                    diag_noise = rng.randn(self.dim) * s\n                    step = scale * sigma * (low + diag_noise)\n                    # small random orthonormal rotation occasionally\n                    if r > 0 and rng.rand() < 0.06:\n                        R = rng.randn(r, r) * 0.04\n                        try:\n                            Qr, _ = np.linalg.qr(np.eye(r) + R)\n                            z_r2 = Qr.dot(z_r)\n                            step = scale * sigma * (B.dot(z_r2) + diag_noise)\n                        except Exception:\n                            pass\n                    candidate = np.minimum(np.maximum(m + step, lb), ub)\n                    cand_step = candidate - m\n                    strategy = 'subspace'\n\n                # evaluate\n                f_c = float(func(candidate))\n                evals += 1\n\n                # archive FIFO\n                X_arch.append(candidate.copy())\n                f_arch.append(f_c)\n                if len(X_arch) > self.archive_size:\n                    del X_arch[0]; del f_arch[0]\n\n                improved = False\n                if f_c < f_best:\n                    f_best = f_c\n                    x_best = candidate.copy()\n                    improved = True\n                    stagn_counter = 0\n                else:\n                    stagn_counter += 1\n\n                # update additive direction weights w using reward per projected length\n                if r > 0 and cand_step is not None:\n                    u_proj = B.T.dot(cand_step)\n                    u_norm = np.linalg.norm(u_proj) + 1e-12\n                    # reward: relative improvement compared to current best of archive\n                    best_recent = np.min(f_arch) if len(f_arch) > 0 else f_best\n                    reward = max(0.0, (best_recent - f_c)) / (sigma * u_norm + 1e-12)\n                    if improved:\n                        reward += 0.25\n                    if np.any(np.abs(u_proj) > 0):\n                        contrib = np.abs(u_proj) / (np.sum(np.abs(u_proj)) + 1e-12)\n                        # additive update then renormalize\n                        w = (1.0 - self.energy_lr) * w + self.energy_lr * (contrib * (1.0 + reward))\n                        # ensure positivity and normalize\n                        w = np.maximum(w, self.min_w)\n                        w = w / (np.sum(w) + 1e-12)\n\n                # update per-coordinate residual scales s via EMA\n                if cand_step is not None:\n                    abs_step_norm = np.abs(cand_step) / (sigma + 1e-12)\n                    # smooth update, clamp extremes\n                    s = (1.0 - self.s_lr) * s + self.s_lr * np.clip(abs_step_norm, self.min_s, self.max_s)\n\n                # acceptance: either improvement (global) or probabilistic uphill with temperature decreasing with sigma\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    T = max(1e-12, 0.4 * sigma * avg_span)\n                    # allow uphill with probability exp(-(fc - f_best)/T)\n                    if rng.rand() < np.exp(-max(0.0, f_c - f_best) / (T + 1e-12)):\n                        accept = True\n\n                if accept:\n                    # learning rate for updating mean depends on strategy\n                    if strategy == 'surrogate':\n                        lr = 0.7\n                    elif strategy == 'cauchy':\n                        lr = 0.35\n                    elif strategy == 'subspace':\n                        lr = 0.3\n                    else:\n                        lr = 0.2\n                    delta = candidate - m\n                    # trust clipping proportional to sigma * sqrt(dim)\n                    trust = 5.0 * sigma * np.sqrt(self.dim)\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                    # adaptive sigma: reduce on success more aggressively, small growth otherwise\n                    sigma = max(1e-12, sigma * (0.88 if improved else 0.98))\n                else:\n                    # small jitter around mean to encourage exploration\n                    m = np.minimum(np.maximum(m + 0.02 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma = sigma * 1.015\n\n                # small random rotation of B to keep exploring new subspace orientations\n                if r > 0 and rng.rand() < 0.04:\n                    Qr = rng.randn(r, r) * 0.06\n                    try:\n                        Qr_orth, _ = np.linalg.qr(np.eye(r) + Qr)\n                        B = B.dot(Qr_orth)\n                        Q2, _ = np.linalg.qr(B)\n                        B = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # opportunistic restart on stagnation\n                if stagn_counter >= stagn_limit and evals < self.budget:\n                    stagn_counter = 0\n                    # reset around best with jitter\n                    jitter = max(0.04 * avg_span, 0.8 * sigma)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma = max(sigma * self.restart_infl, 0.2 * avg_span)\n                    # reset weights and residuals partly and randomize B\n                    if r > 0:\n                        w = np.ones(r) / float(r)\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :r]\n                    s = np.full(self.dim, 0.2)\n                    # reseed a few evaluations around best to refresh archive\n                    for _ in range(min(6, self.budget - evals)):\n                        x = np.minimum(np.maximum(x_best + 0.05 * avg_span * rng.randn(self.dim), lb), ub)\n                        f = float(func(x))\n                        evals += 1\n                        X_arch.append(x.copy()); f_arch.append(f)\n                        if f < f_best:\n                            f_best = f; x_best = x.copy()\n                        if len(X_arch) > self.archive_size:\n                            del X_arch[0]; del f_arch[0]\n                        if evals >= self.budget:\n                            break\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm RAMP scored 0.196 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b0e7fc8a-1fa8-4e80-8412-4a023fed929e", "operator": null, "metadata": {"aucs": [0.09627869308544434, 0.16072264764313704, 0.27586942951915727, 0.21746118521504776, 0.19112077911174963, 0.23453938512706385, 0.22468854834357432, 0.22641273745702084, 0.19171715219450602, 0.14203894577418164]}, "task_prompt": ""}
{"id": "c6395d4f-eae1-4acc-bfba-1659755ed4b5", "fitness": "-inf", "name": "STRIDE", "description": "STRIDE maintains a central mean m and an adaptive trust-radius sigma (initialized small via sigma0_mult) and samples around m using a low-rank orthonormal subspace P plus per-coordinate RMS-like residuals s to blend anisotropic noise, which gives cheap, directional exploration while keeping most search power in a compact subspace. Sampling effort is soft-allocated across multiple relative scales with a reward-weighted softmax (scales, pop) and often uses mirrored paired probes to produce low-variance directional signals, while a compact additive direction memory (dir_memory, updated with dir_lr) biases future samples toward historically productive directions. The algorithm keeps a FIFO archive to drive occasional PCA refreshes of P, fits cheap weighted diagonal-quadratic surrogates in the subspace for local refinement, and performs rare “teleport” elite recombinations (teleport_prob) and probabilistic acceptance (trust-dependent temperature) to enable both local refinement and global jumps. Adaptive controls (sigma and self.trust updated from recent success ratios), conservative mean updates/Trust clipping, opportunistic stagnation restarts with reseeding, and periodic surrogate/evaluation budgeting together balance robustness, exploration, and exploitation for diverse continuous landscapes.", "code": "import numpy as np\n\nclass STRIDE:\n    \"\"\"\n    STRIDE: Stochastic Trust-Region with Integrated Directional Equilibria\n\n    Main ingredients (high-level):\n    - Maintain a mean m, an adaptive trust radius `sigma`, a low-rank subspace P\n      and an additive direction memory (replay buffer) that biases sampling additively.\n    - Soft-allocate sampling effort across multiple relative scales via a scale-reward softmax.\n    - Use mirrored paired probes (x+ and x-) to produce low-variance directional signals when budget permits.\n    - Occasionally fit a cheap weighted diagonal-quadratic surrogate in the subspace to propose a local minimizer.\n    - A \"teleport\" recombination between elites provides rare global jumps.\n    - Adaptive trust update rules expand on repeated success and shrink on failure; ephemeral restarts on stagnation.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 rank=None, pop=18, archive_size=None, scales=(0.25, 1.0, 3.0),\n                 teleport_prob=0.04, dir_lr=0.18, s_lr=0.12, sigma0_mult=0.18,\n                 trust_init=1.0, stagn_frac=0.06, elite_k=6):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.rank = int(rank) if rank is not None else max(1, min(self.dim, max(1, self.dim // 5)))\n        self.pop = int(pop)\n        self.archive_size = archive_size if archive_size is not None else max(6 * self.dim, 120)\n        self.scales = tuple(scales)\n        self.teleport_prob = float(teleport_prob)\n        self.dir_lr = float(dir_lr)   # additive direction memory learning rate\n        self.s_lr = float(s_lr)       # EMA for per-coordinate residuals (RMS-like)\n        self.sigma0_mult = float(sigma0_mult)\n        self.trust = float(trust_init)\n        self.stagn_frac = float(stagn_frac)\n        self.elite_k = int(elite_k)\n\n        # clamps for stability\n        self.min_s = 1e-6\n        self.max_s = 10.0\n        self.min_sigma = 1e-12\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize mean uniformly in bounds\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # initial trust/sigma (search radius)\n        sigma = max(self.min_sigma, self.sigma0_mult * avg_span)\n\n        # low-rank orthonormal subspace P (dim x r)\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            P = Q[:, :r].copy()\n        else:\n            P = np.zeros((self.dim, 0))\n\n        # additive direction memory (store a set of canonical direction vectors and weights)\n        dir_memory = []  # list of (vector, weight); vector unit-norm in R^d\n        max_dir_memory = max(6, r * 3)\n\n        # per-coordinate RMS-like residuals for isotropic noise blending\n        s = np.full(self.dim, 0.35)\n\n        # soft allocation rewards for scales (kept as mean reward estimate)\n        scale_rewards = np.zeros(len(self.scales))\n        scale_counts = np.ones(len(self.scales)) * 1e-6  # prevent divide-by-zero\n\n        # evaluation archive (FIFO)\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # initial seeding: small random pool to build archive and initial best\n        seed_init = min(self.pop * 2, max(8, int(self.budget // 250)))\n        for _ in range(seed_init):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            X_arch.append(x0.copy()); f_arch.append(f0)\n            evals += 1\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            X_arch.append(x0.copy()); f_arch.append(f0)\n            evals += 1\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # stagnation tracking (number of consecutive candidate generations without improvement)\n        stagn_limit = max(6, int(self.stagn_frac * self.budget))\n        stagn_counter = 0\n\n        # sliding window for recent success ratio to adapt trust\n        recent_attempts = 0\n        recent_successes = 0\n        success_window = 60\n\n        gen = 0\n        # helper: fit cheap weighted diagonal-quadratic surrogate in P-subspace\n        def fit_weighted_diag_quad(U, y, weights):\n            # U: (k,r) subspace coords, y: (k,), weights: (k,)\n            k, rloc = U.shape\n            W = np.sqrt(np.maximum(weights, 1e-12))\n            # design: [1 | u | u^2] as columns\n            X = np.ones((k, 1 + 2 * rloc))\n            X[:, 1:1 + rloc] = U\n            X[:, 1 + rloc:] = U ** 2\n            Xw = X * W[:, None]\n            yw = y * W\n            try:\n                theta, *_ = np.linalg.lstsq(Xw, yw, rcond=None)\n            except Exception:\n                theta = np.zeros(1 + 2 * rloc)\n            c = float(theta[0])\n            g = theta[1:1 + rloc].astype(float)\n            hdiag = theta[1 + rloc:].astype(float)\n            # regularize Hessian diagonal so inversion is stable\n            hdiag = np.sign(hdiag) * np.maximum(np.abs(hdiag), 1e-6)\n            return c, g, hdiag\n\n        while evals < self.budget:\n            gen += 1\n\n            # softmax on scale rewards to get sampling probabilities\n            beta = 4.0  # sharpness of allocation\n            norm_rewards = (scale_rewards / (scale_counts + 1e-12))\n            # shift for numerical stability\n            z = norm_rewards - np.max(norm_rewards)\n            expz = np.exp(beta * z)\n            p_scales = expz / (np.sum(expz) + 1e-12)\n\n            # possibly refresh subspace P via simple PCA on recent archive every few gens\n            if gen % max(4, min(20, self.dim // 2)) == 0 and len(X_arch) >= max(3, r):\n                K = min(len(X_arch), self.archive_size)\n                Xr = np.asarray(X_arch[-K:])\n                D = Xr - np.mean(Xr, axis=0, keepdims=True)\n                try:\n                    U_s, S_s, Vt = np.linalg.svd(D, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        P_new = Vt[:r_eff].T\n                        # blend slowly to avoid abrupt flips\n                        P = 0.85 * P + 0.15 * P_new\n                        Q, _ = np.linalg.qr(P)\n                        P = Q[:, :r_eff]\n                except Exception:\n                    pass\n\n            # decide how many candidate probes for this generation (bounded by remaining evals)\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            # for each candidate produce 1 or 2 evaluations (mirrored)\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                # choose whether to teleport (rare recombination of elites)\n                if rng.rand() < self.teleport_prob and len(X_arch) >= 4:\n                    # pick two distinct elites (from top-k)\n                    k = min(self.elite_k, len(X_arch))\n                    idxs = np.argsort(f_arch)[:k]\n                    a, b = rng.choice(idxs, size=2, replace=False)\n                    # differential recombination with random mixture\n                    lam = rng.randn() * 0.8\n                    candidate = np.clip(X_arch[a] + lam * (X_arch[b] - X_arch[a]) + 0.02 * avg_span * rng.randn(self.dim), lb, ub)\n                    strategy = 'teleport'\n                    # single eval\n                    f_c = float(func(candidate))\n                    evals += 1\n                    # update archive\n                    X_arch.append(candidate.copy()); f_arch.append(f_c)\n                    if len(X_arch) > self.archive_size:\n                        del X_arch[0]; del f_arch[0]\n                    improved = False\n                    if f_c < f_best:\n                        f_best = f_c; x_best = candidate.copy(); improved = True; stagn_counter = 0\n                    else:\n                        stagn_counter += 1\n                    # treat teleport as small-scale exploration: attribute reward to smallest scale index\n                    si = 0\n                    scale_counts[si] += 1\n                    scale_rewards[si] += max(0.0, f_best - f_c)\n                    recent_attempts += 1\n                    recent_successes += 1 if improved else 0\n                    # update s via EMA of absolute step\n                    step = candidate - m\n                    s = (1 - self.s_lr) * s + self.s_lr * np.clip(np.abs(step) / (sigma + 1e-12), self.min_s, self.max_s)\n                    # maybe accept mean with damped lr if improved\n                    if improved:\n                        lr = 0.5\n                        delta = candidate - m\n                        m = np.clip(m + lr * delta, lb, ub)\n                        sigma = max(self.min_sigma, sigma * 0.92)\n                    else:\n                        sigma *= 1.01\n                    # update trust adaptively\n                    if recent_attempts >= success_window:\n                        succ_ratio = recent_successes / recent_attempts\n                        if succ_ratio > 0.2:\n                            self.trust *= 1.03\n                        else:\n                            self.trust *= 0.95\n                        recent_attempts = recent_successes = 0\n                    continue\n\n                # otherwise pick a scale using p_scales\n                si = int(rng.choice(len(self.scales), p=p_scales))\n                scale = self.scales[si]\n\n                # build a directional bias from dir_memory: additive weighted sum\n                bias = np.zeros(self.dim)\n                if dir_memory:\n                    # sample one memory direction with probability proportional to weight\n                    weights = np.array([w for (_, w) in dir_memory])\n                    if np.sum(weights) > 0:\n                        probs = weights / (np.sum(weights) + 1e-12)\n                        idx = rng.choice(len(dir_memory), p=probs)\n                        bias = dir_memory[idx][0] * (0.5 * rng.rand())  # scaled bias\n                    else:\n                        bias = np.zeros(self.dim)\n\n                # sample subspace component (if r > 0)\n                if r > 0:\n                    z = rng.randn(r)\n                    sub = P.dot(z)\n                else:\n                    sub = np.zeros(self.dim)\n                # coordinate residual noise\n                noise = rng.randn(self.dim) * s\n                step = scale * sigma * (sub + noise) + 0.5 * sigma * bias\n                # mirrored probe: try to evaluate both + and - if budget allows (helps gradient sign)\n                x_plus = np.clip(m + step, lb, ub)\n                x_minus = np.clip(m - step, lb, ub)\n\n                # decide if we can evaluate both (use one if only one eval left)\n                if evals + 2 <= self.budget:\n                    f_plus = float(func(x_plus)); f_minus = float(func(x_minus))\n                    evals += 2\n                    # archive both\n                    X_arch.append(x_plus.copy()); f_arch.append(f_plus)\n                    X_arch.append(x_minus.copy()); f_arch.append(f_minus)\n                    if len(X_arch) > self.archive_size:\n                        # remove oldest twice\n                        del X_arch[0]; del f_arch[0]\n                        if len(X_arch) > self.archive_size:\n                            del X_arch[0]; del f_arch[0]\n                    # use the better of two as candidate evaluation\n                    if f_plus <= f_minus:\n                        candidate = x_plus; f_c = f_plus; other = x_minus; f_other = f_minus\n                    else:\n                        candidate = x_minus; f_c = f_minus; other = x_plus; f_other = f_plus\n                    # gradient-like directional signal: directional derivative estimate along step\n                    dir_deriv = (f_plus - f_minus) / (2.0 * (np.linalg.norm(step) + 1e-12))\n                    strategy = 'mirrored'\n                    # reward measure: improvement over best\n                    reward = max(0.0, f_best - f_c)\n                    # update scale stats\n                    scale_counts[si] += 2\n                    scale_rewards[si] += reward\n                else:\n                    # only one eval left: evaluate plus\n                    f_c = float(func(x_plus))\n                    evals += 1\n                    X_arch.append(x_plus.copy()); f_arch.append(f_c)\n                    if len(X_arch) > self.archive_size:\n                        del X_arch[0]; del f_arch[0]\n                    candidate = x_plus\n                    strategy = 'single'\n                    reward = max(0.0, f_best - f_c)\n                    scale_counts[si] += 1\n                    scale_rewards[si] += reward\n                    dir_deriv = None\n\n                # update best and counters\n                improved = False\n                if f_c < f_best:\n                    f_best = f_c; x_best = candidate.copy(); improved = True; stagn_counter = 0\n                else:\n                    stagn_counter += 1\n\n                recent_attempts += 1\n                recent_successes += 1 if improved else 0\n\n                # update per-coordinate residuals s using RMS-like EMA on absolute step normalized by sigma\n                abs_step_norm = np.abs(candidate - m) / (sigma + 1e-12)\n                s = (1.0 - self.s_lr) * s + self.s_lr * np.clip(abs_step_norm, self.min_s, self.max_s)\n\n                # update direction memory using directional reward signals:\n                # construct a normalized direction vector from the accepted-improvement direction (candidate - m)\n                step_vec = candidate - m\n                nrm = np.linalg.norm(step_vec)\n                if nrm > 1e-12:\n                    dir_vec = step_vec / (nrm + 1e-12)\n                    # assign weight proportional to improvement per step length (clamped)\n                    w = (max(0.0, (f_best + 1e-12) - f_c)) / (nrm + 1e-12)\n                    # small floor and scaling\n                    w = max(1e-6, w)\n                    # update existing memory if direction similar, else append\n                    merged = False\n                    for i, (v, wt) in enumerate(dir_memory):\n                        if np.dot(v, dir_vec) > 0.85:\n                            # additive update to vector and weight (moving average)\n                            new_v = (1.0 - self.dir_lr) * v + self.dir_lr * dir_vec\n                            new_v = new_v / (np.linalg.norm(new_v) + 1e-12)\n                            dir_memory[i] = (new_v, (1.0 - self.dir_lr) * wt + self.dir_lr * w)\n                            merged = True\n                            break\n                    if not merged:\n                        dir_memory.append((dir_vec, w))\n                    # prune memory if too large: keep largest weights\n                    if len(dir_memory) > max_dir_memory:\n                        dir_memory = sorted(dir_memory, key=lambda it: it[1], reverse=True)[:max_dir_memory]\n\n                # sometimes fit a local surrogate in subspace and propose a refined minimizer\n                if r > 0 and len(X_arch) >= max(6, r + 3) and rng.rand() < 0.12:\n                    K = min(len(X_arch), min(self.archive_size, 2 * (r + 10)))\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    U = (Xr - m).dot(P)  # project into subspace coords\n                    # weights based on proximity to m in ambient space\n                    dists = np.linalg.norm(Xr - m, axis=1)\n                    wts = np.exp(- (dists / (1.5 * sigma + 1e-12)) ** 2)\n                    try:\n                        c_q, g_q, h_q = fit_weighted_diag_quad(U, fr, wts)\n                        # propose minimizer in subspace: u* = -g / h (element-wise)\n                        u_star = -g_q / (h_q + 1e-8)\n                        # clip large subspace moves\n                        max_u_norm = 4.0 * sigma\n                        u_norm = np.linalg.norm(u_star)\n                        if u_norm > max_u_norm:\n                            u_star = u_star * (max_u_norm / (u_norm + 1e-12))\n                        cand_sur = np.clip(m + P.dot(u_star), lb, ub)\n                        # careful: only evaluate if we have budget\n                        if evals < self.budget:\n                            f_sur = float(func(cand_sur)); evals += 1\n                            X_arch.append(cand_sur.copy()); f_arch.append(f_sur)\n                            if len(X_arch) > self.archive_size:\n                                del X_arch[0]; del f_arch[0]\n                            # treat as candidate with possible strong acceptance\n                            if f_sur < f_best:\n                                f_best = f_sur; x_best = cand_sur.copy(); improved = True; stagn_counter = 0\n                                # shift mean aggressively towards surrogate minimizer\n                                m = np.clip(0.7 * m + 0.3 * cand_sur, lb, ub)\n                                sigma = max(self.min_sigma, sigma * 0.85)\n                                # add direction memory entry for this step\n                                step_s = cand_sur - m\n                                nrm_s = np.linalg.norm(step_s)\n                                if nrm_s > 1e-12:\n                                    dir_memory.append((step_s / nrm_s, max(1e-6, (f_best - f_sur) / (nrm_s + 1e-12))))\n                            else:\n                                # penalize trust slightly\n                                sigma *= 1.02\n                    except Exception:\n                        pass\n\n                # acceptance policy for the candidate: accept into mean probabilistically for exploration\n                accept = False\n                # always accept if improved global best (we already updated best)\n                if improved:\n                    accept = True\n                else:\n                    # probabilistic uphill acceptance with temperature proportional to current trust * avg_span\n                    T = max(1e-12, 0.6 * self.trust * avg_span)\n                    delta_f = (f_c - f_best)\n                    if rng.rand() < np.exp(-max(0.0, delta_f) / (T + 1e-12)):\n                        accept = True\n\n                if accept:\n                    # damped update of mean; learning rate depends on scale (smaller scale -> larger lr)\n                    if scale <= sorted(self.scales)[0]:\n                        lr = 0.45\n                    elif scale >= sorted(self.scales)[-1]:\n                        lr = 0.18\n                    else:\n                        lr = 0.28\n                    delta = candidate - m\n                    # trust clipping: don't jump further than trust * sqrt(dim)\n                    trust_clip = max(1e-9, 6.0 * self.trust * np.sqrt(self.dim))\n                    dnorm = np.linalg.norm(delta)\n                    if dnorm > trust_clip:\n                        delta = delta * (trust_clip / (dnorm + 1e-12))\n                    m = np.clip(m + lr * delta, lb, ub)\n                    # on accept reduce sigma slightly (local refinement)\n                    sigma = max(self.min_sigma, sigma * (0.92 if improved else 0.97))\n                    recent_successes += 1 if improved else 0\n                else:\n                    # small random jitter to mean to encourage exploration\n                    m = np.clip(m + 0.02 * avg_span * rng.randn(self.dim), lb, ub)\n                    # expand sigma slightly\n                    sigma = sigma * 1.02\n\n                # adapt trust using sliding window of successes\n                if recent_attempts >= success_window:\n                    succ_ratio = recent_successes / recent_attempts\n                    if succ_ratio > 0.2:\n                        self.trust *= 1.04\n                    elif succ_ratio < 0.08:\n                        self.trust *= 0.92\n                    recent_attempts = recent_successes = 0\n\n                # if stagnation: opportunistic restart centered on current best with added diversity\n                if stagn_counter >= stagn_limit and evals < self.budget:\n                    stagn_counter = 0\n                    # jitter around best\n                    jitter = max(0.06 * avg_span, 0.8 * sigma)\n                    m = np.clip(x_best + jitter * rng.randn(self.dim), lb, ub)\n                    sigma = max(sigma * 1.6, 0.25 * avg_span)\n                    # partially reset P and directional memory\n                    if r > 0:\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        P = Q[:, :r]\n                    dir_memory = []\n                    s = np.full(self.dim, 0.35)\n                    # reseed a few local probes around best to refresh archive\n                    for _j in range(min(6, self.budget - evals)):\n                        xr = np.clip(x_best + 0.07 * avg_span * rng.randn(self.dim), lb, ub)\n                        fr = float(func(xr))\n                        evals += 1\n                        X_arch.append(xr.copy()); f_arch.append(fr)\n                        if fr < f_best:\n                            f_best = fr; x_best = xr.copy()\n                        if len(X_arch) > self.archive_size:\n                            del X_arch[0]; del f_arch[0]\n                        if evals >= self.budget:\n                            break\n\n            # end of generation batch\n\n        # final store\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 999, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: probabilities do not sum to 1", "error": "In the code, line 999, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: probabilities do not sum to 1", "parent_ids": "b0e7fc8a-1fa8-4e80-8412-4a023fed929e", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "cf65efde-5dfd-4e3b-a147-8e096ae44a9b", "fitness": 0.16975602618765867, "name": "DRSE_DA", "description": "The algorithm maintains a low‑rank orthonormal subspace B (default rank ≈ dim/4) plus per‑direction additive “energies” e and per‑coordinate residual scales s to bias multiscale Gaussian sampling: steps are mixtures of subspace-projected noise (scaled by e) and coordinate-wise noise (s), with occasional small orthogonal rotations. It fits a cheap ridge‑regularized diagonal quadratic surrogate in the subspace to propose targeted minimizers (u* = −g/h) and uses multiscale stochastic probes plus rare Levy‑like uniform jumps for global exploration. Energies e are updated additively by reward proportional to improvement per projected length, sigma is adapted via recent success rates and annealed acceptance (simulated‑annealing temperature), and a FIFO archive with periodic PCA refresh steers the basis B toward recently observed variances. Opportunistic restarts, bounded trust updates to the mean, and safety clamps on energies/sigma/s ensure robustness under the fixed budget and [-5,5] bounds.", "code": "import numpy as np\n\nclass DRSE_DA:\n    \"\"\"\n    Dynamic Resilient Subspace Evolution with Directional Annealing (DRSE-DA)\n\n    Main ideas (concise):\n    - Maintain a low-rank orthonormal subspace B (dim x r) and additive direction energies `e`\n      that bias Gaussian sampling inside the subspace.\n    - Fit a cheap ridge-regularized diagonal-quadratic surrogate in the subspace to propose targeted minimizers.\n    - Multiscale stochastic probes combine subspace-projected Gaussian steps and per-coordinate residual noise.\n    - Occasional Levy-like uniform jumps for global exploration.\n    - Additive (not multiplicative) energy updates based on reward per projected length.\n    - Simulated-annealing style uphill acceptance with temperature decaying over generations.\n    - Opportunistic restarts on stagnation and FIFO archive maintenance.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 rank=None, pop=24, archive_size=None, surv_size=300,\n                 pca_refresh=8, multiscale=(0.2, 0.8, 2.5),\n                 levy_prob=0.06, energy_lr=0.12, s_lr=0.08,\n                 sigma0_mult=0.15, stagn_thresh_frac=0.04, restart_infl=2.2,\n                 ridge_lambda=1e-3, temp0_mult=0.8):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        # parameters (different defaults than original MAGES)\n        self.rank = int(rank) if rank is not None else max(1, min(self.dim, max(1, self.dim // 4)))\n        self.pop = int(pop)\n        self.archive_size = archive_size if archive_size is not None else max(8 * self.dim, 200)\n        self.surv_size = int(surv_size)\n        self.pca_refresh = int(pca_refresh)\n        self.multiscale = tuple(multiscale)\n        self.levy_prob = float(levy_prob)\n        self.energy_lr = float(energy_lr)     # additive energy learning rate\n        self.s_lr = float(s_lr)               # EMA learning rate for per-coordinate residuals\n        self.sigma0_mult = float(sigma0_mult)\n        self.stagn_thresh_frac = float(stagn_thresh_frac)\n        self.restart_infl = float(restart_infl)\n        self.ridge_lambda = float(ridge_lambda)\n        self.temp0_mult = float(temp0_mult)\n\n        # safety clamps\n        self.min_energy = 1e-6\n        self.max_energy = 1e2\n        self.min_s = 1e-6\n        self.max_s = 5.0\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds (Many Affine BBOB standard -5..5)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial mean uniformly\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # initial sigma\n        sigma = max(1e-12, self.sigma0_mult * avg_span)\n\n        # low-rank orthonormal basis B (dim x r) and additive energies e\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()\n            e = np.ones(r)  # additive energies\n        else:\n            B = np.zeros((self.dim, 0))\n            e = np.array([])\n\n        # per-coordinate residual noise scales (diag)\n        s = np.full(self.dim, 0.35)\n\n        # archive and bookkeeping\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # seed initial archive (small batch)\n        seed_init = min(self.pop, max(8, int(self.budget // 300)))\n        for _ in range(seed_init):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        # ensure at least one eval\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy())\n            f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # stagnation detection\n        stagn_limit = max(8, int(self.stagn_thresh_frac * self.budget))\n        stagn_counter = 0\n        gen = 0\n\n        # keep track of sliding success rate to adapt sigma\n        recent_successes = 0\n        recent_trials = 0\n        adapt_window = max(10, self.pop)\n\n        # helper: fit ridge diagonal-quadratic in subspace coords U -> y\n        def fit_ridge_diag_quadratic(U, y, ridge):\n            # U: (k,r), y: (k,)\n            k, rloc = U.shape\n            # design: [1, u1..ur, u1^2..ur^2]\n            P = 1 + 2 * rloc\n            X = np.ones((k, P))\n            X[:, 1:1 + rloc] = U\n            X[:, 1 + rloc:] = U * U\n            # ridge regularization via augmentation\n            # append sqrt(ridge) * I rows to X (except bias row) with zero targets\n            if ridge > 0:\n                sqrt_r = np.sqrt(ridge)\n                # shape of reg block: P x P identity scaled -> we can add P rows\n                X_aug = np.vstack([X, sqrt_r * np.eye(P)])\n                y_aug = np.concatenate([y, np.zeros(P)])\n            else:\n                X_aug = X\n                y_aug = y\n            try:\n                theta, *_ = np.linalg.lstsq(X_aug, y_aug, rcond=None)\n            except Exception:\n                theta = np.zeros(P)\n            c = float(theta[0])\n            g = theta[1:1 + rloc].astype(float)\n            hdiag = theta[1 + rloc:].astype(float)\n            # ensure hdiag is not too small to avoid huge steps; clip to signed minimum\n            hdiag = np.sign(hdiag) * np.maximum(np.abs(hdiag), 1e-7)\n            return c, g, hdiag\n\n        # annealing temperature schedule base\n        temp0 = self.temp0_mult * sigma * avg_span\n        temp_decay = 0.995  # per generation multiplier\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n\n            # optional PCA refresh of B using recent archive deltas, different blend and frequency\n            if (gen % self.pca_refresh == 0) and len(X_arch) >= max(4, r):\n                K = min(len(X_arch), self.surv_size)\n                Xr = np.asarray(X_arch[-K:])\n                Dmat = Xr - np.mean(Xr, axis=0, keepdims=True)\n                try:\n                    # SVD on Dmat for principal directions\n                    U_s, S_s, Vt = np.linalg.svd(Dmat, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        B_new = Vt[:r_eff].T\n                        # align sign to old basis columns\n                        for k2 in range(r_eff):\n                            if np.dot(B[:, k2], B_new[:, k2]) < 0:\n                                B_new[:, k2] *= -1.0\n                        # blend more aggressively toward new structure than original\n                        B = 0.6 * B + 0.4 * B_new\n                        Q, _ = np.linalg.qr(B)\n                        B = Q[:, :r_eff]\n                        # additive energies nudged toward variances in projected deltas\n                        if e.size > 0:\n                            proj_var = np.var(Dmat.dot(B), axis=0) + 1e-8\n                            # additive update (keeps mean scale)\n                            e = 0.85 * e + 0.15 * (proj_var / (np.mean(proj_var) + 1e-12))\n                            e = np.clip(e, self.min_energy, self.max_energy)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # generate a small batch of candidates (bounded by budget)\n            n_candidates = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_candidates):\n                if evals >= self.budget:\n                    break\n\n                # decide strategy\n                strategy = 'base'\n                candidate = None\n                cand_step = None\n                coin = rng.rand()\n\n                # Levy-like global jump\n                if rng.rand() < self.levy_prob:\n                    candidate = rng.uniform(lb, ub, size=self.dim)\n                    strategy = 'levy'\n\n                # surrogate-based proposal with larger probability when archive rich\n                use_surrogate_prob = 0.28 if len(X_arch) > max(30, r * 6) else 0.08\n                if candidate is None and coin < use_surrogate_prob and r > 0 and len(X_arch) >= max(6, r + 4):\n                    K = min(len(X_arch), self.surv_size)\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    # project delta from mean m into subspace coords\n                    U = (Xr - m).dot(B)  # (K, r)\n                    try:\n                        c_s, g_s, hdiag = fit_ridge_diag_quadratic(U, fr, self.ridge_lambda)\n                        # propose minimizer in subspace coords: u* = -g / h\n                        # guard against small denominators\n                        denom = hdiag + 1e-8\n                        u_star = -g_s / denom\n                        # clip magnitude of u_star in subspace\n                        u_norm = np.linalg.norm(u_star)\n                        max_u = 6.0 * sigma  # different scale constant\n                        if u_norm > max_u and u_norm > 0:\n                            u_star = u_star * (max_u / (u_norm + 1e-12))\n                        candidate = m + B.dot(u_star)\n                        cand_step = B.dot(u_star)\n                        strategy = 'surrogate'\n                    except Exception:\n                        candidate = None\n\n                # default subspace-guided stochastic probe\n                if candidate is None:\n                    scale = self.multiscale[rng.randint(len(self.multiscale))]\n                    if r > 0:\n                        # sample in r-dim with additive energy bias (energies add to variance)\n                        z_r = rng.randn(r) * (1.0 + e)  # additive energy enters as shift in stdev\n                        low = B.dot(z_r)\n                    else:\n                        low = np.zeros(self.dim)\n                    diag_noise = rng.randn(self.dim) * s\n                    step = scale * sigma * (low + diag_noise)\n                    # small random orthogonal perturbation in subspace sometimes\n                    if rng.rand() < 0.09 and r > 0:\n                        R = rng.randn(r, r) * 0.04\n                        try:\n                            Qr, _ = np.linalg.qr(np.eye(r) + R)\n                            step = scale * sigma * (B.dot(Qr.dot(rng.randn(r) * (1.0 + e))) + diag_noise)\n                        except Exception:\n                            pass\n                    candidate = m + step\n                    cand_step = step\n                    strategy = 'subspace'\n\n                # clip to bounds and evaluate\n                candidate = np.minimum(np.maximum(candidate, lb), ub)\n                f_c = float(func(candidate))\n                evals += 1\n\n                # FIFO archive\n                X_arch.append(candidate.copy())\n                f_arch.append(f_c)\n                if len(X_arch) > self.archive_size:\n                    del X_arch[0]; del f_arch[0]\n\n                # improved?\n                improved = False\n                if f_c < f_best:\n                    f_best = f_c\n                    x_best = candidate.copy()\n                    improved = True\n                    stagn_counter = 0\n                else:\n                    stagn_counter += 1\n\n                # reward and additive energy update (per-subspace-direction)\n                if r > 0 and cand_step is not None:\n                    u_proj = B.T.dot(cand_step)  # r-vector\n                    u_norm = np.linalg.norm(u_proj) + 1e-12\n                    # reward: improvement scaled by projected length (use positive improvement only)\n                    raw_impr = max(0.0, (f_best - f_c))\n                    reward = raw_impr / (sigma * u_norm + 1e-12)\n                    if improved:\n                        reward += 0.15  # small bonus for global improvement\n                    if np.any(np.abs(u_proj) > 0):\n                        contrib = np.abs(u_proj) / (np.sum(np.abs(u_proj)) + 1e-12)\n                        # additive energy update: e <- e + eta * reward * contrib (clamped)\n                        e = e + self.energy_lr * reward * contrib\n                        # mild decay to prevent runaway\n                        e = 0.995 * e\n                        e = np.clip(e, self.min_energy, self.max_energy)\n\n                # update per-coordinate residual s via EMA of absolute normalized step\n                if cand_step is not None:\n                    abs_step_norm = np.abs(cand_step) / (sigma + 1e-12)\n                    s = (1.0 - self.s_lr) * s + self.s_lr * np.clip(abs_step_norm, self.min_s, self.max_s)\n\n                # acceptance: simulated annealing with decaying temperature per generation\n                T = max(1e-12, temp0 * (temp_decay ** (gen - 1)))\n                accept = False\n                if f_c <= f_best + 1e-12 and improved:\n                    accept = True\n                else:\n                    # uphill acceptance probability\n                    delta_f = f_c - f_best\n                    if delta_f <= 0:\n                        accept = True\n                    else:\n                        prob = np.exp(-delta_f / (T + 1e-12))\n                        if rng.rand() < prob:\n                            accept = True\n\n                # apply accepted step: damped mean update; trust clipping scaled differently\n                if accept:\n                    if strategy == 'surrogate':\n                        lr = 0.65\n                    elif strategy == 'levy':\n                        lr = 0.4\n                    elif strategy == 'subspace':\n                        lr = 0.3\n                    else:\n                        lr = 0.22\n                    delta = candidate - m\n                    # trust clamp relative to sigma but scaled with sqrt(dim) in different factor\n                    trust = 5.0 * sigma * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust and dn > 0:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                    # sigma adaptation: shrink on success; if large improvement shrink more\n                    if improved:\n                        sigma = max(1e-12, sigma * (0.89 if raw_impr > 0 else 0.92))\n                    else:\n                        # accepted uphill: slightly increase to encourage exploration after acceptance\n                        sigma = sigma * 1.02\n                    recent_successes += 1\n                else:\n                    # rejected: small exploratory jitter to mean and mild sigma increase\n                    m = np.minimum(np.maximum(m + 0.02 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma = sigma * 1.015\n\n                recent_trials += 1\n                if recent_trials >= adapt_window:\n                    # adjust sigma based on success ratio in window\n                    succ_rate = recent_successes / max(1.0, recent_trials)\n                    if succ_rate > 0.25:\n                        sigma = max(1e-12, sigma * 0.92)\n                    elif succ_rate < 0.08:\n                        sigma = sigma * 1.06\n                    recent_successes = 0\n                    recent_trials = 0\n\n                # small orthonormal rotation occasionally\n                if r > 0 and rng.rand() < 0.04:\n                    Qr = rng.randn(r, r) * 0.06\n                    try:\n                        Qr_orth, _ = np.linalg.qr(np.eye(r) + Qr)\n                        B = B.dot(Qr_orth)\n                        Q2, _ = np.linalg.qr(B)\n                        B = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # opportunistic restart on stagnation: different jitter and energy reset\n                if stagn_counter >= stagn_limit and evals < self.budget:\n                    stagn_counter = 0\n                    jitter = max(0.07 * avg_span, 0.8 * sigma)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma = max(sigma * self.restart_infl, 0.3 * avg_span)\n                    if r > 0:\n                        # reset additive energies to moderate diversity\n                        e = np.ones(r) * np.median(e) if e.size else np.ones(r)\n                        # randomize basis\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :r]\n                    s = np.full(self.dim, 0.35)\n                    # refresh archive slightly around best\n                    for _ in range(min(8, self.budget - evals)):\n                        x = np.minimum(np.maximum(x_best + 0.08 * avg_span * rng.randn(self.dim), lb), ub)\n                        f = float(func(x))\n                        evals += 1\n                        X_arch.append(x.copy())\n                        f_arch.append(f)\n                        if f < f_best:\n                            f_best = f\n                            x_best = x.copy()\n                        if len(X_arch) > self.archive_size:\n                            del X_arch[0]; del f_arch[0]\n                        if evals >= self.budget:\n                            break\n\n            # proceed to next generation (temperature implicitly decays by loop)\n            # ensure sigma doesn't become degenerate\n            sigma = np.clip(sigma, 1e-12, 10.0 * avg_span)\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DRSE_DA scored 0.170 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b0e7fc8a-1fa8-4e80-8412-4a023fed929e", "operator": null, "metadata": {"aucs": [0.08588106358926972, 0.15600952570901183, 0.2357205618170659, 0.16676535953288663, 0.17034597522912243, 0.20180429667945365, 0.18566967591372463, 0.2045606741016458, 0.17674848937165177, 0.11405463993275433]}, "task_prompt": ""}
{"id": "aaac1142-52b0-4703-bbdb-1c418190a06c", "fitness": 0.18757776041809332, "name": "SACM", "description": "SACM maintains a parametric search distribution: a center m with momentum (mom_beta≈0.7), a global step-size sigma, a low‑rank orthonormal subspace B with multiplicative per-direction energies e, and per-coordinate residual scales s, and it samples antithetic mirrored pairs m ± sigma*(B z + diag-noise) to reduce variance and attribute directional rewards to subspace components. Successful normalized steps are buffered and periodically used for PCA (pca_period) to refresh B and for fitting a cheap diagonal quadratic surrogate in the subspace (surrogate_prob) to propose targeted minimizers; archives (arch_size) and buffer_size scale with dimension to balance data richness and cost. Adaptation uses multiplicative sigma updates driven by an EMA success rate (p_smooth≈0.9) toward succ_target=0.20 with sigma_adapt_rate≈0.27, per-coordinate s updated from median absolute normalized steps, and energies e updated by softmax-like multiplicative smoothing of directional gains; candidate selection uses softmax-weighted sampling and uphill acceptance via a Metropolis-like temperature proportional to sigma·avg_span, while mean moves use momentum with trust clipping. Robustness mechanisms include occasional long uniform jumps, opportunistic restarts on stagnation with sigma inflation and reseeding, FIFO archival for surrogate fitting, and sensible defaults that scale pop_base ≈ max(8,6+0.8·log(dim)) and rank ≈ max(1,dim//6) to trade exploration vs. efficiency.", "code": "import numpy as np\n\nclass SACM:\n    \"\"\"\n    SACM: Subspace Antithetic Covariance + Momentum optimizer\n\n    Key ideas:\n      - Maintain mean m, global sigma, low-rank basis B with multiplicative energies e,\n        per-coordinate residual scales s, and a momentum term for mean updates.\n      - Use mirrored (antithetic) pairs from m +/- step where step = sigma*(B*z_r + diag_noise)\n        to get low-variance directional information and attribute gains to subspace directions.\n      - Periodically run PCA on buffered successful normalized steps to refresh B; update\n        energies e multiplicatively based on reward signals.\n      - Fit a cheap diagonal quadratic surrogate in subspace occasionally to propose a\n        targeted minimizer (if enough archive data).\n      - Adapt sigma multiplicatively via an EMA success rate (target ~0.2), perform trust-clipped\n        mean moves, and opportunistic restarts on stagnation.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop_base=None, rank=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.rng = np.random.RandomState(rng_seed)\n\n        # structural choices\n        self.pop_base = pop_base if pop_base is not None else max(8, int(6 + 0.8 * np.log(max(2, dim))))\n        self.rank = int(rank) if rank is not None else max(1, min(dim, max(1, dim // 6)))\n        # adaptation params\n        self.succ_target = 0.20\n        self.sigma_adapt_rate = 0.27\n        self.p_smooth = 0.9  # EMA smoothing for success\n        self.mom_beta = 0.7\n        # PCA & surrogate cadence\n        self.pca_period = 10\n        self.surrogate_prob = 0.18\n        # buffers / sizes\n        self.arch_size = max(6 * dim, 120)\n        self.buffer_size = max(8 * self.rank, 40)\n        # numeric/clipping\n        self.min_sigma = 1e-12\n        self.max_sigma_mult = 4.0\n        self.min_energy = 1e-6\n        self.max_energy = 1e3\n        self.min_s = 1e-6\n        self.max_s = 6.0\n        # exploration\n        self.long_jump_prob = 0.03\n        self.restart_infl = 1.8\n        self.stagn_frac = 0.06\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling (func.bounds.lb/ub may be scalars or arrays)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        # initialize mean uniformly in bounds\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(self.min_sigma, 0.18 * avg_span)\n\n        # low-rank basis B and multiplicative energies e\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()\n            e = np.ones(r) * 0.6\n        else:\n            B = np.zeros((self.dim, 0))\n            e = np.array([])\n\n        # per-coordinate residual scales\n        s = np.full(self.dim, 0.4)\n        mom = np.zeros(self.dim)\n\n        # bookkeeping: archive and buffers\n        X_arch = []\n        f_arch = []\n        success_buffer = []  # normalized successful steps (rows)\n        evals = 0\n\n        # seed initial evaluations to populate archive and best\n        seed_init = min(self.pop_base, max(6, self.budget // 80))\n        for _ in range(seed_init):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        # ensure at least one eval\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        # best so far\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # adaptive controllers\n        p_succ = 0.2\n        stagn_limit = max(5, int(self.stagn_frac * self.budget))\n        stagn_count = 0\n        gen = 0\n\n        # small helper: fit diagonal quadratic in subspace (U coords) -> returns g,hdiag\n        def fit_diag_quadratic(U, y):\n            # U: (k,r), y: (k,)\n            k, rloc = U.shape\n            if k < max(3, rloc + 1):\n                return None\n            # design [1, u, u^2]\n            X = np.ones((k, 1 + 2 * rloc))\n            X[:, 1:1 + rloc] = U\n            X[:, 1 + rloc:] = U ** 2\n            # solve least squares with tiny reg\n            try:\n                theta, *_ = np.linalg.lstsq(X, y, rcond=None)\n                g = theta[1:1 + rloc].astype(float)\n                h = theta[1 + rloc:].astype(float)\n                # force reasonable curvature\n                h = np.sign(h) * np.maximum(np.abs(h), 1e-6)\n                return g, h\n            except Exception:\n                return None\n\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            # prefer even batch for mirrored pairs\n            if lam > 1 and (lam % 2 == 1):\n                lam -= 1\n\n            cand_X = []\n            cand_f = []\n            gen_success = False\n            directional_gains = np.zeros(r) if r > 0 else np.array([])\n\n            pairs = max(0, lam // 2)\n            for _p in range(pairs):\n                if evals + 2 > self.budget:\n                    break\n\n                # sample low-rank coefficients and diag noise\n                if r > 0:\n                    z_r = rng.randn(r) * np.sqrt(np.maximum(e, 1e-12))\n                    low = B.dot(z_r)\n                else:\n                    low = np.zeros(self.dim)\n                z_d = rng.randn(self.dim) * s\n                step = sigma * (low + z_d)\n\n                # mirrored evaluations\n                x_plus = np.minimum(np.maximum(m + step, lb), ub)\n                x_minus = np.minimum(np.maximum(m - step, lb), ub)\n\n                # occasional long jump for x_plus\n                if rng.rand() < self.long_jump_prob:\n                    x_plus = rng.uniform(lb, ub, size=self.dim)\n\n                f_plus = float(func(x_plus)); evals += 1\n                f_minus = float(func(x_minus)); evals += 1\n\n                cand_X.extend([x_plus.copy(), x_minus.copy()])\n                cand_f.extend([f_plus, f_minus])\n\n                # archive FIFO\n                X_arch.append(x_plus.copy()); f_arch.append(f_plus)\n                X_arch.append(x_minus.copy()); f_arch.append(f_minus)\n                while len(X_arch) > self.arch_size:\n                    del X_arch[0]; del f_arch[0]\n\n                # update global best\n                improved = False\n                if f_plus < f_best:\n                    f_best = f_plus; x_best = x_plus.copy(); improved = True\n                    stagn_count = 0\n                if f_minus < f_best:\n                    f_best = f_minus; x_best = x_minus.copy(); improved = True\n                    stagn_count = 0\n                if not improved:\n                    stagn_count += 1\n                gen_success = gen_success or improved\n\n                # directional gain attribution (f_minus - f_plus positive means +step is better)\n                delt = (f_minus - f_plus)\n                step_norm = np.linalg.norm(step) + 1e-12\n                step_unit = step / step_norm\n                if r > 0:\n                    proj = B.T.dot(step_unit)  # r-vector\n                    reward = np.maximum(0.0, delt) * np.abs(proj)\n                    directional_gains += reward\n\n                # record successful normalized steps to buffer (if either improved or delt positive)\n                if (delt > 0) or (f_plus <= f_best + 1e-12) or (f_minus <= f_best + 1e-12):\n                    success_buffer.append((step / (sigma + 1e-12)).copy())\n                    if len(success_buffer) > self.buffer_size:\n                        del success_buffer[0]\n\n            # if leftover single evaluation allowed, do one stochastic probe\n            if evals < self.budget and (self.pop_base > 0) and ((self.pop_base % 2 == 1) or lam == 0):\n                if evals + 1 <= self.budget:\n                    if r > 0:\n                        z_r = rng.randn(r) * np.sqrt(np.maximum(e, 1e-12))\n                        low = B.dot(z_r)\n                    else:\n                        low = np.zeros(self.dim)\n                    z_d = rng.randn(self.dim) * s\n                    step = sigma * (low + z_d)\n                    x = np.minimum(np.maximum(m + step, lb), ub)\n                    if rng.rand() < self.long_jump_prob:\n                        x = rng.uniform(lb, ub, size=self.dim)\n                    f_x = float(func(x)); evals += 1\n                    cand_X.append(x.copy()); cand_f.append(f_x)\n                    X_arch.append(x.copy()); f_arch.append(f_x)\n                    while len(X_arch) > self.arch_size:\n                        del X_arch[0]; del f_arch[0]\n                    if f_x < f_best:\n                        f_best = f_x; x_best = x.copy(); gen_success = True; stagn_count = 0\n                    else:\n                        stagn_count += 1\n                    # record if helpful\n                    if f_x <= f_best + 1e-12:\n                        success_buffer.append((step / (sigma + 1e-12)).copy())\n                        if len(success_buffer) > self.buffer_size:\n                            del success_buffer[0]\n\n            if len(cand_f) == 0:\n                break\n\n            # optionally attempt surrogate minimizer in subspace (one extra evaluation) if archive rich\n            ran_surrogate = False\n            if r > 0 and (rng.rand() < self.surrogate_prob) and (len(X_arch) >= max(2 * r + 4, 30)) and (evals < self.budget):\n                # build U (recent rows) and y (their f)\n                K = min(len(X_arch), 4 * r + 60)\n                Xr = np.asarray(X_arch[-K:])\n                fr = np.asarray(f_arch[-K:])\n                Ucoords = (Xr - m).dot(B)  # (K,r)\n                res = fit_diag_quadratic(Ucoords, fr)\n                if res is not None:\n                    gsub, hdiag = res\n                    # propose u_star = -g/h (clip)\n                    u_star = -gsub / (hdiag + 1e-8)\n                    u_norm = np.linalg.norm(u_star)\n                    max_u = max(1e-12, 4.0 * sigma)\n                    if u_norm > max_u:\n                        u_star = u_star * (max_u / (u_norm + 1e-12))\n                    cand = m + B.dot(u_star)\n                    cand = np.minimum(np.maximum(cand, lb), ub)\n                    f_cand = float(func(cand)); evals += 1\n                    cand_X.append(cand.copy()); cand_f.append(f_cand)\n                    X_arch.append(cand.copy()); f_arch.append(f_cand)\n                    while len(X_arch) > self.arch_size:\n                        del X_arch[0]; del f_arch[0]\n                    ran_surrogate = True\n                    if f_cand < f_best:\n                        f_best = f_cand; x_best = cand.copy(); gen_success = True; stagn_count = 0\n                    else:\n                        stagn_count += 1\n\n            # choose winner by softmax-weighted selection favoring low f\n            f_arr = np.asarray(cand_f)\n            fmin_local = np.min(f_arr)\n            fstd = float(np.std(f_arr) + 1e-12)\n            scores = np.exp(-(f_arr - fmin_local) / (fstd + 1e-12))\n            probs = scores / np.sum(scores)\n            chosen_idx = rng.choice(len(cand_X), p=probs)\n            chosen_x = np.asarray(cand_X[chosen_idx]).copy()\n            chosen_f = float(cand_f[chosen_idx])\n\n            # uphill acceptance with temperature proportional to sigma*avg_span\n            accept = False\n            if chosen_f <= f_best:\n                accept = True\n            else:\n                T = max(1e-12, 0.6 * sigma * avg_span)\n                if rng.rand() < np.exp(-max(0.0, chosen_f - f_best) / (T + 1e-12)):\n                    accept = True\n\n            # mean update via momentum and trust clipping\n            if accept:\n                delta = chosen_x - m\n                # trust radius proportional to sigma and dimension\n                trust = max(1e-12, 6.0 * sigma * np.sqrt(self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > trust:\n                    delta = delta * (trust / (dn + 1e-12))\n                mom = self.mom_beta * mom + (1.0 - self.mom_beta) * delta\n                # learning rate depends on type (stronger when improving)\n                eta = 0.28 if chosen_f <= f_best else 0.18\n                m = np.minimum(np.maximum(m + eta * mom, lb), ub)\n            else:\n                # exploratory jitter on rejection\n                m = np.minimum(np.maximum(m + 0.04 * avg_span * rng.randn(self.dim), lb), ub)\n                mom = mom * 0.85\n\n            # update per-coordinate s from success_buffer median absolute normalized steps\n            if len(success_buffer) > 0:\n                Bbuf = np.asarray(success_buffer)\n                med = np.median(np.abs(Bbuf), axis=0)\n                s = 0.85 * s + 0.15 * np.clip(med, self.min_s, self.max_s)\n\n            # update energies from directional_gains (softmax-like multiplicative update)\n            if r > 0 and np.sum(directional_gains) > 1e-12:\n                g = directional_gains\n                # stabilize scale\n                g = g - g.max()\n                tmp = np.exp(g / (np.std(g) + 1e-12))\n                tmp = tmp / (np.sum(tmp) + 1e-12)\n                # multiplicative smoothing\n                e = 0.85 * e + 0.15 * (tmp * (np.sum(e) + 1e-12))\n                e = np.clip(e, self.min_energy, self.max_energy)\n\n            # PCA refresh to update B occasionally\n            if (gen % self.pca_period == 0) and (len(success_buffer) >= max(3, r)):\n                try:\n                    M = np.asarray(success_buffer)\n                    M -= np.mean(M, axis=0, keepdims=True)\n                    U_s, S_s, Vt = np.linalg.svd(M, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        B_new = Vt[:r_eff].T\n                        # blend to avoid abrupt change\n                        if B.shape[1] == r_eff:\n                            B = 0.85 * B + 0.15 * B_new\n                        else:\n                            # replace and orthonormalize\n                            B = B_new\n                        # orthonormalize\n                        Q, _ = np.linalg.qr(B)\n                        B = Q[:, :r_eff]\n                except Exception:\n                    pass\n\n            # sigma adaptation via smoothed generation success (any candidate improved global best)\n            gen_success_flag = float(gen_success)\n            p_succ = self.p_smooth * p_succ + (1.0 - self.p_smooth) * gen_success_flag\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, self.min_sigma, self.max_sigma_mult * np.max(span))\n\n            # opportunistic restart on stagnation\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                jitter = max(0.04 * avg_span, 0.8 * sigma)\n                m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                sigma = max(sigma * self.restart_infl, 0.2 * avg_span)\n                # partially reset subspace and energies\n                if r > 0:\n                    A = rng.randn(self.dim, r)\n                    Q, _ = np.linalg.qr(A)\n                    B = Q[:, :r]\n                    e = np.ones(r) * np.median(e) if e.size else np.ones(r)\n                s = np.full(self.dim, 0.4)\n                mom = np.zeros(self.dim)\n                success_buffer = []\n                # a few reseed evaluations near best\n                for _ in range(min(6, self.budget - evals)):\n                    x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                    f = float(func(x))\n                    evals += 1\n                    X_arch.append(x.copy()); f_arch.append(f)\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n                    if len(X_arch) > self.arch_size:\n                        del X_arch[0]; del f_arch[0]\n                    if evals >= self.budget:\n                        break\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SACM scored 0.188 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b0e7fc8a-1fa8-4e80-8412-4a023fed929e", "operator": null, "metadata": {"aucs": [0.0814118004942429, 0.14531669166792616, 0.2737813563560224, 0.2227005668771992, 0.1847345392564418, 0.2480969451573407, 0.20533023466315237, 0.20530454548429755, 0.1861815176690873, 0.12291940655522282]}, "task_prompt": ""}
{"id": "3e4ef197-f638-4630-a5db-42cd534b5bb8", "fitness": "-inf", "name": "EliteHybridPatternDE", "description": "The design mixes complementary operators (Gaussian CMA-like sampling, archive-driven Differential Evolution, heavy-tailed Cauchy jumps, and Hooke‑Jeeves local search) and steers them using a small sorted elite archive initialized by space‑filling sampling (init_samples ≈ min(6*dim,80) and archive size 4–16). A compact CMA-like state (mean m, diagonal/regularized covariance C, chol_safe) is maintained and adapted via EWMA (cov_lr=0.22) and a success-rate controller (sigma init ≈0.18·avg_span, sigma_adapt_rate=0.25, success_target=0.2) with covariance floors to preserve exploration. Operator implementations are tuned: Gaussian uses N(m,sigma^2 C); DE is best‑biased with F_base=0.9, cr=0.9, archive-driven parents and jitter; Cauchy jumps anchor on elites with a budget-decaying scale; local search uses per-dimension steps (base_step=0.22·span) that expand by 1.3 or shrink by 0.6. Finally, operator probabilities adapt from recent success counts, occasional uniform injections (inject_period=19) maintain diversity, small local-budget chunks (local_budget_frac=0.035) allow refinement, and opportunistic restarts trigger after prolonged stagnation (≈0.06·budget), all while strictly clipping to bounds and enforcing the evaluation budget.", "code": "import numpy as np\n\nclass EliteHybridPatternDE:\n    \"\"\"\n    EliteHybridPatternDE: archive-driven mixture of operators with a compact CMA-like state.\n\n    Operators:\n     - Gaussian proposals sampled from N(m, sigma^2 C) (CMA-like guidance)\n     - Archive-driven Differential Evolution (best-biased + jitter)\n     - Heavy-tailed Cauchy jumps anchored on elites (budget-aware scale decay)\n     - Hooke-Jeeves-like pattern/local search with per-dimension adaptive steps\n\n    Control:\n     - Maintain and adapt mean m, covariance C, global step sigma via success-rate controller.\n     - Update covariance via EWMA of weighted deltas from selected improving candidates.\n     - Maintain a sorted elite archive and adapt operator probabilities based on archive spread & recent success.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # CMA-like knobs\n        self.cov_lr = 0.22          # covariance learning rate (EWMA)\n        self.sigma_adapt_rate = 0.25\n        self.success_target = 0.2\n\n        # DE knobs\n        self.F_base = 0.9\n        self.cr = 0.9\n\n        # archive/local knobs\n        self.init_samples = None\n        self.archive_size = None\n        self.local_budget_frac = 0.035\n        self.inject_period = 19\n\n        # internal results\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial sampling and archive size\n        if self.init_samples is None:\n            init_samples = max(12, min(80, 6 * self.dim))\n        else:\n            init_samples = int(self.init_samples)\n        init_samples = min(init_samples, max(1, self.budget // 4))\n\n        if self.archive_size is None:\n            archive_k = max(4, min(16, init_samples // 3))\n        else:\n            archive_k = int(self.archive_size)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # sorted list of (f, x)\n\n        def record(x, f):\n            # insert into sorted archive maintaining size\n            nonlocal archive, f_best, x_best\n            if f < f_best:\n                f_best = float(f)\n                x_best = np.asarray(x, dtype=float).copy()\n            if len(archive) < archive_k:\n                archive.append((float(f), np.asarray(x, dtype=float).copy()))\n                archive.sort(key=lambda t: t[0])\n            else:\n                if f < archive[-1][0]:\n                    archive[-1] = (float(f), np.asarray(x, dtype=float).copy())\n                    archive.sort(key=lambda t: t[0])\n\n        def eval_and_record(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            record(x, f)\n            return float(f), x\n\n        # initialize by space-filling uniform samples\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            eval_and_record(x0)\n\n        # ensure at least one archive entry\n        if len(archive) == 0 and evals < self.budget:\n            eval_and_record(rng.uniform(lb, ub))\n\n        # initial CMA-like state: mean, covariance, sigma\n        # initialize mean as weighted average of top half of archive/init points\n        archive_sorted = sorted(archive, key=lambda t: t[0])\n        n_init = len(archive_sorted)\n        mu0 = max(1, n_init // 2)\n        elites0 = np.vstack([archive_sorted[i][1] for i in range(mu0)])\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if w0.sum() <= 0:\n            w0 = np.ones_like(w0)\n        w0 = w0 / w0.sum()\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # covariance: diagonal scaled by bounds (moderate)\n        C = np.diag(((span / 5.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.18 * avg_span)\n\n        # per-dim local search step sizes\n        base_step = 0.22 * span\n        base_step = np.maximum(base_step, 1e-8)\n\n        # operator probabilities and tracking\n        p_gauss = 0.28\n        p_de = 0.38\n        p_cauchy = 0.22\n        p_local = 1.0 - (p_gauss + p_de + p_cauchy)\n        # keep history of recent successes to adapt probabilities\n        recent_success = {'gauss': 1.0, 'de': 1.0, 'cauchy': 1.0, 'local': 1.0}\n        p_succ = self.success_target  # smoothed success rate\n        stagn_iters = 0\n        iter_count = 0\n        attempt = 0\n\n        # helpers\n        def chol_safe(Cmat):\n            eps = 1e-12 * np.maximum(np.diag(Cmat), 1.0)\n            try:\n                A = np.linalg.cholesky(Cmat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(Cmat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        def sample_gaussian():\n            # sample one candidate from N(m, sigma^2 C)\n            A = chol_safe(C)\n            z = rng.normal(size=self.dim)\n            y = z @ A.T\n            x = m + sigma * y\n            x = np.minimum(np.maximum(x, lb), ub)\n            return x\n\n        def de_proposal():\n            # archive-driven best-biased DE with jitter and crossover\n            if len(archive) < 3:\n                return rng.uniform(lb, ub)\n            # sort archive\n            idxs = list(range(len(archive)))\n            archive_sorted_local = sorted(archive, key=lambda t: t[0])\n            # choose base a (best-biased)\n            if rng.rand() < 0.7:\n                a = archive_sorted_local[0][1]\n            else:\n                a = archive_sorted_local[rng.randint(0, len(archive_sorted_local))][1]\n            # choose b, c distinct\n            choices = list(range(len(archive_sorted_local)))\n            # ensure different indices\n            # pick two random indices not equal to index of chosen a if possible\n            if len(choices) <= 3:\n                bidx, cidx = rng.choice(len(choices), size=2, replace=False)\n            else:\n                bidx, cidx = rng.choice(len(choices), size=2, replace=False)\n            b = archive_sorted_local[bidx][1]\n            c = archive_sorted_local[cidx][1]\n            # adapt F based on archive spread (larger F when clustered)\n            spread = np.linalg.norm(archive_sorted_local[0][1] - archive_sorted_local[-1][1]) if len(archive_sorted_local) > 1 else avg_span\n            F_loc = self.F_base * (1.0 + 0.6 * np.exp(-spread / (avg_span + 1e-12)))\n            diff = b - c\n            trial = a + F_loc * diff\n            # crossover\n            mask = rng.rand(self.dim) < self.cr\n            if not np.any(mask):\n                mask[rng.randint(self.dim)] = True\n            target = m if rng.rand() < 0.25 else a\n            cand = np.where(mask, trial, target)\n            # jitter\n            cand += 0.04 * rng.randn(self.dim) * span\n            cand = np.minimum(np.maximum(cand, lb), ub)\n            return cand\n\n        def cauchy_jump():\n            # heavy-tailed jump anchored on an elite\n            if len(archive) == 0:\n                center = m\n            else:\n                if rng.rand() < 0.75:\n                    center = sorted(archive, key=lambda t: t[0])[0][1]\n                else:\n                    center = archive[rng.randint(0, len(archive))][1]\n            # scale decays with budget consumed\n            remain_frac = max(0.0, 1.0 - (evals / max(1.0, self.budget)))\n            scale = 0.6 * remain_frac + 0.06  # between ~0.66 -> 0.06 as budget consumed\n            # anisotropic: multiply by per-dim span and random direction\n            direction = rng.randn(self.dim)\n            direction /= (np.linalg.norm(direction) + 1e-12)\n            cauchy = rng.standard_cauchy(size=1)\n            cauchy = float(np.clip(cauchy, -1e3, 1e3))\n            step = direction * (scale * avg_span * (0.6 + 0.8 * rng.rand()))\n            x = center + cauchy * step\n            x = np.minimum(np.maximum(x, lb), ub)\n            return x\n\n        def local_search(x_start, f_start, local_budget):\n            # Hooke-Jeeves-like pattern search with per-dimension adaptive steps\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = np.asarray(x_start, dtype=float).copy()\n            base_f = float(f_start)\n            steps = base_step.copy()\n            local_used = 0\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_used < local_budget and iters < iter_limit and np.any(steps > 1e-12):\n                iters += 1\n                improved = False\n                x_probe = base.copy()\n                x_probe_f = base_f\n                order = list(range(self.dim))\n                rng.shuffle(order)\n                for i in order:\n                    if local_used >= local_budget or evals >= self.budget:\n                        break\n                    # positive\n                    xp = x_probe.copy()\n                    xp[i] += steps[i]\n                    xp = np.minimum(np.maximum(xp, lb), ub)\n                    res = eval_and_record(xp)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < x_probe_f:\n                        x_probe = xp.copy()\n                        x_probe_f = fp\n                        improved = True\n                        steps[i] *= 1.3\n                        continue\n                    # negative\n                    xn = x_probe.copy()\n                    xn[i] -= steps[i]\n                    xn = np.minimum(np.maximum(xn, lb), ub)\n                    res = eval_and_record(xn)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < x_probe_f:\n                        x_probe = xn.copy()\n                        x_probe_f = fn\n                        improved = True\n                        steps[i] *= 1.3\n                # pattern extension\n                if improved and local_used < local_budget and evals < self.budget:\n                    direction = x_probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + 1.5 * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_and_record(xp)\n                        local_used += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < x_probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = x_probe.copy()\n                                base_f = x_probe_f\n                        else:\n                            base = x_probe.copy()\n                            base_f = x_probe_f\n                    else:\n                        base = x_probe.copy()\n                        base_f = x_probe_f\n                else:\n                    steps *= 0.6\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # main loop: run until budget consumed\n        last_improve_evals = evals\n        while evals < self.budget:\n            attempt += 1\n            iter_count += 1\n            remaining = self.budget - evals\n            # allocate a small local budget chunk for promising candidates\n            alloc_local = min(max(3, int(self.local_budget_frac * self.budget)), remaining - 1) if remaining > 1 else 0\n\n            # adapt operator probabilities based on archive spread and recent success\n            if len(archive) >= 2:\n                spread = np.linalg.norm(archive[0][1] - archive[-1][1])\n            else:\n                spread = avg_span\n            # more spread -> favor gaussian/local; low spread -> favor DE/Cauchy\n            pref_gauss = np.clip(1.0 - (spread / (avg_span + 1e-12)), 0.1, 1.5)\n            p_ga = p_gauss * (0.8 + 0.4 * (1.0 / (1.0 + spread / (0.5 * avg_span))))\n            p_de_local = p_de * (0.9 + 0.3 * (spread / (avg_span + 1e-12)))\n            p_cau_local = p_cauchy * (1.0 + 0.1 * (1.0 - spread / (avg_span + 1e-12)))\n            # normalize to sum <=0.98 leave small for local\n            s = p_ga + p_de_local + p_cau_local\n            if s > 0.98:\n                p_ga = p_ga * 0.98 / s\n                p_de_local = p_de_local * 0.98 / s\n                p_cau_local = p_cau_local * 0.98 / s\n            else:\n                p_ga = p_ga\n            # draw operator\n            r = rng.rand()\n            improved = False\n            used_local = False\n\n            # gaussian proposal\n            if r < p_ga:\n                cand = sample_gaussian()\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n                if f_cand < f_best:\n                    improved = True\n                # possible small local refinement\n                if alloc_local > 0 and f_cand <= (min([a[0] for a in archive]) * 1.03 if len(archive)>0 else np.inf):\n                    local_budget = min(alloc_local, remaining - 1)\n                    f_after, x_after = local_search(cand, f_cand, local_budget)\n                    used_local = True\n                    if f_after < f_cand:\n                        improved = True\n                        cand = x_after\n                        f_cand = f_after\n                recent_success['gauss'] = 0.9 * recent_success['gauss'] + 0.1 * (1.0 if improved else 0.0)\n\n            # DE proposal\n            elif r < p_ga + p_de_local:\n                cand = de_proposal()\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n                if f_cand < f_best:\n                    improved = True\n                # small local refine if promising\n                if alloc_local > 0 and f_cand <= (archive[0][0] * 1.04 if len(archive)>0 else np.inf):\n                    local_budget = min(alloc_local, remaining - 1)\n                    f_after, x_after = local_search(cand, f_cand, local_budget)\n                    used_local = True\n                    if f_after < f_cand:\n                        improved = True\n                        cand = x_after\n                        f_cand = f_after\n                recent_success['de'] = 0.9 * recent_success['de'] + 0.1 * (1.0 if improved else 0.0)\n\n            # cauchy jump\n            elif r < p_ga + p_de_local + p_cau_local:\n                cand = cauchy_jump()\n                res = eval_and_record(cand)\n                if res is None:\n                    break\n                f_cand, cand = res\n                if f_cand < f_best:\n                    improved = True\n                # if very promising do stronger local refine\n                if alloc_local > 0 and f_cand <= (archive[0][0] * 1.08 if len(archive)>0 else np.inf):\n                    local_budget = min(3 * alloc_local, remaining - 1)\n                    f_after, x_after = local_search(cand, f_cand, local_budget)\n                    used_local = True\n                    if f_after < f_cand:\n                        improved = True\n                        cand = x_after\n                        f_cand = f_after\n                recent_success['cauchy'] = 0.9 * recent_success['cauchy'] + 0.1 * (1.0 if improved else 0.0)\n\n            # local operator\n            else:\n                # choose a start point: best, a random elite, or jittered best\n                if len(archive) > 0 and rng.rand() < 0.7:\n                    start_f, start_x = archive[0]\n                elif len(archive) > 1 and rng.rand() < 0.9:\n                    idx = rng.randint(0, len(archive))\n                    start_f, start_x = archive[idx]\n                else:\n                    if x_best is not None:\n                        start_x = x_best + 0.08 * avg_span * rng.randn(self.dim)\n                        res = eval_and_record(start_x)\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                    else:\n                        res = eval_and_record(rng.uniform(lb, ub))\n                        if res is None:\n                            break\n                        start_f, start_x = res\n                local_budget = min(alloc_local, max(2, int(0.05 * remaining)))\n                f_after, x_after = local_search(start_x, start_f, local_budget)\n                used_local = True\n                if f_after < f_best:\n                    improved = True\n                recent_success['local'] = 0.9 * recent_success['local'] + 0.1 * (1.0 if improved else 0.0)\n\n            # adapt CMA covariance and mean using selected improving candidates from archive top\n            # use top-k elites from archive to form ranked update\n            if len(archive) > 0:\n                k = max(1, min(len(archive), 1 + int(0.5 * len(archive))))\n                topk = [archive[i][1] for i in range(k)]\n                # weights: log-based\n                w = np.log(k + 0.5) - np.log(np.arange(1, k + 1))\n                w = np.maximum(w, 0.0)\n                if w.sum() <= 0:\n                    w = np.ones_like(w)\n                w = w / w.sum()\n                Xk = np.vstack(topk)\n                m_new = (w.reshape(-1, 1) * Xk).sum(axis=0)\n                # deltas normalized by sigma\n                deltas = (Xk - m) / (sigma + 1e-20)\n                W = w.reshape(-1, 1)\n                cov_k = (deltas * W).T @ deltas\n                # EWMA covariance update\n                C = (1.0 - self.cov_lr) * C + self.cov_lr * cov_k\n                # ensure symmetry and small floor\n                C = 0.5 * (C + C.T) + np.diag(((span / 40.0) ** 2).clip(min=1e-18))\n                # update mean (move slowly towards weighted mean)\n                m = 0.6 * m + 0.4 * m_new\n\n            # sigma adaptation (smoothed success-rate)\n            p_succ = 0.9 * p_succ + 0.1 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(span))\n\n            # small adaptive operator probability tuning from recent successes\n            total_recent = sum(recent_success.values()) + 1e-12\n            # normalize weights (with floor)\n            for kname in recent_success:\n                recent_success[kname] = max(0.01, recent_success[kname])\n            ssum = sum(recent_success.values())\n            p_gauss = 0.12 + 0.7 * (recent_success['gauss'] / ssum)\n            p_de = 0.12 + 0.7 * (recent_success['de'] / ssum)\n            p_cauchy = 0.08 + 0.5 * (recent_success['cauchy'] / ssum)\n            p_local = max(0.02, 1.0 - (p_gauss + p_de + p_cauchy))\n            # keep small floor and normalize if overflow\n            s = p_gauss + p_de + p_cauchy + p_local\n            p_gauss /= s\n            p_de /= s\n            p_cauchy /= s\n            p_local /= s\n\n            # occasional uniform injection to maintain diversity\n            if (attempt % self.inject_period) == 0 and evals < self.budget:\n                eval_and_record(rng.uniform(lb, ub))\n\n            # opportunistic restart if no improvement for long\n            if evals - last_improve_evals > max(50, int(0.06 * self.budget)):\n                # small re-center around best with jitter, inflate sigma moderately, reset covariance partially\n                last_improve_evals = evals\n                if x_best is not None:\n                    m = x_best + 0.06 * avg_span * rng.randn(self.dim)\n                    m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((span / 6.0) ** 2).clip(min=1e-12))\n                sigma = max(sigma, 0.4 * avg_span)\n\n            # update last_improve_evals\n            if improved:\n                last_improve_evals = evals\n\n            # break guard\n            if evals >= self.budget:\n                break\n\n        # finalize best\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 219, in cauchy_jump, the following error occurred:\nTypeError: only 0-dimensional arrays can be converted to Python scalars\nOn line: cauchy = float(np.clip(cauchy, -1e3, 1e3))", "error": "In the code, line 219, in cauchy_jump, the following error occurred:\nTypeError: only 0-dimensional arrays can be converted to Python scalars\nOn line: cauchy = float(np.clip(cauchy, -1e3, 1e3))", "parent_ids": "b0e7fc8a-1fa8-4e80-8412-4a023fed929e", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "dc34281a-bf69-49eb-a520-fa52a9b6e989", "fitness": "-inf", "name": "ALR_SGE", "description": "ALR-SGE generates candidates as m + U @ (z * s_sub) + sigma_diag * eps, i.e. a low-rank orthonormal subspace (k defaults to ~dim/6) for coordinated moves plus a per-coordinate diagonal residual for fine-scale adaptation, with sigma0 initialized from problem span and clipped by min/max.  \nIt builds cheap quadratic surrogates inside the subspace from a FIFO archive to solve H u = -g for subspace minimizers, and complements these with 1‑D coordinate quadratic refinements and rare heavy‑tailed (Cauchy) jumps; strategies are mixed probabilistically (prob_surrogate≈0.12, prob_coord≈0.06, prob_heavy≈0.04, pop≈16).  \nAdaptation is driven by EWMA per‑coordinate RMS (rms_beta=0.93) to set sigma_diag, multiplicative sigma0 shrink/grow on success/uphill acceptance, SVD refresh of U every dir_refresh iterations, energy-weighted updates of subspace scales, Metropolis‑like uphill acceptance (accept_temp_coeff=0.5), and opportunistic reseeding when stagnation is detected.", "code": "import numpy as np\n\nclass ALR_SGE:\n    \"\"\"\n    Adaptive Low-Rank Surrogate Guided Evolution (ALR-SGE)\n\n    Main ideas:\n    - Maintain a low-rank subspace (U) and a diagonal residual scale to form proposals:\n        x = m + U @ (z * s_sub) + s_diag * eps\n      where z ~ N(0,I_k), eps ~ N(0,I_d).\n    - Fit small quadratic surrogates inside the low-rank subspace using recent archive\n      (cheap least squares) and propose the subspace minimizer.\n    - Perform occasional coordinate 1-D quadratic refinements and rare Cauchy jumps.\n    - Success/failure multiplicative adaptation of global step sigma0 and\n      EWMA updates of subspace/diag scales. Periodic SVD refresh of U from recent steps.\n    - Probabilistic uphill acceptance to allow escapes (Metropolis-like).\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=16, subspace_rank=None, archive_size=None,\n                 init_sigma_mult=0.18, rms_beta=0.93,\n                 prob_surrogate=0.12, prob_coord=0.06, prob_heavy=0.04,\n                 dir_refresh=12, accept_temp_coeff=0.5,\n                 min_sigma=1e-8, max_sigma=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.k = subspace_rank if subspace_rank is not None else max(1, self.dim // 6)\n        self.archive_size = archive_size if archive_size is not None else max(6 * self.dim, 120)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.rms_beta = float(rms_beta)\n        self.prob_surrogate = float(prob_surrogate)\n        self.prob_coord = float(prob_coord)\n        self.prob_heavy = float(prob_heavy)\n        self.dir_refresh = int(dir_refresh)\n        self.accept_temp_coeff = float(accept_temp_coeff)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds (default -5..5)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial mean uniformly\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # step-size and per-dim RMS-like scaling\n        sigma0 = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        v_rms = np.full(self.dim, 1e-6)\n        sigma_diag = np.full(self.dim, sigma0)   # residual diagonal scale\n\n        # low-rank subspace U (dim x k) orthonormal and subspace scale s_sub (k,)\n        k = min(self.k, self.dim)\n        if k > 0:\n            A = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :k].copy()\n            s_sub = np.full(k, sigma0 / np.sqrt(k))  # scale in subspace\n            sub_energy = np.ones(k)  # measure of utility per basis vector\n        else:\n            U = np.zeros((self.dim, 0))\n            s_sub = np.array([])\n            sub_energy = np.array([])\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # seed archive with a handful of random points\n        seed_init = min(self.pop * 3, max(12, int(self.budget // 200)))\n        for _ in range(seed_init):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        # best\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(10, int(0.06 * self.budget))\n\n        # helper: fit quadratic surrogate in k-dim subspace around center C using Xs, fs\n        # model: f ≈ c + g^T u + 0.5 u^T H u, where u = U^T(x - C)\n        def fit_quad_subspace(C, U_sub, Xs, fs):\n            K = Xs.shape[0]\n            k_loc = U_sub.shape[1]\n            if K <= k_loc + 2:\n                # not enough points\n                return None, None\n            # build u coordinates\n            dX = Xs - C[None, :]\n            U = U_sub\n            UTX = dX.dot(U)  # shape (K,k)\n            # build design matrix columns: [1, u1..uk, 0.5*u1^2..0.5*uk^2, u1*u2, u1*u3, ... (i<j)]\n            cols = []\n            cols.append(np.ones(K))\n            for j in range(k_loc):\n                cols.append(UTX[:, j])\n            # diag quadratics\n            for j in range(k_loc):\n                cols.append(0.5 * (UTX[:, j] ** 2))\n            # off-diagonals\n            for i in range(k_loc):\n                for j in range(i + 1, k_loc):\n                    cols.append(UTX[:, i] * UTX[:, j])\n            A = np.vstack(cols).T  # K x P\n            y = fs\n            # small ridge for stability\n            try:\n                theta, *_ = np.linalg.lstsq(A, y, rcond=None)\n            except Exception:\n                return None, None\n            # parse theta\n            idx = 0\n            c0 = float(theta[idx]); idx += 1\n            g = np.zeros(k_loc)\n            for j in range(k_loc):\n                g[j] = float(theta[idx]); idx += 1\n            H = np.zeros((k_loc, k_loc))\n            # diag\n            for j in range(k_loc):\n                H[j, j] = float(theta[idx]); idx += 1\n            # off-diags fill symmetric\n            for i in range(k_loc):\n                for j in range(i + 1, k_loc):\n                    H[i, j] = float(theta[idx])\n                    H[j, i] = H[i, j]\n                    idx += 1\n            return g, H\n\n        # main loop: generate up to budget evaluations\n        while evals < self.budget:\n            gen += 1\n\n            # refresh subspace occasionally by SVD of recent centered steps\n            if (gen % self.dir_refresh == 0) and len(X_arch) >= max(6, k):\n                K = min(len(X_arch), self.archive_size)\n                Xr = np.asarray(X_arch[-K:])\n                Mx = np.mean(Xr, axis=0)\n                S = (Xr - Mx)\n                try:\n                    U_s, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                    r_eff = min(k, Vt.shape[0])\n                    if r_eff > 0 and k > 0:\n                        U_new = Vt[:r_eff].T\n                        # blend to avoid abrupt jumps (exponential blend)\n                        U = 0.85 * U + 0.15 * U_new\n                        # orthonormalize\n                        Q, _ = np.linalg.qr(U)\n                        U = Q[:, :r_eff]\n                        # update subspace scales and energy\n                        s_sub = 0.9 * s_sub[:r_eff] + 0.1 * (np.maximum(svals[:r_eff], 1e-8) / (np.sqrt(r_eff) + 1e-12))\n                        sub_energy = 0.92 * sub_energy[:r_eff] + 0.08 * (svals[:r_eff] + 1e-8)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # number of proposals this generation\n            n_cand = min(self.pop, max(1, self.budget - evals))\n\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                x_cand = None\n                strategy = 'lowrank'\n                step = None\n\n                # heavy-tailed Cauchy escape\n                if rng.rand() < self.prob_heavy:\n                    z = rng.standard_cauchy(size=self.dim)\n                    # robust scale\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    x_cand = m + sigma0 * 4.0 * z\n                    strategy = 'heavy'\n\n                # subspace quadratic surrogate minimizer\n                elif p < self.prob_surrogate and len(X_arch) >= max(8, 3 * k):\n                    # build center as weighted mean of top recent points\n                    K = min(len(X_arch), self.archive_size)\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    topk = max(4, int(0.12 * K))\n                    ids = np.argsort(fr)[:topk]\n                    C = np.mean(Xr[ids], axis=0)\n                    # choose U_sub as current U (or PCA of local cluster)\n                    if k > 0:\n                        U_sub = U.copy()\n                        g_sub, H_sub = fit_quad_subspace(C, U_sub, Xr, fr)\n                        if g_sub is not None and H_sub is not None:\n                            # try to solve H u = -g for subspace minimizer u*\n                            # regularize H to ensure invertibility\n                            reg = 1e-6 * np.eye(H_sub.shape[0])\n                            try:\n                                # ensure symmetric\n                                Hs = 0.5 * (H_sub + H_sub.T) + reg\n                                # add damping if ill-conditioned\n                                cond = np.linalg.cond(Hs)\n                                if cond > 1e12:\n                                    lam = 1e-3\n                                    Hs = Hs + lam * np.eye(Hs.shape[0])\n                                u_star = -np.linalg.solve(Hs, g_sub)\n                                # limit move in subspace\n                                norm_sub = np.linalg.norm(u_star)\n                                max_sub = 6.0 * sigma0\n                                if norm_sub > max_sub:\n                                    u_star = u_star * (max_sub / (norm_sub + 1e-12))\n                                x_star = C + U_sub.dot(u_star)\n                                x_cand = np.minimum(np.maximum(x_star, lb), ub)\n                                step = x_cand - m\n                                strategy = 'surrogate'\n                            except Exception:\n                                x_cand = None\n                        else:\n                            x_cand = None\n                    else:\n                        x_cand = None\n\n                # coordinate 1-D quadratic refinement\n                elif p < self.prob_surrogate + self.prob_coord and len(X_arch) >= 6:\n                    # choose a promising coordinate (largest variance in archive or random)\n                    Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                    var = np.var(Xr, axis=0)\n                    # bias to coordinates with larger RMS accumulation too\n                    coord_weights = var + 1e-6\n                    j = int(rng.choice(self.dim, p=(coord_weights / coord_weights.sum())))\n                    # pick center as best recent\n                    K = min(len(X_arch), max(8, self.dim * 2))\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    C = Xr[np.argmin(fr)].copy()\n                    # sample three points: C, C + a e_j, C - a e_j\n                    a = sigma0 * max(0.5, rng.rand() * 2.0)\n                    pts = [C.copy(),\n                           np.minimum(np.maximum(C + a * np.eye(self.dim)[j], lb), ub),\n                           np.minimum(np.maximum(C - a * np.eye(self.dim)[j], lb), ub)]\n                    # check budget for 2 evaluations (C may be already in archive but still cost to evaluate)\n                    needed = 2\n                    if evals + needed <= self.budget:\n                        fpts = []\n                        for pnt in pts[1:]:\n                            fx = float(func(pnt)); evals += 1\n                            X_arch.append(pnt.copy()); f_arch.append(fx)\n                            fpts.append(fx)\n                        # we need f(C) — get from archive if present else evaluate\n                        fC = None\n                        # try to find f(C) in archive (exact match)\n                        for xi, fi in zip(X_arch, f_arch):\n                            if np.allclose(xi, C):\n                                fC = fi; break\n                        if fC is None:\n                            if evals < self.budget:\n                                fC = float(func(C)); evals += 1\n                                X_arch.append(C.copy()); f_arch.append(fC)\n                            else:\n                                fC = min(f_arch)  # fallback\n                        f0 = fC; f1 = fpts[0]; f2 = fpts[1]\n                        denom = (f1 + f2 - 2.0 * f0)\n                        if abs(denom) > 1e-12:\n                            alpha_star = (a * (f2 - f1)) / (2.0 * denom)\n                            alpha_star = np.clip(alpha_star, -3.0 * a, 3.0 * a)\n                            x_star = np.minimum(np.maximum(C + alpha_star * np.eye(self.dim)[j], lb), ub)\n                            if evals < self.budget:\n                                f_star = float(func(x_star)); evals += 1\n                                X_arch.append(x_star.copy()); f_arch.append(f_star)\n                                x_cand = x_star.copy()\n                                step = x_cand - m\n                                strategy = 'coord'\n                            else:\n                                # fallback to best of the sampled points\n                                best_idx = np.argmin([f0, f1, f2])\n                                if best_idx == 0:\n                                    x_cand = C.copy()\n                                elif best_idx == 1:\n                                    x_cand = pts[1].copy()\n                                else:\n                                    x_cand = pts[2].copy()\n                                step = x_cand - m\n                                strategy = 'coord_fallback'\n                        else:\n                            # fallback\n                            best_idx = np.argmin([f0, f1, f2])\n                            if best_idx == 0:\n                                x_cand = C.copy()\n                            elif best_idx == 1:\n                                x_cand = pts[1].copy()\n                            else:\n                                x_cand = pts[2].copy()\n                            step = x_cand - m\n                            strategy = 'coord_fallback'\n                    else:\n                        x_cand = None\n\n                # default low-rank + diagonal gaussian probe\n                if x_cand is None:\n                    if k > 0 and rng.rand() < 0.88:\n                        # sample subspace coordinate z and residual eps\n                        z = rng.randn(k)\n                        eps = rng.randn(self.dim)\n                        step = U.dot(z * s_sub) + 0.7 * (sigma_diag * eps)\n                        x_cand = m + step\n                        strategy = 'lowrank'\n                    else:\n                        # pure coordinate-wise jitter\n                        eps = rng.randn(self.dim)\n                        step = sigma_diag * eps\n                        x_cand = m + step\n                        strategy = 'diag'\n\n                # clip and evaluate once (ensure not exceeding budget)\n                x_cand = np.minimum(np.maximum(x_cand, lb), ub)\n                if evals >= self.budget:\n                    break\n                f_c = float(func(x_cand)); evals += 1\n                X_arch.append(x_cand.copy()); f_arch.append(f_c)\n                # FIFO archive control\n                if len(X_arch) > self.archive_size:\n                    del X_arch[0]; del f_arch[0]\n\n                improved = False\n                if f_c < f_best:\n                    f_best = f_c\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # compute reward signal based on improvement relative to archive min\n                baseline = np.min(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                reward = raw_reward / (sigma0 * step_norm + 1e-12)\n\n                # update v_rms and sigma_diag (coordinate adaptive)\n                sq = (step / (sigma0 + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq\n                sigma_diag = np.clip(sigma0 / (np.sqrt(v_rms) + 1e-8), self.min_sigma, self.max_sigma)\n\n                # update subspace scale and energies if a subspace direction was used\n                if k > 0 and strategy in ('lowrank', 'surrogate'):\n                    # project step to subspace\n                    projs = U.T.dot(step) if U.size else np.array([])\n                    abs_projs = np.abs(projs)\n                    if abs_projs.size > 0 and abs_projs.sum() > 0:\n                        idx = int(np.argmax(abs_projs))\n                        # additive energy update\n                        alpha_e = 0.22\n                        contrib = abs_projs[idx] / (abs_projs.sum() + 1e-12)\n                        sub_energy[idx] += alpha_e * reward * contrib\n                        # EWMA of subspace scales (increase scales on rewarding directions)\n                        s_sub = np.clip(0.98 * s_sub + 0.02 * (0.5 * (s_sub + np.maximum(abs_projs, 1e-8))),\n                                        self.min_sigma, self.max_sigma)\n                        sub_energy = np.clip(sub_energy * 0.997, 1e-6, 1e6)\n\n                # acceptance: if better or probabilistic uphill based on T\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    T = max(1e-12, self.accept_temp_coeff * sigma0 * avg_span)\n                    deltaE = f_c - f_best\n                    # note: f_best may have changed earlier; use max(0, delta)\n                    if rng.rand() < np.exp(-max(0.0, deltaE) / (T + 1e-12)):\n                        accept = True\n\n                if accept:\n                    # learning rates by strategy\n                    if strategy in ('surrogate',):\n                        lr = 0.78\n                    elif strategy in ('coord', 'coord_fallback'):\n                        lr = 0.55\n                    elif strategy in ('heavy',):\n                        lr = 0.3\n                    elif strategy in ('lowrank',):\n                        lr = 0.32\n                    else:\n                        lr = 0.22\n                    delta = x_cand - m\n                    # trust clipping: avoid extremely large jumps\n                    trust = 6.0 * sigma0 * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                    # on success shrink global sigma for refinement\n                    if improved:\n                        sigma0 = max(self.min_sigma, sigma0 * 0.88)\n                        # shrink v_rms a bit to adapt to new scale\n                        v_rms *= 0.96\n                        # slightly increase subspace energy of used directions (if any)\n                        if k > 0 and 'projs' in locals() and projs.size > 0:\n                            sub_energy = 0.995 * sub_energy\n                    else:\n                        # uphill acceptance: allow exploration increase slightly\n                        sigma0 = min(self.max_sigma, sigma0 * 1.03)\n                else:\n                    # not accepted: small randomized drift of mean and mild sigma increase\n                    m = np.minimum(np.maximum(m + 0.01 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma0 = min(self.max_sigma, sigma0 * 1.01)\n\n                # occasionally rotate/perturb subspace a little\n                if k > 0 and rng.rand() < 0.035:\n                    R = rng.randn(k, k) * 0.05\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(k) + R)\n                        U = U.dot(Qr)\n                        Q2, _ = np.linalg.qr(U)\n                        U = Q2[:, :k]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed on stagnation\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    # reset mean near best and inflate sigma\n                    jitter = max(0.05 * avg_span, 1.2 * sigma0)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma0 = min(self.max_sigma, sigma0 * 1.9)\n                    # randomize U\n                    if k > 0:\n                        A = rng.randn(self.dim, k)\n                        Q, _ = np.linalg.qr(A)\n                        U = Q[:, :k]\n                        s_sub = np.full(k, sigma0 / np.sqrt(k))\n                        sub_energy = np.ones(k)\n                    # add a few reseed evals around best\n                    reseed = min(8, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.08 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = float(func(x)); evals += 1\n                        X_arch.append(x.copy()); f_arch.append(fx)\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n                        if len(X_arch) > self.archive_size:\n                            del X_arch[0]; del f_arch[0]\n                        if evals >= self.budget:\n                            break\n\n                # end candidate\n\n            # end generation\n\n        # store results\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 2767, in norm, the following error occurred:\nTypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'", "error": "In the code, line 2767, in norm, the following error occurred:\nTypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'", "parent_ids": "8f9b8432-bed7-423d-acbf-0d52d6028a4e", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "dfae13cf-938c-4ed5-bd6e-9f9faedb3977", "fitness": 0.19634380464179485, "name": "ALCOVA", "description": "ALCOVA maintains a compact orthonormal direction bank D (r ≈ dim/6) with multiplicative, normalized direction \"energies\" (alpha_e, energy_decay) that bias directional sampling and are gently updated via SVD of recent archive entries, occasional random rotations, and rank‑one nudges from successful steps. Sampling is a probabilistic mixture of tuned strategies — heavy‑tailed Lévy-like global jumps, cheap diagonal quadratic targeting, 1‑D quadratic line probes, elliptical sampling from top archive points, and default directional/coordinate Gaussian probes — with per‑dimension adaptive scales sigma_i driven by an RMS estimator (rms_beta) and a larger initial sigma (init_sigma_mult). Acceptance is Metropolis‑style with an elevated temperature (accept_temp_coeff) to allow controlled uphill moves, and accepted steps move the mean m with strategy‑dependent learning rates and trust clipping (4·sigma0·sqrt(dim)); sigma0 is contracted strongly on improvement (×0.85) and mildly expanded on uphill (×1.05). The algorithm is budget‑aware and archive‑centric (archive_size = max(6·dim,120)), keeps careful evaluation accounting, and uses opportunistic reseeding/local sampling on stagnation to maintain exploration vs refinement balance.", "code": "import numpy as np\n\nclass ALCOVA:\n    \"\"\"\n    Adaptive Local Covariant Oriented Search (ALCOVA)\n\n    Main ideas / differences vs the provided DAPCA:\n    - Direction bank energies are multiplicative (soft, normalized weights) rather\n      than additive; updated multiplicatively with a small factor alpha_e and\n      gently decayed by energy_decay.\n    - Slightly larger initial global sigma (init_sigma_mult=0.25 vs 0.18) and\n      more aggressive RMS forgetting (rms_beta=0.85 vs 0.92).\n    - Different strategy probabilities (lower target-quadratic, higher line probes,\n      explicit elliptical sampling probability).\n    - Acceptance temperature coefficient higher (accept_temp_coeff=0.8 vs 0.5),\n      allowing more uphill exploration in a controlled way.\n    - On success sigma0 shrinks by 0.85 (stronger refinement); uphill expands by 1.05.\n    - Trust clipping is tighter (4·sigma0·sqrt(dim) instead of 6·...).\n    - Uses multiplicative energy updates with normalization and small decay (energy_decay).\n    - Occasional elliptical proposals built from top-ranked archive points (cheap covariance).\n    - Keeps careful budget accounting; never calls func more than self.budget times.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=16, archive_size=None, dir_count=None,\n                 init_sigma_mult=0.25, rms_beta=0.85,\n                 dir_refresh=8, prob_target=0.08, prob_line=0.10,\n                 heavy_tail_prob=0.06, prob_ellipse=0.10,\n                 accept_temp_coeff=0.8, alpha_e=0.18, energy_decay=0.995,\n                 min_sigma=1e-9, max_sigma=7.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.archive_size = archive_size if archive_size is not None else max(6 * self.dim, 120)\n        self.dir_count = dir_count if dir_count is not None else max(1, self.dim // 6)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.rms_beta = float(rms_beta)\n        self.dir_refresh = int(dir_refresh)\n        self.prob_target = float(prob_target)\n        self.prob_line = float(prob_line)\n        self.heavy_tail_prob = float(heavy_tail_prob)\n        self.prob_ellipse = float(prob_ellipse)\n        self.accept_temp_coeff = float(accept_temp_coeff)\n        self.alpha_e = float(alpha_e)\n        self.energy_decay = float(energy_decay)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling (default -5..5)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial mean (center)\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # initial global sigma and per-dim adaptive scales\n        sigma0 = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        sigma_i = np.full(self.dim, sigma0)\n        v_rms = np.full(self.dim, 1e-6)\n\n        # direction bank D and multiplicative energies (normalized weights)\n        r = min(self.dir_count, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            D = Q[:, :r].copy()\n            d_energy = np.ones(r, dtype=float) / float(r)  # normalized weights\n        else:\n            D = np.zeros((self.dim, 0))\n            d_energy = np.array([])\n\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # seed archive with a few random samples (budget-aware)\n        seed_init = min(self.pop * 3, max(8, int(self.budget // 150)))\n        for _ in range(seed_init):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(10, int(0.04 * self.budget))\n\n        # helper: robust per-dim diagonal quadratic fit (weighted)\n        def fit_diag_quad_center(C, Xs, fs, reg=1e-6):\n            K = Xs.shape[0]\n            dX = Xs - C[None, :]\n            g = np.zeros(self.dim)\n            h = np.ones(self.dim) * 1e-6\n            y = fs\n            for j in range(self.dim):\n                uj = dX[:, j]\n                A = np.vstack([np.ones(K), uj, uj * uj]).T\n                # tiny ridge for stability\n                try:\n                    theta, *_ = np.linalg.lstsq(A, y, rcond=None)\n                    g[j] = float(theta[1])\n                    h_est = float(theta[2]) * 2.0\n                    if abs(h_est) < reg:\n                        h_est = np.sign(h_est) * reg if h_est != 0 else reg\n                    h[j] = h_est\n                except Exception:\n                    g[j] = 0.0\n                    h[j] = 1e-6\n            return g, h\n\n        # main loop: generate small batches each generation\n        while evals < self.budget:\n            gen += 1\n\n            # refresh directions from recent high-quality moves occasionally\n            if (gen % self.dir_refresh == 0) and len(X_arch) >= max(4, r):\n                K = min(len(X_arch), self.archive_size)\n                Xr = np.asarray(X_arch[-K:])\n                M = np.mean(Xr, axis=0)\n                S = (Xr - M)\n                try:\n                    U, Svals, Vt = np.linalg.svd(S, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        D_new = Vt[:r_eff].T\n                        # mix gently with existing D, but favor new principal directions slightly more\n                        D = 0.7 * D + 0.3 * D_new\n                        Q, _ = np.linalg.qr(D)\n                        D = Q[:, :r_eff]\n                        # update energy by projecting singular values multiplicatively\n                        if d_energy.size > 0:\n                            raw = Svals[:r_eff] + 1e-8\n                            # multiply energies by normalized Svals^(0.5)\n                            mult = (raw / (np.sum(raw) + 1e-12)) ** 0.5\n                            d_energy = d_energy * (1.0 + 0.2 * mult)\n                            # normalize and gently decay\n                            d_energy = d_energy / (np.sum(d_energy) + 1e-12)\n                            d_energy = d_energy * (self.energy_decay ** 1.0)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # how many candidates to propose now\n            n_cand = min(self.pop, max(1, self.budget - evals))\n\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                x_cand = None\n                step = None\n                strategy = 'random'\n\n                # heavy-tail global jump (scaled Cauchy / Lévy-like)\n                if rng.rand() < self.heavy_tail_prob:\n                    z = rng.standard_cauchy(size=self.dim)\n                    # normalize outliers robustly and scale\n                    z = z / (np.percentile(np.abs(z), 85) + 1e-12)\n                    x_cand = m + sigma0 * 4.0 * z\n                    strategy = 'levy_heavy'\n\n                # targeted cheap diagonal quadratic from good recent center (fewer prob than DAPCA)\n                elif p < self.prob_target and len(X_arch) >= 8:\n                    K = min(len(X_arch), max(10, self.dim * 3))\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    topk = max(3, int(0.10 * K))\n                    ids = np.argsort(fr)[:topk]\n                    C = np.mean(Xr[ids], axis=0)\n                    try:\n                        g_diag, h_diag = fit_diag_quad_center(C, Xr, fr)\n                        dx = - g_diag / (h_diag + 1e-12)\n                        norm_dx = np.linalg.norm(dx)\n                        max_move = 3.0 * sigma0  # slightly smaller trust in diagonal minimizer\n                        if norm_dx > max_move:\n                            dx = dx * (max_move / (norm_dx + 1e-12))\n                        x_cand = C + dx\n                        step = x_cand - m\n                        strategy = 'target_diag'\n                    except Exception:\n                        x_cand = None\n\n                # 1-D quadratic probe (more common than in DAPCA)\n                elif p < self.prob_target + self.prob_line and len(X_arch) >= 8 and r > 0:\n                    # choose direction by multiplicative weights\n                    weights = d_energy / (np.sum(d_energy) + 1e-12)\n                    idx = rng.choice(r, p=weights)\n                    dvec = D[:, idx]\n                    # center from best recent\n                    K = min(len(X_arch), max(8, self.dim * 2))\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    C = Xr[np.argmin(fr)].copy()\n                    a = sigma0 * max(0.5, rng.rand() * 2.2)\n                    pts = [C,\n                           np.minimum(np.maximum(C + a * dvec, lb), ub),\n                           np.minimum(np.maximum(C - a * dvec, lb), ub)]\n                    needed = 3  # will evaluate these three\n                    if evals + needed <= self.budget:\n                        fs = []\n                        for x in pts:\n                            fx = float(func(x)); evals += 1\n                            fs.append(fx)\n                            X_arch.append(x.copy()); f_arch.append(fx)\n                        f0, f1, f2 = fs[0], fs[1], fs[2]\n                        denom = (f1 + f2 - 2.0 * f0)\n                        if abs(denom) > 1e-12:\n                            alpha_star = (a * (f2 - f1)) / (2.0 * denom)\n                            alpha_star = np.clip(alpha_star, -2.0 * a, 2.0 * a)\n                            x_star = np.minimum(np.maximum(C + alpha_star * dvec, lb), ub)\n                            # before evaluating final x_star ensure budget\n                            if evals < self.budget:\n                                f_star = float(func(x_star)); evals += 1\n                                X_arch.append(x_star.copy()); f_arch.append(f_star)\n                                x_cand = x_star\n                                step = x_cand - m\n                                strategy = 'line_refine'\n                            else:\n                                # fallback to best of three\n                                best_idx = int(np.argmin(fs))\n                                x_cand = pts[best_idx].copy()\n                                step = x_cand - m\n                                strategy = 'line_fallback'\n                        else:\n                            best_idx = int(np.argmin(fs))\n                            x_cand = pts[best_idx].copy()\n                            step = x_cand - m\n                            strategy = 'line_flat'\n                    else:\n                        # not enough budget -> skip this special probe\n                        x_cand = None\n\n                # elliptical proposal from top archive points (cheap covariance approximation)\n                elif p < self.prob_target + self.prob_line + self.prob_ellipse and len(X_arch) >= max(6, 2 * self.dim):\n                    K = min(len(X_arch), max(12, 3 * self.dim))\n                    fr = np.asarray(f_arch[-K:])\n                    Xr = np.asarray(X_arch[-K:])\n                    topk = max(6, int(0.15 * K))\n                    ids = np.argsort(fr)[:topk]\n                    Xtop = Xr[ids]\n                    center = np.mean(Xtop, axis=0)\n                    # compute simple diagonal + low-rank covariance\n                    diffs = Xtop - center[None, :]\n                    cov_diag = np.var(diffs, axis=0) + 1e-8\n                    # sample elliptical Gaussian: use diagonal + small random low-rank perturbation\n                    z = rng.randn(self.dim)\n                    lowrank = np.zeros(self.dim)\n                    if diffs.shape[0] >= 2:\n                        # project onto first singular vector for modest anisotropy\n                        try:\n                            U, Svals, Vt = np.linalg.svd(diffs, full_matrices=False)\n                            topv = Vt[0]\n                            lowrank = (rng.randn() * 0.4 * Svals[0]) * topv\n                        except Exception:\n                            lowrank = np.zeros(self.dim)\n                    sample = center + (sigma0 * (0.8 * np.sqrt(cov_diag) * z + lowrank))\n                    x_cand = np.minimum(np.maximum(sample, lb), ub)\n                    strategy = 'ellipse'\n\n                # default directional or coordinate probe\n                if x_cand is None:\n                    if r > 0 and rng.rand() < 0.78:\n                        weights = d_energy / (np.sum(d_energy) + 1e-12)\n                        idx = rng.choice(r, p=weights)\n                        dvec = D[:, idx]\n                        z = rng.randn() * 0.9\n                        jitter = rng.randn(self.dim) * sigma_i\n                        step = z * sigma0 * dvec + 0.7 * jitter\n                        x_cand = m + step\n                        strategy = 'dir_sample'\n                    else:\n                        jitter = rng.randn(self.dim) * sigma_i\n                        step = jitter\n                        x_cand = m + step\n                        strategy = 'coord_sample'\n\n                # enforce bounds\n                x_cand = np.minimum(np.maximum(x_cand, lb), ub)\n\n                # ensure we have remaining budget before evaluating\n                if evals >= self.budget:\n                    break\n                f_c = float(func(x_cand)); evals += 1\n                X_arch.append(x_cand.copy()); f_arch.append(f_c)\n\n                # keep archive FIFO\n                if len(X_arch) > self.archive_size:\n                    del X_arch[0]; del f_arch[0]\n\n                improved = False\n                if f_c < f_best:\n                    f_best = f_c\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # ensure a step vector is defined\n                if step is None:\n                    step = x_cand - m\n\n                step_norm = np.linalg.norm(step) + 1e-12\n                baseline = np.min(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                reward = raw_reward / (sigma0 * step_norm + 1e-12)\n\n                # RMS update, different forgetting\n                sq_norm = (step / (sigma0 + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq_norm\n                sigma_i = np.clip(sigma0 / (np.sqrt(v_rms) + 1e-8), self.min_sigma, self.max_sigma)\n\n                # direction energy multiplicative update for used direction(s)\n                if r > 0 and strategy in ('dir_sample', 'line_refine', 'line_fallback', 'line_flat'):\n                    projs = D.T.dot(step)\n                    abs_projs = np.abs(projs)\n                    if np.sum(abs_projs) > 0:\n                        idx = int(np.argmax(abs_projs))\n                        contrib = abs_projs[idx] / (np.sum(abs_projs) + 1e-12)\n                        # multiplicative bump\n                        d_energy[idx] = d_energy[idx] * (1.0 + self.alpha_e * reward * contrib)\n                        # small decay and renormalize\n                        d_energy = d_energy * (self.energy_decay)\n                        # avoid collapse to zero; renormalize\n                        s = np.sum(d_energy)\n                        if s <= 0:\n                            d_energy = np.ones_like(d_energy) / float(len(d_energy))\n                        else:\n                            d_energy = d_energy / s\n\n                # acceptance test: improved or probabilistic uphill acceptance with larger temp\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    T = max(1e-12, self.accept_temp_coeff * sigma0 * avg_span)\n                    # Metropolis-style acceptance using difference to current best\n                    if rng.rand() < np.exp(-max(0.0, f_c - f_best) / (T + 1e-12)):\n                        accept = True\n\n                if accept:\n                    # different learning rates per strategy (tuned)\n                    if strategy in ('target_diag',):\n                        lr = 0.78\n                    elif strategy in ('line_refine', 'line_fallback', 'line_flat'):\n                        lr = 0.60\n                    elif strategy in ('levy_heavy',):\n                        lr = 0.35\n                    elif strategy in ('dir_sample',):\n                        lr = 0.30\n                    elif strategy in ('ellipse',):\n                        lr = 0.45\n                    else:\n                        lr = 0.24\n                    delta = x_cand - m\n                    # trust clipping is tighter than in original\n                    trust = 4.0 * sigma0 * np.sqrt(self.dim)\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                    # adjust sigma0 based on improvement/uphill\n                    if improved:\n                        sigma0 = max(self.min_sigma, sigma0 * 0.85)\n                        # allow faster RMS decay after success to adapt\n                        v_rms *= 0.95\n                        # incorporate successful direction into D (rank-one nudging)\n                        if r > 0:\n                            success_dir = delta.copy()\n                            if np.linalg.norm(success_dir) > 1e-12:\n                                success_dir = success_dir / (np.linalg.norm(success_dir) + 1e-12)\n                                # small rank-one update and re-orthonormalize\n                                D[:, 0] = 0.9 * D[:, 0] + 0.1 * success_dir\n                                try:\n                                    Q2, _ = np.linalg.qr(D)\n                                    D = Q2[:, :r]\n                                except Exception:\n                                    pass\n                    else:\n                        # uphill accepted: gentle increase in exploration\n                        sigma0 = min(self.max_sigma, sigma0 * 1.05)\n                else:\n                    # not accepted: small mean jitter and tiny sigma inflation\n                    m = np.minimum(np.maximum(m + 0.015 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma0 = min(self.max_sigma, sigma0 * 1.01)\n\n                # small random rotation of direction bank occasionally\n                if r > 0 and rng.rand() < 0.025:\n                    R = rng.randn(r, r) * 0.05\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(r) + R)\n                        D = D.dot(Qr)\n                        Q2, _ = np.linalg.qr(D)\n                        D = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed on longer stagnation but milder than DAPCA\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    jitter = max(0.04 * avg_span, 0.9 * sigma0)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma0 = min(self.max_sigma, sigma0 * 1.6)\n                    # refresh one random direction by sampling a new orthonormal vector\n                    if r > 0:\n                        v = rng.randn(self.dim)\n                        v = v / (np.linalg.norm(v) + 1e-12)\n                        D[:, rng.randint(r)] = v\n                        try:\n                            Q, _ = np.linalg.qr(D)\n                            D = Q[:, :r]\n                        except Exception:\n                            pass\n                        # redistribute energies uniformly\n                        d_energy = np.ones_like(d_energy) / float(len(d_energy))\n                    # add a few local samples near best (budget-aware)\n                    reseed = min(4, self.budget - evals)\n                    for _ in range(reseed):\n                        if evals >= self.budget:\n                            break\n                        x = np.minimum(np.maximum(x_best + 0.05 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = float(func(x)); evals += 1\n                        X_arch.append(x.copy()); f_arch.append(fx)\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n                        if len(X_arch) > self.archive_size:\n                            del X_arch[0]; del f_arch[0]\n\n            # end candidates in generation\n\n        # final results\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ALCOVA scored 0.196 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "8f9b8432-bed7-423d-acbf-0d52d6028a4e", "operator": null, "metadata": {"aucs": [0.09776480300247614, 0.17031507507447752, 0.2660695418538235, 0.22552269971042738, 0.2045852386855893, 0.25491675431650174, 0.21548159496470765, 0.2057839316083434, 0.1841254419231172, 0.1388729652784848]}, "task_prompt": ""}
{"id": "9ca77093-e9fb-4d30-a649-abd9c1038522", "fitness": 0.2395812621231189, "name": "MARSHA", "description": "MARSHA is a small multi-center trust-region style hybrid that maintains a few “guild” centers (default centers=3, pop=14) each with its own trust radius initialized at 20% of the problem span (init_tr_ratio=0.20) to balance global exploration and local refinement. Proposals are anisotropic via a low-rank covariance factor U (cov_rank ≈ dim/6) plus a diagonal jitter scale and an RMS accumulator, and U is updated by rank‑one exponential pushes from successful normalized steps to capture useful search directions cheaply. The algorithm mixes diverse strategies — truncated Lévy heavy‑tail jumps, locally weighted per‑dimension quadratic minimizers (using an archive of recent points), short stochastic line probes toward the global best, centroid recombination, and default low‑rank Gaussian probes — with small tuned probabilities (levy 0.06, quad 0.18, line 0.08, recomb 0.06) and cheap mirrored retries on rejects to salvage candidates. Control and robustness come from an archive for local modeling (~max(6*dim,120)), reward‑scaled center energies and trust‑radius adaptation (shrink on success, expand on failure), a temperature‑based probabilistic acceptance, and periodic stagnation reseeding of weak centers to escape local optima.", "code": "import numpy as np\n\nclass MARSHA:\n    \"\"\"\n    MARSHA: Multi-scale Adaptive Radial Surrogate Hybrid Algorithm\n\n    Key novel mechanisms:\n    - Maintain a small set of 'centers' (guild members) each with its own trust radius.\n    - Use a low-rank covariance factor U plus a diagonal scale to create anisotropic proposals\n      (efficient rank-r covariance adaptation).\n    - Fit locally-weighted diagonal quadratics (per-dimension) around a center using nearby\n      archive points and a Gaussian weight kernel to propose a model minimizer.\n    - Mix strategies: low-rank Gaussian probes, Lévy-like heavy tail jumps, local quadratic minimizers,\n      short line probes, centroid recombination of centers, and mirrored/reflected retries when rejected.\n    - Update covariance factors with successful normalized steps (rank-one exponential smoothing).\n    - Adaptive per-center trust radii shrink on success for local refinement and expand slowly on failures.\n    - Occasional multi-center recombination and targeted reseeds to avoid long stagnation.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=14, centers=3, cov_rank=None, init_tr_ratio=0.20,\n                 levy_prob=0.06, quad_prob=0.18, line_prob=0.08,\n                 recomb_prob=0.06, mirror_prob=0.09,\n                 archive_size=None, rms_beta=0.95,\n                 min_tr=1e-5, max_tr=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.centers = int(max(1, centers))\n        self.cov_rank = cov_rank if cov_rank is not None else max(1, self.dim // 6)\n        self.init_tr_ratio = float(init_tr_ratio)\n        self.levy_prob = float(levy_prob)\n        self.quad_prob = float(quad_prob)\n        self.line_prob = float(line_prob)\n        self.recomb_prob = float(recomb_prob)\n        self.mirror_prob = float(mirror_prob)\n        self.archive_size = archive_size if archive_size is not None else max(6 * self.dim, 120)\n        self.rms_beta = float(rms_beta)\n        self.min_tr = float(min_tr)\n        self.max_tr = float(max_tr)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # get bounds (or assume -5..5)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial trust radius (global baseline) -> per-center radii\n        init_tr = max(self.min_tr, self.init_tr_ratio * avg_span)\n        tr_center = np.full(self.centers, init_tr, dtype=float)\n\n        # low-rank covariance factor U (dim x r) and diagonal scales dscale\n        r = min(self.cov_rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :r].copy()           # columns are orthonormal directions\n        else:\n            U = np.zeros((self.dim, 0))\n        dscale = np.full(self.dim, init_tr)  # diagonal jitter scale\n        # RMS accumulator to maintain per-dim sensitivity\n        v_rms = np.full(self.dim, 1e-6)\n\n        # centers (guild): positions, energies, successes\n        C = [rng.uniform(lb, ub, size=self.dim) for _ in range(self.centers)]\n        c_energy = np.ones(self.centers, dtype=float)\n        c_success = np.zeros(self.centers, dtype=int)\n\n        # archive (FIFO)\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # initial seed: evaluate each center and a few random points to populate archive\n        seed_count = min(self.budget, max(self.centers + 6, int(0.01 * self.budget)))\n        initial_points = []\n        for i in range(self.centers):\n            initial_points.append(C[i].copy())\n        while len(initial_points) < seed_count:\n            initial_points.append(rng.uniform(lb, ub, size=self.dim))\n        for x0 in initial_points:\n            if evals >= self.budget:\n                break\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # helper: locally-weighted diagonal quadratic fit (per-dim) around center C0\n        def local_weighted_diag_quad(C0, Xs, fs, tr):\n            # weights by distance squared with bandwidth = tr * (1 + small)\n            if Xs.shape[0] < 4:\n                # fallback to simple finite-diff gradient approximation\n                g = np.zeros(self.dim)\n                h = np.full(self.dim, 1e-3)\n                return g, h\n            dX = Xs - C0[None, :]\n            d2 = np.sum((dX / (tr + 1e-12)) ** 2, axis=1)\n            w = np.exp(-0.5 * d2)\n            W = w / (np.sum(w) + 1e-12)\n            # per-dim fit: y ≈ c + g_j * dx_j + 0.5 h_j dx_j^2\n            K = Xs.shape[0]\n            g = np.zeros(self.dim)\n            h = np.ones(self.dim) * 1e-6\n            y = fs\n            for j in range(self.dim):\n                uj = dX[:, j]\n                # weighted normal equations for [1, u, u^2]\n                A = np.vstack([np.ones(K), uj, uj * uj]).T\n                Aw = A * w[:, None]\n                try:\n                    theta, *_ = np.linalg.lstsq(Aw, w * y, rcond=None)\n                    g[j] = float(theta[1])\n                    h_est = float(theta[2]) * 2.0\n                    if abs(h_est) < 1e-8:\n                        h_est = np.sign(h_est) * 1e-8 if h_est != 0 else 1e-8\n                    h[j] = h_est\n                except Exception:\n                    g[j] = 0.0\n                    h[j] = 1e-6\n            return g, h\n\n        # helper: low-rank anisotropic sampler\n        def sample_low_rank(tradius):\n            # sample coefficients in low-rank subspace and diag noise\n            if r > 0:\n                z = rng.randn(r)\n                # scale coefficients proportional to singular-like lengths (use tradius)\n                y = U.dot(z) * (tradius * 1.0)\n            else:\n                y = np.zeros(self.dim)\n            # diagonal jitter\n            jitter = rng.randn(self.dim) * dscale\n            return y + 0.9 * jitter\n\n        # helper: truncated Lévy-like sample\n        def levy_like(scale):\n            # symmetric alpha-stable approximation via Cauchy scaling but truncation\n            z = rng.standard_cauchy(size=self.dim)\n            # moderate truncation using percentile\n            z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n            return scale * z\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(12, int(0.03 * self.budget))\n\n        # main loop: generate small candidate batch per generation\n        while evals < self.budget:\n            gen += 1\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            # choose a primary center for this generation biased by energy\n            center_weights = c_energy / (np.sum(c_energy) + 1e-12)\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                # select a center index\n                ci = rng.choice(self.centers, p=center_weights)\n                center = C[ci].copy()\n                tr = tr_center[ci]\n                strategy = 'lowrank'\n                x_cand = None\n                used_extra = 0  # extra evals used by multi-eval strategies\n\n                p = rng.rand()\n                # heavy-tailed Lévy jump (global)\n                if p < self.levy_prob:\n                    step = levy_like(tr * 3.0)\n                    x_cand = np.minimum(np.maximum(center + step, lb), ub)\n                    strategy = 'levy'\n                # targeted local quadratic minimizer (single eval)\n                elif p < self.levy_prob + self.quad_prob and len(X_arch) >= 8:\n                    # select neighbors within 3*tr radius, if none, take nearest K\n                    Xs = np.asarray(X_arch)\n                    fs = np.asarray(f_arch)\n                    d2 = np.sum(((Xs - center) / (tr + 1e-12)) ** 2, axis=1)\n                    mask = d2 < (9.0)  # within 3*tr (in scaled units)\n                    if np.sum(mask) < 6:\n                        # adopt closest K points\n                        ids = np.argsort(d2)[:min(len(d2), max(6, 3 * self.dim))]\n                        Xsel = Xs[ids]; fsel = fs[ids]\n                    else:\n                        ids = np.where(mask)[0]\n                        Xsel = Xs[ids]; fsel = fs[ids]\n                    try:\n                        g_diag, h_diag = local_weighted_diag_quad(center, Xsel, fsel, tr)\n                        dx = - g_diag / (h_diag + 1e-12)\n                        # trust clip: do not move more than 4*tr\n                        norm_dx = np.linalg.norm(dx)\n                        max_move = 4.0 * tr\n                        if norm_dx > max_move:\n                            dx = dx * (max_move / (norm_dx + 1e-12))\n                        x_cand = np.minimum(np.maximum(center + dx, lb), ub)\n                        strategy = 'local_quad'\n                    except Exception:\n                        x_cand = None\n                # short stochastic line probe between center and best\n                elif p < self.levy_prob + self.quad_prob + self.line_prob:\n                    # pick a direction towards current best and maybe along a principal U direction\n                    if rng.rand() < 0.6 and np.linalg.norm(x_best - center) > 1e-12:\n                        dvec = (x_best - center); dvec = dvec / (np.linalg.norm(dvec) + 1e-12)\n                    elif r > 0:\n                        idx = rng.randint(0, r)\n                        dvec = U[:, idx]\n                    else:\n                        dvec = rng.randn(self.dim)\n                        dvec = dvec / (np.linalg.norm(dvec) + 1e-12)\n                    a = tr * (0.8 + rng.rand() * 2.2)\n                    # three probes: center, center + a*d, center - b*d (b may differ)\n                    pts = [center,\n                           np.minimum(np.maximum(center + a * dvec, lb), ub),\n                           np.minimum(np.maximum(center - 0.6 * a * dvec, lb), ub)]\n                    # ensure budget\n                    needed = len(pts)\n                    if evals + needed <= self.budget:\n                        fs_pts = []\n                        for x in pts:\n                            fx = float(func(x)); evals += 1\n                            X_arch.append(x.copy()); f_arch.append(fx)\n                            fs_pts.append(fx)\n                        # fit simple parabola in alpha symmetric-ish: compute vertex analytically\n                        f0, f1, f2 = fs_pts[0], fs_pts[1], fs_pts[2]\n                        denom = (f1 + f2 - 2.0 * f0)\n                        if abs(denom) > 1e-12:\n                            alpha_star = (a * (f2 - f1)) / (2.0 * denom)\n                            alpha_star = np.clip(alpha_star, -3.0 * a, 3.0 * a)\n                            x_star = np.minimum(np.maximum(center + alpha_star * dvec, lb), ub)\n                            if evals < self.budget:\n                                f_star = float(func(x_star)); evals += 1\n                                X_arch.append(x_star.copy()); f_arch.append(f_star)\n                                x_cand = x_star\n                                used_extra = 0  # already accounted\n                                strategy = 'line_search'\n                            else:\n                                # take best of sampled pts if cannot evaluate extra\n                                best_idx = int(np.argmin(fs_pts))\n                                x_cand = pts[best_idx].copy()\n                                strategy = 'line_fallback'\n                        else:\n                            best_idx = int(np.argmin(fs_pts))\n                            x_cand = pts[best_idx].copy()\n                            strategy = 'line_fallback'\n                    else:\n                        # fallback to low-rank sample below\n                        x_cand = None\n                # recombination between centers\n                elif p < self.levy_prob + self.quad_prob + self.line_prob + self.recomb_prob:\n                    # build convex combination of a few centers weighted by energy\n                    k = min(3, self.centers)\n                    ids = rng.choice(self.centers, size=k, replace=False, p=center_weights)\n                    weights = rng.rand(k)\n                    weights = weights / (np.sum(weights) + 1e-12)\n                    comb = np.zeros(self.dim)\n                    for ii, w in zip(ids, weights):\n                        comb += w * C[ii]\n                    # add small low-rank perturbation\n                    perturb = sample_low_rank(tr * 0.8)\n                    x_cand = np.minimum(np.maximum(comb + perturb, lb), ub)\n                    strategy = 'recomb'\n                else:\n                    # default low-rank anisotropic gaussian\n                    step = sample_low_rank(tr)\n                    x_cand = np.minimum(np.maximum(center + step, lb), ub)\n                    strategy = 'lowrank'\n\n                # ensure not exceeding budget\n                if evals >= self.budget:\n                    break\n\n                # if candidate not yet evaluated by model-fitting above\n                if x_cand is not None:\n                    f_c = float(func(x_cand)); evals += 1\n                    X_arch.append(x_cand.copy()); f_arch.append(f_c)\n                else:\n                    continue\n\n                # keep archive size\n                if len(X_arch) > self.archive_size:\n                    del X_arch[0]; del f_arch[0]\n\n                improved = False\n                if f_c < f_best:\n                    f_best = f_c\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # compute step vector relative to center\n                step_vec = x_cand - center\n                step_norm = np.linalg.norm(step_vec) + 1e-12\n\n                # compute a reward signal (uses archive baseline)\n                baseline = np.min(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                reward = raw_reward / (tr * step_norm + 1e-12)\n\n                # update RMS and diagonal scales\n                sq_norm = (step_vec / (tr + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq_norm\n                dscale = np.clip(tr / (np.sqrt(v_rms) + 1e-8), 1e-8, self.max_tr)\n\n                # covariance (low-rank) rank-one adaptation on success\n                if step_norm > 1e-12 and (improved or reward > 1e-6):\n                    # normalized step direction\n                    ustep = step_vec / step_norm\n                    # exponential smoothing into first column(s) of U (rank-one push)\n                    if r > 0:\n                        alpha_u = 0.18\n                        # rotate/replace slowly: push ustep into U via orthonormalization\n                        # construct candidate matrix with first col updated toward ustep\n                        try:\n                            # combine current U and new vector then re-orthonormalize to keep basis fresh\n                            M = np.hstack([0.98 * U, (alpha_u * reward)[:, None] * ustep.reshape(-1, 1)])\n                            # if shapes mismatch (alpha * reward scalar), broadcast properly\n                            if M.shape[1] > r:\n                                Q, _ = np.linalg.qr(M)\n                                U = Q[:, :r]\n                            else:\n                                Q, _ = np.linalg.qr(M)\n                                U = Q[:, :r]\n                        except Exception:\n                            # fallback simple injection\n                            U[:, 0] = 0.95 * U[:, 0] + 0.05 * ustep\n                            Q, _ = np.linalg.qr(U)\n                            U = Q[:, :r]\n                    # increase center success\n                    c_success[ci] += 1\n                    c_energy[ci] += 0.5 * reward + 0.05\n                    # shrink trust radius for refinement\n                    tr_center[ci] = max(self.min_tr, tr_center[ci] * 0.85)\n                else:\n                    # no strong success: mild decay of center energy and expand trust radius\n                    c_energy[ci] = max(1e-6, c_energy[ci] * 0.995)\n                    tr_center[ci] = min(self.max_tr, tr_center[ci] * 1.01)\n\n                # acceptance rule: always accept if improved; otherwise accept probabilistically\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    # temperature scaled by average trust and span\n                    T = max(1e-12, 0.5 * (np.mean(tr_center) + tr) * avg_span)\n                    if rng.rand() < np.exp(-max(0.0, f_c - f_best) / (T + 1e-12)):\n                        accept = True\n\n                if accept:\n                    # move center slightly towards candidate based on strategy\n                    if strategy in ('local_quad', 'recomb'):\n                        lr = 0.7\n                    elif strategy in ('line_search', 'line_fallback'):\n                        lr = 0.5\n                    elif strategy in ('levy',):\n                        lr = 0.22\n                    else:\n                        lr = 0.3\n                    delta = x_cand - center\n                    # clip large trust moves\n                    trust_limit = 6.0 * tr * np.sqrt(self.dim)\n                    dn = np.linalg.norm(delta)\n                    if dn > trust_limit:\n                        delta = delta * (trust_limit / (dn + 1e-12))\n                    # update center\n                    C[ci] = np.minimum(np.maximum(center + lr * delta, lb), ub)\n                    # on improvement slightly decrease tr for local refinement\n                    if improved:\n                        tr_center[ci] = max(self.min_tr, tr_center[ci] * 0.80)\n                    else:\n                        # uphill accepted: enlarge to allow escape\n                        tr_center[ci] = min(self.max_tr, tr_center[ci] * 1.06)\n                else:\n                    # not accepted: mirror attempt with some probability (cheap retry)\n                    if rng.rand() < self.mirror_prob and evals < self.budget:\n                        # reflect around center: x' = center - (x_cand - center)\n                        x_mirror = np.minimum(np.maximum(center - (x_cand - center), lb), ub)\n                        f_m = float(func(x_mirror)); evals += 1\n                        X_arch.append(x_mirror.copy()); f_arch.append(f_m)\n                        if f_m < f_c:\n                            # accept mirrored if better than original and maybe update center\n                            if f_m < f_best:\n                                f_best = f_m; x_best = x_mirror.copy()\n                                stagn = 0\n                            # update covariance and center similarly\n                            step_vec2 = x_mirror - center\n                            step_norm2 = np.linalg.norm(step_vec2) + 1e-12\n                            if step_norm2 > 1e-12:\n                                if r > 0:\n                                    ustep2 = step_vec2 / step_norm2\n                                    try:\n                                        M2 = np.hstack([0.98 * U, 0.02 * ustep2.reshape(-1, 1)])\n                                        Q2, _ = np.linalg.qr(M2)\n                                        U = Q2[:, :r]\n                                    except Exception:\n                                        pass\n                                # accept mirrored as a center move\n                                C[ci] = np.minimum(np.maximum(center + 0.4 * step_vec2, lb), ub)\n                                tr_center[ci] = max(self.min_tr, tr_center[ci] * 0.9)\n                        # end mirror handling\n\n                # occasional center recombination/replace: if some centers are weak, re-seed them near best\n                weakest = np.argmin(c_energy)\n                if c_success[weakest] < 1 and rng.rand() < 0.02 and evals < self.budget:\n                    # reseed weakest center near best with moderate jitter\n                    jitter = max(0.04 * avg_span, 0.8 * np.mean(tr_center))\n                    C[weakest] = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    # evaluate new center\n                    if evals < self.budget:\n                        f_new = float(func(C[weakest])); evals += 1\n                        X_arch.append(C[weakest].copy()); f_arch.append(f_new)\n                        if f_new < f_best:\n                            f_best = f_new; x_best = C[weakest].copy()\n                        # reset stats\n                        c_energy[weakest] = 1.0\n                        c_success[weakest] = 0\n                    if len(X_arch) > self.archive_size:\n                        del X_arch[0]; del f_arch[0]\n\n                # re-normalize center weights occasionally\n                if rng.rand() < 0.05:\n                    c_energy = 0.9 * c_energy + 0.1 * (1.0 + c_success.astype(float))\n\n                # ensure archive size\n                if len(X_arch) > self.archive_size:\n                    del X_arch[0]; del f_arch[0]\n\n            # end generation\n\n            # stagnation restart if necessary\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                # reseed half of centers around the best with increasing radius\n                for i in range(self.centers // 2):\n                    if evals >= self.budget:\n                        break\n                    jitter = max(0.06 * avg_span, 1.5 * np.mean(tr_center))\n                    idx = (i + gen) % self.centers\n                    C[idx] = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    tr_center[idx] = min(self.max_tr, np.mean(tr_center) * 1.5)\n                    # evaluate\n                    fnew = float(func(C[idx])); evals += 1\n                    X_arch.append(C[idx].copy()); f_arch.append(fnew)\n                    if fnew < f_best:\n                        f_best = fnew; x_best = C[idx].copy()\n                    if len(X_arch) > self.archive_size:\n                        del X_arch[0]; del f_arch[0]\n                # randomize U a bit\n                if r > 0:\n                    A = rng.randn(self.dim, r) * 0.6\n                    try:\n                        Q, _ = np.linalg.qr(U + 0.2 * A)\n                        U = Q[:, :r]\n                    except Exception:\n                        pass\n\n        # end while budget\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MARSHA scored 0.240 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "8f9b8432-bed7-423d-acbf-0d52d6028a4e", "operator": null, "metadata": {"aucs": [0.12146974381982678, 0.1733577695260622, 0.3079241162121146, 0.3208216958068877, 0.24376099998674317, 0.2940372536041691, 0.24007074899109138, 0.2910180773469877, 0.2478986940014145, 0.15545352193589201]}, "task_prompt": ""}
{"id": "bac035ec-1eb8-4b6a-9e9b-87fb36d01462", "fitness": 0.18872013845071328, "name": "MDAS", "description": "MDAS combines a small orthonormal direction bank whose per-direction \"energies\" are adapted multiplicatively to bias directional probes, with per-dimension adaptive step scales derived from an RMS accumulator transformed multiplicatively (sigma_i = sigma0*(v_rms^{-power})), so the algorithm automatically stretches/shrinks moves by coordinate sensitivity. It generates diverse proposal strategies — heavy‑tailed Cauchy global jumps, a diagonal surrogate quadratic minimizer, 1‑D quadratic line searches along high‑energy directions, and antithetic directional/coordinate probes — and keeps a FIFO archive for local modeling and SVD‑based conservative refresh of directions. Acceptance is Metropolis‑style using a temperature proportional to sigma0^2·avg_span, while mean updates use trust clipping and momentum, and sigma0 is multiplicatively shrunk on successes or gently expanded on uphill accepts; direction energies decay and are regularized to avoid runaway. To maintain robustness the code includes small random rotations of the direction bank, opportunistic reseeding on stagnation, and parameter choices (moderate momentum, higher heavy‑tail probability, multiplicative energy learning/decay) that favor balanced exploration/exploitation on the BBOB suite.", "code": "import numpy as np\n\nclass MDAS:\n    \"\"\"\n    Multiplicative Directional Adaptive Search (MDAS)\n\n    Main ideas (differences / new parameter equations vs. the provided DAPCA):\n    - Direction bank with multiplicative energy adaptation (energies scaled by 1 + alpha*reward)\n      rather than additive updates.\n    - Per-dimension scaling derived from an RMS accumulator but transformed multiplicatively\n      (sigma_i = sigma0 * (v_rms^{-power})), with rms_beta and power different from DAPCA.\n    - Acceptance temperature proportional to sigma0**2 * avg_span (squared dependence).\n    - Momentum term on the mean update to retain search inertia.\n    - Slightly higher heavy-tail jump probability and different shrink/expand multipliers.\n    - Low-cost diagonal surrogate probe similar to DAPCA but with a different regularizer\n      and step shrinkage rule.\n    - Antithetic sampling for coordinate probes to reduce variance.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=12, archive_size=None, dir_count=None,\n                 init_sigma_mult=0.12, rms_beta=0.88,\n                 dir_refresh=8, prob_surrogate=0.15, prob_line=0.07,\n                 heavy_tail_prob=0.08, accept_temp_coeff=0.8,\n                 min_sigma=1e-9, max_sigma=8.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.archive_size = archive_size if archive_size is not None else max(6 * self.dim, 120)\n        # keep a few directions; somewhat denser than DAPCA default\n        self.dir_count = dir_count if dir_count is not None else max(1, self.dim // 6)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.rms_beta = float(rms_beta)\n        self.dir_refresh = int(dir_refresh)\n        self.prob_surrogate = float(prob_surrogate)\n        self.prob_line = float(prob_line)\n        self.heavy_tail_prob = float(heavy_tail_prob)\n        self.accept_temp_coeff = float(accept_temp_coeff)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n        # multiplicative energy learning rate\n        self.alpha_e = 0.15\n        # energy decay multiplier per generation\n        self.energy_decay = 0.995\n        # momentum for mean updates\n        self.momentum = 0.12\n        # shrink/expand multipliers on sigma0 after success/failure\n        self.shrink_success = 0.85\n        self.expand_uphill = 1.05\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds fallback to -5..5\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize mean uniformly in bounds\n        m = rng.uniform(lb, ub, size=self.dim)\n        m_prev = m.copy()\n\n        # global sigma and per-dim multiplicative scales\n        sigma0 = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        # per-dim sigma_i initially equal to sigma0\n        sigma_i = np.full(self.dim, sigma0, dtype=float)\n        # RMS accumulator (small positive init)\n        v_rms = np.full(self.dim, 1e-6, dtype=float)\n        # exponent/power for per-dim scaling (different eqn)\n        rms_power = 0.95\n\n        # direction bank (orthonormal) and multiplicative energies\n        r = min(self.dir_count, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            D = Q[:, :r].copy()\n            # multiplicative energies (positive)\n            d_energy = np.ones(r, dtype=float)\n        else:\n            D = np.zeros((self.dim, 0))\n            d_energy = np.array([])\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # seed the archive with some initial random samples (small)\n        seed_init = min(self.pop * 3, max(6, int(self.budget // 150)))\n        for _ in range(seed_init):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(10, int(0.04 * self.budget))\n\n        # helper: diagonal ridge-regressed quadratic fit around C (different regularizer)\n        def fit_diag_quad_center(C, Xs, fs):\n            K = Xs.shape[0]\n            dX = Xs - C[None, :]\n            g = np.zeros(self.dim, dtype=float)\n            h = np.ones(self.dim, dtype=float) * 1e-6\n            y = fs.astype(float)\n            # stronger ridge for small data; use lambda proportional to span\n            ridge = max(1e-6, 1e-4 * (avg_span ** 2))\n            for j in range(self.dim):\n                uj = dX[:, j]\n                A = np.vstack([np.ones(K), uj, uj * uj]).T\n                # ridge by augmenting A and y\n                # solve normal eqn with small ridge for stability\n                try:\n                    ATA = A.T.dot(A)\n                    ATA[1,1] += ridge\n                    ATA[2,2] += ridge\n                    ATy = A.T.dot(y)\n                    theta = np.linalg.solve(ATA, ATy)\n                    g[j] = float(theta[1])\n                    h_j = float(theta[2]) * 2.0\n                    # make sure curvature has consistent sign or regularize towards positive definite small curvature\n                    if abs(h_j) < 1e-7:\n                        h_j = 1e-6\n                    h[j] = h_j\n                except Exception:\n                    g[j] = 0.0\n                    h[j] = 1e-6\n            return g, h\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n\n            # periodically refresh direction bank using covariance of recent archive (different blend)\n            if (gen % self.dir_refresh == 0) and len(X_arch) >= max(4, r):\n                K = min(len(X_arch), self.archive_size)\n                Xr = np.asarray(X_arch[-K:])\n                M = np.mean(Xr, axis=0)\n                S = (Xr - M)\n                try:\n                    U, Svals, Vt = np.linalg.svd(S, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        D_new = Vt[:r_eff].T\n                        # more conservative blending than DAPCA but different coefficients\n                        D = 0.9 * D + 0.1 * D_new\n                        Q, _ = np.linalg.qr(D)\n                        D = Q[:, :r_eff]\n                        if d_energy.size > 0:\n                            # multiplicative smoothing with small injection\n                            d_energy = d_energy * (0.98) + 0.02 * (Svals[:r_eff] + 1e-6)\n                            # ensure positivity\n                            d_energy = np.clip(d_energy, 1e-8, 1e8)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # number of candidates to propose this generation\n            n_cand = min(self.pop, max(1, self.budget - evals))\n\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                x_cand = None\n                step = None\n                strategy = 'random'\n\n                # heavy-tail global jump (Cauchy) with different scaling\n                if rng.rand() < self.heavy_tail_prob:\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 92) + 1e-12)\n                    x_cand = m + sigma0 * 4.0 * z\n                    strategy = 'heavy'\n                # surrogate diagonal quadratic minimizer (sometimes)\n                elif p < self.prob_surrogate and len(X_arch) >= 8:\n                    K = min(len(X_arch), max(12, self.dim * 3))\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    topk = max(4, int(0.10 * K))\n                    ids = np.argsort(fr)[:topk]\n                    C = np.mean(Xr[ids], axis=0)\n                    try:\n                        g_diag, h_diag = fit_diag_quad_center(C, Xr[ids], fr[ids])\n                        # propose minimizer but shrink vector relative to sigma0 to avoid big jumps\n                        dx = - g_diag / (h_diag + 1e-12)\n                        max_move = 3.0 * sigma0\n                        norm_dx = np.linalg.norm(dx)\n                        if norm_dx > max_move:\n                            dx = dx * (max_move / (norm_dx + 1e-12))\n                        # additional shrink towards current mean (conservative)\n                        x_cand = C + 0.7 * dx + 0.3 * (m - C)\n                        step = x_cand - m\n                        strategy = 'surrogate'\n                    except Exception:\n                        x_cand = None\n                # 1-D quadratic line probe along a high-energy direction (uses up to 3 evals + maybe one)\n                elif p < self.prob_surrogate + self.prob_line and len(X_arch) >= 8 and r > 0:\n                    # pick direction by energy (multiplicative energies)\n                    weights = d_energy / (np.sum(d_energy) + 1e-12)\n                    idx = rng.choice(r, p=weights)\n                    dvec = D[:, idx]\n                    # pick center as one of the best recent points\n                    K = min(len(X_arch), max(8, self.dim * 2))\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    C = Xr[np.argmin(fr)].copy()\n                    a = sigma0 * max(0.4, rng.rand() * 2.0)\n                    # three symmetric points\n                    pts = [C.copy(),\n                           np.minimum(np.maximum(C + a * dvec, lb), ub),\n                           np.minimum(np.maximum(C - a * dvec, lb), ub)]\n                    # check budget for 3 evals + maybe final\n                    required = 3\n                    if evals + required <= self.budget:\n                        fs = []\n                        for x in pts:\n                            fx = float(func(x)); evals += 1\n                            fs.append(fx)\n                            X_arch.append(x.copy()); f_arch.append(fx)\n                        f0, f1, f2 = fs[0], fs[1], fs[2]\n                        denom = (f1 + f2 - 2.0 * f0)\n                        if abs(denom) > 1e-12:\n                            alpha_star = (a * (f2 - f1)) / (2.0 * denom)\n                            alpha_star = np.clip(alpha_star, -2.5 * a, 2.5 * a)\n                            x_star = np.minimum(np.maximum(C + alpha_star * dvec, lb), ub)\n                            if evals < self.budget:\n                                f_star = float(func(x_star)); evals += 1\n                                X_arch.append(x_star.copy()); f_arch.append(f_star)\n                                x_cand = x_star\n                                step = x_cand - m\n                                strategy = 'line'\n                        else:\n                            best_idx = int(np.argmin(fs))\n                            x_cand = pts[best_idx].copy()\n                            step = x_cand - m\n                            strategy = 'line_fallback'\n                    else:\n                        x_cand = None\n\n                # directional / coordinate probes (with antithetic sampling)\n                if x_cand is None:\n                    if r > 0 and rng.rand() < 0.82:\n                        weights = d_energy / (np.sum(d_energy) + 1e-12)\n                        idx = rng.choice(r, p=weights)\n                        dvec = D[:, idx]\n                        z = rng.randn() * 0.9\n                        # jitter scaled by per-dim sigma_i, using antithetic pair averaged to reduce noise\n                        jitter1 = rng.randn(self.dim) * sigma_i\n                        jitter2 = -jitter1  # antithetic\n                        jitter = 0.5 * (jitter1 + jitter2)\n                        step = z * sigma0 * dvec + 0.9 * jitter\n                        x_cand = m + step\n                        strategy = 'dir_probe'\n                    else:\n                        # coordinate adaptive probe with antithetic pairing\n                        jitter1 = rng.randn(self.dim) * sigma_i\n                        jitter2 = -jitter1\n                        jitter = 0.5 * (jitter1 + jitter2)\n                        step = jitter\n                        x_cand = m + step\n                        strategy = 'coord_probe'\n\n                # clip to bounds\n                x_cand = np.minimum(np.maximum(x_cand, lb), ub)\n                if evals >= self.budget:\n                    break\n                f_c = float(func(x_cand)); evals += 1\n                X_arch.append(x_cand.copy()); f_arch.append(f_c)\n\n                # enforce FIFO archive size\n                if len(X_arch) > self.archive_size:\n                    del X_arch[0]; del f_arch[0]\n\n                improved = False\n                if f_c < f_best:\n                    f_best = f_c\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # ensure step exists\n                if step is None:\n                    step = x_cand - m\n                step_norm = np.linalg.norm(step) + 1e-12\n\n                # reward baseline uses recent best (slightly different baseline)\n                baseline = min(f_best, np.min(f_arch) if len(f_arch) > 0 else f_best)\n                raw_reward = max(0.0, baseline - f_c)\n                # scale reward by sigma0 and step_norm differently (multiplicative style)\n                reward = raw_reward / (sigma0 * (step_norm ** 0.9) + 1e-12)\n\n                # update RMS accumulator (multiplicative-style scaling)\n                sq_norm = (step / (sigma0 + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq_norm\n                # transform to per-dim sigma_i with power (different equation)\n                sigma_i = np.clip(sigma0 * (1.0 / (np.sqrt(v_rms) + 1e-8)) ** rms_power,\n                                  self.min_sigma, self.max_sigma)\n\n                # update direction energies multiplicatively when direction-related\n                if r > 0 and strategy in ('dir_probe', 'line', 'line_fallback'):\n                    projs = D.T.dot(step)\n                    abs_projs = np.abs(projs)\n                    ssum = np.sum(abs_projs) + 1e-12\n                    if ssum > 0:\n                        idx_local = int(np.argmax(abs_projs))\n                        contrib = abs_projs[idx_local] / ssum\n                        # multiplicative update: energy *= (1 + alpha * reward * contrib)\n                        d_energy[idx_local] *= (1.0 + self.alpha_e * reward * contrib)\n                        # gentle decay to avoid runaway\n                        d_energy *= self.energy_decay\n                        # normalize energies to keep scale reasonable\n                        total = np.sum(d_energy) + 1e-12\n                        d_energy = d_energy / total * r\n\n                # acceptance test: improved always accepted; otherwise probabilistic using squared-sigma temperature\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    T = max(1e-12, self.accept_temp_coeff * (sigma0 ** 2) * avg_span)\n                    if rng.rand() < np.exp(-max(0.0, f_c - f_best) / (T + 1e-12)):\n                        accept = True\n\n                # apply mean update with momentum and trust clipping (different trust factor)\n                if accept:\n                    if strategy in ('surrogate',):\n                        lr = 0.70\n                    elif strategy in ('line', 'line_fallback'):\n                        lr = 0.50\n                    elif strategy in ('heavy',):\n                        lr = 0.25\n                    elif strategy in ('dir_probe',):\n                        lr = 0.30\n                    else:\n                        lr = 0.20\n                    delta = x_cand - m\n                    # trust clipping smaller than DAPCA (more conservative)\n                    trust = 4.0 * sigma0 * np.sqrt(self.dim)\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m_new = m + lr * delta + self.momentum * (m - m_prev)\n                    m_prev = m.copy()\n                    m = np.minimum(np.maximum(m_new, lb), ub)\n                    # adjust global sigma0\n                    if improved:\n                        sigma0 = max(self.min_sigma, sigma0 * self.shrink_success)\n                        # on success, also slightly reduce RMS memory to speed adaptation\n                        v_rms *= 0.96\n                    else:\n                        # uphill accepted: moderate increase\n                        sigma0 = min(self.max_sigma, sigma0 * self.expand_uphill)\n                else:\n                    # not accepted: small restorative jitter and mild sigma increase\n                    m_prev = m.copy()\n                    m = np.minimum(np.maximum(m + 0.006 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma0 = min(self.max_sigma, sigma0 * 1.01)\n\n                # small random rotation of D occasionally to keep diversity (slightly different amplitude)\n                if r > 0 and rng.rand() < 0.04:\n                    R = rng.randn(r, r) * 0.045\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(r) + R)\n                        D = D.dot(Qr)\n                        Q2, _ = np.linalg.qr(D)\n                        D = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed on stagnation (different amplitude)\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    jitter = max(0.06 * avg_span, 1.0 * sigma0)\n                    m_prev = m.copy()\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma0 = min(self.max_sigma, sigma0 * 1.6)\n                    if r > 0:\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        D = Q[:, :r]\n                        d_energy = np.ones(r)\n                    reseed = min(8, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.05 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = float(func(x)); evals += 1\n                        X_arch.append(x.copy()); f_arch.append(fx)\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n                        if len(X_arch) > self.archive_size:\n                            del X_arch[0]; del f_arch[0]\n                        if evals >= self.budget:\n                            break\n\n            # end generation\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MDAS scored 0.189 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "8f9b8432-bed7-423d-acbf-0d52d6028a4e", "operator": null, "metadata": {"aucs": [0.09726153749816513, 0.1817261345587473, 0.261534817939604, 0.20627057358924605, 0.17767251956701602, 0.22659914807291714, 0.20683028553822413, 0.20005994085790046, 0.18865607369291337, 0.1405903531923991]}, "task_prompt": ""}
{"id": "d70d8d81-67b9-4515-8cd4-af4a6fab6c4e", "fitness": 0.1639994739962994, "name": "SSAM", "description": "SSAM is a hybrid low-rank + diagonal Gaussian search that maintains a mean m and global step-size sigma while sampling mirrored (antithetic) candidate pairs in a learned low-dimensional subspace U (rank ≈ max(1, dim//6)) plus per-dimension residual noise scaled by an EMA vector s, which stabilizes exploration across coordinates. It attributes per-subspace directional gains from mirror comparisons to update multiplicative energies e (softmax-like exponential updates with energy_lr=0.22) and uses momentum (beta=0.7) with trust-clipped moves toward good archive points to combine exploitation and stability. An archive-backed linear surrogate probe in U and periodic PCA on a buffer of successful normalized steps (pca_period=12, archive size ≈ max(6·dim,120)) refreshes U toward frequently useful directions, while sigma adapts via a smoothed success-rate (target 0.2, sigma0_mult≈0.18) and opportunistic restarts (inflation≈1.8) recover from stagnation. Design choices (population base scaling, clipped energies, per-dim s_lr=0.15, modest learning rates and conservative trust radius) bias the method toward robust, low-variance directional learning across a wide range of continuous landscapes.", "code": "import numpy as np\n\nclass SSAM:  # Synergistic Subspace-Antithetic Momentum search\n    \"\"\"\n    SSAM: Subspace-guided Antithetic Search with Momentum and Surrogates.\n\n    Key mechanisms:\n      - Maintain mean m, global sigma, low-rank orthonormal basis U and multiplicative energies e.\n      - Antithetic/mirrored sampling in U + diag-noise space to extract directional gains.\n      - Per-dimension RMS scaling, momentum on mean, archive-based local surrogate probes,\n        PCA refresh of U from successful normalized steps, trust-clipped mean updates,\n        smoothed sigma adaptation (success-rate), and opportunistic restarts.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # structural defaults\n        self.pop_base = max(8, int(6 + 0.8 * np.log(max(2, dim))))\n        self.rank = max(1, min(self.dim, max(1, self.dim // 6)))\n        self.arch_size = max(6 * self.dim, 120)\n        self.pca_period = 12\n\n        # adaptation hyperparams\n        self.sigma0_mult = 0.18\n        self.s_lr = 0.15             # EMA for per-dim s\n        self.energy_lr = 0.22        # multiplicative energy learning rate\n        self.momentum_beta = 0.7\n        self.p_succ = 0.2\n        self.succ_target = 0.2\n        self.sigma_adapt_rate = 0.25\n        self.min_sigma = 1e-12\n        self.max_sigma_mult = 3.0\n\n        # trust & restarts\n        self.trust_mult = 6.0\n        self.stagn_frac = 0.06\n        self.restart_infl = 1.8\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds support (scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize mean and scale\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(self.min_sigma, self.sigma0_mult * avg_span)\n\n        # initialize low-rank basis U and multiplicative energies e\n        r = min(self.rank, self.dim)\n        A = rng.randn(self.dim, r)\n        Q, _ = np.linalg.qr(A)\n        U = Q[:, :r].copy()\n        e = np.ones(r, dtype=float)\n\n        # per-dimension residual scales (multiplicative on diag noise)\n        s = np.full(self.dim, 0.4)\n\n        # archive and buffers\n        X_arch = []\n        f_arch = []\n        success_buffer = []   # normalized steps to drive PCA\n\n        # evaluation seeding to get initial f_best\n        evals = 0\n        init_pop = min(self.pop_base, max(6, self.budget // 60))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0))\n            evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # controllers\n        p_succ = 0.2\n        stagn_limit = max(5, int(self.stagn_frac * self.budget))\n        stagn_count = 0\n        gen = 0\n\n        # helper: safe projection\n        def project_U(vec):\n            if U.size == 0:\n                return np.zeros(0)\n            return U.T.dot(vec)\n\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            # aim for mirrored pairs where possible\n            if lam % 2 == 1 and lam > 1:\n                lam -= 1\n            n_pairs = max(1, lam // 2)\n\n            # per-generation accumulators\n            gen_improved = False\n            directional_gain = np.zeros(r) if r > 0 else np.array([])\n\n            for _pair in range(n_pairs):\n                if evals + 2 > self.budget:\n                    break\n\n                # sample in low-rank coordinates and diag noise\n                if r > 0:\n                    z_r = rng.randn(r) * np.sqrt(np.maximum(e, 1e-12))\n                    low = U.dot(z_r)\n                else:\n                    low = np.zeros(self.dim)\n                    z_r = np.zeros(0)\n                z_d = rng.randn(self.dim) * s\n                step = sigma * (low + z_d)\n\n                # mirrored candidates\n                x_plus = np.minimum(np.maximum(m + step, lb), ub)\n                x_minus = np.minimum(np.maximum(m - step, lb), ub)\n\n                # evaluate plus then minus (sequential)\n                f_plus = float(func(x_plus)); evals += 1\n                X_arch.append(x_plus.copy()); f_arch.append(f_plus)\n                if f_plus < f_best:\n                    f_best = f_plus; x_best = x_plus.copy(); gen_improved = True; stagn_count = 0\n                else:\n                    stagn_count += 1\n\n                if evals >= self.budget:\n                    # if budget exhausted after one eval, we can't do minus; break\n                    break\n\n                f_minus = float(func(x_minus)); evals += 1\n                X_arch.append(x_minus.copy()); f_arch.append(f_minus)\n                if f_minus < f_best:\n                    f_best = f_minus; x_best = x_minus.copy(); gen_improved = True; stagn_count = 0\n                else:\n                    stagn_count += 1\n\n                # attribute directional gain: if + better than -, direction z_r (if present) is promising\n                if r > 0:\n                    delta = max(0.0, f_minus - f_plus)  # positive if + is better\n                    # normalize reward by step norm\n                    step_norm = np.linalg.norm(step) + 1e-12\n                    reward = delta / (step_norm + 1e-12)\n                    # project normalized step onto U to obtain per-direction attribution\n                    if np.any(z_r != 0):\n                        contrib = np.abs(z_r) / (np.sum(np.abs(z_r)) + 1e-12)\n                        directional_gain += reward * contrib\n\n                # record successful normalized steps into buffer\n                if (f_plus <= f_best + 1e-12) or (f_minus <= f_best + 1e-12) or (f_minus - f_plus > 0):\n                    norm_step = (step / (sigma + 1e-12)).copy()\n                    success_buffer.append(norm_step)\n                    if len(success_buffer) > max(60, self.arch_size // 2):\n                        success_buffer.pop(0)\n\n                # update per-dim s via EMA of absolute normalized step\n                abs_norm = np.abs(step) / (sigma + 1e-12)\n                s = (1.0 - self.s_lr) * s + self.s_lr * np.clip(abs_norm, 1e-6, 4.0)\n\n            # occasionally perform a surrogate probe in subspace (cheap linear surrogate)\n            if evals < self.budget and r > 0 and len(X_arch) >= max(6, r + 4) and rng.rand() < 0.18:\n                # use recent archive to fit linear model in subspace: f ~ a + g^T u\n                K = min(len(X_arch), min(self.arch_size, 4 * (r + 2)))\n                Xr = np.asarray(X_arch[-K:])\n                fr = np.asarray(f_arch[-K:])\n                Ucoords = (Xr - m).dot(U)  # (K, r)\n                # center fr\n                frc = fr - np.min(fr)\n                # weighted least squares (ridge)\n                W = np.ones(K)\n                try:\n                    A = (Ucoords * W.reshape(-1, 1)).T.dot(Ucoords) + 1e-6 * np.eye(r)\n                    b = (Ucoords * W.reshape(-1, 1)).T.dot(frc)\n                    g = np.linalg.solve(A, b)\n                    # propose step opposite to gradient in subspace\n                    u_star = -0.8 * g\n                    # clip magnitude\n                    u_norm = np.linalg.norm(u_star) + 1e-12\n                    max_u = 3.0 * sigma\n                    if u_norm > max_u:\n                        u_star = u_star * (max_u / u_norm)\n                    cand = m + U.dot(u_star)\n                    cand = np.minimum(np.maximum(cand, lb), ub)\n                    # evaluate surrogate candidate\n                    f_c = float(func(cand)); evals += 1\n                    X_arch.append(cand.copy()); f_arch.append(f_c)\n                    if f_c < f_best:\n                        f_best = f_c; x_best = cand.copy(); gen_improved = True; stagn_count = 0\n                    else:\n                        stagn_count += 1\n                    # treat u_star as a successful step if improved\n                    if f_c <= f_best + 1e-12:\n                        success_buffer.append((U.dot(u_star) / (sigma + 1e-12)).copy())\n                        if len(success_buffer) > max(60, self.arch_size // 2):\n                            success_buffer.pop(0)\n                    # update per-dim s with this step as well\n                    abs_norm = np.abs(U.dot(u_star)) / (sigma + 1e-12)\n                    s = (1.0 - self.s_lr) * s + self.s_lr * np.clip(abs_norm, 1e-6, 4.0)\n                except Exception:\n                    pass\n\n            # update multiplicative energies from aggregated directional gains\n            if r > 0 and np.sum(directional_gain) > 0:\n                g = directional_gain\n                # softmax-ish scalable update: e <- e * exp(eta * (g / (std(g)+eps)))\n                denom = np.std(g) + 1e-12\n                e = e * np.exp(self.energy_lr * (g / denom))\n                # clip energies\n                e = np.clip(e, 1e-6, 1e6)\n\n            # PCA refresh of U from success_buffer periodically\n            if (gen % self.pca_period == 0) and len(success_buffer) >= max(3, r):\n                B = np.asarray(success_buffer)\n                # center rows\n                Bc = B - np.mean(B, axis=0, keepdims=True)\n                try:\n                    _, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        U_new = Vt[:r_eff].T\n                        # align sign and blend\n                        if U.shape == U_new.shape:\n                            for k in range(r_eff):\n                                if np.dot(U[:, k], U_new[:, k]) < 0:\n                                    U_new[:, k] *= -1.0\n                            U = 0.85 * U + 0.15 * U_new\n                            # orthonormalize\n                            Q2, _ = np.linalg.qr(U)\n                            U = Q2[:, :r_eff]\n                        else:\n                            U = U_new\n                except Exception:\n                    pass\n\n            # mean update: bias towards the best archive point with momentum and trust clipping\n            # pick a candidate reference (best in recent archive)\n            recent_k = min(len(f_arch), max(1, int(0.12 * len(f_arch))))\n            if recent_k > 0:\n                ids = np.argsort(f_arch)[0:recent_k]\n                # prefer the best among the recent top\n                ref_idx = ids[0]\n                target = X_arch[ref_idx]\n            else:\n                target = x_best\n\n            delta = target - m\n            trust_radius = max(1e-12, self.trust_mult * sigma * np.sqrt(self.dim))\n            dn = np.linalg.norm(delta)\n            if dn > trust_radius:\n                delta = delta * (trust_radius / (dn + 1e-12))\n            # momentum update and move\n            if not hasattr(self, '_mom'):\n                self._mom = np.zeros(self.dim)\n            self._mom = self.momentum_beta * self._mom + (1.0 - self.momentum_beta) * delta\n            lr = 0.22 if gen_improved else 0.12\n            m = np.minimum(np.maximum(m + lr * self._mom, lb), ub)\n\n            # adapt sigma via smoothed success-rate (p_succ)\n            p_gen = 1.0 if gen_improved else 0.0\n            p_succ = 0.85 * p_succ + 0.15 * p_gen\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, self.min_sigma, self.max_sigma_mult * np.max(span))\n\n            # opportunistic restart on stagnation\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # restart around best with jitter, reset some statistics\n                jitter = max(0.05 * avg_span, 0.8 * sigma)\n                m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                sigma = max(sigma * self.restart_infl, 0.2 * avg_span)\n                # reinitialize basis and energies partly\n                A = rng.randn(self.dim, r)\n                Q, _ = np.linalg.qr(A)\n                U = Q[:, :r].copy()\n                e = np.ones(r)\n                s = np.full(self.dim, 0.4)\n                success_buffer = []\n                # small reseed evaluations near best to refresh archive\n                for _ in range(min(6, self.budget - evals)):\n                    x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                    fx = float(func(x)); evals += 1\n                    X_arch.append(x.copy()); f_arch.append(fx)\n                    if fx < f_best:\n                        f_best = fx; x_best = x.copy()\n                    if evals >= self.budget:\n                        break\n\n            # keep archive size bounded FIFO\n            while len(X_arch) > self.arch_size:\n                del X_arch[0]; del f_arch[0]\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SSAM scored 0.164 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "8f9b8432-bed7-423d-acbf-0d52d6028a4e", "operator": null, "metadata": {"aucs": [0.10041853183486249, 0.15414692610048775, 0.2145988003336371, 0.1390788541108623, 0.1671423986907603, 0.17046929463477423, 0.19262175983714824, 0.19534060140582554, 0.1728140784052865, 0.1333634946093497]}, "task_prompt": ""}
{"id": "08ae6fb2-06a5-4097-94cf-7925deed4b52", "fitness": 0.30000472747801066, "name": "TAMES", "description": "1) The algorithm is a trust-region–style ensemble search that maintains a center m and a normalized trust radius rho (initialized from rho_init_frac) and samples mirrored antithetic Gaussian ensembles around m plus targeted eigen-direction probes and occasional cheap ridge-regression gradient probes to balance global and directional exploration.  \n2) Covariance adaptation uses a blend of rank-1 (an evolution path p) and rank-mu weighted covariance computed in normalized coordinates (weights and mu_eff), with c1 and cmu controlling the mix, and an ensure_chol / eigenvalue clipping safeguard to keep C SPD for reliable sampling.  \n3) The trust radius rho is adapted by comparing the normalized RMS spread of the sampled population to a diversity_target via multiplicative updates (alpha_rho) and further expanded/shrunk when a generation improves an approximation of f(m) (rho_expand / rho_shrink), giving a normalized-spread-driven, robustness-oriented step-size control.  \n4) Practical design choices include dimension-aware population sizing (lam ~ log(dim)), bound clipping, an archive for local regression and center-fitness approximation, mirrored sampling for variance reduction, opportunistic jittered restarts on stagnation (stagnation_ratio) or collapsed rho, and budget-aware batching to ensure the func call limit is respected.", "code": "import numpy as np\n\nclass TAMES:\n    \"\"\"\n    Trust-Adaptive Mirrored Ensemble Search (TAMES)\n\n    One-line: Trust-region center search mixing mirrored antithetic sampling,\n    eigen-direction proposals, rank-1 + rank-mu covariance updates, evolution-path,\n    and normalized-spread-driven trust-radius adaptation with robust SPD safeguards.\n\n    Usage: TAMES(budget=10000, dim=10)(func) --> (f_opt, x_opt)\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 c1=0.12, cmu=0.06,\n                 alpha_rho=0.7,\n                 diversity_target=0.30,\n                 rho_init_frac=0.20,\n                 rho_expand=1.25,\n                 rho_shrink=0.70,\n                 stagnation_ratio=0.05,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.c1 = float(c1)\n        self.cmu = float(cmu)\n        self.alpha_rho = float(alpha_rho)\n        self.diversity_target = float(diversity_target)\n        self.rho_init_frac = float(rho_init_frac)\n        self.rho_expand = float(rho_expand)\n        self.rho_shrink = float(rho_shrink)\n        self.stagnation_ratio = float(stagnation_ratio)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds support (scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        max_bound = float(np.max(span))\n\n        # population size (moderate, dimension-aware)\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # initial batch for center and covariance estimation\n        init_batch = min(max(4, 2 * lam), self.budget)\n        evals = 0\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.array([func(x) for x in X0])\n        evals += init_batch\n\n        best_idx = int(np.argmin(f0))\n        f_best = float(f0[best_idx])\n        x_best = X0[best_idx].copy()\n\n        # initial center m: weighted recombination of top half\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.linspace(mu0, 1, mu0)\n        w0 = np.maximum(w0, 1e-12)\n        w0 = w0 / np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance and trust radius (rho)\n        C = np.diag(((span / 6.0) ** 2).clip(min=1e-12))\n        rho = max(1e-12, self.rho_init_frac * np.mean(span))\n        # small secondary scale for normalized spread measurement (not an extra eval scale)\n        # evolution path\n        p = np.zeros(self.dim, dtype=float)\n\n        # archive for gradient-like fits and diversity measurements\n        X_hist = [x.copy() for x in X0]\n        f_hist = [float(v) for v in f0]\n        archive_capacity = max(4 * self.dim, 40)\n\n        # stagnation limits\n        stagn_limit = max(5, int(self.stagnation_ratio * self.budget))\n        stagn_count = 0\n        iter_count = 0\n\n        # helper to ensure SPD and obtain cholesky-like transform A such that A^T A = C\n        def ensure_chol(mat):\n            eps = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                # reconstruct symmetric mat to clipped eigenvalues form\n                mat2 = (vecs * vals) @ vecs.T\n                return A\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            mu_iter = max(1, lam_iter // 2)\n            # linear decreasing weights\n            weights = np.linspace(mu_iter, 1, mu_iter)\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n            W = weights.reshape(-1, 1)\n\n            # SPD and sampling transform\n            A = ensure_chol(C)\n\n            # Candidate generation: mix mirrored Gaussian ensemble around m, eigen-direction probes, occasional gradient probe\n            candidates = []\n\n            # 1) Eigen-direction probes (both signs) for directional exploration\n            try:\n                vals, vecs = np.linalg.eigh(C)\n            except np.linalg.LinAlgError:\n                vals = np.ones(self.dim)\n                vecs = np.eye(self.dim)\n            idxs = np.argsort(-vals)\n            vals = vals[idxs]\n            vecs = vecs[:, idxs]\n            n_dir = min(max(1, lam_iter // 5), self.dim)\n            for k in range(n_dir):\n                v = vecs[:, k]\n                amp = rho * (1.0 + 0.6 * rng.rand()) * (np.sqrt(max(vals[k], 1e-12)) / (np.sqrt(np.mean(vals)) + 1e-12))\n                candidates.append(m + amp * v)\n                if len(candidates) >= lam_iter:\n                    break\n                candidates.append(m - amp * v)\n                if len(candidates) >= lam_iter:\n                    break\n            if len(candidates) >= lam_iter:\n                candidates = candidates[:lam_iter]\n            else:\n                # 2) Mirrored antithetic Gaussian ensemble from covariance C scaled by rho\n                need = lam_iter - len(candidates)\n                half = need // 2\n                odd = (need % 2) != 0\n                if half > 0:\n                    Z = rng.normal(size=(half, self.dim))\n                    Y_half = Z @ A.T  # each row ~ N(0, C)\n                    for y in Y_half:\n                        candidates.append(m + rho * y)\n                        candidates.append(m - rho * y)\n                        if len(candidates) >= lam_iter:\n                            break\n                if odd and len(candidates) < lam_iter:\n                    z = rng.normal(size=self.dim)\n                    yc = z @ A.T\n                    candidates.append(m + rho * yc)\n\n                # 3) occasional gradient-exploitation surrogate step (cheap ridge regression) if enough history\n                if len(candidates) < lam_iter and len(X_hist) >= min(self.dim + 2, 8) and rng.rand() < 0.25:\n                    # use recent points\n                    n_fit = min(len(X_hist), archive_capacity)\n                    X_fit = np.asarray(X_hist[-n_fit:]) - m\n                    y_fit = np.asarray(f_hist[-n_fit:])\n                    # center y around its median to reduce offset effects\n                    y_center = np.median(y_fit)\n                    y = y_fit - y_center\n                    lam_reg = 1e-6 * (1.0 + np.var(y))\n                    XT_X = X_fit.T @ X_fit\n                    try:\n                        beta = np.linalg.solve(XT_X + lam_reg * np.eye(self.dim), X_fit.T @ y)\n                        g = beta\n                        gnorm = np.linalg.norm(g)\n                        if gnorm > 0:\n                            step_scale = rho * (0.9 + 0.6 * rng.rand())\n                            cand = m - (step_scale * (g / (gnorm + 1e-20)))\n                            candidates.append(cand)\n                    except np.linalg.LinAlgError:\n                        pass\n\n                # 4) fill remaining with small uniform jitter around m (local exploration)\n                while len(candidates) < lam_iter:\n                    box = np.clip(0.5 * rho, 1e-12, np.max(span))\n                    cand = m + rng.uniform(-box, box, size=self.dim)\n                    candidates.append(cand)\n\n            # clip and finalize candidate matrix\n            Xcand = np.asarray(candidates[:lam_iter])\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # Evaluate candidates one-by-one to respect budget\n            fc = np.empty(Xcand.shape[0], dtype=float)\n            for i in range(Xcand.shape[0]):\n                if evals >= self.budget:\n                    fc[i:] = np.inf\n                    break\n                fc[i] = func(Xcand[i])\n                evals += 1\n                # update global best immediately\n                if fc[i] < f_best:\n                    f_best = float(fc[i])\n                    x_best = Xcand[i].copy()\n                    stagn_count = 0\n\n            # store into history (trim)\n            for xi, fi in zip(Xcand, fc):\n                X_hist.append(xi.copy())\n                f_hist.append(float(fi))\n            if len(X_hist) > archive_capacity:\n                excess = len(X_hist) - archive_capacity\n                X_hist = X_hist[excess:]\n                f_hist = f_hist[excess:]\n\n            # generation best and elite selection\n            order = np.argsort(fc)\n            gen_best_idx = int(order[0])\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n\n            X_mu = Xcand[order[:mu_iter]]\n            # compute normalized steps y_i = (X_i - m) / rho using old m\n            y_steps = (X_mu - m) / (rho + 1e-20)\n            # weighted rank-mu covariance in normalized coords\n            W = weights.reshape(-1, 1)\n            cov_mu = (W * y_steps).T @ y_steps\n\n            # evolution path update (rank-1)\n            mu_eff = (np.sum(weights))**2 / np.sum(weights**2)\n            c_p = 2.0 / (self.dim + 2.0)\n            y_w = (W * y_steps).sum(axis=0)\n            p = (1.0 - c_p) * p + np.sqrt(c_p * (2.0 - c_p) * mu_eff) * y_w\n\n            # covariance update: blend old C, rank-1 from p and rank-mu\n            c1 = float(self.c1)\n            cmu = float(self.cmu)\n            coef_fix = max(0.0, 1.0 - c1 - cmu)\n            C = coef_fix * C + c1 * np.outer(p, p) + cmu * cov_mu\n\n            # new center by weighted recombination (in original coords)\n            m_new = (W * X_mu).sum(axis=0)\n\n            # normalized RMS spread of whole evaluated population relative to new center\n            y_all = (Xcand - m_new) / (rho + 1e-20)\n            norm_rms = np.sqrt(np.mean(np.sum(y_all**2, axis=1)) / max(1.0, float(self.dim)))\n            # adapt rho toward diversity_target\n            rho *= np.exp(self.alpha_rho * (self.diversity_target - norm_rms))\n            rho = np.clip(rho, 1e-12, 2.0 * np.max(span))\n\n            # trust-region style expansion/shrink based on whether best candidate improved center approx\n            # approximate f(m) by nearest historical evaluation to m\n            if len(X_hist) > 0:\n                Xh = np.asarray(X_hist)\n                dists = np.sum((Xh - m)**2, axis=1)\n                idx0 = int(np.argmin(dists))\n                f_m_approx = float(f_hist[idx0])\n            else:\n                f_m_approx = f_best\n            improved_center = gen_best_f < f_m_approx - 1e-12\n            if improved_center:\n                # accept and expand moderately\n                m = m_new\n                rho = min(2.0 * np.max(span), rho * self.rho_expand)\n                stagn_count = 0\n            else:\n                # soft acceptance towards m_new, shrink radius\n                m = 0.85 * m + 0.15 * m_new\n                rho = max(1e-12, rho * self.rho_shrink)\n                stagn_count += 1\n\n            # numerical SPD safeguards for C\n            C = 0.5 * (C + C.T)\n            try:\n                # clip eigenvalues if necessary\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                C = (vecs * vals) @ vecs.T\n            except np.linalg.LinAlgError:\n                C = np.diag(((span / 6.0) ** 2).clip(min=1e-12))\n\n            # opportunistic restart if stagnation prolonged or rho collapsed\n            if (stagn_count >= stagn_limit) or (rho <= 1e-9 * max_bound):\n                stagn_count = 0\n                # re-center around global best with jitter proportional to current rho\n                jitter = max(0.06 * np.mean(span), 0.5 * rho)\n                m = x_best + rng.randn(self.dim) * jitter\n                m = np.minimum(np.maximum(m, lb), ub)\n                C = np.diag(((span / 8.0) ** 2).clip(min=1e-12))\n                rho = max(self.rho_init_frac * np.mean(span) * 0.8, 1e-12)\n                p = np.zeros_like(p)\n                # reduce lam moderately if budget small\n                if self.budget < 200:\n                    lam = max(4, lam // 2)\n                continue\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm TAMES scored 0.300 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "8f9b8432-bed7-423d-acbf-0d52d6028a4e", "operator": null, "metadata": {"aucs": [0.16738379478291554, 0.2442976657521403, 0.3603615934204696, 0.5131987112122319, 0.2857932055864578, 0.37402996644560405, 0.27459070215228043, 0.3118478681100707, 0.29282562589773176, 0.17571814142020448]}, "task_prompt": ""}
{"id": "8e030180-85b3-49dd-8e92-727c3c1f6f8f", "fitness": 0.18997196987041431, "name": "DSAT", "description": "The DSAT design mixes two cooperating mechanisms: a learned exploitation channel (FIFO directional memory D_mem used to form weighted 1‑D parabolic line searches) and a coordinated exploration channel (an orthonormal subspace B used for Gaussian moves) supplemented by coordinate pattern tweaks and rare Cauchy (Levy) escapes — chosen probabilistically (prob_subspace=0.16, prob_coord=0.08, prob_levy=0.03) with small batches per generation (pop=12). Adaptation is multi-scale: a global sigma initialized as init_sigma_mult·avg_span (0.18 by default) and per-dimension sigma_diag updated via an RMS estimator (rms_beta=0.94), while subspace scales s_sub and trust_sub are adapted from projection magnitudes and periodic PCA/SVD of the evaluation archive (dir_refresh), and a decaying temperature (accept_temp_init) enables occasional uphill acceptance. Robustness and search control come from trust-clipped mean moves, occasional random basis perturbation and reseed on stagnation (stagn_limit), an evaluation-aware safe_eval/archive to drive PCA and median-based rewards, and small heuristics (mem_size, archive_size) to keep the method stable across budgets and dimensions.", "code": "import numpy as np\n\nclass DSAT:\n    \"\"\"\n    Dual-Subspace Adaptive Trust (DSAT)\n\n    Key ideas:\n    - Maintain two cooperating mechanisms:\n      1) A learned exploitation subspace built from a short directional memory (successful deltas).\n      2) A randomized exploration subspace (orthonormal basis) for broader coordinated moves.\n    - Propose candidates from a mixture: subspace 1-D parabolic line-search (cheap surrogate),\n      coordinated Gaussian in exploration subspace + diagonal jitter, occasional Cauchy (Levy) escapes,\n      and coordinate pattern-search tweaks.\n    - Maintain per-direction trust radii and a small FIFO archive for surrogate fits and energy weighting.\n    - Adaptive step-size (sigma) shrinks on repeated success, expands on stagnation; temperature-driven uphill acceptance decays with budget.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=12, k=None, archive_size=None, mem_size=None,\n                 init_sigma_mult=0.18, rms_beta=0.94,\n                 prob_subspace=0.16, prob_coord=0.08, prob_levy=0.03,\n                 dir_refresh=10, accept_temp_init=0.5,\n                 min_sigma=1e-8, max_sigma=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.k = k if (k is not None) else max(1, self.dim // 8)\n        self.archive_size = archive_size if archive_size is not None else max(8 * self.dim, 120)\n        self.mem_size = mem_size if mem_size is not None else max(6, self.k * 6)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.rms_beta = float(rms_beta)\n        self.prob_subspace = float(prob_subspace)\n        self.prob_coord = float(prob_coord)\n        self.prob_levy = float(prob_levy)\n        self.dir_refresh = int(dir_refresh)\n        self.accept_temp_init = float(accept_temp_init)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial mean\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # global scale\n        sigma = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        sigma_diag = np.full(self.dim, sigma)\n        v_rms = np.full(self.dim, 1e-6)\n\n        # exploration subspace (orthonormal basis)\n        k = min(self.k, self.dim)\n        if k > 0:\n            A = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :k].copy()\n            s_sub = np.full(k, sigma / np.sqrt(k))\n            trust_sub = np.full(k, 1.0 * sigma)   # per-direction trust radius\n        else:\n            B = np.zeros((self.dim, 0))\n            s_sub = np.array([])\n            trust_sub = np.array([])\n\n        # directional memory (recent successful deltas) used to form exploitation direction\n        D_mem = []  # list of (delta, reward)\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # helper: safe evaluate with budget check\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            # store\n            X_arch.append(x.copy()); f_arch.append(fx)\n            if len(X_arch) > self.archive_size:\n                del X_arch[0]; del f_arch[0]\n            return fx\n\n        # seed with a few random points\n        seed0 = min(self.pop * 3, max(12, int(self.budget // 200)))\n        for _ in range(seed0):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = safe_eval(x0)\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(12, int(0.05 * self.budget))\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n\n            # refresh exploration basis from archive every dir_refresh gens using PCA-like of offsets\n            if (gen % self.dir_refresh == 0) and len(X_arch) >= max(4, k):\n                K = min(len(X_arch), self.archive_size)\n                Xr = np.asarray(X_arch[-K:])\n                meanX = np.mean(Xr, axis=0)\n                S = (Xr - meanX)\n                try:\n                    # compact SVD; Vt rows are principal directions in variable space\n                    U_s, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                    r_eff = min(k, Vt.shape[0])\n                    if r_eff > 0 and k > 0:\n                        B_new = Vt[:r_eff].T\n                        # soft blend to avoid abrupt changes\n                        B = 0.82 * B + 0.18 * B_new\n                        Q, _ = np.linalg.qr(B)\n                        B = Q[:, :r_eff]\n                        s_sub = 0.9 * s_sub[:r_eff] + 0.1 * (np.maximum(svals[:r_eff], 1e-8) / (np.sqrt(r_eff) + 1e-12))\n                        trust_sub = 0.95 * trust_sub[:r_eff] + 0.05 * (svals[:r_eff] + 1e-8)\n                except Exception:\n                    pass\n\n            # adapt temperature (annealing) for uphill acceptance\n            T = self.accept_temp_init * sigma * avg_span * max(1e-12, 1.0 - (evals / max(1.0, self.budget)))\n\n            # produce up to pop proposals this generation\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                strategy = 'explore_gauss'\n                x_cand = None\n                step = None\n                f_c = None\n\n                # occasional Levy escape\n                if p < self.prob_levy:\n                    strategy = 'levy'\n                    z = rng.standard_cauchy(size=self.dim)\n                    # robust normalized\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    x_cand = m + sigma * 5.0 * z\n                    x_cand = np.minimum(np.maximum(x_cand, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n                    step = x_cand - m\n\n                # exploitation: 1-D parabolic line-search along an exploited direction based on D_mem\n                elif (p < self.prob_subspace) and (len(D_mem) >= 3) and (evals + 3 <= self.budget):\n                    strategy = 'exploit_line'\n                    # build a candidate direction from weighted memory\n                    Ds = np.array([d for (d, rw) in D_mem])\n                    RWs = np.array([rw for (d, rw) in D_mem])\n                    if Ds.size == 0:\n                        continue\n                    weights = (RWs - RWs.min()) + 1e-6\n                    wnorm = weights / (weights.sum() + 1e-12)\n                    ddir = np.tensordot(wnorm, Ds, axes=(0, 0))  # weighted sum\n                    nd = np.linalg.norm(ddir) + 1e-12\n                    ddir = ddir / nd\n                    # trust radius based on recent successes magnitude\n                    r = max(0.8 * sigma, 0.5 * np.mean(np.abs(ddir)) + 1e-12) * (1.0 + 0.2 * rng.rand())\n                    # prepare three alphas: -r, 0, +r (we will evaluate -r and +r and ensure f0 known)\n                    f0 = None\n                    # try to get f(m) from archive (exact match) else evaluate\n                    f0 = None\n                    for xi, fi in zip(X_arch[::-1], f_arch[::-1]):  # search recent first\n                        if np.allclose(xi, m, atol=1e-12):\n                            f0 = fi; break\n                    if f0 is None:\n                        # evaluate m if budget allows\n                        if evals < self.budget:\n                            f0 = safe_eval(m)\n                        else:\n                            f0 = f_best\n                    x_minus = np.minimum(np.maximum(m - r * ddir, lb), ub)\n                    x_plus = np.minimum(np.maximum(m + r * ddir, lb), ub)\n                    f_minus = safe_eval(x_minus)\n                    if f_minus is None:\n                        break\n                    f_plus = safe_eval(x_plus)\n                    if f_plus is None:\n                        break\n                    # fit parabola through (-r, f_minus), (0, f0), (r, f_plus)\n                    # a*alpha^2 + b*alpha + c = f\n                    A = np.array([[r * r, -r, 1.0],\n                                  [0.0, 0.0, 1.0],\n                                  [r * r, r, 1.0]])\n                    y = np.array([f_minus, f0, f_plus])\n                    # solve for coefficients in alpha order [-r,0,r] mapping careful: set system for alphas = [-r,0,r]\n                    # simpler direct formula for parabola min from three points symmetric around 0:\n                    denom = (f_minus + f_plus - 2.0 * f0)\n                    if abs(denom) > 1e-12:\n                        alpha_star = 0.5 * r * (f_minus - f_plus) / denom\n                        alpha_star = np.clip(alpha_star, -2.0 * r, 2.0 * r)\n                        x_star = np.minimum(np.maximum(m + alpha_star * ddir, lb), ub)\n                        f_star = safe_eval(x_star)\n                        if f_star is None:\n                            break\n                        x_cand = x_star\n                        f_c = f_star\n                        step = x_cand - m\n                    else:\n                        # pick best of evaluated -r,+r, or center\n                        cand_list = [ (f_minus, x_minus), (f0, m.copy()), (f_plus, x_plus) ]\n                        f_sel, x_sel = min(cand_list, key=lambda t: t[0])\n                        x_cand = x_sel.copy()\n                        f_c = f_sel\n                        step = x_cand - m\n\n                # coordinate pattern-search tweak (cheap)\n                elif p < (self.prob_subspace + self.prob_coord) and (evals + 1 <= self.budget):\n                    strategy = 'coord'\n                    # choose coordinate weighted by sigma_diag or variances\n                    if len(X_arch) >= 4:\n                        Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                        var = np.var(Xr, axis=0)\n                        weights = var + 1e-8\n                    else:\n                        weights = sigma_diag + 1e-8\n                    weights = weights / (weights.sum() + 1e-12)\n                    j = int(rng.choice(self.dim, p=weights))\n                    step_dir = np.zeros(self.dim)\n                    step_scale = sigma_diag[j] * (0.5 + rng.rand() * 1.5)\n                    step_dir[j] = step_scale * (1.0 if rng.rand() < 0.5 else -1.0)\n                    x_try = np.minimum(np.maximum(m + step_dir, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try\n                    f_c = f_try\n                    step = x_cand - m\n\n                # default exploration: coordinated Gaussian in exploration subspace + diag jitter\n                else:\n                    strategy = 'explore_gauss'\n                    if k > 0 and rng.rand() < 0.88:\n                        z = rng.randn(k)\n                        eps = rng.randn(self.dim)\n                        step = B.dot(z * s_sub) + 0.8 * (sigma_diag * eps)\n                        x_cand = m + step\n                    else:\n                        eps = rng.randn(self.dim)\n                        step = sigma_diag * eps\n                        x_cand = m + step\n                    x_cand = np.minimum(np.maximum(x_cand, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # if somehow f_c not set and we have budget, evaluate\n                if f_c is None and evals < self.budget and x_cand is not None:\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n                    if step is None:\n                        step = x_cand - m\n\n                if f_c is None:\n                    # no evaluation done due to budget; exit\n                    break\n\n                # update best & stagnation\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c)\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # reward signal: improvement relative to recent median\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                reward = raw_reward / (sigma * step_norm + 1e-12)\n\n                # update RMS and sigma_diag\n                sq = (step / (sigma + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq\n                sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-8), self.min_sigma, self.max_sigma)\n\n                # update subspace energies and directional memory\n                if step is not None:\n                    # project onto exploration subspace\n                    if k > 0:\n                        projs = B.T.dot(step)\n                        abs_projs = np.abs(projs)\n                        if abs_projs.size > 0 and abs_projs.sum() > 0:\n                            idx = int(np.argmax(abs_projs))\n                            # increase s_sub a bit for used component\n                            s_sub = np.clip(0.985 * s_sub + 0.015 * (np.abs(projs) + 1e-8),\n                                            self.min_sigma, self.max_sigma)\n                            # adapt trust_sub for component\n                            trust_sub[idx] = 0.97 * trust_sub[idx] + 0.03 * (abs_projs[idx] + 1e-8)\n                    # record into directional memory with reward\n                    if reward > 0 and np.linalg.norm(step) > 1e-12:\n                        # store normalized direction scaled by reward\n                        dnorm = step / (np.linalg.norm(step) + 1e-12)\n                        D_mem.append((dnorm * min(1.0, np.linalg.norm(step) / (sigma + 1e-12)), reward + 1e-12))\n                        # keep FIFO memory limited\n                        if len(D_mem) > self.mem_size:\n                            D_mem.pop(0)\n\n                # acceptance decision: improved or metropolish uphill\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    deltaE = f_c - f_best\n                    if deltaE <= 0:\n                        accept = True\n                    else:\n                        if rng.rand() < np.exp(-deltaE / (T + 1e-12)):\n                            accept = True\n\n                if accept:\n                    # move mean with strategy dependent learning rate\n                    if strategy == 'exploit_line':\n                        lr = 0.88\n                    elif strategy in ('coord',):\n                        lr = 0.55\n                    elif strategy == 'levy':\n                        lr = 0.25\n                    elif strategy == 'explore_gauss':\n                        lr = 0.36\n                    else:\n                        lr = 0.30\n                    delta = (x_cand - m)\n                    # trust clipping on mean movement\n                    trust = 6.0 * sigma * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n\n                    # adjust sigma: shrink on success else slight increase on uphill accept\n                    if improved:\n                        sigma = max(self.min_sigma, sigma * 0.86)\n                        v_rms *= 0.95\n                        # reward increases trust for directions in buffer\n                        if len(D_mem) > 0:\n                            # slightly strengthen top memory entries\n                            D_mem = [(d, rw * 1.01) for (d, rw) in D_mem]\n                    else:\n                        # uphill acceptance slowly inflates sigma\n                        sigma = min(self.max_sigma, sigma * 1.02)\n                else:\n                    # reject: small random drift to escape local traps\n                    m = np.minimum(np.maximum(m + 0.01 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma = min(self.max_sigma, sigma * 1.005)\n\n                # occasional small perturbation of exploration basis\n                if k > 0 and rng.rand() < 0.04:\n                    R = rng.randn(k, k) * 0.06\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(k) + R)\n                        B = B.dot(Qr)\n                        Q2, _ = np.linalg.qr(B)\n                        B = Q2[:, :k]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed if stagnation\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    # jump mean near best with jitter and increase sigma moderately\n                    jitter = max(0.06 * avg_span, 1.2 * sigma)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma = min(self.max_sigma, sigma * 1.6)\n                    # randomize B slightly\n                    if k > 0:\n                        A = rng.randn(self.dim, k)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :k]\n                        s_sub = np.full(k, sigma / np.sqrt(max(1, k)))\n                        trust_sub = np.full(k, sigma)\n                        D_mem = []\n                    # add a few local probes around best\n                    reseed = min(8, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.07 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None:\n                            break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n                        if len(X_arch) > self.archive_size:\n                            del X_arch[0]; del f_arch[0]\n\n            # end generation\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DSAT scored 0.190 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "dc34281a-bf69-49eb-a520-fa52a9b6e989", "operator": null, "metadata": {"aucs": [0.11337622282056525, 0.18071356586443, 0.24000869385519374, 0.1975817803155555, 0.19036401965650152, 0.2307554096487634, 0.21455608784651437, 0.20728961860192063, 0.1863505008812375, 0.13872379921346145]}, "task_prompt": ""}
{"id": "b46a8143-8c7f-4df4-856b-b16a07dd339a", "fitness": "-inf", "name": "ADSS", "description": "The algorithm maintains a low-rank orthonormal subspace U (default k ≈ dim/4) with per-axis scales s_sub and multiplicative sub_energy to focus search on promising low-dimensional directions while also keeping a per-coordinate adaptive scale sigma_diag derived from an RMS accumulator v_rms and a global step sigma0 that is initialized proportional to the problem span. It generates a mixture of budget-aware proposals — a surrogate quadratic minimizer inside U (with damped spectral inversion), blended low-rank + diagonal Gaussian probes, coordinate 1‑D quadratic refinements, and rare heavy‑tailed Cauchy jumps — all clipped to box bounds and evaluated only while respecting the remaining budget. The subspace is periodically refreshed from recent archive steps via SVD, the archive and median-based baselines drive rewards and adaptations, and accepted moves update the mean m with strategy-dependent learning rates, trust clipping and multiplicative sigma0 adjustments (shrink on success, grow on uphill/rejection). Stagnation triggers Levy-like reseeding around the best point plus localized reseeding, and occasional stochastic rotations and mild randomness keep exploration diversified.", "code": "import numpy as np\n\nclass ADSS:\n    \"\"\"\n    Adaptive Dual-Scale Subspace Search (ADSS)\n\n    Main ideas (concise):\n    - Maintain a low-rank orthonormal subspace U and a per-coordinate diagonal scale sigma_diag.\n    - Propose moves from: (A) subspace surrogate minimizers (quadratic fit inside U), (B) blended low-rank + diagonal Gaussian probes,\n      (C) coordinate 1-D refinements, and (D) rare heavy-tailed Cauchy jumps.\n    - Different equations from ALR-SGE:\n        * sigma_diag set as sigma0 * (1 / (1 + sqrt(rms))) rather than sigma0 / sqrt(rms)\n        * surrogate solve uses eigen-regularized inverse (damped spectral inversion)\n        * temperature for uphill acceptance scales as sigma0**1.2 * avg_span**0.8\n        * different adaptation multipliers (success: sigma0 *= 0.9, uphill accept: sigma0 *= 1.06)\n        * subspace scale s_sub updated multiplicatively not additive EWMA\n    - Budget-respecting. Designed for [-5,5] search box typical in BBOB tests.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=12, subspace_rank=None, archive_size=None,\n                 init_sigma_mult=0.12, rms_beta=0.87,\n                 prob_surrogate=0.18, prob_coord=0.08, prob_heavy=0.02,\n                 dir_refresh=8, accept_temp_coeff=1.0,\n                 min_sigma=1e-10, max_sigma=10.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        # choose a slightly larger default subspace rank than ALR-SGE\n        self.k = subspace_rank if subspace_rank is not None else max(1, self.dim // 4)\n        self.archive_size = archive_size if archive_size is not None else max(5 * self.dim, 100)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.rms_beta = float(rms_beta)\n        self.prob_surrogate = float(prob_surrogate)\n        self.prob_coord = float(prob_coord)\n        self.prob_heavy = float(prob_heavy)\n        self.dir_refresh = int(dir_refresh)\n        self.accept_temp_coeff = float(accept_temp_coeff)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds (default -5..5)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial mean: uniform random in box\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # global step and per-dim RMS-like accumulator\n        sigma0 = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        v_rms = np.full(self.dim, 1e-8)\n        sigma_diag = np.full(self.dim, sigma0)\n\n        # low-rank subspace U (dim x k), orthonormal, and s_sub (k,)\n        k = min(self.k, self.dim)\n        if k > 0:\n            A = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :k].copy()\n            # different scaling law: s_sub proportional to sigma0 but scaled by sqrt(k) in denom\n            s_sub = np.full(k, sigma0 * 0.9 / (np.sqrt(k) + 1e-12))\n            sub_energy = np.ones(k) * 1e-3\n        else:\n            U = np.zeros((self.dim, 0))\n            s_sub = np.array([])\n            sub_energy = np.array([])\n\n        # archive (FIFO)\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # seed few points to populate archive\n        seed_init = min(self.pop * 3, max(12, int(self.budget // 300)))\n        for _ in range(seed_init):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(8, int(0.05 * self.budget))\n\n        # helper: fit quadratic surrogate in subspace; returns g (k,) and H (k,k) via least squares\n        def fit_quad_subspace(C, U_sub, Xs, fs):\n            K = Xs.shape[0]\n            k_loc = U_sub.shape[1]\n            if K <= max(6, k_loc + 2):\n                return None, None\n            dX = Xs - C[None, :]\n            U = U_sub\n            UTX = dX.dot(U)  # (K, k)\n            # build features: [1, u_i, u_i^2 (full quadratic), pairwise]\n            cols = [np.ones(K)]\n            for j in range(k_loc):\n                cols.append(UTX[:, j])\n            for i in range(k_loc):\n                for j in range(i, k_loc):\n                    cols.append(UTX[:, i] * UTX[:, j])\n            A = np.vstack(cols).T  # K x P\n            y = fs\n            # small ridge for numerical stability\n            ridge = 1e-8 * np.eye(A.shape[1])\n            try:\n                # solve via normal equations with ridge (stable for small k)\n                ATA = A.T.dot(A) + ridge\n                ATy = A.T.dot(y)\n                theta = np.linalg.solve(ATA, ATy)\n            except Exception:\n                try:\n                    theta, *_ = np.linalg.lstsq(A, y, rcond=None)\n                except Exception:\n                    return None, None\n            # parse parameters\n            idx = 0\n            c0 = float(theta[idx]); idx += 1\n            g = np.zeros(k_loc)\n            for j in range(k_loc):\n                g[j] = float(theta[idx]); idx += 1\n            H = np.zeros((k_loc, k_loc))\n            for i in range(k_loc):\n                for j in range(i, k_loc):\n                    H[i, j] = float(theta[idx]); H[j, i] = H[i, j]\n                    idx += 1\n            return g, H\n\n        # main optimization loop\n        while evals < self.budget:\n            gen += 1\n\n            # refresh subspace periodically with SVD of recent steps (different blend law)\n            if (gen % self.dir_refresh == 0) and len(X_arch) >= max(6, k):\n                K = min(len(X_arch), self.archive_size)\n                Xr = np.asarray(X_arch[-K:])\n                Mx = Xr.mean(axis=0)\n                S = (Xr - Mx)\n                try:\n                    U_s, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                    r_eff = min(k, Vt.shape[0])\n                    if r_eff > 0 and k > 0:\n                        U_new = Vt[:r_eff].T\n                        # gentler blend: weight by sub_energy (promote energetic axes)\n                        w = 0.2\n                        U = (1 - w) * U + w * U_new\n                        Q, _ = np.linalg.qr(U)\n                        U = Q[:, :r_eff]\n                        # multiplicative update for s_sub using svs but different formula\n                        s_sub = np.clip(s_sub[:r_eff] * (0.95 + 0.05 * (svals[:r_eff] / (np.mean(svals[:r_eff]) + 1e-12))),\n                                        self.min_sigma, self.max_sigma)\n                        sub_energy = 0.9 * sub_energy[:r_eff] + 0.1 * (svals[:r_eff] + 1e-9)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # proposals this generation\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                x_cand = None\n                strategy = 'blend'\n                step = np.zeros(self.dim)\n\n                # rare heavy Cauchy jump (smaller prob than default ALR-SGE)\n                if rng.rand() < self.prob_heavy:\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 85) + 1e-12)\n                    x_cand = m + sigma0 * 6.0 * z\n                    strategy = 'heavy'\n\n                # surrogate minimizer inside subspace (more aggressive probability)\n                elif p < self.prob_surrogate and len(X_arch) >= max(10, 3 * k):\n                    K = min(len(X_arch), self.archive_size)\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    # center = weighted mean of top fraction\n                    topk = max(5, int(0.15 * K))\n                    ids = np.argsort(fr)[:topk]\n                    C = Xr[ids].mean(axis=0)\n                    if k > 0:\n                        U_sub = U.copy()\n                        g_sub, H_sub = fit_quad_subspace(C, U_sub, Xr, fr)\n                        if g_sub is not None and H_sub is not None:\n                            # ensure symmetry\n                            Hs = 0.5 * (H_sub + H_sub.T)\n                            # spectral regularization (damped spectral inversion)\n                            try:\n                                eigvals, eigvecs = np.linalg.eigh(Hs)\n                                # compute damping lambda proportional to mean abs eigenvalue\n                                lam = max(1e-6, 0.02 * (np.mean(np.abs(eigvals)) + 1e-12))\n                                inv_eigs = 1.0 / (eigvals + lam)\n                                u_star = -eigvecs.dot(inv_eigs * (eigvecs.T.dot(g_sub)))\n                                # cap movement relative to sigma0\n                                max_sub = 8.0 * sigma0\n                                nsub = np.linalg.norm(u_star)\n                                if nsub > max_sub:\n                                    u_star = u_star * (max_sub / (nsub + 1e-12))\n                                x_star = C + U_sub.dot(u_star)\n                                x_cand = np.minimum(np.maximum(x_star, lb), ub)\n                                step = x_cand - m\n                                strategy = 'surrogate'\n                            except Exception:\n                                x_cand = None\n                    else:\n                        x_cand = None\n\n                # coordinate 1-D quadratic refinement (moderate prob)\n                elif p < self.prob_surrogate + self.prob_coord and len(X_arch) >= 6:\n                    Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                    var = np.var(Xr, axis=0)\n                    coord_weights = var + 1e-8\n                    j = int(rng.choice(self.dim, p=(coord_weights / coord_weights.sum())))\n                    # choose C as best recent\n                    K = min(len(X_arch), max(8, self.dim * 2))\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    C = Xr[np.argmin(fr)].copy()\n                    # try three point quadratic along j with amplitude based on sigma_diag[j]\n                    a = max(1e-6, sigma_diag[j] * (0.7 + rng.rand() * 1.6))\n                    p_plus = np.minimum(np.maximum(C + a * np.eye(self.dim)[j], lb), ub)\n                    p_minus = np.minimum(np.maximum(C - a * np.eye(self.dim)[j], lb), ub)\n                    # budget-check: we will evaluate p_plus, p_minus, and possibly a midpoint\n                    needed = 2\n                    if evals + needed <= self.budget:\n                        f1 = float(func(p_plus)); evals += 1\n                        f2 = float(func(p_minus)); evals += 1\n                        X_arch.append(p_plus.copy()); f_arch.append(f1)\n                        X_arch.append(p_minus.copy()); f_arch.append(f2)\n                        # find fC in archive if available\n                        fC = None\n                        for xi, fi in zip(X_arch, f_arch):\n                            if np.allclose(xi, C):\n                                fC = fi; break\n                        if fC is None and evals < self.budget:\n                            fC = float(func(C)); evals += 1\n                            X_arch.append(C.copy()); f_arch.append(fC)\n                        if fC is None:\n                            fC = min(f_arch)\n                        denom = (f1 + f2 - 2.0 * fC)\n                        if abs(denom) > 1e-12:\n                            alpha_star = (a * (f2 - f1)) / (2.0 * denom)\n                            alpha_star = np.clip(alpha_star, -4.0 * a, 4.0 * a)\n                            x_star = np.minimum(np.maximum(C + alpha_star * np.eye(self.dim)[j], lb), ub)\n                            if evals < self.budget:\n                                f_star = float(func(x_star)); evals += 1\n                                X_arch.append(x_star.copy()); f_arch.append(f_star)\n                                x_cand = x_star.copy()\n                                step = x_cand - m\n                                strategy = 'coord'\n                            else:\n                                # fallback to best observed of C,p_plus,p_minus\n                                best_idx = np.argmin([fC, f1, f2])\n                                if best_idx == 0:\n                                    x_cand = C.copy()\n                                elif best_idx == 1:\n                                    x_cand = p_plus.copy()\n                                else:\n                                    x_cand = p_minus.copy()\n                                step = x_cand - m\n                                strategy = 'coord_fallback'\n                        else:\n                            # fallback\n                            best_idx = np.argmin([fC if fC is not None else 1e20, f1, f2])\n                            if best_idx == 0:\n                                x_cand = C.copy()\n                            elif best_idx == 1:\n                                x_cand = p_plus.copy()\n                            else:\n                                x_cand = p_minus.copy()\n                            step = x_cand - m\n                            strategy = 'coord_fallback'\n                    else:\n                        x_cand = None\n\n                # default blended low-rank + diagonal gaussian probe\n                if x_cand is None:\n                    if k > 0 and rng.rand() < 0.9:\n                        z = rng.randn(k)\n                        eps = rng.randn(self.dim)\n                        # different blend: subspace contribution scaled by s_sub * sigma0, diag by sigma_diag\n                        sub_step = U.dot((z * s_sub) * sigma0)\n                        diag_step = (0.6 * sigma_diag) * eps\n                        step = sub_step + diag_step\n                        x_cand = m + step\n                        strategy = 'blend'\n                    else:\n                        eps = rng.randn(self.dim)\n                        step = sigma_diag * eps * 0.9\n                        x_cand = m + step\n                        strategy = 'diag'\n\n                # clip and evaluate (respect budget)\n                x_cand = np.minimum(np.maximum(x_cand, lb), ub)\n                if evals >= self.budget:\n                    break\n                f_c = float(func(x_cand)); evals += 1\n                X_arch.append(x_cand.copy()); f_arch.append(f_c)\n                if len(X_arch) > self.archive_size:\n                    del X_arch[0]; del f_arch[0]\n\n                improved = False\n                if f_c < f_best:\n                    f_best = f_c\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # reward: improvement relative to median of archive (different baseline)\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                reward = raw_reward / (sigma0 * step_norm + 1e-12)\n\n                # update v_rms and sigma_diag with alternative formula\n                sq = (step / (sigma0 + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq\n                # different mapping from rms to sigma_diag (so equations differ)\n                sigma_diag = sigma0 * (1.0 / (1.0 + np.sqrt(v_rms)))  # values in (0, sigma0]\n                sigma_diag = np.clip(sigma_diag, self.min_sigma, self.max_sigma)\n\n                # update subspace energy & scales multiplicatively\n                if k > 0 and strategy in ('blend', 'surrogate', 'coord'):\n                    projs = U.T.dot(step) if U.size else np.array([])\n                    abs_projs = np.abs(projs)\n                    if abs_projs.size > 0 and abs_projs.sum() > 0:\n                        idx = int(np.argmax(abs_projs))\n                        contrib = abs_projs[idx] / (abs_projs.sum() + 1e-12)\n                        # multiplicative energy boost proportional to reward\n                        boost = 1.0 + 0.28 * reward * contrib\n                        sub_energy[idx] *= boost\n                        # scale s_sub multiplicatively towards observed projection magnitude\n                        obs = np.maximum(abs_projs, 1e-8)\n                        s_sub = np.clip(s_sub * (1.0 + 0.03 * (obs / (np.mean(obs) + 1e-12))),\n                                        self.min_sigma, self.max_sigma)\n                        # slight decay of energies\n                        sub_energy = np.clip(sub_energy * 0.995, 1e-9, 1e9)\n\n                # acceptance test: better always accepted. uphill accepted with different temperature law\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    # temperature scales differently (nonlinear exponents)\n                    T = max(1e-12, self.accept_temp_coeff * (sigma0 ** 1.2) * (avg_span ** 0.8))\n                    deltaE = f_c - f_best\n                    if rng.rand() < np.exp(-max(0.0, deltaE) / (T + 1e-12)):\n                        accept = True\n\n                if accept:\n                    # learning rates by strategy (different constants)\n                    if strategy in ('surrogate',):\n                        lr = 0.72\n                    elif strategy in ('coord', 'coord_fallback'):\n                        lr = 0.5\n                    elif strategy in ('heavy',):\n                        lr = 0.25\n                    elif strategy in ('blend',):\n                        lr = 0.34\n                    else:\n                        lr = 0.2\n                    delta = x_cand - m\n                    # trust clipping uses different factor\n                    trust = 5.0 * sigma0 * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                    # adapt sigma0\n                    if improved:\n                        sigma0 = max(self.min_sigma, sigma0 * 0.90)  # shrink more gently\n                        # reduce v_rms slightly on success to allow refinement\n                        v_rms *= 0.94\n                    else:\n                        # uphill acceptance: increase more noticeably\n                        sigma0 = min(self.max_sigma, sigma0 * 1.06)\n                else:\n                    # rejection: small exploratory drift of mean and mild sigma increase\n                    m = np.minimum(np.maximum(m + 0.008 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma0 = min(self.max_sigma, sigma0 * 1.02)\n\n                # small stochastic rotation of subspace occasionally (different probability & scale)\n                if k > 0 and rng.rand() < 0.045:\n                    R = rng.randn(k, k) * 0.07\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(k) + R)\n                        U = U.dot(Qr)\n                        Q2, _ = np.linalg.qr(U)\n                        U = Q2[:, :k]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed on stagnation but different reseed pattern: Levy-like around best\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    # levy-like jump scale based on sigma0 and avg_span\n                    levy_scale = max(0.06 * avg_span, 1.6 * sigma0)\n                    m = np.minimum(np.maximum(x_best + levy_scale * rng.standard_cauchy(size=self.dim), lb), ub)\n                    sigma0 = min(self.max_sigma, sigma0 * 1.85)\n                    # re-initialize U with small bias towards previous energetic axes\n                    if k > 0:\n                        A = rng.randn(self.dim, k)\n                        Q, _ = np.linalg.qr(A)\n                        U = Q[:, :k]\n                        s_sub = np.full(k, sigma0 * 0.85 / (np.sqrt(k) + 1e-12))\n                        sub_energy = np.ones(k) * 1e-3\n                    # add a few localized evaluations around best (respect budget)\n                    reseed = min(6, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = float(func(x)); evals += 1\n                        X_arch.append(x.copy()); f_arch.append(fx)\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n                        if len(X_arch) > self.archive_size:\n                            del X_arch[0]; del f_arch[0]\n                        if evals >= self.budget:\n                            break\n\n                # ensure sigma_diag within bounds (safety)\n                sigma_diag = np.clip(sigma_diag, self.min_sigma, self.max_sigma)\n                sigma0 = np.clip(sigma0, self.min_sigma, self.max_sigma)\n\n            # end generation\n\n        # store result\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": "dc34281a-bf69-49eb-a520-fa52a9b6e989", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "c7293893-3d0d-4d86-bb9e-9b237e5013c3", "fitness": "-inf", "name": "HARMONY", "description": "The optimizer maintains a low-rank Mahalanobis-like metric (U with intrinsic scales s_sub) plus per-dimension residual scales s_diag learned from a rolling archive (PCA/SVD of top archive points) with conservative blending; rank defaults to dim//8 and archive_size to max(8*dim,120), and the initial trust radius is set from init_radius_mult (0.18) relative to the search span. It uses a small non‑stationary multi-armed bandit (UCB with ucbsigma) to choose among complementary proposal engines: metric‑guided Gaussian moves that combine the low‑rank and diagonal parts, directional 1D/quadratic line and block refinements (using three-point interpolation), and occasional heavy‑tailed Lévy jumps or random fallbacks. Adaptation is hierarchical and conservative: the trust radius and metric scales shrink on success and slowly grow on stagnation, per-dimension s_diag is nudged by recent archive variance, and metric refreshes and small random rotations keep exploration diverse. Finally, strict budget accounting, initial seeding, opportunistic reseed/reheating when stagnating, and modest learning rates/momentum‑free mean updates ensure robustness and stability across the Many Affine BBOB problems.", "code": "import numpy as np\n\nclass HARMONY:\n    \"\"\"\n    HARMONY: Hierarchical Adaptive Random Metric Optimizer\n\n    Key ideas:\n    - Maintain a low-rank Mahalanobis-like metric (U @ diag(s_sub)^2 @ U^T + diag(s_diag^2)) learned from the archive\n      to bias Gaussian proposals in promising principal directions while keeping per-coordinate adaptivity.\n    - Multi-armed proposal set: metric-guided Gaussian, block-coordinate parabola refinement, directional line minimization,\n      and occasional Lévy heavy-tailed jumps. A small non-stationary multi-armed bandit (UCB) decides which proposal to try.\n    - Local quadratic (1-D) interpolation along chosen directions or coordinates for inexpensive line/block minimizers.\n    - Adaptive \"trust radius\" that shrinks on success and grows on long stagnation; periodic PCA refresh of metric.\n    - Opportunistic reseed and reheating restarts when stagnation is detected.\n    - Strict budget accounting: never calls func() more than self.budget times.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=12, rank=None, archive_size=None,\n                 init_radius_mult=0.18, min_radius=1e-8, max_radius=5.0,\n                 p_levy=0.06, p_line=0.22, p_block=0.20,\n                 ucbsigma=1.0, metric_refresh=10, reseed_patience=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.k = rank if rank is not None else max(1, self.dim // 8)\n        self.archive_size = archive_size if archive_size is not None else max(8 * self.dim, 120)\n        self.init_radius_mult = float(init_radius_mult)\n        self.min_radius = float(min_radius)\n        self.max_radius = float(max_radius)\n        # proposal base probabilities (used only for initial UCB priors); selection is done by UCB\n        self.p_levy = float(p_levy)\n        self.p_line = float(p_line)\n        self.p_block = float(p_block)\n        self.ucbsigma = float(ucbsigma)\n        self.metric_refresh = int(metric_refresh)\n        self.reseed_patience = reseed_patience if reseed_patience is not None else max(30, int(0.06 * self.budget))\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial mean uniformly in bounds\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # trust radius (search scale)\n        radius = max(self.min_radius, self.init_radius_mult * avg_span)\n\n        # metric: low-rank U (dim x k), intrinsic scales s_sub and per-dim residual s_diag\n        k = min(self.k, self.dim)\n        if k > 0:\n            A = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :k].copy()\n            s_sub = np.full(k, radius / np.sqrt(max(1, k)))\n        else:\n            U = np.zeros((self.dim, 0))\n            s_sub = np.array([])\n        s_diag = np.full(self.dim, radius * 0.9)\n\n        # bandit for strategy selection\n        strategies = ['metric_gauss', 'line', 'block', 'levy']\n        n_strats = len(strategies)\n        strat_counts = np.ones(n_strats) * 1e-3  # small prior to avoid div-zero\n        strat_rewards = np.zeros(n_strats)\n\n        # simple UCB selection\n        def select_strategy(total_trials):\n            ucb_vals = np.zeros(n_strats)\n            for i in range(n_strats):\n                mean = strat_rewards[i] / (strat_counts[i] + 1e-12)\n                bonus = self.ucbsigma * np.sqrt(np.log(max(1.0, total_trials + 1.0)) / (strat_counts[i] + 1e-12))\n                ucb_vals[i] = mean + bonus\n            # select argmax\n            return int(np.argmax(ucb_vals))\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # seed some initial samples (cheap coverage)\n        seed_init = min(self.pop * 3, max(12, int(self.budget // 300)))\n        for _ in range(seed_init):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        # best\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = self.reseed_patience\n\n        # helper: trim archive\n        def push_archive(x, f):\n            X_arch.append(x.copy()); f_arch.append(float(f))\n            if len(X_arch) > self.archive_size:\n                del X_arch[0]; del f_arch[0]\n\n        # helper: update metric from top points (PCA of top-weighted cluster)\n        def refresh_metric():\n            nonlocal U, s_sub, s_diag\n            if len(X_arch) < max(6, k + 2):\n                return\n            # choose top fraction of archive (by f)\n            K = min(len(X_arch), self.archive_size)\n            Xr = np.asarray(X_arch[-K:])\n            fr = np.asarray(f_arch[-K:])\n            top = max(4, int(0.2 * K))\n            ids = np.argsort(fr)[:top]\n            Xtop = Xr[ids]\n            # center\n            C = Xtop.mean(axis=0)\n            S = Xtop - C\n            # robust covariance (small regularization)\n            try:\n                U_s, svals, _ = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(k, U_s.shape[1])\n                if r_eff > 0:\n                    U_new = U_s[:, :r_eff]\n                    svals = np.maximum(svals[:r_eff] / np.sqrt(max(1, Xtop.shape[0])), 1e-8)\n                    # blend to avoid abrupt jumps\n                    blend = 0.12\n                    if U.shape[1] >= r_eff:\n                        # pad U_new if needed\n                        U = (1.0 - blend) * U + blend * np.hstack([U_new, np.zeros((self.dim, max(0, U.shape[1] - r_eff)))])[:,:U.shape[1]]\n                        Q, _ = np.linalg.qr(U)\n                        U = Q[:, :U.shape[1]]\n                    else:\n                        U = (1.0 - blend) * U + blend * U_new\n                        Q, _ = np.linalg.qr(U)\n                        U = Q[:, :r_eff]\n                    # update s_sub with small EWMA\n                    if s_sub.size == 0:\n                        s_sub = svals.copy()\n                    else:\n                        # resize s_sub to r_eff\n                        old = s_sub.copy()\n                        s_sub = np.resize(s_sub, r_eff)\n                        s_sub = np.clip((1.0 - blend) * s_sub + blend * svals, self.min_radius, self.max_radius)\n                    # also adapt per-dim residual based on diagonal variances\n                    var_diag = np.maximum(np.var(Xtop, axis=0), 1e-9)\n                    s_diag = np.clip(0.9 * s_diag + 0.1 * (np.sqrt(var_diag) + 1e-8), self.min_radius, self.max_radius)\n            except np.linalg.LinAlgError:\n                pass\n\n        # main loop\n        total_trials = 0  # for bandit UCB\n        while evals < self.budget:\n            gen += 1\n\n            # refresh metric periodically\n            if gen % self.metric_refresh == 0:\n                refresh_metric()\n\n            # in each generation propose up to pop candidates\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                total_trials += 1\n                # select strategy via UCB\n                si = select_strategy(total_trials)\n                strat = strategies[si]\n                strat_counts[si] += 1\n\n                # prepare baseline f0 for local interpolation when needed: use best in recent window\n                K = min(len(X_arch), max(8, 3 * self.dim))\n                if K > 0:\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    C = Xr[np.argmin(fr)].copy()\n                else:\n                    C = m.copy()\n\n                x_cand = None\n                step = None\n                used_evals = 0\n                reward = 0.0\n\n                # strategy implementations\n                if strat == 'metric_gauss':\n                    # metric-guided Gaussian: combine low-rank and diagonal residual\n                    if k > 0 and U.size:\n                        z = rng.randn(U.shape[1])\n                        eps = rng.randn(self.dim)\n                        step = U.dot(z * s_sub) + (s_diag * eps)\n                    else:\n                        step = s_diag * rng.randn(self.dim)\n                    # scale by radius\n                    step = step * (radius / (np.linalg.norm(step) / np.sqrt(self.dim) + 1e-12))\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    # single eval\n                    if evals < self.budget:\n                        f_c = float(func(x_cand)); evals += 1; used_evals = 1\n                        push_archive(x_cand, f_c)\n                    else:\n                        break\n\n                elif strat == 'line':\n                    # choose direction: either top principal direction or random\n                    if k > 0 and rng.rand() < 0.6 and U.size:\n                        d = U[:, rng.randint(0, U.shape[1])].copy()\n                    else:\n                        d = rng.randn(self.dim)\n                    d = d / (np.linalg.norm(d) + 1e-12)\n                    # sample three points at -a,0,+a within trust radius\n                    a = radius * (0.6 + 0.8 * rng.rand())\n                    x_m = C.copy()\n                    x_p = np.minimum(np.maximum(x_m + a * d, lb), ub)\n                    x_n = np.minimum(np.maximum(x_m - a * d, lb), ub)\n                    # budget check for two evals (exclude center if same as known best)\n                    can_eval = self.budget - evals\n                    # We must evaluate x_p and x_n at most if budget allows; if center C not in archive, we may evaluate it later.\n                    if can_eval >= 2:\n                        fp = float(func(x_p)); evals += 1; used_evals += 1; push_archive(x_p, fp)\n                        fn = float(func(x_n)); evals += 1; used_evals += 1; push_archive(x_n, fn)\n                        # find fC in archive if exists else estimate with best nearby point (to avoid extra eval if no budget)\n                        fC = None\n                        for xi, fi in zip(X_arch, f_arch):\n                            if np.allclose(xi, x_m):\n                                fC = fi; break\n                        if fC is None and evals < self.budget:\n                            fC = float(func(x_m)); evals += 1; used_evals += 1; push_archive(x_m, fC)\n                        elif fC is None:\n                            # fallback: take min of fp,fn\n                            fC = min(fp, fn)\n                        # quadratic minimizer along line using points (-a, f_n), (0,fC), (+a, f_p)\n                        denom = (fp + fn - 2.0 * fC)\n                        if abs(denom) > 1e-12:\n                            t_star = (a * (fn - fp)) / (2.0 * denom)  # displacement along d\n                            t_star = np.clip(t_star, -3.0 * a, 3.0 * a)\n                            x_star = np.minimum(np.maximum(x_m + t_star * d, lb), ub)\n                            if evals < self.budget:\n                                f_star = float(func(x_star)); evals += 1; used_evals += 1; push_archive(x_star, f_star)\n                                x_cand = x_star.copy()\n                                f_c = f_star\n                            else:\n                                # fallback to best of sampled\n                                best_idx = np.argmin([fC, fp, fn])\n                                if best_idx == 0:\n                                    x_cand = x_m.copy(); f_c = fC\n                                elif best_idx == 1:\n                                    x_cand = x_p.copy(); f_c = fp\n                                else:\n                                    x_cand = x_n.copy(); f_c = fn\n                        else:\n                            best_idx = np.argmin([fC, fp, fn])\n                            if best_idx == 0:\n                                x_cand = x_m.copy(); f_c = fC\n                            elif best_idx == 1:\n                                x_cand = x_p.copy(); f_c = fp\n                            else:\n                                x_cand = x_n.copy(); f_c = fn\n                    else:\n                        # not enough budget: fallback to single metric gaussian\n                        # reuse metric strategy in fallback\n                        if k > 0 and U.size:\n                            z = rng.randn(U.shape[1]); eps = rng.randn(self.dim)\n                            step = U.dot(z * s_sub) + (s_diag * eps)\n                        else:\n                            step = s_diag * rng.randn(self.dim)\n                        step = step * (radius / (np.linalg.norm(step) / np.sqrt(self.dim) + 1e-12))\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        if evals < self.budget:\n                            f_c = float(func(x_cand)); evals += 1; used_evals = 1; push_archive(x_cand, f_c)\n                        else:\n                            break\n\n                elif strat == 'block':\n                    # block-coordinate refinement: pick a small subset of coordinates and do 1D parabola along their average direction\n                    block_size = max(1, min(self.dim, int(max(1, 0.12 * self.dim) * (0.8 + 0.4 * rng.rand()))))\n                    inds = rng.choice(self.dim, size=block_size, replace=False)\n                    # create a block direction (uniform in selected coordinates)\n                    d = np.zeros(self.dim)\n                    d[inds] = rng.randn(block_size)\n                    d = d / (np.linalg.norm(d) + 1e-12)\n                    a = radius * (0.4 + 0.9 * rng.rand())\n                    x_m = C.copy()\n                    x_p = np.minimum(np.maximum(x_m + a * d, lb), ub)\n                    x_n = np.minimum(np.maximum(x_m - a * d, lb), ub)\n                    can_eval = self.budget - evals\n                    if can_eval >= 2:\n                        fp = float(func(x_p)); evals += 1; used_evals += 1; push_archive(x_p, fp)\n                        fn = float(func(x_n)); evals += 1; used_evals += 1; push_archive(x_n, fn)\n                        # get fC if available else evaluate if budget allows\n                        fC = None\n                        for xi, fi in zip(X_arch, f_arch):\n                            if np.allclose(xi, x_m):\n                                fC = fi; break\n                        if fC is None and evals < self.budget:\n                            fC = float(func(x_m)); evals += 1; used_evals += 1; push_archive(x_m, fC)\n                        elif fC is None:\n                            fC = min(fp, fn)\n                        denom = (fp + fn - 2.0 * fC)\n                        if abs(denom) > 1e-12:\n                            t_star = (a * (fn - fp)) / (2.0 * denom)\n                            t_star = np.clip(t_star, -2.5 * a, 2.5 * a)\n                            x_star = np.minimum(np.maximum(x_m + t_star * d, lb), ub)\n                            if evals < self.budget:\n                                f_star = float(func(x_star)); evals += 1; used_evals += 1; push_archive(x_star, f_star)\n                                x_cand = x_star.copy(); f_c = f_star\n                            else:\n                                best_idx = np.argmin([fC, fp, fn])\n                                if best_idx == 0:\n                                    x_cand = x_m.copy(); f_c = fC\n                                elif best_idx == 1:\n                                    x_cand = x_p.copy(); f_c = fp\n                                else:\n                                    x_cand = x_n.copy(); f_c = fn\n                        else:\n                            best_idx = np.argmin([fC, fp, fn])\n                            if best_idx == 0:\n                                x_cand = x_m.copy(); f_c = fC\n                            elif best_idx == 1:\n                                x_cand = x_p.copy(); f_c = fp\n                            else:\n                                x_cand = x_n.copy(); f_c = fn\n                    else:\n                        # fallback to metric gaussian\n                        if k > 0 and U.size:\n                            z = rng.randn(U.shape[1]); eps = rng.randn(self.dim)\n                            step = U.dot(z * s_sub) + (s_diag * eps)\n                        else:\n                            step = s_diag * rng.randn(self.dim)\n                        step = step * (radius / (np.linalg.norm(step) / np.sqrt(self.dim) + 1e-12))\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        if evals < self.budget:\n                            f_c = float(func(x_cand)); evals += 1; used_evals = 1; push_archive(x_cand, f_c)\n                        else:\n                            break\n\n                elif strat == 'levy':\n                    # heavy-tailed Lévy/Cauchy jump scaled by radius\n                    z = rng.standard_cauchy(size=self.dim)\n                    # robust normalizer\n                    z = z / (np.percentile(np.abs(z), 80) + 1e-12)\n                    step = radius * 3.0 * z\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    if evals < self.budget:\n                        f_c = float(func(x_cand)); evals += 1; used_evals = 1; push_archive(x_cand, f_c)\n                    else:\n                        break\n                else:\n                    # safety fallback: random sample\n                    x_cand = rng.uniform(lb, ub, size=self.dim)\n                    f_c = float(func(x_cand)); evals += 1; used_evals = 1; push_archive(x_cand, f_c)\n\n                # after candidate evaluation compute reward and acceptance\n                improved = False\n                if f_c < f_best:\n                    improved = True\n                    f_best = float(f_c)\n                    x_best = x_cand.copy()\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # compute normalized reward: improvement scaled by step magnitude and by used_evals\n                baseline = np.min(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12) if step is not None else 1.0\n                reward = raw_reward / (radius * step_norm + 1e-12)\n                # incorporate success bonus\n                if improved:\n                    reward += 0.5\n\n                # update bandit\n                strat_rewards[si] += reward\n\n                # acceptance decision: accept if better, else metropolis-like with temperature proportional to radius\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    T = max(1e-12, 0.6 * radius * avg_span)\n                    delta = f_c - f_best\n                    if rng.rand() < np.exp(-max(0.0, delta) / (T + 1e-12)):\n                        accept = True\n\n                # move mean if accepted (mirror-like momentum-free update)\n                if accept:\n                    # step towards candidate but clipped by trust and adaptive lr\n                    delta_m = (x_cand - m)\n                    trust = max(1e-12, 6.0 * radius * np.sqrt(self.dim))\n                    dn = np.linalg.norm(delta_m)\n                    if dn > trust:\n                        delta_m = delta_m * (trust / (dn + 1e-12))\n                    # learning rate depends on strategy and success\n                    if improved:\n                        lr = 0.6\n                    else:\n                        lr = 0.18\n                    m = np.minimum(np.maximum(m + lr * delta_m, lb), ub)\n                    # on success shrink radius moderately for refinement\n                    if improved:\n                        radius = max(self.min_radius, radius * 0.86)\n                        # contract metric scales\n                        s_sub = np.clip(0.96 * s_sub, self.min_radius, self.max_radius)\n                        s_diag = np.clip(0.96 * s_diag, self.min_radius, self.max_radius)\n                    else:\n                        # uphill acceptance: enlarge radius slightly to encourage escape\n                        radius = min(self.max_radius, radius * 1.04)\n                        s_sub = np.clip(1.02 * s_sub, self.min_radius, self.max_radius)\n                        s_diag = np.clip(1.02 * s_diag, self.min_radius, self.max_radius)\n                else:\n                    # not accepted: tiny random drift and mild radius growth\n                    m = np.minimum(np.maximum(m + 0.01 * avg_span * rng.randn(self.dim), lb), ub)\n                    radius = min(self.max_radius, radius * 1.02)\n\n                # update simple per-dimension residual adaptivity from archive variance\n                if len(X_arch) >= 6:\n                    # lightweight online diag adaption: higher variance dims get slightly larger s_diag\n                    var_diag = np.maximum(np.var(np.asarray(X_arch[-min(len(X_arch), 40):]), axis=0), 1e-9)\n                    s_diag = np.clip(0.98 * s_diag + 0.02 * (np.sqrt(var_diag) + 1e-8), self.min_radius, self.max_radius)\n\n                # small random rotate of low-rank U occasionally\n                if k > 0 and U.size and rng.rand() < 0.03:\n                    R = rng.randn(U.shape[1], U.shape[1]) * 0.04\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(U.shape[1]) + R)\n                        U = U.dot(Qr)\n                        Q2, _ = np.linalg.qr(U)\n                        U = Q2[:, :U.shape[1]]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed / reheating if stagnation\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    # reheat radius and jitter mean around current best\n                    radius = min(self.max_radius, max(radius, 0.6 * avg_span))\n                    jitter = 0.12 * avg_span\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    # randomize metric a bit\n                    if k > 0:\n                        A = rng.randn(self.dim, k)\n                        Q, _ = np.linalg.qr(A)\n                        U = Q[:, :k]\n                        s_sub = np.full(k, radius / np.sqrt(max(1, k)))\n                    s_diag = np.full(self.dim, radius * 0.9)\n                    # evaluate a few points around best for local refresh (but do not exceed budget)\n                    reseed = min(6, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = float(func(x)); evals += 1\n                        push_archive(x, fx)\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n                            stagn = 0\n                        if evals >= self.budget:\n                            break\n                    # refresh metric immediately after reseed\n                    refresh_metric()\n\n                # trimming archive ensured by push_archive\n\n            # end generation\n\n        # store results\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 365, in hstack, the following error occurred:\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 24 and the array at index 1 has size 10\nOn line: # robust normalizer", "error": "In the code, line 365, in hstack, the following error occurred:\nValueError: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 24 and the array at index 1 has size 10\nOn line: # robust normalizer", "parent_ids": "dc34281a-bf69-49eb-a520-fa52a9b6e989", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "ca57a06c-ec96-4283-af23-644277e8e212", "fitness": "-inf", "name": "ADSE", "description": "The algorithm keeps a compact adaptive orthonormal low-rank subspace (rank ≈ dim/4) for coordinated moves together with per-coordinate RMS-based scales (v_rms with beta=0.9 and sigma_diag = sigma0 / (v_rms^0.6)) so it can exploit correlated structure while retaining independent coordinate agility. It mixes several proposal engines — low-rank Gaussian probes, quadratic surrogate minimization inside the subspace (ridge/eigen-damped solve), 1-D coordinate quadratic refinements, and occasional heavy‑tailed Student‑t escapes — with tuned mixture probabilities (surrogate 0.16, coord 0.08, heavy 0.02) and small population batches. Adaptation and robustness mechanisms include SVD-based subspace refresh from a FIFO archive (size ~6*dim), multiplicative/additive updates of subspace scales and energies, temperature‑based Metropolis acceptance with linear cooling, and step-size sigma0 that shrinks strongly on improvements and slowly increases on rejections. Finally, the method has opportunistic reseeding/rotation and trust clipping to escape stagnation and stabilize large jumps while keeping evaluations within the given budget.", "code": "import numpy as np\n\nclass ADSE:\n    \"\"\"\n    Adaptive Dual-Scale Subspace Explorer (ADSE)\n\n    Main idea (one-line): Maintain a compact adaptive orthonormal subspace for coordinated\n    moves and a per-coordinate residual scale; use cheap quadratic surrogates inside the\n    subspace, coordinate-line refinements, and occasional heavy-tailed escapes. Adapt\n    subspace scales and diagonal scales with different update equations and a temperature\n    schedule for uphill acceptance.\n\n    Differences from the provided ALR-SGE:\n    - default subspace rank ~ dim/4 (not dim/6) and different initialization scalings\n    - surrogate regularization solved via eigen-damping (Levenberg-like) instead of\n      plain solve + ad-hoc conditioning\n    - diagonal scales sigma_diag updated via a different non-linear mapping from v_rms:\n        sigma_diag = sigma0 / (v_rms ** 0.6 + eps)\n    - temperature schedule decreases linearly with used budget (tempered uphill acceptance)\n    - student-t (df=3) heavy-tailed escapes instead of raw Cauchy; coordinate step\n      interpolation uses robust denominator handling with different clipping.\n    - different mixture probabilities and learning rates\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=18, subspace_rank=None, archive_size=None,\n                 init_sigma_mult=0.25, rms_beta=0.90,\n                 prob_surrogate=0.16, prob_coord=0.08, prob_heavy=0.02,\n                 dir_refresh=10, temp_init=1.0,\n                 min_sigma=1e-8, max_sigma=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.k = subspace_rank if subspace_rank is not None else max(1, self.dim // 4)\n        self.archive_size = archive_size if archive_size is not None else max(6 * self.dim, 120)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.rms_beta = float(rms_beta)\n        self.prob_surrogate = float(prob_surrogate)\n        self.prob_coord = float(prob_coord)\n        self.prob_heavy = float(prob_heavy)\n        self.dir_refresh = int(dir_refresh)\n        self.temp_init = float(temp_init)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial mean uniformly\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # step-size and per-dim RMS-like scaling\n        sigma0 = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        v_rms = np.full(self.dim, 1e-6)\n        # different mapping: we'll compute sigma_diag from v_rms with exponent 0.6\n        sigma_diag = np.full(self.dim, sigma0)\n\n        # low-rank subspace U (dim x k) orthonormal and subspace scale s_sub (k,)\n        k = min(self.k, self.dim)\n        if k > 0:\n            A = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :k].copy()\n            # initialize subspace scales slightly larger relative to sigma0\n            s_sub = np.full(k, 0.9 * sigma0 / (np.sqrt(k) + 1e-12))\n            sub_energy = np.ones(k)\n        else:\n            U = np.zeros((self.dim, 0))\n            s_sub = np.array([])\n            sub_energy = np.array([])\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # seed archive with some random points\n        seed_init = min(self.pop * 3, max(12, int(self.budget // 150)))\n        for _ in range(seed_init):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        # best\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(12, int(0.05 * self.budget))\n\n        # helper: fit quadratic surrogate in k-dim subspace around center C using Xs, fs\n        def fit_quad_subspace(C, U_sub, Xs, fs):\n            K = Xs.shape[0]\n            k_loc = U_sub.shape[1]\n            if K <= k_loc + 3:\n                return None, None\n            dX = Xs - C[None, :]\n            U = U_sub\n            UTX = dX.dot(U)  # (K,k)\n            # design: [1, u, 0.5*u^2, off-diags]\n            cols = [np.ones(K)]\n            for j in range(k_loc):\n                cols.append(UTX[:, j])\n            for j in range(k_loc):\n                cols.append(0.5 * (UTX[:, j] ** 2))\n            for i in range(k_loc):\n                for j in range(i + 1, k_loc):\n                    cols.append(UTX[:, i] * UTX[:, j])\n            A = np.vstack(cols).T\n            y = fs\n            # ridge scaled to data\n            lam = 1e-6 + 1e-4 * np.var(y) if y.size > 0 else 1e-6\n            try:\n                # solve normal eq with small ridge for stability\n                ATA = A.T.dot(A) + lam * np.eye(A.shape[1])\n                ATy = A.T.dot(y)\n                theta = np.linalg.solve(ATA, ATy)\n            except Exception:\n                try:\n                    theta, *_ = np.linalg.lstsq(A, y, rcond=None)\n                except Exception:\n                    return None, None\n            idx = 0\n            c0 = float(theta[idx]); idx += 1\n            g = np.zeros(k_loc)\n            for j in range(k_loc):\n                g[j] = float(theta[idx]); idx += 1\n            H = np.zeros((k_loc, k_loc))\n            for j in range(k_loc):\n                H[j, j] = float(theta[idx]); idx += 1\n            for i in range(k_loc):\n                for j in range(i + 1, k_loc):\n                    H[i, j] = float(theta[idx])\n                    H[j, i] = H[i, j]\n                    idx += 1\n            return g, H\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n\n            # refresh subspace occasionally by SVD of recent centered steps (different blending)\n            if (gen % self.dir_refresh == 0) and len(X_arch) >= max(6, k):\n                K = min(len(X_arch), self.archive_size)\n                Xr = np.asarray(X_arch[-K:])\n                Mx = np.mean(Xr, axis=0)\n                S = Xr - Mx\n                try:\n                    U_s, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                    r_eff = min(k, Vt.shape[0])\n                    if r_eff > 0 and k > 0:\n                        U_new = Vt[:r_eff].T\n                        # gentler blending with small randomization\n                        blend = 0.12\n                        U = (1 - blend) * U + blend * U_new\n                        Q, _ = np.linalg.qr(U)\n                        U = Q[:, :r_eff]\n                        # subspace scales update uses median singular value effect\n                        s_sub = np.clip(0.94 * s_sub[:r_eff] + 0.06 * (svals[:r_eff] / (np.sqrt(r_eff) + 1e-12)),\n                                        self.min_sigma, self.max_sigma)\n                        sub_energy = 0.95 * sub_energy[:r_eff] + 0.05 * (svals[:r_eff] + 1e-8)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # temperature schedule (linearly decreases as budget is consumed)\n            T = max(1e-12, self.temp_init * (1.0 - evals / max(1.0, self.budget)))\n\n            # number of proposals this generation\n            n_cand = min(self.pop, max(1, self.budget - evals))\n\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                x_cand = None\n                strategy = 'lowrank'\n                step = np.zeros(self.dim)\n\n                # heavy-tailed Student-t escape (df=3)\n                if rng.rand() < self.prob_heavy:\n                    z = rng.standard_t(df=3, size=self.dim)\n                    # scale robustly (90th percentile)\n                    s90 = np.percentile(np.abs(z), 90) + 1e-12\n                    z = z / s90\n                    x_cand = m + sigma0 * 3.5 * z\n                    strategy = 'heavy'\n\n                # subspace surrogate minimizer\n                elif p < self.prob_surrogate and len(X_arch) >= max(10, 3 * k):\n                    K = min(len(X_arch), self.archive_size)\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    topk = max(5, int(0.12 * K))\n                    ids = np.argsort(fr)[:topk]\n                    C = np.mean(Xr[ids], axis=0)\n                    if k > 0:\n                        U_sub = U.copy()\n                        g_sub, H_sub = fit_quad_subspace(C, U_sub, Xr, fr)\n                        if g_sub is not None and H_sub is not None:\n                            # eigen-decompose H and damp eigenvalues to ensure stable descent\n                            try:\n                                Hs = 0.5 * (H_sub + H_sub.T)\n                                eigvals, Q = np.linalg.eigh(Hs)\n                                # damping: lewinberg-like: add lambda to eigenvalues\n                                lam = max(1e-6, 0.08 * (np.median(np.abs(eigvals)) + 1e-12))\n                                inv_diag = 1.0 / (eigvals + lam)\n                                u_star = -Q.dot(inv_diag * (Q.T.dot(g_sub)))\n                                # limit move magnitude\n                                max_sub = 5.0 * sigma0\n                                nsub = np.linalg.norm(u_star)\n                                if nsub > max_sub:\n                                    u_star = u_star * (max_sub / (nsub + 1e-12))\n                                # add a small diagonal jitter for robustness\n                                eps = rng.randn(self.dim) * 0.15 * sigma0\n                                x_star = C + U_sub.dot(u_star) + eps\n                                x_cand = np.minimum(np.maximum(x_star, lb), ub)\n                                step = x_cand - m\n                                strategy = 'surrogate'\n                            except Exception:\n                                x_cand = None\n\n                # coordinate 1-D quadratic refinement with slightly different formula\n                elif p < self.prob_surrogate + self.prob_coord and len(X_arch) >= 6:\n                    Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                    # choose coordinate with high RMS indicator\n                    coord_scores = (v_rms + 1e-8) * (np.var(Xr, axis=0) + 1e-8)\n                    j = int(rng.choice(self.dim, p=(coord_scores / coord_scores.sum())))\n                    K = min(len(X_arch), max(8, self.dim * 2))\n                    Xr2 = np.asarray(X_arch[-K:])\n                    fr2 = np.asarray(f_arch[-K:])\n                    C = Xr2[np.argmin(fr2)].copy()\n                    a = sigma0 * (0.6 + rng.rand() * 1.8)\n                    e_j = np.zeros(self.dim); e_j[j] = 1.0\n                    p1 = np.minimum(np.maximum(C + a * e_j, lb), ub)\n                    p2 = np.minimum(np.maximum(C - a * e_j, lb), ub)\n                    # evaluate p1 and p2 (cost 2)\n                    if evals + 2 <= self.budget:\n                        f1 = float(func(p1)); evals += 1\n                        f2 = float(func(p2)); evals += 1\n                        X_arch.append(p1.copy()); f_arch.append(f1)\n                        X_arch.append(p2.copy()); f_arch.append(f2)\n                        # try to get f(C) from archive, else evaluate if budget allows\n                        fC = None\n                        for xi, fi in zip(X_arch, f_arch):\n                            if np.allclose(xi, C):\n                                fC = fi; break\n                        if fC is None and evals < self.budget:\n                            fC = float(func(C)); evals += 1\n                            X_arch.append(C.copy()); f_arch.append(fC)\n                        if fC is None:\n                            fC = min(f_arch)\n                        denom = (f1 + f2 - 2.0 * fC)\n                        if abs(denom) > 1e-12:\n                            alpha_star = (a * (f2 - f1)) / (2.0 * denom)\n                            alpha_star = np.clip(alpha_star, -2.5 * a, 2.5 * a)\n                            x_star = np.minimum(np.maximum(C + alpha_star * e_j, lb), ub)\n                            if evals < self.budget:\n                                f_star = float(func(x_star)); evals += 1\n                                X_arch.append(x_star.copy()); f_arch.append(f_star)\n                                x_cand = x_star.copy()\n                                step = x_cand - m\n                                strategy = 'coord'\n                            else:\n                                # fallback to best of three\n                                best_idx = np.argmin([fC, f1, f2])\n                                if best_idx == 0:\n                                    x_cand = C.copy()\n                                elif best_idx == 1:\n                                    x_cand = p1.copy()\n                                else:\n                                    x_cand = p2.copy()\n                                step = x_cand - m\n                                strategy = 'coord_fallback'\n                        else:\n                            best_idx = np.argmin([fC, f1, f2])\n                            if best_idx == 0:\n                                x_cand = C.copy()\n                            elif best_idx == 1:\n                                x_cand = p1.copy()\n                            else:\n                                x_cand = p2.copy()\n                            step = x_cand - m\n                            strategy = 'coord_fallback'\n                    else:\n                        x_cand = None\n\n                # default low-rank + diagonal gaussian probe\n                if x_cand is None:\n                    if k > 0 and rng.rand() < 0.9:\n                        z = rng.randn(k)\n                        eps = rng.randn(self.dim)\n                        step = U.dot(z * s_sub) + 0.65 * (sigma_diag * eps)\n                        x_cand = m + step\n                        strategy = 'lowrank'\n                    else:\n                        eps = rng.randn(self.dim)\n                        step = sigma_diag * eps * 0.9\n                        x_cand = m + step\n                        strategy = 'diag'\n\n                # clip and evaluate\n                x_cand = np.minimum(np.maximum(x_cand, lb), ub)\n                if evals >= self.budget:\n                    break\n                f_c = float(func(x_cand)); evals += 1\n                X_arch.append(x_cand.copy()); f_arch.append(f_c)\n                # FIFO archive control\n                if len(X_arch) > self.archive_size:\n                    del X_arch[0]; del f_arch[0]\n\n                improved = False\n                if f_c < f_best:\n                    f_best = f_c\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # reward normalization: relative to local archive median (different baseline)\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                # reward scaled differently\n                reward = raw_reward / (sigma0 * (step_norm ** 0.7) + 1e-12)\n\n                # update v_rms and sigma_diag (different exponent mapping)\n                sq = (step / (sigma0 + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq\n                sigma_diag = np.clip(sigma0 / (np.power(v_rms + 1e-12, 0.6)), self.min_sigma, self.max_sigma)\n\n                # update subspace scales and energies if a subspace direction was used\n                if k > 0 and strategy in ('lowrank', 'surrogate'):\n                    projs = U.T.dot(step) if U.size else np.array([])\n                    abs_projs = np.abs(projs)\n                    if abs_projs.size > 0 and abs_projs.sum() > 0:\n                        idx = int(np.argmax(abs_projs))\n                        contrib = abs_projs[idx] / (abs_projs.sum() + 1e-12)\n                        # additive energy update (different gain)\n                        alpha_e = 0.18\n                        sub_energy[idx] += alpha_e * reward * contrib\n                        # non-linear subspace scale update: multiplicative blend toward observed projection magnitudes\n                        s_sub = np.clip(0.97 * s_sub + 0.03 * (np.maximum(abs_projs, 1e-8)),\n                                        self.min_sigma, self.max_sigma)\n                        sub_energy = np.clip(sub_energy * 0.998, 1e-8, 1e8)\n\n                # acceptance rule: better always accepted; otherwise Metropolis with T\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    deltaE = f_c - f_best\n                    # deltaE >=0; probability based on T (note f_best updated above if improved)\n                    prob_accept = np.exp(-max(0.0, deltaE) / (T + 1e-12))\n                    if rng.rand() < prob_accept:\n                        accept = True\n\n                if accept:\n                    # learning rates by strategy (different values)\n                    if strategy in ('surrogate',):\n                        lr = 0.9\n                    elif strategy in ('coord', 'coord_fallback'):\n                        lr = 0.6\n                    elif strategy in ('heavy',):\n                        lr = 0.25\n                    elif strategy in ('lowrank',):\n                        lr = 0.5\n                    else:\n                        lr = 0.35\n                    delta = x_cand - m\n                    # trust clipping: avoid extremely large jumps (different scaling)\n                    trust = 5.0 * sigma0 * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                    # sigma0 adaptation: on improvement shrink strongly; uphill acceptance mild increase\n                    if improved:\n                        sigma0 = max(self.min_sigma, sigma0 * 0.90)\n                        v_rms *= 0.95  # reduce RMS memory a bit after success\n                        if k > 0 and 'projs' in locals() and projs.size > 0:\n                            sub_energy = 0.993 * sub_energy\n                    else:\n                        sigma0 = min(self.max_sigma, sigma0 * 1.02)\n                else:\n                    # rejected: random small jitter and mild sigma increase to encourage exploration\n                    m = np.minimum(np.maximum(m + 0.02 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma0 = min(self.max_sigma, sigma0 * 1.01)\n\n                # occasional random rotation of subspace (small)\n                if k > 0 and rng.rand() < 0.04:\n                    R = rng.randn(k, k) * 0.06\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(k) + R)\n                        U = U.dot(Qr)\n                        Q2, _ = np.linalg.qr(U)\n                        U = Q2[:, :k]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed on stagnation (different thresholds)\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    jitter = max(0.06 * avg_span, 1.4 * sigma0)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma0 = min(self.max_sigma, sigma0 * 1.8)\n                    if k > 0:\n                        A = rng.randn(self.dim, k)\n                        Q, _ = np.linalg.qr(A)\n                        U = Q[:, :k]\n                        s_sub = np.full(k, sigma0 * 0.9 / (np.sqrt(k) + 1e-12))\n                        sub_energy = np.ones(k)\n                    # small reseed evaluations around best (controlled)\n                    reseed = min(6, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = float(func(x)); evals += 1\n                        X_arch.append(x.copy()); f_arch.append(fx)\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n                        if len(X_arch) > self.archive_size:\n                            del X_arch[0]; del f_arch[0]\n                        if evals >= self.budget:\n                            break\n\n                # end candidate loop\n\n            # end generation loop\n\n        # store results\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": "dc34281a-bf69-49eb-a520-fa52a9b6e989", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "199a8b0a-c682-4977-8099-e09fd9cb20ee", "fitness": "-inf", "name": "HASTE", "description": "HASTE is a hybrid low-rank + diagonal evolutionary heuristic that maintains a population mean m, a global step-size sigma, a small orthonormal subspace U with per-subspace scales s_sub (rank ≈ dim/6) and per-coordinate RMS-based scales sigma_diag, trading expressive low-dimensional moves with elementwise exploration. It generates antithetic (mirrored) paired samples from the decomposition (U * z + diag_noise) to reduce estimator variance, attribute directional \"pair_gains\" to subspace components, and uses weighted recombination with a momentum term to update the mean. Adaptation is driven by a smoothed success probability (p_succ with beta=0.9) and multiplicative sigma updates (sigma_adapt_rate≈0.26 toward succ_target≈0.2), while per-dimension RMS statistics control diag scales; rare heavy-tailed jumps (heavy_prob≈0.03) and opportunistic reseeds handle deep traps. Auxiliary mechanisms include an archive and a buffer of successful normalized steps used for periodic PCA/SVD refreshes of U and s_sub, plus a cheap ridge linear surrogate in the subspace to propose trust-region moves, and staged restarts when stagnation is detected.", "code": "import numpy as np\n\nclass HASTE:\n    \"\"\"\n    HASTE: Hybrid Adaptive Subspace Trust Evolution\n\n    Main ideas:\n      - Maintain mean m, global step-size sigma, low-rank orthonormal subspace U with subspace scales s_sub,\n        and per-dimension residual scales sigma_diag (via RMS).\n      - Use antithetic (mirrored) paired sampling in the low-rank+diag decomposition to estimate directional gains\n        and reduce variance. Evaluate candidates sequentially until budget.\n      - Update mean by weighted recombination (top half), with a small momentum term.\n      - Keep a FIFO archive and a buffer of normalized successful steps; periodically run SVD on the buffer to refresh U and s_sub.\n      - Fit a small linear surrogate (ridge) in full space (or in subspace) to propose a trust-region/subspace minimizer.\n      - Adapt sigma multiplicatively using a smoothed success rate (approx. 1/5th rule), perform opportunistic restarts and rare heavy-tailed jumps.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # algorithm hyperparameters (sensible defaults)\n        self.pop_base = max(8, int(5 + 1.0 * np.log(max(2, dim))))  # baseline batch size\n        self.rank = max(1, min(dim, dim // 6))                       # low-rank subspace rank\n        self.init_sigma_mult = 0.15\n        self.succ_target = 0.2\n        self.sigma_adapt_rate = 0.26\n        self.p_succ_beta = 0.9\n        self.momentum_beta = 0.65\n        self.rms_beta = 0.92\n        self.pca_period = 9\n        self.buffer_max = max(30, 6 * self.rank)\n        self.arch_size = max(6 * dim, 120)\n        self.trust_scale = 2.5   # trust radius relative to avg span\n        self.heavy_prob = 0.03\n        self.restart_stagn_frac = 0.06\n        self.min_sigma = 1e-12\n        self.max_sigma_mult = 3.0\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds handling: support scalar or per-dim\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize mean and global sigma\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(self.min_sigma, self.init_sigma_mult * avg_span)\n\n        # initialize low-rank subspace U (dim x r) orthonormal and subspace scales s_sub\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :r].copy()\n            s_sub = np.ones(r) * (sigma / max(1.0, np.sqrt(r)))\n            sub_energy = np.ones(r)\n        else:\n            U = np.zeros((self.dim, 0))\n            s_sub = np.array([])\n            sub_energy = np.array([])\n\n        # per-dimension RMS accumulator and diag scales\n        v_rms = np.full(self.dim, 1e-6)\n        sigma_diag = np.full(self.dim, sigma)\n\n        # archive and buffers\n        X_arch = []\n        f_arch = []\n        buffer_steps = []  # normalized successful steps for PCA\n\n        # momentum for mean updates\n        mom = np.zeros(self.dim)\n\n        # bookkeeping\n        evals = 0\n        # seed with a small initial batch to populate archive\n        init_pop = min(self.pop_base, max(6, self.budget // 60))\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # adaptive controllers\n        p_succ = 0.2\n        stagn_limit = max(5, int(self.restart_stagn_frac * self.budget))\n        stagn_count = 0\n\n        gen = 0\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            # prefer even batch for mirrored pairs\n            if lam > 1 and lam % 2 == 1:\n                lam -= 1\n\n            # assemble candidates via mirrored paired sampling\n            cand_X = []\n            cand_f = []\n            cand_type = []  # 'mirror' or 'single' or 'heavy' or 'trust'\n            pair_gains = np.zeros(r) if r > 0 else np.array([])\n\n            pairs = lam // 2\n            for _p in range(pairs):\n                if evals + 2 > self.budget:\n                    break\n\n                # rare heavy-tailed jump to escape traps\n                if rng.rand() < self.heavy_prob:\n                    x_plus = rng.standard_cauchy(self.dim)\n                    # robust scale\n                    scale = np.percentile(np.abs(x_plus), 90) + 1e-12\n                    x_plus = m + (sigma * 4.0) * (x_plus / scale)\n                    x_minus = rng.uniform(lb, ub)\n                else:\n                    # sample low-rank coefficients and diag residual\n                    if r > 0:\n                        z_r = rng.randn(r) * s_sub\n                        low = U.dot(z_r)\n                    else:\n                        low = np.zeros(self.dim)\n                    diag_noise = rng.randn(self.dim) * sigma_diag\n                    step = low + diag_noise  # unscaled by sigma (we use sigma as multiplier below)\n                    x_plus = m + sigma * step\n                    x_minus = m - sigma * step\n\n                # clip to bounds\n                x_plus = np.minimum(np.maximum(x_plus, lb), ub)\n                x_minus = np.minimum(np.maximum(x_minus, lb), ub)\n\n                # evaluate both if budget allows\n                f_plus = float(func(x_plus)); evals += 1\n                f_minus = float(func(x_minus)); evals += 1\n\n                cand_X.append(x_plus.copy()); cand_f.append(f_plus); cand_type.append('mirror')\n                cand_X.append(x_minus.copy()); cand_f.append(f_minus); cand_type.append('mirror')\n\n                # update archive\n                X_arch.append(x_plus.copy()); f_arch.append(f_plus)\n                X_arch.append(x_minus.copy()); f_arch.append(f_minus)\n                if len(X_arch) > self.arch_size:\n                    # trim oldest\n                    excess = len(X_arch) - self.arch_size\n                    del X_arch[0:excess]; del f_arch[0:excess]\n\n                # update best and stagnation counter\n                improved_pair = False\n                if f_plus < f_best:\n                    f_best = f_plus; x_best = x_plus.copy(); improved_pair = True; stagn_count = 0\n                if f_minus < f_best:\n                    f_best = f_minus; x_best = x_minus.copy(); improved_pair = True; stagn_count = 0\n                if not improved_pair:\n                    stagn_count += 1\n\n                # attribute directional gains to subspace components if applicable\n                if r > 0:\n                    # compute projection of step (use low component only if available) in subspace coords\n                    # reconstruct normalized step used (divide by sigma)\n                    step_norm = ( (x_plus - x_minus) * 0.5 ) / (sigma + 1e-20)  # this equals original step\n                    proj = U.T.dot(step_norm)  # r-vector\n                    # gain: positive if average improvement in pair (f_minus - f_plus) > 0\n                    pair_gain = max(0.0, (f_minus - f_plus))\n                    if pair_gain > 0:\n                        pair_gains += pair_gain * np.abs(proj)\n\n                # store successful normalized steps for PCA if either was relatively good\n                # success if either improves over recent local min\n                local_min = np.min(f_arch[-8:]) if len(f_arch) >= 8 else np.min(f_arch)\n                if (f_plus <= local_min + 1e-12) or (f_minus <= local_min + 1e-12):\n                    # normalized by sigma\n                    step_for_buffer = ((x_plus - x_minus) * 0.5) / (sigma + 1e-20)\n                    buffer_steps.append(step_for_buffer.copy())\n                    if len(buffer_steps) > self.buffer_max:\n                        del buffer_steps[0: (len(buffer_steps) - self.buffer_max)]\n\n            # if one remaining evaluation allowed, do a single low-rank+diag probe\n            if evals < self.budget and (self.pop_base - lam) > 0:\n                if rng.rand() < self.heavy_prob:\n                    x = rng.standard_cauchy(self.dim)\n                    scale = np.percentile(np.abs(x), 90) + 1e-12\n                    x = m + (sigma * 4.0) * (x / scale)\n                else:\n                    if r > 0:\n                        z_r = rng.randn(r) * s_sub\n                        low = U.dot(z_r)\n                    else:\n                        low = np.zeros(self.dim)\n                    diag_noise = rng.randn(self.dim) * sigma_diag\n                    step = low + diag_noise\n                    x = m + sigma * step\n                x = np.minimum(np.maximum(x, lb), ub)\n                f_x = float(func(x)); evals += 1\n                cand_X.append(x.copy()); cand_f.append(f_x); cand_type.append('single')\n                X_arch.append(x.copy()); f_arch.append(f_x)\n                if len(X_arch) > self.arch_size:\n                    del X_arch[0: (len(X_arch) - self.arch_size)]\n                if f_x < f_best:\n                    f_best = f_x; x_best = x.copy(); stagn_count = 0\n                else:\n                    stagn_count += 1\n                # buffer\n                if f_x <= np.min(f_arch[-8:]) + 1e-12:\n                    step_norm = (x - m) / (sigma + 1e-20)\n                    buffer_steps.append(step_norm.copy())\n                    if len(buffer_steps) > self.buffer_max:\n                        del buffer_steps[0: (len(buffer_steps) - self.buffer_max)]\n\n            # if no candidates were generated (budget exhausted), break\n            if len(cand_f) == 0:\n                break\n\n            # selection: weighted recombination of top-half elites to update mean\n            fc = np.asarray(cand_f)\n            Xcand = np.asarray(cand_X)\n            lam_eff = Xcand.shape[0]\n            mu = max(1, lam_eff // 2)\n            order = np.argsort(fc)\n            elites = Xcand[order[:mu]]\n            # weights like CMA rank-mu\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones(mu)\n            weights = weights / np.sum(weights)\n            m_new = (weights.reshape(-1, 1) * elites).sum(axis=0)\n\n            # compute normalized deltas for covariance/subspace updates\n            deltas = (elites - m) / (sigma + 1e-20)  # mu x dim\n\n            # update momentum and mean with damping\n            delta_mean = m_new - m\n            mom = self.momentum_beta * mom + (1.0 - self.momentum_beta) * delta_mean\n            # mild learning rate to move mean\n            lr_mean = 0.2\n            m = m + lr_mean * mom\n            m = np.minimum(np.maximum(m, lb), ub)\n\n            # update per-dimension RMS and sigma_diag from elites' deltas\n            if deltas.shape[0] > 0:\n                stat = np.mean(deltas ** 2, axis=0)\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * stat\n                sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-12), self.min_sigma, self.max_sigma_mult * np.max(span))\n            else:\n                # gentle decay\n                v_rms = self.rms_beta * v_rms\n                sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-12), self.min_sigma, self.max_sigma_mult * np.max(span))\n\n            # Update subspace energies from pair_gains if applicable\n            if r > 0 and np.sum(pair_gains) > 0:\n                # softmax-ish scaling and smoothing\n                g = pair_gains\n                g = g - np.max(g)\n                denom = (np.std(g) + 1e-12)\n                p_new = np.exp(g / denom)\n                p_new = p_new / (np.sum(p_new) + 1e-12)\n                # smooth update of s_sub relative magnitudes\n                s_sub = 0.85 * s_sub + 0.15 * ( (s_sub.sum() + 1e-12) * p_new )\n                # keep energies positive\n                s_sub = np.clip(s_sub, 1e-6, 10.0 * sigma)\n\n            # Periodic PCA/SVD refresh on buffer steps to update U and s_sub\n            if (gen % self.pca_period == 0) and len(buffer_steps) >= max(3, r):\n                B = np.asarray(buffer_steps)\n                # center rows\n                Bc = B - np.mean(B, axis=0, keepdims=True)\n                try:\n                    U_s, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        U_new = Vt[:r_eff].T  # dim x r_eff\n                        # align signs to old U for stability when same shape\n                        if U.shape[1] == r_eff:\n                            for k_i in range(r_eff):\n                                if np.dot(U[:, k_i], U_new[:, k_i]) < 0:\n                                    U_new[:, k_i] *= -1.0\n                            U = 0.8 * U + 0.2 * U_new\n                        else:\n                            U = U_new\n                        # orthonormalize\n                        Q, _ = np.linalg.qr(U)\n                        U = Q[:, :r_eff]\n                        # update s_sub from singular values\n                        s_sub = 0.8 * s_sub[:r_eff] + 0.2 * (np.maximum(S_s[:r_eff], 1e-8) * (sigma / max(1.0, np.sqrt(r_eff))))\n                        # clip\n                        s_sub = np.clip(s_sub, 1e-8, 10.0 * sigma)\n                except np.linalg.LinAlgError:\n                    pass\n\n            # Surrogate-guided subspace minimizer (cheap linear ridge in subspace)\n            proposed_trust = None\n            if len(X_arch) >= max(6, r + 3) and r > 0 and evals < self.budget:\n                K = min(len(X_arch), self.arch_size)\n                Xr = np.asarray(X_arch[-K:])\n                fr = np.asarray(f_arch[-K:])\n                # project deltas into subspace coords\n                Uloc = U.copy()\n                Ur = (Xr - m).dot(Uloc)  # K x r\n                # weighted ridge solve for linear surrogate f ~= a + g^T u\n                # solve minimize ||W*(Ur g - (fr - f_med))||^2 + lambda||g||^2\n                f_med = np.median(fr)\n                y = fr - f_med\n                # weighting favor near points\n                dists = np.linalg.norm((Xr - m) / (sigma + 1e-12), axis=1)\n                w = np.exp(-0.6 * dists)\n                W = np.sqrt(w).reshape(-1, 1)\n                A = (W * Ur).T @ (W * Ur) + 1e-6 * np.eye(Ur.shape[1])\n                b = (W * Ur).T @ (W * y)\n                try:\n                    g_sub = np.linalg.solve(A, b)\n                    # propose u_star = -alpha * g_sub (small step along negative gradient in subspace)\n                    alpha = 0.8 * sigma  # scale in subspace units\n                    u_star = - alpha * g_sub\n                    # limit magnitude\n                    norm_sub = np.linalg.norm(u_star)\n                    max_sub = self.trust_scale * avg_span\n                    if norm_sub > max_sub:\n                        u_star = u_star * (max_sub / (norm_sub + 1e-12))\n                    x_trust = m + Uloc.dot(u_star)\n                    x_trust = np.minimum(np.maximum(x_trust, lb), ub)\n                    proposed_trust = x_trust\n                except np.linalg.LinAlgError:\n                    proposed_trust = None\n\n            if proposed_trust is not None and evals < self.budget:\n                f_trust = float(func(proposed_trust)); evals += 1\n                # update archive and best\n                X_arch.append(proposed_trust.copy()); f_arch.append(f_trust)\n                if len(X_arch) > self.arch_size:\n                    del X_arch[0: (len(X_arch) - self.arch_size)]; del f_arch[0: (len(f_arch) - self.arch_size)]\n                if f_trust < f_best:\n                    f_best = f_trust; x_best = proposed_trust.copy(); stagn_count = 0\n                    # accept as mean with stronger pull\n                    m = 0.6 * m + 0.4 * proposed_trust\n                else:\n                    # probabilistic uphill acceptance based on sigma*avg_span\n                    T = max(1e-12, 0.6 * sigma * avg_span)\n                    if rng.rand() < np.exp(-max(0.0, f_trust - f_best) / (T + 1e-12)):\n                        m = 0.2 * m + 0.8 * proposed_trust\n                    else:\n                        # if rejected, increase sigma slightly to explore\n                        sigma = min(self.max_sigma_mult * np.max(span), sigma * 1.06)\n                        stagn_count += 1\n\n            # update smoothed success probability p_succ for sigma adaptation\n            # define generation success if any candidate improved global best in this generation\n            gen_success = float(any(np.array(cand_f) < f_best + 1e-16) or (proposed_trust is not None and f_trust < f_best + 1e-16))\n            p_succ = self.p_succ_beta * p_succ + (1.0 - self.p_succ_beta) * gen_success\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, self.min_sigma, self.max_sigma_mult * np.max(span))\n            # ensure sigma_diag follows sigma if extreme\n            sigma_diag = np.clip(sigma_diag, self.min_sigma, self.max_sigma_mult * np.max(span))\n\n            # opportunistic occasional heavy random reseed if stagnated\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # reseed around best with jitter and inflate sigma\n                jitter = max(0.04 * avg_span, 0.5 * sigma)\n                m = np.minimum(np.maximum(x_best + rng.randn(self.dim) * jitter, lb), ub)\n                sigma = min(self.max_sigma_mult * np.max(span), max(sigma * 1.8, 0.2 * avg_span))\n                # reset some statistics conservatively\n                v_rms = 0.9 * v_rms + 0.1 * np.abs(m) * 0.0\n                sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-12), self.min_sigma, self.max_sigma_mult * np.max(span))\n                # partially reinitialize subspace to encourage new directions\n                if r > 0:\n                    A = rng.randn(self.dim, r)\n                    Q, _ = np.linalg.qr(A)\n                    U = 0.6 * U + 0.4 * Q[:, :r]\n                    Q2, _ = np.linalg.qr(U)\n                    U = Q2[:, :r]\n                    s_sub = np.ones_like(s_sub) * (sigma / max(1.0, np.sqrt(r)))\n                    buffer_steps = []\n                # take a few reseed evaluations near best\n                for _ in range(min(6, self.budget - evals)):\n                    x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                    fx = float(func(x)); evals += 1\n                    X_arch.append(x.copy()); f_arch.append(fx)\n                    if fx < f_best:\n                        f_best = fx; x_best = x.copy()\n                    if len(X_arch) > self.arch_size:\n                        del X_arch[0: (len(X_arch) - self.arch_size)]; del f_arch[0: (len(f_arch) - self.arch_size)]\n                    if evals >= self.budget:\n                        break\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 341, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,14) \nOn line: x_trust = m + Uloc.dot(u_star)", "error": "In the code, line 341, in __call__, the following error occurred:\nValueError: operands could not be broadcast together with shapes (2,) (2,14) \nOn line: x_trust = m + Uloc.dot(u_star)", "parent_ids": "dc34281a-bf69-49eb-a520-fa52a9b6e989", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "6562ea1e-1367-451c-9563-de1b99b2acb9", "fitness": 0.5487111336105255, "name": "TO_ADES", "description": "TO-ADES is a center-based trust-region search that mixes covariance-aware Gaussian sampling around a weighted center m with an adaptive operator pool (diff-to-mean, gaussian-local, elite-mix, Levy-like jump) selected by decaying performance credits, and it stores elites in an archive used for recombination and base selection. It maintains a rank-mu style covariance update (weighted sample covariance normalized by rho) with a directional rank-1 boost toward the generation-best, controlled by cov_lr=0.22 and regularized with an isotropic floor (cov_floor_factor=30) plus chol_safe/eigen clipping to ensure SPD. The trust-region scale rho is initialized as rho_init_frac=0.25 of the mean span and adapted multiplicatively by a smoothed success rate (success_target=0.2, succ_adapt_rate=0.22) with explicit expand/shrink factors (rho_expand=1.18, rho_shrink=0.66), while operator credits decay (op_decay=0.9, op_floor tiny) and operator selection mixes exploration/exploitation (levy_prob≈0.18 for heavy tails). Practical designs include budget-aware batch sizing (lam_base scales with dim and remaining budget), mirrored-opposition initialization, reflect_clamp boundary handling, archive trimming (archive_factor≈6), stagnation detection and opportunistic Levy/isotropic reseeding to escape local traps.", "code": "import numpy as np\n\nclass TO_ADES:\n    \"\"\"\n    Trust-Operator Adaptive Directional Ensemble Search (TO-ADES)\n\n    One-line: Center-based trust-region search (m, rho, C) that mixes covariance-aware Gaussian proposals\n    with an adaptive operator pool (diff-to-mean, gaussian-local, elite-mix, levy) credited by successes,\n    uses rank-mu covariance updates and trust-region rho adaptation plus smoothed success-rate and robust SPD safeguards.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n\n        # Tunables inspired by ADES + OPCMA_TR\n        self.cov_lr = 0.22\n        self.rho_init_frac = 0.25\n        self.rho_expand = 1.18\n        self.rho_shrink = 0.66\n        self.succ_adapt_rate = 0.22   # for smoothed success adaptation of rho-scale\n        self.success_target = 0.2\n        self.min_rho = 1e-12\n        self.archive_factor = 6       # archive size ~ archive_factor * dim\n        self.levy_prob = 0.18\n        self.op_decay = 0.90\n        self.op_floor = 1e-8\n        self.cov_floor_factor = 30.0  # floor relative to bounds span\n        self.stagn_limit_frac = 0.05  # fraction of budget to consider stagnation\n        # operator pool: 0=diff-to-mean,1=gaussian_local,2=elite_mix,3=levy_jump\n        self.n_ops = 4\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds support scalar or per-dim\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        mean_span = float(np.mean(span))\n        max_span = float(np.max(span))\n\n        # adaptive population base (how many candidates per iteration)\n        lam_base = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        lam_base = min(lam_base, max(2, self.budget))\n\n        # initialization: small uniform batch with mirrored opposition-ish samples\n        init_n = max(12, min(60, 6 * self.dim))\n        init_n = min(init_n, max(2, self.budget // 20))\n        pop_init = max(init_n, lam_base)\n        X_init = np.empty((pop_init, self.dim), dtype=float)\n        center_box = 0.5 * (lb + ub)\n        half = (pop_init + 1) // 2\n        for i in range(half):\n            u = rng.rand(self.dim)\n            X_init[i] = lb + u * (ub - lb)\n            j = i + half\n            if j < pop_init:\n                X_init[j] = 2.0 * center_box - X_init[i]\n        X_init = np.minimum(np.maximum(X_init + 1e-8 * rng.randn(*X_init.shape), lb), ub)\n\n        evals = 0\n        f_hist = []\n        X_hist = []\n\n        # Evaluate a moderate initial batch (budget-aware)\n        n_eval_init = min(pop_init, max(4, lam_base))\n        for i in range(n_eval_init):\n            if evals >= self.budget:\n                break\n            x = X_init[i]\n            f = float(func(x))\n            evals += 1\n            f_hist.append(f)\n            X_hist.append(x.copy())\n\n        # ensure at least one point\n        if len(f_hist) == 0:\n            x0 = rng.uniform(lb, ub)\n            f0 = float(func(x0))\n            evals += 1\n            f_hist.append(f0)\n            X_hist.append(x0.copy())\n\n        # initialize center m from weighted elites\n        init_k = max(1, len(f_hist) // 2)\n        order0 = np.argsort(f_hist)\n        elites0 = np.array([X_hist[i] for i in order0[:init_k]])\n        weights0 = np.log(init_k + 0.5) - np.log(np.arange(1, init_k + 1))\n        weights0 = np.maximum(weights0, 0.0)\n        weights0 = weights0 / np.sum(weights0)\n        m = (weights0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # initial covariance & rho\n        C = np.diag(((span / 6.0) ** 2).clip(min=1e-12))\n        rho = max(self.min_rho, self.rho_init_frac * mean_span)\n\n        # archive and best\n        archive_X = np.array(X_hist, dtype=float)\n        archive_f = np.array(f_hist, dtype=float)\n        archive_cap = max(self.dim * self.archive_factor, 4 * self.dim, 20)\n\n        f_best_idx = int(np.argmin(archive_f))\n        f_best = float(archive_f[f_best_idx])\n        x_best = archive_X[f_best_idx].copy()\n\n        # operator credits\n        op_credit = np.ones(self.n_ops, dtype=float)\n\n        # success smoothing\n        p_succ = self.success_target\n\n        stagn_counter = 0\n        stagn_thresh = max(5, int(self.stagn_limit_frac * self.budget))\n        iter_count = 0\n\n        # helper functions\n        def chol_safe(M):\n            eps = 1e-12 * np.maximum(np.diag(M), 1.0)\n            try:\n                return np.linalg.cholesky(M + np.diag(eps))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(M)\n                vals = np.clip(vals, 1e-12, None)\n                return (vecs * np.sqrt(vals)).T\n\n        def reflect_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        def op_probs():\n            s = np.sum(op_credit)\n            if s <= 0:\n                return np.full(self.n_ops, 1.0 / self.n_ops)\n            probs = op_credit / s\n            probs = np.maximum(probs, 1e-6)\n            probs = probs / np.sum(probs)\n            return probs\n\n        def archive_add(x, fx):\n            nonlocal archive_X, archive_f\n            if np.isnan(fx):\n                return\n            if archive_X.size == 0:\n                archive_X = np.array([x.copy()])\n                archive_f = np.array([float(fx)])\n                return\n            # append and trim\n            archive_X = np.vstack([archive_X, x.copy()])\n            archive_f = np.concatenate([archive_f, np.array([float(fx)])])\n            if archive_X.shape[0] > archive_cap:\n                order = np.argsort(archive_f)\n                keep = order[:archive_cap]\n                archive_X = archive_X[keep]\n                archive_f = archive_f[keep]\n\n        # main loop\n        while evals < self.budget:\n            iter_count += 1\n            remaining = self.budget - evals\n            lam = min(lam_base, remaining)\n            mu = max(1, lam // 2)\n\n            # prepare SPD transform\n            A = chol_safe(C)\n\n            # compute mix: half gaussian sampling around m, half operator-driven\n            n_gauss = lam // 2\n            n_op = lam - n_gauss\n\n            Xcand = np.empty((lam, self.dim), dtype=float)\n            cand_origin = np.array([''] * lam)\n\n            # Gaussian proposals N(m, (rho^2) C)\n            if n_gauss > 0:\n                Z = rng.normal(size=(n_gauss, self.dim))\n                Y = Z @ (A.T)  # shape (n_gauss, dim) covariance C\n                Xg = m + (rho * Y)\n                for i in range(n_gauss):\n                    Xcand[i] = reflect_clamp(Xg[i])\n                    cand_origin[i] = 'gauss'\n\n            # operator-driven proposals\n            probs = op_probs()\n            for i in range(n_op):\n                idx = n_gauss + i\n                op = int(rng.choice(self.n_ops, p=probs))\n                cand_origin[idx] = f'op{op}'\n                # choose base from archive or center\n                if archive_X.shape[0] > 0 and rng.rand() < 0.9:\n                    base = archive_X[rng.randint(archive_X.shape[0])].copy()\n                else:\n                    base = m.copy()\n\n                if op == 0:\n                    # diff-to-mean directional\n                    beta = 0.2 + 0.6 * rng.rand()\n                    # pick two archive members if possible\n                    if archive_X.shape[0] >= 2:\n                        a_idx = rng.randint(archive_X.shape[0])\n                        b_idx = rng.randint(archive_X.shape[0])\n                        a = archive_X[a_idx]\n                        b = archive_X[b_idx]\n                    else:\n                        a = base\n                        b = base\n                    trial = base + beta * (m - base) + beta * (a - b) * (0.7 + 0.6 * rng.rand())\n                    Xcand[idx] = reflect_clamp(trial)\n\n                elif op == 1:\n                    # gaussian local around base scaled by rho\n                    local_scale = rho * (0.15 + 0.9 * rng.rand())\n                    trial = base + rng.randn(self.dim) * local_scale\n                    Xcand[idx] = reflect_clamp(trial)\n\n                elif op == 2:\n                    # elite mix: recombine with a top archive member\n                    if archive_X.shape[0] >= 1:\n                        elite = archive_X[rng.randint(archive_X.shape[0])]\n                    else:\n                        elite = m\n                    alpha = 0.3 + 0.7 * rng.rand()\n                    trial = base + alpha * (elite - base) + rng.randn(self.dim) * (0.12 * rho)\n                    Xcand[idx] = reflect_clamp(trial)\n\n                else:\n                    # levy-like heavy tail jump anchored at best or base\n                    anchor = x_best if (rng.rand() < 0.8) else base\n                    # standard Cauchy variates, truncated\n                    s = np.tan(np.pi * (rng.rand(self.dim) - 0.5))\n                    s = np.clip(s, -1e3, 1e3)\n                    scale = 0.5 * mean_span * (0.4 + 1.2 * rng.rand())\n                    trial = anchor + s * scale\n                    Xcand[idx] = reflect_clamp(trial)\n\n            # evaluate candidates sequentially\n            fc = np.empty(lam, dtype=float)\n            for i in range(lam):\n                if evals >= self.budget:\n                    fc[i:] = np.inf\n                    break\n                x_try = Xcand[i]\n                fval = float(func(x_try))\n                fc[i] = fval\n                evals += 1\n                # update archive & best incrementally\n                archive_add(x_try, fval)\n                if fval < f_best:\n                    f_best = float(fval)\n                    x_best = x_try.copy()\n\n            # select top-mu as in ADES\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n            f_mu = fc[order[:mu]]\n            # weighted mean\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            weights = weights / np.sum(weights)\n            m_new = (weights.reshape(-1, 1) * X_mu).sum(axis=0)\n\n            # covariance update (normalized by rho)\n            deltas = (X_mu - m) / (rho + 1e-20)\n            W = weights.reshape(-1, 1)\n            weighted_cov = (deltas * W).T @ deltas\n            # small rank-1 boost toward best candidate\n            gen_best_idx = int(order[0])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            successful = False\n            # approximate f(m): find nearest archived point to m\n            if archive_X.shape[0] > 0:\n                dists = np.sum((archive_X - m) ** 2, axis=1)\n                fm_approx = float(archive_f[np.argmin(dists)]) if archive_f.size > 0 else f_best\n            else:\n                fm_approx = f_best\n            gen_best_f = float(fc[gen_best_idx])\n            if gen_best_f < fm_approx - 1e-12:\n                successful = True\n\n            if successful:\n                step_vec = (gen_best_x - m) / (rho + 1e-20)\n                dir_cov = np.outer(step_vec, step_vec)\n                C = (1.0 - self.cov_lr) * C + self.cov_lr * (0.75 * weighted_cov + 0.25 * dir_cov)\n            else:\n                iso = np.diag(((span / (2.0 * self.cov_floor_factor)) ** 2).clip(min=1e-12))\n                C = (1.0 - 0.5 * self.cov_lr) * C + (0.5 * self.cov_lr) * weighted_cov + (0.5 * self.cov_lr) * iso\n\n            # operator crediting: compare candidates to previous archive median\n            prev_med = np.median(archive_f) if archive_f.size > 0 else np.median(fc)\n            op_try = np.zeros(self.n_ops, dtype=float)\n            op_succ = np.zeros(self.n_ops, dtype=float)\n            for i in range(lam):\n                tag = cand_origin[i]\n                if tag.startswith('op'):\n                    oi = int(tag[2:])\n                elif tag == 'gauss':\n                    oi = 1\n                else:\n                    oi = 1\n                op_try[oi] += 1.0\n                if fc[i] <= prev_med or fc[i] <= f_best:\n                    op_succ[oi] += 1.0\n            # decay + add\n            op_credit = op_credit * self.op_decay + op_succ * (1.0 - self.op_decay)\n            op_credit = np.maximum(op_credit, self.op_floor)\n\n            # smoothed success-rate and rho adaptation (1/5-like smoothing)\n            succ_frac = np.sum(fc < prev_med) / max(1.0, np.sum(np.isfinite(fc)))\n            p_succ = 0.9 * p_succ + 0.1 * succ_frac\n            # multiplicative tweak to rho by success deviation from target\n            adapt_factor = np.exp(self.succ_adapt_rate * (p_succ - self.success_target))\n            rho = float(np.clip(rho * adapt_factor, self.min_rho, 2.0 * max_span))\n\n            # trust-region style acceptance (expand on clear center improvement, else shrink)\n            if successful:\n                # accept and move center\n                m = m_new.copy()\n                rho = min(2.0 * max_span, rho * self.rho_expand)\n                stagn_counter = 0\n            else:\n                # soft acceptance toward m_new and shrink rho\n                m = 0.85 * m + 0.15 * m_new\n                rho = max(self.min_rho, rho * self.rho_shrink)\n                stagn_counter += 1\n\n            # enforce SPD and floor-blend to avoid collapse\n            # apply a small floor blend similar to No1\n            floor = np.diag(((span / self.cov_floor_factor) ** 2).clip(min=1e-12))\n            C = 0.985 * C + 0.015 * floor\n            # eigensafety\n            vals, vecs = np.linalg.eigh(C)\n            vals = np.clip(vals, 1e-16, None)\n            C = (vecs * vals) @ vecs.T\n\n            # update archive arrays for median computations\n            if archive_X.shape[0] > 0:\n                # ensure archive_f synced (we appended earlier via archive_add)\n                archive_f = np.array(archive_f)\n            # opportunistic levy escapes / isotropic re-seeding if stagnating\n            if (stagn_counter * lam) >= stagn_thresh or (iter_count % 23 == 0 and rng.rand() < self.levy_prob):\n                # heavy-tailed jump around best or isotropic reseed\n                if rng.rand() < 0.6 and archive_X.shape[0] > 0:\n                    anchor = x_best\n                    s = np.tan(np.pi * (rng.rand(self.dim) - 0.5))\n                    s = np.clip(s, -1e3, 1e3)\n                    jump = s * (0.5 * mean_span * (0.8 + rng.rand()))\n                    xj = reflect_clamp(anchor + jump)\n                    if evals < self.budget:\n                        fj = float(func(xj)); evals += 1\n                        archive_add(xj, fj)\n                        if fj < f_best:\n                            f_best = fj\n                            x_best = xj.copy()\n                            m = xj.copy()\n                            rho = max(rho, 0.4 * mean_span)\n                            C = np.diag(((span / 6.0) ** 2).clip(min=1e-12))\n                            stagn_counter = 0\n                else:\n                    # isotropic re-seed around m or best\n                    if x_best is not None and rng.rand() < 0.7:\n                        base = x_best\n                    else:\n                        base = m\n                    jitter = rng.randn(self.dim) * (0.08 * mean_span)\n                    m = reflect_clamp(base + jitter)\n                    C = np.diag(((span / 5.0) ** 2).clip(min=1e-12))\n                    rho = max(rho, 0.25 * mean_span)\n                    stagn_counter = 0\n\n            # trim / ensure archive arrays reflect actual\n            if archive_X.shape[0] > 0:\n                # rebuild archive_f from archive_X by evaluating their nearest stored f in f_hist if possible\n                # but we maintain archive_f in archive_add path; ensure shape consistency\n                try:\n                    if archive_f.shape[0] != archive_X.shape[0]:\n                        # rebuild naive: set inf for missing\n                        archive_f = np.concatenate([archive_f, np.full(max(0, archive_X.shape[0] - archive_f.shape[0]), np.inf)])\n                except Exception:\n                    pass\n\n            # safety stop when budget exhausted (loop condition will break)\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm TO_ADES scored 0.549 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "dc34281a-bf69-49eb-a520-fa52a9b6e989", "operator": null, "metadata": {"aucs": [0.13800398987652196, 0.17745274379639697, 0.9520241449014761, 0.9776477190837304, 0.3742387228309211, 0.9749472863780589, 0.27950468954973595, 0.46431538416557316, 0.9471154102888731, 0.2018612452339662]}, "task_prompt": ""}
{"id": "a6173c49-f31a-4805-8ee3-5072a52dea0b", "fitness": 0.27850925050655445, "name": "MAHRS", "description": "MAHRS is a hybrid search that learns a low‑rank manifold from an archive (periodic SVD of recent samples) and mixes manifold-aware proposals with several complementary heuristics to balance global exploration and local intensification. The algorithm maintains a basis B (default rank ≈ dim/10) with per‑component scales (sub_scale) and trusts (trust_vec) derived from singular values, and builds a diagonal quadratic surrogate in that subspace to propose predictive minimizers. Candidates are generated from a weighted mixture (surrogate, low‑rank Gaussian along B + diagonal jitter, radial probes toward the current best, coordinate tweaks, occasional Lévy bursts, mirror reflections, and default Gaussian) with strategy‑dependent learning rates and trust clips, plus small orthonormal perturbations of B to avoid lock‑in. Adaptive control of step sizes is done with a per‑dimension RMS scheme (rms_beta), a global sigma (init_sigma_mult, min/max bounds) and momentum (EMA of accepted deltas), a temperature schedule for occasional uphill acceptance, archive‑driven refresh and safe_eval enforcement of the function‑evaluation budget, and an opportunistic reseed around the best when stagnation is detected.", "code": "import numpy as np\n\nclass MAHRS:\n    \"\"\"\n    Manifold Adaptive Hybrid Random Search (MAHRS)\n\n    Key ideas / mechanisms (brief):\n    - Maintain a low-rank manifold basis B (dim x r) learned from the archive (periodic SVD).\n    - Propose candidates from a mixture:\n       * surrogate-minimizer in the low-rank manifold (diagonal-quadratic fit in subspace),\n       * low-rank Gaussian exploration (coordinated moves along B) + diagonal jitter,\n       * radial probes from mean towards best (intensification),\n       * coordinate annealed tweaks (cheap local moves),\n       * occasional Levy escape,\n       * mirror-reflections of recent worsts to explore opposite directions.\n    - Momentum v biases proposals and is updated on successful accepts (helps traverse ridges).\n    - Trust radii per subspace coordinate (trust_vec) and global sigma adapt with success/failure.\n    - Archive-driven incremental PCA refreshes B every refresh gens.\n    - Temperature schedule for occasional uphill acceptance.\n    - Strict safe_eval to never exceed budget.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=12, rank=None, archive_size=None, init_sigma_mult=0.18,\n                 rms_beta=0.92, temp_init=0.5, dir_refresh=12,\n                 prob_surrogate=0.16, prob_lowrank=0.26, prob_radial=0.18,\n                 prob_coord=0.10, prob_levy=0.03, min_sigma=1e-8, max_sigma=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.rank = rank if rank is not None else max(1, self.dim // 10)\n        self.archive_size = archive_size if archive_size is not None else max(10 * self.dim, 120)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.rms_beta = float(rms_beta)\n        self.temp_init = float(temp_init)\n        self.dir_refresh = int(dir_refresh)\n        # strategy probabilities (should sum <=1; remaining mass goes to default gaussian)\n        self.prob_surrogate = float(prob_surrogate)\n        self.prob_lowrank = float(prob_lowrank)\n        self.prob_radial = float(prob_radial)\n        self.prob_coord = float(prob_coord)\n        self.prob_levy = float(prob_levy)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds (BBOB default -5..5 but allow func to provide)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialization: mean m, best, sigma, per-dim diag scale, momentum v\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        sigma_diag = np.full(self.dim, sigma)\n        v_rms = np.full(self.dim, 1e-6)\n        v_mom = np.zeros(self.dim)  # momentum\n\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()\n            trust_vec = np.full(r, sigma)\n            sub_scale = np.full(r, sigma / np.sqrt(max(1, r)))\n        else:\n            B = np.zeros((self.dim, 0))\n            trust_vec = np.array([])\n            sub_scale = np.array([])\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # safe evaluate wrapper\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            if len(X_arch) > self.archive_size:\n                del X_arch[0]; del f_arch[0]\n            return fx\n\n        # seed with some random samples to populate archive\n        seed0 = min(self.pop * 3, max(12, int(self.budget // 200)))\n        for _ in range(seed0):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        # ensure at least one eval\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(12, int(0.05 * self.budget))\n\n        # helper: incremental refresh of low-rank manifold basis B via SVD of recent archive\n        def refresh_basis():\n            nonlocal B, sub_scale, trust_vec, r\n            if len(X_arch) < 4 or r == 0:\n                return\n            K = min(len(X_arch), self.archive_size)\n            Xr = np.asarray(X_arch[-K:])\n            meanX = Xr.mean(axis=0)\n            S = (Xr - meanX)\n            try:\n                U_s, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(r, Vt.shape[0])\n                if r_eff > 0:\n                    B_new = Vt[:r_eff].T\n                    # blend softly\n                    alpha = 0.16\n                    if B.shape[1] == r_eff:\n                        B = (1.0 - alpha) * B + alpha * B_new\n                    else:\n                        # reinitialize\n                        B = B_new.copy()\n                    # orthonormalize\n                    Q, _ = np.linalg.qr(B)\n                    B = Q[:, :r_eff]\n                    # update scales/trust based on singular values\n                    sub_scale = 0.88 * sub_scale[:r_eff] + 0.12 * (np.maximum(svals[:r_eff], 1e-8) / (np.sqrt(r_eff) + 1e-12))\n                    trust_vec = 0.94 * trust_vec[:r_eff] + 0.06 * (svals[:r_eff] + 1e-8)\n            except Exception:\n                pass\n\n        # main optimization loop: generate candidates in small batches until budget exhausted\n        while evals < self.budget:\n            gen += 1\n\n            # periodic refresh\n            if gen % self.dir_refresh == 0:\n                refresh_basis()\n\n            # annealing temperature for uphill acceptance\n            T = self.temp_init * sigma * avg_span * max(1e-12, 1.0 - (evals / max(1.0, self.budget)))\n\n            # produce up to pop candidates\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                x_cand = None\n                step = None\n                f_c = None\n                strategy = 'gauss'\n\n                # Levy burst escape\n                if p < self.prob_levy:\n                    strategy = 'levy'\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    step = 6.0 * sigma * z\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # surrogate-guided step in low-rank manifold (diagonal quadratic fit in subspace)\n                elif p < self.prob_surrogate and r > 0 and len(X_arch) >= max(12, 6 * r):\n                    strategy = 'surrogate'\n                    # build subspace coords z for archive points centered at m\n                    Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                    Fr = np.asarray(f_arch[-Xr.shape[0]:])\n                    Z = (Xr - m).dot(B)  # (n_samples, r)\n                    # build diagonal quadratic model: f ~ c + b^T z + 0.5 * q * z^2 (elementwise q)\n                    # features: [1, z_i for i, z_i^2 for i]\n                    n = Z.shape[0]\n                    F = np.ones((n, 1 + r + r))\n                    F[:, 1:1 + r] = Z\n                    F[:, 1 + r:] = Z * Z\n                    # ridge solve\n                    lam = 1e-6 * (1.0 + np.var(Fr))\n                    try:\n                        # theta = (F^T F + lam I)^{-1} F^T Fr\n                        FtF = F.T.dot(F)\n                        reg = lam * np.eye(FtF.shape[0])\n                        theta = np.linalg.solve(FtF + reg, F.T.dot(Fr))\n                        c = theta[0]\n                        b = theta[1:1 + r]\n                        q = theta[1 + r:1 + r + r]\n                        # prevent tiny/negative curvature from causing huge steps\n                        q_pos = np.maximum(q, 1e-6)\n                        z_star = - b / (q_pos + 1e-12)\n                        # trust clip in subspace\n                        z_star = np.clip(z_star, -3.0 * trust_vec, 3.0 * trust_vec)\n                        x_pred = np.minimum(np.maximum(m + B.dot(z_star), lb), ub)\n                        f_pred = safe_eval(x_pred)\n                        if f_pred is None:\n                            break\n                        x_cand = x_pred\n                        f_c = f_pred\n                        step = x_cand - m\n                    except Exception:\n                        # fallback to gaussian if surrogate fails\n                        pass\n\n                # low-rank gaussian exploration (coordinated moves along B plus diagonal jitter)\n                if x_cand is None and p < (self.prob_surrogate + self.prob_lowrank) and r > 0:\n                    strategy = 'lowrank'\n                    z = rng.randn(r)\n                    eps = rng.randn(self.dim)\n                    step = B.dot(z * sub_scale) + 0.7 * (sigma_diag * eps) + 0.25 * v_mom\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # radial probe: shoot from mean towards best with variable radius (intensify)\n                if x_cand is None and p < (self.prob_surrogate + self.prob_lowrank + self.prob_radial):\n                    strategy = 'radial'\n                    d = x_best - m\n                    nd = np.linalg.norm(d) + 1e-12\n                    dirv = d / nd\n                    # radius is adaptive: combination of distance to best and sigma\n                    r_probe = (0.6 + rng.rand() * 1.4) * max(0.8 * sigma, 0.5 * nd)\n                    step = dirv * r_probe + 0.15 * v_mom\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # coordinate tweak (cheap)\n                if x_cand is None and p < (self.prob_surrogate + self.prob_lowrank + self.prob_radial + self.prob_coord):\n                    strategy = 'coord'\n                    if len(X_arch) >= 6:\n                        Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                        var = np.var(Xr, axis=0)\n                        weights = var + 1e-8\n                    else:\n                        weights = sigma_diag + 1e-8\n                    weights = weights / (weights.sum() + 1e-12)\n                    j = int(rng.choice(self.dim, p=weights))\n                    step_dir = np.zeros(self.dim)\n                    step_scale = sigma_diag[j] * (0.4 + rng.rand() * 1.6)\n                    step_dir[j] = step_scale * (1.0 if rng.rand() < 0.5 else -1.0)\n                    x_try = np.minimum(np.maximum(m + step_dir, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try\n                    f_c = f_try\n                    step = x_cand - m\n\n                # mirror reflection of a recent worst to explore opposite side\n                if x_cand is None and len(X_arch) >= 4 and rng.rand() < 0.06:\n                    strategy = 'mirror'\n                    # pick a recent worst\n                    idx = int(np.argmax(f_arch[-min(len(f_arch), 20):]))\n                    x_worst = np.asarray(X_arch[-min(len(X_arch), 20):][idx])\n                    step = (m - x_worst) + 0.2 * rng.randn(self.dim) * sigma\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # default gaussian exploration\n                if x_cand is None:\n                    strategy = 'gauss'\n                    eps = rng.randn(self.dim)\n                    step = sigma_diag * eps + 0.2 * v_mom\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # if still no evaluation due to some fallback, skip\n                if f_c is None:\n                    break\n\n                # update best & stagnation\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c)\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # reward based on improvement relative to archive median\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                reward = raw_reward / (sigma * step_norm + 1e-12)\n\n                # RMS update for per-dim sigma_diag\n                sq = (step / (sigma + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq\n                sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-8), self.min_sigma, self.max_sigma)\n\n                # update subspace scales/trust if used\n                if step is not None and r > 0:\n                    projs = B.T.dot(step)\n                    abs_projs = np.abs(projs)\n                    if abs_projs.size > 0 and abs_projs.sum() > 0:\n                        idxp = int(np.argmax(abs_projs))\n                        # gently increase scale for used components\n                        sub_scale = np.clip(0.98 * sub_scale + 0.02 * (np.abs(projs) + 1e-8),\n                                            self.min_sigma, self.max_sigma)\n                        trust_vec[idxp] = 0.975 * trust_vec[idxp] + 0.025 * (abs_projs[idxp] + 1e-8)\n\n                # momentum update (on success accepted)\n                # acceptance decision: improved or probabilistic uphill\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    deltaE = f_c - f_best\n                    if deltaE <= 0:\n                        accept = True\n                    else:\n                        if rng.rand() < np.exp(-deltaE / (T + 1e-12)):\n                            accept = True\n\n                if accept:\n                    # learning rates depend on strategy (more cautious for levy)\n                    if strategy == 'surrogate':\n                        lr = 0.95\n                    elif strategy == 'radial':\n                        lr = 0.65\n                    elif strategy in ('coord', 'mirror'):\n                        lr = 0.5\n                    elif strategy == 'levy':\n                        lr = 0.25\n                    elif strategy == 'lowrank':\n                        lr = 0.42\n                    else:\n                        lr = 0.36\n\n                    delta = (x_cand - m)\n                    # trust clip on mean move\n                    trust = 6.0 * sigma * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    # move mean\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n\n                    # update momentum (EMA of accepted deltas)\n                    v_mom = 0.86 * v_mom + 0.14 * (delta)\n\n                    # adapt sigma: shrink on success more when surrogate/lowrank works, else moderate\n                    if improved:\n                        shrink = 0.84 if strategy in ('surrogate', 'lowrank') else 0.88\n                        sigma = max(self.min_sigma, sigma * shrink)\n                        v_rms *= 0.96\n                    else:\n                        # uphill acceptance inflates sigma slightly to allow exploration\n                        sigma = min(self.max_sigma, sigma * 1.03)\n                else:\n                    # reject: small random jitter to mean and slight sigma inflation\n                    m = np.minimum(np.maximum(m + 0.01 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma = min(self.max_sigma, sigma * 1.006)\n                    v_mom *= 0.98\n\n                # occasional small orthonormal perturbation to B to avoid lock-in\n                if r > 0 and rng.rand() < 0.035:\n                    R = rng.randn(r, r) * 0.05\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(r) + R)\n                        B = B.dot(Qr)\n                        Q2, _ = np.linalg.qr(B)\n                        B = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed around best when stagnation high\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    jitter = max(0.04 * avg_span, 1.1 * sigma)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma = min(self.max_sigma, sigma * 1.6)\n                    v_mom = np.zeros(self.dim)\n                    # refresh basis randomly\n                    if r > 0:\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :r]\n                        sub_scale = np.full(r, sigma / np.sqrt(max(1, r)))\n                        trust_vec = np.full(r, sigma)\n                    # local probes around best\n                    reseed = min(6, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None:\n                            break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # end generation\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MAHRS scored 0.279 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "8e030180-85b3-49dd-8e92-727c3c1f6f8f", "operator": null, "metadata": {"aucs": [0.1155935902139581, 0.1988708682178406, 0.3597534434250774, 0.4627849454498061, 0.2515943056585269, 0.4088597870395132, 0.2462863598640168, 0.34742203698728236, 0.24355384067651697, 0.15037332753300614]}, "task_prompt": ""}
{"id": "f232ce9e-f16e-4ff9-bcfd-8aec5372b2cf", "fitness": 0.19582642816845414, "name": "ADEX2", "description": "ADEX2 mixes two cooperative channels: a memory-driven exploitation channel that stores scored normalized step directions for cheap 1-D parabolic probes (three-point/quadratic interpolation) and a coordinated exploration channel that samples Gaussian proposals in a learned k-dimensional orthonormal subspace B plus per-dimension noise. Per-dimension step scales are adapted with Adam-like first/second moments (m1, m2 → sigma_diag) while a global sigma is adjusted multiplicatively (strong shrink on consistent success, mild inflation on rejections/uphill accepts); the subspace basis and s_sub scales are periodically refreshed via PCA/eigen decomposition with geometric blending and updated multiplicatively from projection energy. The algorithm includes rare Levy escapes and small multi-coordinate tweaks to inject large and targeted diversity, maintains an archive and directional memory for sampling and weighting, and uses reward/scoring of candidates to update memory. Moves are accepted via a simulated-annealing acceptance rule with a decaying temperature, trust-clipped mean updates toward accepted candidates, and opportunistic reseeding on stagnation; parameters bias moderate population (pop=16), small subspace (k≈dim/6), infrequent Levy (0.01) and subspace use (0.25) to balance exploration/exploitation.", "code": "import numpy as np\n\nclass ADEX2:\n    \"\"\"\n    ADEX2: Adaptive Dual-Mechanism Explorer 2\n\n    - Mixes two cooperating channels:\n      * Memory-driven exploitation: weighted directional memory used for cheap 1-D parabolic probes.\n      * Coordinated exploration: an orthonormal subspace B with per-component scales s_sub for Gaussian proposals.\n    - Per-dimension scales adapt via Adam-like moments (beta1, beta2).\n    - Global sigma adapts multiplicatively (shrink on consistent success, mild inflation on rejections).\n    - Periodic PCA/eigen refresh of B with geometric blending (soft updates).\n    - Occasional Levy escapes and coordinate tweaks.\n    \"\"\"\n    def __init__(self, budget, dim, rng_seed=None,\n                 pop=16, k=None, archive_size=None, mem_size=None,\n                 init_sigma_mult=0.25, beta1=0.90, beta2=0.999,\n                 prob_subspace=0.25, prob_coord=0.05, prob_levy=0.01,\n                 dir_refresh=8, temp_init=0.7,\n                 min_sigma=1e-9, max_sigma=10.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.k = k if (k is not None) else max(1, self.dim // 6)  # slightly larger subspace than DSAT\n        self.archive_size = archive_size if archive_size is not None else max(6 * self.dim, 120)\n        self.mem_size = mem_size if mem_size is not None else max(8, self.k * 5)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.beta1 = float(beta1)\n        self.beta2 = float(beta2)\n        self.prob_subspace = float(prob_subspace)\n        self.prob_coord = float(prob_coord)\n        self.prob_levy = float(prob_levy)\n        self.dir_refresh = int(dir_refresh)\n        self.temp_init = float(temp_init)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds (BBOB: usually [-5,5], but use provided bounds if present)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial mean\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # evaluate initial mean to have a reference f_m\n        evals = 0\n        X_arch = []\n        f_arch = []\n\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            if len(X_arch) > self.archive_size:\n                del X_arch[0]; del f_arch[0]\n            return fx\n\n        # seed a handful of random points\n        seed0 = min(self.pop * 3, max(12, int(self.budget // 200)))\n        for _ in range(seed0):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = safe_eval(x0)\n\n        # ensure m evaluated so we have f_m\n        f_m = None\n        # try to find exact match for m in archive\n        for xi, fi in zip(X_arch[::-1], f_arch[::-1]):\n            if np.allclose(xi, m, atol=1e-12):\n                f_m = fi; break\n        if f_m is None and evals < self.budget:\n            f_m = safe_eval(m)\n        if f_m is None:\n            # fallback: choose best seen as mean\n            idx = int(np.argmin(f_arch))\n            m = X_arch[idx].copy()\n            f_m = float(f_arch[idx])\n\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        # global sigma and per-dim diag scales (Adam-like)\n        base_sigma = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        sigma = float(base_sigma)\n        sigma_diag = np.full(self.dim, sigma)\n        m1 = np.zeros(self.dim)   # first moment accumulator (mean of |step|)\n        m2 = np.zeros(self.dim)   # second moment accumulator (mean square)\n        eps = 1e-8\n\n        # exploration subspace\n        k = min(self.k, self.dim)\n        if k > 0:\n            A = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :k].copy()\n            s_sub = np.full(k, sigma / np.sqrt(max(1, k)))\n        else:\n            B = np.zeros((self.dim, 0))\n            s_sub = np.array([])\n\n        # directional memory: store (normalized_dir, score)\n        D_mem = []\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(10, int(0.03 * self.budget))\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n\n            # Basis refresh: use last K archive points, eigen-decompose covariance, geometric blend\n            if (gen % self.dir_refresh == 0) and (k > 0) and len(X_arch) >= max(4, k):\n                K = min(len(X_arch), self.archive_size)\n                Xr = np.asarray(X_arch[-K:])\n                meanX = np.mean(Xr, axis=0)\n                S = (Xr - meanX)\n                try:\n                    # covariance-like matrix in variable space (small K x dim approach)\n                    C = (S.T @ S) / max(1.0, float(S.shape[0] - 1))\n                    vals, vecs = np.linalg.eigh(C)  # ascending eigenvalues\n                    # pick top-k eigenvectors (largest eigenvalues)\n                    idxs = np.argsort(vals)[::-1][:k]\n                    Vk = vecs[:, idxs]\n                    eigs = vals[idxs]\n                    # geometric blend to avoid abrupt flips (alpha larger than DSAT's linear)\n                    alpha = 0.25\n                    B_new = Vk.copy()\n                    # blend and re-orthonormalize\n                    Mblend = (1.0 - alpha) * B + alpha * B_new\n                    Qb, _ = np.linalg.qr(Mblend)\n                    B = Qb[:, :k]\n                    # update s_sub using geometric mixing with sqrt(eigs)\n                    s_sub = np.maximum(self.min_sigma,\n                                       (s_sub ** 0.9) * ((np.sqrt(np.maximum(eigs, 1e-12)) / (np.sqrt(k) + 1e-12)) ** 0.1))\n                except Exception:\n                    pass\n\n            # temperature schedule (more aggressive early, steeper decay)\n            T = self.temp_init * base_sigma * (1.0 - (evals / max(1.0, self.budget))) ** 1.5\n            T = max(T, 1e-12)\n\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                strategy = 'explore_gauss'\n                x_cand = None\n                step = None\n                f_c = None\n\n                # Levy escape (rare, scaled by 3*sigma)\n                if p < self.prob_levy:\n                    strategy = 'levy'\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 85) + 1e-12)\n                    x_cand = m + 3.0 * sigma * z\n                    x_cand = np.minimum(np.maximum(x_cand, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n                    step = x_cand - m\n\n                # exploitation: 1-D memory-driven parabolic search (needs >=3 memory entries)\n                elif (p < self.prob_subspace) and (len(D_mem) >= 4) and (evals + 2 <= self.budget):\n                    strategy = 'exploit_line'\n                    Ds = np.array([d for (d, sc) in D_mem])\n                    scores = np.array([sc for (d, sc) in D_mem])\n                    if Ds.size == 0:\n                        continue\n                    # exponential weighting to emphasize top-scored directions\n                    scaled = np.exp(np.minimum(10.0, (scores - scores.mean()) / (scores.std() + 1e-12)))\n                    w = scaled / (scaled.sum() + 1e-12)\n                    ddir = w @ Ds\n                    nd = np.linalg.norm(ddir) + 1e-12\n                    ddir = ddir / nd\n                    # trust radius from median of stored step magnitudes and scores\n                    mags = np.array([np.linalg.norm(d) for (d, sc) in D_mem]) + 1e-12\n                    r0 = np.median(mags) * (base_sigma + 1e-12)\n                    r = np.clip(r0 * (1.0 + 0.3 * rng.rand()), 0.5 * sigma, 6.0 * sigma)\n                    # ensure we have f(m) (f_m)\n                    # evaluate ends -r and +r\n                    x_minus = np.minimum(np.maximum(m - r * ddir, lb), ub)\n                    x_plus = np.minimum(np.maximum(m + r * ddir, lb), ub)\n                    f_minus = safe_eval(x_minus)\n                    if f_minus is None:\n                        break\n                    f_plus = safe_eval(x_plus)\n                    if f_plus is None:\n                        break\n                    # center f0 is f_m (already known)\n                    f0 = f_m\n                    denom = (f_minus + f_plus - 2.0 * f0)\n                    if abs(denom) > 1e-14:\n                        alpha_star = 0.5 * r * (f_minus - f_plus) / denom\n                        alpha_star = np.clip(alpha_star, -2.5 * r, 2.5 * r)\n                        x_star = np.minimum(np.maximum(m + alpha_star * ddir, lb), ub)\n                        f_star = safe_eval(x_star)\n                        if f_star is None:\n                            break\n                        x_cand = x_star; f_c = f_star; step = x_cand - m\n                    else:\n                        # pick best among three\n                        cand_list = [(f_minus, x_minus), (f0, m.copy()), (f_plus, x_plus)]\n                        f_sel, x_sel = min(cand_list, key=lambda t: t[0])\n                        x_cand = x_sel.copy(); f_c = f_sel; step = x_cand - m\n\n                # coordinate tweak (small multi-coordinate tweak)\n                elif p < (self.prob_subspace + self.prob_coord) and (evals + 1 <= self.budget):\n                    strategy = 'coord'\n                    # pick a small subset of coordinates biased by variance in archive\n                    if len(X_arch) >= 6:\n                        Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                        var = np.var(Xr, axis=0)\n                        weights = var + 1e-8\n                    else:\n                        weights = sigma_diag + 1e-8\n                    weights = weights / (weights.sum() + 1e-12)\n                    # choose s coordinates (1 to 3)\n                    s = min(3, self.dim)\n                    coords = rng.choice(self.dim, size=s, replace=False, p=weights)\n                    step_dir = np.zeros(self.dim)\n                    scale = base_sigma * (0.3 + rng.rand() * 1.2)\n                    for j in coords:\n                        step_dir[j] = scale * (1.0 if rng.rand() < 0.5 else -1.0)\n                    x_try = np.minimum(np.maximum(m + step_dir, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try; f_c = f_try; step = x_cand - m\n\n                # coordinated Gaussian exploration\n                else:\n                    strategy = 'explore_gauss'\n                    if (k > 0) and (rng.rand() < 0.9):\n                        z = rng.randn(k)\n                        eps_vec = rng.randn(self.dim)\n                        step = B.dot(z * s_sub) + (sigma_diag * 0.9) * eps_vec\n                        x_cand = m + step\n                    else:\n                        eps_vec = rng.randn(self.dim)\n                        step = sigma_diag * eps_vec\n                        x_cand = m + step\n                    x_cand = np.minimum(np.maximum(x_cand, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                if f_c is None and x_cand is not None and evals < self.budget:\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n                    if step is None:\n                        step = x_cand - m\n\n                if f_c is None:\n                    break\n\n                # update best and stagnation counters\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c)\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # reward: improvement over recent median scaled by step length and base_sigma\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                reward = raw_reward / (base_sigma * step_norm + 1e-12)\n                # transform reward to positive \"score-like\" quantity\n                score = reward * (1.0 + 2.0 * rng.rand())\n\n                # update per-dimension Adam-like moments using normalized absolute step\n                if step is not None:\n                    g = np.abs(step) / (base_sigma + eps)  # per-dim signal\n                    m1 = self.beta1 * m1 + (1.0 - self.beta1) * g\n                    m2 = self.beta2 * m2 + (1.0 - self.beta2) * (g * g)\n                    # bias-correct (approx, using gen as time)\n                    # compute sigma_diag from second moment (like RMSprop/Adam)\n                    denom = np.sqrt(m2) + eps\n                    sigma_diag = np.clip(base_sigma / denom, self.min_sigma, self.max_sigma)\n\n                # update subspace scales from projection energy (geometric tweak)\n                if step is not None and k > 0:\n                    projs = B.T.dot(step)\n                    abs_projs = np.abs(projs)\n                    if abs_projs.size > 0 and abs_projs.sum() > 0:\n                        # increase s_sub multiplicatively where used\n                        s_sub = np.clip(s_sub * (1.0 + 0.06 * (abs_projs / (abs_projs.mean() + 1e-12))),\n                                        self.min_sigma, self.max_sigma)\n\n                # store in directional memory if it had positive score and a meaningful step\n                if step is not None and score > 1e-12 and np.linalg.norm(step) > 1e-12:\n                    dnorm = step / (np.linalg.norm(step) + 1e-12)\n                    # store direction scaled by log-like magnitude to avoid huge values\n                    mag = np.log1p(np.linalg.norm(step) / (base_sigma + 1e-12))\n                    D_mem.append((dnorm * mag, score + 1e-12))\n                    if len(D_mem) > self.mem_size:\n                        D_mem.pop(0)\n\n                # acceptance: compare to local f_m (not to global best) with simulated annealing\n                accept = False\n                if f_c <= f_m - 1e-15:\n                    accept = True\n                else:\n                    deltaE = f_c - f_m\n                    # accept uphill with probability exp(-deltaE / T)\n                    if rng.rand() < np.exp(-deltaE / T):\n                        accept = True\n\n                if accept:\n                    # mean update learning rate depending on strategy (different lr choices than DSAT)\n                    if strategy == 'exploit_line':\n                        lr = 0.92\n                    elif strategy == 'coord':\n                        lr = 0.60\n                    elif strategy == 'levy':\n                        lr = 0.20\n                    elif strategy == 'explore_gauss':\n                        lr = 0.40\n                    else:\n                        lr = 0.35\n                    delta = (x_cand - m)\n                    # trust clipping based on base_sigma and dimension\n                    trust = 5.5 * sigma * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                    # update f_m to new location\n                    # We must ensure f_m is the evaluation at m: if x_cand equals new m (within lr=1), f_c might correspond.\n                    # To stay safe, set f_m to f_c if moving to x_cand, else evaluate new m if budget allows.\n                    if np.allclose(m, x_cand, atol=1e-12):\n                        f_m = f_c\n                    else:\n                        # evaluate new m only if budget allows; otherwise keep previous f_m\n                        if evals < self.budget:\n                            val = safe_eval(m)\n                            if val is not None:\n                                f_m = val\n\n                    # adjust global sigma multiplicatively: shrink on successful moves (stronger shrink), mild inflation on uphill accept\n                    if f_c < f_best + 1e-15 or improved:\n                        sigma = max(self.min_sigma, sigma * 0.92)  # stronger shrink than DSAT (0.86 -> 0.92 multiplicative)\n                        base_sigma = sigma\n                    else:\n                        # uphill acceptance: slight inflation\n                        sigma = min(self.max_sigma, sigma * 1.01)\n                        base_sigma = sigma\n                else:\n                    # reject: small random drift and mild sigma inflation\n                    m = np.minimum(np.maximum(m + 0.005 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma = min(self.max_sigma, sigma * 1.008)\n                    base_sigma = sigma\n\n                # small ensemble perturbation of subspace\n                if k > 0 and rng.rand() < 0.06:\n                    R = rng.randn(k, k) * 0.08\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(k) + R)\n                        B = B.dot(Qr)\n                        Q2, _ = np.linalg.qr(B)\n                        B = Q2[:, :k]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed if stagnated\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    jitter = max(0.04 * avg_span, 1.1 * sigma)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    if evals < self.budget:\n                        val = safe_eval(m)\n                        if val is not None:\n                            f_m = val\n                    sigma = min(self.max_sigma, sigma * 1.5)\n                    # reinitialize basis softly\n                    if k > 0:\n                        A = rng.randn(self.dim, k)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :k]\n                        s_sub = np.full(k, sigma / np.sqrt(max(1, k)))\n                        D_mem = []\n\n            # end generation\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ADEX2 scored 0.196 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "8e030180-85b3-49dd-8e92-727c3c1f6f8f", "operator": null, "metadata": {"aucs": [0.12829044389044042, 0.2012160362922758, 0.24211436950703602, 0.20474830328070825, 0.19731390914072666, 0.21266098408634648, 0.22210241980859935, 0.20745136456476354, 0.19303308087653404, 0.1493333702371109]}, "task_prompt": ""}
{"id": "f0c98316-d2d3-4f3c-af62-12143b02f5c7", "fitness": 0.20209469911855815, "name": "TASE", "description": "TASE is a hybrid, budget-aware continuous optimizer that maintains a compact low-rank exploration subspace U (learned from an archive via SVD and incremental updates) combined with per-dimension adaptive scaling (RMS/AdaGrad style g_acc → diag_scale) and a global trust radius that adapts to recent success rate. It blends three cooperative proposers—anisotropic low-rank + diagonal Gaussian sampling for controlled local search, archive-guided 1‑D parabola line-searches along learned directional memory for focused exploitation, and sparse/Householder-rotated Cauchy escapes for rare heavy‑tailed global moves—selected probabilistically (prob_line≈0.16, prob_rotate≈0.10, prob_escape≈0.03). Acceptance uses strategy-dependent learning rates and a Metropolis-like uphill probability with a temperature schedule, while an archive, directional memory, and opportunistic reseeding on stagnation preserve diversity and allow recovery from local traps. Practical safeguards include bounds clamping, budget‑aware safe_eval, clipped step lengths, and tunable sizes for population, subspace rank k, archive and memory so the method scales with dimension and available evaluations.", "code": "import numpy as np\n\nclass TASE:\n    \"\"\"\n    Tri-Adapt Subspace Ensemble (TASE)\n\n    Key ideas (short):\n    - Maintain a compact low-rank exploration subspace U (dim x k) learned from archive (PCA-like).\n    - Use three cooperative proposers:\n        1) Archive-guided 1-D parabola line-searches along promising directions (from directional memory or U).\n        2) Anisotropic elliptical Gaussian sampling using low-rank + diagonal preconditioner.\n        3) Rotational sparse/Cauchy escapes via randomized Householder-like rotations for heavy tails.\n    - Adaptive per-dimension scaling (AdaGrad/RMS style), a trust radius that adapts to recent success rate,\n      and occasional reseed if stagnation occurs.\n    - Budget-aware safe_eval ensures we never exceed budget.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, pop=14, k=None, seed=None,\n                 init_sigma_mult=0.20, rms_beta=0.96, dir_refresh=12,\n                 prob_line=0.16, prob_rotate=0.10, prob_escape=0.03,\n                 mem_size=None, archive_size=None,\n                 accept_temp_init=0.6, min_sigma=1e-8, max_sigma=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop = int(pop)\n        self.rng = np.random.RandomState(seed)\n        self.k = int(k) if k is not None else max(1, self.dim // 10)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.rms_beta = float(rms_beta)\n        self.dir_refresh = int(dir_refresh)\n        self.prob_line = float(prob_line)\n        self.prob_rotate = float(prob_rotate)\n        self.prob_escape = float(prob_escape)\n        self.accept_temp_init = float(accept_temp_init)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n        self.archive_size = archive_size if archive_size is not None else max(8 * self.dim, 120)\n        self.mem_size = mem_size if mem_size is not None else max(6, int(self.k * 6))\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # --- bounds handling (Many BBOB typical bounds [-5,5] but we check func.bounds if provided) ---\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial mean - uniform in bounds\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # global step scale and per-dimension accumulator (RMS/AdaGrad hybrid)\n        sigma = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        g_acc = np.full(self.dim, 1e-6)   # accumulation of squared steps\n        diag_scale = np.full(self.dim, sigma)\n\n        # low-rank exploration subspace U (orthonormal columns), per-axis scales s_sub\n        k = min(self.k, self.dim)\n        if k > 0:\n            A = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :k].copy()\n            s_sub = np.full(k, sigma / np.sqrt(k))\n        else:\n            U = np.zeros((self.dim, 0))\n            s_sub = np.array([])\n\n        # directional memory (successful normalized steps + reward)\n        D_mem = []  # list of (direction, reward)\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # safe evaluate wrapper, clamps to bounds, respects budget, stores archive\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            if len(X_arch) > self.archive_size:\n                del X_arch[0]; del f_arch[0]\n            return fx\n\n        # initial seeding of archive (diverse)\n        seed0 = min(self.pop * 4, max(12, int(self.budget // 200)))\n        for _ in range(seed0):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = safe_eval(x0)\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            safe_eval(rng.uniform(lb, ub, size=self.dim))\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # trust region radius (elliptical), adapt from success ratio\n        trust = sigma * np.sqrt(self.dim)\n        success_window = []  # last few accepts (1/0)\n        suc_window_len = max(6, int(0.02 * self.budget))\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(12, int(0.06 * self.budget))\n\n        # helper: compute principal directions from archive (PCA-like) for U update\n        def refresh_subspace():\n            nonlocal U, s_sub\n            if len(X_arch) < max(4, k):\n                return\n            K = min(len(X_arch), self.archive_size)\n            Xr = np.asarray(X_arch[-K:])\n            meanX = Xr.mean(axis=0)\n            S = (Xr - meanX)\n            try:\n                # use compact SVD (rows = samples -> Vt columns are directions)\n                _, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(k, Vt.shape[0])\n                if r_eff > 0:\n                    U_new = Vt[:r_eff].T  # dim x r_eff\n                    # soft update of subspace via blending and re-orthonormalize\n                    blend = 0.18\n                    if U.shape[1] == 0:\n                        U = U_new.copy()\n                    else:\n                        # pad or truncate to match r_eff\n                        U = 0.82 * U[:, :r_eff] + blend * U_new\n                        Q, _ = np.linalg.qr(U)\n                        U = Q[:, :r_eff]\n                    # adapt s_sub from singular values (scale how much to explore along these axes)\n                    s_sub = 0.9 * s_sub[:r_eff] + 0.1 * (np.maximum(svals[:r_eff], 1e-8) / (np.sqrt(r_eff) + 1e-12))\n            except Exception:\n                pass\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n\n            # occasionally refresh U from archive\n            if (gen % self.dir_refresh == 0):\n                refresh_subspace()\n\n            # update diag_scale from g_acc (AdaGrad-like)\n            diag_scale = np.clip(sigma / (np.sqrt(g_acc) + 1e-8), self.min_sigma, self.max_sigma)\n\n            # temperature schedule for uphill acceptance\n            T = self.accept_temp_init * sigma * avg_span * max(1e-12, 1.0 - (evals / max(1.0, self.budget)))\n\n            # produce candidates\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                x_cand = None\n                f_c = None\n                step = None\n                strategy = 'elliptical'\n\n                # Rare heavy-tail global escape (large Cauchy)\n                if p < self.prob_escape:\n                    strategy = 'escape_cauchy'\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    scale = max(2.5 * sigma, 0.3 * avg_span)\n                    x_cand = np.minimum(np.maximum(m + scale * z, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n                    step = x_cand - m\n\n                # Archive-guided 1-D parabola (line-search) along a promising direction\n                elif p < self.prob_line and len(D_mem) >= 3 and (evals + 2 <= self.budget):\n                    strategy = 'line_search'\n                    # form direction from D_mem weighted by recent reward and recency\n                    Ds = np.array([d for (d, rw) in D_mem])\n                    RWs = np.array([rw for (d, rw) in D_mem])\n                    if Ds.size == 0:\n                        continue\n                    # combine recency and reward: last entries get slight bonus\n                    recency = np.linspace(0.7, 1.0, len(RWs))\n                    weights = (RWs + 1e-8) * recency\n                    wnorm = weights / (weights.sum() + 1e-12)\n                    ddir = np.tensordot(wnorm, Ds, axes=(0,0))\n                    nd = np.linalg.norm(ddir) + 1e-12\n                    ddir = ddir / nd\n                    # try to compute an effective radius r from trust and archive spread along ddir\n                    proj_vals = None\n                    if len(X_arch) >= 6:\n                        Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                        proj_vals = (Xr - m).dot(ddir)\n                    spread = float(np.std(proj_vals)) if proj_vals is not None and proj_vals.size > 1 else 0.5 * sigma\n                    r = np.clip(1.5 * spread + 0.5 * sigma, 0.2 * sigma, 6.0 * sigma) * (1.0 + 0.2 * rng.rand())\n                    # evaluate at -r and +r around m, and fit symmetric parabola as robust formula\n                    x_minus = np.minimum(np.maximum(m - r * ddir, lb), ub)\n                    x_plus = np.minimum(np.maximum(m + r * ddir, lb), ub)\n                    f_minus = safe_eval(x_minus)\n                    if f_minus is None:\n                        break\n                    f_plus = safe_eval(x_plus)\n                    if f_plus is None:\n                        break\n                    # try parabola min estimate alpha* in [-2r,2r]\n                    denom = (f_minus + f_plus - 2.0 * np.min([f_minus, f_plus, f_best]))\n                    if abs(denom) > 1e-12:\n                        alpha = 0.5 * r * (f_minus - f_plus) / denom\n                        alpha = np.clip(alpha, -2.0 * r, 2.0 * r)\n                        x_star = np.minimum(np.maximum(m + alpha * ddir, lb), ub)\n                        f_star = safe_eval(x_star)\n                        if f_star is None:\n                            break\n                        x_cand = x_star\n                        f_c = f_star\n                        step = x_cand - m\n                    else:\n                        # pick better of the endpoints\n                        if f_minus < f_plus:\n                            x_cand = x_minus; f_c = f_minus; step = x_cand - m\n                        else:\n                            x_cand = x_plus; f_c = f_plus; step = x_cand - m\n\n                # Rotational sparse/Cauchy perturbation (structured heavy-tail)\n                elif p < (self.prob_line + self.prob_rotate) and (evals + 1 <= self.budget):\n                    strategy = 'rotational'\n                    # build a small random Householder-like rotation based on vector h\n                    h = rng.randn(self.dim)\n                    h = h / (np.linalg.norm(h) + 1e-12)\n                    # construct sparse cauchy vector (only a few nonzeros) to create directional escape\n                    sparse_mask = rng.rand(self.dim) < (0.12 + 0.02 * rng.rand())\n                    if not np.any(sparse_mask):\n                        sparse_mask[rng.randint(self.dim)] = True\n                    z = np.zeros(self.dim)\n                    z[sparse_mask] = rng.standard_cauchy(size=np.count_nonzero(sparse_mask))\n                    z = z / (np.percentile(np.abs(z[sparse_mask]), 90) + 1e-12)\n                    # apply reflection: v - 2*(h^T v) h\n                    v = z - 2.0 * (h.dot(z)) * h\n                    scale = max(0.5 * sigma, 0.08 * avg_span) * (1.0 + 0.6 * rng.rand())\n                    x_cand = np.minimum(np.maximum(m + scale * v, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n                    step = x_cand - m\n\n                # default: anisotropic elliptical Gaussian sampling using low-rank U + diag preconditioner\n                else:\n                    strategy = 'elliptical'\n                    if k > 0 and rng.rand() < 0.9:\n                        zk = rng.randn(U.shape[1])\n                        ed = rng.randn(self.dim)\n                        step = U.dot(zk * s_sub) + 0.9 * (diag_scale * ed)\n                    else:\n                        ed = rng.randn(self.dim)\n                        step = diag_scale * ed\n                    # clip step by trust to keep proposals controlled\n                    step_norm = np.linalg.norm(step) + 1e-12\n                    max_step = 2.5 * trust\n                    if step_norm > max_step:\n                        step = step * (max_step / step_norm)\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # ensure we have f_c\n                if f_c is None:\n                    if x_cand is not None and evals < self.budget:\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n                        if step is None:\n                            step = x_cand - m\n                    else:\n                        break\n\n                # update best & stagnation counters\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c)\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # compute reward: improvement relative to median of archive\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                # normalize reward by local scale and distance: rewards small efficient improvements\n                reward = raw_reward / (sigma * step_norm + 1e-12)\n\n                # update g_acc (RMS-like) and diag_scale\n                scaled_step = (step / (sigma + 1e-12))\n                g_acc = self.rms_beta * g_acc + (1.0 - self.rms_beta) * (scaled_step ** 2)\n                diag_scale = np.clip(sigma / (np.sqrt(g_acc) + 1e-8), self.min_sigma, self.max_sigma)\n\n                # update low-rank U using successful step direction (incremental)\n                if step_norm > 1e-12:\n                    dir_norm = step / step_norm\n                    if reward > 1e-9:\n                        # push new direction with intensity proportional to reward\n                        add_vec = dir_norm * (0.06 + 0.6 * min(1.0, reward))\n                    else:\n                        add_vec = dir_norm * 0.02\n                    if U.shape[1] > 0:\n                        # blend and re-orthonormalize\n                        U = 0.96 * U + 0.04 * np.reshape(add_vec, (-1,1))[:,:U.shape[1]]\n                        try:\n                            Q, _ = np.linalg.qr(U)\n                            U = Q[:, :U.shape[1]]\n                        except Exception:\n                            pass\n                    else:\n                        if k > 0:\n                            # initialize U with the new vector + some random complement\n                            A = np.column_stack([add_vec, rng.randn(self.dim, k-1)])\n                            Q, _ = np.linalg.qr(A)\n                            U = Q[:, :k]\n                    # slightly adapt s_sub along projection magnitudes\n                    if U.shape[1] > 0:\n                        projs = np.abs(U.T.dot(step))\n                        s_sub = np.clip(0.98 * s_sub + 0.02 * (projs + 1e-8), self.min_sigma, self.max_sigma)\n\n                # update directional memory D_mem (FIFO) using normalized directions scaled by step length\n                if step_norm > 1e-12 and reward > 1e-12:\n                    dnorm = step / step_norm\n                    scaled_dir = dnorm * min(1.0, step_norm / (sigma + 1e-12))\n                    D_mem.append((scaled_dir, reward + 1e-12))\n                    if len(D_mem) > self.mem_size:\n                        D_mem.pop(0)\n\n                # acceptance: improved or metropolis-like uphill acceptance\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    deltaE = f_c - f_best\n                    # if deltaE <= 0 accept (numerical) else probabilistic\n                    if deltaE <= 0:\n                        accept = True\n                    else:\n                        if rng.rand() < np.exp(-deltaE / (T + 1e-12)):\n                            accept = True\n\n                # decide move of mean m\n                if accept:\n                    # learning rates depend on strategy (conservative for escapes)\n                    if strategy == 'line_search':\n                        lr = 0.92\n                    elif strategy == 'elliptical':\n                        lr = 0.40\n                    elif strategy == 'rotational':\n                        lr = 0.32\n                    elif strategy == 'escape_cauchy':\n                        lr = 0.20\n                    else:\n                        lr = 0.35\n                    delta = (x_cand - m)\n                    # trust clipping on mean movement - keeps m from jumping too far\n                    trust_clip = max(0.5 * trust, 6.0 * sigma * np.sqrt(max(1, self.dim)))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust_clip:\n                        delta = delta * (trust_clip / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n\n                    # adapt trust based on success ratio\n                    success_window.append(1)\n                    if len(success_window) > suc_window_len:\n                        success_window.pop(0)\n                    suc_rate = float(sum(success_window)) / max(1, len(success_window))\n                    # if many successes, shrink trust (exploit), else expand (explore)\n                    if suc_rate > 0.6:\n                        trust = max(0.5 * sigma, trust * 0.86)\n                        sigma = max(self.min_sigma, sigma * 0.90)\n                    elif suc_rate < 0.2:\n                        trust = min(self.max_sigma * avg_span, trust * 1.06)\n                        sigma = min(self.max_sigma, sigma * 1.03)\n                    else:\n                        # minor damping\n                        trust = trust * (0.995 + 0.01 * rng.rand())\n\n                else:\n                    # rejected proposals cause a small isotropic jitter on mean to maintain exploration\n                    m = np.minimum(np.maximum(m + 0.004 * avg_span * rng.randn(self.dim), lb), ub)\n                    success_window.append(0)\n                    if len(success_window) > suc_window_len:\n                        success_window.pop(0)\n                    # slight inflation of sigma if many rejects\n                    if sum(success_window) < max(1, 0.25 * len(success_window)):\n                        sigma = min(self.max_sigma, sigma * 1.004)\n\n                # opportunistic reseed when prolonged stagnation\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    # reposition mean near best with jitter and inflate sigma to escape\n                    jitter = max(0.06 * avg_span, 1.4 * sigma)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma = min(self.max_sigma, sigma * 1.7)\n                    # randomize U moderately\n                    if k > 0:\n                        A = rng.randn(self.dim, k)\n                        Q, _ = np.linalg.qr(A)\n                        U = Q[:, :k]\n                        s_sub = np.full(k, sigma / np.sqrt(max(1, k)))\n                    D_mem = []\n                    # add some local probes around best\n                    reseed = min(8, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None:\n                            break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # end generation (candidates)\n\n        # done budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm TASE scored 0.202 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "8e030180-85b3-49dd-8e92-727c3c1f6f8f", "operator": null, "metadata": {"aucs": [0.11636067120968319, 0.18486821191968483, 0.27224081465306993, 0.23029069588043682, 0.1945212569532715, 0.26200916444371014, 0.21026872909506422, 0.20747756898423642, 0.19191641912728763, 0.15099345891913718]}, "task_prompt": ""}
{"id": "345bd800-3e9b-45d2-b730-a4d72eceffa7", "fitness": 0.18995199479251784, "name": "TSAS", "description": "The algorithm is a hybrid Trend-and-Subspace Adaptive Search that mixes coordinated subspace Gaussian sampling (k ≈ dim/6) with per-dimension jitter, occasional coordinate tweaks, trend-line 1D exploitation from an EMA trend and a rewarded direction memory (D_mem), and rare heavy‑tail Cauchy escapes — these strategies are probabilistically chosen (prob_trend=0.22, prob_coord=0.06, prob_heavy=0.02) to balance exploration and exploitation. It maintains an archive (size ≈ max(6·dim,100)) for PCA/SVD-based subspace refreshes every dir_refresh generations and for robust baselines (median) used in reward computation, while subspace scales s_sub and per-dimension scales sigma_diag are adapted from observed projection energies and an EMA of absolute normalized step sizes (ema_alpha≈0.14). Global step-size sigma is updated multiplicatively with a win‑stay/lose‑shift rule driven by short-term success fraction, acceptance uses a Metropolis-like temperature that decays quadratically with budget, and the mean m is moved with strategy-dependent learning rates plus trust clipping. Additional robustness features include bounds clipping, occasional random subspace rotations, opportunistic reseeding on stagnation (jitter ∝ max(0.08·avg_span,1.4·sigma)), and conservative default parameter choices (pop=16, init_sigma_mult≈0.12) to work across Many BBOB scenarios.", "code": "import numpy as np\n\nclass TSAS:\n    \"\"\"\n    Trend-and-Subspace Adaptive Search (TSAS)\n\n    Main parameters (defaults chosen intentionally different from DSAT):\n    - pop: candidates per generation (default 16)\n    - k: exploration subspace dimension (default max(1, dim//6))\n    - archive_size: number of recent evals for PCA (default max(6*dim, 100))\n    - mem_size: directional memory size for trend (default max(8, k*8))\n    - init_sigma_mult: global sigma multiplier for average span (default 0.12)\n    - ema_alpha: exponential smoothing for trend / per-dim statistics (default 0.14)\n    - prob_trend: probability to try trend-line exploitation (default 0.22)\n    - prob_coord: probability of coordinate tweak (default 0.06)\n    - prob_heavy: probability of heavy-tail escape (default 0.02)\n    - dir_refresh: refresh PCA every dir_refresh generations (default 8)\n    - temp_init: initial uphill acceptance temperature multiplier (default 0.4)\n    - min_sigma / max_sigma: sigma clipping (defaults 1e-9, 10.0)\n    Notes: uses different equations for sigma_diag/adaptation than DSAT:\n      - per-dim adapt factor s_diag tracked as EMA of |step|/sigma\n      - sigma_diag = sigma * (1 + s_diag) / (1 + mean(s_diag))  (keeps column-scale relative)\n      - sigma updated multiplicatively using success-rate based exponentials (win-stay/lose-shift)\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=16, k=None, archive_size=None, mem_size=None,\n                 init_sigma_mult=0.12, ema_alpha=0.14,\n                 prob_trend=0.22, prob_coord=0.06, prob_heavy=0.02,\n                 dir_refresh=8, temp_init=0.4,\n                 min_sigma=1e-9, max_sigma=10.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.k = k if (k is not None) else max(1, self.dim // 6)\n        self.archive_size = archive_size if archive_size is not None else max(6 * self.dim, 100)\n        self.mem_size = mem_size if mem_size is not None else max(8, self.k * 8)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.ema_alpha = float(ema_alpha)\n        self.prob_trend = float(prob_trend)\n        self.prob_coord = float(prob_coord)\n        self.prob_heavy = float(prob_heavy)\n        self.dir_refresh = int(dir_refresh)\n        self.temp_init = float(temp_init)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds detection (Many BBOB typically -5..5)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial mean uniformly random\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # global sigma\n        sigma = max(self.min_sigma, self.init_sigma_mult * avg_span)\n\n        # per-dimension relative scale (starts uniform)\n        s_diag = np.ones(self.dim)  # relative per-dim multiplier (EMA tracked)\n        sigma_diag = np.clip(sigma * (1.0 + s_diag) / (1.0 + np.mean(s_diag)), self.min_sigma, self.max_sigma)\n\n        # exploration subspace (orthonormal)\n        k = min(self.k, self.dim)\n        if k > 0:\n            A = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :k].copy()\n            s_sub = np.full(k, sigma / np.sqrt(max(1, k)))\n        else:\n            B = np.zeros((self.dim, 0))\n            s_sub = np.array([])\n\n        # trend/exploitation memory: EMA trend vector + FIFO memory\n        trend = np.zeros(self.dim)\n        D_mem = []  # list of normalized steps with reward\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # safe evaluation respecting budget and bounds\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            if len(X_arch) > self.archive_size:\n                del X_arch[0]; del f_arch[0]\n            return fx\n\n        # seed initial budget fraction with random samples (small number but different than DSAT)\n        seed0 = min(self.pop * 3, max(8, int(self.budget // 250)))\n        for _ in range(seed0):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = safe_eval(x0)\n\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(10, int(0.03 * self.budget))\n\n        # statistics for sigma adaptation: track successes within sliding window\n        recent_successes = 0\n        recent_attempts = 0\n        # per-dim EMA of absolute normalized step sizes (for s_diag)\n        ema_abs = np.full(self.dim, 1e-6)\n\n        while evals < self.budget:\n            gen += 1\n\n            # Refresh PCA-like exploration basis using centered archive innovations (different blending)\n            if (gen % self.dir_refresh == 0) and len(X_arch) >= max(4, k):\n                K = min(len(X_arch), self.archive_size)\n                Xr = np.asarray(X_arch[-K:])\n                meanX = np.mean(Xr, axis=0)\n                S = (Xr - meanX)\n                try:\n                    U_s, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                    r_eff = min(k, Vt.shape[0])\n                    if r_eff > 0 and k > 0:\n                        B_new = Vt[:r_eff].T\n                        # stronger blending to emphasize new directions slightly more than DSAT\n                        gamma = 0.35\n                        B = (1.0 - gamma) * B[:, :r_eff] + gamma * B_new\n                        Q, _ = np.linalg.qr(B)\n                        B = Q[:, :r_eff]\n                        s_sub = 0.8 * s_sub[:r_eff] + 0.2 * (np.maximum(svals[:r_eff], 1e-8) / (np.sqrt(r_eff) + 1e-12))\n                except Exception:\n                    pass\n\n            # temperature schedule (quadratic decay)\n            temp = self.temp_init * sigma * avg_span * max(1e-12, (1.0 - (evals / max(1.0, self.budget)))**2)\n\n            # generate candidates this generation\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                strategy = 'explore_subspace'\n                x_cand = None\n                step = None\n                f_c = None\n\n                # rare heavy-tail escape (different scale / tilting)\n                if p < self.prob_heavy:\n                    strategy = 'heavy_tail'\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 85) + 1e-12)  # normalize using 85th percentile\n                    x_cand = m + sigma * 6.0 * z\n                    x_cand = np.minimum(np.maximum(x_cand, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n                    step = x_cand - m\n\n                # trend-based 1D exploitation line (uses EMA trend rather than DSAT memory weighting)\n                elif (p < self.prob_trend) and (len(D_mem) >= 3) and (evals + 2 <= self.budget):\n                    strategy = 'trend_line'\n                    # use EMA trend vector if available else aggregate recent memory\n                    if np.linalg.norm(trend) < 1e-12:\n                        Ds = np.array([d for (d, rw) in D_mem])\n                        RWs = np.array([rw for (d, rw) in D_mem])\n                        if Ds.size == 0:\n                            continue\n                        weights = (RWs - RWs.min()) + 1e-8\n                        wnorm = weights / (weights.sum() + 1e-12)\n                        ddir = np.tensordot(wnorm, Ds, axes=(0, 0))\n                    else:\n                        ddir = trend.copy()\n                    nd = np.linalg.norm(ddir) + 1e-12\n                    ddir = ddir / nd\n                    # trust radius based on interquartile of archive projections (different equation)\n                    if len(X_arch) >= 6:\n                        proj_vals = np.abs((np.asarray(X_arch) - np.mean(np.asarray(X_arch), axis=0)).dot(ddir))\n                        r = np.percentile(proj_vals, 75) + 0.5 * sigma\n                    else:\n                        r = 1.2 * sigma\n                    r *= (0.8 + 0.4 * rng.rand())\n\n                    # evaluate two points +/- r scaled\n                    x_minus = np.minimum(np.maximum(m - r * ddir, lb), ub)\n                    x_plus = np.minimum(np.maximum(m + r * ddir, lb), ub)\n                    f_minus = safe_eval(x_minus)\n                    if f_minus is None:\n                        break\n                    f_plus = safe_eval(x_plus)\n                    if f_plus is None:\n                        break\n                    # pick the better direction and try a midpoint biased toward improvement (different formula)\n                    if f_minus < f_plus:\n                        alpha = -0.55 * r\n                    else:\n                        alpha = 0.55 * r\n                    # refined candidate between center and best side\n                    x_ref = np.minimum(np.maximum(m + 0.6 * alpha * ddir, lb), ub)\n                    f_ref = safe_eval(x_ref)\n                    if f_ref is None:\n                        break\n                    # keep best among sampled points\n                    f_cand, x_cand = min((f_minus, x_minus), (f_plus, x_plus), (f_ref, x_ref), key=lambda t: t[0])\n                    f_c = f_cand\n                    step = x_cand - m\n\n                # coordinate tweak (cheap, different weighting)\n                elif p < (self.prob_trend + self.prob_coord) and (evals + 1 <= self.budget):\n                    strategy = 'coord'\n                    if len(X_arch) >= 6:\n                        Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                        var = np.var(Xr, axis=0)\n                        weights = var + 1e-8\n                    else:\n                        weights = s_diag + 1e-8\n                    weights = weights / (weights.sum() + 1e-12)\n                    j = int(rng.choice(self.dim, p=weights))\n                    step_dir = np.zeros(self.dim)\n                    step_scale = sigma_diag[j] * (0.6 + rng.rand() * 1.4)\n                    step_dir[j] = step_scale * (1.0 if rng.rand() < 0.5 else -1.0)\n                    x_try = np.minimum(np.maximum(m + step_dir, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try\n                    f_c = f_try\n                    step = x_cand - m\n\n                # default: coordinated subspace Gaussian + diag jitter\n                else:\n                    strategy = 'explore_subspace'\n                    if k > 0 and rng.rand() < 0.9:\n                        z = rng.randn(k)\n                        eps = rng.randn(self.dim)\n                        step = B.dot(z * s_sub) + 0.9 * (sigma_diag * eps)\n                        x_cand = m + step\n                    else:\n                        eps = rng.randn(self.dim)\n                        step = sigma_diag * eps\n                        x_cand = m + step\n                    x_cand = np.minimum(np.maximum(x_cand, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # Ensure evaluation done if not already\n                if f_c is None and evals < self.budget and x_cand is not None:\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n                    if step is None:\n                        step = x_cand - m\n\n                if f_c is None:\n                    break\n\n                # track attempts and successes for sigma rule\n                recent_attempts += 1\n\n                # improvement check\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c)\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                    recent_successes += 1\n                else:\n                    stagn += 1\n\n                # reward relative to median archive, use robust baseline\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                reward = raw_reward / (sigma * step_norm + 1e-12)\n\n                # update per-dim EMA stats (abs normalized step)\n                if step is not None:\n                    abs_norm = np.abs(step) / (sigma + 1e-12)\n                    ema_abs = (1.0 - self.ema_alpha) * ema_abs + self.ema_alpha * abs_norm\n                    # update s_diag from ema_abs (slightly different mapping)\n                    s_diag = np.clip((1.0 + ema_abs) , 1e-6, 1e6)\n                    sigma_diag = np.clip(sigma * (1.0 + s_diag) / (1.0 + np.mean(s_diag)), self.min_sigma, self.max_sigma)\n\n                # update subspace energies if step projected\n                if step is not None and k > 0:\n                    projs = B.T.dot(step)\n                    abs_projs = np.abs(projs)\n                    if abs_projs.size > 0:\n                        idx = int(np.argmax(abs_projs))\n                        s_sub = np.clip(0.92 * s_sub + 0.08 * (np.abs(projs) + 1e-8), self.min_sigma, self.max_sigma)\n\n                # update trend and D_mem on positive reward\n                if reward > 0 and np.linalg.norm(step) > 1e-12:\n                    dnorm = step / (np.linalg.norm(step) + 1e-12)\n                    # add to memory with reward; different scaling\n                    D_mem.append((dnorm * min(1.0, np.linalg.norm(step) / (sigma + 1e-12)), reward + 1e-12))\n                    if len(D_mem) > self.mem_size:\n                        D_mem.pop(0)\n                    # EMA trend update with stronger beta to adapt quickly\n                    beta_trend = min(0.5, 0.18 + 0.02 * (reward))\n                    trend = (1.0 - beta_trend) * trend + beta_trend * dnorm\n                    # normalize trend magnitude to moderate length\n                    if np.linalg.norm(trend) > 0:\n                        trend = trend / (np.linalg.norm(trend) + 1e-12) * (0.8 + 0.4 * np.tanh(np.linalg.norm(trend)))\n\n                # Acceptance: improved or Metropolis with temperature\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    deltaE = f_c - f_best\n                    if deltaE <= 0:\n                        accept = True\n                    else:\n                        if rng.rand() < np.exp(-deltaE / (temp + 1e-12)):\n                            accept = True\n\n                # If accepted, move mean with strategy-dependent LR\n                if accept:\n                    if strategy == 'trend_line':\n                        lr = 0.86\n                    elif strategy == 'coord':\n                        lr = 0.6\n                    elif strategy == 'heavy_tail':\n                        lr = 0.28\n                    elif strategy == 'explore_subspace':\n                        lr = 0.4\n                    else:\n                        lr = 0.35\n                    delta = (x_cand - m)\n                    # trust clipping scaled differently (less aggressive, based on RMS of sigma_diag)\n                    trust = 5.0 * sigma * np.sqrt(max(1, self.dim)) * (1.0 + 0.2 * (np.mean(s_diag)))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n\n                    # update sigma multiplicatively based on recent success rate (win-stay/lose-shift)\n                    # compute short-term success fraction\n                    if recent_attempts > 0:\n                        succ_frac = recent_successes / (recent_attempts + 1e-12)\n                        # shrink when many successes, expand otherwise\n                        sigma = np.clip(sigma * np.exp(-0.9 * (succ_frac - 0.15)), self.min_sigma, self.max_sigma)\n                    else:\n                        sigma = np.clip(sigma * 0.99, self.min_sigma, self.max_sigma)\n                    # gentle damping of ema_abs when success to allow smaller diag\n                    ema_abs *= 0.96\n                else:\n                    # rejection: small randomized drift and slight sigma inflation\n                    m = np.minimum(np.maximum(m + 0.008 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma = np.clip(sigma * 1.006, self.min_sigma, self.max_sigma)\n\n                # reset short-term counters periodically\n                if recent_attempts >= 40:\n                    recent_attempts = 0\n                    recent_successes = 0\n\n                # occasional small random rotation perturbation of subspace\n                if k > 0 and rng.rand() < 0.05:\n                    R = rng.randn(k, k) * 0.05\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(k) + R)\n                        B = B.dot(Qr)\n                        Q2, _ = np.linalg.qr(B)\n                        B = Q2[:, :k]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed on stagnation (different jitter policy)\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    jitter = max(0.08 * avg_span, 1.4 * sigma)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma = np.clip(sigma * 1.7, self.min_sigma, self.max_sigma)\n                    if k > 0:\n                        A = rng.randn(self.dim, k)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :k]\n                        s_sub = np.full(k, sigma / np.sqrt(max(1, k)))\n                    D_mem = []\n                    trend = np.zeros(self.dim)\n                    # probe a few points around best\n                    reseed = min(6, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None:\n                            break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # end generation\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm TSAS scored 0.190 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "8e030180-85b3-49dd-8e92-727c3c1f6f8f", "operator": null, "metadata": {"aucs": [0.11190638070794867, 0.1723324446248128, 0.25362541630957847, 0.2263090296014444, 0.1925651802859022, 0.19276024732802832, 0.2134816971059088, 0.20932178589862827, 0.18743255743318488, 0.13978520862974186]}, "task_prompt": ""}
{"id": "5421032d-8c51-4083-bc07-e18b3910a33a", "fitness": 0.1777757162374099, "name": "HLMSE", "description": "The algorithm is a hybrid low-rank + diagonal mutation strategy that maintains a population-independent mean m, a global step-size sigma, an orthonormal low-rank subspace U (rank k ≈ dim/6) with per-direction \"energies\" and subspace scales s_sub, plus per-coordinate RMS scales s_diag to capture residual variability. Proposals are a purposeful mixture (pop=16): mirrored antithetic low-rank+diag pairs (p≈0.36) for directional credit assignment and energy updates, a cheap subspace quadratic surrogate minimizer using a FIFO archive (p≈0.12), variance-weighted coordinate probes (p≈0.10), rare heavy-tailed Cauchy escapes (p≈0.03), and default low-rank Gaussian probes. Adaptation is multiplicative and smoothed: energies are exponentiated from mirrored rewards (energy_lr), s_diag is updated like an RMS trace (s_diag_lr), the global sigma is multiplicatively adapted toward a success target (p_succ, sigma_adapt_rate), and PCA on a buffer of normalized successful steps (period ≈ 11) refreshes U and s_sub. Mean updates are trust-clipped with occasional uphill (Metropolis-like) acceptance (uphill_temp_coeff, trust_mult), opportunistic restarts on stagnation (based on a stagnation fraction of the budget), and many practical safeguards (clipping, small regularizers, archive/buffer sizing ≈ O(dim)) to keep the method stable and robust across Many-Affine BBOB problems.", "code": "import numpy as np\n\nclass HLMSE:\n    \"\"\"\n    Hybrid Low-Rank Mirrored Surrogate Evolution (HLMSE)\n\n    Key features:\n    - Maintain mean m, global scale sigma and an orthonormal subspace U (rank k) + per-dim residual scales.\n    - Generate mixed proposals: mirrored antithetic pairs in low-rank+diag noise, low-rank Gaussian probes,\n      cheap subspace quadratic minimizers built from a recent FIFO archive, coordinate probes and rare Cauchy escapes.\n    - Update subspace periodically via PCA on a buffer of successful normalized steps, update per-direction energies\n      by exponentiated reward, and adapt sigma multiplicatively using a smoothed success-rate.\n    - Trust-clipped mean updates with occasional probabilistic uphill acceptance and opportunistic restarts.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # internal hyperparameters (conservative defaults tuned for Many Affine BBOB)\n        self.pop = 16\n        self.k = max(1, self.dim // 6)                # subspace rank\n        self.archive_size = max(6 * self.dim, 120)\n        self.buffer_size = max(8 * self.k, 40)        # buffer of successful normalized steps\n        self.pca_period = 11\n\n        # sigma adaptation\n        self.succ_target = 0.2\n        self.sigma_adapt_rate = 0.25\n        self.p_succ_beta = 0.85\n\n        # energies and learning\n        self.energy_lr = 0.22\n        self.s_diag_lr = 0.12\n\n        # trust & acceptance\n        self.trust_mult = 6.0\n        self.uphill_temp_coeff = 0.5\n\n        # other\n        self.mirrored_prob = 0.36\n        self.surrogate_prob = 0.12\n        self.coord_prob = 0.10\n        self.cauchy_prob = 0.03\n        self.min_sigma = 1e-10\n        self.max_sigma_mult = 3.0\n        self.restart_stagn_frac = 0.06\n        self.restart_inflate = 1.6\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds support scalar or per-dim\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize state\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(self.min_sigma, 0.18 * avg_span)\n\n        # low-rank orthonormal basis U and direction energies (multiplicative)\n        k = min(self.k, self.dim)\n        if k > 0:\n            A = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :k].copy()\n            energies = np.ones(k)\n            s_sub = np.full(k, sigma / max(1.0, np.sqrt(k)))\n        else:\n            U = np.zeros((self.dim, 0))\n            energies = np.array([])\n            s_sub = np.array([])\n\n        # per-dimension RMS-like adaptive scales for residual noise\n        v_rms = np.full(self.dim, 1e-6)\n        s_diag = np.full(self.dim, sigma)\n\n        # archives and buffers\n        X_arch = []\n        f_arch = []\n        success_buffer = []  # normalized successful steps for PCA\n        evals = 0\n\n        # bookkeeping best\n        f_best = np.inf\n        x_best = None\n\n        # smoothed success probability\n        p_succ = 0.2\n\n        # stagnation detection\n        stagn_limit = max(6, int(self.restart_stagn_frac * self.budget))\n        stagn_count = 0\n\n        # helper to safely evaluate and manage archive/budget\n        def safe_eval(x):\n            nonlocal evals, f_best, x_best, stagn_count\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x))\n            evals += 1\n            X_arch.append(x.copy())\n            f_arch.append(fx)\n            # keep FIFO\n            if len(X_arch) > self.archive_size:\n                del X_arch[0]; del f_arch[0]\n            # update best quickly\n            if fx < f_best:\n                f_best = fx\n                x_best = x.copy()\n                stagn_count = 0\n            else:\n                stagn_count += 1\n            return fx\n\n        # simple helper to fit a diagonal quadratic surrogate in subspace coordinates\n        def fit_subspace_quadratic(C, U_sub, Xs, fs):\n            # C: center, U_sub: dim x k, Xs: n x dim, fs: n\n            # model f ≈ c + g^T u + 0.5 * diag(h) * u^2, u = U^T (x - C)\n            if Xs.shape[0] < U_sub.shape[1] + 4:\n                return None, None\n            Utx = (Xs - C.reshape(1, -1)).dot(U_sub)  # n x k\n            n, kloc = Utx.shape\n            # design: [1, u1..uk, 0.5*u1^2..0.5*uk^2]\n            A = np.ones((n, 1 + kloc + kloc))\n            A[:, 1:1 + kloc] = Utx\n            A[:, 1 + kloc:] = 0.5 * (Utx ** 2)\n            try:\n                # ridge for stability\n                reg = 1e-8\n                theta, *_ = np.linalg.lstsq(A, fs, rcond=None)\n                c0 = float(theta[0])\n                g = theta[1:1 + kloc].astype(float)\n                hdiag = theta[1 + kloc:].astype(float)\n                # ensure reasonable curvature\n                hdiag = np.sign(hdiag) * np.maximum(np.abs(hdiag), 1e-6)\n                return g, hdiag\n            except Exception:\n                return None, None\n\n        gen = 0\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            # number of proposals this generation (cap by remaining)\n            n_cand = min(self.pop, remaining)\n\n            # for this generation, collect candidates & evaluations\n            gen_candidates = []\n            gen_values = []\n\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n                coin = rng.rand()\n\n                # 1) mirrored antithetic low-rank pairs (consume two evals if possible)\n                if coin < self.mirrored_prob and evals + 1 < self.budget:\n                    # build step: low-rank + diag noise\n                    if k > 0:\n                        z = rng.randn(k) * np.sqrt(np.maximum(energies, 1e-12))\n                        low = U.dot(z * s_sub)\n                    else:\n                        low = np.zeros(self.dim)\n                    eps = rng.randn(self.dim) * s_diag\n                    step = sigma * (low + 0.7 * eps)\n                    x_plus = m + step\n                    x_minus = m - step\n                    f_plus = safe_eval(x_plus)\n                    f_minus = safe_eval(x_minus)\n                    if f_plus is None or f_minus is None:\n                        # In case budget exhausted mid-pair, stop\n                        break\n                    gen_candidates.append(x_plus.copy()); gen_values.append(f_plus)\n                    gen_candidates.append(x_minus.copy()); gen_values.append(f_minus)\n\n                    # attribute rewards to directions\n                    if k > 0:\n                        # reward positive directional difference towards the better side\n                        diff = f_minus - f_plus\n                        if diff > 0:\n                            proj = U.T.dot(step / (np.linalg.norm(step) + 1e-12))\n                            contrib = np.abs(proj)\n                            if contrib.sum() > 0:\n                                # multiplicative update\n                                energies *= np.exp(self.energy_lr * (diff / (abs(diff) + 1e-12)) * (contrib / (contrib.sum())))\n                        else:\n                            # if other side better, reward opposite\n                            proj = U.T.dot(-step / (np.linalg.norm(step) + 1e-12))\n                            contrib = np.abs(proj)\n                            if contrib.sum() > 0:\n                                energies *= np.exp(self.energy_lr * ((-diff) / (abs(diff) + 1e-12)) * (contrib / (contrib.sum())))\n\n                    # record successful steps into buffer if improvement or directional signal\n                    if f_plus <= f_best + 1e-12 or f_minus <= f_best + 1e-12 or (f_minus - f_plus) != 0:\n                        norm_step = (step / (sigma + 1e-12))\n                        success_buffer.append(norm_step.copy())\n                        if len(success_buffer) > self.buffer_size:\n                            del success_buffer[0]\n\n                    # continue to next candidate slot (we already consumed 2 evals)\n                    continue\n\n                # 2) subspace surrogate minimizer\n                if coin < self.mirrored_prob + self.surrogate_prob and k > 0 and len(X_arch) >= max(8, k + 4):\n                    # center on recent best cluster\n                    K = min(len(X_arch), self.archive_size)\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    topk = max(4, int(0.12 * K))\n                    ids = np.argsort(fr)[:topk]\n                    C = np.mean(Xr[ids], axis=0)\n                    g_sub, hdiag = fit_subspace_quadratic(C, U, Xr, fr)\n                    if g_sub is not None:\n                        # solve diag Hessian in subspace: u* = -g / hdiag\n                        u_star = - g_sub / (hdiag + 1e-12)\n                        # limit step in subspace\n                        max_sub = 6.0 * sigma\n                        if np.linalg.norm(u_star) > max_sub:\n                            u_star = u_star * (max_sub / (np.linalg.norm(u_star) + 1e-12))\n                        x_star = C + U.dot(u_star)\n                        f_star = safe_eval(x_star)\n                        if f_star is None:\n                            break\n                        gen_candidates.append(x_star.copy()); gen_values.append(f_star)\n                        # attribute energy reward to most contributing direction\n                        if k > 0:\n                            absproj = np.abs(u_star)\n                            if absproj.sum() > 0:\n                                energies *= np.exp(self.energy_lr * (np.maximum(0.0, np.min(fr) - f_star + 1e-12) / (sigma + 1e-12)) * (absproj / (absproj.sum())))\n                                energies = np.clip(energies, 1e-8, 1e8)\n                        # record buffer\n                        if f_star <= f_best + 1e-12:\n                            norm_step = (x_star - m) / (sigma + 1e-12)\n                            success_buffer.append(norm_step.copy())\n                            if len(success_buffer) > self.buffer_size:\n                                del success_buffer[0]\n                        continue\n\n                # 3) coordinate probe\n                if coin < self.mirrored_prob + self.surrogate_prob + self.coord_prob:\n                    # choose coordinate by variance in archive or uniformly\n                    if len(X_arch) >= 4:\n                        Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                        var = np.var(Xr, axis=0) + 1e-12\n                        probs = var / var.sum()\n                    else:\n                        probs = np.ones(self.dim) / self.dim\n                    j = int(rng.choice(self.dim, p=probs))\n                    step = np.zeros(self.dim)\n                    step[j] = (0.8 + rng.rand() * 1.6) * s_diag[j]\n                    x_try = m + step\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    gen_candidates.append(x_try.copy()); gen_values.append(f_try)\n                    # record if helpful\n                    if f_try <= f_best + 1e-12:\n                        norm_step = (x_try - m) / (sigma + 1e-12)\n                        success_buffer.append(norm_step.copy())\n                        if len(success_buffer) > self.buffer_size:\n                            del success_buffer[0]\n                    continue\n\n                # 4) Cauchy (heavy-tailed) rare escape\n                if coin < self.mirrored_prob + self.surrogate_prob + self.coord_prob + self.cauchy_prob:\n                    z = rng.standard_cauchy(size=self.dim)\n                    # robust scaling\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    x_try = m + sigma * 4.0 * z\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    gen_candidates.append(x_try.copy()); gen_values.append(f_try)\n                    if f_try <= f_best + 1e-12:\n                        norm_step = (x_try - m) / (sigma + 1e-12)\n                        success_buffer.append(norm_step.copy())\n                        if len(success_buffer) > self.buffer_size:\n                            del success_buffer[0]\n                    continue\n\n                # 5) default low-rank Gaussian probe\n                # sample subspace coefficients weighted by energies\n                if k > 0:\n                    # sample gaussian scaled by energies\n                    z = rng.randn(k) * np.sqrt(np.maximum(energies, 1e-12))\n                    low = U.dot(z * s_sub)\n                else:\n                    low = np.zeros(self.dim)\n                eps = rng.randn(self.dim) * s_diag\n                step = sigma * (low + 0.7 * eps)\n                x_try = m + step\n                f_try = safe_eval(x_try)\n                if f_try is None:\n                    break\n                gen_candidates.append(x_try.copy()); gen_values.append(f_try)\n                # if improved, record\n                if f_try <= f_best + 1e-12:\n                    norm_step = (step / (sigma + 1e-12))\n                    success_buffer.append(norm_step.copy())\n                    if len(success_buffer) > self.buffer_size:\n                        del success_buffer[0]\n\n            # End generation candidate creation / evaluations for this loop\n\n            if len(gen_values) == 0:\n                break\n\n            # selection: pick best candidate(s) from this generation and decide mean update\n            gen_values_arr = np.array(gen_values)\n            gen_candidates_arr = np.array(gen_candidates)\n            # softmax weights favor better candidates (lower objective)\n            fmin_local = np.min(gen_values_arr)\n            fstd = float(np.std(gen_values_arr) + 1e-12)\n            scores = np.exp(-(gen_values_arr - fmin_local) / (1e-2 + fstd))\n            probs = scores / (np.sum(scores) + 1e-12)\n            chosen_idx = int(rng.choice(len(gen_candidates_arr), p=probs))\n            chosen_x = gen_candidates_arr[chosen_idx].copy()\n            chosen_f = float(gen_values_arr[chosen_idx])\n\n            # uphill acceptance probabilistic (Metropolis-like)\n            T = max(1e-12, self.uphill_temp_coeff * sigma * avg_span)\n            accept = False\n            # If chosen improves global best (we updated f_best in safe_eval), prefer strong move\n            if chosen_f <= f_best + 1e-12:\n                accept = True\n            else:\n                # acceptance relative to local best\n                delta = chosen_f - fmin_local\n                if rng.rand() < np.exp(-delta / (T + 1e-12)):\n                    accept = True\n\n            # Move mean towards chosen_x if accepted (trust clipping)\n            if accept:\n                delta = chosen_x - m\n                trust = max(1e-12, self.trust_mult * sigma * np.sqrt(max(1, self.dim)))\n                dn = np.linalg.norm(delta)\n                if dn > trust:\n                    delta = delta * (trust / (dn + 1e-12))\n                # learning rate depends on whether candidate improved global best\n                eta = 0.36 if chosen_f <= f_best + 1e-12 else 0.22\n                m = np.minimum(np.maximum(m + eta * delta, lb), ub)\n                # shrink sigma a bit on success (local refinement), else small bounce handled below\n                if chosen_f <= f_best + 1e-12:\n                    sigma = max(self.min_sigma, sigma * 0.90)\n                else:\n                    sigma = min(self.max_sigma_mult * np.max(span), sigma * 1.02)\n            else:\n                # rejection: small drift and slight sigma inflation to encourage exploration\n                m = np.minimum(np.maximum(m + 0.01 * avg_span * rng.randn(self.dim), lb), ub)\n                sigma = min(self.max_sigma_mult * np.max(span), sigma * 1.01)\n\n            # update per-dim RMS and s_diag using collected evaluated steps in this generation\n            # compute steps relative to m for all evaluated gen candidates\n            steps = (gen_candidates_arr - m.reshape(1, -1))\n            if steps.size > 0:\n                sq = (steps / (sigma + 1e-12)) ** 2\n                mean_sq = np.mean(sq, axis=0)\n                v_rms = (1.0 - self.s_diag_lr) * v_rms + self.s_diag_lr * mean_sq\n                s_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-8), 1e-12, np.max(span) * 2.0)\n\n            # update direction energies softly (normalization)\n            energies = np.clip(energies, 1e-8, 1e8)\n\n            # update smoothed success probability p_succ using whether any gen candidate improved global best\n            gen_improved = float(np.any(np.array(gen_values) <= (f_best + 1e-12)))\n            p_succ = self.p_succ_beta * p_succ + (1.0 - self.p_succ_beta) * gen_improved\n            # multiplicative sigma adaptation\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, self.min_sigma, self.max_sigma_mult * np.max(span))\n\n            # periodic PCA refresh of U from success_buffer\n            if (gen % self.pca_period == 0) and len(success_buffer) >= max(3, k):\n                B = np.asarray(success_buffer)\n                Bc = B - np.mean(B, axis=0, keepdims=True)\n                try:\n                    U_s, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    r_eff = min(k, Vt.shape[0])\n                    if r_eff > 0:\n                        U_new = Vt[:r_eff].T\n                        # blend to avoid abrupt basis flips\n                        U = 0.85 * U + 0.15 * U_new\n                        # re-orthonormalize\n                        Q, _ = np.linalg.qr(U)\n                        U = Q[:, :r_eff]\n                        # update subspace scales and gently nudge energies by singular values\n                        s_sub = 0.9 * s_sub[:r_eff] + 0.1 * (np.maximum(S_s[:r_eff], 1e-8) / (np.sqrt(max(1, r_eff))))\n                        if energies.size == r_eff:\n                            energies = 0.9 * energies + 0.1 * (S_s[:r_eff] + 1e-8)\n                        else:\n                            energies = np.ones(r_eff)\n                except Exception:\n                    # ignore PCA failures\n                    pass\n\n            # opportunistic restart on prolonged stagnation\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # restart around the best with jitter and reinitialize some stats\n                if x_best is not None:\n                    jitter_scale = max(0.05 * avg_span, 0.8 * sigma)\n                    m = np.minimum(np.maximum(x_best + rng.randn(self.dim) * jitter_scale, lb), ub)\n                else:\n                    m = rng.uniform(lb, ub, size=self.dim)\n                sigma = max(sigma * self.restart_inflate, 0.22 * avg_span)\n                # reinitialize subspace modestly\n                if k > 0:\n                    A = rng.randn(self.dim, k)\n                    Q, _ = np.linalg.qr(A)\n                    U = Q[:, :k]\n                    energies = np.ones(k)\n                    s_sub = np.full(k, sigma / max(1.0, np.sqrt(k)))\n                v_rms = np.full(self.dim, 1e-6)\n                s_diag = np.full(self.dim, sigma)\n                success_buffer = []\n                # do a few local reseed evals near best\n                for _ in range(min(6, self.budget - evals)):\n                    x = np.minimum(np.maximum((x_best if x_best is not None else rng.uniform(lb, ub, size=self.dim)) + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                    fx = safe_eval(x)\n                    if fx is None:\n                        break\n\n        # finalize best (already tracked)\n        if x_best is None:\n            # no evaluations performed (unlikely) — sample one\n            x0 = np.minimum(np.maximum(m, lb), ub)\n            fx0 = float(func(x0))\n            f_best, x_best = fx0, x0\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HLMSE scored 0.178 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "8e030180-85b3-49dd-8e92-727c3c1f6f8f", "operator": null, "metadata": {"aucs": [0.09801181097982725, 0.16734284383353293, 0.23586139050529176, 0.16962083688551477, 0.16666194519535016, 0.20711522747552868, 0.22132411855640677, 0.18456077727315323, 0.19287850368580406, 0.13437970798368948]}, "task_prompt": ""}
{"id": "4fca1f01-59ec-4918-baa1-f6ab9f019a1f", "fitness": 0.4002302678900094, "name": "MAPLES", "description": "MAPLES is essentially a mirrored (antithetic) evolution strategy that uses paired sampling for sample-efficiency and stable covariance estimation, combining a rank-1 evolution path (p) and rank-mu covariance update with weighted recombination (mu_eff) to adapt the search distribution. Step-size is adapted via a normalized RMS spread (alpha_sigma and diversity_target) with conservative initialization and clipping, while population size and weights are chosen by simple dimension-aware heuristics to balance exploration and budget. A small elite archive is maintained for restart seeding, archive-guided heavy-tailed (Cauchy-like) global jumps and diversity checks, and jittered restarts when stagnation is detected (stagn_count/stagn_limit) to escape basins. Local exploitation is provided by a bounded Hooke–Jeeves–style pattern search triggered on promising candidates or stagnation, and numeric safety (Cholesky/eigendecomposition SPD fixes), strict budget accounting, and per-eval recording ensure robustness.", "code": "import numpy as np\n\nclass MAPLES:\n    \"\"\"\n    Mirrored Adaptive Pattern-Levy Evolution Strategy (MAPLES)\n\n    Key ideas:\n    - Mirrored pair sampling (antithetic) for sample-efficiency and stable covariance learning.\n    - Rank-1 (evolution path) + rank-mu covariance updates and sigma adaptation by normalized spread.\n    - Small elite archive maintained for restarts, local refinement seeds and diversity checks.\n    - Archive-guided heavy-tailed (Cauchy-like) jumps and jittered restarts to escape basins.\n    - Cheap Hooke-Jeeves style coordinate local search triggered on promising candidates or stagnation.\n    - Strict budget accounting: func() is never called beyond self.budget.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop_base=None,\n                 c1=0.12, cmu=0.06, alpha_sigma=0.7, diversity_target=0.30,\n                 archive_size=None,\n                 global_jump_prob=0.18,\n                 local_budget_frac=0.03):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.pop_base = pop_base\n        self.c1 = float(c1)\n        self.cmu = float(cmu)\n        self.alpha_sigma = float(alpha_sigma)\n        self.diversity_target = float(diversity_target)\n        self.archive_size = archive_size if archive_size is not None else max(6, int(0.6 * (max(12, int(6 + 2 * np.sqrt(dim))))))\n        self.global_jump_prob = float(global_jump_prob)\n        self.local_budget_frac = float(local_budget_frac)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # parse bounds (Many Affine BBOB uses -5,5 but support func.bounds)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        bounds_scale = ub - lb\n        avg_span = float(np.mean(bounds_scale))\n\n        # population size (mirrored ES prefers even-ish lam)\n        if self.pop_base is None:\n            lam = max(12, int(6 + 2 * np.sqrt(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # evaluation bookkeeping and best tracking\n        evals = 0\n        f_best = np.inf\n        x_best = None\n\n        # elite archive: list of (f, x), sorted ascending\n        archive = []\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            # clip to bounds\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = func(x)\n            evals += 1\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # archive insertion\n            if len(archive) < self.archive_size or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > self.archive_size:\n                    archive.pop()\n            return float(f), x\n\n        # initialize mean m using a few random points (use some budget)\n        init_points = min(max(4, lam // 2), max(1, self.budget // 20))\n        X0 = []\n        for _ in range(init_points):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            res = eval_and_record(x0)\n            if res is not None:\n                X0.append(res[1])\n        if x_best is None:\n            # fallback single sample\n            res = eval_and_record(rng.uniform(lb, ub))\n            if res is None:\n                # budget exhausted immediately\n                self.f_opt = float(f_best)\n                self.x_opt = np.zeros(self.dim, dtype=float)\n                return self.f_opt, self.x_opt\n\n        # initialize m to best-so-far or mean of initial points\n        if len(X0) > 0:\n            m = np.mean(np.vstack(X0), axis=0)\n        else:\n            m = x_best.copy()\n\n        # initialize covariance and sigma\n        init_scale = (bounds_scale / 6.0)\n        C = np.diag((init_scale ** 2).clip(min=1e-12))\n        sigma = 0.15 * np.mean(bounds_scale)  # conservative start\n\n        # strategy state\n        p = np.zeros(self.dim, dtype=float)\n        stagn_count = 0\n        stagn_limit = max(8, int(0.02 * self.budget))\n        gen = 0\n\n        # Helper: build SPD factor A via Cholesky or eigen fallback\n        def build_A(Cmat):\n            eps = 1e-12 * np.maximum(np.diag(Cmat), 1.0)\n            try:\n                A = np.linalg.cholesky(Cmat + np.diag(eps))\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(Cmat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n            return A\n\n        # Hooke-Jeeves-like local search (bounded small budget)\n        def local_pattern_search(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            step0 = 0.25 * avg_span\n            steps = np.full(self.dim, step0, dtype=float)\n            shrink = 0.5\n            pattern_factor = 1.4\n            local_used = 0\n            # limit iterations\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_used < local_budget and iters < iter_limit and np.any(steps > 1e-10) and evals < self.budget:\n                iters += 1\n                improved = False\n                probe = base.copy()\n                probe_f = base_f\n                for i in range(self.dim):\n                    if local_used >= local_budget or evals >= self.budget:\n                        break\n                    # try plus\n                    xp = probe.copy()\n                    xp[i] += steps[i]\n                    res = eval_and_record(xp)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < probe_f:\n                        probe = xp.copy()\n                        probe_f = fp\n                        improved = True\n                        continue\n                    # try minus\n                    xn = probe.copy()\n                    xn[i] -= steps[i]\n                    res = eval_and_record(xn)\n                    local_used += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < probe_f:\n                        probe = xn.copy()\n                        probe_f = fn\n                        improved = True\n                # pattern move\n                if improved and local_used < local_budget and evals < self.budget:\n                    direction = probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + pattern_factor * direction\n                        res = eval_and_record(xp)\n                        local_used += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < probe_f:\n                                base = xp.copy(); base_f = fp\n                            else:\n                                base = probe.copy(); base_f = probe_f\n                        else:\n                            base = probe.copy(); base_f = probe_f\n                    else:\n                        base = probe.copy(); base_f = probe_f\n                else:\n                    steps *= shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # main generation loop\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            if lam_iter <= 0:\n                break\n            mu_iter = max(1, lam_iter // 2)\n            weights = np.linspace(mu_iter, 1, mu_iter)\n            weights = np.maximum(weights, 1e-12)\n            weights = weights / np.sum(weights)\n\n            # build factor A\n            A = build_A(C)\n\n            # mirrored sampling (use pairs +/-)\n            half = lam_iter // 2\n            odd = (lam_iter % 2) != 0\n            Xcand = []\n            Ylist = []\n            for _ in range(half):\n                z = rng.randn(self.dim)\n                y = A.T.dot(z)\n                Xcand.append(m + sigma * y)\n                Xcand.append(m - sigma * y)\n                Ylist.append(y); Ylist.append(-y)\n            if odd:\n                z = rng.randn(self.dim)\n                y = A.T.dot(z)\n                Xcand.append(m + sigma * y)\n                Ylist.append(y)\n            # evaluate candidates one by one with eval_and_record\n            fc = []\n            Xeval = []\n            Yeval = []\n            for i in range(len(Xcand)):\n                if evals >= self.budget:\n                    break\n                res = eval_and_record(Xcand[i])\n                if res is None:\n                    break\n                fi, xi = res\n                fc.append(fi)\n                Xeval.append(xi.copy())\n                Yeval.append(Ylist[i])\n            if len(fc) == 0:\n                break\n\n            # generation best and bookkeeping\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xeval[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                f_best = gen_best_f\n                x_best = gen_best_x.copy()\n                improved = True\n                stagn_count = 0\n            else:\n                stagn_count += 1\n\n            # form elites for recombination\n            order = np.argsort(fc)\n            X_mu = np.vstack([Xeval[i] for i in order[:mu_iter]])\n            Y_mu = np.vstack([Yeval[i] for i in order[:mu_iter]])\n            # weighted new mean\n            m_new = np.sum((weights.reshape(-1,1) * X_mu), axis=0)\n            # compute normalized y_steps relative to old m\n            y_steps = (X_mu - m) / (sigma + 1e-20)\n            # effective mu\n            mu_eff = (np.sum(weights))**2 / np.sum(weights**2)\n            # evolution path update (with dimension-aware factor)\n            c_p = 2.0 / (self.dim + 2.0)\n            y_w = np.sum(weights.reshape(-1,1) * y_steps, axis=0)\n            p = (1.0 - c_p) * p + np.sqrt(c_p * (2.0 - c_p) * mu_eff) * y_w\n\n            # rank-mu covariance\n            W = weights.reshape(-1,1)\n            cov_mu = (W * y_steps).T @ y_steps\n\n            coef_fix = max(0.0, 1.0 - self.c1 - self.cmu)\n            C = coef_fix * C + self.c1 * np.outer(p, p) + self.cmu * cov_mu\n\n            # update mean\n            m = m_new\n\n            # sigma adaptation by normalized RMS spread\n            y_all = (np.vstack(Xeval) - m) / (sigma + 1e-20)\n            norm_rms = np.sqrt(np.mean(np.sum(y_all**2, axis=1)) / max(1.0, float(self.dim)))\n            sigma *= np.exp(self.alpha_sigma * (self.diversity_target - norm_rms))\n            # clip sigma to reasonable interval\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n            # archive update already done by eval_and_record\n\n            # occasional archive-guided heavy-tailed global jump (if archive non-empty)\n            # increase chance when stagnating\n            adj_jump_prob = min(0.6, self.global_jump_prob + 0.02 * max(0, stagn_count // 3))\n            if rng.rand() < adj_jump_prob and len(archive) > 0 and evals < self.budget:\n                # choose center from archive (best or random elite)\n                if rng.rand() < 0.75:\n                    center = archive[0][1]\n                else:\n                    center = archive[rng.randint(0, len(archive))]\n                    if isinstance(center, tuple):\n                        center = center[1]\n                # Cauchy-like step (direction random scaled by avg_span)\n                direction = rng.randn(self.dim)\n                direction /= (np.linalg.norm(direction) + 1e-12)\n                step_length = rng.standard_cauchy()\n                step_length = float(np.clip(step_length, -1e3, 1e3))\n                # per-dim anisotropy using bounds\n                anis = 0.5 + 0.5 * rng.rand(self.dim)\n                jump = direction * (0.8 * avg_span * anis)\n                cand = center + step_length * jump\n                res = eval_and_record(cand)\n                if res is not None:\n                    f_cand, x_cand = res\n                    # if promising, run a small local pattern search around it\n                    if f_cand < (archive[0][0] if len(archive) else np.inf) * 1.05 and evals < self.budget:\n                        local_budget = min(int(self.local_budget_frac * self.budget), self.budget - evals)\n                        local_budget = max(1, local_budget)\n                        f_after, x_after = local_pattern_search(x_cand, f_cand, local_budget)\n                        # accept local improvements via eval_and_record already handled\n\n            # If stagnating strongly, trigger a cheap local refinement around best\n            if (stagn_count >= max(3, stagn_limit // 4)) and evals < self.budget:\n                local_budget = min(int(self.local_budget_frac * self.budget), self.budget - evals)\n                local_budget = max(1, local_budget)\n                if x_best is not None:\n                    f_after, x_after = local_pattern_search(x_best, f_best, local_budget)\n                    # update best if local found improvements (eval_and_record did that)\n\n            # opportunistic jittered restart if stagnation exceeded\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # inflate sigma and re-center around best with jitter\n                sigma = min(1.0 * np.max(bounds_scale), sigma * 3.0)\n                if x_best is not None:\n                    jitter = sigma * (0.2 + 0.6 * rng.rand(self.dim))\n                    m = np.minimum(np.maximum(x_best + rng.randn(self.dim) * jitter, lb), ub)\n                # shrink covariance to encourage exploration\n                C = np.diag(((bounds_scale / 8.0) ** 2).clip(min=1e-12))\n                p = np.zeros_like(p)\n                # small uniform injections into archive to diversify\n                if evals < self.budget:\n                    res = eval_and_record(rng.uniform(lb, ub))\n                    # continue main loop\n\n            # archive diversity check: if too clustered, nudge sigma/jump prob\n            if len(archive) >= 2:\n                spread = np.linalg.norm(archive[0][1] - archive[-1][1])\n                if spread < 1e-9 + 0.01 * avg_span:\n                    # encourage more global moves by increasing sigma a bit\n                    sigma = min(2.0 * np.max(bounds_scale), sigma * 1.15)\n                    self.global_jump_prob = min(0.6, self.global_jump_prob * 1.05)\n                else:\n                    # gently decay jump probability\n                    self.global_jump_prob = max(0.03, self.global_jump_prob * 0.995)\n\n            # safety SPD corrections\n            if np.any(np.isnan(C)) or np.any(np.isinf(C)):\n                C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n            try:\n                _ = np.linalg.cholesky(C + np.eye(self.dim) * 1e-16)\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                C = (vecs * vals) @ vecs.T\n\n        # finalize best\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MAPLES scored 0.400 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "8e030180-85b3-49dd-8e92-727c3c1f6f8f", "operator": null, "metadata": {"aucs": [0.11064866973485143, 0.1574854061465265, 0.37146775041652347, 0.985815547705236, 0.3559890239026856, 0.9895954579550418, 0.21218636196069374, 0.4685804575877971, 0.21985793970714995, 0.1306760637835882]}, "task_prompt": ""}
{"id": "ba26f129-6da8-46bd-88ce-1bbc98bfec1b", "fitness": 0.26818748466493114, "name": "AOES", "description": "AOES keeps an archive and elite set plus an incremental low‑rank PCA basis (default rank ≈ dim/8) to represent a learned manifold around a search mean m, with per‑component scales and curvature estimates.  \nEach generation it samples a heterogeneous ensemble of proposals — Elite‑Mahalanobis anisotropic draws (using a robust sqrt covariance), a PCA‑surrogate quadratic minimizer in subspace, directional 1‑D line probes with parabolic interpolation, simplex‑style reflection/expansion moves, RMS‑adapted anisotropic jitter, and occasional heavy‑tailed (Cauchy/Levy) escapes — chosen by tuned probabilities (e.g. prob_maha=0.22, prob_pca_sur=0.18, prob_line=0.18, prob_reflect=0.12, prob_levy=0.03).  \nAdaptation is driven by per‑dimension RMS (rms_beta=0.92) for step scaling, an EMA momentum for acceleration, curvature‑aware clipping of PCA steps, a direction taboo list to penalize repeated failed directions, and periodic soft PCA refresh via SVD of recent archive.  \nA safe_eval enforces bounds and the evaluation budget, acceptance always takes improvements and occasionally uphill moves via a small decaying temperature, sigma is shrunk on consistent improvements and expanded on uphill/rejects, and a stagnation‑triggered reseed/refinement around the best point avoids long plateaus.", "code": "import numpy as np\n\nclass AOES:\n    \"\"\"\n    Adaptive Orthonormal Ensemble Search (AOES)\n\n    Main ideas / novel pieces:\n    - Maintain an elite set and an incremental PCA basis (low-rank manifold).\n    - Generate candidates from a diverse ensemble:\n        * Elite-Mahalanobis sampling (anisotropic proposals shaped by elite covariance)\n        * PCA-surrogate minimizer (ridge-fit quadratic in the PCA subspace)\n        * Directional line probes (cheap 1D bracketing + parabolic interpolation) along recent promising directions\n        * Simple reflection/expansion moves inspired by simplex ideas\n        * Default anisotropic jitter with per-dimension RMS adaptation\n        * Occasional large Cauchy/Levy escapes\n    - Direction taboo list: penalize repeated failed directions; promote orthogonal exploration.\n    - Curvature-aware per-subspace step scales derived from surrogate curvature estimate.\n    - Strict safe_eval wrapper to never exceed self.budget evaluations.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=12, rank=None, elite_frac=0.12, init_sigma_mult=0.18,\n                 rms_beta=0.92, pca_refresh=12, prob_maha=0.22,\n                 prob_pca_sur=0.18, prob_line=0.18, prob_reflect=0.12,\n                 prob_levy=0.03, min_sigma=1e-8, max_sigma=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.rank = rank if rank is not None else max(1, self.dim // 8)\n        self.elite_frac = float(elite_frac)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.rms_beta = float(rms_beta)\n        self.pca_refresh = int(pca_refresh)\n        # strategy probabilities; leftover is default jitter\n        self.prob_maha = float(prob_maha)\n        self.prob_pca_sur = float(prob_pca_sur)\n        self.prob_line = float(prob_line)\n        self.prob_reflect = float(prob_reflect)\n        self.prob_levy = float(prob_levy)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling (default many BBOB -5..5)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial center (mean of search) and scales\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        sigma_diag = np.full(self.dim, sigma)\n        v_rms = np.full(self.dim, 1e-6)   # for per-dim adaptation\n        momentum = np.zeros(self.dim)\n\n        # PCA manifold basis\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()\n            sub_scale = np.full(r, sigma / np.sqrt(max(1, r)))\n            curvature = np.full(r, 1.0)  # surrogate curvature estimate per component\n        else:\n            B = np.zeros((self.dim, 0))\n            sub_scale = np.array([])\n            curvature = np.array([])\n\n        # archive & elite set\n        X_arch = []\n        f_arch = []\n        eliteK = max(3, int(np.ceil(self.elite_frac * max(50, self.budget / 10))))\n        evals = 0\n\n        # direction taboo list: store recent failed normalized directions to discourage repeats\n        taboo_dirs = []\n\n        # safe evaluation wrapper\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            if len(X_arch) > max(3 * self.archive_size if hasattr(self, 'archive_size') else 10 * self.dim, 10 * self.dim):\n                # keep archives bounded (choose a pragmatic cap)\n                X_arch.pop(0); f_arch.pop(0)\n            return fx\n\n        # Provide a default archive_size property for internal management (not user-facing)\n        self.archive_size = max(10 * self.dim, 120)\n\n        # seed initial archive with some random samples\n        seed0 = min(self.pop * 4, max(20, int(self.budget // 200)))\n        for _ in range(seed0):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        # ensure at least one eval\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        # initialize best\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(12, int(0.05 * self.budget))\n\n        # helper: refresh PCA basis via SVD of recent archive (blend softly)\n        def refresh_pca():\n            nonlocal B, sub_scale, curvature, r\n            if r == 0 or len(X_arch) < (4 + r):\n                return\n            K = min(len(X_arch), self.archive_size)\n            Xr = np.asarray(X_arch[-K:])\n            meanX = Xr.mean(axis=0)\n            S = (Xr - meanX)\n            try:\n                U, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(r, Vt.shape[0])\n                if r_eff <= 0:\n                    return\n                B_new = Vt[:r_eff].T\n                alpha = 0.18\n                if B.shape[1] == r_eff:\n                    B = (1 - alpha) * B + alpha * B_new\n                else:\n                    B = B_new.copy()\n                Q, _ = np.linalg.qr(B)\n                B = Q[:, :r_eff]\n                # adapt subspace scales from singular values (normalize by sqrt(n_samples))\n                n = max(1, Xr.shape[0])\n                s_est = svals[:r_eff] / np.sqrt(n)\n                # update sub_scale softly and curvature (inverse of svals relates to curvature)\n                sub_scale = 0.9 * sub_scale[:r_eff] + 0.1 * (s_est + 1e-12)\n                curvature = 0.9 * curvature[:r_eff] + 0.1 * (1.0 / (svals[:r_eff] + 1e-8))\n            except Exception:\n                pass\n\n        # helper: compute elite set (sorted)\n        def get_elites():\n            if len(X_arch) == 0:\n                return [], []\n            idxs = np.argsort(f_arch)[:min(eliteK, len(f_arch))]\n            Xe = [X_arch[i].copy() for i in idxs]\n            Fe = [f_arch[i] for i in idxs]\n            return np.asarray(Xe), np.asarray(Fe)\n\n        # helper: compute robust sqrt covariance (for Mahalanobis proposals)\n        def sqrt_cov_from(Xe):\n            # Xe: (k, dim)\n            k = Xe.shape[0]\n            if k <= 1:\n                return np.eye(self.dim)\n            C = np.cov(Xe.T) + 1e-8 * np.eye(self.dim)\n            try:\n                # use eigen decomposition for sqrt symmetric PSD\n                w, V = np.linalg.eigh(C)\n                w = np.maximum(w, 1e-12)\n                S = V.dot(np.diag(np.sqrt(w))).dot(V.T)\n                return S\n            except Exception:\n                # fallback to cholesky-like via svd\n                U, s, Vt = np.linalg.svd(C)\n                return U.dot(np.diag(np.sqrt(s))).dot(Vt)\n\n        # helper: small directional line probe (1D bracketing + parabolic interpolation) uses up to 3 evals\n        def line_probe(base, direction, max_scale=2.0):\n            # direction assumed normalized\n            nonlocal evals\n            # compute three points: -a, 0, +b along direction\n            a = 0.6 * (0.5 + rng.rand()) * sigma * max_scale\n            b = 0.6 * (0.5 + rng.rand()) * sigma * max_scale\n            x1 = np.minimum(np.maximum(base - a * direction, lb), ub)\n            f1 = safe_eval(x1); \n            if f1 is None:\n                return None, None\n            x2 = np.minimum(np.maximum(base + b * direction, lb), ub)\n            f2 = safe_eval(x2)\n            if f2 is None:\n                return None, None\n            # fit parabola through (x=-a,f1),(0,f0),(x=b,f2) but we need f0 at base\n            f0 = safe_eval(base)\n            if f0 is None:\n                return None, None\n            # solve for vertex x* in 1D: use formula from three points\n            # x* relative coordinate along direction: numerator/denom\n            denom = ( (f1 - 2*f0 + f2) )\n            if abs(denom) < 1e-12:\n                # pick best among evaluated\n                fs = [f1, f0, f2]\n                xs = [x1, base, x2]\n                idx = int(np.argmin(fs))\n                return xs[idx].copy(), fs[idx]\n            # use Lagrange parabola vertex formula -> x_star = 0.5*( (f1 - f2)/(f1 - 2*f0 + f2) )*(a + b) + (b - a)/2 something complex\n            # simpler: convert to coordinates [-a,0,b], solve quadratic ax^2+bx+c then vertex -b/(2a)\n            X = np.array([[-a, a*a, 1.0],\n                          [0.0, 0.0, 1.0],\n                          [b, b*b, 1.0]])\n            F = np.array([f1, f0, f2])\n            try:\n                # solve for [coef1, coef2, c] where f = coef1*x + coef2*x^2 + c ; better arranged as quadratic\n                # We'll solve for [A,B,C] with f = A*x^2 + B*x + C\n                M = np.vstack([[-a*a, -a, 1.0], [0.0, 0.0, 1.0], [b*b, b, 1.0]])\n                # slight rearrangement to keep numbers reasonable\n                coeffs = np.linalg.solve(M, F)\n                A = coeffs[0]; B = coeffs[1]\n                if abs(A) < 1e-14:\n                    # flat parabola; pick best\n                    fs = [f1, f0, f2]; xs = [x1, base, x2]\n                    idx = int(np.argmin(fs))\n                    return xs[idx].copy(), fs[idx]\n                xstar = -B / (2.0 * A)\n                # clamp xstar in bracket [-a, b]\n                xstar = max(-a, min(b, xstar))\n                x_best_line = np.minimum(np.maximum(base + xstar * direction, lb), ub)\n                f_best_line = safe_eval(x_best_line)\n                if f_best_line is None:\n                    return None, None\n                return x_best_line.copy(), f_best_line\n            except Exception:\n                fs = [f1, f0, f2]; xs = [x1, base, x2]\n                idx = int(np.argmin(fs))\n                return xs[idx].copy(), fs[idx]\n\n        # main loop: produce batches of candidate evaluations until budget exhausted\n        while evals < self.budget:\n            gen += 1\n\n            # periodic PCA refresh\n            if gen % self.pca_refresh == 0:\n                refresh_pca()\n\n            # build elites and covariance\n            Xe, Fe = get_elites()\n            S_sqrt = sqrt_cov_from(Xe) if Xe.size else np.eye(self.dim)\n\n            # small temperature for uphill acceptance (decays with evals)\n            T = 1e-6 + 0.6 * sigma * max(1e-12, 1.0 - (evals / max(1.0, self.budget)))\n\n            # prepare candidate batch\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                x_cand = None\n                f_c = None\n                step = None\n                strategy = 'jitter'\n\n                # levy escape\n                if p < self.prob_levy:\n                    strategy = 'levy'\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    step = 8.0 * sigma * z\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # Elite Mahalanobis sampling (anisotropic global/local guided)\n                elif p < self.prob_maha and Xe.size:\n                    strategy = 'maha'\n                    # mix between sampling around mean and around a random elite\n                    if rng.rand() < 0.6:\n                        center = m\n                    else:\n                        center = Xe[rng.randint(0, Xe.shape[0])]\n                    z = rng.randn(self.dim)\n                    # anisotropic scale: use S_sqrt (so L z approximates cov^0.5 z)\n                    step = 1.2 * sigma * (S_sqrt.dot(z)) + 0.15 * momentum\n                    # discourage taboo directions (we project step onto taboo and subtract a component)\n                    if len(taboo_dirs) > 0:\n                        for td in taboo_dirs[-6:]:\n                            proj = np.dot(step, td) * td\n                            step = step - 0.5 * proj\n                    x_cand = np.minimum(np.maximum(center + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # PCA surrogate minimizer in learned r-dim subspace (quadratic ridge)\n                elif p < (self.prob_maha + self.prob_pca_sur) and r > 0 and len(X_arch) >= (max(20, 6 * r)):\n                    strategy = 'pca_surrogate'\n                    # project recent archive into B relative to m\n                    K = min(len(X_arch), self.archive_size)\n                    Xr = np.asarray(X_arch[-K:])\n                    Fr = np.asarray(f_arch[-Xr.shape[0]:])\n                    Z = (Xr - m).dot(B)  # n x r\n                    n = Z.shape[0]\n                    # build basis [1, z, z^2] but solve with ridge per-coord (diagonal quad)\n                    Fmat = np.ones((n, 1 + r + r))\n                    Fmat[:, 1:1 + r] = Z\n                    Fmat[:, 1 + r:] = Z * Z\n                    lam = 1e-6 * (1.0 + np.var(Fr))\n                    try:\n                        FtF = Fmat.T.dot(Fmat)\n                        theta = np.linalg.solve(FtF + lam * np.eye(FtF.shape[0]), Fmat.T.dot(Fr))\n                        b = theta[1:1 + r]\n                        q = theta[1 + r:1 + r + r]\n                        q_pos = np.maximum(q, 1e-8)\n                        z_star = - b / (q_pos + 1e-12)\n                        # curvature-aware clip: scale z_star according to curvature estimate (shorten if high curvature)\n                        z_star = np.clip(z_star, -4.0 * sub_scale, 4.0 * sub_scale)\n                        # damp direction if it aligns with taboo dirs\n                        for td in taboo_dirs[-6:]:\n                            proj = (B.dot(z_star)).dot(td)\n                            if abs(proj) > 0.5 * np.linalg.norm(B.dot(z_star)):\n                                z_star = 0.6 * z_star\n                        x_pred = np.minimum(np.maximum(m + B.dot(z_star), lb), ub)\n                        f_pred = safe_eval(x_pred)\n                        if f_pred is None:\n                            break\n                        x_cand = x_pred\n                        f_c = f_pred\n                        step = x_cand - m\n                        # update curvature estimate\n                        curvature = 0.9 * curvature + 0.1 * (1.0 / (q_pos + 1e-8))\n                    except Exception:\n                        pass\n\n                # directional line probe along promising direction (use small eval budget)\n                elif p < (self.prob_maha + self.prob_pca_sur + self.prob_line):\n                    strategy = 'line'\n                    # choose a direction: either momentum, best - m, or a PCA component\n                    choice = rng.rand()\n                    if choice < 0.35:\n                        d = x_best - m\n                    elif choice < 0.7 and r > 0:\n                        idx = rng.randint(0, r)\n                        d = B[:, idx] * sub_scale[idx]\n                    else:\n                        d = momentum + 0.2 * rng.randn(self.dim)\n                    nd = np.linalg.norm(d) + 1e-12\n                    d = d / nd\n                    # avoid directions that are too similar to taboo list\n                    similar = False\n                    for td in taboo_dirs[-6:]:\n                        if abs(np.dot(d, td)) > 0.92:\n                            similar = True; break\n                    if similar:\n                        # perturb to be different\n                        d = d - 0.6 * np.dot(d, td) * td\n                        d = d / (np.linalg.norm(d) + 1e-12)\n                    # perform line probe (may consume up to 3 evals)\n                    res = line_probe(m, d, max_scale=2.2)\n                    if res[0] is None:\n                        # if failed, fallback jitter\n                        eps = rng.randn(self.dim)\n                        step = sigma_diag * eps\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n                    else:\n                        x_line, f_line = res\n                        x_cand = x_line; f_c = f_line\n                        step = x_cand - m\n                        # if line probe worsened, add direction to taboo\n                        if f_c > f_best:\n                            dnorm = np.linalg.norm(step)\n                            if dnorm > 1e-12:\n                                taboo_dirs.append(step / dnorm)\n                                if len(taboo_dirs) > 24:\n                                    taboo_dirs.pop(0)\n\n                # reflection/expansion move inspired by simplex reflection across centroid of elites\n                elif p < (self.prob_maha + self.prob_pca_sur + self.prob_line + self.prob_reflect) and Xe.size:\n                    strategy = 'reflect'\n                    centroid = Xe.mean(axis=0)\n                    # reflect worst recent sample across centroid\n                    worst_idx = int(np.argmax(f_arch[-min(len(f_arch), 20):]))\n                    x_worst = np.asarray(X_arch[-min(len(X_arch), 20):][worst_idx])\n                    step = (centroid - x_worst) + 0.3 * rng.randn(self.dim) * sigma\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # default anisotropic jitter (RMS-adapted)\n                else:\n                    strategy = 'jitter'\n                    eps = rng.randn(self.dim)\n                    step = sigma_diag * eps + 0.18 * momentum\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # ensure we have a result\n                if f_c is None:\n                    break\n\n                # bookkeeping: improvement?\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c)\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # reward metric: improvement relative to median of archive\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                reward = raw_reward / (sigma * step_norm + 1e-12)\n\n                # update RMS adaptives\n                sq = (step / (sigma + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq\n                sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-8), self.min_sigma, self.max_sigma)\n\n                # update subspace usage stats\n                if step is not None and r > 0:\n                    projs = B.T.dot(step)\n                    absprojs = np.abs(projs)\n                    if absprojs.size > 0 and absprojs.sum() > 0:\n                        # increase sub_scale gently for used components\n                        sub_scale = np.clip(0.97 * sub_scale + 0.03 * (absprojs + 1e-8), self.min_sigma, self.max_sigma)\n\n                # acceptance decision: always accept improvements; accept uphill rarely according to T\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    delta = f_c - f_best\n                    if delta <= 0:\n                        accept = True\n                    else:\n                        if rng.rand() < np.exp(-delta / (T + 1e-12)):\n                            accept = True\n\n                if accept:\n                    # learning rate depends on strategy\n                    if strategy in ('pca_surrogate', 'maha'):\n                        lr = 0.9\n                    elif strategy == 'line':\n                        lr = 0.6\n                    elif strategy in ('reflect',):\n                        lr = 0.5\n                    elif strategy == 'levy':\n                        lr = 0.2\n                    else:\n                        lr = 0.35\n\n                    delta = (x_cand - m)\n                    # global trust clipping to avoid giant jumps in mean\n                    trust = 8.0 * sigma * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    # update mean\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n\n                    # momentum update (EMA)\n                    momentum = 0.85 * momentum + 0.15 * delta\n\n                    # adapt sigma: shrink on consistent improvement, expand on uphill acceptance\n                    if improved:\n                        sigma = max(self.min_sigma, sigma * 0.86)\n                        v_rms *= 0.96\n                    else:\n                        sigma = min(self.max_sigma, sigma * 1.02)\n                else:\n                    # reject: tiny random jitter to escape local plateau, and penalize momentum\n                    m = np.minimum(np.maximum(m + 0.01 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma = min(self.max_sigma, sigma * 1.004)\n                    momentum *= 0.97\n                    # if repeated rejects along similar direction, add to taboo\n                    if step is not None:\n                        snorm = np.linalg.norm(step)\n                        if snorm > 1e-12:\n                            td = step / snorm\n                            taboo_dirs.append(td)\n                            if len(taboo_dirs) > 36:\n                                taboo_dirs.pop(0)\n\n                # occasional small orthonormal perturbation of B to avoid lock-in\n                if r > 0 and rng.rand() < 0.04:\n                    R = rng.randn(r, r) * 0.06\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(r) + R)\n                        B = B.dot(Qr)\n                        Q2, _ = np.linalg.qr(B)\n                        B = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed around best when stagnation high\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    jitter = max(0.03 * avg_span, 1.2 * sigma)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma = min(self.max_sigma, sigma * 1.5)\n                    momentum = np.zeros(self.dim)\n                    # reinitialize B randomly\n                    if r > 0:\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :r]\n                        sub_scale = np.full(r, sigma / np.sqrt(max(1, r)))\n                        curvature = np.full(r, 1.0)\n                    # local refine around best with a few evaluations\n                    reseed = min(6, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.04 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None:\n                            break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # end candidate batch\n\n        # store results\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AOES scored 0.268 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a6173c49-f31a-4805-8ee3-5072a52dea0b", "operator": null, "metadata": {"aucs": [0.12123690753893801, 0.17071124906336144, 0.32756650547791855, 0.4382838778435433, 0.26754760565864766, 0.38657467861972317, 0.24991210422165444, 0.30481750466000423, 0.2415255816471198, 0.17369883191840052]}, "task_prompt": ""}
{"id": "f5c608bb-0288-403e-8dd6-e64a40352b78", "fitness": 0.21214091699972873, "name": "ARVE", "description": "ARVE is a hybrid, population-style heuristic that mixes archive-driven PCA and subspace sampling (rank default ~dim/5, archive_size ~8*dim, periodic SVD refresh) with a ridge-regression gradient proxy in PCA coordinates, radial intensification toward the current best, coordinate-biased tweaks, occasional heavy‑tailed Cauchy escapes and uniform/Gaussian fallbacks (strategy chosen stochastically each proposal; pop candidates per generation). It adaptively scales steps with a global_scale (init_scale=0.18·span) and per-dimension scales driven by an RMS EMA (step_beta=0.90) while keeping a subspace covariance EMA (cov_beta=0.92) to set sub_scale, and it clips large proposals by a trust limit and uses a momentum-like vel for smoothing. Acceptance is opportunistic: greedy improvements are always taken, otherwise a Boltzmann-style uphill acceptance with a decaying temperature (temp0=0.5) allows exploration; improved moves shrink global_scale, uphill moves slightly inflate it. Practical safeguards include bound clipping, strict budget accounting (safe_eval), occasional random basis rotations to avoid lock-in, and opportunistic reseeding/local intensification when stagnation is detected.", "code": "import numpy as np\n\nclass ARVE:\n    \"\"\"\n    Adaptive Ridge-and-Valley Explorer (ARVE)\n\n    One-line idea:\n      Mix PCA-guided correlated exploration with simple subspace gradient proxies,\n      coordinate tweaks, radial intensification and occasional heavy-tailed escapes,\n      using archive-driven PCA and adaptive per-dimension scales.\n\n    Main parameters (accessible in __init__):\n      - budget: total number of allowed function evaluations\n      - dim: problem dimensionality\n      - pop: number of candidate proposals generated per internal generation\n      - rank: subspace rank for PCA / guided proposals (if None a heuristic is used)\n      - archive_size: how many recent samples to keep for PCA and models\n      - init_scale: initial global step scale factor relative to search span\n      - cov_beta: EMA coefficient for subspace covariance adaptation\n      - step_beta: EMA for per-dimension squared-step normalization (RMS-like)\n      - temp0: base temperature multiplier for uphill acceptance\n      - refresh_every: generations between PCA refreshes\n      - strategy probabilities: prob_pca, prob_grad, prob_radial, prob_coord, prob_cauchy\n      - min_scale / max_scale: bounds for per-dimension scales\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=14, rank=None, archive_size=None, init_scale=0.18,\n                 cov_beta=0.92, step_beta=0.90, temp0=0.5, refresh_every=10,\n                 prob_pca=0.26, prob_grad=0.14, prob_radial=0.20,\n                 prob_coord=0.16, prob_cauchy=0.03, min_scale=1e-8, max_scale=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        # choose rank more aggressively than MAHRS: a larger fraction of dim\n        self.rank = rank if rank is not None else max(1, min(self.dim, max(2, self.dim // 5)))\n        self.archive_size = archive_size if archive_size is not None else max(8 * self.dim, 120)\n        self.init_scale = float(init_scale)\n        self.cov_beta = float(cov_beta)\n        self.step_beta = float(step_beta)\n        self.temp0 = float(temp0)\n        self.refresh_every = int(refresh_every)\n\n        # strategy probabilities - ensure they sum <= 1, remainder is uniform sampling\n        self.prob_pca = float(prob_pca)\n        self.prob_grad = float(prob_grad)\n        self.prob_radial = float(prob_radial)\n        self.prob_coord = float(prob_coord)\n        self.prob_cauchy = float(prob_cauchy)\n\n        self.min_scale = float(min_scale)\n        self.max_scale = float(max_scale)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds (try to read from func; otherwise default -5..5)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize mean, scales, velocity-like momentum and RMS tracker\n        m = rng.uniform(lb, ub, size=self.dim)\n        global_scale = max(self.min_scale, self.init_scale * avg_span)\n        per_dim_scale = np.full(self.dim, global_scale)\n        rms_sq = np.full(self.dim, 1e-6)  # EMA of squared normalized steps\n        vel = np.zeros(self.dim)\n\n        # subspace basis initialization (orthonormal)\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()  # principal directions placeholder\n            sub_cov = np.eye(r) * (global_scale**2)  # small subspace covariance\n            sub_scale = np.full(r, global_scale / np.sqrt(max(1, r)))\n        else:\n            B = np.zeros((self.dim, 0))\n            sub_cov = np.zeros((0, 0))\n            sub_scale = np.array([])\n\n        # archive and evaluation bookkeeping\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # safe_eval wrapper to enforce budget and store archive\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            # clip to bounds for safety\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            if len(X_arch) > self.archive_size:\n                del X_arch[0]; del f_arch[0]\n            return fx\n\n        # initial seeding to build a modest archive\n        seed0 = min(self.pop * 4, max(12, int(self.budget // 250)))\n        for _ in range(seed0):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(12, int(0.06 * self.budget))\n\n        # PCA refresh routine: compute top-r principal directions and subspace covariances\n        def refresh_pca():\n            nonlocal B, sub_cov, sub_scale, r\n            if len(X_arch) < 4 or r == 0:\n                return\n            K = min(len(X_arch), self.archive_size)\n            Xr = np.asarray(X_arch[-K:])\n            meanX = Xr.mean(axis=0)\n            S = (Xr - meanX)\n            try:\n                # compute SVD of centered samples; Vt rows are principal directions\n                U_s, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(r, Vt.shape[0])\n                if r_eff > 0:\n                    B_new = Vt[:r_eff].T\n                    # softer blending to avoid abrupt resets\n                    alpha = 0.18\n                    if B.shape[1] == r_eff:\n                        B = (1.0 - alpha) * B + alpha * B_new\n                    else:\n                        B = B_new.copy()\n                    # orthonormalize\n                    Q, _ = np.linalg.qr(B)\n                    B = Q[:, :r_eff]\n                    # update subspace covariance estimate from singular values (variance proxy)\n                    new_cov_diag = (svals[:r_eff] ** 2) / max(1, K - 1)\n                    # EMA update of sub_cov (diagonalized)\n                    sub_cov = self.cov_beta * sub_cov\n                    # ensure matching shape\n                    if sub_cov.shape[0] != r_eff:\n                        sub_cov = np.diag(new_cov_diag + 1e-12)\n                    else:\n                        sub_cov += (1.0 - self.cov_beta) * np.diag(new_cov_diag + 1e-12)\n                    sub_scale = np.sqrt(np.maximum(np.diag(sub_cov), 1e-12))\n            except Exception:\n                pass\n\n        # main loop: create small batches of candidates per generation\n        while evals < self.budget:\n            gen += 1\n\n            # periodic refresh of subspace\n            if gen % self.refresh_every == 0:\n                refresh_pca()\n\n            # temperature for uphill acceptance decays slowly with evals\n            temp = self.temp0 * global_scale * (1.0 - (evals / max(1.0, self.budget)))**0.5\n            temp = max(temp, 1e-12)\n\n            # propose up to pop candidates but not exceed remaining budget\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                x_cand = None\n                step = None\n                f_c = None\n                strategy = 'uniform'\n\n                # strategy selection by cumulative probabilities\n                cum1 = self.prob_pca\n                cum2 = cum1 + self.prob_grad\n                cum3 = cum2 + self.prob_radial\n                cum4 = cum3 + self.prob_coord\n                cum5 = cum4 + self.prob_cauchy\n\n                # 1) PCA-guided correlated Gaussian\n                if p < cum1 and r > 0:\n                    strategy = 'pca'\n                    # sample from subspace normal with diagonalized sub_cov\n                    z = rng.randn(r) * sub_scale\n                    # reconstruct correlated step and add small diag jitter\n                    jitter = 0.6 * (per_dim_scale * rng.randn(self.dim))\n                    step = B.dot(z) + jitter + 0.12 * vel\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # 2) subspace-gradient proxy: fit linear model in PCA coords to estimate descent direction\n                elif p < cum2 and r > 0 and len(X_arch) >= max(12, 5 * r):\n                    strategy = 'grad_proxy'\n                    Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                    Fr = np.asarray(f_arch[-Xr.shape[0]:])\n                    Z = (Xr - m).dot(B)  # (n_samples, r)\n                    # simple ridge linear regression f ~ 1 + g^T z\n                    n = Z.shape[0]\n                    F = np.ones((n, 1 + r))\n                    F[:, 1:] = Z\n                    lam = 1e-6 * (1.0 + np.var(Fr))\n                    try:\n                        FtF = F.T.dot(F)\n                        theta = np.linalg.solve(FtF + lam * np.eye(FtF.shape[0]), F.T.dot(Fr))\n                        grad_sub = theta[1:]\n                        # take a step opposite to estimated gradient in subspace with trust clipping\n                        trust = 2.5 * sub_scale\n                        vstep_sub = - (grad_sub / (np.linalg.norm(grad_sub) + 1e-12)) * (trust * (0.8 + 0.4 * rng.rand()))\n                        step = B.dot(vstep_sub) + 0.3 * per_dim_scale * rng.randn(self.dim)\n                        x_pred = np.minimum(np.maximum(m + step, lb), ub)\n                        f_pred = safe_eval(x_pred)\n                        if f_pred is None:\n                            break\n                        x_cand = x_pred\n                        f_c = f_pred\n                    except Exception:\n                        # fallback to small PCA gaussian\n                        z = 0.5 * rng.randn(r) * sub_scale\n                        step = B.dot(z) + 0.8 * per_dim_scale * rng.randn(self.dim)\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # 3) radial intensify towards current best\n                elif p < cum3:\n                    strategy = 'radial'\n                    d = x_best - m\n                    nd = np.linalg.norm(d) + 1e-12\n                    dirv = d / nd\n                    # radius blends distance-to-best and global_scale\n                    radius = (0.5 + rng.rand() * 1.6) * max(0.7 * global_scale, 0.4 * nd)\n                    step = dirv * radius + 0.18 * vel + 0.3 * per_dim_scale * rng.randn(self.dim)\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # 4) coordinate tweak: single coordinate large-or-small change biased by archive variances\n                elif p < cum4:\n                    strategy = 'coord'\n                    if len(X_arch) >= 6:\n                        Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                        var = np.var(Xr, axis=0)\n                        weights = var + 1e-9\n                    else:\n                        weights = per_dim_scale + 1e-9\n                    weights = weights / (weights.sum() + 1e-12)\n                    j = int(rng.choice(self.dim, p=weights))\n                    step_dir = np.zeros(self.dim)\n                    # mixed scale: sometimes big jump, sometimes fine tweak\n                    if rng.rand() < 0.28:\n                        step_scale = 1.4 * global_scale\n                    else:\n                        step_scale = 0.28 * per_dim_scale[j]\n                    step_dir[j] = step_scale * (1.0 if rng.rand() < 0.5 else -1.0)\n                    x_try = np.minimum(np.maximum(m + step_dir + 0.05 * vel, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try\n                    f_c = f_try\n                    step = x_cand - m\n\n                # 5) heavy-tailed Cauchy escape\n                elif p < cum5:\n                    strategy = 'cauchy'\n                    z = rng.standard_cauchy(size=self.dim)\n                    # normalize by robust scale to avoid outliers blowing up\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    step = z * (4.0 * global_scale) + 0.2 * per_dim_scale * rng.randn(self.dim)\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # 6) fallback uniform/gauussian mixture\n                else:\n                    strategy = 'uniform'\n                    if rng.rand() < 0.4:\n                        # global uniform restart probe\n                        x_cand = rng.uniform(lb, ub, size=self.dim)\n                        step = x_cand - m\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n                    else:\n                        # default gaussian around mean\n                        eps = rng.randn(self.dim)\n                        step = per_dim_scale * eps + 0.15 * vel\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # at this point we should have f_c or have broken due to budget\n                if f_c is None:\n                    break\n\n                # update best and stagnation counter\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c)\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # compute reward-like signal (archive median baseline)\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_gain = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                reward = raw_gain / (global_scale * step_norm + 1e-12)\n\n                # update per-dimension RMS (like Adam RMS but simpler)\n                normalized_step = step / (global_scale + 1e-12)\n                sq = normalized_step**2\n                rms_sq = self.step_beta * rms_sq + (1.0 - self.step_beta) * sq\n                per_dim_scale = np.clip(global_scale / (np.sqrt(rms_sq) + 1e-8), self.min_scale, self.max_scale)\n\n                # adjust subspace stats if used\n                if r > 0 and step is not None:\n                    projs = B.T.dot(step)\n                    abs_projs = np.abs(projs)\n                    if abs_projs.size > 0 and abs_projs.sum() > 0:\n                        # gentle EMA update of sub_cov diagonal\n                        sub_cov = self.cov_beta * sub_cov + (1.0 - self.cov_beta) * np.diag((projs**2) + 1e-12)\n                        sub_scale = np.sqrt(np.maximum(np.diag(sub_cov), 1e-12))\n\n                # acceptance decision: improved or uphill with Boltzmann prob\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    deltaE = f_c - f_best\n                    # Note: if f_best updated above on improvement, deltaE >= 0 here\n                    if deltaE <= 0:\n                        accept = True\n                    else:\n                        if rng.rand() < np.exp(-deltaE / (temp + 1e-12)):\n                            accept = True\n\n                # apply acceptance effects\n                if accept:\n                    # learning rates per strategy (different constants than MAHRS)\n                    if strategy == 'pca':\n                        lr = 0.82\n                    elif strategy == 'grad_proxy':\n                        lr = 0.78\n                    elif strategy == 'radial':\n                        lr = 0.60\n                    elif strategy == 'coord':\n                        lr = 0.46\n                    elif strategy == 'cauchy':\n                        lr = 0.22\n                    elif strategy == 'uniform':\n                        lr = 0.34\n                    else:\n                        lr = 0.36\n\n                    m_old = m.copy()\n                    # trust limit scaled by dimension and global scale (different formula)\n                    trust = 4.8 * global_scale * np.sqrt(max(1, self.dim) / max(1, r))\n                    dn = np.linalg.norm(step)\n                    delta = step.copy()\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n\n                    # move mean toward candidate\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n\n                    # update velocity with different momentum mixing\n                    vel = 0.78 * vel + 0.22 * (m - m_old)\n\n                    # adapt global scale more aggressively for clear improvements\n                    if improved:\n                        shrink = 0.88 if strategy in ('pca', 'grad_proxy') else 0.90\n                        global_scale = max(self.min_scale, global_scale * shrink)\n                        # temper RMS to allow finer steps\n                        rms_sq *= 0.95\n                    else:\n                        # uphill acceptance expands search a bit\n                        global_scale = min(self.max_scale, global_scale * 1.04)\n                else:\n                    # rejection: random small perturbation to mean and slight inflation\n                    m = np.minimum(np.maximum(m + 0.015 * avg_span * rng.randn(self.dim), lb), ub)\n                    global_scale = min(self.max_scale, global_scale * 1.008)\n                    vel *= 0.96\n\n                # occasional small random rotation to the basis to prevent lock-in (different magnitude)\n                if r > 0 and rng.rand() < 0.04:\n                    R = rng.randn(r, r) * 0.035\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(r) + R)\n                        B = B.dot(Qr)\n                        Q2, _ = np.linalg.qr(B)\n                        B = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed around best on stagnation (different thresholds / sizes)\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    jitter = max(0.06 * avg_span, 1.6 * global_scale)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    global_scale = min(self.max_scale, global_scale * 1.8)\n                    vel = np.zeros(self.dim)\n                    # reinitialize subspace randomly to encourage different directions\n                    if r > 0:\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :r]\n                        sub_scale = np.full(r, global_scale / np.sqrt(max(1, r)))\n                        sub_cov = np.diag(sub_scale**2)\n                    # local intensive probes around best\n                    reseed = min(8, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.08 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None:\n                            break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # end batch\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ARVE scored 0.212 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a6173c49-f31a-4805-8ee3-5072a52dea0b", "operator": null, "metadata": {"aucs": [0.11527337562619866, 0.165923610064162, 0.2586607778038452, 0.27914935916080885, 0.22767719607076176, 0.24549065981137685, 0.2266565609238288, 0.22891005744987092, 0.21310093857015022, 0.1605666345162835]}, "task_prompt": ""}
{"id": "9bf6feaf-9d67-4414-99e1-7c68612ebd79", "fitness": 0.21269415921438176, "name": "ARES", "description": "ARES is an ensemble-based continuous optimizer that runs multiple \"actors\" (centers) in parallel and adaptively focuses search by learning a low-rank rotation basis from recent archive data (incremental SVD) to drive anisotropic proposals and lightweight subspace quadratic predictions. It mixes many complementary move strategies (surrogate subspace prediction, DE-like differential steps, eigen-direction sampling, coordinate tweaks, mirrored-opponent moves, Lévy bursts and fallback Gaussian) chosen by tunable probabilities, uses per-dimension RMS scaling, trust-radius clipping, and an \"echo\" directional momentum plus a small global momentum to bias successful directions. Adaptation and robustness come from temperature-controlled uphill acceptance, adaptive global sigma (shrink on improvements, inflate on stagnation), periodic basis rotations, opportunistic reseed/local probes on stagnation, and strict safe-evaluation to never exceed the given budget.", "code": "import numpy as np\n\nclass ARES:\n    \"\"\"\n    Adaptive Rotational Ensemble Search (ARES)\n\n    Summary of novelties:\n    - Maintains an ensemble of 'actors' (centers) that propose moves in parallel.\n    - Learns a low-rank rotation (eigen-basis) from recent archive via incremental SVD.\n    - Performs lightweight subspace quadratic predictions (diagonal or small full-quadratic if r small).\n    - Combines strategies: surrogate-predictor, differential-ensemble (DE-like), anisotropic eigen-sampling,\n      coordinate tweaks, Lévy bursts and mirrored-opponent moves.\n    - Uses \"echo momentum\": successful direction gains temporary amplification for follow-up proposals.\n    - Temperature-controlled uphill acceptance, per-dimension RMS scaling, periodic small random rotations\n      of the learned basis, and opportunistic reseed on stagnation.\n    - Safe evaluation ensures the function is never called beyond budget.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=12, rank=None, archive_size=None,\n                 init_sigma_mult=0.18, rms_beta=0.92,\n                 temp0=0.6, dir_refresh=10,\n                 prob_surrogate=0.18, prob_de=0.22, prob_eigen=0.24,\n                 prob_coord=0.10, prob_levy=0.03,\n                 min_sigma=1e-8, max_sigma=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.rank = rank if rank is not None else max(1, self.dim // 8)\n        self.archive_size = archive_size if archive_size is not None else max(12 * self.dim, 120)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.rms_beta = float(rms_beta)\n        self.temp0 = float(temp0)\n        self.dir_refresh = int(dir_refresh)\n        # strategy probabilities (sum <= 1, remainder -> gaussian fallback)\n        self.prob_surrogate = float(prob_surrogate)\n        self.prob_de = float(prob_de)\n        self.prob_eigen = float(prob_eigen)\n        self.prob_coord = float(prob_coord)\n        self.prob_levy = float(prob_levy)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds (default -5..5)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize ensemble of centers (actors)\n        pop = max(2, min(self.pop, 2 * self.dim))\n        centers = rng.uniform(lb, ub, size=(pop, self.dim))\n        f_centers = np.full(pop, np.inf)\n\n        # initial global scales and per-dim RMS\n        sigma = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        sigma_diag = np.full(self.dim, sigma)\n        v_rms = np.full(self.dim, 1e-6)\n        echoes = np.zeros((pop, self.dim))  # directional echo momentum per center\n        global_mom = np.zeros(self.dim)\n\n        # low-rank basis\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :r].copy()      # learned rotation basis (dim x r)\n            eigvals = np.full(r, sigma * sigma)\n            tau = np.maximum(1e-8, np.sqrt(eigvals))\n        else:\n            U = np.zeros((self.dim, 0))\n            eigvals = np.array([])\n            tau = np.array([])\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # safe eval wrapper\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            if len(X_arch) > self.archive_size:\n                del X_arch[0]; del f_arch[0]\n            return fx\n\n        # seed ensemble evaluations (initial population)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            fx = safe_eval(centers[i])\n            if fx is None:\n                break\n            f_centers[i] = fx\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        # record best\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(12, int(0.05 * self.budget))\n\n        # function to refresh low-rank basis via SVD of recent archive\n        def refresh_basis():\n            nonlocal U, eigvals, tau, r\n            if len(X_arch) < 6 or r == 0:\n                return\n            K = min(len(X_arch), self.archive_size)\n            Xr = np.asarray(X_arch[-K:])\n            meanX = Xr.mean(axis=0)\n            S = (Xr - meanX)\n            try:\n                # economy SVD: U_s * svals * Vt where Vt rows are principal components directions\n                U_s, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                # principal directions are rows of Vt: we take top r\n                r_eff = min(r, Vt.shape[0])\n                if r_eff > 0:\n                    U_new = Vt[:r_eff].T\n                    # blend to avoid abrupt rotations (small rotation mixing)\n                    alpha = 0.18\n                    if U.shape[1] == r_eff:\n                        U = (1.0 - alpha) * U + alpha * U_new\n                    else:\n                        U = U_new.copy()\n                    # orthonormalize\n                    Q, _ = np.linalg.qr(U)\n                    U = Q[:, :r_eff]\n                    # eigen-like scales from singular values (variances along components)\n                    eigvals = 0.9 * eigvals[:r_eff] + 0.1 * (svals[:r_eff] ** 2 + 1e-12)\n                    tau = np.maximum(1e-8, np.sqrt(eigvals))\n            except Exception:\n                pass\n\n        # lightweight subspace quadratic fit (diagonal or small full quadratic depending on r)\n        def subspace_predictor(m_center):\n            # returns candidate x_pred or None\n            if r == 0 or len(X_arch) < max(12, 6 * r):\n                return None, None\n            Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n            Fr = np.asarray(f_arch[-Xr.shape[0]:])\n            Z = (Xr - m_center).dot(U)  # (n, r)\n            n = Z.shape[0]\n            # design matrix: constant + linear terms + diag quadratic terms\n            # if r small (<=6) allow cross-terms to get a better predictive direction\n            if r <= 6 and n > (1 + r + (r * (r + 1)) // 2):\n                # build full quadratic (symmetric) terms\n                num_quad = (r * (r + 1)) // 2\n                F = np.ones((n, 1 + r + num_quad))\n                F[:, 1:1 + r] = Z\n                # fill upper-triangular quadratic terms z_i*z_j\n                idx = 1 + r\n                for i in range(r):\n                    for j in range(i, r):\n                        F[:, idx] = Z[:, i] * Z[:, j]\n                        idx += 1\n            else:\n                # diagonal quadratic model: constant + linear + elementwise z^2\n                F = np.ones((n, 1 + r + r))\n                F[:, 1:1 + r] = Z\n                F[:, 1 + r:] = Z * Z\n            # ridge regression\n            lam = 1e-6 * (1.0 + np.var(Fr))\n            try:\n                FtF = F.T.dot(F)\n                reg = lam * np.eye(FtF.shape[0])\n                theta = np.linalg.solve(FtF + reg, F.T.dot(Fr))\n                c = theta[0]\n                b = theta[1:1 + r]\n                # compute a diagonal curvature from remaining parameters (if available)\n                if F.shape[1] == 1 + r + r:\n                    q = theta[1 + r:1 + r + r]\n                    qpos = np.maximum(q, 1e-6)\n                    z_star = - b / (qpos + 1e-12)\n                else:\n                    # if full quadratic, approximate diagonal curvature by diagonal of Hessian constructed\n                    # extract quadratic entries to symmetric Q matrix\n                    Qm = np.zeros((r, r))\n                    idx = 1 + r\n                    for i in range(r):\n                        for j in range(i, r):\n                            val = theta[idx]\n                            if i == j:\n                                Qm[i, j] = val\n                            else:\n                                Qm[i, j] = val / 2.0\n                                Qm[j, i] = val / 2.0\n                            idx += 1\n                    diagH = np.diag(Qm)\n                    diagH_pos = np.maximum(diagH, 1e-6)\n                    z_star = - b / (diagH_pos + 1e-12)\n                # trust clipping based on tau (scaled)\n                clip = 3.0 * tau\n                if clip.size == 0:\n                    return None, None\n                z_star = np.clip(z_star, -clip, clip)\n                x_pred = np.minimum(np.maximum(m_center + U.dot(z_star), lb), ub)\n                return x_pred, z_star\n            except Exception:\n                return None, None\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n\n            # refresh basis periodically\n            if gen % self.dir_refresh == 0:\n                refresh_basis()\n\n            # temperature schedule (decays with evals)\n            T = self.temp0 * max(1e-12, sigma) * avg_span * max(1e-12, 1.0 - (evals / max(1.0, self.budget)))\n\n            # number of proposals this generation: attempt one per center or up to remaining budget\n            n_prop = min(len(centers), max(1, self.budget - evals))\n            for actor in range(n_prop):\n                if evals >= self.budget:\n                    break\n\n                # choose strategy\n                p = rng.rand()\n                x_cand = None\n                strategy = 'gauss'\n                actor_pos = centers[actor].copy()\n                actor_f = f_centers[actor] if np.isfinite(f_centers[actor]) else np.inf\n\n                # chance of Levy burst\n                if p < self.prob_levy:\n                    strategy = 'levy'\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 80) + 1e-12)\n                    step = 8.0 * sigma * z + 0.4 * echoes[actor]\n                    x_try = np.minimum(np.maximum(actor_pos + step, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try\n                    f_cand = f_try\n\n                # surrogate predictor in learned subspace\n                elif p < self.prob_surrogate:\n                    strategy = 'surrogate'\n                    pred, z_star = subspace_predictor(actor_pos)\n                    if pred is not None:\n                        # small jitter along subspace orthogonal complement\n                        orth_jitter = 0.08 * sigma * rng.randn(self.dim)\n                        x_try = np.minimum(np.maximum(pred + orth_jitter, lb), ub)\n                        f_try = safe_eval(x_try)\n                        if f_try is None:\n                            break\n                        x_cand = x_try\n                        f_cand = f_try\n\n                # differential ensemble (DE-like) move using other centers\n                elif p < (self.prob_surrogate + self.prob_de) and len(centers) >= 3:\n                    strategy = 'de'\n                    # pick distinct indices\n                    idxs = list(range(len(centers)))\n                    idxs.remove(actor)\n                    i_b, i_c = rng.choice(idxs, size=2, replace=False)\n                    a = centers[actor]\n                    b = centers[i_b]\n                    c = centers[i_c]\n                    F = 0.6 + 0.8 * rng.rand()\n                    step = F * (b - c) + 0.12 * sigma * rng.randn(self.dim) + 0.25 * echoes[actor]\n                    x_try = np.minimum(np.maximum(a + step, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try\n                    f_cand = f_try\n\n                # anisotropic eigen sampling (explore along learned eigenvectors)\n                elif p < (self.prob_surrogate + self.prob_de + self.prob_eigen) and r > 0:\n                    strategy = 'eigen'\n                    z = rng.randn(r) * tau  # scale by learned tau per component\n                    step = U.dot(z) + 0.6 * sigma_diag * rng.randn(self.dim) + 0.18 * global_mom\n                    x_try = np.minimum(np.maximum(actor_pos + step, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try\n                    f_cand = f_try\n\n                # coordinate tweak\n                elif p < (self.prob_surrogate + self.prob_de + self.prob_eigen + self.prob_coord):\n                    strategy = 'coord'\n                    # pick a coordinate with probability proportional to archive variance\n                    if len(X_arch) >= 6:\n                        var = np.var(np.asarray(X_arch[-min(len(X_arch), self.archive_size):]), axis=0)\n                    else:\n                        var = sigma_diag\n                    probs = (var + 1e-12) / (np.sum(var) + 1e-12)\n                    j = int(rng.choice(self.dim, p=probs))\n                    step_vec = np.zeros(self.dim)\n                    step_size = sigma_diag[j] * (0.25 + rng.rand() * 1.75)\n                    step_vec[j] = step_size * (1.0 if rng.rand() < 0.5 else -1.0)\n                    x_try = np.minimum(np.maximum(actor_pos + step_vec + 0.12 * echoes[actor], lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try\n                    f_cand = f_try\n\n                # mirrored opponent move (reflect a recent poor sample across actor)\n                elif p < (self.prob_surrogate + self.prob_de + self.prob_eigen + self.prob_coord + 0.06) and len(X_arch) >= 4:\n                    strategy = 'mirror'\n                    idx = int(np.argmax(f_arch[-min(len(f_arch), 30):]))\n                    x_worst = np.asarray(X_arch[-min(len(X_arch), 30):][idx])\n                    step = (actor_pos - x_worst) + 0.2 * sigma * rng.randn(self.dim)\n                    x_try = np.minimum(np.maximum(actor_pos + step, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try\n                    f_cand = f_try\n\n                # fallback gaussian\n                else:\n                    strategy = 'gauss'\n                    step = sigma_diag * rng.randn(self.dim) + 0.2 * global_mom + 0.08 * echoes[actor]\n                    x_try = np.minimum(np.maximum(actor_pos + step, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try\n                    f_cand = f_try\n\n                # if for some reason no candidate created, continue\n                if x_cand is None:\n                    continue\n\n                # update global archive best\n                improved = False\n                if f_cand < f_best - 1e-15:\n                    f_best = float(f_cand)\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # reward metric: improvement relative to median of archive\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_cand)\n                step_norm = (np.linalg.norm(x_cand - actor_pos) + 1e-12)\n                reward = raw_reward / (sigma * step_norm + 1e-12)\n\n                # per-dim RMS update\n                sq = ((x_cand - actor_pos) / (sigma + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq\n                sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-8), self.min_sigma, self.max_sigma)\n\n                # acceptance (prefer improvement or accept uphill by temperature)\n                accept = False\n                if f_cand < actor_f - 1e-15:\n                    accept = True\n                else:\n                    deltaE = f_cand - actor_f if np.isfinite(actor_f) else f_cand - f_best\n                    if deltaE <= 0:\n                        accept = True\n                    else:\n                        if rng.rand() < np.exp(-deltaE / (T + 1e-12)):\n                            accept = True\n\n                # learning rates by strategy\n                if strategy == 'surrogate':\n                    lr = 0.92\n                elif strategy == 'de':\n                    lr = 0.56\n                elif strategy == 'eigen':\n                    lr = 0.48\n                elif strategy in ('coord', 'mirror'):\n                    lr = 0.42\n                elif strategy == 'levy':\n                    lr = 0.26\n                else:\n                    lr = 0.36\n\n                if accept:\n                    # update actor position towards candidate\n                    delta = x_cand - actor_pos\n                    # trust radius prevents catastrophic jumps\n                    trust = 8.0 * sigma * max(1.0, np.sqrt(self.dim))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    new_pos = np.minimum(np.maximum(actor_pos + lr * delta, lb), ub)\n                    centers[actor] = new_pos\n                    f_centers[actor] = float(f_cand)\n\n                    # update echoes (directional momentum): boost along accepted delta proportionally to reward\n                    echoes[actor] = 0.86 * echoes[actor] + 0.14 * (delta * (1.0 + min(5.0, reward * 50.0)))\n                    # update global momentum\n                    global_mom = 0.88 * global_mom + 0.12 * delta\n\n                    # adapt sigma: shrink a bit on improvement, else mild\n                    if improved:\n                        sigma = max(self.min_sigma, sigma * (0.82 if strategy == 'surrogate' else 0.86))\n                        v_rms *= 0.95\n                    else:\n                        sigma = min(self.max_sigma, sigma * 1.02)\n                else:\n                    # reject: small jitter to actor to diversify and decay echoes\n                    centers[actor] = np.minimum(np.maximum(actor_pos + 0.01 * avg_span * rng.randn(self.dim), lb), ub)\n                    f_centers[actor] = safe_eval(centers[actor]) if evals < self.budget else f_centers[actor]\n                    sigma = min(self.max_sigma, sigma * 1.004)\n                    echoes[actor] *= 0.92\n                    global_mom *= 0.96\n\n                # occasionally slightly rotate learned basis to avoid lock-in\n                if r > 0 and rng.rand() < 0.04:\n                    R = rng.randn(r, r) * 0.04\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(r) + R)\n                        U = U.dot(Qr)\n                        Q2, _ = np.linalg.qr(U)\n                        U = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed when global stagnation occurs\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    # reseed a subset of actors around the best found\n                    jitter = max(0.04 * avg_span, 1.2 * sigma)\n                    n_reseed = min(len(centers), max(1, int(0.12 * len(centers))))\n                    for k in range(n_reseed):\n                        centers[k] = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                        f_centers[k] = safe_eval(centers[k]) if evals < self.budget else f_centers[k]\n                    # inflate sigma a bit for escape\n                    sigma = min(self.max_sigma, sigma * 1.5)\n                    # reset echoes and momentum\n                    echoes *= 0.0\n                    global_mom[:] = 0.0\n                    # rebuild basis randomly to encourage new directions\n                    if r > 0:\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        U = Q[:, :r]\n                        eigvals = np.full(r, sigma * sigma)\n                        tau = np.maximum(1e-8, np.sqrt(eigvals))\n                    # local probes around best\n                    reseed_local = min(6, self.budget - evals)\n                    for _ in range(reseed_local):\n                        x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None:\n                            break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # prune worst actors occasionally, replace by samples near best to keep ensemble focused\n            if gen % max(3, int(10 - np.log1p(self.dim))) == 0 and len(centers) > 2:\n                # keep best half\n                idx_sorted = np.argsort(f_centers)\n                keep = max(2, len(centers) // 2)\n                survivors = idx_sorted[:keep]\n                new_centers = centers[survivors].copy()\n                new_f = f_centers[survivors].copy()\n                # re-create others by sampling around best-known point\n                while new_centers.shape[0] < len(centers):\n                    x_new = np.minimum(np.maximum(x_best + 0.08 * avg_span * rng.randn(self.dim), lb), ub)\n                    fx_new = safe_eval(x_new)\n                    if fx_new is None:\n                        break\n                    new_centers = np.vstack([new_centers, x_new])\n                    new_f = np.concatenate([new_f, [fx_new]])\n                centers = new_centers\n                f_centers = new_f\n                echoes = np.zeros((centers.shape[0], self.dim))\n\n        # return best found\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ARES scored 0.213 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a6173c49-f31a-4805-8ee3-5072a52dea0b", "operator": null, "metadata": {"aucs": [0.1396956240210958, 0.17847172673562217, 0.2817635241239368, 0.25710141379119256, 0.21846296662023623, 0.2419972024681485, 0.22652175143938036, 0.2269120634595856, 0.20814309410990706, 0.14787222537471212]}, "task_prompt": ""}
{"id": "b95e8d40-b9bb-4139-9c0b-598c6e36a31e", "fitness": 0.2576084719788981, "name": "SLoWaR", "description": "SLoWaR builds and continually refreshes a low-rank search manifold (default rank ≈ dim//6, archive size ≥ max(8·dim,80)) via SVD on recent samples and maintains orthonormal basis B with per-component scales (sub_scale, trust_vec) for correlated, anisotropic exploration. It mixes several proposal strategies — damped quadratic surrogate in the subspace, low-rank Gaussian moves, radial probes toward the best, coordinate tweaks, heavy‑tailed Cauchy escapes, mirror moves, and a default Gaussian — and adapts their selection probabilities online with a softmax over learned weights (alpha_strat≈0.12) driven by a simple reward signal. Per-dimension step normalization (sigma_diag) is tracked with a high‑beta RMS (rms_beta=0.90) and combined with a global sigma (initial 0.25·avg_span) that is shrunk on improvements or modestly inflated on uphill acceptance; momentum (v_mom) and strategy-specific learning rates control mean updates. Robustness features include simulated‑annealing style uphill acceptance (temperature decays with budget), opportunistic reseed on stagnation, small random rotations/perturbations of the manifold, and guarded numerical fallbacks to avoid premature lock‑in.", "code": "import numpy as np\n\nclass SLoWaR:\n    \"\"\"\n    SLoWaR: Stochastic Low-rank Adaptive Restart\n\n    One-line idea:\n      Maintain an adaptive low-rank manifold from recent samples and mix multiple\n      proposal strategies whose probabilities are adapted online by simple reward\n      signals; use a damped-quadratic surrogate in the subspace, low-rank Gaussian\n      moves, radial intensification, coordinate tweaks, Cauchy heavy-tail escapes,\n      mirror reflections, and a default Gaussian. Opportunistic reseed and small\n      manifold perturbations avoid premature lock-in.\n\n    Main tunable parameters (defaults chosen differently from MAHRS):\n      - budget, dim: required.\n      - rng_seed: random seed.\n      - pop: batch candidates per generation (default 16).\n      - rank: low-rank manifold dimension (default max(1, dim//6)).\n      - archive_size: number of recent samples retained (default max(8*dim, 80)).\n      - init_sigma_mult: initial global scale multiplier relative to search-span (default 0.25).\n      - rms_beta: EMA beta for per-dimension RMS (default 0.90).\n      - temp_init: initial temperature multiplier for uphill acceptance (default 0.7).\n      - dir_refresh: generations between manifold refresh (default 8).\n      - min_sigma / max_sigma: bounds for sigma and sigma_diag (default 1e-9, 3.0).\n      - strategy learning: strategy weights adapt with smoothing alpha_strat (0.12).\n    \"\"\"\n\n    def __init__(self, budget, dim, rng_seed=None,\n                 pop=16, rank=None, archive_size=None,\n                 init_sigma_mult=0.25, rms_beta=0.90, temp_init=0.7, dir_refresh=8,\n                 min_sigma=1e-9, max_sigma=3.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.rank = rank if rank is not None else max(1, self.dim // 6)\n        self.archive_size = archive_size if archive_size is not None else max(8 * self.dim, 80)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.rms_beta = float(rms_beta)\n        self.temp_init = float(temp_init)\n        self.dir_refresh = int(dir_refresh)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n        # strategy list (order matters for indices)\n        self.strategies = ['surrogate', 'lowrank', 'radial', 'coord', 'cauchy', 'mirror', 'gauss']\n        # initial (unnormalized) weights -> will be normalized online\n        self.strat_weights = np.array([1.6, 2.0, 1.4, 1.0, 0.6, 0.8, 1.6], dtype=float)\n        self.alpha_strat = 0.12   # smoothing for strategy weight adaptation\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds (use func.bounds if present)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial mean m: random within bounds\n        m = rng.uniform(lb, ub, size=self.dim)\n\n        # global sigma and per-dim diag scale\n        sigma = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        sigma_diag = np.full(self.dim, sigma)\n\n        # RMS accumulator and momentum (different smoothing)\n        v_rms = np.full(self.dim, 1e-8)\n        v_mom = np.zeros(self.dim)\n\n        # low-rank manifold init\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()            # orthonormal basis, columns are basis vectors\n            sub_scale = np.full(r, sigma / np.sqrt(max(1, r)) * 0.9)\n            trust_vec = np.full(r, sigma * 1.1)\n        else:\n            B = np.zeros((self.dim, 0))\n            sub_scale = np.array([])\n            trust_vec = np.array([])\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # safe evaluate wrapper ensures budget not exceeded\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            if len(X_arch) > self.archive_size:\n                del X_arch[0]; del f_arch[0]\n            return fx\n\n        # initial seeding to fill the archive a bit\n        seed0 = min(self.pop * 4, max(12, int(self.budget // 120)))\n        for _ in range(seed0):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        # ensure at least one eval\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(10, int(0.04 * self.budget))\n\n        # helper: refresh manifold basis using recent archive + small EMA on singulars\n        svals_ema = None\n        def refresh_basis():\n            nonlocal B, sub_scale, trust_vec, r, svals_ema\n            if len(X_arch) < max(6, r + 2) or r == 0:\n                return\n            K = min(len(X_arch), self.archive_size)\n            Xr = np.asarray(X_arch[-K:])\n            meanX = Xr.mean(axis=0)\n            S = (Xr - meanX)\n            try:\n                # economy SVD on the centered samples\n                U_s, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(r, Vt.shape[0])\n                if r_eff > 0:\n                    B_new = Vt[:r_eff].T\n                    # softer blend than MAHRS, favour stability\n                    alpha = 0.10\n                    if B.shape[1] == r_eff:\n                        B = (1.0 - alpha) * B + alpha * B_new\n                    else:\n                        B = B_new.copy()\n                    # orthonormalize\n                    Q, _ = np.linalg.qr(B)\n                    B = Q[:, :r_eff]\n\n                    # update scales / trust with small EMA on singular values\n                    if svals_ema is None:\n                        svals_ema = svals[:r_eff].copy()\n                    else:\n                        svals_ema = 0.92 * svals_ema + 0.08 * svals[:r_eff]\n\n                    # define subspace scales and trust by svals_ema with different mapping\n                    sub_scale = np.maximum(1e-12, 0.98 * (sub_scale[:r_eff] if sub_scale.shape[0] >= r_eff else np.full(r_eff, sigma / np.sqrt(max(1, r_eff)))) \\\n                                           + 0.02 * (svals_ema / (np.sqrt(r_eff) + 1e-12)))\n                    trust_vec = np.maximum(1e-12, 0.97 * (trust_vec[:r_eff] if trust_vec.shape[0] >= r_eff else np.full(r_eff, sigma)) \\\n                                          + 0.03 * (svals_ema + 1e-12))\n            except Exception:\n                pass\n\n        # helper: select a strategy index via softmax of weights\n        def pick_strategy():\n            probs = np.exp(self.strat_weights - np.max(self.strat_weights))\n            probs = probs / (probs.sum() + 1e-12)\n            idx = int(rng.choice(len(self.strategies), p=probs))\n            return idx, self.strategies[idx]\n\n        # main loop: generate candidates in batches until budget exhausted\n        while evals < self.budget:\n            gen += 1\n\n            # periodic manifold refresh\n            if gen % self.dir_refresh == 0:\n                refresh_basis()\n\n            # dynamic temperature schedule: larger early, decaying\n            T = self.temp_init * sigma * avg_span * max(1e-12, (1.0 - evals / max(1.0, self.budget)))\n\n            # produce up to pop candidates\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                idx_strat, strategy = pick_strategy()\n                x_cand = None\n                step = None\n                f_c = None\n\n                # strategy implementations (different equations/parameters from MAHRS)\n                if strategy == 'cauchy':\n                    # heavy-tailed Cauchy escape with scaled student-t-like rescaling\n                    z = rng.standard_cauchy(size=self.dim)\n                    # guard against extremely large tails via percentile rescale\n                    clipval = max(1e-12, np.percentile(np.abs(z), 85))\n                    z = z / (clipval + 1e-12)\n                    step = 4.2 * sigma * z + 0.2 * v_mom\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                elif strategy == 'surrogate' and r > 0 and len(X_arch) >= max(12, 5 * r):\n                    # build a damped quadratic surrogate in the low-rank subspace\n                    Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                    Fr = np.asarray(f_arch[-Xr.shape[0]:])\n                    Z = (Xr - m).dot(B)  # (n_samples, r)\n                    n = Z.shape[0]\n                    # features: [1, z_i (r), z_i^2 (r)] - diagonal quadratic\n                    F = np.ones((n, 1 + r + r))\n                    F[:, 1:1 + r] = Z\n                    F[:, 1 + r:] = Z * Z\n                    lam = 1e-5 * (1.0 + np.var(Fr))\n                    try:\n                        FtF = F.T.dot(F)\n                        theta = np.linalg.solve(FtF + lam * np.eye(FtF.shape[0]), F.T.dot(Fr))\n                        c = theta[0]\n                        b = theta[1:1 + r]\n                        q = theta[1 + r:1 + r + r]\n                        # map q to positive curvature with damping factor depending on median scale\n                        q_pos = np.maximum(np.abs(q), 1e-7)\n                        eta = 0.18 * np.median(q_pos)\n                        z_star = - b / (q_pos + eta + 1e-12)\n                        # clip by trust but allow a bit larger exploration than MAHRS\n                        z_star = np.clip(z_star, -4.0 * trust_vec, 4.0 * trust_vec)\n                        x_pred = np.minimum(np.maximum(m + B.dot(z_star), lb), ub)\n                        f_pred = safe_eval(x_pred)\n                        if f_pred is None:\n                            break\n                        x_cand = x_pred\n                        f_c = f_pred\n                        step = x_cand - m\n                    except Exception:\n                        # fallback to gauss below\n                        pass\n\n                elif strategy == 'lowrank' and r > 0:\n                    # low-rank Gaussian but with correlated multipliers and directional bias\n                    z = rng.randn(r)\n                    # include an anisotropic scaling favoring top components\n                    comp_factor = 1.0 + 0.6 * (np.arange(r)[::-1] / max(1, r))\n                    step = B.dot(z * sub_scale * comp_factor) + 0.6 * (sigma_diag * rng.randn(self.dim)) + 0.18 * v_mom\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                elif strategy == 'radial' and len(X_arch) > 0:\n                    # radial probe from mean towards best with randomized damped radius\n                    d = x_best - m\n                    nd = np.linalg.norm(d) + 1e-12\n                    dirv = d / nd\n                    r_probe = (0.4 + rng.rand() * 1.8) * max(0.7 * sigma, 0.45 * nd)\n                    step = dirv * r_probe + 0.12 * v_mom + 0.05 * rng.randn(self.dim) * sigma\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                elif strategy == 'coord':\n                    # coordinate tweak: pick several coordinates proportional to variance\n                    if len(X_arch) >= 6:\n                        Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                        var = np.var(Xr, axis=0) + 1e-12\n                    else:\n                        var = sigma_diag + 1e-12\n                    probs = var / var.sum()\n                    # tweak 1..3 coordinates\n                    k = 1 + (rng.rand() < 0.25) + (rng.rand() < 0.12)\n                    idxs = rng.choice(self.dim, size=k, replace=False, p=probs)\n                    step = np.zeros(self.dim)\n                    for j in idxs:\n                        step[j] = sigma_diag[j] * (0.35 + rng.rand() * 1.8) * (1.0 if rng.rand() < 0.5 else -1.0)\n                    x_try = np.minimum(np.maximum(m + step, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try\n                    f_c = f_try\n\n                elif strategy == 'mirror' and len(X_arch) >= 6:\n                    # mirror of a recent poor sample with random scaling\n                    idx_local = int(np.argmax(f_arch[-min(len(f_arch), 24):]))\n                    x_worst = np.asarray(X_arch[-min(len(X_arch), 24):][idx_local])\n                    step = (m - x_worst) * (0.9 + 0.6 * rng.rand()) + 0.18 * rng.randn(self.dim) * sigma\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                else:\n                    # default gaussian exploration\n                    eps = rng.randn(self.dim)\n                    step = sigma_diag * eps + 0.18 * v_mom\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # safety: if no evaluation done, continue\n                if f_c is None:\n                    break\n\n                # update best & stagnation counter\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c)\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # compute reward: improvement relative to robust baseline\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                # reward scaled to favor close and informative improvements\n                reward = raw_reward / (sigma * step_norm + 1e-12)\n\n                # adapt per-dim RMS for sigma_diag (different weighting)\n                sq = (step / (sigma + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq\n                sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-9), self.min_sigma, self.max_sigma)\n\n                # update subspace scales/trust (slightly different rule)\n                if step is not None and r > 0:\n                    projs = B.T.dot(step)\n                    abs_projs = np.abs(projs)\n                    if abs_projs.size > 0 and abs_projs.sum() > 0:\n                        idxp = int(np.argmax(abs_projs))\n                        sub_scale = np.clip(0.985 * sub_scale + 0.015 * (np.abs(projs) + 1e-9),\n                                            self.min_sigma, self.max_sigma)\n                        trust_vec[idxp] = 0.985 * trust_vec[idxp] + 0.015 * (abs_projs[idxp] + 1e-9)\n\n                # acceptance decision: improved or probabilistic uphill with temperature T\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    deltaE = f_c - f_best\n                    if deltaE <= 0:\n                        accept = True\n                    else:\n                        if rng.rand() < np.exp(-deltaE / (T + 1e-12)):\n                            accept = True\n\n                if accept:\n                    # strategy dependent learning rates (different numbers)\n                    if strategy == 'surrogate':\n                        lr = 0.92\n                    elif strategy == 'lowrank':\n                        lr = 0.48\n                    elif strategy == 'radial':\n                        lr = 0.62\n                    elif strategy == 'coord':\n                        lr = 0.44\n                    elif strategy == 'cauchy':\n                        lr = 0.20\n                    elif strategy == 'mirror':\n                        lr = 0.50\n                    else:\n                        lr = 0.34\n\n                    delta = (x_cand - m)\n                    # trust clip on mean move using RMS-based trust (different formula)\n                    trust = 5.0 * sigma * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n\n                    # update mean and momentum\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                    v_mom = 0.88 * v_mom + 0.12 * delta\n\n                    # adapt sigma: shrink/inflate based on reward and strategy\n                    if improved:\n                        shrink = 0.86 if strategy in ('surrogate', 'lowrank') else 0.88\n                        # mix shrink with reward-driven extra shrink (cap)\n                        sigma = max(self.min_sigma, sigma * (shrink ** (1.0 + min(1.0, reward * 8.0))))\n                        v_rms *= 0.95\n                    else:\n                        # uphill acceptance: modest inflation proportional to reward\n                        sigma = min(self.max_sigma, sigma * (1.02 + 0.12 * min(1.0, reward)))\n                else:\n                    # reject: small jitter, small sigma inflation, reduce momentum\n                    m = np.minimum(np.maximum(m + 0.008 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma = min(self.max_sigma, sigma * 1.004)\n                    v_mom *= 0.975\n\n                # adapt strategy weights: increase weight for strategies that produced reward on accept\n                # small positive update for accepted proposals, otherwise slight decay\n                if accept and reward > 1e-12:\n                    self.strat_weights[idx_strat] = (1.0 - self.alpha_strat) * self.strat_weights[idx_strat] + self.alpha_strat * (self.strat_weights[idx_strat] + 0.5 * min(3.0, reward))\n                else:\n                    # gentle decay to avoid overweighting stagnant strategies\n                    self.strat_weights[idx_strat] = self.strat_weights[idx_strat] * (1.0 - 0.015)\n\n                # small random orthonormal rotation to B occasionally\n                if r > 0 and rng.rand() < 0.038:\n                    R = rng.randn(r, r) * 0.04\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(r) + R)\n                        B = B.dot(Qr)\n                        Q2, _ = np.linalg.qr(B)\n                        B = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed around best when stagnating\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    jitter = max(0.05 * avg_span, 1.2 * sigma)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma = min(self.max_sigma, sigma * 1.7)\n                    v_mom = np.zeros(self.dim)\n                    # randomize manifold a bit\n                    if r > 0:\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :r]\n                        sub_scale = np.full(r, sigma / np.sqrt(max(1, r)))\n                        trust_vec = np.full(r, sigma)\n                    # local probes around best\n                    reseed = min(6, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.05 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None:\n                            break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # end generation loop\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SLoWaR scored 0.258 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a6173c49-f31a-4805-8ee3-5072a52dea0b", "operator": null, "metadata": {"aucs": [0.16198710814688388, 0.24361109677835313, 0.35229887877616495, 0.3022933880046007, 0.2601795916320494, 0.327193056064229, 0.23520111847210556, 0.2826070737916683, 0.2653061687183558, 0.1454072394045699]}, "task_prompt": ""}
{"id": "1bfac78d-546a-4c1e-9843-86a1602af03f", "fitness": 0.17802270158134953, "name": "SAMSARA", "description": "SAMSARA is a hybrid, population-style continuous optimizer that samples antithetic (mirrored) pairs from a composite search distribution made of a low‑rank adaptive subspace U (with per-component energies e) plus per‑dimension diagonal noise (sigma_diag) to capture both correlated and independent directions. It reduces variance and learns directionality by attributing paired gains to subspace coordinates (directional_buffer → energy reweighting of e), maintains a success_buffer of normalized successful steps and periodically refreshes U by PCA/SVD on that buffer (blended updates to avoid abrupt changes), and sometimes fits a local quadratic surrogate inside the subspace to propose a subspace minimizer. Global step sizes are adapted multiplicatively via a smoothed success probability p_succ (1/5‑like control with sigma_adapt_rate and succ_target), while per‑dimension scales use RMS accumulation (rms_beta) to form sigma_diag; mean moves are applied with momentum, trust‑clipping and probabilistic uphill acceptance (softmax selection + temperature), plus occasional heavy‑tailed jumps and opportunistic restarts to escape stagnation. Practicalities include bounded sampling in [lb,ub], initial seeding, archives for local fitting, FIFO buffers to limit memory, and conservative defaults (small initial sigma, moderate adaptivity) to balance exploration and exploitation.", "code": "import numpy as np\n\nclass SAMSARA:\n    \"\"\"\n    Subspace-Adaptive Multi-Scale Antithetic Recombination Algorithm (SAMSARA)\n\n    Key ideas:\n    - Maintain mean m, global scale sigma, per-dim sigma_diag (RMS-driven), low-rank basis U with energies e.\n    - Use antithetic (mirrored) pairs from the low-rank + diag noise model to reduce variance and estimate directional gains.\n    - Periodically fit a quadratic surrogate inside the low-rank subspace and propose the subspace minimizer.\n    - Adapt sigma multiplicatively via smoothed success probability (approx 1/5 rule),\n      adapt per-dim scales via RMS, reweight energies via softmax of pair gains, and update basis U via PCA on a success buffer.\n    - Use momentum (EMA of accepted deltas), trust-clipping of mean moves, occasional Cauchy jumps and opportunistic restarts.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop_base=None, rank=None,\n                 pca_period=12, buffer_size=None,\n                 sigma_init_mult=0.15,\n                 sigma_adapt_rate=0.22, succ_target=0.2,\n                 rms_beta=0.92, energy_lr=0.18,\n                 restart_frac=0.05, stagn_tol=5):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # population and subspace choices\n        self.pop_base = pop_base if pop_base is not None else max(6, int(4 + 2 * np.log(max(2, self.dim))))\n        self.rank = int(rank) if rank is not None else max(1, self.dim // 6)\n        self.pca_period = int(pca_period)\n        self.buffer_size = buffer_size if buffer_size is not None else max(8 * self.rank, 3 * self.rank + 10)\n\n        # adaptation params\n        self.sigma_init_mult = float(sigma_init_mult)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.succ_target = float(succ_target)\n        self.rms_beta = float(rms_beta)\n        self.energy_lr = float(energy_lr)\n\n        # restarts / stagnation\n        self.restart_frac = float(restart_frac)\n        self.stagn_tol = int(stagn_tol)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds support\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize mean, sigma, per-dim diag scale, RMS accumulator\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(1e-10, self.sigma_init_mult * avg_span)\n        sigma_diag = np.full(self.dim, sigma)\n        v_rms = np.full(self.dim, 1e-6)\n\n        # low-rank orthonormal basis U and per-component energies e\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :r].copy()\n            e = np.ones(r, dtype=float)\n        else:\n            U = np.zeros((self.dim, 0))\n            e = np.array([])\n\n        # momentum (accepted deltas)\n        v_mom = np.zeros(self.dim)\n\n        # archives and buffers\n        X_arch = []\n        f_arch = []\n        success_buffer = []  # normalized successful steps for PCA\n        directional_buffer = np.zeros(r) if r > 0 else np.array([])\n\n        # bookkeeping\n        evals = 0\n        pop = max(2, int(self.pop_base))\n        pca_period = max(1, self.pca_period)\n        buffer_size = int(self.buffer_size)\n        sigma_min = 1e-10\n        sigma_max_mult = 3.0\n\n        # initial seeding to populate archive\n        init_seed = min(pop, max(4, int(self.budget // 200)))\n        for _ in range(init_seed):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        best_idx = int(np.argmin(f_arch))\n        f_best = float(f_arch[best_idx])\n        x_best = X_arch[best_idx].copy()\n\n        # success smoothing for sigma adaptation\n        p_succ = 0.2\n\n        # stagnation tracking\n        stagn_count = 0\n        stagn_limit = max(5, int(self.restart_frac * max(1, self.budget)))\n\n        gen = 0\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(pop, remaining)\n            if lam <= 0:\n                break\n\n            # ensure mirroring: use even number for pairs when possible\n            use_pairs = (lam // 2) if lam >= 2 else 0\n            extra_single = lam - 2 * use_pairs\n\n            # current per-batch stats\n            batch_candidates = []\n            batch_f = []\n            batch_steps = []\n            batch_types = []\n            batch_success_mask = []\n\n            # antithetic paired sampling\n            for pidx in range(use_pairs):\n                if evals + 2 > self.budget:\n                    break\n\n                # sample in subspace + diag residual\n                if r > 0:\n                    # energy-weighted scaling\n                    sqrt_e = np.sqrt(np.maximum(e, 1e-12))\n                    z = rng.normal(size=r) * sqrt_e\n                    low = U.dot(z)\n                else:\n                    low = np.zeros(self.dim)\n\n                diag_noise = rng.normal(size=self.dim) * (sigma_diag * 0.95)\n                step = sigma * (low + diag_noise / (sigma + 1e-20))\n\n                # mirrored pair\n                x_plus = m + step\n                x_minus = m - step\n                # occasional long jump for one of the pair\n                if rng.rand() < 0.02:\n                    x_plus = rng.uniform(lb, ub, size=self.dim)\n                x_plus = np.minimum(np.maximum(x_plus, lb), ub)\n                x_minus = np.minimum(np.maximum(x_minus, lb), ub)\n\n                f_plus = float(func(x_plus)); evals += 1\n                f_minus = float(func(x_minus)); evals += 1\n\n                # append both\n                batch_candidates.append(x_plus.copy()); batch_f.append(f_plus); batch_steps.append(step.copy()); batch_types.append('mirror_plus')\n                batch_candidates.append(x_minus.copy()); batch_f.append(f_minus); batch_steps.append((-step).copy()); batch_types.append('mirror_minus')\n\n                # update archive FIFO\n                X_arch.append(x_plus.copy()); f_arch.append(f_plus)\n                X_arch.append(x_minus.copy()); f_arch.append(f_minus)\n                while len(X_arch) > max(200, 8 * self.dim):\n                    del X_arch[0]; del f_arch[0]\n\n                # update best and stagnation\n                improved_pair = False\n                if f_plus < f_best:\n                    f_best = f_plus; x_best = x_plus.copy(); improved_pair = True; stagn_count = 0\n                if f_minus < f_best:\n                    f_best = f_minus; x_best = x_minus.copy(); improved_pair = True; stagn_count = 0\n                if not improved_pair:\n                    stagn_count += 1\n\n                # directional gain: positive if +step better than -step\n                gain = (f_minus - f_plus)  # positive means +step better\n                if r > 0:\n                    # attribute gain to subspace coords via projection of step onto U\n                    proj = U.T.dot(step)\n                    if np.linalg.norm(proj) > 0:\n                        contrib = np.abs(proj)\n                        # accumulate weighted gains (sum)\n                        directional_buffer += np.maximum(0.0, gain) * contrib\n\n                # record successes into success_buffer (normalized)\n                if (f_plus <= f_best + 1e-16) or (f_minus <= f_best + 1e-16) or (gain > 0):\n                    norm_step = (step / (np.linalg.norm(step) + 1e-12))\n                    success_buffer.append(norm_step.copy())\n                    if len(success_buffer) > buffer_size:\n                        success_buffer.pop(0)\n\n            # optional extra single candidates (surrogate or random)\n            for _ in range(extra_single):\n                if evals >= self.budget:\n                    break\n                # sometimes propose subspace surrogate minimizer\n                do_surrogate = (r > 0 and len(X_arch) >= max(8, 4 * r) and rng.rand() < 0.18)\n                if do_surrogate:\n                    # build local subspace surrogate (ridge) using recent archive\n                    K = min(len(X_arch), 4 * max(8, r))\n                    Xr = np.asarray(X_arch[-K:])\n                    fr = np.asarray(f_arch[-K:])\n                    # center at current mean m\n                    Z = (Xr - m).dot(U)  # (K, r)\n                    # fit diag quadratic f ≈ c + b^T z + 0.5 * q * z^2\n                    # design matrix\n                    G = np.ones((K, 1 + r + r))\n                    G[:, 1:1 + r] = Z\n                    G[:, 1 + r:] = 0.5 * (Z ** 2)\n                    reg = 1e-6 * np.eye(G.shape[1])\n                    try:\n                        theta = np.linalg.lstsq(G.T.dot(G) + reg, G.T.dot(fr), rcond=None)[0]\n                        b = theta[1:1 + r]\n                        q = theta[1 + r:1 + r + r]\n                        qpos = np.maximum(q, 1e-6)\n                        u_star = - b / (qpos + 1e-12)\n                        # clip u_star magnitude\n                        max_sub = 6.0 * sigma\n                        u_norm = np.linalg.norm(u_star)\n                        if u_norm > max_sub:\n                            u_star = u_star * (max_sub / (u_norm + 1e-12))\n                        x_pred = m + U.dot(u_star)\n                        x_pred = np.minimum(np.maximum(x_pred, lb), ub)\n                        f_pred = float(func(x_pred)); evals += 1\n                        batch_candidates.append(x_pred.copy()); batch_f.append(f_pred); batch_steps.append(U.dot(u_star)); batch_types.append('surrogate')\n                        X_arch.append(x_pred.copy()); f_arch.append(f_pred)\n                        while len(X_arch) > max(200, 8 * self.dim):\n                            del X_arch[0]; del f_arch[0]\n                        if f_pred < f_best:\n                            f_best = f_pred; x_best = x_pred.copy(); stagn_count = 0\n                        else:\n                            stagn_count += 1\n                        # store normalized step\n                        if np.linalg.norm(u_star) > 1e-12:\n                            success_buffer.append((U.dot(u_star) / (np.linalg.norm(U.dot(u_star)) + 1e-12)).copy())\n                            if len(success_buffer) > buffer_size:\n                                success_buffer.pop(0)\n                    except Exception:\n                        # fallback to a random small probe\n                        x_r = np.minimum(np.maximum(m + sigma * 0.6 * rng.randn(self.dim), lb), ub)\n                        f_r = float(func(x_r)); evals += 1\n                        batch_candidates.append(x_r.copy()); batch_f.append(f_r); batch_steps.append(x_r - m); batch_types.append('rand_fallback')\n                        X_arch.append(x_r.copy()); f_arch.append(f_r)\n                        while len(X_arch) > max(200, 8 * self.dim):\n                            del X_arch[0]; del f_arch[0]\n                        if f_r < f_best:\n                            f_best = f_r; x_best = x_r.copy(); stagn_count = 0\n                        else:\n                            stagn_count += 1\n                else:\n                    # default single low-rank + diag probe or heavy-tailed occasionally\n                    if rng.rand() < 0.04:\n                        # heavy-tailed Cauchy jump\n                        z = rng.standard_cauchy(size=self.dim)\n                        z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                        x_try = np.minimum(np.maximum(m + 4.0 * sigma * z, lb), ub)\n                    else:\n                        if r > 0 and rng.rand() < 0.9:\n                            z = rng.randn(r) * np.sqrt(np.maximum(e, 1e-12))\n                            low = U.dot(z)\n                        else:\n                            low = 0.0\n                        diag_noise = rng.randn(self.dim) * (sigma_diag * 0.95)\n                        step = sigma * (low + diag_noise / (sigma + 1e-20))\n                        x_try = np.minimum(np.maximum(m + step, lb), ub)\n                    f_try = float(func(x_try)); evals += 1\n                    batch_candidates.append(x_try.copy()); batch_f.append(f_try); batch_steps.append(x_try - m); batch_types.append('single')\n                    X_arch.append(x_try.copy()); f_arch.append(f_try)\n                    while len(X_arch) > max(200, 8 * self.dim):\n                        del X_arch[0]; del f_arch[0]\n                    if f_try < f_best:\n                        f_best = f_try; x_best = x_try.copy(); stagn_count = 0\n                    else:\n                        stagn_count += 1\n                    # success buffer\n                    if f_try <= f_best + 1e-12:\n                        sstep = (x_try - m)\n                        if np.linalg.norm(sstep) > 1e-12:\n                            success_buffer.append((sstep / (np.linalg.norm(sstep) + 1e-12)).copy())\n                            if len(success_buffer) > buffer_size:\n                                success_buffer.pop(0)\n\n            # if no batch candidates (budget finished), break\n            if len(batch_f) == 0:\n                break\n\n            # selection: pick one candidate to influence mean using softmax on negative f (prefer small)\n            f_arr = np.asarray(batch_f)\n            fmin = np.min(f_arr)\n            # avoid degenerate std=0\n            fstd = float(np.std(f_arr)) + 1e-12\n            scores = np.exp(-(f_arr - fmin) / fstd)\n            probs = scores / np.sum(scores)\n            chosen_idx = rng.choice(len(batch_candidates), p=probs)\n            chosen_x = np.asarray(batch_candidates[chosen_idx])\n            chosen_f = float(batch_f[chosen_idx])\n            chosen_step = np.asarray(batch_steps[chosen_idx])\n\n            # probabilistic uphill acceptance (temperature decays slowly with evals)\n            temp = 0.6 * sigma * (1.0 - evals / max(1.0, self.budget))\n            accept = False\n            if chosen_f <= f_best:\n                accept = True\n            else:\n                if rng.rand() < np.exp(-max(0.0, chosen_f - f_best) / (temp + 1e-12)):\n                    accept = True\n\n            # move mean toward chosen_x with trust clipping and momentum\n            if accept:\n                # learning rate depends on type\n                typ = batch_types[chosen_idx]\n                if typ in ('surrogate',):\n                    eta = 0.6\n                elif typ.startswith('mirror'):\n                    eta = 0.34\n                elif typ == 'single':\n                    eta = 0.25\n                else:\n                    eta = 0.28\n                delta = chosen_x - m\n                trust = max(1e-12, 6.0 * sigma * np.sqrt(self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > trust:\n                    delta = delta * (trust / (dn + 1e-12))\n                # momentum update and apply\n                v_mom = 0.85 * v_mom + 0.15 * delta\n                m = np.minimum(np.maximum(m + eta * v_mom, lb), ub)\n            else:\n                # small exploratory jitter on reject\n                m = np.minimum(np.maximum(m + 0.015 * avg_span * rng.randn(self.dim), lb), ub)\n                v_mom = 0.98 * v_mom\n\n            # update per-dim RMS using all batch_steps\n            all_steps = np.asarray(batch_steps)\n            if all_steps.size > 0:\n                # normalize by sigma for scale invariance\n                sq = (all_steps / (sigma + 1e-20)) ** 2\n                # mean across steps\n                stat = np.mean(sq, axis=0)\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * stat\n                sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-12), 1e-12, sigma_max_mult * np.max(span))\n\n            # compute generation success: any candidate improved global best\n            gen_success = float(np.any(np.asarray(batch_f) < f_best + 1e-16))\n            # update smoothed success probability and sigma multiplicatively\n            p_succ = 0.9 * p_succ + 0.1 * gen_success\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, sigma_min, sigma_max_mult * np.max(span))\n\n            # directional energy update from directional_buffer\n            if r > 0:\n                if np.any(directional_buffer > 0):\n                    g = directional_buffer.copy()\n                    # softmax-like exponentiated reward\n                    g = g - g.max()\n                    new_weights = np.exp(g / (np.std(g) + 1e-12))\n                    new_weights /= (np.sum(new_weights) + 1e-12)\n                    # smooth multiplicative update toward new_weights but preserve geometric scale\n                    e = 0.88 * e + 0.12 * (new_weights * (np.sum(e) + 1e-12))\n                    e = np.clip(e, 1e-6, 1e6)\n                # decay directional buffer slowly\n                directional_buffer *= 0.4\n\n            # periodic PCA refresh of U from success_buffer\n            if (gen % pca_period == 0) and len(success_buffer) >= max(3, r):\n                B = np.asarray(success_buffer[-min(len(success_buffer), buffer_size):])\n                # center rows then SVD\n                Bc = B - np.mean(B, axis=0, keepdims=True)\n                try:\n                    U_s, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        U_new = Vt[:r_eff].T\n                        # blend to avoid abrupt changes\n                        alpha = 0.18\n                        if U.shape[1] == U_new.shape[1]:\n                            U = (1.0 - alpha) * U + alpha * U_new\n                        else:\n                            U = U_new.copy()\n                        # orthonormalize\n                        Q, _ = np.linalg.qr(U)\n                        U = Q[:, :r_eff]\n                        # slight renormalization of e based on singular values\n                        sv = S_s[:r_eff] if S_s.size >= r_eff else np.ones(r_eff)\n                        e = 0.9 * e[:r_eff] + 0.1 * (sv + 1e-8)\n                        # resize e if needed\n                        if e.shape[0] != U.shape[1]:\n                            e = np.ones(U.shape[1]) * np.median(e)\n                except Exception:\n                    pass\n\n            # opportunistic restart if stagnated for long\n            if stagn_count >= max(self.stagn_tol, stagn_limit) and evals < self.budget:\n                stagn_count = 0\n                # restart: re-center around best with jitter, inflate sigma, reset some statistics\n                jitter = max(0.04 * avg_span, 0.7 * sigma)\n                m = np.minimum(np.maximum(x_best + rng.randn(self.dim) * jitter, lb), ub)\n                sigma = max(sigma * 1.8, 0.2 * avg_span)\n                v_rms = np.full(self.dim, 1e-6)\n                sigma_diag = np.full(self.dim, sigma)\n                v_mom = np.zeros(self.dim)\n                success_buffer = []\n                directional_buffer = np.zeros(r)\n                # rebuild U randomly a bit\n                if r > 0:\n                    A = rng.randn(self.dim, r)\n                    Q, _ = np.linalg.qr(A)\n                    U = Q[:, :r]\n                    e = np.ones(r)\n\n            # safety: keep archive bounded\n            if len(X_arch) > max(1000, 40 * self.dim):\n                # keep most recent slice\n                keep = max(200, 8 * self.dim)\n                X_arch = X_arch[-keep:]\n                f_arch = f_arch[-keep:]\n\n        # finish\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SAMSARA scored 0.178 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a6173c49-f31a-4805-8ee3-5072a52dea0b", "operator": null, "metadata": {"aucs": [0.08553572247627028, 0.14826783405311628, 0.2534464056672079, 0.21719237428885874, 0.16045847638347666, 0.2131560337649543, 0.1892917809473733, 0.21786434065022475, 0.17352956356541893, 0.12148448401659406]}, "task_prompt": ""}
{"id": "8e39ec9f-6118-4540-87dd-4776fbf3f27a", "fitness": 0.37726566224104896, "name": "MC_PLS", "description": "The algorithm blends CMA-like adaptive sampling (covariance C, weighted elite mean m, controlled rank-one and covariance learning rates) with a momentum term v and per-coordinate scaling s_diag to inject directional bias and coordinate-wise step control, using antithetic normal draws and a safe Cholesky/eigendecomposition for stable sampling. Step-size sigma is budget-aware and adaptively tuned from a running success measure (sigma_adapt_rate, success_target), while population and archive sizes are chosen conservatively (small lam0, archive_k) to be sample-efficient. Exploration is driven by a small elite archive plus occasional heavy-tailed, archive-anchored global jumps (Cauchy/Levy-like, clipped and annealed via global_jump_prob and global_jump_shrink), periodic uniform injections, and stagnation-triggered restarts; promising jump candidates trigger budgeted local refinement. Exploitation is intensified by a Hooke–Jeeves style, budget-limited pattern search (local_budget_frac, local_initial_step, local_shrink) around good points and by nudging the global mean and covariance toward locally improved solutions.", "code": "import numpy as np\n\nclass MC_PLS:\n    \"\"\"\n    Momentum-Covariance Pattern-Levy Sampler (MC-PLS)\n\n    Combines:\n      - Momentum+covariance adaptive sampling with antithetic variance reduction (MCAS style),\n      - A small elite archive and archive-guided heavy-tailed global jumps (APLS style),\n      - Budget-aware Hooke-Jeeves coordinate pattern local searches on promising candidates,\n      - Adaptive global_jump probability driven by archive diversity and stagnation.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # sampling & adaptation hyper-params (sensible defaults)\n        self.pop_base = None\n        self.cov_update = 0.16\n        self.rank1 = 0.06\n        self.mom_beta = 0.8\n        self.s_diag_beta = 0.6\n        self.sigma_adapt_rate = 0.25\n        self.success_target = 0.2\n\n        # archive & global jump controls (inspired by APLS)\n        self.archive_size = None\n        self.global_jump_prob = 0.20\n        self.global_jump_shrink = 0.98  # shrink per major iteration\n        self.levy_clip = 1e3\n\n        # local search controls (Hooke-Jeeves style)\n        self.local_budget_frac = 0.03\n        self.local_pattern_factor = 1.5\n        self.local_shrink = 0.6\n        self.local_initial_step = 0.22  # fraction of avg span\n        self.local_min_step_frac = 1e-5\n\n        # diversification\n        self.uniform_inject_period = 23\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # adaptive archive size\n        if self.archive_size is None:\n            archive_k = max(3, min(10, max(4, int(6 * np.log1p(self.dim)))))\n        else:\n            archive_k = int(self.archive_size)\n\n        # population base\n        if self.pop_base is None:\n            lam0 = max(6, int(3 + 2 * np.log(max(2, self.dim))))\n        else:\n            lam0 = int(self.pop_base)\n        lam0 = min(lam0, max(2, self.budget))\n\n        # evaluation bookkeeping\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x) sorted ascending\n\n        def eval_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = np.minimum(np.maximum(x, lb), ub)\n            f = float(func(x))\n            evals += 1\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # archive maintenance\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((f, x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return f, x\n\n        # initial batch sampling to seed mean, covariance and archive\n        batch0 = min(lam0, self.budget - evals)\n        X0 = rng.uniform(lb, ub, size=(batch0, self.dim))\n        f0 = np.empty(batch0, dtype=float)\n        for i in range(batch0):\n            if evals >= self.budget:\n                break\n            res = eval_record(X0[i])\n            if res is None:\n                f0[i] = np.inf\n            else:\n                f0[i], X0[i] = res\n\n        if evals == 0:\n            # make at least one evaluation\n            res = eval_record(rng.uniform(lb, ub))\n            if res is None:\n                # no budget at all\n                self.f_opt = float(f_best)\n                self.x_opt = np.asarray(x_best) if x_best is not None else np.zeros(self.dim)\n                return self.f_opt, self.x_opt\n\n        # initialize mean from top half\n        valid_idxs = np.argsort(f0)[:max(1, batch0 // 2)]\n        elites0 = X0[valid_idxs]\n        mu0 = max(1, elites0.shape[0])\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 = w0 / np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0[:w0.shape[0]]).sum(axis=0)\n\n        # covariance, sigma, momentum and per-coordinate scale\n        bounds_scale = span\n        C = np.diag(((bounds_scale / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.18 * np.mean(bounds_scale))\n        v = np.zeros(self.dim, dtype=float)\n        s_diag = np.ones(self.dim, dtype=float)\n        p_succ = self.success_target\n        stagn_iters = 0\n        major_iter = 0\n\n        # safe cholesky/eig helper\n        def chol_safe(Cmat):\n            eps = 1e-12 * np.maximum(np.diag(Cmat), 1.0)\n            try:\n                A = np.linalg.cholesky(Cmat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(Cmat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        # heavy-tailed global jump anchored on archive\n        def global_jump(center, scale):\n            direction = rng.randn(self.dim)\n            norm = np.linalg.norm(direction) + 1e-12\n            direction /= norm\n            step_length = rng.standard_cauchy()\n            step_length = np.clip(step_length, -self.levy_clip, self.levy_clip)\n            step = direction * (float(scale) * avg_span * (0.4 + 0.6 * rng.rand()))\n            return center + step_length * step\n\n        # Hooke-Jeeves local search (budget-limited)\n        def local_search(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            step0 = max(1e-12, self.local_initial_step * avg_span * (0.7 + 0.6 * rng.rand()))\n            steps = np.full(self.dim, step0, dtype=float)\n            local_evals = 0\n            iter_limit = max(1, int(max(1, local_budget) // max(1, self.dim)))\n            iters = 0\n            min_step = self.local_min_step_frac * avg_span\n            while local_evals < local_budget and iters < iter_limit and np.any(steps > min_step):\n                iters += 1\n                improved = False\n                x_probe = base.copy()\n                x_probe_f = base_f\n                for i in range(self.dim):\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    # plus\n                    xp = x_probe.copy()\n                    xp[i] = np.minimum(xp[i] + steps[i], ub[i])\n                    res = eval_record(xp)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < x_probe_f:\n                        x_probe = xp.copy()\n                        x_probe_f = fp\n                        improved = True\n                        continue\n                    # minus\n                    xn = x_probe.copy()\n                    xn[i] = np.maximum(xn[i] - steps[i], lb[i])\n                    res = eval_record(xn)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < x_probe_f:\n                        x_probe = xn.copy()\n                        x_probe_f = fn\n                        improved = True\n                # pattern move\n                if improved and local_evals < local_budget and evals < self.budget:\n                    direction = x_probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + self.local_pattern_factor * direction\n                        xp = np.minimum(np.maximum(xp, lb), ub)\n                        res = eval_record(xp)\n                        local_evals += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < x_probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = x_probe.copy()\n                                base_f = x_probe_f\n                        else:\n                            base = x_probe.copy()\n                            base_f = x_probe_f\n                    else:\n                        base = x_probe.copy()\n                        base_f = x_probe_f\n                else:\n                    steps *= self.local_shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # main sampling loop\n        while evals < self.budget:\n            major_iter += 1\n            remaining = self.budget - evals\n            lam = min(lam0, remaining)\n            lam = max(2 if remaining >= 2 else 1, lam)\n\n            # prepare weights and cholesky\n            mu = max(1, lam // 2)\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n            W = weights.reshape(-1, 1)\n\n            A = chol_safe(C)\n\n            # antithetic sampling\n            half = lam // 2\n            Zpos = rng.normal(size=(half, self.dim))\n            Z = np.vstack([Zpos, -Zpos])\n            if lam % 2 == 1:\n                Z = np.vstack([Z, rng.normal(size=(1, self.dim))])\n\n            # directional momentum injection\n            vlen = np.linalg.norm(v) + 1e-20\n            v_unit = v / (vlen + 1e-20) if vlen > 0 else np.zeros_like(v)\n            dir_strength = 0.7 * (vlen / (1.0 + vlen))\n            s_scalar = rng.normal(scale=dir_strength, size=(Z.shape[0], 1))\n\n            Y = Z @ A.T\n            Y = Y + s_scalar * v_unit.reshape(1, -1)\n            Y = Y * s_diag.reshape(1, -1)\n\n            Xcand = m + sigma * Y\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate candidates one by one\n            lam_actual = Xcand.shape[0]\n            fc = np.full(lam_actual, np.inf, dtype=float)\n            for i in range(lam_actual):\n                if evals >= self.budget:\n                    break\n                fc[i] = float(func(Xcand[i]))\n                evals += 1\n                # update best/archive inline\n                if fc[i] < f_best:\n                    f_best = fc[i]\n                    x_best = Xcand[i].copy()\n                    # immediate archive insert\n                    if len(archive) < archive_k or fc[i] < archive[-1][0]:\n                        archive.append((float(fc[i]), Xcand[i].copy()))\n                        archive.sort(key=lambda t: t[0])\n                        if len(archive) > archive_k:\n                            archive.pop()\n\n            # truncate if budget ended mid-batch\n            valid = np.isfinite(fc)\n            if not np.all(valid):\n                Xcand = Xcand[valid]\n                fc = fc[valid]\n                lam_actual = fc.shape[0]\n                if lam_actual == 0:\n                    break\n\n            # generation best and improvement tracking\n            gen_best_idx = int(np.argmin(fc))\n            gen_best_f = float(fc[gen_best_idx])\n            gen_best_x = Xcand[gen_best_idx].copy()\n            improved = False\n            if gen_best_f < f_best:\n                # already handled above, but keep improved flag\n                improved = True\n\n            # selection of elites for updates\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:min(mu, Xcand.shape[0])]]\n\n            # compute normalized deltas and covariance update\n            deltas = (X_mu - m) / (sigma + 1e-20) if X_mu.shape[0] > 0 else np.zeros((0, self.dim))\n            if deltas.shape[0] > 0:\n                if deltas.shape[0] != weights.shape[0]:\n                    mu_eff = deltas.shape[0]\n                    w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if np.sum(w_eff) <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff = w_eff / np.sum(w_eff)\n                    Wd = w_eff.reshape(-1, 1)\n                    weighted_cov = (deltas * Wd).T @ deltas\n                    delta_mean = (Wd * deltas).sum(axis=0)\n                else:\n                    weighted_cov = (deltas * W).T @ deltas\n                    delta_mean = (W * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # update momentum and covariance\n            v = self.mom_beta * v + (1.0 - self.mom_beta) * delta_mean\n            rank_one = np.outer(v, v)\n            c_cov = float(self.cov_update)\n            c1 = float(self.rank1)\n            C = (1.0 - c_cov - c1) * C + c_cov * weighted_cov + c1 * rank_one\n            C = 0.5 * (C + C.T) + np.diag(np.maximum(np.diag(C), 1e-18))\n\n            # update coordinate scale\n            if deltas.shape[0] > 0:\n                stat = np.mean(deltas ** 2, axis=0)\n            else:\n                stat = 1e-6 * np.ones(self.dim)\n            s_diag = (self.s_diag_beta * s_diag +\n                      (1.0 - self.s_diag_beta) * np.sqrt(stat + 1e-20))\n            s_diag = np.clip(s_diag, 0.2, 5.0)\n\n            # update mean\n            if X_mu.shape[0] > 0:\n                if X_mu.shape[0] != weights.shape[0]:\n                    # recompute weighted mean for smaller set\n                    mu_eff = X_mu.shape[0]\n                    w_eff = np.log(mu_eff + 0.5) - np.log(np.arange(1, mu_eff + 1))\n                    w_eff = np.maximum(w_eff, 0.0)\n                    if np.sum(w_eff) <= 0:\n                        w_eff = np.ones_like(w_eff)\n                    w_eff = w_eff / np.sum(w_eff)\n                    m_new = (w_eff.reshape(-1, 1) * X_mu).sum(axis=0)\n                else:\n                    m_new = (W * X_mu).sum(axis=0)\n                m = m_new.copy()\n\n            # step-size adaptation\n            # consider improvement if generation produced a new global best (tracked earlier)\n            # we already updated f_best inline; check if gen_best improves previous recorded best\n            # For smoother behavior, treat any candidate better than median as small success\n            thr = np.median(fc) if fc.size > 0 else np.inf\n            gen_succ = float(np.mean(fc < thr))\n            p_succ = 0.85 * p_succ + 0.15 * (1.0 if gen_best_f < f_best else gen_succ)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, 1e-12, 2.0 * np.max(bounds_scale))\n\n            # stagnation tracking and archive-driven global jumps / local refinements\n            if len(archive) > 0:\n                # diversity measure between best and worst archive\n                if len(archive) >= 2:\n                    diversity = np.linalg.norm(archive[0][1] - archive[-1][1])\n                else:\n                    diversity = avg_span * 0.5\n                if diversity < 0.01 * avg_span + 1e-9:\n                    self.global_jump_prob = min(0.65, self.global_jump_prob + 0.03)\n                else:\n                    self.global_jump_prob = max(0.05, self.global_jump_prob * 0.995)\n\n            # occasionally perform an archive-guided heavy-tailed jump\n            if len(archive) > 0 and rng.rand() < self.global_jump_prob and evals < self.budget:\n                # choose anchor from archive (prefer best)\n                if rng.rand() < 0.75:\n                    anchor = archive[0][1]\n                else:\n                    anchor = archive[rng.randint(0, len(archive))]\n                    anchor = anchor[1] if isinstance(anchor, tuple) else anchor\n                scale = max(0.05, 1.0 - 0.01 * major_iter)\n                cand = global_jump(anchor, scale)\n                cand = np.minimum(np.maximum(cand, lb), ub)\n                res = eval_record(cand)\n                if res is not None:\n                    f_cand, cand = res\n                    # if promising, do a small local search around candidate\n                    threshold = archive[0][0] * 1.12 if len(archive) > 0 else np.inf\n                    if f_cand <= threshold and evals < self.budget:\n                        local_alloc = min(int(self.local_budget_frac * self.budget) * 3, self.budget - evals)\n                        local_alloc = max(1, local_alloc)\n                        f_after, x_after = local_search(cand, f_cand, local_alloc)\n                        if f_after < f_best:\n                            f_best = f_after\n                            x_best = x_after.copy()\n                            # re-center a bit: nudge mean to new promising location\n                            m = 0.6 * m + 0.4 * x_after\n                            # slightly tighten covariance\n                            C = 0.95 * C + 0.05 * np.diag(((bounds_scale / 8.0) ** 2).clip(min=1e-12))\n                            stagn_iters = 0\n\n            # periodic uniform injection to maintain diversity\n            if (major_iter % self.uniform_inject_period) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                res = eval_record(xu)\n                if res is not None:\n                    fu, xu = res\n                    # nudge mean away from overconfidence if injection is good\n                    if fu < f_best:\n                        f_best = fu\n                        x_best = xu.copy()\n                        m = 0.7 * m + 0.3 * xu\n                        stagn_iters = 0\n\n            # periodic local search around current best to intensify exploitation\n            if evals < self.budget and (major_iter % max(5, int(5 + np.log1p(self.dim))) == 0):\n                remaining = self.budget - evals\n                alloc = min(max(1, int(self.local_budget_frac * self.budget)), remaining)\n                f_after, x_after = local_search(x_best if x_best is not None else m, f_best, alloc)\n                if f_after < f_best:\n                    f_best = f_after\n                    x_best = x_after.copy()\n                    # inject to archive\n                    if len(archive) < archive_k or f_after < archive[-1][0]:\n                        archive.append((float(f_after), x_after.copy()))\n                        archive.sort(key=lambda t: t[0])\n                        if len(archive) > archive_k:\n                            archive.pop()\n                    # pull mean toward local improvement\n                    m = 0.5 * m + 0.5 * x_after\n                    # modestly decrease sigma to exploit\n                    sigma = max(1e-12, sigma * 0.85)\n                    stagn_iters = 0\n\n            # stagnation handling: if no improvement for a while, perform trust-region restart\n            if f_best < np.inf:\n                if stagn_iters >= max(20, int(0.02 * self.budget)):\n                    # restart around best with jitter\n                    stagn_iters = 0\n                    jitter_scale = max(0.08 * np.mean(bounds_scale), 0.6 * sigma)\n                    m = np.minimum(np.maximum(x_best + rng.randn(self.dim) * jitter_scale, lb), ub)\n                    C = np.diag(((bounds_scale / 6.0) ** 2).clip(min=1e-12))\n                    sigma = max(sigma * 1.4, 0.2 * np.mean(bounds_scale))\n                    v = np.zeros_like(v)\n                    s_diag = np.ones_like(s_diag)\n                else:\n                    stagn_iters += 1\n\n            # slowly shrink global jump aggressiveness as the run progresses\n            if major_iter % 10 == 0:\n                self.global_jump_prob = max(0.03, self.global_jump_prob * self.global_jump_shrink)\n\n        # finalize best\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MC_PLS scored 0.377 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "a6173c49-f31a-4805-8ee3-5072a52dea0b", "operator": null, "metadata": {"aucs": [0.08394829399065096, 0.14948790970876524, 0.5352656775513867, 0.897057020500041, 0.2535386702194632, 0.85627250030481, 0.23047670405744536, 0.3869772478338276, 0.24940920918770038, 0.13022338905639919]}, "task_prompt": ""}
{"id": "03c4a78b-1749-4b5d-9b52-08b0dc80cbce", "fitness": 0.18589832211583995, "name": "ACTEQS", "description": "1) The algorithm maintains an archive and an elite subset (elite_frac, archive_size) and seeds with a small random batch; elites produce a robust sqrt-covariance used for anisotropic sampling and for diversity/entropy measurements that adapt the global trust radius (step_scale between min_step and max_step).  \n2) It learns a low-rank PCA-like subspace (subrank default ≈ dim/6, refreshed every pca_refresh) and fits regularized quadratic surrogates inside that subspace (ridge solve, PD-regularization) to propose minimizers clipped by a trust region, falling back to linear/local fits when data are insufficient.  \n3) A lightweight quasi-Newton mechanism stores secant pairs in subspace (limited memory, ~40) and runs an L‑BFGS two‑loop in subspace to propose steps, while also providing coordinate-pattern probes on high-variance dimensions, elite-shaped Gaussian proposals, and occasional heavy‑tailed (Levy/Cauchy) escapes for global diversification.  \n4) Per-dimension RMS adaptation (rms_beta), momentum, taboo directions, probabilistic strategy mixing (prob_elite, prob_subquad, prob_pattern, prob_qn, prob_levy), simulated-annealing-like uphill acceptance (temperature T), small random rotations of the basis, and stagnation-triggered restarts together balance local refinement and global exploration.", "code": "import numpy as np\n\nclass ACTEQS:\n    \"\"\"\n    Adaptive Coordinate-Trust with Ensemble-Quadratic Surrogates (ACTEQS)\n\n    Main ideas:\n    - Maintain an archive and elite set. Learn a low-rank subspace (B) from recent archive.\n    - Fit a quadratic surrogate in that subspace (regularized) and propose its minimizer inside\n      an adaptive trust region. If insufficient data for full quadratic, fallback to linear/local fits.\n    - Maintain lightweight quasi-Newton (secant) memory in the subspace using finite-difference gradient\n      approximations from local linear regressions; apply L-BFGS style two-loop to propose a quasi-Newton step.\n    - Coordinate-pattern exploratory probes on the most sensitive coordinates (variance/slope heuristics).\n    - Elite-shaped anisotropic sampling via a robust sqrt-cov produced from elites.\n    - Entropy/diversity control: adjust trust radius up/down according to archive spread (encourage exploration if low diversity).\n    - Occasional heavy-tailed escapes and restarts when stagnation detected.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=12, subrank=None, elite_frac=0.12, init_step=0.12,\n                 rms_beta=0.92, pca_refresh=10, prob_elite=0.28,\n                 prob_subquad=0.22, prob_pattern=0.18, prob_qn=0.15,\n                 prob_levy=0.03, min_step=1e-8, max_step=5.0,\n                 archive_size=None, lb=-5.0, ub=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.subrank = subrank if subrank is not None else max(1, self.dim // 6)\n        self.elite_frac = float(elite_frac)\n        self.init_step = float(init_step)  # fraction of domain span\n        self.rms_beta = float(rms_beta)\n        self.pca_refresh = int(pca_refresh)\n        # strategy probabilities\n        self.prob_elite = float(prob_elite)\n        self.prob_subquad = float(prob_subquad)\n        self.prob_pattern = float(prob_pattern)\n        self.prob_qn = float(prob_qn)\n        self.prob_levy = float(prob_levy)\n        self.min_step = float(min_step)\n        self.max_step = float(max_step)\n        self.lb_user = lb\n        self.ub_user = ub\n        self.archive_size = archive_size if archive_size is not None else max(12 * self.dim, 200)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, float(self.lb_user))\n            ub = np.full(self.dim, float(self.ub_user))\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # internal state\n        m = rng.uniform(lb, ub, size=self.dim)        # search center\n        step_scale = max(self.min_step, self.init_step * avg_span)  # global trust radius (scalar)\n        step_diag = np.full(self.dim, step_scale)     # per-dim nominal step\n        v_rms = np.full(self.dim, 1e-6)               # RMS adapt per-dim\n        momentum = np.zeros(self.dim)\n\n        # low-rank subspace basis\n        r = min(self.subrank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()   # columns are orthonormal basis\n        else:\n            B = np.zeros((self.dim, 0))\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n        eliteK = max(3, int(np.ceil(self.elite_frac * max(50, self.budget / 8))))\n\n        # secant (quasi-Newton) memory in subspace: store pairs (s,z,y) where z are subspace coords\n        secant_memory = []  # list of dicts: {'s':z_step, 'y':grad_diff}\n\n        # taboo directions (failed)\n        taboo_dirs = []\n\n        # safe evaluation wrapper\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # trim archive\n            if len(X_arch) > self.archive_size:\n                del X_arch[0: len(X_arch) - self.archive_size]\n                del f_arch[0: len(f_arch) - self.archive_size]\n            return fx\n\n        # initial seeding: small latin-ish random batch\n        seed0 = min(self.pop * 4, max(20, int(self.budget // 200)))\n        for _ in range(seed0):\n            if evals >= self.budget: break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n        if len(f_arch) == 0 and evals < self.budget:\n            safe_eval(rng.uniform(lb, ub, size=self.dim))\n\n        # initialize best\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(12, int(0.03 * self.budget))\n\n        # helper: compute elites\n        def get_elites():\n            if len(X_arch) == 0:\n                return np.empty((0, self.dim)), np.empty((0,))\n            k = min(eliteK, len(X_arch))\n            idxs = np.argsort(f_arch)[:k]\n            Xe = np.asarray([X_arch[i].copy() for i in idxs])\n            Fe = np.asarray([f_arch[i] for i in idxs])\n            return Xe, Fe\n\n        # helper: robust sqrt cov from elites\n        def sqrt_cov_from(Xe):\n            if Xe.size == 0:\n                return np.eye(self.dim)\n            C = np.cov(Xe.T) + 1e-10 * np.eye(self.dim)\n            try:\n                w, V = np.linalg.eigh(C)\n                w = np.maximum(w, 1e-12)\n                S = V.dot(np.diag(np.sqrt(w))).dot(V.T)\n                return S\n            except Exception:\n                U, s, Vt = np.linalg.svd(C)\n                return U.dot(np.diag(np.sqrt(s))).dot(Vt)\n\n        # helper: refresh subspace basis via PCA-like on recent archive (blended)\n        def refresh_subspace():\n            nonlocal B, r\n            if r == 0 or len(X_arch) < (4 + r):\n                return\n            K = min(len(X_arch), self.archive_size)\n            Xr = np.asarray(X_arch[-K:])\n            M = Xr.mean(axis=0)\n            S = (Xr - M)\n            try:\n                U, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(r, Vt.shape[0])\n                if r_eff <= 0:\n                    return\n                B_new = Vt[:r_eff].T\n                # blend gently\n                alpha = 0.15\n                if B.shape[1] == r_eff:\n                    B = (1 - alpha) * B + alpha * B_new\n                else:\n                    B = B_new.copy()\n                Q, _ = np.linalg.qr(B)\n                B = Q[:, :r_eff]\n            except Exception:\n                pass\n\n        # helper: fit quadratic surrogate in r-dim subspace: f(m+ B z) ≈ c + g^T z + 0.5 z^T H z\n        # returns (z_star, predicted_value, H_reg, g) or (None, None, None, None) if not possible\n        def fit_subspace_quadratic_and_minimize(max_samples=200, reg=1e-6):\n            if r == 0 or len(X_arch) < (r + 6):\n                return None, None, None, None\n            K = min(len(X_arch), max_samples)\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(B)  # n x r coords around current m\n            n, rr = Z.shape\n            # Build design matrix for quadratic: [1, z_i (r), outer unique elements of z*z (r*(r+1)/2)]\n            # We'll parametrize symmetric H with indices.\n            tri_idx = []\n            for i in range(rr):\n                for j in range(i, rr):\n                    tri_idx.append((i, j))\n            p = 1 + rr + len(tri_idx)\n            if n < p:\n                return None, None, None, None\n            # build design\n            Phi = np.ones((n, p))\n            Phi[:, 1:1 + rr] = Z\n            col = 1 + rr\n            for (i, j) in tri_idx:\n                Phi[:, col] = Z[:, i] * Z[:, j]\n                col += 1\n            # ridge solve\n            try:\n                A = Phi.T.dot(Phi) + reg * np.eye(p)\n                b = Phi.T.dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1 + rr]\n                H_vec = coeff[1 + rr:]\n                # assemble H symmetric matrix\n                H = np.zeros((rr, rr))\n                idx = 0\n                for ii in range(rr):\n                    for jj in range(ii, rr):\n                        val = H_vec[idx]\n                        H[ii, jj] = val\n                        H[jj, ii] = val\n                        idx += 1\n                # regularize H to be PD\n                # try to make H_pos = H + mu * I with mu >= 0 small\n                eigs = np.linalg.eigvalsh(H)\n                min_eig = eigs[0]\n                mu = 0.0\n                if min_eig <= 1e-8:\n                    mu = (1e-6 - min_eig) + 1e-8\n                    H = H + mu * np.eye(rr)\n                # compute minimizer z* = - H^{-1} g\n                try:\n                    z_star = -np.linalg.solve(H, g)\n                except Exception:\n                    # fall back to pseudo-inverse\n                    z_star = -np.linalg.pinv(H).dot(g)\n                # clip by trust radius in subspace (norm of z relative to step_scale)\n                z_norm = np.linalg.norm(z_star)\n                max_z = step_scale * np.sqrt(rr) / (np.linalg.norm(B, ord=2) + 1e-12)\n                if z_norm > max_z:\n                    z_star = z_star * (max_z / (z_norm + 1e-12))\n                # predict value\n                f_pred = c + g.dot(z_star) + 0.5 * z_star.dot(H.dot(z_star))\n                return z_star, float(f_pred), H, g\n            except Exception:\n                return None, None, None, None\n\n        # helper: build approximate gradients at m by local linear regression in subspace (used for secants)\n        def approx_gradient_in_subspace(K= min(60, max(0, 60))):\n            # use recent samples in neighborhood of m\n            if r == 0:\n                return None\n            K = min(len(X_arch),  max(8, r+4,  min(self.archive_size, 80)))\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(B)\n            # weight by distance (closer samples more)\n            dists = np.linalg.norm(Z, axis=1) + 1e-12\n            w = np.exp(- (dists / (0.5 * step_scale + 1e-12))**2)\n            W = np.diag(w)\n            # design matrix for linear model f ≈ c + g^T z\n            Phi = np.hstack([np.ones((Z.shape[0],1)), Z])\n            try:\n                A = Phi.T.dot(W).dot(Phi) + 1e-8 * np.eye(1 + r)\n                b = Phi.T.dot(W).dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                g = coeff[1:1+r]\n                return g\n            except Exception:\n                return None\n\n        # helper: L-BFGS two-loop in subspace using secant_memory to propose z step\n        def lbfgs_step_in_subspace(gk, max_norm=None):\n            if gk is None or len(secant_memory) == 0:\n                return None\n            q = gk.copy()\n            alphas = []\n            rhos = []\n            for pair in reversed(secant_memory[-8:]):\n                s = pair['s']  # z step\n                y = pair['y']  # grad diff\n                rho = 1.0 / (np.dot(y, s) + 1e-12)\n                rhos.append(rho)\n                alpha = rho * np.dot(s, q)\n                alphas.append(alpha)\n                q = q - alpha * y\n            # initial H0: scalar times identity using yi^T si / (yi^T yi)\n            if len(secant_memory) > 0:\n                last = secant_memory[-1]\n                s = last['s']; y = last['y']\n                gamma = max(1e-6, np.dot(s, y) / (np.dot(y, y) + 1e-12))\n            else:\n                gamma = 1.0\n            r = gamma * q\n            for i, pair in enumerate(secant_memory[-8:]):\n                s = pair['s']; y = pair['y']\n                rho = rhos[len(rhos)-1 - i]\n                alpha = alphas[len(alphas)-1 - i]\n                beta = rho * np.dot(y, r)\n                r = r + s * (alpha - beta)\n            step_z = -r\n            if max_norm is not None:\n                nrm = np.linalg.norm(step_z)\n                if nrm > max_norm:\n                    step_z = step_z * (max_norm / (nrm + 1e-12))\n            return step_z\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n\n            # periodic refresh subspace\n            if gen % self.pca_refresh == 0:\n                refresh_subspace()\n\n            Xe, Fe = get_elites()\n            S_sqrt = sqrt_cov_from(Xe) if Xe.size else np.eye(self.dim)\n\n            # measure spread/entropy-like diversity (use eigenvalues of cov of archive)\n            diversity = 0.0\n            if len(X_arch) >= 4:\n                try:\n                    Cfull = np.cov(np.asarray(X_arch).T) + 1e-12 * np.eye(self.dim)\n                    ev = np.linalg.eigvalsh(Cfull)\n                    ev = np.maximum(ev, 1e-16)\n                    # Shannon-like measure\n                    p = ev / np.sum(ev)\n                    diversity = -np.sum(p * np.log(p + 1e-12))\n                except Exception:\n                    diversity = 0.0\n\n            # adapt trust based on diversity: if diversity low -> enlarge to escape; if high -> shrink to refine\n            if diversity < 0.6:\n                step_scale = min(self.max_step, step_scale * 1.02)\n            else:\n                step_scale = max(self.min_step, step_scale * 0.997)\n\n            # temperature for uphill acceptance\n            T = 1e-8 + 0.6 * step_scale * max(1e-12, 1.0 - (evals / max(1.0, self.budget)))\n\n            # produce batch\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget: break\n                p = rng.rand()\n                x_cand = None; f_c = None; strategy = 'jitter'; step = None\n\n                # heavy tail escape\n                if p < self.prob_levy:\n                    strategy = 'levy'\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    step = 6.0 * step_scale * z\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # elite-shaped anisotropic sampling\n                elif p < self.prob_elite:\n                    strategy = 'elite'\n                    if Xe.size and rng.rand() < 0.7:\n                        center = Xe[rng.randint(0, Xe.shape[0])]\n                    else:\n                        center = m\n                    z = rng.randn(self.dim)\n                    step = 1.3 * step_scale * S_sqrt.dot(z) + 0.12 * momentum\n                    # discourage taboo\n                    if len(taboo_dirs) > 0:\n                        for td in taboo_dirs[-6:]:\n                            proj = np.dot(step, td) * td\n                            step = step - 0.45 * proj\n                    x_cand = np.minimum(np.maximum(center + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # subspace quadratic surrogate minimizer\n                elif p < (self.prob_elite + self.prob_subquad):\n                    strategy = 'subquad'\n                    z_star, f_pred, H, g = fit_subspace_quadratic_and_minimize()\n                    if z_star is not None:\n                        x_prop = np.minimum(np.maximum(m + B.dot(z_star), lb), ub)\n                        f_prop = safe_eval(x_prop)\n                        if f_prop is None:\n                            break\n                        x_cand = x_prop; f_c = f_prop; step = x_cand - m\n                        # store secant info via local gradient approximation differences later\n                        # update secant memory: approximate gradient at m and at x_prop then store difference\n                        g0 = approx_gradient_in_subspace()\n                        # we need to map to subspace grads; if g0 None fallback to finite diff approx along z_star\n                        if z_star is not None and g0 is not None:\n                            # approximate gradient at x_prop with shifted center\n                            m2 = m + B.dot(z_star)\n                            # compute gradient near m2 by local regression on points close to m2 (reuse archive temporarily)\n                            old_m = m.copy()\n                            m = m2  # temporarily shift to use approx_gradient_in_subspace\n                            g1 = approx_gradient_in_subspace()\n                            m = old_m\n                            if g0 is not None and g1 is not None:\n                                s = z_star.copy()\n                                y = (g1 - g0)\n                                if np.dot(s, y) > 1e-12:\n                                    secant_memory.append({'s': s, 'y': y})\n                                    if len(secant_memory) > 40:\n                                        secant_memory.pop(0)\n                    else:\n                        # fallback to jitter\n                        eps = rng.randn(self.dim)\n                        step = step_diag * eps + 0.12 * momentum\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # quasi-Newton in subspace using secant memory\n                elif p < (self.prob_elite + self.prob_subquad + self.prob_qn):\n                    strategy = 'qn'\n                    # get approximate gradient at m in subspace\n                    gsub = approx_gradient_in_subspace()\n                    if gsub is not None and len(secant_memory) > 0:\n                        # propose lbfgs step\n                        max_norm = step_scale * np.sqrt(r)\n                        z_step = lbfgs_step_in_subspace(gsub, max_norm=max_norm)\n                        if z_step is not None:\n                            x_prop = np.minimum(np.maximum(m + B.dot(z_step), lb), ub)\n                            f_prop = safe_eval(x_prop)\n                            if f_prop is None:\n                                break\n                            x_cand = x_prop; f_c = f_prop; step = x_cand - m\n                            # update secant memory with new grad estimate\n                            g1 = approx_gradient_in_subspace()\n                            if g1 is not None:\n                                s = z_step.copy()\n                                y = (g1 - gsub)\n                                if np.dot(s, y) > 1e-12:\n                                    secant_memory.append({'s': s, 'y': y})\n                                    if len(secant_memory) > 40:\n                                        secant_memory.pop(0)\n                        else:\n                            # fallback jitter\n                            eps = rng.randn(self.dim)\n                            step = step_diag * eps + 0.12 * momentum\n                            x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                            f_c = safe_eval(x_cand)\n                            if f_c is None:\n                                break\n                    else:\n                        # fallback to jitter\n                        eps = rng.randn(self.dim)\n                        step = step_diag * eps + 0.12 * momentum\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # coordinate-pattern probes (exploratory along top sensitive dims)\n                elif p < (self.prob_elite + self.prob_subquad + self.prob_qn + self.prob_pattern):\n                    strategy = 'pattern'\n                    # choose sensitive coords via per-dim variance in elites or archive\n                    var = np.var(np.asarray(X_arch), axis=0) if len(X_arch) > 1 else np.ones(self.dim)\n                    idxs = np.argsort(-var)[:max(1, min(6, self.dim//2))]\n                    # try pattern search: positive/negative along each selected coordinate until find improvement or exhaust small budget\n                    found = False\n                    for i in idxs:\n                        if evals >= self.budget: break\n                        dirvec = np.zeros(self.dim); dirvec[i] = 1.0\n                        a = 1.0 * step_scale\n                        for sign in (+1.0, -1.0):\n                            x_try = np.minimum(np.maximum(m + sign * a * dirvec, lb), ub)\n                            f_try = safe_eval(x_try)\n                            if f_try is None:\n                                break\n                            if f_try < (f_best - 1e-15):\n                                x_cand = x_try; f_c = f_try; step = x_cand - m\n                                found = True; break\n                        if found: break\n                    if not found and x_cand is None:\n                        # fallback jitter\n                        eps = rng.randn(self.dim)\n                        step = step_diag * eps + 0.12 * momentum\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # default jitter\n                else:\n                    strategy = 'jitter'\n                    eps = rng.randn(self.dim)\n                    step = step_diag * eps + 0.12 * momentum\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # ensure we have result\n                if f_c is None:\n                    break\n\n                # bookkeeping improvement\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c); x_best = x_cand.copy(); improved = True; stagn = 0\n                else:\n                    stagn += 1\n\n                # reward-like measure for RMS\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                reward = raw_reward / (step_scale * step_norm + 1e-12)\n\n                # update RMS adaptives\n                sq = ( (step / (step_scale + 1e-12)) ** 2 )\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq\n                step_diag = np.clip(step_scale / (np.sqrt(v_rms) + 1e-8), self.min_step, self.max_step)\n\n                # update tabu: if pattern or poor proposals along a direction repeatedly\n                if not improved and step is not None:\n                    sn = np.linalg.norm(step)\n                    if sn > 1e-12:\n                        td = step / sn\n                        if len(taboo_dirs) == 0 or np.min([abs(np.dot(td, t)) for t in taboo_dirs]) < 0.95:\n                            taboo_dirs.append(td)\n                            if len(taboo_dirs) > 48:\n                                taboo_dirs.pop(0)\n\n                # acceptance policy: always accept improvement; accept uphill occasionally\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    delta = f_c - f_best\n                    if delta <= 0:\n                        accept = True\n                    else:\n                        if rng.rand() < np.exp(-delta / (T + 1e-12)):\n                            accept = True\n\n                if accept:\n                    # learning rate scaling by strategy\n                    if strategy in ('subquad', 'qn'):\n                        lr = 0.85\n                    elif strategy == 'pattern':\n                        lr = 0.6\n                    elif strategy == 'elite':\n                        lr = 0.5\n                    elif strategy == 'levy':\n                        lr = 0.18\n                    else:\n                        lr = 0.33\n\n                    delta_m = (x_cand - m)\n                    # clip large jump\n                    trust = 8.0 * step_scale * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta_m)\n                    if dn > trust:\n                        delta_m = delta_m * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta_m, lb), ub)\n\n                    # momentum update\n                    momentum = 0.82 * momentum + 0.18 * delta_m\n\n                    # adapt step_scale: shrink on consistent improvements, expand on uphill accept\n                    if improved:\n                        step_scale = max(self.min_step, step_scale * 0.88)\n                        v_rms *= 0.97\n                    else:\n                        step_scale = min(self.max_step, step_scale * 1.02)\n\n                else:\n                    # reject: small perturbation and penalize momentum\n                    m = np.minimum(np.maximum(m + 0.015 * avg_span * rng.randn(self.dim), lb), ub)\n                    step_scale = min(self.max_step, step_scale * 1.006)\n                    momentum *= 0.96\n\n                # opportunistic small rotation of subspace basis to avoid lock-in\n                if r > 0 and rng.rand() < 0.05:\n                    R = rng.randn(r, r) * 0.05\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(r) + R)\n                        B = B.dot(Qr)\n                        Q2, _ = np.linalg.qr(B)\n                        B = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # stagnation restart\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    # reseed center near best, increase step_scale and clear momentum\n                    jitter = max(0.03 * avg_span, 2.0 * step_scale)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    step_scale = min(self.max_step, step_scale * 1.6)\n                    momentum = np.zeros(self.dim)\n                    # reinitialize subspace\n                    if r > 0:\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :r]\n                    # local refine around best\n                    reseed = min(8, self.budget - evals)\n                    for _ in range(reseed):\n                        if evals >= self.budget: break\n                        x = np.minimum(np.maximum(x_best + 0.045 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None: break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # end batch\n\n        # store results\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ACTEQS scored 0.186 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ba26f129-6da8-46bd-88ce-1bbc98bfec1b", "operator": null, "metadata": {"aucs": [0.07978394183982818, 0.15395867207284242, 0.27907953186260803, 0.21709636507501429, 0.17041868839120233, 0.23532074720681895, 0.19572691730231284, 0.19476340149135418, 0.17795031028984276, 0.15488464562657556]}, "task_prompt": ""}
{"id": "e9ae792a-19a6-4a4e-949e-327eb67d1af8", "fitness": 0.22272719472027055, "name": "AMMS", "description": "The design centers a robust medoid (archive member minimizing pairwise distances) as the search anchor and maintains a capped archive seeded with random samples to balance exploration and memory. Per-dimension adaptive scales are estimated with median absolute deviation and an EMA (bounded by min/max) to drive anisotropic Gaussian jitter, trust-clipped moves, momentum, and tabooing of failed coordinates for targeted local search. Global and directional exploration come from low-probability heavy-tailed Lévy jumps, weighted-elite low-rank subspace proposals (elite-weighted SVD in a sub_dim ≈ dim/6 space), and centroid/reflection pattern moves, while coordinate-wise quadratic (three-point parabola) probes enable efficient 1D refinement. A multiplicative temperature annealing with Metropolis-style uphill acceptance, scale shrink/expand on improvement/uphill, opportunistic reseeding and local refinement on stagnation, and sporadic subspace reorientation together provide robustness across many affine/noiseless BBOB problems.", "code": "import numpy as np\n\nclass AMMS:\n    \"\"\"\n    Adaptive Medoid-MAD Search (AMMS)\n\n    Main idea (one line): Robust medoid-centered ensemble using per-dimension MAD scales,\n    weighted-elite low-rank subspace proposals, coordinate parabola probes, and multiplicative\n    temperature annealing to explore Many Affine BBOB noiseless functions.\n\n    Primary tunable parameters (defaults chosen to differ from AOES):\n    - pop: number of candidates evaluated per generation (default 16)\n    - elite_frac: fraction of archive used as elites (default 0.15)\n    - init_scale: initial fraction of search width for step sizes (default 0.22)\n    - temp0, temp_decay: initial temperature and multiplicative decay per evaluation (default 0.8, 0.9992)\n    - ema_beta: EMA factor for MAD adapt (default 0.86)\n    - sub_dim: low-rank subspace dimension (default max(1, dim//6))\n    - levy_prob: probability of heavy-tailed jump (default 0.03)\n    - coord_prob: probability of doing coordinate parabola probe (default 0.18)\n    - pattern_prob: probability of centroid reflection/pattern move (default 0.12)\n    - min_scale/max_scale: bounds for per-dim scales\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=16, elite_frac=0.15, init_scale=0.22,\n                 temp0=0.8, temp_decay=0.9992, ema_beta=0.86,\n                 sub_dim=None, levy_prob=0.03, coord_prob=0.18,\n                 pattern_prob=0.12, min_scale=1e-8, max_scale=6.0,\n                 archive_size_factor=12):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.elite_frac = float(elite_frac)\n        self.init_scale = float(init_scale)\n        self.temp0 = float(temp0)\n        self.temp_decay = float(temp_decay)\n        self.ema_beta = float(ema_beta)\n        self.sub_dim = sub_dim if sub_dim is not None else max(1, self.dim // 6)\n        self.levy_prob = float(levy_prob)\n        self.coord_prob = float(coord_prob)\n        self.pattern_prob = float(pattern_prob)\n        self.min_scale = float(min_scale)\n        self.max_scale = float(max_scale)\n        self.archive_size_factor = int(archive_size_factor)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling (default -5..5)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initial medoid center (sample uniformly)\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # safe evaluation wrapper: respects budget and bounds\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # cap archive size to keep memory reasonable\n            cap = max(40, self.archive_size_factor * self.dim)\n            if len(X_arch) > cap:\n                X_arch.pop(0); f_arch.pop(0)\n            return fx\n\n        # seed initial archive with random samples\n        seed0 = min(self.pop * 6, max(30, int(self.budget // 150)))\n        for _ in range(seed0):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        # ensure at least one eval\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        # initialize best and medoid center\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # medoid: pick archive member minimizing sum distances\n        def medoid_center():\n            if len(X_arch) == 0:\n                return rng.uniform(lb, ub, size=self.dim)\n            # use a subset if archive large\n            K = min(len(X_arch), 120)\n            Xr = np.asarray(X_arch[-K:])\n            # compute pairwise distances to each candidate\n            dsum = np.sum(np.linalg.norm(Xr[:, None, :] - Xr[None, :, :], axis=2), axis=1)\n            return Xr[int(np.argmin(dsum))].copy()\n\n        m = medoid_center()\n\n        # per-dimension robust scale: median absolute deviation (MAD) with EMA\n        def compute_mad(Xr):\n            if Xr.shape[0] == 0:\n                return np.full(self.dim, self.init_scale * avg_span)\n            med = np.median(Xr, axis=0)\n            mad = np.median(np.abs(Xr - med), axis=0)\n            # fallback to small positive\n            mad = np.maximum(mad, 1e-12)\n            return mad\n\n        Xr = np.asarray(X_arch)\n        mad_init = compute_mad(Xr) if Xr.size else np.full(self.dim, self.init_scale * avg_span)\n        mad_ema = mad_init.copy()\n        per_dim_scale = np.clip(mad_ema, self.min_scale, self.max_scale)\n\n        # momentum of accepted moves (EMA)\n        momentum = np.zeros(self.dim)\n\n        # taboo coordinates (indices) for recent failed coordinate probes\n        taboo_coords = []\n\n        # temperature for uphill acceptance\n        T = float(self.temp0)\n\n        # helper: get elites (by function value)\n        def elites():\n            if len(X_arch) == 0:\n                return np.empty((0, self.dim)), np.array([])\n            k = max(2, int(np.ceil(self.elite_frac * max(20, len(X_arch)))))\n            idx = np.argsort(f_arch)[:k]\n            Xe = np.asarray([X_arch[i].copy() for i in idx])\n            Fe = np.asarray([f_arch[i] for i in idx])\n            return Xe, Fe\n\n        # helper: random orthonormal subspace from weighted elite differences\n        def subspace_directions(Xe, Fe, k):\n            # Build direction matrix from (Xe - medoid) weighted by elite quality\n            if Xe.shape[0] == 0:\n                A = rng.randn(self.dim, k)\n                Q, _ = np.linalg.qr(A)\n                return Q[:, :k]\n            diffs = Xe - m  # n x dim\n            # weights: better elites (smaller f) get higher weight; shift by best\n            w = np.exp(-2.0 * (Fe - np.min(Fe)) / (np.std(Fe) + 1e-12))\n            W = (w / (np.sum(w) + 1e-12))[:, None]\n            D = (W * diffs).T  # dim x n\n            try:\n                # SVD and take top-k directions\n                U, s, Vt = np.linalg.svd(D, full_matrices=False)\n                if U.shape[1] >= k:\n                    return U[:, :k]\n                else:\n                    # pad with random\n                    A = rng.randn(self.dim, k - U.shape[1])\n                    Qp, _ = np.linalg.qr(A)\n                    return np.concatenate([U, Qp], axis=1)[:, :k]\n            except Exception:\n                A = rng.randn(self.dim, k)\n                Q, _ = np.linalg.qr(A)\n                return Q[:, :k]\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(10, int(0.04 * self.budget))\n\n        # main loop: evaluate candidates until budget exhausted\n        while evals < self.budget:\n            gen += 1\n            # refresh medoid every few generations\n            if gen % 3 == 0:\n                m = medoid_center()\n\n            Xe, Fe = elites()\n            U = subspace_directions(Xe, Fe, min(self.sub_dim, self.dim))\n\n            # candidate batch\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                strategy = 'jitter'\n                x_cand = None\n                f_c = None\n                step = None\n\n                # Levy heavy-tailed escape\n                if p < self.levy_prob:\n                    strategy = 'levy'\n                    z = rng.standard_cauchy(size=self.dim)\n                    # scale to robust quantile to avoid extreme overflow\n                    z = z / (np.percentile(np.abs(z), 85) + 1e-12)\n                    step = (2.5 * avg_span) * z\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # subspace weighted-elite proposal (weighted average of elite projections)\n                elif p < 0.5 and Xe.shape[0] >= 2:\n                    strategy = 'subspace'\n                    # project elites into U\n                    Z = (Xe - m).dot(U)  # n x k\n                    # weights inversely proportional to f (shifted)\n                    w = np.exp(-1.8 * (Fe - np.min(Fe)) / (np.std(Fe) + 1e-12))\n                    w = w / (np.sum(w) + 1e-12)\n                    # robust location of z: weighted median-like using weights -> weighted mean here\n                    z_mean = np.sum(Z * w[:, None], axis=0)\n                    # add small stochastic perturbation scaled by per-dimension projected scale\n                    proj_scale = np.sqrt(np.maximum(np.var(Z, axis=0), 1e-12))\n                    z_noise = 0.9 * z_mean + 0.6 * proj_scale * rng.randn(z_mean.size)\n                    step = U.dot(z_noise)\n                    # scale overall step by a factor proportional to median mad\n                    step = step * (0.9 * np.median(per_dim_scale) / (np.linalg.norm(step) / np.sqrt(self.dim) + 1e-12))\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # coordinate parabola probe (1D) using three evals: -s, 0, +s on a chosen coordinate\n                elif p < 0.5 + self.coord_prob:\n                    strategy = 'coord_probe'\n                    # pick a coordinate (prefer those with larger scale)\n                    probs = per_dim_scale / (np.sum(per_dim_scale) + 1e-12)\n                    j = int(np.searchsorted(np.cumsum(probs), rng.rand()))\n                    # avoid taboo coords\n                    if j in taboo_coords and rng.rand() < 0.7:\n                        # pick another coordinate\n                        choices = [i for i in range(self.dim) if i not in taboo_coords]\n                        if choices:\n                            j = rng.choice(choices)\n                    s = (0.8 + rng.rand() * 0.8) * per_dim_scale[j]\n                    x_minus = m.copy(); x_plus = m.copy()\n                    x_minus[j] = np.clip(m[j] - s, lb[j], ub[j])\n                    x_plus[j] = np.clip(m[j] + s, lb[j], ub[j])\n                    f_minus = safe_eval(x_minus)\n                    if f_minus is None:\n                        break\n                    f_plus = safe_eval(x_plus)\n                    if f_plus is None:\n                        break\n                    f0 = safe_eval(m)\n                    if f0 is None:\n                        break\n                    # fit quadratic ax^2 + bx + c on coords [-s, 0, +s]\n                    A = np.array([[s * s, -s, 1.0],\n                                  [0.0,    0.0, 1.0],\n                                  [s * s,  s, 1.0]])\n                    F = np.array([f_minus, f0, f_plus])\n                    try:\n                        coeffs = np.linalg.solve(A, F)  # [a, b, c] with symmetric arrangement\n                        # rebuild correctly: here we used custom layout; compute vertex analytically\n                        # For symmetric points, vertex offset from 0 is -b/(2a)\n                        a = coeffs[0]\n                        b = coeffs[1]\n                        if abs(a) < 1e-14:\n                            # take best of three\n                            arr = [(f_minus, x_minus), (f0, m), (f_plus, x_plus)]\n                            f_best_local, x_best_local = min(arr, key=lambda t: t[0])\n                            x_cand = x_best_local.copy(); f_c = float(f_best_local)\n                        else:\n                            x_rel = -b / (2.0 * a)\n                            # clamp inside [-s, s]\n                            x_rel = max(-s, min(s, x_rel))\n                            x_try = m.copy()\n                            x_try[j] = np.clip(m[j] + x_rel, lb[j], ub[j])\n                            f_try = safe_eval(x_try)\n                            if f_try is None:\n                                break\n                            x_cand = x_try; f_c = f_try\n                            # if trial worse than median, add coord to taboo\n                            if f_c > np.median(f_arch):\n                                taboo_coords.append(j)\n                                if len(taboo_coords) > max(6, self.dim):\n                                    taboo_coords.pop(0)\n                    except Exception:\n                        # fallback jitter\n                        eps = rng.randn(self.dim)\n                        step = per_dim_scale * eps\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # pattern / reflection move across elite centroid\n                elif p < 0.5 + self.coord_prob + self.pattern_prob and Xe.shape[0] > 1:\n                    strategy = 'pattern'\n                    centroid = Xe.mean(axis=0)\n                    # vector from worst elite to centroid\n                    worst_idx = int(np.argmax(Fe))\n                    worst = Xe[worst_idx]\n                    step = (centroid - worst) * (0.9 + 0.4 * rng.rand())\n                    # small random orthogonalization to avoid degeneracy\n                    step = step + 0.15 * np.linalg.norm(step) * rng.randn(self.dim)\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # default robust jitter (MAD-scaled anisotropic gaussian)\n                else:\n                    strategy = 'jitter'\n                    z = rng.randn(self.dim)\n                    step = per_dim_scale * (0.9 * z + 0.05 * rng.randn(self.dim))\n                    # bias occasionally towards best-known direction\n                    if rng.rand() < 0.22:\n                        step = 0.7 * step + 0.3 * (x_best - m)\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                if f_c is None:\n                    break\n\n                # improvement?\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c)\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # update per-dim mad EMA using last K archive points\n                K = min(len(X_arch), max(8, self.archive_size_factor * self.dim // 4))\n                Xr = np.asarray(X_arch[-K:])\n                mad_now = compute_mad(Xr)\n                mad_ema = self.ema_beta * mad_ema + (1.0 - self.ema_beta) * mad_now\n                per_dim_scale = np.clip(mad_ema + 1e-12, self.min_scale, self.max_scale)\n\n                # reward-like measure (not used directly for updates, but could be)\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n\n                # acceptance: improvements always; otherwise Metropolis with multiplicative temperature\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    delta = f_c - f_best\n                    if delta <= 0:\n                        accept = True\n                    else:\n                        # multiplicative temperature decay is applied per eval below\n                        prob_accept = np.exp(-max(0.0, delta) / (T + 1e-12))\n                        if rng.rand() < prob_accept:\n                            accept = True\n\n                if accept:\n                    # learning rate depends on strategy (different constants than AOES)\n                    if strategy == 'subspace':\n                        lr = 0.8\n                    elif strategy == 'coord_probe':\n                        lr = 0.55\n                    elif strategy == 'pattern':\n                        lr = 0.45\n                    elif strategy == 'levy':\n                        lr = 0.18\n                    else:\n                        lr = 0.3\n\n                    delta_m = (x_cand - m)\n                    # trust clipping: maximum move equal to 6 * median scale * sqrt(dim)\n                    trust = 6.0 * np.median(per_dim_scale) * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta_m)\n                    if dn > trust and dn > 0:\n                        delta_m = delta_m * (trust / dn)\n                    # update medoid-center by moving towards candidate by lr\n                    m = np.minimum(np.maximum(m + lr * delta_m, lb), ub)\n\n                    # momentum update (EMA)\n                    momentum = 0.78 * momentum + 0.22 * delta_m\n\n                    # shrink scales slightly on improvement, expand on uphill accept\n                    if improved:\n                        mad_ema *= 0.975\n                    else:\n                        mad_ema = np.clip(mad_ema * 1.01, self.min_scale, self.max_scale)\n\n                else:\n                    # reject: small random perturbation to medoid and mild momentum decay\n                    m = np.minimum(np.maximum(m + 0.02 * avg_span * rng.randn(self.dim), lb), ub)\n                    momentum *= 0.94\n                    # if rejection from a coordinate probe, penalize that coord\n                    if strategy == 'coord_probe' and 'j' in locals():\n                        if j not in taboo_coords:\n                            taboo_coords.append(j)\n                            if len(taboo_coords) > max(6, self.dim):\n                                taboo_coords.pop(0)\n\n                # temperature multiplicative decay per evaluation (robust, different from AOES additive)\n                T = max(1e-8, T * (self.temp_decay ** 1.0))\n\n                # sporadic small random reorientation of subspace U to avoid lock-in\n                if rng.rand() < 0.05:\n                    R = rng.randn(U.shape[1], U.shape[1]) * 0.08\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(U.shape[1]) + R)\n                        U = U.dot(Qr)\n                    except Exception:\n                        pass\n\n                # opportunistic reseed when stagnating\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    jitter = max(0.035 * avg_span, 1.4 * np.median(per_dim_scale))\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    # increase exploration temporarily\n                    mad_ema = np.clip(mad_ema * 1.6, self.min_scale, self.max_scale)\n                    momentum = np.zeros(self.dim)\n                    # local refinement around best with a few samples\n                    reseed = min(8, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.03 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None:\n                            break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # end batch\n\n        # store and return results\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm AMMS scored 0.223 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ba26f129-6da8-46bd-88ce-1bbc98bfec1b", "operator": null, "metadata": {"aucs": [0.10070470256296904, 0.16910545623876527, 0.3012620315417187, 0.26109851656537253, 0.21265822775474796, 0.34471780508876404, 0.2389114842131631, 0.24066969491748658, 0.21615832610704255, 0.1419857022126757]}, "task_prompt": ""}
{"id": "f779db08-8058-48c6-b620-fe2eb355244c", "fitness": 0.20730770913846844, "name": "TopoSubspaceExplorer", "description": "The algorithm builds and maintains an archive and a weighted topology (weights combine fitness and recency via weight_beta and an RBF graph scale) to compute a weighted covariance and extract a low-dimensional spectral subspace B (rank ~ dim/6) with associated sub_var used to focus search along dominant directions. It fits a robust per-component diagonal quadratic in that spectral subspace from nearest neighbors to produce Newton-like steps (clipped by sub_var and trust radii) while also offering finite-difference directional probes for local gradient signals and local Gaussian refinements. Exploration is a heterogeneous mixture of operators (probabilistic mix of topological Newton walks, topology-guided DE recombination, anisotropic spectral jumps, FD probes, and occasional heavy‑tailed Cauchy escapes) with always-accept improvements and Metropolis-like uphill acceptance under a decaying temperature, plus momentum and step-size (sigma) adaptation on success/failure. Practical controls include budget‑aware safe_eval with archive capping, periodic basis refresh and stagnation-triggered local restarts, sensible defaults (pop=12, init sigma ≈0.15·span, refresh_every=8, graph_sigma_mult=0.6) to balance global exploration and focused subspace exploitation.", "code": "import numpy as np\n\nclass TopoSubspaceExplorer:\n    \"\"\"\n    TopoSubspace Explorer (TSE)\n\n    Main ideas:\n    - Maintain an archive and build a weighted topology (affinity graph) where weights\n      depend on fitness and recency. Use these weights to compute a weighted covariance\n      and extract a low-dimensional spectral subspace B (r dims).\n    - Fit a robust diagonal quadratic (per-component curvature) in that subspace around\n      the current best using nearest neighbors; derive Newton-like steps with curvature clipping.\n    - Generate a heterogeneous mixture of proposals:\n        * topological walk (graph-guided move based on neighbor barycenters + subspace Newton step)\n        * graph-based differential recombination (DE-style using archive connectivity)\n        * spectral jump (sample anisotropic Gaussian in spectral subspace)\n        * finite-difference gradient probe (2-eval central diff + mirror-descent update)\n        * occasional heavy-tailed global escapes (Cauchy)\n    - Acceptance: always accept improvements; otherwise accept uphill rarely according to a decaying temperature.\n    - Adaptive trust region and restart when stagnation detected.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=12, rank=None, init_samples=None,\n                 graph_sigma_mult=0.6, weight_beta=0.8, refresh_every=8,\n                 prob_topo=0.22, prob_recomb=0.20, prob_spec=0.30,\n                 prob_fd=0.23, prob_cauchy=0.05, min_sigma=1e-8, max_sigma=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.rank = rank if rank is not None else max(1, self.dim // 6)\n        self.init_samples = init_samples if init_samples is not None else max(30, int(self.budget // 200))\n        self.graph_sigma_mult = float(graph_sigma_mult)\n        self.weight_beta = float(weight_beta)\n        self.refresh_every = int(refresh_every)\n        # strategy probs (leftover goes to spectral)\n        self.prob_topo = float(prob_topo)\n        self.prob_recomb = float(prob_recomb)\n        self.prob_spec = float(prob_spec)\n        self.prob_fd = float(prob_fd)\n        self.prob_cauchy = float(prob_cauchy)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling (default -5..5)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # state\n        evals = 0\n        X_arch = []\n        f_arch = []\n        ages = []  # recency measure (0 newest, increasing)\n        # initial sigma (global step scale)\n        sigma = max(self.min_sigma, 0.15 * avg_span)\n        sigma_diag = np.full(self.dim, sigma)\n        # mean / incumbent\n        m = rng.uniform(lb, ub, size=self.dim)\n        momentum = np.zeros(self.dim)\n\n        # subspace\n        r = min(self.rank, self.dim)\n        if r > 0:\n            # init as random orthonormal basis\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()\n            sub_var = np.ones(r) * (sigma / np.sqrt(max(1, r)))\n        else:\n            B = np.zeros((self.dim, 0))\n            sub_var = np.array([])\n\n        # safe_eval wrapper (enforce budget and bounds)\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx); ages.append(0)\n            # age all others\n            for i in range(len(ages)-1):\n                ages[i] += 1\n            # cap archive to reasonable size\n            cap = max(6 * self.dim, 200)\n            if len(X_arch) > cap:\n                X_arch.pop(0); f_arch.pop(0); ages.pop(0)\n            return fx\n\n        # seed initial archive\n        seed_n = max(6, min(self.init_samples, self.budget // 4))\n        for _ in range(seed_n):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        # ensure at least one eval\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(12, int(0.04 * self.budget))\n\n        # compute weighted topology and spectral subspace\n        def refresh_topology():\n            nonlocal B, sub_var, r\n            if len(X_arch) < max(6, r + 3):\n                return\n            X = np.asarray(X_arch)\n            F = np.asarray(f_arch)\n            # weights: prefer lower f and recent points\n            f0 = np.min(F)\n            rel = F - f0\n            # quality weight\n            wq = np.exp(-self.weight_beta * rel / (1.0 + np.std(F) + 1e-12))\n            # recency weight\n            wa = np.exp(-0.05 * np.asarray(ages))\n            w = wq * wa + 1e-12\n            W = w / (np.sum(w) + 1e-12)\n            # weighted mean relative to current m\n            meanX = np.sum(X * W[:, None], axis=0)\n            S = (X - meanX) * np.sqrt(W[:, None])\n            # weighted covariance\n            C = S.T.dot(S) + 1e-9 * np.eye(self.dim)\n            try:\n                wvals, V = np.linalg.eigh(C)\n                # sort descending\n                idx = np.argsort(wvals)[::-1]\n                wvals = wvals[idx]\n                V = V[:, idx]\n                r_eff = min(r, V.shape[1])\n                if r_eff <= 0:\n                    return\n                B_new = V[:, :r_eff]\n                # blend with previous basis to avoid abrupt change\n                alpha = 0.18\n                if B.shape[1] == r_eff:\n                    B = (1 - alpha) * B + alpha * B_new\n                    Q, _ = np.linalg.qr(B)\n                    B = Q[:, :r_eff]\n                else:\n                    B = B_new.copy()\n                # subspace variances proportional to eigenvalues (stabilized)\n                sub_var = 0.9 * sub_var[:r_eff] + 0.1 * (np.maximum(wvals[:r_eff], 1e-12))\n            except Exception:\n                pass\n\n        # build local quadratic approx in subspace around center (best)\n        def local_diag_quadratic(center, n_neighbors=None):\n            # returns (g, q_diag) in subspace coordinates: f ≈ c + g^T z + 0.5 * sum q_i * z_i^2\n            if r == 0 or len(X_arch) < 4:\n                return None, None\n            X = np.asarray(X_arch)\n            n = X.shape[0]\n            # distances in ambient to center\n            dists = np.linalg.norm(X - center[None, :], axis=1)\n            if n_neighbors is None:\n                n_neighbors = min(max(6, 3 * r), n)\n            idx = np.argsort(dists)[:n_neighbors]\n            Xn = X[idx]\n            Fn = np.asarray(f_arch)[idx]\n            # project to subspace\n            Z = (Xn - center).dot(B)  # n_neighbors x r\n            # design: columns [1, z1..zr, 0.5*z1^2..0.5*zr^2] -> linear + diag quadratic\n            Phi = np.ones((Z.shape[0], 1 + r + r))\n            Phi[:, 1:1 + r] = Z\n            Phi[:, 1 + r:] = 0.5 * (Z * Z)\n            # ridge for stability\n            lam = 1e-6 * (1.0 + np.var(Fn))\n            try:\n                # solve least squares robustly\n                theta, *_ = np.linalg.lstsq(Phi, Fn, rcond=None)\n                b = theta[1:1 + r]\n                q = theta[1 + r:1 + r + r]\n                # ensure q positive-ish for minimization behaviour; if negative, clamp softly\n                q_pos = np.where(q > 1e-8, q, 1e-8 + 0.2 * np.abs(q))\n                return b, q_pos\n            except Exception:\n                return None, None\n\n        # helper: build local affinity neighbors for recombination\n        def pick_neighbors_by_topology(k=3):\n            if len(X_arch) <= k:\n                return list(range(len(X_arch)))\n            # choose a seed by fitness-weighted sampling\n            F = np.asarray(f_arch)\n            f0 = np.min(F)\n            rel = F - f0\n            w = np.exp(-self.weight_beta * rel / (1.0 + np.std(F) + 1e-12))\n            if np.sum(w) <= 0:\n                w = np.ones_like(w)\n            p = w / np.sum(w)\n            seed = rng.choice(len(X_arch), p=p)\n            # find nearest neighbors to seed (within archive)\n            X = np.asarray(X_arch)\n            d = np.linalg.norm(X - X[seed], axis=1)\n            idx = np.argsort(d)\n            neighbors = [int(i) for i in idx[:k+1] if i != seed]\n            # ensure we have enough\n            if len(neighbors) < k:\n                extra = [i for i in range(len(X_arch)) if i not in neighbors and i != seed]\n                rng.shuffle(extra)\n                neighbors.extend(extra[:(k - len(neighbors))])\n            return neighbors[:k]\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            # periodic topology refresh\n            if gen % self.refresh_every == 0:\n                refresh_topology()\n\n            # compute temperature (decays with evals and with sigma)\n            T = 1e-8 + 0.8 * sigma * max(1.0 - evals / max(1.0, self.budget), 0.02)\n\n            # build candidate batch\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                x_cand = None\n                f_c = None\n                strategy = 'spec'\n                step = None\n\n                # strategy: heavy-tailed global escape\n                if p < self.prob_cauchy:\n                    strategy = 'cauchy'\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 80) + 1e-12)\n                    step = 6.0 * sigma * z\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # topological Newton-like walk (graph guided + subspace Newton)\n                elif p < self.prob_cauchy + self.prob_topo:\n                    strategy = 'topo_walk'\n                    # pick neighbor barycenter weighted by adjacency (RBF)\n                    if len(X_arch) < 4:\n                        # fallback random jitter\n                        step = sigma * rng.randn(self.dim)\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n                    else:\n                        # build small affinity to nearest neighbors around current best\n                        X = np.asarray(X_arch)\n                        # compute local scale for RBF\n                        dists = np.linalg.norm(X - m[None, :], axis=1)\n                        med = np.median(dists) + 1e-12\n                        sigma_g = self.graph_sigma_mult * max(med, 1e-3 * avg_span)\n                        # weights\n                        w = np.exp(-0.5 * (dists / sigma_g) ** 2)\n                        # take top K\n                        K = min(len(w), 12)\n                        idx = np.argsort(-w)[:K]\n                        weights = w[idx]\n                        weights = weights / (np.sum(weights) + 1e-12)\n                        bary = np.sum(X[idx] * weights[:, None], axis=0)\n                        # local quadratic in subspace around bary or current best\n                        center = bary\n                        b, q = local_diag_quadratic(center)\n                        if b is None:\n                            # fallback small move toward bary\n                            step = 0.6 * (bary - m) + sigma * rng.randn(self.dim) * 0.3\n                            x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                            f_c = safe_eval(x_cand)\n                            if f_c is None:\n                                break\n                        else:\n                            # Newton-like in subspace (z_star = -g / q), with curvature-aware trust clipping\n                            z_star = - b / (q + 1e-12)\n                            # scale by sub_var and clip\n                            z_star = np.clip(z_star, -4.0 * np.sqrt(sub_var + 1e-12), 4.0 * np.sqrt(sub_var + 1e-12))\n                            delta = B.dot(z_star)\n                            # blend with bary direction\n                            delta = 0.7 * delta + 0.3 * (bary - m)\n                            # trust clipping\n                            trust = 6.0 * sigma * np.sqrt(max(1, self.dim))\n                            dn = np.linalg.norm(delta)\n                            if dn > trust:\n                                delta = delta * (trust / (dn + 1e-12))\n                            step = delta\n                            x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                            f_c = safe_eval(x_cand)\n                            if f_c is None:\n                                break\n\n                # graph recombination (DE-like) guided by topology\n                elif p < self.prob_cauchy + self.prob_topo + self.prob_recomb:\n                    strategy = 'recomb'\n                    # pick neighbors in archive by topology\n                    ids = pick_neighbors_by_topology(k=3)\n                    if len(ids) < 3:\n                        # fallback jitter\n                        step = sigma * rng.randn(self.dim)\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n                    else:\n                        a = X_arch[ids[0]]; b = X_arch[ids[1]]; c = X_arch[ids[2]]\n                        Fscale = 0.8 + 0.4 * rng.rand()\n                        trial = a + Fscale * (b - c)\n                        # mix with mean and add small spectral perturbation\n                        if r > 0 and rng.rand() < 0.6:\n                            z = rng.randn(r) * np.sqrt(sub_var + 1e-12)\n                            trial = 0.6 * trial + 0.4 * (m + B.dot(z))\n                        trial = np.minimum(np.maximum(trial, lb), ub)\n                        # final jitter\n                        trial = np.minimum(np.maximum(trial + 0.12 * sigma * rng.randn(self.dim), lb), ub)\n                        x_cand = trial\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # spectral jump: sample anisotropic gaussian in subspace\n                elif p < self.prob_cauchy + self.prob_topo + self.prob_recomb + self.prob_spec:\n                    strategy = 'spec'\n                    if r > 0:\n                        z = rng.randn(r) * np.sqrt(sub_var + 1e-12)\n                        # occasional sign flip for exploration of opposite manifold side\n                        if rng.rand() < 0.12:\n                            flip_idx = rng.randint(0, r)\n                            z[flip_idx] = -2.0 * z[flip_idx]\n                        delta = B.dot(z)\n                        # add small ambient jitter scaled by sigma_diag\n                        delta = delta + 0.08 * sigma * rng.randn(self.dim)\n                        step = delta\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n                    else:\n                        step = sigma * rng.randn(self.dim)\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # finite-difference directional probe (two evals) and mirror descent scalar update\n                else:\n                    strategy = 'fd'\n                    # choose direction: prefer spectral directions\n                    if r > 0 and rng.rand() < 0.7:\n                        idx = rng.randint(0, r)\n                        d = B[:, idx]\n                        # scale to unit\n                        d = d / (np.linalg.norm(d) + 1e-12)\n                    else:\n                        d = rng.randn(self.dim)\n                        d = d / (np.linalg.norm(d) + 1e-12)\n                    h = 1e-4 * (1.0 + avg_span)\n                    x_plus = np.minimum(np.maximum(m + h * d, lb), ub)\n                    x_minus = np.minimum(np.maximum(m - h * d, lb), ub)\n                    f_plus = safe_eval(x_plus)\n                    if f_plus is None:\n                        break\n                    f_minus = safe_eval(x_minus)\n                    if f_minus is None:\n                        break\n                    # central difference gradient estimate along d\n                    g_est = (f_plus - f_minus) / (2.0 * h)\n                    # propose mirror-descent step opposite gradient direction\n                    step = - (0.6 * sigma) * g_est * d\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # ensure we have a result\n                if f_c is None:\n                    break\n\n                # bookkeeping\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c)\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # reward-like step normalization (simple)\n                step_norm = (np.linalg.norm(step) + 1e-12) if step is not None else 1.0\n\n                # adapt sigma_diag moderately by success\n                if improved:\n                    sigma = max(self.min_sigma, sigma * 0.88)\n                    sigma_diag = np.clip(sigma_diag * 0.95, self.min_sigma, self.max_sigma)\n                    # if improvement came from subspace step, shrink sub_var to focus\n                    if strategy in ('topo_walk', 'spec'):\n                        sub_var = np.clip(0.95 * sub_var, 1e-10, 1e6)\n                else:\n                    # enlarge a bit on rejection\n                    sigma = min(self.max_sigma, sigma * 1.01)\n                    sigma_diag = np.clip(sigma_diag * 1.01, self.min_sigma, self.max_sigma)\n                    # occasionally perturb the basis to diversify\n                    if r > 0 and rng.rand() < 0.03:\n                        R = rng.randn(r, r) * 0.06\n                        try:\n                            Qr, _ = np.linalg.qr(np.eye(r) + R)\n                            B = B.dot(Qr)\n                            Q2, _ = np.linalg.qr(B)\n                            B = Q2[:, :r]\n                        except Exception:\n                            pass\n\n                # acceptance: improvements always, else Metropolis-like\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    delta_f = f_c - f_best\n                    if delta_f <= 0:\n                        accept = True\n                    else:\n                        if rng.rand() < np.exp(-delta_f / (T + 1e-12)):\n                            accept = True\n\n                if accept:\n                    # update mean m with a strategy-weighted learning rate\n                    if strategy in ('topo_walk',):\n                        lr = 0.75\n                    elif strategy in ('recomb',):\n                        lr = 0.6\n                    elif strategy in ('spec',):\n                        lr = 0.45\n                    elif strategy in ('fd',):\n                        lr = 0.35\n                    else:\n                        lr = 0.25\n                    delta = x_cand - m\n                    # global trust clipping\n                    trust = 7.0 * sigma * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                    # momentum\n                    momentum = 0.8 * momentum + 0.2 * delta\n                else:\n                    # rejected: tiny reposition and increase momentum damping\n                    m = np.minimum(np.maximum(m + 0.02 * avg_span * rng.randn(self.dim), lb), ub)\n                    momentum *= 0.94\n\n                # opportunistic local refine around best if lots of improvements recently\n                if improved and rng.rand() < 0.25:\n                    # try a small local gaussian around x_best\n                    x_local = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                    f_local = safe_eval(x_local)\n                    if f_local is None:\n                        break\n                    if f_local < f_best:\n                        f_best = f_local; x_best = x_local.copy()\n\n                # periodic soft refresh of spectral basis if many new evaluations\n                if gen % max(1, self.refresh_every // 2) == 0 and len(X_arch) > (2 * r + 4):\n                    refresh_topology()\n\n                # stagnation-triggered restart around best\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    # local reseed: move m near best with moderate sigma\n                    jitter = max(0.04 * avg_span, 1.2 * sigma)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma = min(self.max_sigma, sigma * 1.6)\n                    momentum = np.zeros(self.dim)\n                    # refresh basis randomly\n                    if r > 0:\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :r]\n                        sub_var = np.ones(r) * (sigma / np.sqrt(max(1, r)))\n                    # local refine\n                    reseed = min(8, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.03 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None:\n                            break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # end batch\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm TopoSubspaceExplorer scored 0.207 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ba26f129-6da8-46bd-88ce-1bbc98bfec1b", "operator": null, "metadata": {"aucs": [0.08289418604253329, 0.15259085137704165, 0.2760456358105987, 0.2685423329728739, 0.2051112376454538, 0.27616286531784706, 0.2227049141799453, 0.2500906133959244, 0.1950031101156937, 0.14393134452677225]}, "task_prompt": ""}
{"id": "fa56d7ab-b644-4735-88b0-04f1627bf4e5", "fitness": 0.24763139045044621, "name": "STARSUB", "description": "The algorithm is a hybrid stochastic trust-region optimizer that combines an archive-and-elite framework with multiple proposal strategies (anisotropic jitter, PCA-subspace surrogate minimization, Mahalanobis sampling, line probes, reflections and occasional Lévy/Cauchy escapes) and an SA-like acceptance rule, using a fixed budget of evaluations. It emphasizes subspace modeling: a relatively large PCA rank (default ≈ dim//4), frequent PCA refreshes, learned subspace scales/curvatures and a cheap quadratic surrogate solved in the PCA coordinates (with clipping and rotation) to propose strong low‑dimensional steps. Sampling diversity and robustness come from per-dimension RMS-adapted sigmas (rms_beta=0.85), momentum, Ledoit–Wolf style shrinkage covariance for Mahalanobis draws, a taboo-direction list to discourage repeated bad moves, and occasional orthonormal perturbations of the subspace. Adaptation is governed by a short-term success window that multiplicatively shrinks/expands global sigma, a mild sqrt-based temperature schedule for probabilistic acceptance, trust-region clipping proportional to sigma*sqrt(dim), and opportunistic reseeding plus local refinement when stagnation is detected.", "code": "import numpy as np\n\nclass STARSUB:\n    \"\"\"\n    STARSUB: Stochastic Trust-Region Adaptive Subspace Search\n\n    Main differences (parameters & equations) vs. the provided AOES:\n    - Default low-rank PCA dimension is larger: rank ≈ max(1, dim//4) (AOES used ~dim/8).\n    - Smaller initial global step multiplier (init_sigma_mult default 0.08).\n    - Faster PCA refresh cadence (pca_refresh default 8).\n    - Different strategy probabilities biased toward PCA-surrogate (prob_pca_sur default 0.30)\n      and lower Elite-Mahalanobis probability (prob_maha default 0.15).\n    - RMS smoothing factor changed (rms_beta default 0.85).\n    - Sigma adaptation is governed by a short-term success-rate window (multiplicative adjustments),\n      not just immediate shrink/expand factors.\n    - Temperature schedule decays proportional to sqrt(remaining budget) (milder early acceptance).\n    - Covariance used for Mahalanobis proposals uses Ledoit-Wolf style shrinkage toward diagonal.\n    - Different momentum and trust-region constants; different clipping equations for subspace steps.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=16, rank=None, elite_frac=0.18, init_sigma_mult=0.08,\n                 rms_beta=0.85, pca_refresh=8,\n                 prob_maha=0.15, prob_pca_sur=0.30, prob_line=0.10,\n                 prob_reflect=0.05, prob_levy=0.05,\n                 min_sigma=1e-9, max_sigma=3.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        # larger default rank than AOES to capture more subspace structure\n        self.rank = rank if rank is not None else max(1, max(1, self.dim // 4))\n        self.elite_frac = float(elite_frac)\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.rms_beta = float(rms_beta)\n        self.pca_refresh = int(pca_refresh)\n        self.prob_maha = float(prob_maha)\n        self.prob_pca_sur = float(prob_pca_sur)\n        self.prob_line = float(prob_line)\n        self.prob_reflect = float(prob_reflect)\n        self.prob_levy = float(prob_levy)\n        self.min_sigma = float(min_sigma)\n        self.max_sigma = float(max_sigma)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling; default [-5,5]\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0, dtype=float)\n            ub = np.full(self.dim, 5.0, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize search mean and scales\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = float(max(self.min_sigma, self.init_sigma_mult * avg_span))\n        # per-dimension sigma diag adapted by RMS activity\n        sigma_diag = np.full(self.dim, sigma)\n        v_rms = np.full(self.dim, 1e-6)\n        momentum = np.zeros(self.dim)\n\n        # PCA subspace\n        r = min(self.rank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()\n            sub_scale = np.full(r, max(1e-8, sigma / np.sqrt(max(1, r))))\n            curvature = np.full(r, 1.0)\n        else:\n            B = np.zeros((self.dim, 0))\n            sub_scale = np.array([])\n            curvature = np.array([])\n\n        # archive & elites\n        X_arch = []\n        f_arch = []\n        eliteK = max(3, int(np.ceil(self.elite_frac * max(60, self.budget / 8))))\n\n        evals = 0\n        # short-term success window for sigma adaptation\n        success_window = []\n        success_win_len = 20\n\n        # direction taboo list to discourage repeated bad directions\n        taboo_dirs = []\n\n        # safe evaluation wrapper: enforces budget and bounds, maintains archive\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # cap archive to a pragmatic limit\n            max_arch = max(12 * self.dim, 300)\n            if len(X_arch) > max_arch:\n                X_arch.pop(0); f_arch.pop(0)\n            return fx\n\n        # seed initial archive with a moderate number of random samples\n        seed0 = min(self.pop * 6, max(20, int(self.budget // 120)))\n        for _ in range(seed0):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        # initialize best\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(10, int(0.03 * self.budget))\n\n        # helper: compute elites\n        def get_elites():\n            if len(X_arch) == 0:\n                return np.empty((0, self.dim)), np.array([])\n            idxs = np.argsort(f_arch)[:min(eliteK, len(f_arch))]\n            Xe = np.asarray([X_arch[i].copy() for i in idxs])\n            Fe = np.asarray([f_arch[i] for i in idxs])\n            return Xe, Fe\n\n        # helper: robust sqrt-cov with shrinkage to diagonal (Ledoit-Wolf style simple)\n        def sqrt_cov_from(Xe):\n            k = Xe.shape[0]\n            if k <= 1:\n                return np.eye(self.dim)\n            C = np.cov(Xe.T) + 1e-12 * np.eye(self.dim)\n            # shrinkage towards diagonal with factor gamma computed from trace variance heuristic\n            diag = np.diag(np.diag(C))\n            trC = np.trace(C)\n            if trC <= 0:\n                gamma = 0.5\n            else:\n                gamma = min(0.9, 1.0 / (1.0 + k / (10.0 + self.dim)))\n            C_shr = (1.0 - gamma) * C + gamma * diag\n            try:\n                w, V = np.linalg.eigh(C_shr)\n                w = np.maximum(w, 1e-12)\n                S = V.dot(np.diag(np.sqrt(w))).dot(V.T)\n                return S\n            except Exception:\n                U, s, Vt = np.linalg.svd(C_shr)\n                return U.dot(np.diag(np.sqrt(np.maximum(s, 1e-12)))).dot(Vt)\n\n        # helper: light PCA refresh using recent archive, blend with current B\n        def refresh_pca():\n            nonlocal B, sub_scale, curvature, r\n            if r == 0 or len(X_arch) < (4 + r):\n                return\n            K = min(len(X_arch), max(self.dim * 4, 60))\n            Xr = np.asarray(X_arch[-K:])\n            meanX = Xr.mean(axis=0)\n            S = (Xr - meanX)\n            try:\n                U, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(r, Vt.shape[0])\n                if r_eff <= 0:\n                    return\n                B_new = Vt[:r_eff].T\n                alpha = 0.25  # slightly stronger blending\n                if B.shape[1] == r_eff:\n                    B = (1 - alpha) * B + alpha * B_new\n                else:\n                    B = B_new.copy()\n                Q, _ = np.linalg.qr(B)\n                B = Q[:, :r_eff]\n                n = max(1, Xr.shape[0])\n                s_est = svals[:r_eff] / np.sqrt(n)\n                sub_scale = 0.85 * sub_scale[:r_eff] + 0.15 * (s_est + 1e-12)\n                curvature = 0.85 * curvature[:r_eff] + 0.15 * (1.0 / (svals[:r_eff] + 1e-8))\n            except Exception:\n                pass\n\n        # small golden-ish bracket 1D probe (up to 3 evals), simpler than full parabola\n        def line_probe(base, direction, max_scale=1.8):\n            # direction normalized\n            nonlocal evals\n            a = 0.5 * (0.5 + rng.rand()) * sigma * max_scale\n            b = 0.5 * (0.5 + rng.rand()) * sigma * max_scale\n            x1 = np.minimum(np.maximum(base - a * direction, lb), ub)\n            f1 = safe_eval(x1)\n            if f1 is None:\n                return None, None\n            x2 = np.minimum(np.maximum(base + b * direction, lb), ub)\n            f2 = safe_eval(x2)\n            if f2 is None:\n                return None, None\n            # pick best among three and optionally try midpoint if beneficial\n            f0 = safe_eval(base)\n            if f0 is None:\n                return None, None\n            fs = [f1, f0, f2]\n            xs = [x1, base, x2]\n            idx = int(np.argmin(fs))\n            bestx = xs[idx]; bestf = fs[idx]\n            # one extra refinement: midpoint between best and center if budget allows\n            if evals < self.budget:\n                mid = 0.5 * (bestx + base)\n                fmid = safe_eval(mid)\n                if fmid is not None and fmid < bestf:\n                    return mid.copy(), fmid\n            return bestx.copy(), bestf\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            # periodic PCA refresh (more frequent by default)\n            if gen % self.pca_refresh == 0:\n                refresh_pca()\n\n            Xe, Fe = get_elites()\n            S_sqrt = sqrt_cov_from(Xe) if Xe.size else np.eye(self.dim)\n\n            # temperature schedule decays with remaining budget in a mild sqrt way\n            rem = max(1, self.budget - evals)\n            T = 1e-8 + 0.7 * sigma * np.sqrt(rem / max(1.0, self.budget))\n\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n\n                p = rng.rand()\n                x_cand = None\n                f_c = None\n                step = None\n                strategy = 'jitter'\n\n                # Levy-like heavy escape (Cauchy) occasionally (slightly larger scale)\n                if p < self.prob_levy:\n                    strategy = 'levy'\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 85) + 1e-12)\n                    step = 6.0 * sigma * z\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # Elite Mahalanobis sampling (less weight than AOES)\n                elif p < self.prob_maha and Xe.size:\n                    strategy = 'maha'\n                    # mix center between m and a random elite with stronger bias to elites\n                    center = Xe[rng.randint(0, Xe.shape[0])] if rng.rand() < 0.7 else m\n                    z = rng.randn(self.dim)\n                    step = 1.0 * sigma * (S_sqrt.dot(z)) + 0.12 * momentum\n                    # penalize taboo directions by subtracting projection stronger\n                    if len(taboo_dirs) > 0:\n                        for td in taboo_dirs[-8:]:\n                            proj = np.dot(step, td) * td\n                            step = step - 0.6 * proj\n                    x_cand = np.minimum(np.maximum(center + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # PCA surrogate minimizer (bigger share of budget devoted here)\n                elif p < (self.prob_maha + self.prob_pca_sur) and r > 0 and len(X_arch) >= (max(30, 5 * r)):\n                    strategy = 'pca_surrogate'\n                    K = min(len(X_arch), 6 * self.dim)\n                    Xr = np.asarray(X_arch[-K:])\n                    Fr = np.asarray(f_arch[-Xr.shape[0]:])\n                    Z = (Xr - m).dot(B)  # project onto B\n                    n = Z.shape[0]\n                    # Fit simple diagonal quadratic in subspace: f ≈ c + b^T z + 0.5 * q^T z^2\n                    # Solve via ridge least squares for parameters [c, b (r), q (r)]\n                    Fmat = np.ones((n, 1 + 2 * r))\n                    Fmat[:, 1:1 + r] = Z\n                    Fmat[:, 1 + r:] = 0.5 * (Z * Z)\n                    lam = 1e-6 * (1.0 + np.var(Fr))\n                    try:\n                        FtF = Fmat.T.dot(Fmat)\n                        rhs = Fmat.T.dot(Fr)\n                        theta = np.linalg.solve(FtF + lam * np.eye(FtF.shape[0]), rhs)\n                        b = theta[1:1 + r]\n                        q = theta[1 + r:1 + r + r]\n                        # ensure convex-ish directions by pushing q slightly positive\n                        q_pos = np.sign(q) * np.maximum(np.abs(q), 1e-8)\n                        z_star = -b / (q_pos + 1e-12)\n                        # stronger clipping based on sub_scale and curvature\n                        z_star = np.clip(z_star, -3.5 * sub_scale, 3.5 * sub_scale)\n                        # penalize alignment with taboo directions\n                        for td in taboo_dirs[-8:]:\n                            proj = (B.dot(z_star)).dot(td)\n                            if abs(proj) > 0.6 * np.linalg.norm(B.dot(z_star)):\n                                z_star = 0.55 * z_star\n                        x_pred = np.minimum(np.maximum(m + B.dot(z_star), lb), ub)\n                        f_pred = safe_eval(x_pred)\n                        if f_pred is None:\n                            break\n                        x_cand = x_pred\n                        f_c = f_pred\n                        step = x_cand - m\n                        curvature = 0.88 * curvature + 0.12 * (1.0 / (np.abs(q_pos) + 1e-8))\n                    except Exception:\n                        # fallback jitter\n                        eps = rng.randn(self.dim)\n                        step = sigma_diag * eps\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # directional line probe (lighter)\n                elif p < (self.prob_maha + self.prob_pca_sur + self.prob_line):\n                    strategy = 'line'\n                    choice = rng.rand()\n                    if choice < 0.3:\n                        d = x_best - m\n                    elif choice < 0.65 and r > 0:\n                        idx = rng.randint(0, r)\n                        d = B[:, idx] * sub_scale[idx]\n                    else:\n                        d = momentum + 0.18 * rng.randn(self.dim)\n                    nd = np.linalg.norm(d) + 1e-12\n                    d = d / nd\n                    # avoid too-similar taboo directions\n                    for td in taboo_dirs[-8:]:\n                        if abs(np.dot(d, td)) > 0.9:\n                            d = d - 0.5 * np.dot(d, td) * td\n                            d = d / (np.linalg.norm(d) + 1e-12)\n                    res = line_probe(m, d, max_scale=2.0)\n                    if res[0] is None:\n                        eps = rng.randn(self.dim)\n                        step = sigma_diag * eps\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n                    else:\n                        x_line, f_line = res\n                        x_cand = x_line; f_c = f_line\n                        step = x_cand - m\n                        if f_c > f_best:\n                            snorm = np.linalg.norm(step)\n                            if snorm > 1e-12:\n                                taboo_dirs.append(step / snorm)\n                                if len(taboo_dirs) > 40:\n                                    taboo_dirs.pop(0)\n\n                # reflection/expansion inspired move (rare)\n                elif p < (self.prob_maha + self.prob_pca_sur + self.prob_line + self.prob_reflect) and Xe.size:\n                    strategy = 'reflect'\n                    centroid = Xe.mean(axis=0)\n                    # pick a recent poor point and reflect with expansion factor\n                    cand_pool = min(len(X_arch), 30)\n                    worst_idx_local = int(np.argmax(f_arch[-cand_pool:]))\n                    x_worst = np.asarray(X_arch[-cand_pool:][worst_idx_local])\n                    step = 1.4 * (centroid - x_worst) + 0.25 * rng.randn(self.dim) * sigma\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # default anisotropic jitter (RMS-adapted) with slightly different coefficients\n                else:\n                    strategy = 'jitter'\n                    eps = rng.randn(self.dim)\n                    step = sigma_diag * eps + 0.14 * momentum\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                if f_c is None:\n                    break\n\n                # check improvement\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c)\n                    x_best = x_cand.copy()\n                    improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # reward-like measure and update RMS\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                sq = (step / (sigma + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq\n                sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-8), self.min_sigma, self.max_sigma)\n\n                # update subspace usage scales\n                if step is not None and r > 0:\n                    projs = B.T.dot(step)\n                    absprojs = np.abs(projs)\n                    if absprojs.size > 0 and absprojs.sum() > 0:\n                        sub_scale = np.clip(0.95 * sub_scale + 0.05 * (absprojs + 1e-8), self.min_sigma, self.max_sigma)\n\n                # acceptance: always accept improvement; non-improvements accepted with SA prob\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    delta = f_c - f_best\n                    if delta <= 0:\n                        accept = True\n                    else:\n                        if rng.rand() < np.exp(-delta / (T + 1e-12)):\n                            accept = True\n\n                # bookkeeping for success window\n                success_window.append(1 if improved else 0)\n                if len(success_window) > success_win_len:\n                    success_window.pop(0)\n                succ_rate = float(np.mean(success_window)) if success_window else 0.0\n\n                if accept:\n                    # learning rate depends on strategy but slightly different constants\n                    if strategy == 'pca_surrogate':\n                        lr = 0.85\n                    elif strategy == 'maha':\n                        lr = 0.7\n                    elif strategy == 'line':\n                        lr = 0.55\n                    elif strategy == 'reflect':\n                        lr = 0.45\n                    elif strategy == 'levy':\n                        lr = 0.18\n                    else:\n                        lr = 0.32\n\n                    delta_m = (x_cand - m)\n                    # trust clipping scaled with dimension differently (milder)\n                    trust = 6.0 * sigma * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta_m)\n                    if dn > trust:\n                        delta_m = delta_m * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta_m, lb), ub)\n\n                    # momentum update with milder smoothing\n                    momentum = 0.80 * momentum + 0.20 * delta_m\n\n                    # success-rate driven sigma adaptation (different equation)\n                    if succ_rate > 0.22:\n                        # many recent successes -> shrink step\n                        sigma = max(self.min_sigma, sigma * 0.92)\n                        v_rms *= 0.97\n                    elif succ_rate < 0.06:\n                        # few successes -> expand to escape plateau\n                        sigma = min(self.max_sigma, sigma * 1.035)\n                    else:\n                        # mild cooling\n                        sigma = max(self.min_sigma, sigma * 0.998)\n                else:\n                    # reject: small perturb to mean and penalize momentum\n                    m = np.minimum(np.maximum(m + 0.012 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma = min(self.max_sigma, sigma * 1.006)\n                    momentum *= 0.95\n                    if step is not None:\n                        snorm = np.linalg.norm(step)\n                        if snorm > 1e-12:\n                            td = step / snorm\n                            taboo_dirs.append(td)\n                            if len(taboo_dirs) > 48:\n                                taboo_dirs.pop(0)\n\n                # small random orthonormal rotation of B occasionally\n                if r > 0 and rng.rand() < 0.06:\n                    R = rng.randn(r, r) * 0.05\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(r) + R)\n                        B = B.dot(Qr)\n                        Q2, _ = np.linalg.qr(B)\n                        B = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # opportunistic reseed on stagnation (slightly more frequent reseed)\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    jitter = max(0.02 * avg_span, 1.0 * sigma)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    sigma = min(self.max_sigma, sigma * 1.6)\n                    momentum = np.zeros(self.dim)\n                    if r > 0:\n                        A = rng.randn(self.dim, r)\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :r]\n                        sub_scale = np.full(r, sigma / np.sqrt(max(1, r)))\n                        curvature = np.full(r, 1.0)\n                    # local refine around best (a few cheap evals)\n                    reseed = min(8, self.budget - evals)\n                    for _ in range(reseed):\n                        x = np.minimum(np.maximum(x_best + 0.03 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None:\n                            break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # end batch\n\n        # results\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm STARSUB scored 0.248 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ba26f129-6da8-46bd-88ce-1bbc98bfec1b", "operator": null, "metadata": {"aucs": [0.11001177108555882, 0.16347058455947816, 0.2988130462505101, 0.3731617426021969, 0.2324942100391204, 0.3729459906682646, 0.24689670576191525, 0.29089492166111663, 0.23964509096411013, 0.1479798409121913]}, "task_prompt": ""}
{"id": "0708a074-e9e7-47f7-add8-d97a3ea7e373", "fitness": 0.44213182483093716, "name": "HASTMM", "description": "HASTMM is built around a low-rank adaptive subspace (initialized by random orthonormal basis, default rank ≈ dim/6) whose directions are periodically refreshed by PCA on a buffer of normalized successful steps and scored by multiplicative \"energies\" so search emphasizes productive modes. Candidate generation uses mirrored/antithetic pairs that combine subspace-coefficients and adaptive per-dimension diagonal jitter (RMS-smoothed via rms_beta≈0.92) with a small persistent momentum term to bias proposals and a trust-clipping on mean updates to avoid overly large jumps. A cheap diagonal-quadratic surrogate is fit in the subspace to occasionally propose a targeted minimizer, acceptance is probabilistic (allowing uphill moves early) with stronger moves for improvements, and subspace energies are updated from directional gains to concentrate sampling. Global step-size sigma is adapted multiplicatively from a smoothed success rate (succ_target≈0.2, sigma_adapt_rate≈0.25), with opportunistic restarts (stagn_frac≈0.06, restart_infl≈1.6), archive seeding, and light local reseeding around the best when stagnation occurs.", "code": "import numpy as np\n\nclass HASTMM:\n    \"\"\"\n    HASTMM: Hybrid Adaptive Subspace Trust with Mirrored Momentum\n\n    Main features:\n      - Low-rank subspace U (periodic PCA on successful normalized steps) with multiplicative energies\n      - Mirrored / antithetic sampling in low-rank + diagonal residual noise to estimate directional gains\n      - Per-dimension RMS for diagonal adaptation; momentum vector to bias proposals\n      - Small subspace quadratic/linear surrogate to propose a targeted minimizer occasionally\n      - Sigma adapted multiplicatively via smoothed success-rate, trust-clipped mean updates,\n        probabilistic uphill acceptance, and opportunistic restarts on stagnation\n\n    Usage:\n      opt = HASTMM(budget=10000, dim=10)\n      f_opt, x_opt = opt(func)\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 rank=None, pop_base=None, init_sigma_mult=0.18,\n                 succ_target=0.2, sigma_adapt_rate=0.25,\n                 rms_beta=0.92, energy_lr=0.18,\n                 pca_period=12, buffer_size=None,\n                 stagn_frac=0.06, restart_infl=1.6):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.rank = int(rank) if rank is not None else max(1, self.dim // 6)\n        self.pop_base = pop_base if pop_base is not None else max(8, int(6 + np.log(max(2, self.dim))))\n        self.init_sigma_mult = float(init_sigma_mult)\n        self.succ_target = float(succ_target)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.rms_beta = float(rms_beta)\n        self.energy_lr = float(energy_lr)\n        self.pca_period = int(pca_period)\n        self.buffer_size = buffer_size if buffer_size is not None else max(4 * self.rank, 40)\n        self.stagn_frac = float(stagn_frac)\n        self.restart_infl = float(restart_infl)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds support (scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize mean and scales\n        m = rng.uniform(lb, ub, size=self.dim)\n        sigma = max(1e-10, self.init_sigma_mult * avg_span)\n        # per-dimension RMS accumulator and diagonal scale (sigma_diag = sigma / sqrt(rms))\n        v_rms = np.full(self.dim, 1e-6)\n        sigma_diag = np.full(self.dim, sigma)\n\n        # low-rank basis U (dim x k), energies (multiplicative), and subspace scales\n        k = min(self.rank, self.dim)\n        if k > 0:\n            A = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :k].copy()\n            energies = np.ones(k)\n            sub_scale = np.full(k, sigma / np.sqrt(max(1, k)))\n        else:\n            U = np.zeros((self.dim, 0))\n            energies = np.array([])\n            sub_scale = np.array([])\n\n        # archive and buffers\n        X_arch = []\n        f_arch = []\n        success_buffer = []  # normalized steps (rows) for PCA refresh\n\n        # bookkeeping\n        evals = 0\n        init_seed = min(self.pop_base * 2, max(6, int(self.budget // 80)))\n        # seed archive with a few random evaluations\n        for _ in range(init_seed):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        # ensure at least one evaluation\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # control params\n        p_succ = 0.2\n        stagn_limit = max(5, int(self.stagn_frac * self.budget))\n        stagn_count = 0\n        gen = 0\n        momentum = np.zeros(self.dim)\n\n        # safe eval closure\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            return fx\n\n        # small helper: fit cheap diagonal quadratic in subspace (ridge) to propose u* (may return None)\n        def subspace_surrogate_minimize(center, U_sub, Xs, fs):\n            # project recent deltas into subspace coords\n            if U_sub.size == 0 or Xs.shape[0] < max(6, U_sub.shape[1] + 3):\n                return None\n            Z = (Xs - center).dot(U_sub)  # n x k\n            y = np.asarray(fs)\n            n, kk = Z.shape\n            # design [1, z1..zk, 0.5*z1^2..0.5*zk^2]\n            F = np.ones((n, 1 + kk + kk))\n            F[:, 1:1+kk] = Z\n            F[:, 1+kk:] = 0.5 * (Z**2)\n            # ridge regularization\n            lam = 1e-6 * (1.0 + np.var(y))\n            try:\n                A = F.T.dot(F) + lam * np.eye(F.shape[1])\n                b = F.T.dot(y)\n                theta = np.linalg.solve(A, b)\n                g = theta[1:1+kk]\n                hdiag = theta[1+kk:1+kk+kk]\n                # ensure positive curvature\n                hpos = np.maximum(hdiag, 1e-6)\n                # solve diag H u = -g\n                u_star = - g / (hpos + 1e-12)\n                # clip magnitude\n                max_norm = 6.0 * sigma\n                nrm = np.linalg.norm(u_star)\n                if nrm > max_norm and nrm > 0:\n                    u_star = u_star * (max_norm / (nrm + 1e-12))\n                return u_star\n            except Exception:\n                return None\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop_base, remaining)\n            # ensure even for mirrored pairs if possible\n            if lam % 2 == 1 and lam > 1:\n                lam -= 1\n            if lam <= 0:\n                break\n\n            # occasionally propose a surrogate minimizer in subspace\n            if (gen % max(3, self.pca_period // 2) == 0) and U.size and len(X_arch) >= max(8, 4 * k):\n                # use recent archive for surrogate\n                K = min(len(X_arch), 3 * max(10, k * 6))\n                Xr = np.asarray(X_arch[-K:])\n                fr = np.asarray(f_arch[-K:])\n                u_star = subspace_surrogate_minimize(m, U, Xr, fr)\n                if u_star is not None and evals < self.budget:\n                    x_prop = np.minimum(np.maximum(m + U.dot(u_star), lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        improved = False\n                        if f_prop < f_best:\n                            f_best = f_prop; x_best = x_prop.copy(); improved = True\n                            stagn_count = 0\n                        else:\n                            stagn_count += 1\n                        # acceptance (stronger if improving)\n                        accept = improved or (rng.rand() < np.exp(-max(0.0, f_prop - f_best) / (0.5 * sigma * avg_span + 1e-12)))\n                        if accept:\n                            eta = 0.6 if improved else 0.25\n                            delta = x_prop - m\n                            # trust clip\n                            trust = max(1e-12, 6.0 * sigma * np.sqrt(self.dim))\n                            dn = np.linalg.norm(delta)\n                            if dn > trust:\n                                delta = delta * (trust / (dn + 1e-12))\n                            m = np.minimum(np.maximum(m + eta * delta, lb), ub)\n                            # update momentum\n                            momentum = 0.85 * momentum + 0.15 * (eta * delta)\n                            # if improved, record normalized step for PCA\n                            if improved:\n                                u_norm = (delta / (sigma + 1e-12))\n                                success_buffer.append(u_norm.copy())\n                                if len(success_buffer) > self.buffer_size:\n                                    success_buffer.pop(0)\n                                # small sigma shrink on success\n                                sigma = max(1e-12, sigma * 0.88)\n\n            # mirrored / antithetic sampling\n            half = lam // 2\n            gen_success = False\n            directional_gains = np.zeros(k) if k > 0 else np.array([])\n            for i in range(half):\n                if evals + 2 > self.budget:\n                    break\n                # sample in subspace\n                if k > 0:\n                    # scale subspace coefficients by sqrt(energies)\n                    z_sub = rng.randn(k) * np.sqrt(np.maximum(energies, 1e-12))\n                    low = U.dot(z_sub)\n                else:\n                    low = np.zeros(self.dim)\n                # diagonal jitter: adaptive per-dim\n                z_diag = rng.randn(self.dim) * (sigma_diag)\n                step = sigma * (low + z_diag)\n                # bias by momentum small fraction to encourage direction persistence\n                plus = np.minimum(np.maximum(m + step + 0.15 * momentum, lb), ub)\n                minus = np.minimum(np.maximum(m - step + 0.15 * momentum, lb), ub)\n                f_plus = safe_eval(plus); \n                if f_plus is None:\n                    break\n                f_minus = safe_eval(minus)\n                if f_minus is None:\n                    break\n\n                # store to archive already done by safe_eval\n                # update best\n                improved_pair = False\n                if f_plus < f_best:\n                    f_best = f_plus; x_best = plus.copy(); improved_pair = True; stagn_count = 0\n                if f_minus < f_best:\n                    f_best = f_minus; x_best = minus.copy(); improved_pair = True; stagn_count = 0\n                if not improved_pair:\n                    stagn_count += 1\n\n                gen_success = gen_success or improved_pair\n\n                # directional attribution: reward subspace components proportional to projection of step onto U\n                if k > 0:\n                    proj = z_sub  # because step ≈ sigma * U z_sub + diag; projection on U is approx z_sub * sigma\n                    # reward proportional to (f_minus - f_plus) * abs(proj)\n                    gain = max(0.0, (f_minus - f_plus))\n                    if gain > 0:\n                        directional_gains += gain * np.abs(proj)\n\n                # if either improved, record normalized accepted step(s)\n                if improved_pair:\n                    # choose better candidate among the two and record its normalized step\n                    if f_plus <= f_minus:\n                        delta = (plus - m) / (sigma + 1e-12)\n                    else:\n                        delta = (minus - m) / (sigma + 1e-12)\n                    success_buffer.append(delta.copy())\n                    if len(success_buffer) > self.buffer_size:\n                        success_buffer.pop(0)\n\n                # optionally move mean towards the better of the pair softly\n                # pick winner among pair\n                if f_plus <= f_minus:\n                    winner = plus; fw = f_plus\n                else:\n                    winner = minus; fw = f_minus\n                # acceptance of winner into mean (probabilistic)\n                accept = False\n                if fw <= f_best:\n                    accept = True\n                else:\n                    # allow uphill sometimes\n                    temp = max(1e-12, 0.6 * sigma * avg_span * (1.0 - evals / max(1.0, self.budget)))\n                    if rng.rand() < np.exp(-max(0.0, fw - f_best) / (temp + 1e-12)):\n                        accept = True\n                if accept:\n                    eta = 0.28 if not improved_pair else 0.45\n                    delta = winner - m\n                    trust = max(1e-12, 6.0 * sigma * np.sqrt(self.dim))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + eta * delta, lb), ub)\n                    # update momentum\n                    momentum = 0.86 * momentum + 0.14 * (eta * delta)\n                    # success-based sigma shrink\n                    if improved_pair:\n                        sigma = max(1e-12, sigma * 0.93)\n\n                # update per-dim RMS and sigma_diag from both evaluated steps\n                # use average absolute step normalized by sigma\n                avg_abs = (np.abs(plus - m) + np.abs(minus - m)) / (2.0 * (sigma + 1e-12))\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * (avg_abs ** 2)\n                sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-8), 1e-12, 4.0 * np.max(span))\n\n            # end mirrored block\n\n            # reallocate energies in subspace from accumulated gains\n            if k > 0 and np.sum(directional_gains) > 0:\n                g = directional_gains\n                g = g - g.max()\n                denom = (np.std(g) + 1e-12)\n                scaled = np.exp(g / (denom + 1e-12))\n                scaled = scaled / (np.sum(scaled) + 1e-12)\n                # multiplicative / smoothed update of energies\n                energies = np.clip( (1.0 - self.energy_lr) * energies + self.energy_lr * (scaled * np.sum(energies)), 1e-6, 1e6 )\n\n            # update smoothed success rate and adapt sigma\n            p_succ = 0.92 * p_succ + 0.08 * (1.0 if gen_success else 0.0)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, 1e-12, 4.0 * np.max(span))\n            # keep sigma_diag consistent\n            sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-8), 1e-12, 4.0 * np.max(span))\n\n            # periodic PCA refresh of U from success_buffer\n            if (gen % max(1, self.pca_period) == 0) and len(success_buffer) >= max(3, k):\n                B = np.asarray(success_buffer)\n                # center rows\n                Bc = B - np.mean(B, axis=0, keepdims=True)\n                try:\n                    U_s, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    r_eff = min(k, Vt.shape[0])\n                    if r_eff > 0:\n                        U_new = Vt[:r_eff].T\n                        # blend basis softly\n                        if U.shape[1] == r_eff:\n                            U = 0.85 * U + 0.15 * U_new\n                        else:\n                            U = U_new.copy()\n                        # re-orthonormalize\n                        Q, _ = np.linalg.qr(U)\n                        U = Q[:, :r_eff]\n                        # update sub_scales from singular values\n                        svals = S_s[:r_eff]\n                        sub_scale = 0.8 * sub_scale[:r_eff] + 0.2 * (np.maximum(svals, 1e-12))\n                        # moderate smoothing of energies toward variance explained\n                        eig_energy = (S_s[:r_eff] ** 2) / max(1, Bc.shape[0] - 1)\n                        if eig_energy.size == energies.size:\n                            energies = 0.88 * energies + 0.12 * (eig_energy / (np.mean(eig_energy) + 1e-12) * np.mean(energies))\n                        else:\n                            # reshape energies\n                            energies = np.clip(eig_energy / (np.mean(eig_energy) + 1e-12), 1e-6, 1e6)\n                except Exception:\n                    pass\n\n            # opportunistic restart when stagnation prolonged\n            if stagn_count >= stagn_limit and evals < self.budget:\n                stagn_count = 0\n                # re-center around best with jitter and inflate sigma\n                jitter = max(0.04 * avg_span, 0.7 * sigma)\n                m = np.minimum(np.maximum(x_best + rng.randn(self.dim) * jitter, lb), ub)\n                sigma = max(sigma * self.restart_infl, 0.2 * avg_span)\n                v_rms = np.full(self.dim, 1e-6)\n                sigma_diag = np.full(self.dim, sigma)\n                # reinitialize subspace moderately\n                if k > 0:\n                    A = rng.randn(self.dim, k)\n                    Q, _ = np.linalg.qr(A)\n                    U = Q[:, :k]\n                    energies = np.ones(k)\n                    sub_scale = np.full(k, sigma / np.sqrt(max(1, k)))\n                # small local reseed evaluations around best\n                for _ in range(min(6, self.budget - evals)):\n                    x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                    f = safe_eval(x)\n                    if f is None:\n                        break\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n\n        # finished\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HASTMM scored 0.442 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ba26f129-6da8-46bd-88ce-1bbc98bfec1b", "operator": null, "metadata": {"aucs": [0.120157787247817, 0.2996845850861166, 0.4914199919881177, 0.9821868373176135, 0.49737299887767084, 0.6341996910588752, 0.25665203118743796, 0.4451292320326241, 0.4878961644986235, 0.20661892901447454]}, "task_prompt": ""}
{"id": "ea187148-44e9-4a75-bd95-7db4f3a654ed", "fitness": 0.17407853726389427, "name": "ACADS", "description": "1) Hybrid search: a compact CMA-style core samples from N(m, (sigma^2)C) with a small, budget-aware population (lam ≈ max(8,4+3·log(dim))), rank-mu weighted recombination using log-rank weights, and conservative covariance learning (cov_lr=0.2) with covariance and sigma initialization scaled to the problem span (C diag ∝ (span/4)^2, sigma = 0.25·mean_span).  \n2) Archive-guided exploration: an elite archive (6–12 entries seeded by init_samples = min(max(8,4·dim),budget)) provides anisotropic candidate injection (prob 0.18) and a principal archive direction via a cheap power-iteration; these feed a budget-aware directional line-search (line_budget_frac ≈ 0.04) that expands on success (×1.8) and shrinks on failure (×0.7), using a mixed direction (0.6 archive + 0.4 covariance eigenvector) and start step ≈0.8·sigma.  \n3) Robustness & budget discipline: all evaluations are strictly budget-counted, bounds are handled by reflect-then-clamp, SPD problems are fixed via Cholesky/eigendecomposition and small regularizers, sigma is adapted by a smoothed success-rate (sigma_adapt_rate≈0.18 toward success_target≈0.2), and opportunistic restarts with inflated sigma and jittered mean recover from stagnation.", "code": "import numpy as np\n\nclass ACADS:\n    \"\"\"\n    Archive-guided Covariance-Adaptive Directional Search (ACADS)\n\n    One-line: Combine a compact CMA-style covariance/mean sampler and success-rate sigma adaptation\n    with an archive-driven, budget-aware directional line-search to get robust global-local search.\n\n    - Maintain mean m, covariance C and global step size sigma; sample small Gaussian batches N(m, sigma^2 C).\n    - Keep an elite archive updated on every evaluation; extract principal directions from the archive.\n    - Update mean by weighted recombination of top candidates and update C with a rank-mu style estimate.\n    - Adapt sigma via a smoothed success-rate (approx 1/5th rule).\n    - Occasionally run a budget-limited directional line-search along archive/CMA principal directions (expand-on-success).\n    - SPD safeguards (Cholesky + eigen fixes), reflect-then-clamp bounds, and opportunistic restarts on stagnation.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 cov_lr=0.2,\n                 sigma_adapt_rate=0.18,\n                 success_target=0.2,\n                 archive_size=None,\n                 init_samples=None,\n                 line_budget_frac=0.04,\n                 stagnation_iters_frac=0.05,\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.cov_lr = float(cov_lr)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.success_target = float(success_target)\n        self.archive_size = archive_size\n        self.init_samples = init_samples\n        self.line_budget_frac = float(line_budget_frac)\n        self.stagnation_iters_frac = float(stagnation_iters_frac)\n        self.seed = seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        # bounds handling (expected -5..5 but remain generic)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        mean_span = float(np.mean(span))\n        max_span = float(np.max(span))\n\n        # population size (compact)\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # initial sampling count\n        if self.init_samples is None:\n            init_samples = min(max(8, 4 * self.dim), self.budget)\n        else:\n            init_samples = int(min(self.init_samples, self.budget))\n\n        # archive size\n        if self.archive_size is None:\n            archive_k = max(6, min(12, init_samples // 2))\n        else:\n            archive_k = int(self.archive_size)\n\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of tuples (f, x) sorted by f ascending\n\n        def reflect_clamp(x):\n            x = np.asarray(x, dtype=float).copy()\n            below = x < lb\n            if np.any(below):\n                x[below] = lb[below] + (lb[below] - x[below])\n            above = x > ub\n            if np.any(above):\n                x[above] = ub[above] - (x[above] - ub[above])\n            np.minimum(np.maximum(x, lb), ub, out=x)\n            return x\n\n        def add_archive(fv, xv):\n            nonlocal archive\n            xv = xv.copy()\n            if len(archive) < archive_k or fv < archive[-1][0]:\n                archive.append((float(fv), xv))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n\n        def eval_record(x):\n            nonlocal evals, f_best, x_best\n            if evals >= self.budget:\n                return None\n            x = reflect_clamp(x)\n            f = float(func(x))\n            evals += 1\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            add_archive(f, x)\n            return f, x\n\n        # initial uniform sampling to seed archive and mean\n        X0 = []\n        F0 = []\n        for i in range(init_samples):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            res = eval_record(x0)\n            if res is None:\n                break\n            f0, x0 = res\n            X0.append(x0.copy()); F0.append(f0)\n        if len(X0) == 0:\n            # fallback pick one\n            res = eval_record(rng.uniform(lb, ub))\n            if res is None:\n                self.f_opt = np.inf\n                self.x_opt = np.zeros(self.dim)\n                return self.f_opt, self.x_opt\n            f0, x0 = res\n            X0.append(x0.copy()); F0.append(f0)\n\n        X0 = np.vstack(X0)\n        F0 = np.array(F0, dtype=float)\n\n        # initialize mean as best or weighted top-half\n        order0 = np.argsort(F0)\n        mu0 = max(1, X0.shape[0] // 2)\n        elites = X0[order0[:mu0]]\n        weights = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        weights = np.maximum(weights, 0.0)\n        if np.sum(weights) <= 0:\n            weights = np.ones_like(weights)\n        weights = weights / np.sum(weights)\n        m = (weights.reshape(-1, 1) * elites).sum(axis=0)\n\n        # covariance and sigma initialization (moderate)\n        C = np.diag(((span / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-8, 0.25 * mean_span)\n\n        # success smoothing and stagnation\n        p_succ = float(self.success_target)\n        stagn_iters = 0\n        stagn_threshold = max(3, int(self.stagnation_iters_frac * max(10, self.budget)))\n        gen = 0\n\n        # helpers for SPD decomposition\n        def chol_or_eig(mat):\n            eps = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        # principal direction from archive via power iteration (cheap)\n        def archive_principal_direction():\n            if len(archive) <= 1:\n                v = rng.randn(self.dim)\n                v /= max(1e-12, np.linalg.norm(v))\n                return v\n            pts = np.stack([a[1] for a in archive], axis=0)\n            M = pts - np.mean(pts, axis=0)\n            cov = (M.T @ M) / max(1.0, M.shape[0]) + 1e-8 * np.eye(self.dim)\n            b = rng.randn(self.dim)\n            for _ in range(8):\n                b = cov @ b\n                nrm = np.linalg.norm(b)\n                if nrm == 0:\n                    b = rng.randn(self.dim)\n                else:\n                    b /= nrm\n            return b / (np.linalg.norm(b) + 1e-16)\n\n        # budget-aware directional line-search (expand on success)\n        def directional_line_search(x0, f0, direction, budget_for_line, start_step):\n            nonlocal evals, f_best, x_best\n            if budget_for_line <= 0 or evals >= self.budget:\n                return f0, x0\n            d = np.array(direction, dtype=float)\n            nrm = np.linalg.norm(d)\n            if nrm == 0:\n                d = rng.randn(self.dim)\n                d /= np.linalg.norm(d)\n            else:\n                d = d / nrm\n            s = float(start_step)\n            best_x = x0.copy()\n            best_f = float(f0)\n            remaining = min(budget_for_line, self.budget - evals)\n            # try centered expansions\n            while remaining > 0 and s > 1e-12:\n                # +s\n                if remaining <= 0:\n                    break\n                xp = reflect_clamp(x0 + s * d)\n                res = eval_record(xp)\n                remaining = min(budget_for_line, self.budget - evals)\n                if res is None:\n                    break\n                fp, xp = res\n                if fp < best_f:\n                    best_f = fp\n                    best_x = xp.copy()\n                    # expand aggressively\n                    x0, f0 = best_x.copy(), best_f\n                    s *= 1.8\n                    remaining = min(budget_for_line, self.budget - evals)\n                    continue\n                # -s\n                if remaining <= 0:\n                    break\n                xn = reflect_clamp(x0 - s * d)\n                res = eval_record(xn)\n                remaining = min(budget_for_line, self.budget - evals)\n                if res is None:\n                    break\n                fn, xn = res\n                if fn < best_f:\n                    best_f = fn\n                    best_x = xn.copy()\n                    x0, f0 = best_x.copy(), best_f\n                    s *= 1.8\n                    remaining = min(budget_for_line, self.budget - evals)\n                    continue\n                # shrink if no improvement\n                s *= 0.7\n                remaining = min(budget_for_line, self.budget - evals)\n            return best_f, best_x\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            batch = min(lam, remaining)\n            mu = max(1, batch // 2)\n\n            # recompute weights\n            w = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            w = np.maximum(w, 0.0)\n            if np.sum(w) <= 0:\n                w = np.ones_like(w)\n            w = w / np.sum(w)\n            W = w.reshape(-1, 1)\n\n            # ensure SPD factor\n            A = chol_or_eig(C)\n\n            # sample batch from N(m, sigma^2 C)\n            Z = rng.normal(size=(batch, self.dim))\n            Y = Z @ A.T\n            Xcand = m + sigma * Y\n\n            # occasionally inject archive-informed anisotropic candidate (one slot)\n            if len(archive) >= 3 and rng.rand() < 0.18:\n                # build anisotropic perturbation from per-dim archive variance\n                pts = np.stack([a[1] for a in archive], axis=0)\n                per_dim_var = np.var(pts, axis=0) + 1e-8\n                scale_diag = np.sqrt(per_dim_var) * (0.8 + 0.5 * rng.rand(self.dim))\n                # center on best with small bias\n                center = archive[0][1]\n                anis = center + (rng.randn(self.dim) * scale_diag) * (0.6 * sigma / max(1e-12, mean_span) + 0.05)\n                # replace random slot\n                idx_rep = rng.randint(0, Xcand.shape[0])\n                Xcand[idx_rep] = anis\n\n            # clamp candidates\n            Xcand = np.minimum(np.maximum(Xcand, lb), ub)\n\n            # evaluate sequentially with strict budget\n            fc = np.full(batch, np.inf, dtype=float)\n            improved = False\n            for i in range(batch):\n                if evals >= self.budget:\n                    break\n                res = eval_record(Xcand[i])\n                if res is None:\n                    break\n                fci, xci = res\n                fc[i] = fci\n                if fci < f_best:\n                    # eval_record already updated global best and archive\n                    improved = True\n\n            # if no valid candidates due to budget, break\n            valid_mask = np.isfinite(fc)\n            if not np.any(valid_mask):\n                break\n            Xcand = Xcand[valid_mask]\n            fc = fc[valid_mask]\n            batch = fc.shape[0]\n            mu = max(1, batch // 2)\n            # selection: top-mu\n            order = np.argsort(fc)\n            X_mu = Xcand[order[:mu]]\n\n            # compute normalized deltas and weighted covariance (in normalized coordinates)\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            if deltas.shape[0] > 0:\n                weighted_cov = (deltas * W[:deltas.shape[0]]).T @ deltas\n                delta_mean = (W[:deltas.shape[0]] * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # update covariance (rank-mu) and add small regularization\n            C = (1.0 - self.cov_lr) * C + self.cov_lr * weighted_cov\n            C = 0.5 * (C + C.T) + np.diag(np.maximum(np.diag(C), 1e-18))\n\n            # update mean toward elite recombination\n            if X_mu.shape[0] > 0:\n                m = np.minimum(np.maximum((W[:X_mu.shape[0]] * X_mu).sum(axis=0), lb), ub)\n\n            # adapt sigma via smoothed success-rate (approx 1/5th)\n            p_succ = 0.9 * p_succ + 0.1 * float(improved)\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, 1e-12, 2.0 * max_span)\n\n            # opportunistic directional local search occasionally or on stagnation\n            if (gen % 8 == 0 and evals < self.budget) or stagn_iters >= stagn_threshold:\n                # allocate budget for line-search\n                remaining = self.budget - evals\n                line_alloc = min(max(2, int(self.line_budget_frac * self.budget)), remaining)\n                if line_alloc > 0 and len(archive) > 0:\n                    # choose direction: mix archive principal direction and covariance principal eigenvector\n                    dir_a = archive_principal_direction()\n                    # principal eigenvector of C via power iteration\n                    b = rng.randn(self.dim)\n                    for _ in range(8):\n                        b = C @ b\n                        nrm = np.linalg.norm(b)\n                        if nrm == 0:\n                            b = rng.randn(self.dim)\n                        else:\n                            b /= nrm\n                    dir_c = b / (np.linalg.norm(b) + 1e-16)\n                    dir_mix = 0.6 * dir_a + 0.4 * dir_c\n                    dir_mix /= (np.linalg.norm(dir_mix) + 1e-16)\n                    # start point: best or current mean with small prob\n                    start_x = x_best.copy() if (x_best is not None and rng.rand() < 0.9) else m.copy()\n                    start_f = f_best\n                    # start step proportional to sigma and domain\n                    start_step = max(1e-12, 0.8 * sigma)\n                    f_after, x_after = directional_line_search(start_x, start_f, dir_mix, line_alloc, start_step)\n                    if f_after < f_best:\n                        f_best = f_after\n                        x_best = x_after.copy()\n                        stagn_iters = 0\n                        # nudge mean and covariance gently toward improvement\n                        m = 0.9 * m + 0.1 * x_after\n                        s = (x_after - m) / (sigma + 1e-20)\n                        C = 0.98 * C + 0.02 * np.outer(s, s)\n                    else:\n                        stagn_iters += 1\n                else:\n                    stagn_iters += 1\n            else:\n                # track stagnation based on generation improvements\n                if improved:\n                    stagn_iters = 0\n                else:\n                    stagn_iters += 1\n\n            # opportunistic restart if stagnated too long or sigma collapsed\n            if stagn_iters * lam >= stagn_threshold and evals < self.budget:\n                stagn_iters = 0\n                # inflate sigma and re-center around best with jitter\n                jitter = (rng.randn(self.dim) * (0.4 * sigma + 0.05 * span))\n                if x_best is None:\n                    m = rng.uniform(lb, ub)\n                else:\n                    m = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                C = np.diag(((span / 6.0) ** 2).clip(min=1e-12))\n                sigma = max(sigma, 0.4 * mean_span)\n                p_succ = self.success_target\n\n            # SPD safeguard\n            try:\n                _ = np.linalg.cholesky(C + np.eye(self.dim) * 1e-16)\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                C = (vecs * vals) @ vecs.T\n\n        # finalize best\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ACADS scored 0.174 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "ba26f129-6da8-46bd-88ce-1bbc98bfec1b", "operator": null, "metadata": {"aucs": [0.0875852170996737, 0.14986739317796627, 0.24421001935595132, 0.2069965218810269, 0.16699886765309402, 0.19288751950113725, 0.20730928771622503, 0.1706455954830043, 0.17266284755892736, 0.14162210321193658]}, "task_prompt": ""}
{"id": "7085e0ca-6bc0-45d8-b32a-44eb8685728e", "fitness": 0.24518903313279017, "name": "MAMOS", "description": "MAMOS maintains an evaluated archive and a moving search center m, seeded by random sampling, and adapts a trust radius (initialized as 0.18·avg_span) based on an entropy/diversity signal of the archive so it expands when search is stuck and shrinks on improvement. It learns a low-rank linear manifold via PCA (default subspace_dim = max(1, dim//6), pca_window=120) and fits a lightweight diagonal quadratic surrogate in that subspace to propose local minimizers, while also sampling anisotropically from an elites’ covariance (robust sqrt-cov) to capture important directions. Exploration is hybridized: a small PSO-like swarm (swarm_size ~6) does local moves, Levy heavy-tailed jumps (scale ≈ 3.5·trust_radius) provide global escapes, coordinate pattern probes and Gaussian jitter do fine local searches, and per-dimension RMS + momentum modulate step sizes. Operator choice is adapted with a UCB-like bandit (c≈1.2, small randomization), candidates update m by a softmax-weighted aggregation (lr tuned by trust_radius: 0.45 or 0.25), and stagnation triggers targeted re-seeding/restoration and archive trimming to stay sample-efficient within the budget.", "code": "import numpy as np\n\nclass MAMOS:\n    \"\"\"\n    Manifold-Adaptive Multi-Operator Search (MAMOS)\n\n    Key ideas (high level):\n    - Maintain an archive and a current search center m.\n    - Learn a low-rank linear manifold (PCA) from recent archive and fit a light-weight diagonal-quadratic surrogate in that subspace.\n    - Maintain a small particle swarm for local exploration (PSO-like updates) and complement with heavy-tailed escapes (Levy),\n      coordinate pattern probes, and random jitter.\n    - Use an operator-bandit (UCB-like) scheme to adapt which operator to call more often based on historical success.\n    - Use an entropy/diversity signal to expand/shrink a global trust radius and to control exploration intensity.\n    - Update search center via softmax-weighted aggregation of evaluated candidates (mirror-softmax style),\n      blending exploration and exploitation.\n    Notes:\n    - Goal: robust, sample-efficient continuous black-box optimizer for [-5,5]^d style bounds (Many Affine BBOB).\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=12, swarm_size=6, subspace_dim=None,\n                 init_radius=0.18, rms_beta=0.93,\n                 pca_window=120, min_radius=1e-8, max_radius=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.swarm_size = int(min(swarm_size, pop))\n        self.subspace_dim = subspace_dim if subspace_dim is not None else max(1, self.dim // 6)\n        self.init_radius = float(init_radius)\n        self.rms_beta = float(rms_beta)\n        self.pca_window = int(pca_window)\n        self.min_radius = float(min_radius)\n        self.max_radius = float(max_radius)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling (support scalar or vector)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # internal state\n        evals = 0\n        X_arch = []\n        f_arch = []\n\n        # initialize center m by a small Latin-ish seeding\n        seed0 = min(max(20, int(self.budget // 200)), self.pop * 6)\n        for _ in range(seed0):\n            if evals >= self.budget: break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            fx0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(fx0)\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            fx0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(fx0)\n\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        m = x_best.copy()\n        trust_radius = max(self.min_radius, self.init_radius * avg_span)\n        per_dim_rms = np.full(self.dim, 1e-6)\n        momentum = np.zeros(self.dim)\n\n        # initialize small swarm around center\n        swarm_pos = [np.minimum(np.maximum(m + 0.02 * avg_span * rng.randn(self.dim), lb), ub) for _ in range(self.swarm_size)]\n        swarm_vel = [0.2 * trust_radius * rng.randn(self.dim) for _ in range(self.swarm_size)]\n        swarm_best_pos = swarm_pos.copy()\n        swarm_best_val = []\n        for x in swarm_pos:\n            # we may not have budget to evaluate all; but evaluate as possible\n            if evals >= self.budget: break\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            swarm_best_val.append(fx)\n        # if budget exhausted, still continue returning best found\n        if len(f_arch) > 0:\n            idx_best = int(np.argmin(f_arch))\n            x_best = X_arch[idx_best].copy()\n            f_best = float(f_arch[idx_best])\n            m = x_best.copy()\n\n        # operator bandit stats for UCB-like selection\n        operators = ['manifold_min', 'particle_move', 'levy_jump', 'pattern_probe', 'jitter']\n        op_stats = {op: {'succ': 1e-6, 'total': 1e-6} for op in operators}  # small priors\n\n        # helper: safe evaluation counting budget\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch, x_best, f_best\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # trim archive if very large\n            if len(X_arch) > 5 * max(self.pca_window, self.pop):\n                excess = len(X_arch) - 5 * max(self.pca_window, self.pop)\n                del X_arch[0:excess]\n                del f_arch[0:excess]\n            # update best\n            if fx < f_best:\n                x_best = x.copy(); f_best = float(fx)\n            return fx\n\n        # helper: compute elites and robust sqrt-cov of elites for anisotropic sampling\n        def get_elites(k_frac=0.15):\n            n = len(X_arch)\n            if n == 0:\n                return np.empty((0, self.dim))\n            k = max(3, int(np.ceil(k_frac * max(20, n))))\n            idxs = np.argsort(f_arch)[:min(k, n)]\n            return np.asarray([X_arch[i].copy() for i in idxs])\n\n        def robust_sqrt_cov(Xe):\n            if Xe.size == 0:\n                return np.eye(self.dim)\n            C = np.cov(Xe.T) + 1e-9 * np.eye(self.dim)\n            try:\n                w, V = np.linalg.eigh(C)\n                w = np.maximum(w, 1e-12)\n                return V.dot(np.diag(np.sqrt(w))).dot(V.T)\n            except Exception:\n                U, s, Vt = np.linalg.svd(C)\n                return U.dot(np.diag(np.sqrt(s))).dot(Vt)\n\n        # helper: build low-rank subspace (PCA) from recent window\n        def learn_subspace(k=self.subspace_dim):\n            if len(X_arch) < (k + 4):\n                return np.zeros((self.dim, 0))\n            K = min(len(X_arch), self.pca_window)\n            Xr = np.asarray(X_arch[-K:])\n            M = Xr.mean(axis=0)\n            S = Xr - M\n            try:\n                U, s, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(k, Vt.shape[0])\n                if r_eff <= 0:\n                    return np.zeros((self.dim, 0))\n                B = Vt[:r_eff].T.copy()\n                # small random orthonormal mix to avoid exact freezing\n                if r_eff < self.dim:\n                    noise = 0.02 * rng.randn(r_eff, r_eff)\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(r_eff) + noise)\n                        B = B.dot(Qr)\n                    except Exception:\n                        pass\n                return B\n            except Exception:\n                return np.zeros((self.dim, 0))\n\n        # helper: fit diagonal quadratic in subspace z (lightweight)\n        # model: f ≈ c + g^T z + 0.5 * sum_i h_i * z_i^2\n        def fit_diag_quadratic(B, samples= min(120, max(12, self.subspace_dim * 10)), reg=1e-6):\n            r = B.shape[1]\n            if r == 0 or len(X_arch) < (r + 6):\n                return None, None, None\n            K = min(samples, len(X_arch))\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(B)  # shape n x r\n            n = Z.shape[0]\n            # design: columns: [1, z1..zr, z1^2..zr^2]\n            Phi = np.ones((n, 1 + r + r))\n            Phi[:, 1:1 + r] = Z\n            Phi[:, 1 + r:1 + r + r] = Z ** 2\n            try:\n                A = Phi.T.dot(Phi) + reg * np.eye(Phi.shape[1])\n                b = Phi.T.dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1 + r]\n                h_diag = coeff[1 + r:1 + r + r]\n                # ensure curvature not too negative\n                h_diag = np.where(h_diag < 1e-8, 1e-8, h_diag)\n                # compute minimizer z* = - g / h_diag\n                z_star = - g / (h_diag + 1e-12)\n                # clip by trust in subspace\n                z_norm = np.linalg.norm(z_star)\n                max_z = (trust_radius / (np.linalg.norm(B, ord=2) + 1e-12)) * np.sqrt(max(1, r))\n                if z_norm > max_z:\n                    z_star = z_star * (max_z / (z_norm + 1e-12))\n                f_pred = float(c + g.dot(z_star) + 0.5 * np.sum(h_diag * (z_star ** 2)))\n                return z_star, f_pred, (g, h_diag, c)\n            except Exception:\n                return None, None, None\n\n        # helper: simple Levy draw (normalized)\n        def levy_step(scale=1.0):\n            z = rng.standard_cauchy(size=self.dim)\n            # clip extreme tails but keep heavy-tailed character\n            clip = np.percentile(np.abs(z), 92) + 1e-12\n            z = z / clip\n            return scale * z\n\n        # helper: UCB-like operator selection (choose operator)\n        def select_operator(total_rounds):\n            # compute UCB score for each operator\n            scores = {}\n            c = 1.2\n            for op in operators:\n                s = op_stats[op]['succ']\n                t = op_stats[op]['total']\n                mean = s / (t + 1e-12)\n                bonus = c * np.sqrt(np.log(total_rounds + 1.0) / (t + 1e-12))\n                scores[op] = mean + bonus\n            # choose argmax, but add occasional randomization\n            if rng.rand() < 0.08:\n                return rng.choice(operators)\n            return max(scores.items(), key=lambda x: x[1])[0]\n\n        total_ops = 1.0\n        gen = 0\n        stagn = 0\n        stagn_limit = max(10, int(0.02 * self.budget))\n\n        # main loop: generate candidate batches until budget exhausted\n        while evals < self.budget:\n            gen += 1\n\n            # periodic subspace learning\n            if gen % max(1, int(self.pca_window // 8)) == 0:\n                B = learn_subspace(self.subspace_dim)\n            else:\n                # keep previous B or learn on first iteration if not set\n                try:\n                    B\n                except NameError:\n                    B = learn_subspace(self.subspace_dim)\n\n            Xe = get_elites()\n            S_sqrt = robust_sqrt_cov(Xe) if Xe.size else np.eye(self.dim)\n\n            # compute diversity (entropy-like) across archive covariance eigenvalues\n            diversity = 0.0\n            if len(X_arch) >= 4:\n                try:\n                    Cfull = np.cov(np.asarray(X_arch).T) + 1e-12 * np.eye(self.dim)\n                    ev = np.linalg.eigvalsh(Cfull)\n                    ev = np.maximum(ev, 1e-16)\n                    p = ev / np.sum(ev)\n                    diversity = -np.sum(p * np.log(p + 1e-12))\n                except Exception:\n                    diversity = 0.0\n\n            # adjust trust radius according to diversity (encourage expansion when low diversity)\n            if diversity < 0.6:\n                trust_radius = min(self.max_radius, trust_radius * 1.03)\n            else:\n                trust_radius = max(self.min_radius, trust_radius * 0.998)\n\n            # temperature for softmax center aggregation (smaller radius => more aggressive exploitation)\n            beta = max(1e-6, 0.6 / (trust_radius + 1e-12))\n\n            # produce a batch of candidates (size pop or remaining budget)\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            batch_X = []\n            batch_f = []\n            batch_strat = []\n\n            for ci in range(n_cand):\n                if evals >= self.budget: break\n                total_ops += 1.0\n                op = select_operator(total_ops)\n                strategy = op\n                x_cand = None\n                f_c = None\n\n                if op == 'manifold_min':\n                    # try subspace diagonal quadratic fit and propose minimizer in full space\n                    z_star, f_pred, params = fit_diag_quadratic(B)\n                    if z_star is not None:\n                        x_prop = np.minimum(np.maximum(m + B.dot(z_star), lb), ub)\n                        f_prop = safe_eval(x_prop)\n                        if f_prop is None:\n                            break\n                        x_cand = x_prop; f_c = f_prop\n                    else:\n                        # fallback: sample anisotropic around center using elites covariance\n                        z = rng.randn(self.dim)\n                        step = 1.2 * trust_radius * S_sqrt.dot(z)\n                        x_prop = np.minimum(np.maximum(m + step, lb), ub)\n                        f_prop = safe_eval(x_prop)\n                        if f_prop is None:\n                            break\n                        x_cand = x_prop; f_c = f_prop\n\n                elif op == 'particle_move':\n                    # choose a particle, update velocity with cognitive & social terms\n                    pid = rng.randint(0, max(1, len(swarm_pos)))\n                    if pid >= len(swarm_pos):\n                        # initialize if needed\n                        swarm_pos.append(np.minimum(np.maximum(m + 0.02 * avg_span * rng.randn(self.dim), lb), ub))\n                        swarm_vel.append(0.2 * trust_radius * rng.randn(self.dim))\n                        swarm_best_pos.append(swarm_pos[-1].copy())\n                        if evals < self.budget:\n                            fx = safe_eval(swarm_pos[-1])\n                            if fx is None:\n                                break\n                            swarm_best_val.append(fx)\n                    # update\n                    w = 0.65\n                    c1 = 0.9; c2 = 0.9\n                    r1 = rng.rand(self.dim); r2 = rng.rand(self.dim)\n                    pbest = swarm_best_pos[pid]\n                    gbest = x_best\n                    vel = w * swarm_vel[pid] + c1 * r1 * (pbest - swarm_pos[pid]) + c2 * r2 * (gbest - swarm_pos[pid])\n                    # scale velocity by trust\n                    vel = vel * (trust_radius / (np.linalg.norm(vel) + 1e-12)) * min(1.0, np.linalg.norm(vel) / (0.5 * trust_radius) + 1e-12)\n                    new_pos = np.minimum(np.maximum(swarm_pos[pid] + vel + 0.06 * momentum, lb), ub)\n                    f_new = safe_eval(new_pos)\n                    if f_new is None:\n                        break\n                    swarm_vel[pid] = vel\n                    swarm_pos[pid] = new_pos\n                    if f_new < (swarm_best_val[pid] if pid < len(swarm_best_val) else 1e99):\n                        if pid < len(swarm_best_val):\n                            swarm_best_val[pid] = f_new\n                            swarm_best_pos[pid] = new_pos.copy()\n                        else:\n                            swarm_best_val.append(f_new); swarm_best_pos.append(new_pos.copy())\n                    x_cand = new_pos; f_c = f_new\n\n                elif op == 'levy_jump':\n                    # heavy-tailed global jump from either center or a random elite\n                    if Xe.size and rng.rand() < 0.6:\n                        center = Xe[rng.randint(0, Xe.shape[0])]\n                    else:\n                        center = m\n                    step = levy_step(scale=3.5 * trust_radius)\n                    x_prop = np.minimum(np.maximum(center + step + 0.08 * momentum, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is None:\n                        break\n                    x_cand = x_prop; f_c = f_prop\n\n                elif op == 'pattern_probe':\n                    # coordinate pattern along top variance dims (try positive and negative)\n                    var = np.var(np.asarray(X_arch), axis=0) if len(X_arch) > 1 else np.ones(self.dim)\n                    idxs = np.argsort(-var)[:max(1, min(6, self.dim // 2))]\n                    found = False\n                    for i in idxs:\n                        if evals >= self.budget: break\n                        a = 0.9 * trust_radius\n                        for sign in (1.0, -1.0):\n                            x_try = np.minimum(np.maximum(m + sign * a * np.eye(1, self.dim, i).flatten(), lb), ub)\n                            f_try = safe_eval(x_try)\n                            if f_try is None:\n                                break\n                            if f_try < f_best - 1e-12:\n                                x_cand = x_try; f_c = f_try; found = True; break\n                        if found:\n                            break\n                    if not found and x_cand is None:\n                        # jitter fallback\n                        step = 0.9 * trust_radius * rng.randn(self.dim)\n                        x_try = np.minimum(np.maximum(m + step, lb), ub)\n                        f_try = safe_eval(x_try)\n                        if f_try is None:\n                            break\n                        x_cand = x_try; f_c = f_try\n\n                else:  # jitter\n                    step = trust_radius * rng.randn(self.dim)\n                    x_try = np.minimum(np.maximum(m + step + 0.06 * momentum, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try; f_c = f_try\n\n                # if no evaluation (budget exhausted) break\n                if f_c is None:\n                    break\n\n                # record batch result for center aggregation later\n                batch_X.append(np.asarray(x_cand, dtype=float))\n                batch_f.append(float(f_c))\n                batch_strat.append(strategy)\n\n                # quick local bookkeeping: reward operator if it improved global best\n                improved = (f_c < f_best)\n                if improved:\n                    op_stats[op]['succ'] += 1.0\n                op_stats[op]['total'] += 1.0\n\n                # update per-dim RMS using the step that produced candidate relative to center\n                step_vec = x_cand - m\n                sq = (step_vec / (trust_radius + 1e-12)) ** 2\n                per_dim_rms = self.rms_beta * per_dim_rms + (1.0 - self.rms_beta) * sq\n                # adapt small per-dim step modifiers (used inside jitter or velocity scaling)\n                per_dim_scale = np.clip(trust_radius / (np.sqrt(per_dim_rms) + 1e-9), 1e-8, self.max_radius)\n\n                # taboo-like small mechanism: negative reinforcement for repeated poor directions\n                if not improved:\n                    # slightly penalize operator's success history (but keep exploration)\n                    op_stats[op]['succ'] *= 0.9995\n\n                # stagnation update\n                if f_c < f_best - 1e-12:\n                    stagn = 0\n                    f_best = float(f_c); x_best = x_cand.copy()\n                else:\n                    stagn += 1\n\n                # opportunistic small random rotation of subspace to avoid lock-in\n                if B.shape[1] > 0 and rng.rand() < 0.04:\n                    try:\n                        r = B.shape[1]\n                        R = rng.randn(r, r) * 0.06\n                        Qr, _ = np.linalg.qr(np.eye(r) + R)\n                        B = B.dot(Qr)\n                    except Exception:\n                        pass\n\n            # if we collected any batch candidates, do a softmax aggregation to update center m\n            if len(batch_X) > 0:\n                Fs = np.asarray(batch_f)\n                Xs = np.asarray(batch_X)\n                # shift by best to form softmax weights (lower f -> higher weight)\n                f_shift = Fs - (np.min(Fs) if len(Fs) > 0 else f_best)\n                # temperature scaled by trust_radius and diversity (higher diversity -> larger temperature)\n                temp = max(1e-6, 0.8 * (trust_radius + 1e-12) * (1.0 + 0.5 * (0.8 - diversity)))\n                weights = np.exp(- (f_shift) / (temp + 1e-12))\n                weights = weights / (np.sum(weights) + 1e-12)\n                # soft update: exponential moving towards weighted average\n                x_mean = np.sum(weights[:, None] * Xs, axis=0)\n                lr = 0.45 if trust_radius < 0.5 * avg_span else 0.25\n                delta = x_mean - m\n                # clip delta by a trust-based limit\n                max_jump = 6.0 * trust_radius * np.sqrt(max(1, self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > max_jump:\n                    delta = delta * (max_jump / (dn + 1e-12))\n                m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                # update momentum\n                momentum = 0.78 * momentum + 0.22 * (lr * delta)\n\n                # reward/oppenent: if batch produced improvements, shrink trust to refine; else slowly expand\n                if np.any(np.asarray(batch_f) < f_best):\n                    trust_radius = max(self.min_radius, trust_radius * 0.83)\n                    per_dim_rms *= 0.985\n                else:\n                    trust_radius = min(self.max_radius, trust_radius * 1.015)\n                    momentum *= 0.97\n\n            # stagnation restart\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                # re-seed center near best plus a mixture of global noise and elite anisotropic perturbation\n                jitter = max(0.04 * avg_span, 2.0 * trust_radius)\n                if Xe.size:\n                    elite_center = Xe[rng.randint(0, Xe.shape[0])]\n                else:\n                    elite_center = x_best\n                m = np.minimum(np.maximum(elite_center + jitter * (0.8 * rng.randn(self.dim) + 0.2 * (S_sqrt.dot(rng.randn(self.dim)))), lb), ub)\n                trust_radius = min(self.max_radius, trust_radius * 1.8)\n                momentum = np.zeros(self.dim)\n                # reinitialize swarm\n                swarm_pos = [np.minimum(np.maximum(m + 0.03 * avg_span * rng.randn(self.dim), lb), ub) for _ in range(self.swarm_size)]\n                swarm_vel = [0.2 * trust_radius * rng.randn(self.dim) for _ in range(self.swarm_size)]\n                swarm_best_pos = swarm_pos.copy()\n                swarm_best_val = []\n                # take a few local refinement samples around best\n                reseed = min(6, self.budget - evals)\n                for _ in range(reseed):\n                    if evals >= self.budget: break\n                    x = np.minimum(np.maximum(x_best + 0.035 * avg_span * rng.randn(self.dim), lb), ub)\n                    fx = safe_eval(x)\n                    if fx is None:\n                        break\n                    if fx < f_best:\n                        f_best = fx; x_best = x.copy()\n\n        # store results\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MAMOS scored 0.245 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "03c4a78b-1749-4b5d-9b52-08b0dc80cbce", "operator": null, "metadata": {"aucs": [0.14806163784773907, 0.21572038105163172, 0.27956206234130154, 0.3192414848757663, 0.23868203410893796, 0.28842783448046505, 0.25069681100052443, 0.27358608367978743, 0.25382990984697795, 0.1840820920947699]}, "task_prompt": ""}
{"id": "8f195638-5170-49ce-8751-a51a004f388a", "fitness": 0.20370609001771706, "name": "SASB", "description": "1) A hybrid stochastic optimizer that mixes multiple proposal engines (global jitter, elite-shaped sampling from a robust archive, subspace quadratic surrogate minimization, subspace L‑BFGS quasi‑Newton, coordinate‑pattern moves, and tempered Student‑t heavy‑tail escapes) chosen probabilistically with jitter fallbacks to ensure coverage.  \n2) It operates mostly in a low‑rank adaptive subspace (default r ≈ dim//4) that is refreshed via robust SVD every pca_refresh iterations with conservative blending and occasional Householder perturbations, and fits a ridge‑regularized quadratic in that subspace where the regularizer scales with median variances (trace‑like) to keep surrogate fits stable.  \n3) Global control uses a scalar trust radius step_scale adapted from a short recent success window and a cooling temperature for Metropolis acceptance, while per‑coordinate RMS tracking (rms_beta ≈ 0.9) produces a diagonal step scaling; an archive with elite_frac (≈0.15) drives elite sampling and a median‑based robust covariance for shaped proposals.  \n4) Memory and quasi‑Newton acceleration are provided by storing full‑space secant pairs (s,y) that are projected into the subspace for a two‑loop L‑BFGS with a Barzilai‑Borwein scalar init; robustness is reinforced via weighted/median regressions, bounds enforcement, momentum smoothing, stagnation restarts toward elites, and tempered Student‑t escapes for heavy‑tail exploration.", "code": "import numpy as np\n\nclass SASB:\n    \"\"\"\n    Stochastic Adaptive Subspace Ensemble with Barzilai-Borwein steps (SASB)\n\n    Key ideas (differences vs ACTEQS):\n    - Subspace rank defaults to dim//4 (different ratio) and is refreshed more conservatively.\n    - Trust-region adapts from a short moving-window success ratio (not entropy) with different multipliers.\n    - Surrogates are fit with ridge whose regularization strength adapts to coordinate variances (robust trace-based lambda).\n    - Quasi-Newton proposals use Barzilai-Borwein (BB) style scalar initial Hessian approximation and\n      store limited-memory secants in the full space (not only subspace) with two-loop in the subspace.\n    - Heavy-tail escapes use tempered Student-t sampling (nu=3) scaled more moderately.\n    - Different mixing probabilities and learning rates, momentum is simpler, and occasional orthogonal Householder\n      rotations are used to perturb the subspace basis.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=16, subrank=None, elite_frac=0.15, init_step=0.08,\n                 rms_beta=0.90, pca_refresh=20,\n                 prob_elite=0.30, prob_subquad=0.20, prob_pattern=0.18,\n                 prob_qn=0.20, prob_student=0.05,\n                 min_step=1e-9, max_step=5.0, archive_size=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.subrank = subrank if subrank is not None else max(1, self.dim // 4)\n        self.elite_frac = float(elite_frac)\n        self.init_step = float(init_step)\n        self.rms_beta = float(rms_beta)\n        self.pca_refresh = int(pca_refresh)\n        # strategy probabilities (should sum < 1; leftovers -> jitter)\n        self.prob_elite = float(prob_elite)\n        self.prob_subquad = float(prob_subquad)\n        self.prob_pattern = float(prob_pattern)\n        self.prob_qn = float(prob_qn)\n        self.prob_student = float(prob_student)\n        self.min_step = float(min_step)\n        self.max_step = float(max_step)\n        self.archive_size = archive_size if archive_size is not None else max(20 * self.dim, 300)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling (BBOB style)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # state\n        m = rng.uniform(lb, ub, size=self.dim)           # search center\n        step_scale = max(self.min_step, self.init_step * avg_span)  # global trust radius (scalar)\n        step_diag = np.full(self.dim, step_scale)\n        v_rms = np.full(self.dim, 1e-6)\n        momentum = np.zeros(self.dim)\n\n        # subspace initialization (orthonormal columns)\n        r = min(self.subrank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()\n        else:\n            B = np.zeros((self.dim, 0))\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n        eliteK_min = 4\n\n        # secant memory in full space (store s = delta_x, y = delta_grad)\n        secant = []  # list of dicts {'s': , 'y': }\n\n        # helper: safe eval\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # maintain archive size\n            if len(X_arch) > self.archive_size:\n                excess = len(X_arch) - self.archive_size\n                del X_arch[0:excess]\n                del f_arch[0:excess]\n            return fx\n\n        # seeding\n        seed0 = min(self.pop * 6, max(24, int(self.budget // 160)))\n        for _ in range(seed0):\n            if evals >= self.budget: break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n        if len(f_arch) == 0 and evals < self.budget:\n            safe_eval(rng.uniform(lb, ub, size=self.dim))\n\n        # init best\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        gen = 0\n        # adapt via recent window success ratio\n        recent_success = []\n        success_window = max(12, int(0.01 * self.budget))\n        stagn = 0\n        stagn_limit = max(15, int(0.03 * self.budget))\n\n        # helpers\n        def get_elites():\n            if len(X_arch) == 0:\n                return np.empty((0, self.dim)), np.empty((0,))\n            k = max(eliteK_min, int(np.ceil(self.elite_frac * len(X_arch))))\n            k = min(k, len(X_arch))\n            idxs = np.argsort(f_arch)[:k]\n            Xe = np.asarray([X_arch[i].copy() for i in idxs])\n            Fe = np.asarray([f_arch[i] for i in idxs])\n            return Xe, Fe\n\n        def robust_sqrt_cov(Xe):\n            # robustify via median absolute deviation + shrinkage\n            if Xe.size == 0:\n                return np.eye(self.dim)\n            C = np.cov(Xe.T)  # might be low-rank\n            # shrink towards diagonal using robust scale\n            mad = np.median(np.abs(Xe - np.median(Xe, axis=0)), axis=0) + 1e-12\n            diag_shrink = np.diag(mad**2)\n            alpha = 0.2\n            Csh = (1 - alpha) * C + alpha * diag_shrink + 1e-12 * np.eye(self.dim)\n            try:\n                w, V = np.linalg.eigh(Csh)\n                w = np.maximum(w, 1e-12)\n                S = V.dot(np.diag(np.sqrt(w))).dot(V.T)\n                return S\n            except Exception:\n                U, s, Vt = np.linalg.svd(Csh)\n                return U.dot(np.diag(np.sqrt(s))).dot(Vt)\n\n        def refresh_subspace():\n            nonlocal B, r\n            if r == 0 or len(X_arch) < (6 + r):\n                return\n            K = min(len(X_arch), 2 * (r + 6))\n            Xr = np.asarray(X_arch[-K:])\n            # center on weighted median (robust)\n            M = np.median(Xr, axis=0)\n            S = Xr - M\n            try:\n                # randomized SVD style: compute compact SVD\n                U, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(r, Vt.shape[0])\n                if r_eff <= 0:\n                    return\n                B_new = Vt[:r_eff].T\n                # blend more conservatively than ACTEQS\n                beta = 0.08\n                if B.shape[1] == r_eff:\n                    B = (1 - beta) * B + beta * B_new\n                else:\n                    B = B_new.copy()\n                Q, _ = np.linalg.qr(B)\n                B = Q[:, :r_eff]\n            except Exception:\n                pass\n\n        # fit quadratic surrogate in subspace (robust ridge where lambda scales with trace variance)\n        def fit_subquad_and_minimize(max_samples=300):\n            if r == 0 or len(X_arch) < (r + 8):\n                return None, None, None, None\n            K = min(len(X_arch), max_samples)\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(B)  # n x r\n            n, rr = Z.shape\n            # design with constant, linear and quadratic diagonal + cross terms\n            tri_idx = [(i, j) for i in range(rr) for j in range(i, rr)]\n            p = 1 + rr + len(tri_idx)\n            if n < p:\n                return None, None, None, None\n            Phi = np.ones((n, p))\n            Phi[:, 1:1 + rr] = Z\n            col = 1 + rr\n            for (i, j) in tri_idx:\n                Phi[:, col] = Z[:, i] * Z[:, j]\n                col += 1\n            # adaptive ridge: lambda = c * median(var(Z)) * rr\n            varZ = np.median(np.var(Z, axis=0)) + 1e-12\n            lam = max(1e-8, 5e-3 * varZ * rr)\n            try:\n                A = Phi.T.dot(Phi) + lam * np.eye(p)\n                b = Phi.T.dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1 + rr]\n                H_vec = coeff[1 + rr:]\n                H = np.zeros((rr, rr))\n                idx = 0\n                for ii in range(rr):\n                    for jj in range(ii, rr):\n                        val = H_vec[idx]\n                        H[ii, jj] = val\n                        H[jj, ii] = val\n                        idx += 1\n                # enforce positive-definiteness mildly\n                eigs = np.linalg.eigvalsh(H)\n                min_eig = np.min(eigs)\n                if min_eig <= 1e-8:\n                    H += (abs(min_eig) + 1e-8) * np.eye(rr)\n                # minimizer\n                try:\n                    z_star = -np.linalg.solve(H, g)\n                except Exception:\n                    z_star = -np.linalg.pinv(H).dot(g)\n                # clip in subspace momentum-aware scaling\n                max_z = (step_scale * rr) / (np.linalg.norm(B, ord=2) + 1e-12)\n                znorm = np.linalg.norm(z_star)\n                if znorm > max_z:\n                    z_star = z_star * (max_z / (znorm + 1e-12))\n                f_pred = c + g.dot(z_star) + 0.5 * z_star.dot(H.dot(z_star))\n                return z_star, float(f_pred), H, g\n            except Exception:\n                return None, None, None, None\n\n        # approximate gradient in subspace using weighted linear fit (robust)\n        def approx_grad_subspace(K=None):\n            if r == 0:\n                return None\n            K = min(len(X_arch), max(12, 6 + r)) if K is None else min(len(X_arch), K)\n            if K < (r + 3):\n                return None\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(B)\n            dists = np.linalg.norm(Z, axis=1) + 1e-12\n            # robust weights using Lahiri-type: heavy downweight outliers\n            w = 1.0 / (1.0 + (dists / (0.8 * step_scale + 1e-12))**2)\n            W = np.diag(w)\n            Phi = np.hstack([np.ones((Z.shape[0], 1)), Z])\n            try:\n                A = Phi.T.dot(W).dot(Phi) + 1e-9 * np.eye(1 + r)\n                b = Phi.T.dot(W).dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                g = coeff[1:1 + r]\n                return g\n            except Exception:\n                return None\n\n        # two-loop LBFGS in subspace using secant stored in subspace coordinates\n        def lbfgs_subspace(gk, mem=12, max_norm=None):\n            if gk is None or len(secant) == 0 or r == 0:\n                return None\n            # build subspace secant memory\n            mem_pairs = []\n            for p in secant[-mem:]:\n                # project s and y into subspace\n                s_sub = B.T.dot(p['s'])\n                y_sub = B.T.dot(p['y'])\n                if np.linalg.norm(s_sub) > 0 and np.linalg.norm(y_sub) > 0:\n                    mem_pairs.append({'s': s_sub, 'y': y_sub})\n            if len(mem_pairs) == 0:\n                return None\n            q = gk.copy()\n            alphas = []\n            rhos = []\n            for pair in reversed(mem_pairs):\n                s = pair['s']; y = pair['y']\n                rho = 1.0 / (np.dot(y, s) + 1e-12)\n                rhos.append(rho)\n                alpha = rho * np.dot(s, q)\n                alphas.append(alpha)\n                q = q - alpha * y\n            # BB scalar initialization: gamma = (s^T y) / (y^T y) from last pair\n            last = mem_pairs[-1]\n            s = last['s']; y = last['y']\n            gamma = max(1e-6, np.dot(s, y) / (np.dot(y, y) + 1e-12))\n            rvec = gamma * q\n            for i, pair in enumerate(mem_pairs):\n                s = pair['s']; y = pair['y']\n                rho = rhos[len(rhos)-1 - i]\n                alpha = alphas[len(alphas)-1 - i]\n                beta = rho * np.dot(y, rvec)\n                rvec = rvec + s * (alpha - beta)\n            step_z = -rvec\n            if max_norm is not None:\n                nrm = np.linalg.norm(step_z)\n                if nrm > max_norm:\n                    step_z = step_z * (max_norm / (nrm + 1e-12))\n            return step_z\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n\n            # refresh subspace occasionally\n            if gen % self.pca_refresh == 0:\n                refresh_subspace()\n\n            Xe, Fe = get_elites()\n            S_sqrt = robust_sqrt_cov(Xe) if Xe.size else np.eye(self.dim)\n\n            # adapt trust based on recent success ratio\n            if len(recent_success) >= success_window:\n                recent_success = recent_success[-success_window:]\n            succ_ratio = np.mean(recent_success) if recent_success else 0.0\n            if succ_ratio > 0.28:\n                step_scale = max(self.min_step, step_scale * 0.90)\n            elif succ_ratio < 0.08:\n                step_scale = min(self.max_step, step_scale * 1.06)\n            else:\n                # slight conservative drift\n                step_scale = np.clip(step_scale * (0.995 + 0.01 * (0.18 - succ_ratio)), self.min_step, self.max_step)\n\n            # temperature schedule based on budget remaining (faster cooling than ACTEQS)\n            T = 1e-10 + 0.4 * step_scale * max(1e-12, 1.0 - (evals / max(1.0, self.budget))**1.2)\n\n            # produce a small batch\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget:\n                    break\n                p = rng.rand()\n                x_cand = None; f_c = None; strategy = 'jitter'; step = None\n\n                # tempered heavy-tail Student-t (nu=3)\n                if p < self.prob_student:\n                    strategy = 'student'\n                    nu = 3.0\n                    z = rng.standard_t(nu, size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    step = 3.0 * step_scale * z\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # elite-shaped sampling with robust center selection\n                elif p < self.prob_elite:\n                    strategy = 'elite'\n                    if Xe.size and rng.rand() < 0.6:\n                        # pick an elite by sigmoid-weighted preference for best\n                        idx = int(np.floor((rng.rand()**2) * Xe.shape[0]))\n                        center = Xe[idx]\n                    else:\n                        center = m\n                    z = rng.randn(self.dim)\n                    step = 1.1 * step_scale * S_sqrt.dot(z) + 0.08 * momentum\n                    # partially project out last taboo directions if exist\n                    if len(secant) > 0 and rng.rand() < 0.3:\n                        # use last few secant s directions as taboo\n                        for ptd in secant[-6:]:\n                            td = ptd['s'] / (np.linalg.norm(ptd['s']) + 1e-12)\n                            proj = np.dot(step, td) * td\n                            step = step - 0.3 * proj\n                    x_cand = np.minimum(np.maximum(center + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # subspace quadratic surrogate minimizer\n                elif p < (self.prob_elite + self.prob_subquad):\n                    strategy = 'subquad'\n                    z_star, f_pred, H, g = fit_subquad_and_minimize()\n                    if z_star is not None:\n                        x_prop = np.minimum(np.maximum(m + B.dot(z_star), lb), ub)\n                        f_prop = safe_eval(x_prop)\n                        if f_prop is None:\n                            break\n                        x_cand = x_prop; f_c = f_prop; step = x_cand - m\n                        # update secant via approximate gradients if possible\n                        g0 = approx_grad_subspace()\n                        if g0 is not None:\n                            # approximate gradient at new center by local linear fit around x_prop\n                            old_m = m.copy()\n                            m_temp = x_prop.copy()\n                            # temporarily compute gradient around m_temp (without changing m)\n                            # we implement a local helper to compute subspace gradient at any center\n                            def grad_at(center):\n                                K = min(len(X_arch), max(12, 6 + r))\n                                if K < (r + 3):\n                                    return None\n                                Xr = np.asarray(X_arch[-K:])\n                                Fr = np.asarray(f_arch[-K:])\n                                Zc = (Xr - center).dot(B)\n                                dists = np.linalg.norm(Zc, axis=1) + 1e-12\n                                w = 1.0 / (1.0 + (dists / (0.8 * step_scale + 1e-12))**2)\n                                W = np.diag(w)\n                                Phi = np.hstack([np.ones((Zc.shape[0], 1)), Zc])\n                                try:\n                                    A = Phi.T.dot(W).dot(Phi) + 1e-9 * np.eye(1 + r)\n                                    b = Phi.T.dot(W).dot(Fr)\n                                    coeff = np.linalg.solve(A, b)\n                                    return coeff[1:1 + r]\n                                except Exception:\n                                    return None\n                            g1 = grad_at(m_temp)\n                            if g1 is not None:\n                                s = B.dot(z_star)\n                                y = B.dot(g1 - g0)\n                                if np.dot(s, y) > 1e-12:\n                                    secant.append({'s': s.copy(), 'y': y.copy()})\n                                    if len(secant) > 40:\n                                        secant.pop(0)\n                    else:\n                        # jitter fallback\n                        eps = rng.randn(self.dim)\n                        step = step_diag * eps + 0.08 * momentum\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # quasi-Newton proposals via LBFGS in subspace + BB scaling\n                elif p < (self.prob_elite + self.prob_subquad + self.prob_qn):\n                    strategy = 'qn'\n                    gsub = approx_grad_subspace()\n                    if gsub is not None and len(secant) > 0 and r > 0:\n                        max_norm = step_scale * np.sqrt(r)\n                        z_step = lbfgs_subspace(gsub, mem=10, max_norm=max_norm)\n                        if z_step is not None:\n                            x_prop = np.minimum(np.maximum(m + B.dot(z_step), lb), ub)\n                            f_prop = safe_eval(x_prop)\n                            if f_prop is None:\n                                break\n                            x_cand = x_prop; f_c = f_prop; step = x_cand - m\n                            # update full-space secant via two subspace gradients mapping\n                            g1 = approx_grad_subspace()\n                            if g1 is not None:\n                                s_full = B.dot(z_step)\n                                y_full = B.dot(g1 - gsub)\n                                if np.dot(s_full, y_full) > 1e-12:\n                                    secant.append({'s': s_full.copy(), 'y': y_full.copy()})\n                                    if len(secant) > 40:\n                                        secant.pop(0)\n                        else:\n                            eps = rng.randn(self.dim)\n                            step = step_diag * eps + 0.08 * momentum\n                            x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                            f_c = safe_eval(x_cand)\n                            if f_c is None:\n                                break\n                    else:\n                        # jitter fallback\n                        eps = rng.randn(self.dim)\n                        step = step_diag * eps + 0.08 * momentum\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # coordinate-pattern exploration (robust MAD-driven)\n                elif p < (self.prob_elite + self.prob_subquad + self.prob_qn + self.prob_pattern):\n                    strategy = 'pattern'\n                    if len(X_arch) > 2:\n                        mad = np.median(np.abs(np.asarray(X_arch) - np.median(np.asarray(X_arch), axis=0)), axis=0)\n                        idxs = np.argsort(-mad)[:max(1, min(6, self.dim//2))]\n                    else:\n                        idxs = np.arange(min(3, self.dim))\n                    found = False\n                    for i in idxs:\n                        if evals >= self.budget: break\n                        dirvec = np.zeros(self.dim); dirvec[i] = 1.0\n                        a = 1.0 * step_scale * (1.0 + 0.5 * rng.rand())\n                        for sign in (+1.0, -1.0):\n                            x_try = np.minimum(np.maximum(m + sign * a * dirvec, lb), ub)\n                            f_try = safe_eval(x_try)\n                            if f_try is None:\n                                break\n                            if f_try < (f_best - 1e-15):\n                                x_cand = x_try; f_c = f_try; step = x_cand - m\n                                found = True; break\n                        if found: break\n                    if not found and x_cand is None:\n                        eps = rng.randn(self.dim)\n                        step = step_diag * eps + 0.08 * momentum\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # default jitter\n                else:\n                    strategy = 'jitter'\n                    eps = rng.randn(self.dim)\n                    step = step_diag * eps + 0.08 * momentum\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                if f_c is None:\n                    break\n\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c); x_best = x_cand.copy(); improved = True; stagn = 0\n                else:\n                    stagn += 1\n\n                # reward-like measure and RMS update (different scaling)\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                step_norm = (np.linalg.norm(step) + 1e-12)\n                # update v_rms using normalized squared steps (using robust denom)\n                sq = ((step / (step_scale + 1e-12)) ** 2)\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq\n                step_diag = np.clip(step_scale / (np.sqrt(v_rms) + 1e-8), self.min_step, self.max_step)\n\n                # acceptance: always accept improvements; uphill with Metropolis at temperature T\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    delta = f_c - f_best\n                    if delta <= 0 or rng.rand() < np.exp(-delta / (T + 1e-12)):\n                        accept = True\n\n                # bookkeeping for recent success window\n                recent_success.append(1.0 if improved else 0.0)\n                if len(recent_success) > success_window:\n                    recent_success.pop(0)\n\n                if accept:\n                    # learning rate by strategy (different constants)\n                    if strategy in ('subquad', 'qn'):\n                        lr = 0.78\n                    elif strategy == 'pattern':\n                        lr = 0.55\n                    elif strategy == 'elite':\n                        lr = 0.45\n                    elif strategy == 'student':\n                        lr = 0.22\n                    else:\n                        lr = 0.30\n\n                    delta_m = (x_cand - m)\n                    # clip very large jump by a different trust metric\n                    trust = 6.0 * step_scale * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta_m)\n                    if dn > trust:\n                        delta_m = delta_m * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta_m, lb), ub)\n\n                    # momentum update (exponential smoothing of moves)\n                    momentum = 0.78 * momentum + 0.22 * delta_m\n\n                    # adapt step_scale: reduce if frequent success, expand slightly on accepting uphill\n                    if improved:\n                        step_scale = max(self.min_step, step_scale * 0.86)\n                    else:\n                        step_scale = min(self.max_step, step_scale * 1.03)\n                else:\n                    # reject: small random nudge, damp momentum\n                    m = np.minimum(np.maximum(m + 0.01 * avg_span * rng.randn(self.dim), lb), ub)\n                    step_scale = min(self.max_step, step_scale * 1.01)\n                    momentum *= 0.93\n\n                # occasionally perturb subspace by Householder reflection (orthogonal flip)\n                if r > 0 and rng.rand() < 0.04:\n                    v = rng.randn(self.dim)\n                    v = v - B.dot(B.T.dot(v))  # component orthogonal to subspace\n                    if np.linalg.norm(v) > 1e-12:\n                        v = v / np.linalg.norm(v)\n                        # Householder to reflect a random column of B slightly toward v\n                        j = rng.randint(0, r)\n                        u = B[:, j] + v\n                        if np.linalg.norm(u) > 1e-12:\n                            H = np.eye(self.dim) - 2.0 * np.outer(u, u) / (np.dot(u, u) + 1e-12)\n                            B = H.dot(B)\n                            Q, _ = np.linalg.qr(B)\n                            B = Q[:, :r]\n\n                # stagnation restart (different policy)\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    # move center to a convex combination of best and a random elite, increase step_scale\n                    Xe2, _ = get_elites()\n                    if Xe2.size:\n                        pick = Xe2[rng.randint(0, Xe2.shape[0])]\n                    else:\n                        pick = x_best\n                    m = np.minimum(np.maximum(0.6 * x_best + 0.4 * pick + 0.08 * avg_span * rng.randn(self.dim), lb), ub)\n                    step_scale = min(self.max_step, step_scale * 1.8)\n                    momentum = np.zeros(self.dim)\n                    # reinitialize subspace with small random perturbation\n                    if r > 0:\n                        A = rng.randn(self.dim, r) * 0.7 + B * 0.3\n                        Q, _ = np.linalg.qr(A)\n                        B = Q[:, :r]\n                    # local sampling near best\n                    reseed = min(12, self.budget - evals)\n                    for _ in range(reseed):\n                        if evals >= self.budget: break\n                        x = np.minimum(np.maximum(x_best + 0.03 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None: break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # end batch loop\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SASB scored 0.204 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "03c4a78b-1749-4b5d-9b52-08b0dc80cbce", "operator": null, "metadata": {"aucs": [0.09787630274946335, 0.17086304181203693, 0.2612586643224527, 0.26346496599508307, 0.21448375405030873, 0.23339359801581128, 0.22792996825936118, 0.21904128815745294, 0.19458998443575848, 0.15415933237944146]}, "task_prompt": ""}
{"id": "dabfb41e-dd1f-4918-86cb-cabad2c1bccf", "fitness": 0.19446534157114903, "name": "MIDAS", "description": "MIDAS combines a multi-scale bandit (geometric absolute radii \"scales\" with Thompson-like beta stats scale_alpha/scale_beta) that is adaptively shrunk/expanded on successes/failures to trade off exploration and exploitation. It builds cheap local models via a random Gaussian sketch P into a low-dimensional subspace and fits a regularized quadratic surrogate (fit_sketch_quadratic) to propose mapped minimizers, complemented by antithetic finite-difference gradient probes (antithetic_grad) for directional information. A diverse mixture of proposal strategies (elite-shaped anisotropic sampling using per-dim robust MAD scales, coordinate-pattern probes on high-variance dims, and heavy‑tailed Levy jumps), plus strategy-dependent learning rates and a simulated-annealing acceptance temperature, provides robust local search and escape mechanisms. Global control is enforced by strict safe_eval budget accounting, initial space-filling seeding, entropy/diversity monitoring, stagnation detection (stagn/stagn_limit) that triggers sketch refreshes and soft restarts, and dynamic clipping of jump sizes to respect bounds and stability.", "code": "import numpy as np\n\nclass MIDAS:\n    \"\"\"\n    MIDAS: Multi-scale Information-Directed Adaptive Sampling\n\n    Main ingredients (novel combination):\n    - Multi-scale trust radii (geometric scales). Use Thompson-sampling-like beta statistics\n      to select scales that historically gave improvements.\n    - Sketching-based local quadratic surrogate: random Gaussian sketch projects full-dim\n      data to a low-dimensional subspace; we fit a regularized quadratic in that sketched\n      space and map minimizer back to full space.\n    - Antithetic finite-difference gradient probes along random orthonormal directions for\n      cheap gradient/Hessian-vector information.\n    - Elite-shaped sampling via robust scale (MAD) + directional tempering.\n    - Coordinate-pattern exploration on top-variance dims.\n    - Entropy/diversity monitoring triggers soft restarts and broadened scales.\n    - Strict budget accounting via safe_eval wrapper.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=10, subdim=None, n_scales=6, base_scale=0.4,\n                 elite_frac=0.12, init_seed=32, min_step=1e-8, max_step=10.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.subdim = subdim if subdim is not None else max(1, self.dim // 6)\n        self.n_scales = int(max(1, n_scales))\n        self.base_scale = float(base_scale)  # relative to average span, scaled later\n        self.elite_frac = float(elite_frac)\n        self.init_seed = int(init_seed)\n        self.min_step = float(min_step)\n        self.max_step = float(max_step)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # Bounds handling\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # internal state\n        evals = 0\n        X_arch = []\n        f_arch = []\n\n        # safe function evaluation with strict budget\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # cap archive size to keep memory reasonable\n            if len(X_arch) > max(600, 60 * self.dim):\n                del X_arch[0: len(X_arch) - max(600, 60 * self.dim)]\n                del f_arch[0: len(f_arch) - max(600, 60 * self.dim)]\n            return fx\n\n        # initial seed sample (space-filling-ish)\n        seed0 = min(self.init_seed, max(20, int(self.budget // 200)))\n        for _ in range(seed0):\n            if evals >= self.budget: break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n        if len(f_arch) == 0 and evals < self.budget:\n            safe_eval(rng.uniform(lb, ub, size=self.dim))\n\n        # initialize best\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        # initial center is best found so far\n        m = x_best.copy()\n\n        # multi-scale radii (absolute), geometric progression\n        base = self.base_scale * avg_span\n        # ensure scales in reasonable range\n        scales = base * (2.0 ** np.arange(self.n_scales))\n        scales = np.clip(scales, self.min_step, self.max_step)\n        # Thompson-like beta priors for each scale: alpha=successes+1, beta=failures+1\n        scale_alpha = np.ones(self.n_scales)\n        scale_beta = np.ones(self.n_scales)\n\n        # subspace sketch matrix (random gaussian) and refresh rate\n        r = min(self.subdim, self.dim)\n        def new_sketch():\n            A = rng.randn(self.dim, r)\n            # orthonormalize columns for better geometry\n            Q, _ = np.linalg.qr(A)\n            return Q[:, :r].copy()\n        P = new_sketch()\n\n        # stagnation detector\n        stagn = 0\n        stagn_limit = max(12, int(0.04 * self.budget))\n\n        # helper: get elites\n        def get_elites():\n            if len(X_arch) == 0:\n                return np.empty((0,self.dim)), np.empty((0,))\n            k = max(3, int(np.ceil(self.elite_frac * max(50, self.budget / 8))))\n            k = min(k, len(X_arch))\n            idxs = np.argsort(f_arch)[:k]\n            Xe = np.asarray([X_arch[i].copy() for i in idxs])\n            Fe = np.asarray([f_arch[i] for i in idxs])\n            return Xe, Fe\n\n        # robust scale estimator (per-dim) using MAD\n        def robust_scale(Xe):\n            if Xe.size == 0:\n                return np.ones(self.dim)\n            med = np.median(Xe, axis=0)\n            mad = np.median(np.abs(Xe - med), axis=0) + 1e-12\n            # convert MAD to approx std (assuming normal) (factor 1.4826), clamp\n            return np.clip(1.4826 * mad, 1e-6, 1e6)\n\n        # sketch-quadratic fit in r-dim subspace: fit f(m + P z) ≈ c + g^T z + 0.5 z^T H z\n        def fit_sketch_quadratic(max_samples=300, reg=1e-6):\n            # need enough samples\n            if len(X_arch) < max(4, r + 6):\n                return None, None, None, None\n            K = min(len(X_arch), max_samples)\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(P)  # n x r coordinates around m\n            n, rr = Z.shape\n            # design for quadratic: [1, z (r), z_i*z_j for i<=j]\n            tri_idx = [(i,j) for i in range(rr) for j in range(i, rr)]\n            p = 1 + rr + len(tri_idx)\n            if n < p:\n                # fallback: try linear only\n                Phi = np.hstack([np.ones((n,1)), Z])\n                try:\n                    A = Phi.T.dot(Phi) + reg * np.eye(Phi.shape[1])\n                    b = Phi.T.dot(Fr)\n                    coeff = np.linalg.solve(A, b)\n                    c = coeff[0]; g = coeff[1:1+rr]\n                    H = np.eye(rr) * 1e-8\n                    z_star = -np.linalg.solve(H + 1e-6*np.eye(rr), g)\n                    return z_star, float(c + g.dot(z_star) + 0.5*z_star.dot(H.dot(z_star))), H, g\n                except Exception:\n                    return None, None, None, None\n            Phi = np.ones((n, p))\n            Phi[:,1:1+rr] = Z\n            col = 1 + rr\n            for (i,j) in tri_idx:\n                Phi[:, col] = Z[:, i] * Z[:, j]\n                col += 1\n            # weighting: prefer points near center\n            d2 = np.sum(Z**2, axis=1)\n            sigma = max(1e-8, np.median(np.sqrt(d2)) + 1e-8, (scales[0] / (avg_span + 1e-12)) * 1.0)\n            w = np.exp(-0.5 * (d2 / ( (sigma*1.2)**2 + 1e-12)))\n            W = np.diag(w)\n            try:\n                A = Phi.T.dot(W).dot(Phi) + reg * np.eye(p)\n                b = Phi.T.dot(W).dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1+rr]\n                H_vec = coeff[1+rr:]\n                H = np.zeros((rr, rr))\n                idx = 0\n                for ii in range(rr):\n                    for jj in range(ii, rr):\n                        val = H_vec[idx]\n                        H[ii, jj] = val\n                        H[jj, ii] = val\n                        idx += 1\n                # ensure PD-ish\n                eigs = np.linalg.eigvalsh(H)\n                min_eig = np.min(eigs)\n                if min_eig <= 1e-8:\n                    H = H + (abs(min_eig)+1e-6)*np.eye(rr)\n                # solve z* = -H^{-1} g (safely)\n                try:\n                    z_star = -np.linalg.solve(H, g)\n                except Exception:\n                    z_star = -np.linalg.pinv(H).dot(g)\n                f_pred = c + g.dot(z_star) + 0.5 * z_star.dot(H.dot(z_star))\n                return z_star, float(f_pred), H, g\n            except Exception:\n                return None, None, None, None\n\n        # antithetic gradient estimate around m using k orthonormal directions\n        def antithetic_grad(k= max(1, min(6, self.dim//3)), eps_scale=0.03):\n            # produce k orthonormal directions via QR\n            G = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(G)\n            dirs = Q[:, :k].T  # k x dim\n            grads = np.zeros((k, self.dim))\n            # central differences along each direction (antithetic pairs)\n            eps = eps_scale * avg_span\n            for i, d in enumerate(dirs):\n                if evals + 2 >= self.budget:\n                    return None  # budget too low\n                x1 = np.minimum(np.maximum(m + eps * d, lb), ub)\n                f1 = safe_eval(x1)\n                if f1 is None: return None\n                x2 = np.minimum(np.maximum(m - eps * d, lb), ub)\n                f2 = safe_eval(x2)\n                if f2 is None: return None\n                # directional derivative approx: (f1 - f2)/(2*eps)\n                deriv = (f1 - f2) / (2.0 * eps)\n                grads[i] = deriv * d  # project back to full-dim\n            # aggregate into full-dim gradient estimate\n            g_est = grads.sum(axis=0)\n            return g_est\n\n        # adaptive temperature schedule\n        def temperature():\n            # decreases with evals, scales with typical step\n            return 1e-8 + 0.6 * np.mean(scales) * max(1e-12, 1.0 - (evals / max(1.0, self.budget)))\n\n        # main loop: at each iteration propose up to pop candidates (bounded by budget)\n        while evals < self.budget:\n            # compute diversity / entropy measure to detect collapse\n            diversity = 0.0\n            if len(X_arch) >= 6:\n                try:\n                    C = np.cov(np.asarray(X_arch).T) + 1e-12 * np.eye(self.dim)\n                    ev = np.linalg.eigvalsh(C)\n                    ev = np.maximum(ev, 1e-16)\n                    pvec = ev / np.sum(ev)\n                    diversity = -np.sum(pvec * np.log(pvec + 1e-12))\n                except Exception:\n                    diversity = 0.0\n            # if diversity too low -> refresh sketch and broaden scales a bit\n            if diversity < 0.5 and rng.rand() < 0.07:\n                P = new_sketch()\n                scales = np.minimum(self.max_step, scales * 1.15)\n\n            # choose scale by Thompson sampling on beta stats\n            thompson_samples = rng.beta(scale_alpha, scale_beta)\n            idx_scale = int(np.argmax(thompson_samples))\n            chosen_scale = scales[idx_scale]\n\n            # sample batch (each proposal uses same chosen_scale to evaluate that scale's usefulness)\n            batch_size = min(self.pop, max(1, self.budget - evals))\n            for _ in range(batch_size):\n                if evals >= self.budget: break\n                # choose strategy mixture (weights can be tuned). Different from ACTEQS: composition favors sketch/quadratic and antithetic probes.\n                p = rng.rand()\n                x_cand = None; f_c = None; strategy = None\n\n                # Strategy A: sketched quadratic minimizer (exploitation)\n                if p < 0.38:\n                    strategy = 'sketch_quad'\n                    z_star, f_pred, H, g = fit_sketch_quadratic(max_samples=300, reg=1e-6)\n                    if z_star is not None:\n                        # map back to full space and scale by chosen_scale\n                        # limit step in sketched coords proportionally to chosen_scale\n                        max_z = (chosen_scale / (avg_span + 1e-12)) * np.sqrt(r) * 1.5\n                        nz = np.linalg.norm(z_star)\n                        if nz > max_z:\n                            z_star = z_star * (max_z / (nz + 1e-12))\n                        x_prop = np.minimum(np.maximum(m + P.dot(z_star), lb), ub)\n                        f_prop = safe_eval(x_prop)\n                        if f_prop is None:\n                            break\n                        x_cand = x_prop; f_c = f_prop\n                    else:\n                        # fallback: jitter around m\n                        eps = rng.randn(self.dim)\n                        step = chosen_scale * 0.8 * eps\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # Strategy B: antithetic gradient probes (information gathering)\n                elif p < 0.38 + 0.22:\n                    strategy = 'antithetic_grad'\n                    g_est = antithetic_grad(k=max(1, min(6, self.dim//3)), eps_scale=0.03)\n                    if g_est is None:\n                        # budget exhausted or failed -> do a single jitter eval\n                        eps = rng.randn(self.dim)\n                        x_cand = np.minimum(np.maximum(m + chosen_scale * 0.8 * eps, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None: break\n                    else:\n                        # take a quasi-Newton-like step: x = m - alpha * g_est where alpha proportional to chosen_scale\n                        alpha = chosen_scale / (np.linalg.norm(g_est) + 1e-12) * 0.6\n                        delta = -alpha * g_est\n                        # cap jump\n                        max_jump = 6.0 * chosen_scale * np.sqrt(self.dim)\n                        if np.linalg.norm(delta) > max_jump:\n                            delta = delta * (max_jump / (np.linalg.norm(delta) + 1e-12))\n                        x_prop = np.minimum(np.maximum(m + delta, lb), ub)\n                        f_prop = safe_eval(x_prop)\n                        if f_prop is None: break\n                        x_cand = x_prop; f_c = f_prop\n\n                # Strategy C: elite-shaped anisotropic sampling (exploration guided by elites)\n                elif p < 0.38 + 0.22 + 0.20:\n                    strategy = 'elite'\n                    Xe, Fe = get_elites()\n                    if Xe.size > 0 and rng.rand() < 0.8:\n                        center = Xe[rng.randint(0, Xe.shape[0])]\n                    else:\n                        center = m\n                    # robust per-dim scales\n                    rs = robust_scale(Xe) if Xe.size else np.ones(self.dim) * (0.2 * avg_span)\n                    z = rng.randn(self.dim)\n                    step = (chosen_scale * 1.3) * (z * (rs / (np.mean(rs) + 1e-12)))\n                    x_prop = np.minimum(np.maximum(center + step, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is None: break\n                    x_cand = x_prop; f_c = f_prop\n\n                # Strategy D: coordinate pattern probing (local structured search)\n                elif p < 0.38 + 0.22 + 0.20 + 0.12:\n                    strategy = 'pattern'\n                    # choose top variance dims\n                    if len(X_arch) > 3:\n                        var = np.var(np.asarray(X_arch), axis=0)\n                    else:\n                        var = np.ones(self.dim)\n                    idxs = np.argsort(-var)[:max(1, min(6, self.dim//2))]\n                    found = False\n                    for i in idxs:\n                        if evals >= self.budget: break\n                        dirvec = np.zeros(self.dim); dirvec[i] = 1.0\n                        a = chosen_scale * 1.05\n                        for sign in (+1.0, -1.0):\n                            x_try = np.minimum(np.maximum(m + sign * a * dirvec, lb), ub)\n                            f_try = safe_eval(x_try)\n                            if f_try is None:\n                                break\n                            if f_try < (f_best - 1e-15):\n                                x_cand = x_try; f_c = f_try; found = True; break\n                        if found: break\n                    if x_cand is None:\n                        # fallback jitter\n                        eps = rng.randn(self.dim)\n                        x_cand = np.minimum(np.maximum(m + chosen_scale * 0.9 * eps, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None: break\n\n                # Strategy E: heavy-tail escape (Cauchy / Levy style)\n                else:\n                    strategy = 'levy'\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    step = 4.0 * chosen_scale * z\n                    x_prop = np.minimum(np.maximum(m + step, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is None: break\n                    x_cand = x_prop; f_c = f_prop\n\n                # After candidate evaluation:\n                if f_c is None:\n                    break\n\n                # improvement bookkeeping\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c); x_best = x_cand.copy(); improved = True; stagn = 0\n                else:\n                    stagn += 1\n\n                # acceptance rule: always accept improvement; otherwise simulated annealing\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    delta = f_c - f_best\n                    T = temperature()\n                    if delta <= 0:\n                        accept = True\n                    else:\n                        if rng.rand() < np.exp(-delta / (T + 1e-12)):\n                            accept = True\n\n                # if accepted, update center and scale bandit stats\n                if accept:\n                    # learning rates depending on strategy (novel choices)\n                    if strategy in ('sketch_quad', 'antithetic_grad'):\n                        lr = 0.9\n                    elif strategy == 'elite':\n                        lr = 0.6\n                    elif strategy == 'pattern':\n                        lr = 0.5\n                    else:\n                        lr = 0.3\n                    # move center towards x_cand\n                    delta_m = (x_cand - m)\n                    # dynamic clipping: avoid giant jumps\n                    max_jump = 8.0 * chosen_scale * np.sqrt(max(1, self.dim))\n                    if np.linalg.norm(delta_m) > max_jump:\n                        delta_m = delta_m * (max_jump / (np.linalg.norm(delta_m) + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta_m, lb), ub)\n\n                    # reward scale bandit\n                    # treat any accepted improvement as success for chosen scale, else soft success\n                    if improved:\n                        scale_alpha[idx_scale] += 1.0\n                    else:\n                        # soft update proportional to relative improvement likelihood estimated by annealing\n                        scale_beta[idx_scale] += 0.4\n\n                    # if accepted and got improvement, shrink scales gradually\n                    if improved:\n                        scales = np.maximum(self.min_step, scales * 0.90)\n                    else:\n                        # slight expansion to encourage exploration\n                        scales = np.minimum(self.max_step, scales * 1.01)\n                else:\n                    # rejection: add small random perturbation and count as failure for scale\n                    m = np.minimum(np.maximum(m + 0.02 * avg_span * rng.randn(self.dim), lb), ub)\n                    scale_beta[idx_scale] += 1.0\n                    # mild broadening on rejections to allow escape\n                    scales = np.minimum(self.max_step, scales * 1.003)\n\n                # opportunistic refresh of sketch if many rejections and low diversity\n                if stagn > stagn_limit * 0.25 and rng.rand() < 0.03:\n                    P = new_sketch()\n\n                # stagnation-triggered soft restart: perturb center around global best, broaden scales and re-sample P\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    # jump near global best with jitter proportional to average scale\n                    jitter = max(0.03 * avg_span, 2.0 * np.mean(scales))\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    scales = np.minimum(self.max_step, scales * 1.8)\n                    P = new_sketch()\n                    # small local refinement around best\n                    reseed = min(6, self.budget - evals)\n                    for _ in range(reseed):\n                        if evals >= self.budget: break\n                        x = np.minimum(np.maximum(x_best + 0.05 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None: break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # end batch\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MIDAS scored 0.194 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "03c4a78b-1749-4b5d-9b52-08b0dc80cbce", "operator": null, "metadata": {"aucs": [0.08227590564085374, 0.1921904510776511, 0.2547875511366071, 0.22121428070302263, 0.19739883513796852, 0.24042587773595336, 0.20898016350720694, 0.21150049984659114, 0.1888007040094295, 0.14707914691620627]}, "task_prompt": ""}
{"id": "aec37e12-62e7-4102-a573-f8644ce55447", "fitness": "-inf", "name": "ASERTOS", "description": "The optimizer is an ensemble-style heuristic that keeps an evaluation archive and an elite subset and samples new candidates from a mixture of strategies (global isotropic jitter, elite-shaped anisotropic sampling using a shrinkage covariance, low-rank affine/subspace descent on a PCA-like basis, elite recombination, lightweight L-BFGS proposals using secant memory with approximate gradient probes, and occasional heavy-tailed Levy escapes) while strictly enforcing the evaluation budget and box bounds. It adapts a global trust radius (step_scale) from archive diversity and recent success rates, uses per-dimension RMS statistics (v_rms → step_diag) and momentum to scale steps and focus search, and employs a decaying temperature to allow occasional uphill acceptance. Exploitation is strengthened by maintaining a low-rank basis B (refreshed periodically) for subspace searches and by storing s/y secants for a two-loop L‑BFGS-like direction computed from cheap symmetric probes. Robustness features include shrinkage covariance for elite sampling, opportunistic orthogonal rotations of the basis, archive trimming, and controlled restarts/local reseeding when stagnation is detected; the algorithm’s defaults bias towards moderate batch exploration (pop=12) with more probability on global/elite moves (~0.28 each) and small probability for directed or escape moves.", "code": "import numpy as np\n\nclass ASERTOS:\n    \"\"\"\n    ASERTOS: Adaptive Sparse Ensemble-Rotation Trust-Region Optimizer\n\n    Main ideas (parameters are described here):\n    - budget, dim: required. Optional:\n      - pop: batch size per iteration (default 12)\n      - elite_frac: fraction of archive considered elite (default 0.15)\n      - subrank: target low-rank dimension for affine/subspace searches (default max(1, dim//6))\n      - init_step: initial trust radius as fraction of domain span (default 0.10)\n      - rms_beta: exponential moving average coefficient for per-dim scaling (default 0.94)\n      - pca_refresh: refresh frequency for low-rank basis (default 7)\n      - prob_global, prob_elite, prob_subspace, prob_recomb, prob_lbfgs, prob_levy:\n        strategy mixture probabilities (sum <=1, remaining probability -> jitter)\n      - min_step, max_step: allowed step scales (absolute)\n      - archive_size: maximum archive stored (default max(12*dim, 200))\n      - rng_seed: RNG seed for reproducibility\n      - lb, ub: user-specified bounds if func doesn't provide them (defaults -5, 5)\n    - The optimizer keeps an archive of evaluated points, an elite set, a low-rank PCA-like basis B,\n      a lightweight secant memory for an L-BFGS two-loop (stored in ambient dim),\n      and adaptive per-dimension scales using an RMS-like statistic.\n    - Strategies:\n      - global Gaussian jitter,\n      - elite-shaped anisotropic sampling (shrinkage covariance of elites),\n      - affine-subspace deterministic descent (ridge-linear surrogate in subspace),\n      - elite recombination (convex mixes + noise),\n      - L-BFGS proposals using stored secants (approx gradients via small probes),\n      - occasional heavy-tailed Levy/Cauchy escapes.\n    - Acceptance: greedy on improvements, stochastic uphill acceptance via temperature that decays\n      with used budget. Trust radius adapts based on improvement rate and archive spread.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=12, elite_frac=0.15, subrank=None, init_step=0.10,\n                 rms_beta=0.94, pca_refresh=7,\n                 prob_global=0.28, prob_elite=0.28, prob_subspace=0.18,\n                 prob_recomb=0.12, prob_lbfgs=0.08, prob_levy=0.04,\n                 min_step=1e-8, max_step=5.0, archive_size=None,\n                 lb=-5.0, ub=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.elite_frac = float(elite_frac)\n        self.subrank = subrank if subrank is not None else max(1, self.dim // 6)\n        self.init_step = float(init_step)\n        self.rms_beta = float(rms_beta)\n        self.pca_refresh = int(pca_refresh)\n        # mixture probabilities (they may sum < 1; remainder is jitter)\n        self.prob_global = float(prob_global)\n        self.prob_elite = float(prob_elite)\n        self.prob_subspace = float(prob_subspace)\n        self.prob_recomb = float(prob_recomb)\n        self.prob_lbfgs = float(prob_lbfgs)\n        self.prob_levy = float(prob_levy)\n        self.min_step = float(min_step)\n        self.max_step = float(max_step)\n        self.lb_user = lb\n        self.ub_user = ub\n        self.archive_size = archive_size if archive_size is not None else max(12 * self.dim, 200)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, float(self.lb_user))\n            ub = np.full(self.dim, float(self.ub_user))\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # state\n        evals = 0\n        X_arch = []\n        f_arch = []\n        # center (start random)\n        m = rng.uniform(lb, ub, size=self.dim)\n        step_scale = max(self.min_step, self.init_step * avg_span)\n        v_rms = np.full(self.dim, 1e-6)    # per-dim RMS variance estimate\n        step_diag = np.full(self.dim, step_scale)\n        momentum = np.zeros(self.dim)\n        # low-rank basis (orthonormal columns)\n        r = min(self.subrank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            B = Q[:, :r].copy()\n        else:\n            B = np.zeros((self.dim, 0))\n        # secant memory in ambient dim for light L-BFGS\n        secants = []  # list of dicts {'s':s, 'y':y}\n        max_sec = 24\n        # stagnation counters\n        stagn = 0\n        stagn_limit = max(12, int(0.03 * self.budget))\n\n        # safe evaluation wrapper\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            if len(X_arch) > self.archive_size:\n                # drop oldest\n                cut = len(X_arch) - self.archive_size\n                del X_arch[0:cut]\n                del f_arch[0:cut]\n            return fx\n\n        # seed with small Latin-ish random batch (diverse)\n        seed0 = min(self.pop * 4, max(20, int(self.budget // 250)))\n        for _ in range(seed0):\n            if evals >= self.budget: break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n        if len(f_arch) == 0 and evals < self.budget:\n            safe_eval(rng.uniform(lb, ub, size=self.dim))\n\n        # init best\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        gen = 0\n\n        # helpers\n        def get_elites():\n            if len(X_arch) == 0:\n                return np.empty((0, self.dim)), np.empty((0,))\n            k = max(3, int(np.ceil(self.elite_frac * max(50, self.budget / 6))))\n            k = min(k, len(X_arch))\n            idxs = np.argsort(f_arch)[:k]\n            Xe = np.asarray([X_arch[i].copy() for i in idxs])\n            Fe = np.asarray([f_arch[i] for i in idxs])\n            return Xe, Fe\n\n        def shrinkage_cov(Xe, shrink=0.2):\n            # robust covariance with Ledoit-Wolf-style shrinkage toward diagonal\n            n, d = Xe.shape\n            if n < 2:\n                return np.eye(d)\n            C = np.cov(Xe.T)\n            diag = np.diag(np.diag(C))\n            return (1 - shrink) * C + shrink * diag + 1e-12 * np.eye(d)\n\n        def refresh_basis():\n            nonlocal B, r\n            if r == 0 or len(X_arch) < (4 + r):\n                return\n            K = min(len(X_arch), self.archive_size)\n            Xr = np.asarray(X_arch[-K:])\n            # center and compute SVD of deviations\n            M = Xr.mean(axis=0)\n            S = Xr - M\n            try:\n                U, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(r, Vt.shape[0])\n                if r_eff <= 0:\n                    return\n                B_new = Vt[:r_eff].T\n                # gentle rotation blending to retain diversity\n                alpha = 0.18\n                if B.shape[1] == r_eff:\n                    B = (1 - alpha) * B + alpha * B_new\n                else:\n                    B = B_new.copy()\n                Q, _ = np.linalg.qr(B)\n                B = Q[:, :r_eff]\n            except Exception:\n                pass\n\n        def approx_grad_via_probes(center, eps_scale):\n            # approximate gradient by symmetric probes along top eigenvectors of archive covariance,\n            # fallback to coordinate finite differences\n            if len(X_arch) < 6:\n                # coordinate finite differences (small randomized directions)\n                d = self.dim\n                g = np.zeros(d)\n                probes = min(6, d)\n                D = rng.randn(probes, d)\n                for i in range(probes):\n                    v = D[i]\n                    v = v / (np.linalg.norm(v) + 1e-12)\n                    h = max(1e-6, eps_scale * 1e-3)\n                    xp = np.minimum(np.maximum(center + h * v, lb), ub)\n                    xm = np.minimum(np.maximum(center - h * v, lb), ub)\n                    fp = safe_eval(xp)\n                    fm = safe_eval(xm)\n                    if fp is None or fm is None:\n                        return None\n                    g += (fp - fm) / (2.0 * h) * v\n                return g / float(probes)\n            # use archive cov eigenvectors\n            try:\n                C = np.cov(np.asarray(X_arch).T) + 1e-12 * np.eye(self.dim)\n                ev, V = np.linalg.eigh(C)\n                # pick top few directions (but at most 8)\n                k = min(8, self.dim)\n                idx = np.argsort(-ev)[:k]\n                dirs = V[:, idx].T\n                g = np.zeros(self.dim)\n                h = max(1e-7, eps_scale * 1e-3)\n                for v in dirs:\n                    v = v / (np.linalg.norm(v) + 1e-12)\n                    xp = np.minimum(np.maximum(center + h * v, lb), ub)\n                    xm = np.minimum(np.maximum(center - h * v, lb), ub)\n                    fp = safe_eval(xp); fm = safe_eval(xm)\n                    if fp is None or fm is None:\n                        return None\n                    g += ((fp - fm) / (2.0 * h)) * v\n                return g / float(k)\n            except Exception:\n                return None\n\n        def lbfgs_two_loop(gk):\n            # two-loop L-BFGS using secants (ambient dim)\n            if gk is None or len(secants) == 0:\n                return None\n            q = gk.copy()\n            alphas = []\n            rhos = []\n            L = len(secants)\n            # use most recent up to 12\n            Slist = secants[-12:]\n            for pair in reversed(Slist):\n                s = pair['s']; y = pair['y']\n                rho = 1.0 / (np.dot(y, s) + 1e-12)\n                rhos.append(rho)\n                alpha = rho * np.dot(s, q)\n                alphas.append(alpha)\n                q = q - alpha * y\n            # initial Hessian approx scalar\n            gamma = 1.0\n            if len(Slist) > 0:\n                s = Slist[-1]['s']; y = Slist[-1]['y']\n                gamma = max(1e-6, np.dot(s, y) / (np.dot(y, y) + 1e-12))\n            rvec = gamma * q\n            for i, pair in enumerate(Slist):\n                s = pair['s']; y = pair['y']\n                rho = rhos[len(rhos)-1 - i]\n                alpha = alphas[len(alphas)-1 - i]\n                beta = rho * np.dot(y, rvec)\n                rvec = rvec + s * (alpha - beta)\n            step = -rvec\n            return step\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            if gen % self.pca_refresh == 0:\n                refresh_basis()\n\n            Xe, Fe = get_elites()\n            # robust elite covariance\n            if Xe.size:\n                C_el = shrinkage_cov(Xe, shrink=0.2)\n                try:\n                    w, V = np.linalg.eigh(C_el)\n                    w = np.maximum(w, 1e-12)\n                    S_sqrt = V.dot(np.diag(np.sqrt(w))).dot(V.T)\n                except Exception:\n                    S_sqrt = np.linalg.cholesky(C_el + 1e-12 * np.eye(self.dim))\n            else:\n                S_sqrt = np.eye(self.dim)\n\n            # diversity measure: log-determinant proxy of archive covariance\n            diversity = 0.0\n            if len(X_arch) >= 4:\n                try:\n                    Cfull = np.cov(np.asarray(X_arch).T) + 1e-12 * np.eye(self.dim)\n                    _, svals, _ = np.linalg.svd(Cfull)\n                    svals = np.maximum(svals, 1e-16)\n                    diversity = float(np.sum(np.log(svals)))\n                except Exception:\n                    diversity = 0.0\n\n            # adapt trust radius: if diversity collapses, widen; if diverse, shrink slowly\n            if diversity < -5.0:\n                step_scale = min(self.max_step, step_scale * 1.035)\n            else:\n                step_scale = max(self.min_step, step_scale * 0.995)\n\n            # temperature for uphill acceptance (decreases with evals)\n            T = 2e-8 + 0.8 * step_scale * (1.0 - evals / max(1.0, self.budget))\n\n            # batch of candidates\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            for _ in range(n_cand):\n                if evals >= self.budget: break\n                p = rng.rand()\n                x_cand = None; f_c = None; strategy = 'jitter'; step = None\n\n                # Levy heavy-tailed escape\n                if p < self.prob_levy:\n                    strategy = 'levy'\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 85) + 1e-12)\n                    step = 5.5 * step_scale * z\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # elite anisotropic sampling\n                elif p < (self.prob_levy + self.prob_elite):\n                    strategy = 'elite'\n                    center = m if (Xe.size == 0 or rng.rand() < 0.3) else Xe[rng.randint(0, Xe.shape[0])]\n                    z = rng.randn(self.dim)\n                    step = 1.1 * step_scale * S_sqrt.dot(z) + 0.08 * momentum\n                    x_cand = np.minimum(np.maximum(center + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # global Gaussian jitter (isotropic)\n                elif p < (self.prob_levy + self.prob_elite + self.prob_global):\n                    strategy = 'global'\n                    eps = rng.randn(self.dim)\n                    step = step_diag * eps + 0.12 * momentum\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                # affine subspace deterministic descent - linear ridge surrogate in subspace\n                elif p < (self.prob_levy + self.prob_elite + self.prob_global + self.prob_subspace):\n                    strategy = 'subspace'\n                    if r > 0 and len(X_arch) >= (r + 4):\n                        # build coordinates Z around m in basis B\n                        K = min(len(X_arch), 200)\n                        Xr = np.asarray(X_arch[-K:])\n                        Fr = np.asarray(f_arch[-K:])\n                        Z = (Xr - m).dot(B)  # n x r\n                        # fit ridge linear model f ≈ c + g^T z\n                        Phi = np.hstack([np.ones((Z.shape[0], 1)), Z])\n                        lam = 1e-6 + 1e-3 * np.trace(np.cov(Z.T)) if Z.shape[0] > 1 else 1e-6\n                        try:\n                            A = Phi.T.dot(Phi) + lam * np.eye(1 + r)\n                            b = Phi.T.dot(Fr)\n                            coeff = np.linalg.solve(A, b)\n                            g_z = coeff[1:1 + r]\n                            # propose step in subspace: scaled negative gradient with adaptive step\n                            z_step = - (0.9 * step_scale) * (g_z / (np.linalg.norm(g_z) + 1e-12))\n                            # clip to subspace trust radius\n                            maxz = 2.0 * step_scale * np.sqrt(r)\n                            if np.linalg.norm(z_step) > maxz:\n                                z_step = z_step * (maxz / (np.linalg.norm(z_step) + 1e-12))\n                            x_prop = np.minimum(np.maximum(m + B.dot(z_step), lb), ub)\n                            f_prop = safe_eval(x_prop)\n                            if f_prop is None:\n                                break\n                            x_cand = x_prop; f_c = f_prop; step = x_cand - m\n                            # try to get ambient gradient approx for secant memory (cheap probes)\n                            g_approx = approx_grad_via_probes(m, step_scale)\n                            if g_approx is not None:\n                                # probe near x_prop for another gradient estimate (but do limited probes)\n                                g_approx2 = approx_grad_via_probes(x_prop, step_scale)\n                                if g_approx2 is not None:\n                                    s = (x_prop - m).copy()\n                                    y = (g_approx2 - g_approx)\n                                    if np.dot(s, y) > 1e-12:\n                                        secants.append({'s': s, 'y': y})\n                                        if len(secants) > max_sec:\n                                            secants.pop(0)\n                        except Exception:\n                            # fallback jitter\n                            eps = rng.randn(self.dim)\n                            step = step_diag * eps + 0.12 * momentum\n                            x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                            f_c = safe_eval(x_cand)\n                            if f_c is None:\n                                break\n                    else:\n                        # fallback jitter\n                        eps = rng.randn(self.dim)\n                        step = step_diag * eps + 0.12 * momentum\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # recombination among elites (convex mix + noise)\n                elif p < (self.prob_levy + self.prob_elite + self.prob_global + self.prob_subspace + self.prob_recomb):\n                    strategy = 'recomb'\n                    if Xe.size and Xe.shape[0] >= 2:\n                        i, j = rng.choice(Xe.shape[0], size=2, replace=False)\n                        alpha = rng.beta(1.2, 1.2)\n                        base = alpha * Xe[i] + (1 - alpha) * Xe[j]\n                        step = 0.8 * step_scale * rng.randn(self.dim)\n                        x_cand = np.minimum(np.maximum(base + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n                    else:\n                        eps = rng.randn(self.dim)\n                        step = step_diag * eps + 0.12 * momentum\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                # L-BFGS ambient proposal using secants\n                elif p < (self.prob_levy + self.prob_elite + self.prob_global + self.prob_subspace + self.prob_recomb + self.prob_lbfgs):\n                    strategy = 'lbfgs'\n                    # try approximate gradient at m (cheap small probes)\n                    g_approx = approx_grad_via_probes(m, step_scale)\n                    if g_approx is not None and len(secants) > 0:\n                        step_full = lbfgs_two_loop(g_approx)\n                        if step_full is not None:\n                            # clip to trust\n                            max_full = 3.0 * step_scale * np.sqrt(self.dim)\n                            if np.linalg.norm(step_full) > max_full:\n                                step_full = step_full * (max_full / (np.linalg.norm(step_full) + 1e-12))\n                            x_prop = np.minimum(np.maximum(m + step_full, lb), ub)\n                            f_prop = safe_eval(x_prop)\n                            if f_prop is None:\n                                break\n                            x_cand = x_prop; f_c = f_prop; step = x_cand - m\n                            # update secants using two gradient probes (try but be conservative)\n                            g2 = approx_grad_via_probes(x_prop, step_scale)\n                            if g2 is not None:\n                                s = (x_prop - m).copy()\n                                y = (g2 - g_approx)\n                                if np.dot(s, y) > 1e-12:\n                                    secants.append({'s': s, 'y': y})\n                                    if len(secants) > max_sec:\n                                        secants.pop(0)\n                        else:\n                            eps = rng.randn(self.dim)\n                            step = step_diag * eps + 0.12 * momentum\n                            x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                            f_c = safe_eval(x_cand)\n                            if f_c is None:\n                                break\n                    else:\n                        eps = rng.randn(self.dim)\n                        step = step_diag * eps + 0.12 * momentum\n                        x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                        f_c = safe_eval(x_cand)\n                        if f_c is None:\n                            break\n\n                else:\n                    # fallback jitter\n                    strategy = 'jitter'\n                    eps = rng.randn(self.dim)\n                    step = step_diag * eps + 0.12 * momentum\n                    x_cand = np.minimum(np.maximum(m + step, lb), ub)\n                    f_c = safe_eval(x_cand)\n                    if f_c is None:\n                        break\n\n                if f_c is None:\n                    break\n\n                # bookkeeping improvement\n                improved = False\n                if f_c < f_best - 1e-15:\n                    f_best = float(f_c); x_best = x_cand.copy(); improved = True; stagn = 0\n                else:\n                    stagn += 1\n\n                # reward-like measure to adapt v_rms\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                raw_reward = max(0.0, baseline - f_c)\n                # update RMS using squared per-dim normalized step\n                if step is not None:\n                    sq = ((step / (step_scale + 1e-12)) ** 2)\n                    v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq\n                    # new step_diag: inversely proportional to sqrt variance (clip)\n                    step_diag = np.clip( (step_scale) / (np.sqrt(v_rms) + 1e-9), self.min_step, self.max_step)\n\n                # acceptance: greedy or probabilistic uphill via T\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    delta = f_c - f_best\n                    if delta <= 0:\n                        accept = True\n                    else:\n                        if rng.rand() < np.exp(-delta / (T + 1e-12)):\n                            accept = True\n\n                if accept:\n                    # learning rate depends on strategy (aggressive for descent proposals)\n                    if strategy in ('subspace', 'lbfgs'):\n                        lr = 0.86\n                    elif strategy == 'recomb':\n                        lr = 0.6\n                    elif strategy == 'elite':\n                        lr = 0.5\n                    elif strategy == 'levy':\n                        lr = 0.18\n                    else:\n                        lr = 0.35\n\n                    delta_m = (x_cand - m)\n                    # clip huge jumps\n                    trust = 10.0 * step_scale * np.sqrt(max(1, self.dim))\n                    dn = np.linalg.norm(delta_m)\n                    if dn > trust:\n                        delta_m = delta_m * (trust / (dn + 1e-12))\n\n                    m = np.minimum(np.maximum(m + lr * delta_m, lb), ub)\n                    momentum = 0.78 * momentum + 0.22 * delta_m\n\n                    # adapt step_scale: reduce when improving, expand slightly on uphill accepts\n                    if improved:\n                        step_scale = max(self.min_step, step_scale * 0.86)\n                        v_rms *= 0.975\n                    else:\n                        step_scale = min(self.max_step, step_scale * 1.025)\n                else:\n                    # reject: small random perturb to escape and cool momentum\n                    m = np.minimum(np.maximum(m + 0.016 * avg_span * rng.randn(self.dim), lb), ub)\n                    step_scale = min(self.max_step, step_scale * 1.007)\n                    momentum *= 0.95\n\n                # opportunistic orthogonal rotation of B to avoid alignment lock-in\n                if r > 0 and rng.rand() < 0.04:\n                    R = rng.randn(r, r) * 0.04\n                    try:\n                        Qr, _ = np.linalg.qr(np.eye(r) + R)\n                        B = B.dot(Qr)\n                        Q2, _ = np.linalg.qr(B)\n                        B = Q2[:, :r]\n                    except Exception:\n                        pass\n\n                # if stagnation detected, do a controlled restart near best and widen trust\n                if stagn >= stagn_limit and evals < self.budget:\n                    stagn = 0\n                    jitter = max(0.02 * avg_span, 1.6 * step_scale)\n                    m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                    step_scale = min(self.max_step, step_scale * 1.5)\n                    momentum = np.zeros(self.dim)\n                    secants = []\n                    # local refine around best\n                    reseed = min(6, self.budget - evals)\n                    for _ in range(reseed):\n                        if evals >= self.budget: break\n                        x = np.minimum(np.maximum(x_best + 0.035 * avg_span * rng.randn(self.dim), lb), ub)\n                        fx = safe_eval(x)\n                        if fx is None: break\n                        if fx < f_best:\n                            f_best = fx; x_best = x.copy()\n\n            # end batch\n\n        # return best found\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 1870, in trace, the following error occurred:\nValueError: diag requires an array of at least two dimensions", "error": "In the code, line 1870, in trace, the following error occurred:\nValueError: diag requires an array of at least two dimensions", "parent_ids": "03c4a78b-1749-4b5d-9b52-08b0dc80cbce", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "17a55b80-ed8b-40a6-b7f7-ae9626b2f134", "fitness": "-inf", "name": "SYNTHESIS", "description": "The algorithm is a hybrid heuristic that centers search on an elite-weighted mean and generates mirrored antithetic candidates by sampling an anisotropic mixture of a learned low-rank PCA manifold (U) plus a diagonal residual, combining exploration (mirrored/low-rank, Cauchy heavy tails, coordinate probes) with exploitation. It continuously learns a compact subspace (subrank = max(1, dim//6), large FIFO archive, pca_refresh) and uses cheap per-subspace quadratic fits to propose minimizers and an L-BFGS two-loop in subspace with secant memory for stronger local steps. Step sizes are controlled by multiplicative sigma adaptation driven by a smoothed success-rate (p_succ → succ_target=0.2, sigma_adapt_rate=0.28), per-dimension RMS normalization (rms_beta=0.925) and momentum (momentum_beta=0.8), with conservative init_sigma_mult (0.18) and clamped sigma_max for stability. Practical robustness features include mirrored-pair sampling fraction (mirror_frac=0.5), small probabilities for surrogate/cauchy/coord probes, opportunistic restarts on stagnation, and a mixed greedy + Metropolis-like acceptance to allow uphill moves.", "code": "import numpy as np\n\nclass SYNTHESIS:\n    \"\"\"\n    SYNTHESIS: Subspace-guided hybrid optimizer combining mirrored antithetic sampling,\n    low-rank PCA manifold, cheap quadratic surrogates and subspace L-BFGS, per-dim RMS scaling,\n    momentum and smoothed success-rate sigma adaptation with opportunistic restarts.\n\n    Usage: algo = SYNTHESIS(budget=10000, dim=10); f_opt, x_opt = algo(func)\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # tunables (sensible defaults)\n        self.pop = max(8, int(6 + 1.2 * np.log(max(2, dim))))\n        self.subrank = max(1, min(dim, dim // 6))  # low-rank dimension\n        self.archive_size = max(6 * dim, 120)\n        self.init_sigma_mult = 0.18\n        self.rms_beta = 0.925\n        self.succ_target = 0.2\n        self.sigma_adapt_rate = 0.28\n        self.pca_refresh = 11\n        self.lbfgs_memory = 32\n        self.momentum_beta = 0.8\n        self.min_sigma = 1e-10\n        self.max_sigma_mult = 4.0\n        self.cauchy_prob = 0.03\n        self.surrogate_prob = 0.18\n        self.coord_prob = 0.08\n        self.mirror_frac = 0.5\n        self.restart_frac = 0.05\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds support\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # state\n        evals = 0\n        # seed archive with a small randomized batch\n        init_seed = min(self.pop * 3, max(12, int(self.budget // 200)))\n        X_arch = []\n        f_arch = []\n\n        # helper safe eval\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x))\n            evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # trim archive FIFO\n            if len(X_arch) > self.archive_size:\n                del X_arch[0]; del f_arch[0]\n            return fx\n\n        for _ in range(init_seed):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            safe_eval(x0)\n\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub)\n            safe_eval(x0)\n\n        # best\n        best_idx = int(np.argmin(f_arch))\n        f_best = float(f_arch[best_idx])\n        x_best = X_arch[best_idx].copy()\n\n        # initialize center as elite-weighted mean\n        def compute_elite_mean(k_frac=0.4):\n            k = max(1, int(len(f_arch) * k_frac))\n            ids = np.argsort(f_arch)[:k]\n            return np.mean(np.asarray([X_arch[i] for i in ids]), axis=0)\n        m = compute_elite_mean()\n\n        # low-rank basis U and diag residual scale v (in sampling units)\n        r = min(self.subrank, self.dim)\n        if r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :r].copy()\n            sub_scale = np.full(r, 0.8 * self.init_sigma_mult * avg_span / np.sqrt(max(1, r)))\n        else:\n            U = np.zeros((self.dim, 0))\n            sub_scale = np.array([])\n\n        sigma = max(self.min_sigma, self.init_sigma_mult * avg_span)\n        sigma = float(sigma)\n        sigma_max = self.max_sigma_mult = self.max_sigma_mult if hasattr(self, 'max_sigma_mult') else 4.0\n        sigma_max = self.max_sigma_mult * avg_span\n\n        # per-dim RMS scaling\n        v_rms = np.full(self.dim, 1e-6)\n        sigma_diag = np.full(self.dim, sigma)\n\n        # L-BFGS-like secant memory in subspace (store s,z where s = z step, y = grad diff)\n        secant = []\n\n        # momentum in original space\n        mom = np.zeros(self.dim)\n\n        # smoothed success prob\n        p_succ = 0.2\n\n        gen = 0\n        stagn = 0\n        stagn_limit = max(6, int(self.restart_frac * self.budget))\n\n        # small helper functions\n        def refresh_subspace():\n            nonlocal U, sub_scale, r\n            if r == 0 or len(X_arch) < max(4, r + 3):\n                return\n            K = min(len(X_arch), self.archive_size)\n            Xr = np.asarray(X_arch[-K:])\n            Mx = Xr.mean(axis=0)\n            S = Xr - Mx\n            try:\n                U_s, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(r, Vt.shape[0])\n                if r_eff > 0:\n                    U_new = Vt[:r_eff].T\n                    # blend to avoid abrupt jumps\n                    if U.shape[1] == r_eff:\n                        U = 0.82 * U + 0.18 * U_new\n                    else:\n                        U = U_new.copy()\n                    # orthonormalize\n                    Q, _ = np.linalg.qr(U)\n                    U = Q[:, :r_eff]\n                    # update sub_scale gently from singular values\n                    svals = np.maximum(svals, 1e-8)\n                    sub_scale = 0.9 * sub_scale[:r_eff] + 0.1 * (svals[:r_eff] / (np.sqrt(r_eff) + 1e-12))\n            except Exception:\n                pass\n\n        def fit_diag_quadratic_subspace(center, U_sub, Xs, fs):\n            # fit per-subspace-diagonal quadratic f ≈ c + b^T z + 0.5 * q * z^2 where z = U^T(x-center)\n            if U_sub.size == 0:\n                return None, None\n            Z = (Xs - center).dot(U_sub)  # n x r\n            n, kloc = Z.shape\n            if n < (2 * kloc + 4):\n                return None, None\n            # design: [1, z_i (k), 0.5*z_i^2 (k)]\n            F = np.ones((n, 1 + 2 * kloc))\n            F[:, 1:1 + kloc] = Z\n            F[:, 1 + kloc:] = 0.5 * (Z ** 2)\n            try:\n                theta, *_ = np.linalg.lstsq(F, fs, rcond=None)\n                c = float(theta[0])\n                b = theta[1:1 + kloc].astype(float)\n                q = theta[1 + kloc:1 + kloc + kloc].astype(float)\n                # regularize q positive-ish\n                q = np.sign(q) * np.maximum(np.abs(q), 1e-6)\n                return (c, b, q), None\n            except Exception:\n                return None, None\n\n        def propose_subspace_minimizer(center, U_sub):\n            # fit quadratic in subspace and propose minimizer z* = -b / q (elementwise) if valid\n            if U_sub.size == 0 or len(X_arch) < 6:\n                return None\n            K = min(len(X_arch), self.archive_size)\n            Xr = np.asarray(X_arch[-K:])\n            fr = np.asarray(f_arch[-K:])\n            res, _ = fit_diag_quadratic_subspace(center, U_sub, Xr, fr)\n            if res is None:\n                return None\n            c, b, q = res\n            z_star = - b / (q + 1e-12)\n            # clip z_star by trust\n            max_norm = 6.0 * sigma\n            znorm = np.linalg.norm(z_star)\n            if znorm > max_norm:\n                z_star = z_star * (max_norm / (znorm + 1e-12))\n            x_prop = np.minimum(np.maximum(center + U_sub.dot(z_star), lb), ub)\n            return x_prop\n\n        def lbfgs_in_subspace_proposal(U_sub):\n            # attempt L-BFGS two-loop in subspace\n            if U_sub.size == 0 or len(secant) < 2:\n                return None\n            # approximate gradient at m via local linear regression in subspace\n            K = min(len(X_arch), 80)\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(U_sub)\n            # weight by distance\n            d = np.linalg.norm(Z, axis=1) + 1e-12\n            w = np.exp(-(d / (np.median(d) + 1e-12))**2)\n            W = np.sqrt(w).reshape(-1, 1)\n            Phi = np.hstack([np.ones((Z.shape[0], 1)), Z])\n            try:\n                A = (W * Phi).T.dot(W * Phi) + 1e-8 * np.eye(Phi.shape[1])\n                bvec = (W * Phi).T.dot(W * Fr)\n                theta = np.linalg.solve(A, bvec)\n                g = theta[1:].astype(float)\n            except Exception:\n                return None\n            # two-loop\n            qv = g.copy()\n            alphas = []\n            rhos = []\n            for entry in reversed(secant[-self.lbfgs_memory:]):\n                s = entry['s']; y = entry['y']\n                rho = 1.0 / (np.dot(y, s) + 1e-12)\n                rhos.append(rho)\n                alpha = rho * np.dot(s, qv)\n                alphas.append(alpha)\n                qv = qv - alpha * y\n            if len(secant) > 0:\n                last = secant[-1]\n                s, y = last['s'], last['y']\n                gamma = max(1e-6, np.dot(s, y) / (np.dot(y, y) + 1e-12))\n            else:\n                gamma = 1.0\n            rvec = gamma * qv\n            for i, entry in enumerate(secant[-self.lbfgs_memory:]):\n                s = entry['s']; y = entry['y']\n                rho = rhos[len(rhos) - 1 - i]\n                alpha = alphas[len(alphas) - 1 - i]\n                beta = rho * np.dot(y, rvec)\n                rvec = rvec + s * (alpha - beta)\n            z_step = - rvec\n            # clip step\n            max_norm = 6.0 * sigma\n            zn = np.linalg.norm(z_step)\n            if zn > max_norm:\n                z_step = z_step * (max_norm / (zn + 1e-12))\n            x_prop = np.minimum(np.maximum(m + U_sub.dot(z_step), lb), ub)\n            return x_prop, z_step\n\n        # main loop: generate small batches until budget exhausted\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop, remaining)\n            # refresh subspace occasionally\n            if (gen % self.pca_refresh) == 0:\n                refresh_subspace()\n\n            # determine mixture counts\n            n_mirror_pairs = int(max(1, np.round(self.mirror_frac * lam)) // 2)\n            # ensure at least one candidate\n            proposals = []\n            types = []\n\n            # maybe propose surrogate minimizer or L-BFGS in subspace first (exploit)\n            if rng.rand() < self.surrogate_prob and U.size > 0 and remaining >= 1:\n                prop = propose_subspace_minimizer(m, U)\n                if prop is not None:\n                    proposals.append(prop); types.append('subsur')\n            if len(proposals) < lam and rng.rand() < 0.14 and U.size > 0 and remaining >= 1:\n                res = lbfgs_in_subspace_proposal(U)\n                if res is not None:\n                    proposals.append(res[0]); types.append('lbfgs')\n\n            # mirrored antithetic sampling in anisotropic low-rank + diag residual space\n            # generate half batch and mirror them\n            half = max(1, (lam - len(proposals)) // 2)\n            for _ in range(half):\n                if len(proposals) + 2 > lam:\n                    break\n                # sample subspace coordinates\n                if U.size > 0:\n                    z = rng.normal(scale=sub_scale)\n                    low = U.dot(z)\n                else:\n                    low = np.zeros(self.dim)\n                eps = rng.randn(self.dim) * sigma_diag\n                step = sigma * (low + eps / (sigma + 1e-20))\n                x_p = np.minimum(np.maximum(m + step, lb), ub)\n                x_m = np.minimum(np.maximum(m - step, lb), ub)\n                proposals.append(x_p); types.append('mirror+')\n                proposals.append(x_m); types.append('mirror-')\n\n            # fill remaining proposals by mixed strategies\n            while len(proposals) < lam:\n                p = rng.rand()\n                if p < self.cauchy_prob and remaining >= 1:\n                    # heavy-tailed escape\n                    z = rng.standard_cauchy(size=self.dim)\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    x = np.minimum(np.maximum(m + 6.0 * sigma * z, lb), ub)\n                    proposals.append(x); types.append('cauchy')\n                elif p < (self.cauchy_prob + self.coord_prob) and remaining >= 1:\n                    # coordinate probe: tweak top variance coordinate\n                    if len(X_arch) >= 6:\n                        Xr = np.asarray(X_arch[-min(len(X_arch), self.archive_size):])\n                        var = np.var(Xr, axis=0)\n                        j = int(rng.choice(self.dim, p=(var + 1e-12) / (np.sum(var) + 1e-12)))\n                    else:\n                        j = rng.randint(0, self.dim)\n                    a = sigma * (0.6 + 1.4 * rng.rand())\n                    step = np.zeros(self.dim); step[j] = a if rng.rand() < 0.5 else -a\n                    x = np.minimum(np.maximum(m + step, lb), ub)\n                    proposals.append(x); types.append('coord')\n                else:\n                    # low-rank Gaussian + diag residual jitter\n                    if U.size > 0:\n                        z = rng.normal(scale=sub_scale)\n                        low = U.dot(z)\n                    else:\n                        low = np.zeros(self.dim)\n                    eps = rng.randn(self.dim) * sigma_diag\n                    step = sigma * (low + eps / (sigma + 1e-20))\n                    x = np.minimum(np.maximum(m + step, lb), ub)\n                    proposals.append(x); types.append('lowrank')\n\n            # Evaluate proposals sequentially, respecting budget\n            fvals = []\n            x_evaluated = []\n            for x in proposals:\n                if evals >= self.budget:\n                    break\n                fx = safe_eval(x)\n                if fx is None:\n                    break\n                x_evaluated.append(np.asarray(x, dtype=float))\n                fvals.append(float(fx))\n                # immediate best update\n                if fx < f_best:\n                    f_best = float(fx); x_best = np.asarray(x, dtype=float)\n                    stagn = 0\n                else:\n                    stagn += 1\n\n            if len(fvals) == 0:\n                break\n\n            # selection: pick best in this mini-batch\n            idx_local = int(np.argmin(fvals))\n            x_local_best = x_evaluated[idx_local]; f_local_best = fvals[idx_local]\n\n            # compute normalized steps for statistics; normalized with sigma and diag\n            deltas = (np.asarray(x_evaluated) - m.reshape(1, -1)) / (sigma + 1e-20)\n\n            # success indicator: any candidate improved current m-based reference (global best)\n            gen_success = any(np.array(fvals) < f_best + 1e-12)\n\n            # update smoothed success-rate and adapt sigma multiplicatively (1/5 style)\n            p_succ = 0.92 * p_succ + 0.08 * (1.0 if np.min(fvals) < f_best + 1e-12 else 0.0)\n            # multiplicative update: exponent\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n            sigma = np.clip(sigma, self.min_sigma, sigma_max)\n\n            # update per-dim RMS (sigma_diag)\n            stat = np.mean(np.abs(deltas), axis=0)\n            v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * (stat ** 2)\n            sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-12), 1e-12, sigma_max)\n\n            # momentum update from the chosen local best relative to m\n            delta_m = (x_local_best - m)\n            mom = self.momentum_beta * mom + (1.0 - self.momentum_beta) * delta_m\n\n            # acceptance: accept chosen candidate into mean if improves global best or via Metropolis-like uphill acceptance\n            accept = False\n            if f_local_best <= f_best:\n                accept = True\n            else:\n                # uphill acceptance probability scaled by sigma * avg_span\n                T = max(1e-12, 0.7 * sigma * avg_span)\n                if rng.rand() < np.exp(-max(0.0, f_local_best - f_best) / (T + 1e-12)):\n                    accept = True\n\n            if accept:\n                # learning rate depends on type\n                typ = types[idx_local] if idx_local < len(types) else 'lowrank'\n                if typ in ('subsur', 'lbfgs'):\n                    eta = 0.72\n                elif typ.startswith('mirror'):\n                    eta = 0.38\n                elif typ in ('coord',):\n                    eta = 0.55\n                else:\n                    eta = 0.32\n                # trust clipping to avoid huge jumps\n                trust = max(1e-12, 8.0 * sigma * np.sqrt(max(1, self.dim)))\n                dn = np.linalg.norm(delta_m)\n                if dn > trust:\n                    delta_m = delta_m * (trust / (dn + 1e-12))\n                m = np.minimum(np.maximum(m + eta * delta_m, lb), ub)\n            else:\n                # mild exploratory drift\n                m = np.minimum(np.maximum(m + 0.03 * avg_span * rng.randn(self.dim), lb), ub)\n\n            # update low-rank basis from successful normalized steps into buffer\n            # collect improving normalized steps\n            for i, (x_i, f_i) in enumerate(zip(x_evaluated, fvals)):\n                # reward if improved relative to local median or directional signal from mirrored pairs\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                if f_i <= baseline or (types[i].startswith('mirror') and f_i < np.median(fvals)):\n                    # normalized step in original units divided by sigma\n                    step_normed = (x_i - m) / (sigma + 1e-20)\n                    # push small sample into a transient buffer stored in X_arch for PCA refresh\n                    X_arch.append((m + step_normed * sigma).copy())\n                    f_arch.append(f_i)\n                    if len(X_arch) > self.archive_size:\n                        del X_arch[0]; del f_arch[0]\n\n            # update secant info for L-BFGS in subspace when subspace proposals used\n            if U.size > 0:\n                # use best evaluated to compute subspace difference relative to previous mean projection\n                z_new = (x_local_best - m).dot(U)\n                # approximate gradient via local linear fit in subspace\n                # compute gradient approx g at m: use small neighborhood points if available\n                K = min(len(X_arch), 40)\n                if K >= 6:\n                    Xr = np.asarray(X_arch[-K:])\n                    Fr = np.asarray(f_arch[-K:])\n                    Z = (Xr - m).dot(U)\n                    # linear regression f ~ c + g^T z\n                    try:\n                        Phi = np.hstack([np.ones((Z.shape[0], 1)), Z])\n                        theta, *_ = np.linalg.lstsq(Phi, Fr, rcond=None)\n                        g_est = theta[1:].astype(float)\n                        # if prior gradient exists, compute secant y\n                        if len(secant) > 0:\n                            g_prev = secant[-1].get('g', None)\n                            s_vec = (z_new - secant[-1].get('z', np.zeros_like(z_new)))\n                            if g_prev is not None and s_vec is not None:\n                                y_vec = g_est - g_prev\n                                if np.dot(s_vec, y_vec) > 1e-12:\n                                    secant.append({'s': s_vec.copy(), 'y': y_vec.copy(), 'z': z_new.copy(), 'g': g_est.copy()})\n                                else:\n                                    secant.append({'s': s_vec.copy(), 'y': y_vec.copy(), 'z': z_new.copy(), 'g': g_est.copy()})\n                            else:\n                                secant.append({'s': np.zeros_like(z_new), 'y': np.zeros_like(z_new), 'z': z_new.copy(), 'g': g_est.copy()})\n                        else:\n                            secant.append({'s': np.zeros_like(z_new), 'y': np.zeros_like(z_new), 'z': z_new.copy(), 'g': g_est.copy()})\n                        # limit memory\n                        if len(secant) > self.lbfgs_memory:\n                            secant.pop(0)\n                    except Exception:\n                        pass\n\n            # opportunistic restart if stagnation large\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                # restart around best with jitter, reset some statistics but keep low-rank structure partly\n                jitter = max(0.04 * avg_span, 0.8 * sigma)\n                m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                sigma = max(sigma * 1.8, 0.2 * avg_span)\n                sigma = min(sigma, sigma_max)\n                # refresh subspace randomly a bit\n                if r > 0:\n                    A = rng.randn(self.dim, r)\n                    Q, _ = np.linalg.qr(A)\n                    U = Q[:, :r]\n                    sub_scale = np.full(r, 0.8 * self.init_sigma_mult * avg_span / np.sqrt(max(1, r)))\n                # clear some secant memory\n                secant = secant[-max(1, int(0.3 * len(secant))):]\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 248, in lbfgs_in_subspace_proposal, the following error occurred:\nValueError: operands could not be broadcast together with shapes (10,) (10,80) \nOn line: x_prop = np.minimum(np.maximum(m + U_sub.dot(z_step), lb), ub)", "error": "In the code, line 248, in lbfgs_in_subspace_proposal, the following error occurred:\nValueError: operands could not be broadcast together with shapes (10,) (10,80) \nOn line: x_prop = np.minimum(np.maximum(m + U_sub.dot(z_step), lb), ub)", "parent_ids": "03c4a78b-1749-4b5d-9b52-08b0dc80cbce", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "ca85c407-7ee4-4c6c-b774-e18646f39161", "fitness": 0.5279312448437746, "name": "ArchiveLevyDiagonalEvolution", "description": "The algorithm mixes isotropic Gaussian evolution with a strong mean-pull (alpha_mean=0.65) and per-individual sigmas initialized relative to the domain (sigma_init_frac≈0.25·range_mean) that are adapted from a windowed success history (window_len=12) using conservative decrease/increase factors (0.90/1.08) and soft sigma resets, producing self-tuning exploration/exploitation. Selection uses opportunistic evaluation of crossover-like mixed trials (per-dimension mix_prob) and occasional opposition sampling (opposition_prob≈0.12), while bounds are handled by a reflect-then-clamp rule to preserve feasibility. A compact elite archive (archive_frac≈0.25) seeds heavy-tailed Cauchy-style global jumps (global_jump_prob≈0.18) and archive-guided jittered restarts, and promising candidates trigger budget-limited Hooke–Jeeves coordinate-pattern local searches (local_budget_frac≈0.04) to refine solutions. Initialization is Latin-like stratified with jitter, periodic uniform injections and adaptive jump probabilities maintain diversity, and the whole loop enforces strict evaluation-budget accounting.", "code": "import numpy as np\n\nclass ArchiveLevyDiagonalEvolution:\n    \"\"\"\n    Sigma-adaptive mean-pull evolution with archive-guided Cauchy restarts and Hooke-Jeeves local refinements.\n    - Population evolves by isotropic Gaussian mutations with per-individual sigma and a pull towards the population mean.\n    - Sigmas adapt via a windowed success history (increase/decrease multipliers).\n    - Maintain a compact elite archive used to seed heavy-tailed Cauchy-like global jumps and jittered restarts.\n    - Periodically or on stagnation trigger a budget-limited Hooke-Jeeves coordinate pattern local search around best/archive candidates.\n    - Strict budget accounting, reflect-then-clamp bounds handling, occasional opposition/uniform injections and archive-driven replacement of worst individuals.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop_base=None,\n                 alpha_mean=0.65,\n                 sigma_init_frac=0.25,\n                 sigma_min_frac=1e-5,\n                 sigma_max_frac=1.2,\n                 window_len=12,\n                 decrease_factor=0.90,\n                 increase_factor=1.08,\n                 tau_sigma_reset=0.04,\n                 opposition_prob=0.12,\n                 local_period=12,\n                 local_stagn_gen=35,\n                 local_budget_frac=0.04,\n                 archive_frac=0.25,\n                 global_jump_prob=0.18,\n                 rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop_base = pop_base\n        self.alpha_mean = float(alpha_mean)\n        self.sigma_init_frac = float(sigma_init_frac)\n        self.sigma_min_frac = float(sigma_min_frac)\n        self.sigma_max_frac = float(sigma_max_frac)\n        self.window_len = int(window_len)\n        self.decrease_factor = float(decrease_factor)\n        self.increase_factor = float(increase_factor)\n        self.tau_sigma_reset = float(tau_sigma_reset)\n        self.opposition_prob = float(opposition_prob)\n        self.local_period = int(local_period)\n        self.local_stagn_gen = int(local_stagn_gen)\n        self.local_budget_frac = float(local_budget_frac)\n        self.archive_frac = float(archive_frac)\n        self.global_jump_prob = float(global_jump_prob)\n        self.rng_seed = rng_seed\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # Read bounds; many BBOB problems use scalar bounds [-5,5]\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        range_vec = ub - lb\n        range_mean = float(np.mean(range_vec))\n        eps = 1e-12\n\n        # population size (moderate)\n        if self.pop_base is None:\n            pop = max(12, int(min(48, max(12, int(6 * np.sqrt(max(1, self.dim)))))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        # helper: reflect once then clamp\n        def reflect_clamp(x):\n            x = np.asarray(x, dtype=float).copy()\n            below = x < lb\n            if np.any(below):\n                x[below] = lb[below] + (lb[below] - x[below])\n            above = x > ub\n            if np.any(above):\n                x[above] = ub[above] - (x[above] - ub[above])\n            np.minimum(np.maximum(x, lb), ub, out=x)\n            return x\n\n        # heavy-tailed Cauchy-like jump generator\n        def cauchy_jump(center, scale):\n            # direction + standard Cauchy length, clipped\n            direction = rng.randn(self.dim)\n            nd = np.linalg.norm(direction)\n            if nd == 0:\n                direction = rng.randn(self.dim)\n                nd = np.linalg.norm(direction) + 1e-12\n            direction /= nd\n            step_len = rng.standard_cauchy()\n            step_len = np.clip(step_len, -1e3, 1e3)\n            # per-dim scaling by domain and individual scale factor\n            step = direction * (scale * range_mean * (0.4 + 0.6 * rng.rand()))\n            return reflect_clamp(center + step_len * step)\n\n        # Hooke-Jeeves style local search (coordinate pattern moves), strict local_budget\n        def local_pattern_search(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            # initial step: fraction of mean range\n            step0 = max(eps, 0.4 * range_mean * (0.5 + 0.5 * rng.rand()))\n            steps = np.full(self.dim, step0, dtype=float)\n            shrink = 0.6\n            pattern_factor = 1.5\n            local_evals = 0\n            # limit iterations to avoid overconsuming evaluations\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_evals < local_budget and iters < iter_limit and np.any(steps > (1e-8 * range_mean)):\n                iters += 1\n                improved = False\n                x_probe = base.copy()\n                x_probe_f = base_f\n                # exploratory moves\n                for i in range(self.dim):\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    # plus\n                    xp = x_probe.copy()\n                    xp[i] = min(ub[i], xp[i] + steps[i])\n                    xp = reflect_clamp(xp)\n                    if evals < self.budget:\n                        fp = float(func(xp)); evals += 1; local_evals += 1\n                        # record via eval_and_record wrapper logic below\n                        # update best/archive inside eval wrapper alternate path\n                        if fp < x_probe_f:\n                            x_probe = xp.copy()\n                            x_probe_f = fp\n                            improved = True\n                            # immediate update to global records\n                            _record(fp, xp)\n                            continue\n                    # minus\n                    xn = x_probe.copy()\n                    xn[i] = max(lb[i], xn[i] - steps[i])\n                    xn = reflect_clamp(xn)\n                    if evals < self.budget:\n                        fn = float(func(xn)); evals += 1; local_evals += 1\n                        if fn < x_probe_f:\n                            x_probe = xn.copy()\n                            x_probe_f = fn\n                            improved = True\n                            _record(fn, xn)\n                # pattern move\n                if improved and local_evals < local_budget and evals < self.budget:\n                    direction = x_probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + pattern_factor * direction\n                        xp = reflect_clamp(xp)\n                        if evals < self.budget:\n                            fp = float(func(xp)); evals += 1; local_evals += 1\n                            if fp < x_probe_f:\n                                base = xp.copy(); base_f = fp\n                                _record(fp, xp)\n                            else:\n                                base = x_probe.copy(); base_f = x_probe_f\n                    else:\n                        base = x_probe.copy(); base_f = x_probe_f\n                else:\n                    steps *= shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # eval wrapper that also maintains best and archive\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f, x) sorted\n        archive_k = max(3, min(12, int(max(3, pop * self.archive_frac))))\n\n        def _record(f, x):\n            nonlocal f_best, x_best, archive\n            if f < f_best:\n                f_best = float(f)\n                x_best = x.copy()\n            # archive insert\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n\n        # initialize population via Latin-like stratification\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / float(pop)\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        # jitter a fraction\n        jitter_scale = 0.2 * range_mean / max(1.0, self.dim)\n        X += (rng.rand(pop, self.dim) - 0.5) * jitter_scale\n        X = np.minimum(np.maximum(X, lb), ub)\n\n        f = np.full(pop, np.inf, dtype=float)\n        # evaluate initial population sequentially\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            fx = float(func(X[i])); evals += 1\n            f[i] = fx\n            _record(fx, X[i].copy())\n        if evals >= self.budget:\n            best_idx = int(np.argmin(f[:min(pop, evals)]))\n            self.f_opt = float(f[best_idx]); self.x_opt = X[best_idx].copy()\n            return self.f_opt, self.x_opt\n\n        # per-individual sigmas (isotropic)\n        sigma = np.full(pop, max(eps, self.sigma_init_frac * range_mean), dtype=float)\n        sigma_min = max(eps, self.sigma_min_frac * range_mean)\n        sigma_max = max(eps, self.sigma_max_frac * range_mean)\n        mix_prob = np.clip(0.2 + 0.2 * rng.rand(pop), 0.05, 0.9)\n\n        # success history window\n        win = max(1, self.window_len)\n        success_hist = np.zeros((pop, win), dtype=np.int8)\n        hist_pos = 0\n\n        gen = 0\n        gens_since_improve = 0\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            improved_in_gen = False\n\n            pop_mean = np.mean(X, axis=0)\n\n            order = rng.permutation(pop)\n            gen_success = np.zeros(pop, dtype=np.int8)\n\n            for ii in order:\n                if evals >= self.budget:\n                    break\n\n                xi = X[ii].copy()\n                fi = float(f[ii])\n\n                # rare sigma reset for exploration\n                if rng.rand() < self.tau_sigma_reset:\n                    sigma[ii] = rng.rand() * (sigma_max - sigma_min) + sigma_min\n\n                # generate trial: pull to mean + gaussian\n                pull = self.alpha_mean * (pop_mean - xi)\n                gauss = rng.randn(self.dim) * sigma[ii]\n                trial = xi + pull + gauss\n\n                # mixing like crossover\n                mask = rng.rand(self.dim) < mix_prob[ii]\n                if not np.any(mask):\n                    mask[rng.randint(self.dim)] = True\n                trial = np.where(mask, trial, xi)\n                trial = reflect_clamp(trial)\n\n                # opposition consideration\n                candidate_points = [trial]\n                if rng.rand() < self.opposition_prob:\n                    opp = lb + ub - trial\n                    opp += (rng.randn(self.dim) * 0.01 * range_mean)\n                    opp = reflect_clamp(opp)\n                    candidate_points.append(opp)\n\n                # opportunistic evaluation ordering: try the one closer to mean first\n                dists = [np.linalg.norm(cp - pop_mean) for cp in candidate_points]\n                idx_order = np.argsort(dists)\n                best_local_f = np.inf\n                best_local_x = None\n                for idx in idx_order:\n                    if evals >= self.budget:\n                        break\n                    xc = candidate_points[idx]\n                    fv = float(func(xc)); evals += 1\n                    if fv < best_local_f:\n                        best_local_f = fv\n                        best_local_x = xc.copy()\n\n                # selection\n                if best_local_f <= fi:\n                    X[ii] = best_local_x.copy()\n                    f[ii] = best_local_f\n                    gen_success[ii] = 1\n                    _record(best_local_f, best_local_x.copy())\n                    if best_local_f < f_best:\n                        f_best = float(best_local_f)\n                        x_best = best_local_x.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n                else:\n                    gen_success[ii] = 0\n\n            # update history and adapt sigma\n            success_hist[:, hist_pos] = gen_success\n            hist_pos = (hist_pos + 1) % win\n            success_rate = np.sum(success_hist, axis=1) / float(win)\n            for i in range(pop):\n                if success_rate[i] > 0.27:\n                    sigma[i] = max(sigma_min, sigma[i] * self.decrease_factor)\n                elif success_rate[i] < 0.15:\n                    sigma[i] = min(sigma_max, sigma[i] * self.increase_factor)\n                # jitter mix_prob a little\n                if rng.rand() < 0.02:\n                    mix_prob[i] = np.clip(mix_prob[i] + (rng.randn() * 0.04), 0.01, 0.95)\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n\n            # occasional archive-guided Cauchy jump: seed from best or random archive member\n            if len(archive) > 0 and rng.rand() < (self.global_jump_prob * (1.0 + 0.6 * (gens_since_improve > self.local_stagn_gen))):\n                center = archive[0][1] if rng.rand() < 0.7 else archive[rng.randint(0, len(archive))]\n                if isinstance(center, tuple):\n                    center = center[1]\n                # scale adaptively smaller as generations progress\n                scale = max(0.05, 1.0 - 0.01 * gen)\n                cand = cauchy_jump(center, scale)\n                if evals < self.budget:\n                    fc = float(func(cand)); evals += 1\n                    _record(fc, cand.copy())\n                    # if promising, do a small local pattern search\n                    threshold = archive[0][0] * 1.12 if len(archive) > 0 else np.inf\n                    if fc <= threshold and evals < self.budget:\n                        local_alloc = min(max(2, int(self.local_budget_frac * self.budget)), self.budget - evals)\n                        # slightly larger budget for promising cue\n                        local_alloc = max(2, int(local_alloc * 2))\n                        f_after, x_after = local_pattern_search(cand, fc, local_alloc)\n                        if f_after < np.max(f):\n                            worst_idx = int(np.argmax(f))\n                            X[worst_idx] = x_after.copy()\n                            f[worst_idx] = f_after\n                            _record(f_after, x_after.copy())\n                            if f_after < f_best:\n                                f_best = float(f_after)\n                                x_best = x_after.copy()\n                                gens_since_improve = 0\n                                improved_in_gen = True\n\n            # Periodic or stagnation-triggered local pattern search around best\n            remaining = self.budget - evals\n            if remaining > 0 and (gen % self.local_period == 0 or gens_since_improve >= self.local_stagn_gen):\n                alloc = min(max(2, int(self.local_budget_frac * self.budget)), remaining)\n                # if strongly stagnating, increase local budget\n                if gens_since_improve >= self.local_stagn_gen:\n                    alloc = min(self.budget - evals, max(alloc, int(alloc * 3)))\n                if x_best is not None and alloc > 0:\n                    f_after, x_after = local_pattern_search(x_best, f_best, alloc)\n                    if f_after < f_best:\n                        worst_idx = int(np.argmax(f))\n                        X[worst_idx] = x_after.copy()\n                        f[worst_idx] = f_after\n                        _record(f_after, x_after.copy())\n                        f_best = float(f_after)\n                        x_best = x_after.copy()\n                        gens_since_improve = 0\n                        improved_in_gen = True\n                    else:\n                        # mild jitter nudges from best if still stagnating\n                        if gens_since_improve >= self.local_stagn_gen:\n                            nudges = min(pop // 3, max(1, int((gens_since_improve - self.local_stagn_gen + 1))))\n                            for k in range(nudges):\n                                if evals >= self.budget:\n                                    break\n                                jitter = 0.06 * (range_vec) * rng.randn(self.dim)\n                                newx = reflect_clamp(x_best + jitter)\n                                fv = float(func(newx)); evals += 1\n                                worst_idx = int(np.argmax(f))\n                                X[worst_idx] = newx.copy()\n                                f[worst_idx] = fv\n                                _record(fv, newx.copy())\n                                if fv < f_best:\n                                    f_best = float(fv)\n                                    x_best = newx.copy()\n                                    gens_since_improve = 0\n                                    improved_in_gen = True\n\n            # occasional uniform injection for diversity\n            if (gen % 19) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                fu = float(func(xu)); evals += 1\n                worst_idx = int(np.argmax(f))\n                X[worst_idx] = xu.copy()\n                f[worst_idx] = fu\n                _record(fu, xu.copy())\n                if fu < f_best:\n                    f_best = float(fu)\n                    x_best = xu.copy()\n                    gens_since_improve = 0\n                    improved_in_gen = True\n\n            # adapt global_jump_prob based on archive spread\n            if len(archive) >= 2:\n                diversity = np.linalg.norm(archive[0][1] - archive[-1][1])\n                if diversity < 0.01 * range_mean + 1e-9:\n                    self.global_jump_prob = min(0.6, self.global_jump_prob + 0.02)\n                else:\n                    self.global_jump_prob = max(0.02, self.global_jump_prob * 0.996)\n\n            # sync best from population\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n                improved_in_gen = True\n\n            # safety: stop if budget exhausted\n            if evals >= self.budget:\n                break\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ArchiveLevyDiagonalEvolution scored 0.528 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "03c4a78b-1749-4b5d-9b52-08b0dc80cbce", "operator": null, "metadata": {"aucs": [0.13093665107858998, 0.157648221785475, 0.8190322453785963, 0.9888303192503594, 0.9865850640668561, 0.9835475632508945, 0.2817797777194301, 0.5075174295605431, 0.25539232027579517, 0.16804285607120717]}, "task_prompt": ""}
{"id": "b49a045b-62d7-481c-95dd-d06c3592f774", "fitness": 0.20555704253059542, "name": "DARTS", "description": "The algorithm maintains an evaluated archive and a central iterate m, learns an online low-rank search subspace U via Oja's rule (subspace_dim ≈ max(1, dim//6), oja_lr=0.06) and fits a lightweight ridge/quadratic surrogate in that subspace to propose a subspace minimizer and predicted improvements. It uses a diverse set of complementary operators — subspace surrogate minimizer, directional line probes along principal/random axes, coordinate-adaptive steps with per-dimension learning rates, finite-difference directional gradient steps, Cauchy heavy-tailed jumps for global escapes and Gaussian random walks — and allocates evaluations among them with multiplicative-weights (replicator-style) updates (op_decay=0.995, eta_w scaling with generation). The center is updated by a Tsallis-q weighted aggregation (q≈1.2) of recent evaluated candidates (tempering by trust/diversity), while a trust radius (init ≈0.18·avg_span, bounded by [1e-8,5.0]) is adaptively shrunk or expanded based on improvement, predicted vs. actual behavior and archive diversity. Robustness measures include covariance shrinkage for elites, surrogate regularization, bounds clamping/safe_eval to respect the budget, archive trimming, stagnation-driven targeted restarts using elite covariance and local reseeding, and conservative numeric safeguards throughout.", "code": "import numpy as np\n\nclass DARTS:\n    \"\"\"\n    Directional Adaptive Rotational Trust Search (DARTS)\n\n    Main ideas:\n    - Maintain an evaluated archive and a center m.\n    - Learn a streaming/online low-rank basis U via Oja's rule (incremental PCA).\n    - Fit a lightweight ridge/quadratic surrogate inside the learned subspace and propose subspace minimizers.\n    - Use a multiplicative-weights operator allocator (replicator dynamics) instead of UCB.\n    - Operators: subspace surrogate minimizer, directional line probes along principal axes, coordinate-adaptive steps,\n                 finite-difference directional gradient steps and Cauchy heavy-tailed jumps.\n    - Center update via Tsallis-q weighted aggregation (q-softmax) to bias toward better points while retaining robustness.\n    - Adaptive trust radius adjusted by predicted/actual improvement ratio and archive diversity.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop=12, subspace_dim=None,\n                 init_trust=0.18, oja_lr=0.06, surrogate_reg=1e-6,\n                 q_tsallis=1.2, min_trust=1e-8, max_trust=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.rng = np.random.RandomState(seed)\n        self.pop = int(pop)\n        self.subspace_dim = subspace_dim if subspace_dim is not None else max(1, self.dim // 6)\n        self.init_trust_rel = float(init_trust)  # relative to avg span\n        self.oja_lr = float(oja_lr)\n        self.surrogate_reg = float(surrogate_reg)\n        self.q_tsallis = float(q_tsallis)\n        self.min_trust = float(min_trust)\n        self.max_trust = float(max_trust)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling (support scalar or vector)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        trust_radius = max(self.min_trust, self.init_trust_rel * avg_span)\n\n        # archive and bookkeeping\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # small RNG seed sampling to initialize\n        seed0 = min(max(8, int(self.budget // 300)), max(12, self.pop * 4))\n        for _ in range(seed0):\n            if evals >= self.budget: break\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        if len(f_arch) == 0 and evals < self.budget:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        # center\n        m = x_best.copy()\n\n        # streaming PCA (Oja) initialize U with random orthonormal if possible\n        r = min(self.subspace_dim, self.dim)\n        if r > 0:\n            U = rng.randn(self.dim, r)\n            # orthonormalize\n            try:\n                U, _ = np.linalg.qr(U)\n                U = U[:, :r]\n            except Exception:\n                U = U / (np.linalg.norm(U, axis=0, keepdims=True) + 1e-12)\n        else:\n            U = np.zeros((self.dim, 0))\n\n        # per-dimension adaptive learning rates for coordinate operator\n        per_dim_lr = np.full(self.dim, 0.12 * avg_span / (1.0 + np.arange(self.dim) * 0.0))\n        per_dim_lr = np.clip(per_dim_lr, 1e-6, 1.0 * avg_span)\n\n        # multiplicative operator weights\n        operators = ['subspace_opt', 'dir_line', 'coord_adapt', 'fin_dir', 'cauchy_jump', 'rand_walk']\n        w_op = np.ones(len(operators))\n        op_index = {op: i for i, op in enumerate(operators)}\n        op_decay = 0.995  # decay for explore-exploit\n\n        # helper: safe evaluation\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch, x_best, f_best\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # trim archive to recent window\n            max_archive = max(6 * self.subspace_dim, 3 * self.pop, 200)\n            if len(X_arch) > max_archive:\n                del X_arch[0:(len(X_arch) - max_archive)]\n                del f_arch[0:(len(f_arch) - max_archive)]\n            if fx < f_best:\n                x_best = x.copy(); f_best = float(fx)\n            return fx\n\n        # helper: compute robust (shrunk) covariance for elites\n        def shrink_cov(Xe, shrink=0.1):\n            if Xe.size == 0:\n                return np.eye(self.dim)\n            S = np.cov(Xe.T) if Xe.shape[0] > 1 else np.zeros((self.dim, self.dim))\n            F = np.trace(S) / max(1, self.dim)\n            C = (1.0 - shrink) * S + shrink * F * np.eye(self.dim)\n            # ensure positive definite\n            C += 1e-10 * np.eye(self.dim)\n            return C\n\n        # helper: Oja update for U with one new centered sample z = x - m\n        def oja_update(Umat, z, lr):\n            if Umat.shape[1] == 0:\n                return Umat\n            # normalize z a bit to avoid scale issues\n            zn = z / (np.linalg.norm(z) + 1e-12)\n            for j in range(Umat.shape[1]):\n                uj = Umat[:, j]\n                # Oja update: u <- u + lr * (z * (z^T u) - (u * (u^T z)^2))\n                proj = np.dot(zn, uj)\n                uj = uj + lr * (zn * proj - uj * (proj ** 2 + 1e-12))\n                Umat[:, j] = uj\n            # orthonormalize columns\n            try:\n                Q, _ = np.linalg.qr(Umat)\n                return Q[:, :Umat.shape[1]]\n            except Exception:\n                # fallback normalize\n                norms = np.linalg.norm(Umat, axis=0) + 1e-12\n                return Umat / norms\n       \n        # lightweight subspace surrogate fit (ridge) using basis U\n        # model: f ≈ c + g^T z + 0.5 * H_diag * z^2  (diagonal Hessian approximation)\n        def fit_subspace_surrogate(Umat, samples= min(120, max(20, self.subspace_dim * 12))):\n            if Umat.shape[1] == 0 or len(X_arch) < (Umat.shape[1] + 4):\n                return None\n            K = min(samples, len(X_arch))\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(Umat)  # n x r\n            n, r = Z.shape\n            Phi = np.ones((n, 1 + r + r))\n            Phi[:, 1:1 + r] = Z\n            Phi[:, 1 + r:1 + r + r] = Z ** 2\n            try:\n                A = Phi.T.dot(Phi) + self.surrogate_reg * np.eye(Phi.shape[1])\n                b = Phi.T.dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1 + r]\n                Hdiag = coeff[1 + r:1 + r + r]\n                # ensure positive curvature (regularize small or negative to small positive)\n                Hdiag = np.maximum(Hdiag, 1e-8)\n                # minimizer in subspace (diagonal): z* = - g / Hdiag\n                zstar = - g / (Hdiag + 1e-12)\n                # scale by trust radius in subspace\n                max_norm = (trust_radius / (np.linalg.norm(Umat, ord=2) + 1e-12)) * np.sqrt(max(1, r))\n                znorm = np.linalg.norm(zstar)\n                if znorm > max_norm:\n                    zstar = zstar * (max_norm / (znorm + 1e-12))\n                fpred = float(c + g.dot(zstar) + 0.5 * np.sum(Hdiag * (zstar ** 2)))\n                return zstar, fpred, (g, Hdiag, c)\n            except Exception:\n                return None\n\n        # Tsallis q-weighted aggregation (q-softmax) for center update using last batch\n        def tsallis_weights(fs, q=1.2, temp=1.0):\n            # lower f should have higher weight\n            fmin = np.min(fs)\n            delta = fs - fmin\n            # transform: w_i ∝ max(0, 1 - (q-1) * delta / temp)^{1/(q-1)}\n            eps = 1e-12\n            coeff = 1.0 - (q - 1.0) * (delta / (temp + eps))\n            coeff = np.maximum(coeff, 1e-12)\n            w = coeff ** (1.0 / (q - 1.0 + eps))\n            w = w / (np.sum(w) + 1e-12)\n            return w\n\n        # helper: choose operator by softmax sampling of w_op\n        def choose_operator():\n            prob = np.exp(np.log(w_op + 1e-12) - np.mean(np.log(w_op + 1e-12)))\n            prob = prob / (np.sum(prob) + 1e-12)\n            idx = rng.choice(len(operators), p=prob)\n            return operators[idx], idx\n\n        # helper: elite set\n        def get_elites(k_frac=0.15):\n            n = len(X_arch)\n            if n == 0:\n                return np.empty((0, self.dim))\n            k = max(3, int(np.ceil(k_frac * max(20, n))))\n            idxs = np.argsort(f_arch)[:min(k, n)]\n            return np.asarray([X_arch[i].copy() for i in idxs])\n\n        # main loop\n        stagn = 0\n        stagn_limit = max(10, int(0.02 * self.budget))\n        gen = 0\n\n        while evals < self.budget:\n            gen += 1\n\n            # recompute some statistics\n            Xe = get_elites()\n            Csh = shrink_cov(Xe) if Xe.size else np.eye(self.dim)\n            # diversity measure via eigenvalue entropy\n            try:\n                ev = np.linalg.eigvalsh(np.cov(np.asarray(X_arch).T) + 1e-12 * np.eye(self.dim)) if len(X_arch) > 3 else np.ones(self.dim)\n                ev = np.maximum(ev, 1e-16)\n                p = ev / np.sum(ev)\n                diversity = -np.sum(p * np.log(p + 1e-12))\n            except Exception:\n                diversity = 0.0\n\n            # expand/shrink trust slightly based on diversity\n            if diversity < 0.55:\n                trust_radius = min(self.max_trust, trust_radius * (1.02 + 0.002 * rng.rand()))\n            else:\n                trust_radius = max(self.min_trust, trust_radius * (0.998 - 0.001 * rng.rand()))\n\n            # prepare candidate batch size (1..pop)\n            n_batch = min(self.pop, max(1, self.budget - evals))\n            batch_X = []\n            batch_f = []\n            batch_ops = []\n            # fit surrogate once per generation\n            surrogate = fit_subspace_surrogate(U)\n\n            for bi in range(n_batch):\n                if evals >= self.budget:\n                    break\n                op, idx = choose_operator()\n                x_cand = None\n                f_c = None\n                predicted_impr = None\n\n                if op == 'subspace_opt' and surrogate is not None:\n                    zstar, fpred, params = surrogate\n                    x_prop = m + U.dot(zstar)\n                    x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop; predicted_impr = max(0.0, f_best - fpred)\n\n                elif op == 'dir_line':\n                    # pick a direction: prefer top principal axes or random if unavailable\n                    if U.shape[1] > 0 and rng.rand() < 0.75:\n                        j = rng.randint(0, U.shape[1])\n                        d = U[:, j]\n                    else:\n                        d = rng.randn(self.dim)\n                        d = d / (np.linalg.norm(d) + 1e-12)\n                    # bracket with three quick probes: center ±0.5*trust and ±1.0*trust (clamped)\n                    scales = [0.0, 0.5, -0.5, 1.0, -1.0]\n                    best_local = None; best_f = 1e99; best_x = None\n                    for s in scales:\n                        if evals >= self.budget: break\n                        x_try = m + s * trust_radius * d\n                        x_try = np.minimum(np.maximum(x_try, lb), ub)\n                        f_try = safe_eval(x_try)\n                        if f_try is None:\n                            break\n                        if f_try < best_f:\n                            best_f = f_try; best_x = x_try.copy()\n                    if best_x is not None:\n                        x_cand = best_x; f_c = best_f\n\n                elif op == 'coord_adapt':\n                    # pick coordinate with largest variance in archive, or random\n                    if len(X_arch) > 3:\n                        var = np.var(np.asarray(X_arch), axis=0)\n                        i = int(np.argmax(var))\n                    else:\n                        i = rng.randint(0, self.dim)\n                    # try positive and negative step scaled by per-dim lr and trust_radius\n                    step = per_dim_lr[i] * (trust_radius / (avg_span + 1e-12))\n                    signs = [1.0, -1.0] if rng.rand() < 0.9 else [-1.0, 1.0]\n                    improved = False\n                    for s in signs:\n                        if evals >= self.budget: break\n                        x_try = m.copy()\n                        x_try[i] = np.clip(x_try[i] + s * step, lb[i], ub[i])\n                        f_try = safe_eval(x_try)\n                        if f_try is None:\n                            break\n                        if f_try < f_best - 1e-12:\n                            per_dim_lr[i] = min(per_dim_lr[i] * 1.12, avg_span)\n                            improved = True\n                            x_cand = x_try; f_c = f_try; break\n                    if not improved and x_cand is None:\n                        # fallback small random perturb\n                        x_try = m + 0.6 * trust_radius * rng.randn(self.dim)\n                        x_try = np.minimum(np.maximum(x_try, lb), ub)\n                        f_try = safe_eval(x_try)\n                        if f_try is not None:\n                            x_cand = x_try; f_c = f_try\n                        per_dim_lr[i] = max(per_dim_lr[i] * 0.96, 1e-8)\n\n                elif op == 'fin_dir':\n                    # directional finite-difference gradient along a random combination of top U columns\n                    if U.shape[1] > 0 and rng.rand() < 0.8:\n                        kdir = min(2, U.shape[1])\n                        inds = rng.choice(U.shape[1], kdir, replace=False)\n                        d = np.sum(U[:, inds], axis=1)\n                    else:\n                        d = rng.randn(self.dim)\n                    d = d / (np.linalg.norm(d) + 1e-12)\n                    eps = 0.07 * trust_radius + 1e-8\n                    x_plus = np.minimum(np.maximum(m + eps * d, lb), ub)\n                    x_minus = np.minimum(np.maximum(m - eps * d, lb), ub)\n                    f_plus = safe_eval(x_plus)\n                    if f_plus is None:\n                        break\n                    f_minus = safe_eval(x_minus)\n                    if f_minus is None:\n                        break\n                    # estimate directional derivative g ≈ (f_plus - f_minus) / (2 eps)\n                    gdir = (f_plus - f_minus) / (2.0 * eps + 1e-12)\n                    # step in negative gradient direction with magnitude modulated by trust\n                    step_len = min(1.5 * trust_radius, max(0.3 * trust_radius, abs(gdir) * trust_radius))\n                    x_prop = np.minimum(np.maximum(m - np.sign(gdir) * step_len * d, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                elif op == 'cauchy_jump':\n                    # heavy-tailed global escape using multivariate Cauchy scaled by trust, centered at random elite or m\n                    if Xe.size and rng.rand() < 0.66:\n                        center = Xe[rng.randint(0, Xe.shape[0])]\n                    else:\n                        center = m\n                    z = rng.standard_cauchy(size=self.dim)\n                    # scale down extreme tails but keep heavy-tail behaviour\n                    clipv = np.percentile(np.abs(z), 92) + 1e-12\n                    z = z / clipv\n                    step = 3.5 * trust_radius * z\n                    x_prop = np.minimum(np.maximum(center + step, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                else:  # rand_walk\n                    # gaussian jitter around center, small amplitude when trust small\n                    sigma = 0.95 * trust_radius * (0.6 + 0.8 * rng.rand())\n                    x_prop = np.minimum(np.maximum(m + sigma * rng.randn(self.dim), lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                # if candidate was evaluated, record and update online components\n                if f_c is not None:\n                    batch_X.append(x_cand.copy())\n                    batch_f.append(f_c)\n                    batch_ops.append(op)\n\n                    # reward measure: improvement over previous center-best\n                    reward = max(0.0, (f_best - f_c) / (abs(f_best) + 1e-12))\n                    # multiplicative update of operator weight\n                    eta_w = 0.9 * 1.0 / max(1.0, np.sqrt(gen))\n                    w_op[idx] = w_op[idx] * (1.0 + eta_w * reward)\n                    # mild decay to keep exploration\n                    w_op *= op_decay\n                    w_op = np.maximum(w_op, 1e-6)\n\n                    # adapt U via Oja with centered vector z = x - m\n                    zc = x_cand - m\n                    U = oja_update(U, zc, lr=self.oja_lr * (0.5 + 0.5 * rng.rand()))\n\n                    # if improved global best, shrink trust (refine), else slowly increase\n                    if f_c < f_best - 1e-12:\n                        trust_radius = max(self.min_trust, trust_radius * 0.82)\n                        stagn = 0\n                        f_best = float(f_c); x_best = x_cand.copy()\n                    else:\n                        trust_radius = min(self.max_trust, trust_radius * 1.01)\n                        stagn += 1\n\n                else:\n                    # no evaluation (budget exhausted)\n                    break\n\n            # center aggregation step using Tsallis weights if we gathered batch items\n            if len(batch_X) > 0:\n                Xs = np.asarray(batch_X)\n                Fs = np.asarray(batch_f)\n                # temperature depends on trust and diversity\n                temp = max(1e-6, 0.9 * (trust_radius + 1e-12) * (1.0 + 0.5 * (0.7 - diversity)))\n                weights = tsallis_weights(Fs, q=self.q_tsallis, temp=temp)\n                x_mean = np.sum(weights[:, None] * Xs, axis=0)\n                # mirror-like update: move center toward weighted mean, scale by trust\n                lr_center = 0.45 if trust_radius < 0.5 * avg_span else 0.25\n                delta = x_mean - m\n                # clip big moves by dimension-aware max jump\n                max_jump = 4.0 * trust_radius * np.sqrt(max(1, self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > max_jump:\n                    delta = delta * (max_jump / (dn + 1e-12))\n                m = np.minimum(np.maximum(m + lr_center * delta, lb), ub)\n\n                # small stabilizing adjustments: if any improved in batch, slightly reduce trust; else increase\n                if np.any(Fs < f_best):\n                    trust_radius = max(self.min_trust, trust_radius * 0.86)\n                else:\n                    trust_radius = min(self.max_trust, trust_radius * 1.02)\n\n            # stagnation-driven targeted restart\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                # choose elite center or best, add anisotropic perturbation using elite cov\n                if Xe.size:\n                    center = Xe[rng.randint(0, Xe.shape[0])]\n                else:\n                    center = x_best\n                C = shrink_cov(Xe)\n                try:\n                    # robust sqrt via eigh\n                    w, V = np.linalg.eigh(C)\n                    w = np.maximum(w, 1e-12)\n                    S_sqrt = V.dot(np.diag(np.sqrt(w))).dot(V.T)\n                except Exception:\n                    S_sqrt = np.eye(self.dim)\n                jitter = max(0.05 * avg_span, 1.8 * trust_radius)\n                m = np.minimum(np.maximum(center + jitter * (0.7 * rng.randn(self.dim) + 0.3 * (S_sqrt.dot(rng.randn(self.dim)))), lb), ub)\n                trust_radius = min(self.max_trust, trust_radius * 1.6)\n                # small local reseed around best\n                reseed = min(6, self.budget - evals)\n                for _ in range(reseed):\n                    if evals >= self.budget: break\n                    x = np.minimum(np.maximum(x_best + 0.03 * avg_span * rng.randn(self.dim), lb), ub)\n                    f = safe_eval(x)\n                    if f is None:\n                        break\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DARTS scored 0.206 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "7085e0ca-6bc0-45d8-b32a-44eb8685728e", "operator": null, "metadata": {"aucs": [0.11449675259173575, 0.17228492774640147, 0.2626220581731564, 0.23094577710532405, 0.22003801791728272, 0.23788916709963215, 0.22353154119587115, 0.23898219569477952, 0.19241441051842412, 0.16236557726334722]}, "task_prompt": ""}
{"id": "04a78a21-c7fd-4881-b6b2-6fb841f2b659", "fitness": "-inf", "name": "AMGES", "description": "The algorithm is a hybrid, archive-driven heuristic that mixes global (DE-style and Gaussian-mixture) and local (PCA-line probes and subspace quadratic) search operators while always clipping samples to the problem bounds and using an initial random seeding schedule that scales with budget and population (pop=16, seed0 ~ budget/150). It adaptively learns a low-dimensional PCA subspace from the recent archive (pca_window=100, subspace_dim = max(1, dim//4) by default) and fits a ridge-regularized quadratic (ridge ~ 5e-3) to produce a Newton-like subspace minimizer z_star that is clipped by a trust_radius derived from init_radius*avg_span. Operator choice is driven by a softmax-style bandit with exponential reward decay (weight_decay=0.92) where rewards combine improvement magnitude and a diversity metric, and sampling is often informed by an elite covariance (Cholesky) to create anisotropic proposals. Trust radius and center updates are multiplicative and conservative (shrink 0.72 on improvement, slow growth 1+0.012*tanh(no_improve/50)), velocity is an EMA of steps (vel_alpha=0.18) to bias proposals, and a stagnation restart mixes best, elites and noise while resetting operator weights and expanding radius to reintroduce exploration.", "code": "import numpy as np\n\nclass AMGES:\n    \"\"\"\n    Adaptive Manifold-Guided Evolutionary Search (AMGES)\n\n    Key ideas (differences vs the provided MAMOS):\n    - Different initialization sizing and subspace dimensionality (default subspace_dim = max(1, dim//4)).\n    - Operator selection via a softmax-weighted bandit with exponential reward decay (not UCB).\n    - Subspace surrogate fit uses a slightly stronger ridge and different clipping for the minimizer.\n    - Trust radius adapts multiplicatively with an exponential schedule (shrinks faster on improvement,\n      grows slowly with stagnation) and uses a different scaling constant.\n    - Population uses DE-style mutation/crossover as a primary global operator (distinct from PSO-like).\n    - PCA-line probing performs a small discrete line search along the top eigenvector (multi-step).\n    - Momentum / velocity uses a simple EMA of steps with different coefficients.\n    - All constants / equations intentionally differ from the original algorithm.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop=16, subspace_dim=None, init_radius=0.12,\n                 pca_window=100, min_radius=1e-6, max_radius=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(seed)\n        self.pop = int(pop)\n        self.subspace_dim = subspace_dim if subspace_dim is not None else max(1, self.dim // 4)\n        self.init_radius = float(init_radius)\n        self.pca_window = int(pca_window)\n        self.min_radius = float(min_radius)\n        self.max_radius = float(max_radius)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # state\n        evals = 0\n        X_arch = []\n        f_arch = []\n\n        # initial random seeding (slightly different schedule)\n        seed0 = min(max(30, int(self.budget // 150)), self.pop * 8)\n        for _ in range(seed0):\n            if evals >= self.budget: break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            fx0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(fx0)\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            fx0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(fx0)\n\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        # center m and trust radius (different factor)\n        m = x_best.copy()\n        trust_radius = max(self.min_radius, self.init_radius * avg_span)\n\n        # velocity/momentum as EMA of steps (different constants)\n        velocity = np.zeros(self.dim)\n        vel_alpha = 0.18  # EMA factor for velocity\n\n        # operator set (distinct choices)\n        operators = ['subspace_min', 'de_mutation', 'pca_line', 'gaussian_mix', 'jitter']\n        # softmax bandit weights (start uniform)\n        op_weights = {op: 1.0 for op in operators}\n        weight_decay = 0.92  # decay for weights to forget old history\n        reward_scale = 1.0\n\n        # helpers\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch, x_best, f_best\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # trim archive to keep memory reasonable\n            max_len = max(3 * self.pca_window, 4 * self.pop)\n            if len(X_arch) > 6 * max_len:\n                excess = len(X_arch) - 6 * max_len\n                del X_arch[0:excess]\n                del f_arch[0:excess]\n            if fx < f_best:\n                x_best = x.copy(); f_best = float(fx)\n            return fx\n\n        def get_elites(k_frac=0.18):\n            n = len(X_arch)\n            if n == 0:\n                return np.empty((0, self.dim))\n            k = max(3, int(np.ceil(k_frac * max(20, n))))\n            idxs = np.argsort(f_arch)[:min(k, n)]\n            return np.asarray([X_arch[i].copy() for i in idxs])\n\n        def learn_pca(r=self.subspace_dim):\n            if len(X_arch) < (r + 3):\n                return np.zeros((self.dim, 0)), np.zeros(self.dim)\n            K = min(len(X_arch), self.pca_window)\n            Xr = np.asarray(X_arch[-K:])\n            M = Xr.mean(axis=0)\n            S = Xr - M\n            try:\n                U, s, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(r, Vt.shape[0])\n                if r_eff <= 0:\n                    return np.zeros((self.dim, 0)), M\n                B = Vt[:r_eff].T.copy()\n                return B, M\n            except Exception:\n                return np.zeros((self.dim, 0)), Xr.mean(axis=0)\n\n        def fit_subspace_quadratic(B, M, samples=None, ridge=1e-3):\n            \"\"\"Fit c + g^T z + 0.5 * diag(h) z^2 in subspace (z = B^T (x - m)).\n               Return z_star and predicted f if fit possible.\"\"\"\n            r = B.shape[1]\n            if r == 0 or len(X_arch) < (r + 6):\n                return None, None\n            K = min(len(X_arch), samples if samples is not None else min(120, 12 + 8 * r))\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(B)  # n x r\n            n = Z.shape[0]\n            # design matrix [1, z, z^2]\n            Phi = np.ones((n, 1 + r + r))\n            Phi[:, 1:1 + r] = Z\n            Phi[:, 1 + r:1 + r + r] = Z ** 2\n            try:\n                A = Phi.T.dot(Phi) + ridge * np.eye(Phi.shape[1])\n                b = Phi.T.dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1 + r]\n                h = coeff[1 + r:1 + r + r]\n                # ensure moderate positive curvature\n                h = np.where(h < 1e-6, 1e-6, h)\n                # Newton-like minimizer\n                z_star = - g / (h + 1e-12)\n                # clip z by trust radius with a different factor\n                max_norm = 1.2 * trust_radius * np.sqrt(max(1, r)) / (np.linalg.norm(B, ord=2) + 1e-12)\n                znorm = np.linalg.norm(z_star)\n                if znorm > max_norm:\n                    z_star = z_star * (max_norm / (znorm + 1e-12))\n                f_pred = float(c + g.dot(z_star) + 0.5 * np.sum(h * (z_star ** 2)))\n                return z_star, f_pred\n            except Exception:\n                return None, None\n\n        def chol_cov(Xe):\n            if Xe.size == 0:\n                return np.eye(self.dim)\n            C = np.cov(Xe.T) + 1e-8 * np.eye(self.dim)\n            try:\n                L = np.linalg.cholesky(C)\n                return L\n            except Exception:\n                # fallback via eigh\n                w, V = np.linalg.eigh(C)\n                w = np.maximum(w, 1e-12)\n                return V.dot(np.diag(np.sqrt(w)))\n\n        # initial PCA/subspace\n        B, M_pca = learn_pca(self.subspace_dim)\n\n        # main loop\n        it = 0\n        no_improve = 0\n        stagn_limit = max(12, int(0.03 * self.budget))\n\n        # helper operator selection: softmax over op_weights\n        def select_op():\n            vals = np.array([op_weights[op] for op in operators], dtype=float)\n            # stabilize\n            vals = vals - vals.max()\n            probs = np.exp(vals / (0.4 + 0.04 * rng.rand()))  # small randomization in temperature\n            probs = probs / (probs.sum() + 1e-12)\n            return rng.choice(operators, p=probs)\n\n        while evals < self.budget:\n            it += 1\n            # periodically relearn PCA\n            if it % max(1, int(self.pca_window // 6)) == 0:\n                B, M_pca = learn_pca(self.subspace_dim)\n\n            Xe = get_elites()\n            L_e = chol_cov(Xe)  # for mixture sampling\n\n            # compute a simple diversity measure (trace-normalized)\n            diversity = 0.0\n            if len(X_arch) >= 4:\n                try:\n                    Cfull = np.cov(np.asarray(X_arch).T) + 1e-12 * np.eye(self.dim)\n                    ev = np.linalg.eigvalsh(Cfull)\n                    ev = np.maximum(ev, 1e-16)\n                    diversity = np.sum(ev) / (np.max(ev) + 1e-12)  # different metric\n                except Exception:\n                    diversity = 0.0\n\n            # trust radius adaptation (different multiplicative rule)\n            # if recent no improvement stretches, slowly grow; if improvement, shrink quickly\n            if no_improve == 0:\n                # an improvement was just found previously: shrink\n                trust_radius = max(self.min_radius, trust_radius * 0.72)\n            else:\n                # slow growth with diminishing returns\n                trust_radius = min(self.max_radius, trust_radius * (1.0 + 0.012 * np.tanh(no_improve / 50.0)))\n\n            # choose operator\n            op = select_op()\n            x_cand = None\n            f_cand = None\n\n            if op == 'subspace_min':\n                # try subspace quadratic minimizer\n                z_star, f_pred = fit_subspace_quadratic(B, M_pca, samples= max(20, 8 * B.shape[1]), ridge=5e-3)\n                if z_star is not None:\n                    x_prop = np.minimum(np.maximum(m + B.dot(z_star), lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n                else:\n                    # fallback: take anisotropic gaussian around m using elite cholesky\n                    z = rng.randn(self.dim)\n                    step = 1.1 * trust_radius * (L_e.dot(z))\n                    x_prop = np.minimum(np.maximum(m + step, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n\n            elif op == 'de_mutation':\n                # differential-evolution style mutation among elites or archive\n                Ee = Xe if Xe.shape[0] >= 6 else np.asarray(X_arch)\n                nE = Ee.shape[0] if Ee.size else max(4, len(X_arch))\n                # pick three distinct indices from available pool\n                pool = Ee if Ee.size else np.asarray(X_arch[-min(len(X_arch), 40):])\n                if pool.size == 0:\n                    base = m\n                else:\n                    base = pool[rng.randint(0, pool.shape[0])]\n                # choose two difference vectors\n                if pool.shape[0] >= 3:\n                    idx = rng.choice(np.arange(pool.shape[0]), size=3, replace=False)\n                    a, b, c = pool[idx[0]], pool[idx[1]], pool[idx[2]]\n                else:\n                    # random perturbations\n                    a = base\n                    b = m + 0.1 * avg_span * rng.randn(self.dim)\n                    c = m + 0.1 * avg_span * rng.randn(self.dim)\n                F = rng.uniform(0.55, 0.9)\n                mutant = a + F * (b - c)\n                # binomial crossover\n                CR = 0.2\n                mask = rng.rand(self.dim) < CR\n                if not mask.any():\n                    mask[rng.randint(0, self.dim)] = True\n                trial = np.where(mask, mutant, m)\n                # scale trial step to trust_radius\n                step_norm = np.linalg.norm(trial - m)\n                if step_norm > 1e-12:\n                    trial = m + (trial - m) * (trust_radius / (step_norm + 1e-12)) * rng.uniform(0.6, 1.4)\n                trial = np.minimum(np.maximum(trial, lb), ub)\n                f_trial = safe_eval(trial)\n                if f_trial is not None:\n                    x_cand = trial; f_cand = f_trial\n\n            elif op == 'pca_line':\n                # probe along top PCA direction: evaluate several points along +/- v\n                if B.shape[1] > 0:\n                    v = B[:, 0]\n                else:\n                    # fallback to top eigenvector of archive covariance\n                    if len(X_arch) >= 4:\n                        Cfull = np.cov(np.asarray(X_arch).T) + 1e-12 * np.eye(self.dim)\n                        w, V = np.linalg.eigh(Cfull)\n                        v = V[:, -1]\n                    else:\n                        v = rng.randn(self.dim)\n                        v = v / (np.linalg.norm(v) + 1e-12)\n                alphas = np.linspace(-1.6, 1.6, 7) * trust_radius * rng.uniform(0.8, 1.2)\n                best_local_x = None\n                best_local_f = 1e99\n                for a in alphas:\n                    if evals >= self.budget: break\n                    trial = np.minimum(np.maximum(m + a * v, lb), ub)\n                    f_trial = safe_eval(trial)\n                    if f_trial is None:\n                        break\n                    if f_trial < best_local_f:\n                        best_local_f = f_trial; best_local_x = trial.copy()\n                if best_local_x is not None:\n                    x_cand = best_local_x; f_cand = best_local_f\n\n            elif op == 'gaussian_mix':\n                # mixture of global isotropic gaussian and elite-informed gaussian\n                if Xe.size and rng.rand() < 0.75:\n                    z = rng.randn(self.dim)\n                    # small scale factor to keep sampling local-ish\n                    step = trust_radius * (L_e.dot(z)) * rng.uniform(0.6, 1.6)\n                    center = Xe[rng.randint(0, Xe.shape[0])]\n                else:\n                    # global\n                    step = 1.8 * trust_radius * rng.randn(self.dim)\n                    center = m\n                trial = np.minimum(np.maximum(center + step + 0.12 * velocity, lb), ub)\n                f_trial = safe_eval(trial)\n                if f_trial is not None:\n                    x_cand = trial; f_cand = f_trial\n\n            else:  # jitter\n                step = 0.9 * trust_radius * rng.randn(self.dim)\n                trial = np.minimum(np.maximum(m + step + 0.08 * velocity, lb), ub)\n                f_trial = safe_eval(trial)\n                if f_trial is not None:\n                    x_cand = trial; f_cand = f_trial\n\n            # if budget exhausted or no candidate produced, break\n            if f_cand is None:\n                break\n\n            # reward calculation (improvement over center or global best)\n            prev_best = f_best\n            improved = (f_cand < prev_best - 1e-12)\n            improvement_amount = max(0.0, prev_best - f_cand)\n            # soft reward proportional to improvement and diversity (promote exploration when diverse)\n            reward = reward_scale * (improvement_amount + 1e-4) * (1.0 + 0.2 * (diversity / (1.0 + diversity)))\n            # update operator weight (softmax-bandit style with exponential decay)\n            op_weights[op] = weight_decay * op_weights[op] + (1.0 - weight_decay) * reward\n\n            # update velocity (EMA of steps)\n            stepvec = x_cand - m\n            velocity = (1.0 - vel_alpha) * velocity + vel_alpha * stepvec\n\n            # update center m with a conservative move towards improvements (different equation)\n            # Use a trust-aware learning rate\n            lr = 0.35 if trust_radius < 0.4 * avg_span else 0.18\n            # Accept candidate into center if it is better than weighted average of recent samples,\n            # otherwise make a partial drift towards it\n            if f_cand < f_best:\n                # strong move towards found improvement\n                m = np.minimum(np.maximum(0.6 * m + 0.4 * x_cand, lb), ub)\n            else:\n                # partial drift scaled by trust and candidate quality\n                qual = 1.0 / (1.0 + (f_cand - f_best))\n                drift = lr * qual * (x_cand - m)\n                # clip drift by trust radius\n                dnorm = np.linalg.norm(drift)\n                maxd = 3.0 * trust_radius\n                if dnorm > maxd:\n                    drift = drift * (maxd / (dnorm + 1e-12))\n                m = np.minimum(np.maximum(m + drift, lb), ub)\n\n            # update best and stagnation counters\n            if f_cand < f_best - 1e-12:\n                f_best = float(f_cand)\n                x_best = x_cand.copy()\n                no_improve = 0\n            else:\n                no_improve += 1\n\n            # occasional subspace random rotation to avoid freezing (different probability)\n            if B.shape[1] > 0 and rng.rand() < 0.03:\n                try:\n                    r = B.shape[1]\n                    R = 0.04 * rng.randn(r, r)\n                    Qr, _ = np.linalg.qr(np.eye(r) + R)\n                    B = B.dot(Qr)\n                except Exception:\n                    pass\n\n            # stagnation restart policy (distinct mixing)\n            if no_improve >= stagn_limit and evals < self.budget:\n                no_improve = 0\n                # choose a new center as mixture of best and a random elite/global noise\n                if Xe.size:\n                    choice = Xe[rng.randint(0, Xe.shape[0])]\n                    noise = 0.9 * trust_radius * rng.randn(self.dim) + 0.4 * (L_e.dot(rng.randn(self.dim)))\n                    m = np.minimum(np.maximum(0.6 * x_best + 0.4 * (choice + noise), lb), ub)\n                else:\n                    m = np.minimum(np.maximum(x_best + 1.2 * trust_radius * rng.randn(self.dim), lb), ub)\n                # reset operator weights slightly to reintroduce exploration\n                for opn in op_weights:\n                    op_weights[opn] = max(0.1, op_weights[opn] * 0.6 + 0.4)\n                trust_radius = min(self.max_radius, trust_radius * 1.6)\n                velocity = np.zeros(self.dim)\n                # take a few refinement samples around best immediately\n                reseed = min(6, self.budget - evals)\n                for _ in range(reseed):\n                    if evals >= self.budget: break\n                    x = np.minimum(np.maximum(x_best + 0.03 * avg_span * rng.randn(self.dim), lb), ub)\n                    fx = safe_eval(x)\n                    if fx is None:\n                        break\n                    if fx < f_best:\n                        f_best = fx; x_best = x.copy()\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "Evaluation timed out after 600 seconds.", "error": "Evaluation timed out after 600 seconds.", "parent_ids": "7085e0ca-6bc0-45d8-b32a-44eb8685728e", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "8f428211-4a87-4434-8e0b-45977fc61bac", "fitness": 0.2679369974849279, "name": "AURORA", "description": "AURORA maintains an evaluated archive and two centers (incumbent x_best and an exploratory center m), seeds the search with uniform samples and keeps elites for robust statistics. It learns low-dimensional PCA subspaces from recent samples and fits lightweight locally-weighted quadratic models (diagonal Hessian) to propose model_min moves, complemented by a portfolio of operators — axis annealing probes, anisotropic covariance mutations, small jitter, and heavy-tailed “hallucinate” jumps — to trade off local refinement and global exploration. Operator choice is driven by a Thompson-like Beta sampling of empirical success/trial counts, while an EWMA covariance estimate (cov_est → cov_sqrt), adaptive per-dimension log-scales, and a multiplicative global_scale steer anisotropic sampling and annealing (successes shrink scale, stagnation inflates it). Batches of candidates update the exploratory center by an uncertainty/novelty-weighted average, and persistent stagnation triggers orthogonal restarts and scale annealing to escape local traps.", "code": "import numpy as np\n\nclass AURORA:\n    \"\"\"\n    AURORA: Adaptive Uncertainty-Reduction & Orthogonal Regression Annealing\n\n    Main ideas:\n    - Maintain an evaluated archive and two centers: incumbent x_best and an exploratory center m.\n    - Fit lightweight locally-weighted quadratic models in low-dimensional PCA subspaces (orthogonal regression).\n    - Use an operator portfolio (model minimizer, axis annealing line-probe, covariance mutation, jitter, heavy-tail hallucination).\n    - Select operators via Thompson-like sampling from Beta distributions built from empirical success/trial counts.\n    - Maintain an adaptive covariance (EWMA) to bias anisotropic sampling and an uncertainty score (residual variance + distance) to guide exploration.\n    - Orthogonal restarts and annealing of noise scales when stagnation occurs.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=12, subspace_dim=None, init_scale=0.18,\n                 pca_window=80, cov_ewma=0.02, stagn_factor=0.02,\n                 min_scale=1e-8, max_scale=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.subspace_dim = subspace_dim if subspace_dim is not None else max(1, self.dim // 6)\n        self.init_scale = float(init_scale)\n        self.pca_window = int(pca_window)\n        self.cov_ewma = float(cov_ewma)\n        self.min_scale = float(min_scale)\n        self.max_scale = float(max_scale)\n        # internal results\n        self.f_opt = np.inf\n        self.x_opt = None\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling (allow scalar or vector)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # internal state\n        evals = 0\n        X_arch = []\n        f_arch = []\n\n        # safe eval utility\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch, x_best, f_best\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # trim archive occasionally\n            max_len = max(200, 5 * self.pca_window)\n            if len(X_arch) > max_len:\n                excess = len(X_arch) - max_len\n                del X_arch[0:excess]; del f_arch[0:excess]\n            # update best\n            if fx < f_best:\n                f_best = fx; x_best = x.copy()\n            return fx\n\n        # initial seed\n        seed0 = min(max(20, int(self.budget // 200)), self.pop * 8)\n        for _ in range(seed0):\n            if evals >= self.budget: break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            fx0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(fx0)\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            fx0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(fx0)\n\n        best_idx = int(np.argmin(f_arch))\n        x_best = X_arch[best_idx].copy(); f_best = float(f_arch[best_idx])\n\n        # exploratory center\n        m = x_best.copy()\n        # adaptive global scale (like trust radius but multiplicative)\n        global_scale = max(self.min_scale, self.init_scale * avg_span)\n        # covariance estimate for anisotropic sampling (EWMA of sample covariances)\n        cov_est = np.eye(self.dim) * ((global_scale ** 2) + 1e-9)\n        cov_sqrt = np.linalg.cholesky(cov_est + 1e-9 * np.eye(self.dim))\n\n        # adaptive per-dimension log-scale (for annealing steps)\n        log_scale = np.log(np.full(self.dim, global_scale + 1e-12))\n\n        # operator portfolio and Beta-thompson counters (start with mild priors)\n        operators = ['model_min', 'axis_anneal', 'cov_mutation', 'jitter', 'hallucinate']\n        op_counts = {op: {'succ': 1, 'trial': 2} for op in operators}  # small prior to allow Beta sampling\n\n        # stagnation control\n        stagn = 0\n        stagn_limit = max(10, int(self.stagn_factor_to_count(stagn_factor=0.02)))\n        gen = 0\n\n        # helper: compute orthonormal basis (PCA) from recent window\n        def learn_basis(k=self.subspace_dim):\n            if len(X_arch) < (k + 3):\n                return np.zeros((self.dim, 0)), np.zeros(self.dim)\n            K = min(len(X_arch), self.pca_window)\n            Xr = np.asarray(X_arch[-K:])\n            M = Xr.mean(axis=0)\n            S = Xr - M\n            try:\n                U, s, Vt = np.linalg.svd(S, full_matrices=False)\n                r = min(k, Vt.shape[0])\n                if r <= 0:\n                    return np.zeros((self.dim, 0)), M\n                B = Vt[:r].T.copy()  # dim x r\n                return B, M\n            except Exception:\n                return np.zeros((self.dim, 0)), Xr.mean(axis=0)\n\n        # helper: weighted local quadratic fit in subspace B\n        # model: f ≈ c + g^T z + 0.5 * z^T H z  (we enforce diagonal H for robustness)\n        def fit_local_weighted_quad(B, center, max_samples= min(120, max(12, self.subspace_dim * 12)), reg=1e-6):\n            r = B.shape[1]\n            if r == 0 or len(X_arch) < (r + 6):\n                return None\n            K = min(len(X_arch), max_samples)\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - center).dot(B)  # n x r\n            # distances in full space for weighting\n            d2 = np.sum((Xr - center) ** 2, axis=1)\n            # weight: exponential kernel with adaptive length scale based on global_scale\n            lam = max(1e-8, (global_scale ** 2) * (1.0 + 0.5 * r))\n            w = np.exp(-d2 / (2.0 * lam))\n            W = np.sqrt(w)\n            # build design with columns [1, z_i (r), z_i^2 (r)]\n            n = Z.shape[0]\n            Phi = np.ones((n, 1 + r + r))\n            Phi[:, 1:1 + r] = Z\n            Phi[:, 1 + r:1 + r + r] = Z ** 2\n            # weighted least squares\n            A = (W[:, None] * Phi).T.dot(W[:, None] * Phi) + reg * np.eye(Phi.shape[1])\n            b = (W[:, None] * Phi).T.dot(W * Fr)\n            try:\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1 + r]\n                h_diag = coeff[1 + r:1 + r + r]\n                # ensure positive curvature (regularize)\n                h_diag = np.where(h_diag < 1e-8, 1e-8, h_diag)\n                # minimizer in z: - inv(H_diag) * g\n                z_star = - g / (h_diag + 1e-12)\n                # clip z_star magnitude relative to scale\n                max_z = (2.5 * global_scale / (np.linalg.norm(B, ord=2) + 1e-12)) * np.sqrt(max(1, r))\n                znorm = np.linalg.norm(z_star)\n                if znorm > max_z:\n                    z_star = z_star * (max_z / (znorm + 1e-12))\n                # predicted value\n                fpred = float(c + g.dot(z_star) + 0.5 * np.sum(h_diag * (z_star ** 2)))\n                return z_star, fpred, (g, h_diag, c)\n            except Exception:\n                return None\n\n        # helper: robust sqrt-cov from elites\n        def robust_sqrt_cov(Xe):\n            if Xe.size == 0:\n                return np.eye(self.dim)\n            C = np.cov(Xe.T) + 1e-9 * np.eye(self.dim)\n            try:\n                w, V = np.linalg.eigh(C)\n                w = np.maximum(w, 1e-12)\n                return V.dot(np.diag(np.sqrt(w))).dot(V.T)\n            except Exception:\n                U, s, Vt = np.linalg.svd(C)\n                return U.dot(np.diag(np.sqrt(s))).dot(Vt)\n\n        # helper: sample operator via Beta-Thompson-like draw\n        def select_operator_thompson():\n            draws = {}\n            for op in operators:\n                succ = op_counts[op]['succ']\n                trial = op_counts[op]['trial']\n                # Beta(succ, trial - succ) sampling; ensure proper positivity\n                a = max(0.5, succ)\n                b = max(0.5, trial - succ)\n                draws[op] = rng.beta(a, b)\n            # with small epsilon do random operator to maintain exploration\n            if rng.rand() < 0.06:\n                return rng.choice(operators)\n            return max(draws.items(), key=lambda x: x[1])[0]\n\n        # helper: convert log_scale to actual scale diag\n        def get_scale_diag():\n            s = np.exp(log_scale)\n            s = np.clip(s, self.min_scale, self.max_scale)\n            return s\n\n        # initial elites and cov sqrt\n        def get_elites(k_frac=0.15):\n            n = len(X_arch)\n            if n == 0:\n                return np.empty((0, self.dim))\n            k = max(3, int(np.ceil(k_frac * max(20, n))))\n            idxs = np.argsort(f_arch)[:min(k, n)]\n            return np.asarray([X_arch[i].copy() for i in idxs])\n\n        # start main loop\n        while evals < self.budget:\n            gen += 1\n\n            # periodically re-learn basis\n            if gen % max(1, int(self.pca_window // 6)) == 0:\n                B, B_mean = learn_basis(self.subspace_dim)\n            else:\n                try:\n                    B\n                except NameError:\n                    B, B_mean = learn_basis(self.subspace_dim)\n\n            Xe = get_elites()\n            S_sqrt = robust_sqrt_cov(Xe) if Xe.size else np.eye(self.dim)\n\n            # compute local residual variance as uncertainty proxy\n            unc = 0.0\n            if len(X_arch) > 6:\n                # residuals to a local linear approx around m\n                Xr = np.asarray(X_arch[-min(len(X_arch), self.pca_window):])\n                Fr = np.asarray(f_arch[-min(len(X_arch), self.pca_window):])\n                # simple linear regression in top principal direction\n                try:\n                    _, Vt = np.linalg.eig(np.cov(Xr.T))\n                    pdir = Vt[:, -1] if Vt.shape[0] == self.dim else np.ones(self.dim)\n                    proj = (Xr - m).dot(pdir)\n                    A = np.vstack([np.ones_like(proj), proj]).T\n                    beta, *_ = np.linalg.lstsq(A, Fr, rcond=None)\n                    res = Fr - A.dot(beta)\n                    unc = float(np.mean(res ** 2))\n                except Exception:\n                    unc = 0.0\n\n            # diversity measure (entropy of eigenvalues)\n            diversity = 0.0\n            if len(X_arch) >= 4:\n                try:\n                    Cfull = np.cov(np.asarray(X_arch).T) + 1e-12 * np.eye(self.dim)\n                    ev = np.linalg.eigvalsh(Cfull)\n                    ev = np.maximum(ev, 1e-16)\n                    p = ev / np.sum(ev)\n                    diversity = -np.sum(p * np.log(p + 1e-12))\n                except Exception:\n                    diversity = 0.0\n\n            # adapt global_scale: increase when low uncertainty & low diversity (escape), shrink on improvements\n            if unc < 1e-6:\n                global_scale = min(self.max_scale, global_scale * (1.02 if diversity < 0.7 else 1.01))\n            else:\n                global_scale = max(self.min_scale, global_scale * (0.995 if diversity > 0.9 else 0.999))\n\n            # rebuild cov_sqrt from cov_est\n            try:\n                cov_sqrt = np.linalg.cholesky(cov_est + 1e-9 * np.eye(self.dim))\n            except Exception:\n                cov_sqrt = robust_sqrt_cov(np.asarray(X_arch) if len(X_arch) else np.eye(self.dim))\n\n            # prepare a batch of candidate generation attempts (bounded by remaining budget)\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            batch_X = []\n            batch_f = []\n            batch_ops = []\n\n            for ci in range(n_cand):\n                if evals >= self.budget:\n                    break\n                op = select_operator_thompson()\n                x_cand = None\n                f_cand = None\n\n                # ---------- operator: model minimizer in local PCA subspace ----------\n                if op == 'model_min':\n                    res = fit_local_weighted_quad(B, m)\n                    if res is not None:\n                        z_star, f_pred, _ = res\n                        x_prop = np.minimum(np.maximum(m + B.dot(z_star), lb), ub)\n                        f_prop = safe_eval(x_prop)\n                        if f_prop is None:\n                            break\n                        x_cand = x_prop; f_cand = f_prop\n                    else:\n                        # fallback to anisotropic cov mutation\n                        noise = cov_sqrt.dot(rng.randn(self.dim)) * (1.1 * global_scale)\n                        x_prop = np.minimum(np.maximum(m + noise, lb), ub)\n                        f_prop = safe_eval(x_prop)\n                        if f_prop is None:\n                            break\n                        x_cand = x_prop; f_cand = f_prop\n\n                # ---------- operator: axis annealing (1D probes along orthogonal directions) ----------\n                elif op == 'axis_anneal':\n                    # choose a direction from basis if available, otherwise random orthonormal\n                    if B.shape[1] > 0 and rng.rand() < 0.7:\n                        d = B[:, rng.randint(0, B.shape[1])]\n                    else:\n                        v = rng.randn(self.dim)\n                        d = v / (np.linalg.norm(v) + 1e-12)\n                    step0 = np.mean(np.exp(log_scale)) * (1.2 + 0.8 * rng.rand())\n                    # probe + and - directions (two evals)\n                    x_plus = np.minimum(np.maximum(m + step0 * d, lb), ub)\n                    f_plus = safe_eval(x_plus)\n                    if f_plus is None:\n                        break\n                    x_minus = np.minimum(np.maximum(m - step0 * d, lb), ub)\n                    f_minus = safe_eval(x_minus)\n                    if f_minus is None:\n                        break\n                    # choose best of the probe; optionally do small backtrack if improved\n                    if f_plus < f_minus and f_plus < f_best:\n                        # backtrack further along same sign once\n                        x2 = np.minimum(np.maximum(m + 1.8 * step0 * d, lb), ub)\n                        f2 = safe_eval(x2)\n                        if f2 is None:\n                            break\n                        if f2 < f_plus:\n                            x_cand = x2; f_cand = f2\n                        else:\n                            x_cand = x_plus; f_cand = f_plus\n                    elif f_minus < f_plus and f_minus < f_best:\n                        x2 = np.minimum(np.maximum(m - 1.8 * step0 * d, lb), ub)\n                        f2 = safe_eval(x2)\n                        if f2 is None:\n                            break\n                        if f2 < f_minus:\n                            x_cand = x2; f_cand = f2\n                        else:\n                            x_cand = x_minus; f_cand = f_minus\n                    else:\n                        # pick the better probe (no improvement maybe)\n                        if f_plus <= f_minus:\n                            x_cand = x_plus; f_cand = f_plus\n                        else:\n                            x_cand = x_minus; f_cand = f_minus\n\n                # ---------- operator: covariance mutation (anisotropic Gaussian) ----------\n                elif op == 'cov_mutation':\n                    scale_fac = (1.0 + 0.6 * rng.rand()) * global_scale\n                    noise = cov_sqrt.dot(rng.randn(self.dim)) * scale_fac\n                    x_prop = np.minimum(np.maximum(m + noise, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is None:\n                        break\n                    x_cand = x_prop; f_cand = f_prop\n\n                # ---------- operator: jitter (small Gaussian) ----------\n                elif op == 'jitter':\n                    sd = np.mean(np.exp(log_scale)) * 0.45\n                    noise = sd * rng.randn(self.dim)\n                    x_prop = np.minimum(np.maximum(m + noise, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is None:\n                        break\n                    x_cand = x_prop; f_cand = f_prop\n\n                # ---------- operator: hallucinate (heavy-tailed exploration) ----------\n                else:  # 'hallucinate'\n                    # student-t like heavy tails via scaled normal / chi\n                    v = max(2.5, 2.0 + rng.rand() * 6.0)\n                    g = rng.randn(self.dim)\n                    chi = np.sqrt(rng.chisquare(df=v) + 1e-12)\n                    step = (g / chi) * (3.0 * global_scale * (1.0 + 0.5 * rng.rand()))\n                    # sometimes originate from a random elite\n                    if Xe.size and rng.rand() < 0.5:\n                        origin = Xe[rng.randint(0, Xe.shape[0])]\n                    else:\n                        origin = m\n                    x_prop = np.minimum(np.maximum(origin + step, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is None:\n                        break\n                    x_cand = x_prop; f_cand = f_prop\n\n                # if budget exhausted or no candidate obtained, break\n                if f_cand is None:\n                    break\n\n                # record\n                batch_X.append(np.asarray(x_cand, dtype=float))\n                batch_f.append(float(f_cand))\n                batch_ops.append(op)\n\n                # update op_counts\n                improved = (f_cand < f_best)\n                op_counts[op]['trial'] += 1\n                if improved:\n                    op_counts[op]['succ'] += 1\n                    # shrink global_scale on success to refine search\n                    global_scale = max(self.min_scale, global_scale * 0.82)\n                else:\n                    # small decay to success to penalize repeated failures\n                    op_counts[op]['succ'] = max(0.1, op_counts[op]['succ'] * 0.999)\n\n                # update cov_est via EWMA using neighborhood around candidate if candidate is good (elite)\n                if f_cand <= np.percentile(f_arch, 50) if len(f_arch) > 8 else (f_cand < f_best + 1e-6):\n                    # incremental covariance update centered at candidate\n                    x_vec = (x_cand - m).reshape(self.dim, 1)\n                    cov_inc = (x_vec.dot(x_vec.T))\n                    cov_est = (1.0 - self.cov_ewma) * cov_est + self.cov_ewma * cov_inc + 1e-9 * np.eye(self.dim)\n\n                # metropolis-like update of log_scale: success increases scale for dimensions where step had magnitude\n                step_rel = np.abs(x_cand - m) + 1e-12\n                adapt = 0.06 * (0.5 if improved else 0.18)\n                log_scale += adapt * ((step_rel / (np.mean(step_rel) + 1e-12)) - 1.0) * (0.5 + rng.rand() * 0.5)\n                # clip\n                log_scale = np.clip(log_scale, np.log(self.min_scale + 1e-12), np.log(self.max_scale + 1e-12))\n\n                # update stagnation / best\n                if f_cand + 1e-12 < f_best:\n                    f_best = float(f_cand); x_best = x_cand.copy(); stagn = 0\n                else:\n                    stagn += 1\n\n                # small random orthonormal rotation of basis occasionally\n                if B.shape[1] > 0 and rng.rand() < 0.03:\n                    try:\n                        r = B.shape[1]\n                        R = rng.randn(r, r) * 0.04\n                        Qr, _ = np.linalg.qr(np.eye(r) + R)\n                        B = B.dot(Qr)\n                    except Exception:\n                        pass\n\n            # aggregate batch to update center m via uncertainty-weighted average\n            if len(batch_X) > 0:\n                Xs = np.asarray(batch_X)\n                Fs = np.asarray(batch_f)\n                # uncertainty weight: combination of residual uncertainty and distance-based novelty\n                dists = np.linalg.norm(Xs - m[None, :], axis=1)\n                novelty = dists / (np.mean(dists) + 1e-12)\n                # lower function values get higher weight; but we also encourage novel points with some temperature\n                temp = max(1e-6, 0.8 * (global_scale + 1e-12) * (1.0 + 0.5 * (0.8 - diversity)))\n                f_shift = Fs - (np.min(Fs) if len(Fs) else f_best)\n                w = np.exp(-(f_shift) / (temp + 1e-12)) * (1.0 + 0.5 * novelty)\n                w = w / (np.sum(w) + 1e-12)\n                x_mean = np.sum(w[:, None] * Xs, axis=0)\n                # learn rate depends on scale and diversity: larger scale = smaller immediate move\n                lr = 0.5 if global_scale < 0.6 * avg_span else 0.18\n                delta = x_mean - m\n                # clip max jump based on scale\n                max_jump = 5.0 * global_scale * np.sqrt(max(1, self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > max_jump:\n                    delta = delta * (max_jump / (dn + 1e-12))\n                m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n\n                # when the batch contains improvements, contract; else slowly expand\n                if np.any(Fs < f_best):\n                    global_scale = max(self.min_scale, global_scale * 0.85)\n                else:\n                    global_scale = min(self.max_scale, global_scale * 1.012)\n\n            # stagnation triggered orthogonal restart\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                # create orthonormal random rotation and sample around best with increased scale\n                Q = np.eye(self.dim)\n                R = rng.randn(self.dim, self.dim) * 0.08\n                try:\n                    Q, _ = np.linalg.qr(Q + R)\n                except Exception:\n                    pass\n                # choose a small subspace to sample\n                r = max(1, min(self.subspace_dim, int(max(1, self.dim // 8))))\n                sub = Q[:, :r]\n                # generate multiple restart samples\n                n_restart = min(6, self.budget - evals)\n                for _ in range(n_restart):\n                    if evals >= self.budget:\n                        break\n                    z = rng.randn(r)\n                    step = 2.5 * global_scale * (sub.dot(z))\n                    x = np.minimum(np.maximum(x_best + step + 0.5 * (S_sqrt.dot(rng.randn(self.dim))), lb), ub)\n                    fx = safe_eval(x)\n                    if fx is None:\n                        break\n                    if fx < f_best:\n                        f_best = float(fx); x_best = x.copy()\n                # increase exploration scale moderately\n                global_scale = min(self.max_scale, global_scale * 1.9)\n                # slightly reset log_scale\n                log_scale = np.log(np.clip(np.exp(log_scale) * 0.7 + 1e-12, self.min_scale, self.max_scale))\n\n            # update cov_sqrt for next generation (robust)\n            try:\n                cov_sqrt = np.linalg.cholesky(cov_est + 1e-9 * np.eye(self.dim))\n            except Exception:\n                cov_sqrt = robust_sqrt_cov(np.asarray(X_arch) if len(X_arch) else np.eye(self.dim))\n\n        # final store and return best\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt\n\n    # helper to map stagnation factor to counts relative to typical budgets (used only in init)\n    def stagn_factor_to_count(self, stagn_factor=0.02):\n        return max(10, int(self.budget * stagn_factor))", "configspace": "", "generation": 0, "feedback": "The algorithm AURORA scored 0.268 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "7085e0ca-6bc0-45d8-b32a-44eb8685728e", "operator": null, "metadata": {"aucs": [0.1724258748358899, 0.32269699740889335, 0.26722469879373933, 0.3611222574527926, 0.24438710853357826, 0.33921045968903474, 0.24731803408523045, 0.29398068628114127, 0.24890799727071733, 0.1820958604982612]}, "task_prompt": ""}
{"id": "6ba3417a-5c00-4f1c-a134-02100ce0eed2", "fitness": 0.2277453931604306, "name": "ARCOM", "description": "ARCOM is an archive-driven, hybrid heuristic that enforces a strict budget and maintains an evolving center m plus an archive of evaluated points to learn anisotropic structure (robust covariance with cov_shrink, PCA-like subspace B with default dim//5) and adapt a trust radius (init_radius_frac=0.12) via a logistic rule based on recent improvement rate. It mixes diverse operators—quadratic minimization inside the learned subspace, anisotropic covariance sampling, Student‑t heavy‑tailed global jumps (student_df≈3), principal-direction probes and local Gaussian jitter—selected by a Thompson‑sampling bandit (Beta priors with soft decay) and modulates per-dimension step sizes with an EMA RMS (rms_alpha≈0.92) and a small momentum term. Batch candidates are aggregated with a tempered softmax weighting to update the center, lightweight swarm particles provide local intensification, and the algorithm uses soft restarts, clipping/regularization and conservative scaling (covariance sqrt, clipping of subspace steps, small penalties for operator \"failures\") to stabilize search across many continuous BBOB problems.", "code": "import numpy as np\n\nclass ARCOM:\n    \"\"\"\n    ARCOM: Adaptive Rotated Covariance-guided Multi-Operator Search\n\n    Main algorithm parameters (tunable):\n    - budget: total function evaluations allowed\n    - dim: problem dimensionality\n    - pop: candidate batch size per generation\n    - swarm_size: small local particle set\n    - subspace_dim: dimensionality of learned linear subspace (default floor(dim/5))\n    - init_radius: initial trust radius as fraction of average span (default 0.12)\n    - cov_shrink: shrinkage for covariance estimate regularization (default 1e-6)\n    - student_df: degrees-of-freedom for Student-t heavy tail proposals (default 3.0)\n    - beta_prior: prior counts for Thompson sampling bandit (successes and failures)\n    - rms_alpha: EMA factor for per-dimension squared-step tracking (default 0.92)\n    - restart_patience: number of generations without improvement before soft restart\n    Notes:\n    - This implementation enforces the budget strictly (safe_eval).\n    - Bounds are taken from func.bounds if available, otherwise [-5,5]^d.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=14, swarm_size=7, subspace_dim=None,\n                 init_radius=0.12, student_df=3.0, cov_shrink=1e-6,\n                 rms_alpha=0.92, beta_prior=(1.0, 1.0),\n                 restart_patience=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.swarm_size = int(min(swarm_size, pop))\n        self.subspace_dim = subspace_dim if subspace_dim is not None else max(1, self.dim // 5)\n        self.init_radius_frac = float(init_radius)\n        self.student_df = float(student_df)\n        self.cov_shrink = float(cov_shrink)\n        self.rms_alpha = float(rms_alpha)\n        self.beta_prior = (float(beta_prior[0]), float(beta_prior[1]))\n        self.restart_patience = restart_patience if restart_patience is not None else max(12, int(0.015 * self.budget))\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # --------------------------------\n        # bounds\n        # --------------------------------\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # --------------------------------\n        # internal state\n        # --------------------------------\n        evals = 0\n        X_arch = []\n        f_arch = []\n\n        # safe evaluation helper (strictly respects budget)\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch, x_best, f_best\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float).reshape(-1)\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # beware of unbounded archive growth: keep a sliding window large enough\n            max_archive = max(200, 8 * max(20, self.subspace_dim * 10))\n            if len(X_arch) > max_archive:\n                excess = len(X_arch) - max_archive\n                del X_arch[0:excess]\n                del f_arch[0:excess]\n            if fx < f_best:\n                x_best = x.copy(); f_best = fx\n            return fx\n\n        # initial seeding: small Sobol/latin-ish via random uniform with some spread\n        seed0 = min(max(20, int(self.budget // 250)), self.pop * 6)\n        for _ in range(seed0):\n            if evals >= self.budget:\n                break\n            x0 = lb + rng.rand(self.dim) * (ub - lb)\n            fx0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(fx0)\n\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = lb + rng.rand(self.dim) * (ub - lb)\n            fx0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(fx0)\n\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n        m = x_best.copy()\n\n        # trust radius initial (different scaling equation vs MAMOS)\n        trust_radius = max(1e-9, self.init_radius_frac * avg_span)\n\n        # per-dimension RMS of scaled steps (tracks typical scaled step size)\n        per_dim_rms = np.full(self.dim, 1e-6)\n        momentum = np.zeros(self.dim)\n\n        # small swarm (particle set) for local exploration\n        swarm_pos = [np.minimum(np.maximum(m + 0.015 * avg_span * rng.randn(self.dim), lb), ub) for _ in range(self.swarm_size)]\n        swarm_vel = [0.12 * trust_radius * rng.randn(self.dim) for _ in range(self.swarm_size)]\n        swarm_best_pos = swarm_pos.copy()\n        swarm_best_val = []\n        for x in swarm_pos:\n            if evals >= self.budget:\n                break\n            fx = safe_eval(x)\n            if fx is None:\n                break\n            swarm_best_val.append(fx)\n        if len(f_arch) > 0:\n            idx_best = int(np.argmin(f_arch))\n            x_best = X_arch[idx_best].copy()\n            f_best = float(f_arch[idx_best])\n            m = x_best.copy()\n\n        # operators and Thompson-sampling bandit (Beta priors)\n        operators = ['subspace_min', 'cov_sample', 'student_jump', 'principal_probe', 'local_gauss']\n        op_stats = {op: {'s': self.beta_prior[0], 'f': self.beta_prior[1]} for op in operators}\n\n        # helper: robust covariance sqrt\n        def robust_sqrt_cov(Xe):\n            if Xe.size == 0:\n                return np.eye(self.dim)\n            C = np.cov(Xe.T) + self.cov_shrink * np.eye(self.dim)\n            try:\n                w, V = np.linalg.eigh(C)\n                w = np.maximum(w, 1e-14)\n                return V.dot(np.diag(np.sqrt(w))).dot(V.T)\n            except Exception:\n                U, s, Vt = np.linalg.svd(C)\n                return U.dot(np.diag(np.sqrt(s))).dot(Vt)\n\n        # helper: select elites\n        def get_elites(k_frac=0.18):\n            n = len(X_arch)\n            if n == 0:\n                return np.empty((0, self.dim))\n            k = max(4, int(np.ceil(k_frac * max(20, n))))\n            idxs = np.argsort(f_arch)[:min(k, n)]\n            return np.asarray([X_arch[i].copy() for i in idxs])\n\n        # helper: learn small PCA-like subspace via SVD on recent window (differently: randomized centering)\n        def learn_subspace(k=self.subspace_dim, window=120):\n            if len(X_arch) < max(8, k + 4):\n                return np.zeros((self.dim, 0)), np.zeros(self.dim)\n            K = min(len(X_arch), window)\n            Xr = np.asarray(X_arch[-K:])\n            # center around median to be robust\n            M = np.median(Xr, axis=0)\n            S = Xr - M\n            try:\n                U, s, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(k, Vt.shape[0])\n                if r_eff <= 0:\n                    return np.zeros((self.dim, 0)), M\n                B = Vt[:r_eff].T.copy()\n                # small random orthonormal mixing to avoid freeze\n                noise = 0.03 * rng.randn(r_eff, r_eff)\n                try:\n                    Qr, _ = np.linalg.qr(np.eye(r_eff) + noise)\n                    B = B.dot(Qr)\n                except Exception:\n                    pass\n                return B, M\n            except Exception:\n                return np.zeros((self.dim, 0)), M\n\n        # helper: fit ridge quadratic in subspace (we fit full quadratic diagonal + small off-diagonal smoothing)\n        def fit_quadratic_subspace(B, M_center, samples=None, reg=1e-5):\n            r = B.shape[1]\n            if r == 0 or len(X_arch) < (r + 8):\n                return None\n            if samples is None:\n                samples = min(120, max(20, r * 12, len(X_arch)))\n            K = min(samples, len(X_arch))\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            # project relative to current center m (not M_center necessarily)\n            Z = (Xr - m).dot(B)  # n x r\n            n = Z.shape[0]\n            # design: constant, linear, diag-quadratic, and one aggregate quadratic cross-term\n            Phi = np.ones((n, 1 + r + r + 1))\n            Phi[:, 1:1 + r] = Z\n            Phi[:, 1 + r:1 + r + r] = Z ** 2\n            Phi[:, -1] = np.sum(Z ** 2, axis=1)  # coarse cross-term\n            try:\n                A = Phi.T.dot(Phi) + reg * np.eye(Phi.shape[1])\n                b = Phi.T.dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1 + r]\n                h_diag = coeff[1 + r:1 + r + r]\n                h_cross = coeff[-1]\n                # enforce moderate positive curvature\n                h_diag = np.where(h_diag < 1e-7, 1e-7, h_diag)\n                # minimizer in subspace: solve (H z + g = 0) with H diagonal + h_cross * 1-vector-outer-1\n                # approximate by treating cross-term as small isotropic addition\n                H = np.diag(h_diag) + (abs(h_cross) * 0.1) * np.eye(r)\n                try:\n                    z_star = -np.linalg.solve(H, g)\n                except np.linalg.LinAlgError:\n                    z_star = -g / (h_diag + 1e-12)\n                # clip z_star to trust radius in subspace norm\n                z_norm = np.linalg.norm(z_star)\n                sub_norm_factor = (np.linalg.norm(B, ord=2) + 1e-12)\n                max_z = (trust_radius / sub_norm_factor) * np.sqrt(max(1, r))\n                if z_norm > max_z:\n                    z_star = z_star * (max_z / (z_norm + 1e-12))\n                f_pred = float(c + g.dot(z_star) + 0.5 * (h_diag.dot(z_star ** 2)) + 0.5 * h_cross * (np.sum(z_star ** 2)))\n                return z_star, f_pred\n            except Exception:\n                return None\n\n        # helper: Student-t multivariate heavy tail scalar draw (scaled isotropic)\n        def student_t_step(scale=1.0):\n            # draw independent student-t entries and scale isotropically\n            u = rng.standard_t(self.student_df, size=self.dim)\n            # clip extreme tails but keep heavy-tailed behavior\n            clip = np.percentile(np.abs(u), 92) + 1e-12\n            u = u / clip\n            return scale * u\n\n        # Thompson-sampling operator selection\n        def select_operator_thompson():\n            samples = {}\n            for op in operators:\n                s = op_stats[op]['s']\n                f = op_stats[op]['f']\n                # draw from Beta(s, f) to represent success probability\n                samples[op] = rng.beta(s, f)\n            # small probability to explore randomly\n            if rng.rand() < 0.07:\n                return rng.choice(operators)\n            return max(samples.items(), key=lambda x: x[1])[0]\n\n        # bookkeeping and control\n        gen = 0\n        stagn_gens = 0\n        improve_window = []  # moving window (last 40 candidates) of boolean improvements\n        max_improve_window = 40\n\n        # initialize subspace\n        B, M_center = learn_subspace(self.subspace_dim)\n\n        # main evolution loop - produce candidates until budget exhausted\n        while evals < self.budget:\n            gen += 1\n\n            # refresh subspace periodically with modest frequency\n            if gen % max(1, int(120 // 6)) == 0:\n                B, M_center = learn_subspace(self.subspace_dim, window=120)\n\n            # compute elites and anisotropic sqrt-cov\n            Xe = get_elites()\n            S_sqrt = robust_sqrt_cov(Xe) if Xe.size else np.eye(self.dim)\n\n            # compute an improvement rate over recent archive (used to adapt trust via logistic)\n            recent_k = min(len(f_arch), 40)\n            improv_rate = 0.0\n            if recent_k >= 4:\n                fr = np.asarray(f_arch[-recent_k:])\n                better_count = np.sum(fr < (np.min(f_arch) + 1e-30))  # trivial: count of minima hits (rare)\n                # instead compute normalized slope of best-so-far improvements:\n                # measure how many improvements occurred in the recent window\n                diffs = fr[:-1] - fr[1:]\n                improv_rate = max(0.0, np.sum(diffs > 1e-9) / max(1, recent_k - 1))\n            # logistic adaptation: increase radius if improvement low, shrink if improvement high\n            # different from MAMOS multiplicative small increments: here logistic scaling provides bounded factor\n            target_r = (1.0 / (1.0 + np.exp(10.0 * (0.12 - improv_rate)))) * (0.9 * max(span) + 0.1 * avg_span)\n            # blend towards target\n            trust_radius = np.clip(0.85 * trust_radius + 0.15 * (target_r * self.init_radius_frac), 1e-9, max(span))\n\n            # build a batch of candidates\n            n_cand = min(self.pop, max(1, self.budget - evals))\n            batch_X = []\n            batch_f = []\n            batch_ops = []\n\n            for ci in range(n_cand):\n                if evals >= self.budget:\n                    break\n                op = select_operator_thompson()\n                x_cand = None\n                f_cand = None\n\n                if op == 'subspace_min' and B.shape[1] > 0:\n                    # try a quadratic minimizer in learned subspace\n                    result = fit_quadratic_subspace(B, M_center)\n                    if result is not None:\n                        z_star, f_pred = result\n                        x_prop = np.minimum(np.maximum(m + B.dot(z_star), lb), ub)\n                        f_prop = safe_eval(x_prop)\n                        if f_prop is None:\n                            break\n                        x_cand = x_prop; f_cand = f_prop\n                    else:\n                        # fallback to directional cov sampling\n                        z = rng.randn(self.dim)\n                        step = 1.1 * trust_radius * S_sqrt.dot(z)\n                        x_prop = np.minimum(np.maximum(m + step, lb), ub)\n                        f_prop = safe_eval(x_prop)\n                        if f_prop is None:\n                            break\n                        x_cand = x_prop; f_cand = f_prop\n\n                elif op == 'cov_sample':\n                    # anisotropic sampling using sqrt-cov of elites, but include a random rotation to diversify\n                    R = np.eye(self.dim)\n                    if B.shape[1] > 0 and rng.rand() < 0.22:\n                        # small random rotation in learned subspace\n                        r = B.shape[1]\n                        G = 0.07 * rng.randn(r, r)\n                        try:\n                            Qr, _ = np.linalg.qr(np.eye(r) + G)\n                            Rsub = B.dot(Qr).dot(B.T)\n                            R = Rsub\n                        except Exception:\n                            R = np.eye(self.dim)\n                    z = rng.randn(self.dim)\n                    step = trust_radius * (S_sqrt.dot(z) * 0.9 + 0.2 * (R.dot(z)))\n                    x_prop = np.minimum(np.maximum(m + step, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is None:\n                        break\n                    x_cand = x_prop; f_cand = f_prop\n\n                elif op == 'student_jump':\n                    # heavy-tailed global escape: Student-t scaled by trust radius; start either from center or random elite\n                    if Xe.size and rng.rand() < 0.55:\n                        center = Xe[rng.randint(0, Xe.shape[0])]\n                    else:\n                        center = m\n                    step = student_t_step(scale=3.2 * trust_radius)\n                    x_prop = np.minimum(np.maximum(center + step + 0.04 * momentum, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is None:\n                        break\n                    x_cand = x_prop; f_cand = f_prop\n\n                elif op == 'principal_probe':\n                    # probe along principal variance direction(s)\n                    if len(X_arch) > 3:\n                        cov_full = np.cov(np.asarray(X_arch).T) + 1e-12 * np.eye(self.dim)\n                        try:\n                            ev, V = np.linalg.eigh(cov_full)\n                            idx = np.argsort(-ev)\n                            top = V[:, idx[:max(1, min(4, self.dim))]]\n                            # choose a random linear combination of top components\n                            coeffs = rng.randn(top.shape[1])\n                            dir_vec = top.dot(coeffs)\n                            dir_vec = dir_vec / (np.linalg.norm(dir_vec) + 1e-12)\n                            for sign in (1.0, -1.0):\n                                x_try = np.minimum(np.maximum(m + sign * 0.9 * trust_radius * dir_vec, lb), ub)\n                                f_try = safe_eval(x_try)\n                                if f_try is None:\n                                    break\n                                if f_try < (f_best - 1e-12):\n                                    x_cand = x_try; f_cand = f_try\n                                    break\n                            if x_cand is None:\n                                # fallback small gaussian\n                                x_try = np.minimum(np.maximum(m + 0.4 * trust_radius * rng.randn(self.dim), lb), ub)\n                                f_try = safe_eval(x_try)\n                                if f_try is None:\n                                    break\n                                x_cand = x_try; f_cand = f_try\n                        except Exception:\n                            x_try = np.minimum(np.maximum(m + 0.4 * trust_radius * rng.randn(self.dim), lb), ub)\n                            f_try = safe_eval(x_try)\n                            if f_try is None:\n                                break\n                            x_cand = x_try; f_cand = f_try\n                    else:\n                        # no archive yet: sample local gaussian\n                        x_try = np.minimum(np.maximum(m + 0.45 * trust_radius * rng.randn(self.dim), lb), ub)\n                        f_try = safe_eval(x_try)\n                        if f_try is None:\n                            break\n                        x_cand = x_try; f_cand = f_try\n\n                else:  # local_gauss\n                    # local gaussian jitter with per-dimension scaling from EMA\n                    per_scale = np.clip(trust_radius / (np.sqrt(per_dim_rms) + 1e-9), 1e-8, max(span))\n                    step = (rng.randn(self.dim) * per_scale) * 0.65 + 0.05 * momentum\n                    x_try = np.minimum(np.maximum(m + step, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try; f_cand = f_try\n\n                if f_cand is None:\n                    break\n\n                # record candidate\n                batch_X.append(np.asarray(x_cand, dtype=float))\n                batch_f.append(float(f_cand))\n                batch_ops.append(op)\n\n                # update Thompson stats: success = improved beyond small threshold\n                improved = (f_cand < f_best - 1e-12)\n                if improved:\n                    op_stats[op]['s'] += 1.0\n                else:\n                    op_stats[op]['f'] += 0.3  # softer penalty for failures (keeps exploration)\n                # lightly decay counts to keep bandit adaptive\n                if (ci % 8) == 0:\n                    for kop in operators:\n                        op_stats[kop]['s'] *= 0.9995\n                        op_stats[kop]['f'] *= 0.9995\n\n                # update per-dim rms with different equation (RMS of absolute scaled steps)\n                step_vec = x_cand - m\n                scaled = np.abs(step_vec) / (trust_radius + 1e-12)\n                per_dim_rms = self.rms_alpha * per_dim_rms + (1.0 - self.rms_alpha) * (scaled ** 1.8)\n\n                # opportunistic update of particle swarm (lightweight)\n                if rng.rand() < 0.15 and len(swarm_pos) > 0:\n                    pid = rng.randint(0, len(swarm_pos))\n                    # replace a weak particle with this candidate with some prob\n                    if f_cand < (swarm_best_val[pid] if pid < len(swarm_best_val) else 1e99):\n                        if pid < len(swarm_best_val):\n                            swarm_best_val[pid] = f_cand\n                            swarm_best_pos[pid] = x_cand.copy()\n                        else:\n                            swarm_best_val.append(f_cand); swarm_best_pos.append(x_cand.copy())\n                        swarm_pos[pid] = x_cand.copy()\n\n                # update global best and stagnation counters\n                if f_cand < f_best - 1e-12:\n                    f_best = float(f_cand); x_best = x_cand.copy()\n                    stagn_gens = 0\n                    improve_window.append(1)\n                else:\n                    stagn_gens += 1\n                    improve_window.append(0)\n                if len(improve_window) > max_improve_window:\n                    improve_window.pop(0)\n\n                # small momentum update\n                momentum = 0.7 * momentum + 0.3 * (x_cand - m) * 0.5\n\n            # end batch generation\n\n            # center aggregation: a tempered softmax that biases toward better scores but also keeps diversity\n            if len(batch_X) > 0:\n                Fs = np.asarray(batch_f)\n                Xs = np.asarray(batch_X)\n                # robust scaling of Fs: subtract median\n                f_med = np.median(Fs)\n                scaled = (Fs - f_med) / (np.std(Fs) + 1e-12)\n                # temperature scaled by trust_radius and archive diversity\n                # different functional form: temp = temp0 * (1 + log(1 + trust_radius))\n                temp0 = 0.7\n                temp = temp0 * (1.0 + np.log1p(trust_radius + 1e-12))\n                weights = np.exp(-scaled / (temp + 1e-12))\n                weights = weights / (np.sum(weights) + 1e-12)\n                x_mean = np.sum(weights[:, None] * Xs, axis=0)\n                # learning rate depends on trust_radius relative to avg_span (but reversed scaling vs MAMOS)\n                lr = 0.33 if trust_radius < 0.25 * avg_span else 0.18\n                delta = x_mean - m\n                # clip by a different trust-based limit: scale by sqrt(dim) but reduced factor\n                max_jump = 3.2 * trust_radius * np.sqrt(max(1, self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > max_jump:\n                    delta = delta * (max_jump / (dn + 1e-12))\n                m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                # update momentum and per_dim_rms shrink when improvement occurred\n                momentum = 0.68 * momentum + 0.32 * (lr * delta)\n                if np.any(Fs < f_best):\n                    trust_radius = max(1e-9, trust_radius * 0.78)\n                    per_dim_rms *= 0.97\n                else:\n                    trust_radius = min(max(span), trust_radius * 1.02)\n                    per_dim_rms *= 0.999\n\n            # soft restart when stagnation persists\n            if stagn_gens >= self.restart_patience and evals < self.budget:\n                stagn_gens = 0\n                # targeted reseed: mix of best, elites and random global noise\n                Xe = get_elites()\n                if Xe.size:\n                    pick = Xe[rng.randint(0, Xe.shape[0])]\n                else:\n                    pick = x_best\n                jitter = max(0.03 * avg_span, 1.5 * trust_radius)\n                # combine anisotropic elite perturbation and isotropic global noise\n                noise = 0.6 * rng.randn(self.dim) + 0.4 * (S_sqrt.dot(rng.randn(self.dim)))\n                m = np.minimum(np.maximum(pick + jitter * noise, lb), ub)\n                trust_radius = min(max(span), trust_radius * 1.6)\n                momentum = np.zeros(self.dim)\n                # re-seed swarm around new center\n                swarm_pos = [np.minimum(np.maximum(m + 0.02 * avg_span * rng.randn(self.dim), lb), ub) for _ in range(self.swarm_size)]\n                swarm_vel = [0.12 * trust_radius * rng.randn(self.dim) for _ in range(self.swarm_size)]\n                swarm_best_pos = swarm_pos.copy()\n                swarm_best_val = []\n                for x in swarm_pos:\n                    if evals >= self.budget:\n                        break\n                    fx = safe_eval(x)\n                    if fx is None:\n                        break\n                    swarm_best_val.append(fx)\n\n        # final results\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ARCOM scored 0.228 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "7085e0ca-6bc0-45d8-b32a-44eb8685728e", "operator": null, "metadata": {"aucs": [0.14195251204039228, 0.21739749242419337, 0.28195756397666905, 0.30037873802941295, 0.21091241729329557, 0.2872075435160255, 0.23128643831587814, 0.24186505597198305, 0.20607001337895703, 0.15842615665749882]}, "task_prompt": ""}
{"id": "dd5841f1-229d-4037-ba80-3751b9908811", "fitness": 0.26372940807635803, "name": "SYNERGIA", "description": "SYNERGIA is a hybrid low-rank + diagonal search technique that represents steps as a combination of a small learned subspace (U, subrank ≈ dim//6, subscale ~ sigma/√k) and per-dimension residual scales (s_diag ≈ 0.35·span), generating proposal batches from mirrored antithetic low-rank+diag pairs, elite-shaped anisotropic Gaussians, coordinate probes and occasional Lévy escapes to balance exploration and exploitation. Adaptation is driven by a multiplicative sigma update using a smoothed success rate (target ≈ 0.2, adapt rate 0.25, p_succ smoothing 0.9), per-coordinate RMS smoothing (rms_beta ≈ 0.93) to set s_diag, a momentum/rank-one vector v_dir learned from mirrored gains, periodic PCA refresh of the low-rank basis from recent successful normalized steps, and an opportunistic quadratic surrogate minimizer in the subspace when enough local data exist. Robustness and diversity are supported by an archive-based elite covariance for anisotropic draws, antithetic pair evaluation to estimate directional gains and update momentum, bounded trust moves and inflation restarts on stagnation, and conservative default population/batch sizing (pop scales with log(dim), archive_size ~ max(6·dim,120)) to work across many functions and dimensions.", "code": "import numpy as np\n\nclass SYNERGIA:\n    \"\"\"\n    SYNERGIA: SYNErgetic Rank-Adapted Mirrored Evolution\n\n    Key components:\n    - Maintain search center m, global scale sigma, low-rank orthonormal basis U and diag residual scales s_diag.\n    - Produce a mixture of proposals each generation:\n        * mirrored low-rank + diagonal paired samples (antithetic) for directional gain estimation,\n        * subspace quadratic surrogate minimizer when enough local data available,\n        * elite-shaped anisotropic Gaussian draws (robust sqrt-cov),\n        * coordinate probes and occasional Levy (Cauchy) heavy-tail escapes.\n    - Momentum vector (rank-one) biases sampling and updates covariance-like direction when helpful.\n    - Per-dimension RMS adapts diagonal scales; sigma adapts multiplicatively via smoothed success rate.\n    - Periodic PCA refresh of U from recent successful normalized steps; opportunistic restarts on stagnation.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n\n        # Tunables (sensible defaults)\n        self.pop = max(8, int(6 + 0.8 * np.log(max(2, dim))))  # proposals per generation\n        self.subrank = max(1, min(dim, dim // 6))  # low-rank basis size\n        self.archive_size = max(6 * dim, 120)\n        self.success_target = 0.2\n        self.sigma_adapt_rate = 0.25\n        self.p_succ_smooth = 0.9\n        self.rms_beta = 0.93\n        self.mom_beta = 0.85\n        self.pca_period = 9\n        self.surrogate_prob = 0.18\n        self.levy_prob = 0.03\n        self.coord_prob = 0.08\n        self.min_sigma = 1e-9\n        self.max_sigma_mult = 3.0\n        self.restart_inflate = 1.6\n        self.stagn_frac = 0.05\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # Bounds\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # state\n        evals = 0\n        # initial seeding\n        seed_init = min(self.pop * 3, max(12, self.budget // 200))\n        X_arch = []\n        f_arch = []\n        while evals < self.budget and len(X_arch) < seed_init:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        if len(X_arch) == 0:\n            # at least one\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            f0 = float(func(x0)); evals += 1\n            X_arch.append(x0.copy()); f_arch.append(f0)\n\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n\n        # Initialize search center at weighted average of best samples\n        m = x_best.copy()\n\n        # initial sigma & per-dim diag scales\n        sigma = max(self.min_sigma, 0.16 * avg_span)\n        s_diag = np.full(self.dim, 0.35 * avg_span)  # residual diag noise scale\n        v_rms = np.full(self.dim, 1e-6)  # RMS accumulator\n\n        # low-rank orthonormal basis U and subspace scales\n        k = min(self.subrank, self.dim)\n        if k > 0:\n            A = rng.randn(self.dim, k)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :k].copy()\n            s_sub = np.full(k, sigma / np.sqrt(max(1, k)))\n        else:\n            U = np.zeros((self.dim, 0))\n            s_sub = np.array([])\n\n        # momentum / rank-one direction\n        v_dir = np.zeros(self.dim)\n\n        # buffer of normalized successful steps for PCA\n        success_steps = []\n\n        # elite storage\n        elite_K = max(3, int(0.12 * max(50, self.budget // 10)))\n\n        # smoothed success probability\n        p_succ = 0.2\n\n        # stagnation counters\n        stagn = 0\n        stagn_limit = max(6, int(self.stagn_frac * self.budget))\n\n        gen = 0\n        total_evals = evals\n\n        # utility functions\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch, f_best, x_best, stagn\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # FIFO archive\n            if len(X_arch) > self.archive_size:\n                del X_arch[0]; del f_arch[0]\n            if fx < f_best:\n                f_best = fx; x_best = x.copy(); stagn = 0\n            else:\n                stagn += 1\n            return fx\n\n        def robust_sqrt_cov_of_elites():\n            if len(X_arch) == 0:\n                return np.eye(self.dim)\n            K = min(elite_K, len(X_arch))\n            idxs = np.argsort(f_arch)[:K]\n            Xe = np.asarray([X_arch[i] for i in idxs])\n            if Xe.shape[0] <= 1:\n                return np.eye(self.dim)\n            C = np.cov(Xe.T) + 1e-8 * np.eye(self.dim)\n            try:\n                w, V = np.linalg.eigh(C)\n                w = np.clip(w, 1e-12, None)\n                S = (V * np.sqrt(w)).dot(V.T)\n                return S\n            except Exception:\n                Ue, svals, Vt = np.linalg.svd(C)\n                return Ue.dot(np.diag(np.sqrt(np.maximum(svals, 1e-12)))).dot(Vt)\n\n        def pca_refresh():\n            nonlocal U, s_sub\n            if len(success_steps) < max(3, k):\n                return\n            B = np.asarray(success_steps)\n            Bc = B - np.mean(B, axis=0, keepdims=True)\n            try:\n                _, Svals, Vt = np.linalg.svd(Bc, full_matrices=False)\n                r_eff = min(k, Vt.shape[0])\n                if r_eff <= 0:\n                    return\n                U_new = Vt[:r_eff].T\n                # blend\n                if U.shape[1] == r_eff:\n                    U = 0.82 * U + 0.18 * U_new\n                else:\n                    U = U_new.copy()\n                # orthonormalize\n                Q, _ = np.linalg.qr(U)\n                U = Q[:, :r_eff]\n                # update subspace scales modestly\n                s_sub = 0.88 * s_sub[:r_eff] + 0.12 * (np.maximum(Svals[:r_eff], 1e-8) / np.sqrt(max(1, Bc.shape[0])))\n            except Exception:\n                pass\n\n        def fit_diag_quadratic_in_subspace(C, U_sub, Xs, fs):\n            # model f ≈ c + g^T u + 0.5 * h * u^2 (diagonal Hessian in subspace coords)\n            n = Xs.shape[0]\n            rloc = U_sub.shape[1]\n            if n <= (1 + 2 * rloc):\n                return None, None\n            Z = (Xs - C).dot(U_sub)  # n x rloc\n            # design: [1, z_i..., z_i^2...]\n            Phi = np.ones((n, 1 + rloc + rloc))\n            Phi[:, 1:1 + rloc] = Z\n            Phi[:, 1 + rloc:] = Z * Z\n            y = fs\n            reg = 1e-6 * np.eye(Phi.shape[1])\n            try:\n                theta = np.linalg.solve(Phi.T.dot(Phi) + reg, Phi.T.dot(y))\n                c = float(theta[0])\n                g = theta[1:1 + rloc]\n                h = theta[1 + rloc:1 + rloc + rloc]\n                h = np.where(h < 1e-8, 1e-8, h)\n                z_star = - g / (h + 1e-12)\n                # clip z_star to reasonable magnitude\n                max_z = 6.0 * sigma\n                nz = np.linalg.norm(z_star)\n                if nz > max_z:\n                    z_star = z_star * (max_z / (nz + 1e-12))\n                x_star = C + U_sub.dot(z_star)\n                f_pred = float(c + g.dot(z_star) + 0.5 * np.sum(h * (z_star ** 2)))\n                return x_star, f_pred\n            except Exception:\n                return None, None\n\n        # Main loop: iterative generation of batches until budget exhausted\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop, remaining)\n            # prefer even for antithetic pairs\n            if lam >= 2:\n                lam = lam - (lam % 2)\n\n            # recompute weights etc.\n            S_elite = robust_sqrt_cov_of_elites()\n\n            candidates = []\n            cand_types = []\n\n            # possibly propose surrogate minimizer\n            if (rng.rand() < self.surrogate_prob) and len(X_arch) >= max(12, k + 6) and k > 0:\n                # use recent archive\n                K = min(len(X_arch), self.archive_size)\n                Xr = np.asarray(X_arch[-K:])\n                fr = np.asarray(f_arch[-K:])\n                x_star, f_pred = fit_diag_quadratic_in_subspace(m, U if U.shape[1] > 0 else U, Xr, fr)\n                if x_star is not None:\n                    candidates.append(x_star)\n                    cand_types.append('surrogate')\n\n            # create mirrored antithetic low-rank + diag pairs\n            pairs = max(0, lam // 2 - len(candidates) // 2)\n            for _ in range(pairs):\n                # produce low-rank component\n                if k > 0 and U.size > 0:\n                    z_r = rng.randn(k) * s_sub\n                    low = U.dot(z_r)\n                else:\n                    low = np.zeros(self.dim)\n                # diagonal residual\n                z_d = rng.randn(self.dim) * (s_diag)\n                # step and mirrored pair\n                step = sigma * (low + z_d) + 0.6 * v_dir  # bias by momentum\n                x_p = np.minimum(np.maximum(m + step, lb), ub)\n                x_m = np.minimum(np.maximum(m - step, lb), ub)\n                candidates.append(x_p); cand_types.append('mirror_plus')\n                candidates.append(x_m); cand_types.append('mirror_minus')\n\n            # fill remaining with elite-shaped and coordinate and levy\n            while len(candidates) < lam:\n                coin = rng.rand()\n                if coin < 0.06 and rng.rand() < self.levy_prob:\n                    # levy heavy-tailed from either m or an elite\n                    if rng.rand() < 0.6 and len(X_arch) >= 3:\n                        center = X_arch[rng.randint(0, len(X_arch))]\n                    else:\n                        center = m\n                    z = rng.standard_cauchy(size=self.dim)\n                    clip = np.percentile(np.abs(z), 90) + 1e-12\n                    z = z / clip\n                    step = 3.5 * sigma * z\n                    x = np.minimum(np.maximum(center + step, lb), ub)\n                    candidates.append(x); cand_types.append('levy')\n                elif coin < 0.5:\n                    # elite-shaped anisotropic gaussian\n                    z = rng.randn(self.dim)\n                    step = 1.0 * sigma * (S_elite.dot(z)) + 0.2 * v_dir\n                    x = np.minimum(np.maximum(m + step, lb), ub)\n                    candidates.append(x); cand_types.append('elite')\n                elif coin < 0.8:\n                    # coordinate probe\n                    j = rng.randint(0, self.dim)\n                    step = np.zeros(self.dim)\n                    step[j] = (0.6 + rng.rand() * 1.6) * s_diag[j]\n                    if rng.rand() < 0.5:\n                        step = -step\n                    x = np.minimum(np.maximum(m + step, lb), ub)\n                    candidates.append(x); cand_types.append('coord')\n                else:\n                    # default low-rank + diag gaussian (not mirrored)\n                    if k > 0 and U.size > 0:\n                        z_r = rng.randn(k) * s_sub\n                        low = U.dot(z_r)\n                    else:\n                        low = np.zeros(self.dim)\n                    z_d = rng.randn(self.dim) * s_diag\n                    step = sigma * (low + z_d) + 0.4 * v_dir\n                    x = np.minimum(np.maximum(m + step, lb), ub)\n                    candidates.append(x); cand_types.append('lowrank')\n\n            # Evaluate candidates sequentially (safe_eval enforces budget)\n            fc = np.full(len(candidates), np.inf)\n            for i, x in enumerate(candidates):\n                if evals >= self.budget:\n                    break\n                fval = safe_eval(x)\n                if fval is None:\n                    break\n                fc[i] = fval\n\n            # truncate invalid\n            valid = np.isfinite(fc)\n            if not np.any(valid):\n                break\n            candidates = [candidates[i] for i in range(len(candidates)) if valid[i]]\n            cand_types = [cand_types[i] for i in range(len(cand_types)) if valid[i]]\n            fc = fc[valid]\n\n            # analyze mirrored pairs for directional gains\n            # assume mirrored pairs stored consecutively as plus/minus; detect and attribute gains\n            for i in range(0, len(candidates) - 1, 2):\n                if cand_types[i].startswith('mirror') and cand_types[i + 1].startswith('mirror'):\n                    xp = np.asarray(candidates[i]); xm = np.asarray(candidates[i + 1])\n                    fp = float(fc[i]); fm = float(fc[i + 1])\n                    # direction estimate (xp - xm) / 2 normalized by sigma\n                    step = (xp - xm) * 0.5\n                    step_norm = np.linalg.norm(step) + 1e-12\n                    if step_norm > 1e-12:\n                        s_normed = step / (step_norm)\n                        # reward: how much better plus is than minus\n                        gain = max(0.0, fm - fp) / (abs(fm) + abs(fp) + 1e-12)\n                        if gain > 0:\n                            # update directional momentum in ambient coordinates\n                            v_dir = self.mom_beta * v_dir + (1.0 - self.mom_beta) * (gain * s_normed)\n                            # record successful normalized step for PCA buffer\n                            success_steps.append((step / (sigma + 1e-12)).copy())\n                            if len(success_steps) > max(40, self.archive_size // 3):\n                                del success_steps[0]\n\n            # Update per-dim RMS and s_diag based on evaluated steps\n            # compute steps relative to m for all candidates\n            Xcand_arr = np.asarray(candidates)\n            deltas = Xcand_arr - m.reshape(1, -1)\n            # update RMS per coordinate\n            sq = (deltas / (sigma + 1e-12)) ** 2\n            stat = np.mean(sq, axis=0)\n            v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * stat\n            # set s_diag relative to sigma and rms\n            s_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-12), 1e-8, self.max_sigma_mult * avg_span)\n\n            # select best candidate of this batch\n            best_idx = int(np.argmin(fc))\n            gen_best_x = np.asarray(candidates[best_idx])\n            gen_best_f = float(fc[best_idx])\n            improved = (gen_best_f < f_best)\n\n            # move center m toward a weighted average of good candidates (soft selection)\n            # compute softmax weights favoring low fc\n            f_shift = fc - np.min(fc)\n            fstd = float(np.std(fc) + 1e-12)\n            scores = np.exp(- (f_shift) / (fstd + 1e-12))\n            weights = scores / (np.sum(scores) + 1e-12)\n            weighted_mean = np.sum(weights.reshape(-1, 1) * Xcand_arr, axis=0)\n            # learning rate depends on improvement and type\n            lr = 0.28 if improved else 0.16\n            # trust clip the move\n            delta = weighted_mean - m\n            max_move = 6.0 * sigma * np.sqrt(max(1, self.dim))\n            dn = np.linalg.norm(delta)\n            if dn > max_move:\n                delta = delta * (max_move / (dn + 1e-12))\n            m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n\n            # update momentum v_dir smoothing already integrated above; keep a mild EMA to retain direction\n            v_dir = self.mom_beta * v_dir + (1.0 - self.mom_beta) * (weighted_mean - m)\n\n            # update success rate and adapt sigma multiplicatively\n            gen_success = float(np.any(fc < f_best + 1e-12))\n            p_succ = self.p_succ_smooth * p_succ + (1.0 - self.p_succ_smooth) * gen_success\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, self.min_sigma, self.max_sigma_mult * np.max(span))\n\n            # periodic PCA refresh\n            if (gen % self.pca_period) == 0 and len(success_steps) >= max(3, k):\n                pca_refresh()\n\n            # opportunistic restart if stagnated\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                # restart around best with jitter\n                jitter = max(0.04 * avg_span, 0.8 * sigma)\n                m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                sigma = max(sigma * self.restart_inflate, 0.2 * avg_span)\n                # reset some stats\n                v_dir = np.zeros(self.dim)\n                if k > 0:\n                    A = rng.randn(self.dim, k)\n                    Q, _ = np.linalg.qr(A)\n                    U = Q[:, :k]\n                    s_sub = np.full(k, sigma / np.sqrt(max(1, k)))\n                s_diag = np.full(self.dim, 0.35 * avg_span)\n                v_rms = np.full(self.dim, 1e-6)\n                success_steps = []\n                # do a few reseed evaluations near best\n                for _ in range(min(6, self.budget - evals)):\n                    if evals >= self.budget:\n                        break\n                    x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                    fx = safe_eval(x)\n                    if fx is None:\n                        break\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SYNERGIA scored 0.264 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "7085e0ca-6bc0-45d8-b32a-44eb8685728e", "operator": null, "metadata": {"aucs": [0.13705819257909546, 0.18398709768267651, 0.352158338928224, 0.30308354866411535, 0.2378981761147182, 0.3995551823927397, 0.25162327174369403, 0.33624880491582876, 0.27074898737247, 0.16493248037001862]}, "task_prompt": ""}
{"id": "902ef24e-8669-4409-8406-927786c97844", "fitness": 0.4698676371797889, "name": "DirectionalLevyjDE", "description": "The algorithm is a hybrid compact current-to-pbest/1 jDE (small population sized ~max(12, 4+3·log(dim))) that combines adaptive DE (jDE updates of F and CR with tau1/tau2≈0.12) with archive-driven heavy‑tailed global moves and occasional local polishing. It keeps a small elite archive (3–8) maintained by fitness, uses quasi‑uniform stratified initialization and reflect/clamp bound handling, and computes per‑dimension diversity scales from the archive to produce anisotropic steps. Global exploration is driven by directional Student‑t (Levy‑like, df=3) jumps centered on elites or the best point, occasional archive recombination injections and periodic uniform injections to maintain diversity, while promising candidates trigger budget‑aware Hooke–Jeeves local search (local_budget_frac≈0.04) with geometric shrink (0.618). Finally, exploration intensity is adaptive: a tanh function of stagnation controls global jump probability (global_base_prob≈0.22) and this base prob is mildly adjusted from archive spread to balance exploration/exploitation.", "code": "import numpy as np\n\nclass DirectionalLevyjDE:\n    \"\"\"\n    DirectionalLevyjDE\n\n    Compact current-to-pbest/1 jDE enhanced with archive-driven directional Student-t (Levy-like)\n    jumps, anisotropic per-dimension scaling from archive diversity, occasional archive recombination,\n    and budget-aware Hooke-Jeeves local polishing. Adaptive global jump probability via a tanh\n    function of stagnation encourages exploration when needed.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop_base=None,\n                 p_frac=0.2,\n                 init_step_frac=0.18,\n                 local_budget_frac=0.04,\n                 global_base_prob=0.22,\n                 student_df=3):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.pop_base = pop_base\n        self.p_frac = float(p_frac)\n        self.init_step_frac = float(init_step_frac)\n        self.local_budget_frac = float(local_budget_frac)\n        self.global_base_prob = float(global_base_prob)\n        self.student_df = float(student_df)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.rng_seed)\n\n        # bounds (scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # population size similar to No.5 but tunable\n        if self.pop_base is None:\n            pop = max(12, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            pop = int(self.pop_base)\n        pop = min(pop, max(2, self.budget))\n\n        # archive size small (3..8 like No.5)\n        archive_k = max(3, min(8, pop // 2))\n\n        # bookkeeping\n        evals = 0\n        f_best = np.inf\n        x_best = None\n        archive = []  # list of (f,x) sorted ascending\n\n        def clamp(x):\n            return np.minimum(np.maximum(x, lb), ub)\n\n        def eval_and_record(x):\n            nonlocal evals, f_best, x_best, archive\n            if evals >= self.budget:\n                return None\n            x = np.asarray(x, dtype=float)\n            x = clamp(x)\n            f = float(func(x))\n            evals += 1\n            if f < f_best:\n                f_best = f\n                x_best = x.copy()\n            # maintain archive\n            if len(archive) < archive_k or f < archive[-1][0]:\n                archive.append((float(f), x.copy()))\n                archive.sort(key=lambda t: t[0])\n                if len(archive) > archive_k:\n                    archive.pop()\n            return float(f), x\n\n        # quasi-uniform stratified initialization (per-dim) with light jitter\n        X = np.empty((pop, self.dim), dtype=float)\n        for d in range(self.dim):\n            perm = rng.permutation(pop)\n            strata = (np.arange(pop) + 0.5) / pop\n            X[:, d] = lb[d] + (ub[d] - lb[d]) * strata[perm]\n        X += (rng.rand(pop, self.dim) - 0.5) * (0.5 * span / max(1.0, self.dim))\n        X = clamp(X)\n\n        # evaluate initial population sequentially\n        f = np.full(pop, np.inf, dtype=float)\n        for i in range(pop):\n            if evals >= self.budget:\n                break\n            res = eval_and_record(X[i])\n            if res is None:\n                break\n            f[i], X[i] = res\n\n        # ensure at least one point\n        if x_best is None and evals < self.budget:\n            res = eval_and_record(rng.uniform(lb, ub))\n            if res is None:\n                return np.inf, None\n\n        # jDE style F and CR initialization\n        F = np.clip(0.6 + 0.1 * rng.randn(pop), 0.05, 0.95)\n        CR = np.clip(rng.rand(pop), 0.0, 1.0)\n        tau1 = 0.12\n        tau2 = 0.12\n\n        # helper: diversity-based per-dim scale\n        def diversity_scale():\n            if len(archive) >= 2:\n                pts = np.vstack([t[1] for t in archive])\n                std = np.std(pts, axis=0)\n                return np.maximum(std, 0.03 * span)\n            else:\n                return 0.2 * span\n\n        # reflect-then-clamp (like No.5)\n        def reflect_bounds(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = clamp(xr)\n            return xr\n\n        # Student-t directional heavy-tailed jump from center with anisotropic scaling\n        def studentt_jump(center, scale_factor=0.8):\n            dscale = diversity_scale()\n            # random direction\n            dirv = rng.randn(self.dim)\n            dirv /= (np.linalg.norm(dirv) + 1e-12)\n            tdraw = rng.standard_t(self.student_df)\n            anis = dscale / (np.mean(dscale) + 1e-12)\n            base_step = dirv * (scale_factor * avg_span * (0.4 + 0.8 * rng.rand()))\n            step = tdraw * base_step * anis\n            return clamp(center + step)\n\n        # differential recombination from archive (like No.1)\n        def recombine_archive():\n            if len(archive) >= 2:\n                i, j = rng.choice(len(archive), size=2, replace=False)\n                x1 = archive[i][1]\n                x2 = archive[j][1]\n                child = x1 + 0.8 * (x1 - x2) + 0.05 * avg_span * rng.standard_t(self.student_df, size=self.dim)\n                return clamp(child)\n            else:\n                return clamp(rng.uniform(lb, ub))\n\n        # Hooke-Jeeves local search (budget-aware)\n        def hooke_jeeves(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best, archive\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            base = x_start.copy()\n            base_f = float(f_start)\n            # per-dim initial steps from diversity and avg_span\n            dscale = diversity_scale()\n            steps = np.minimum(0.5 * dscale, 0.4 * avg_span)\n            shrink = 0.618\n            pattern_factor = 1.5\n            local_evals = 0\n            iter_limit = max(1, int(local_budget // max(1, self.dim)))\n            iters = 0\n            while local_evals < local_budget and iters < iter_limit and np.any(steps > 1e-10):\n                iters += 1\n                improved = False\n                probe = base.copy()\n                probe_f = base_f\n                order = rng.permutation(self.dim)\n                for idx in order:\n                    if local_evals >= local_budget or evals >= self.budget:\n                        break\n                    xp = probe.copy()\n                    xp[idx] += steps[idx]\n                    xp = clamp(xp)\n                    res = eval_and_record(xp)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fp, xp = res\n                    if fp < probe_f:\n                        probe = xp.copy()\n                        probe_f = fp\n                        improved = True\n                        continue\n                    xn = probe.copy()\n                    xn[idx] -= steps[idx]\n                    xn = clamp(xn)\n                    res = eval_and_record(xn)\n                    local_evals += 1\n                    if res is None:\n                        break\n                    fn, xn = res\n                    if fn < probe_f:\n                        probe = xn.copy()\n                        probe_f = fn\n                        improved = True\n                # pattern move\n                if improved and local_evals < local_budget and evals < self.budget:\n                    direction = probe - base\n                    if np.linalg.norm(direction) > 0:\n                        xp = base + pattern_factor * direction\n                        xp = clamp(xp)\n                        res = eval_and_record(xp)\n                        local_evals += 1\n                        if res is not None:\n                            fp, xp = res\n                            if fp < probe_f:\n                                base = xp.copy()\n                                base_f = fp\n                            else:\n                                base = probe.copy()\n                                base_f = probe_f\n                        else:\n                            base = probe.copy()\n                            base_f = probe_f\n                    else:\n                        base = probe.copy()\n                        base_f = probe_f\n                else:\n                    steps *= shrink\n                if evals >= self.budget:\n                    break\n            return base_f, base\n\n        # main loop\n        gen = 0\n        gens_since_improve = 0\n        no_improve_since = 0\n\n        # adaptive global jump probability uses tanh like No.1\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            # ranking and p-best pool\n            order = np.argsort(f)\n            pnum_min = max(2, int(np.ceil(self.p_frac * pop)))\n            p_pool = order[:max(pnum_min, 2)]\n            improved_in_gen = False\n\n            idxs = rng.permutation(pop)\n            for ii in idxs:\n                if evals >= self.budget:\n                    break\n                # jDE adaptation\n                if rng.rand() < tau1:\n                    F[ii] = np.clip(0.4 + 0.4 * rng.rand(), 0.05, 0.95)\n                if rng.rand() < tau2:\n                    CR[ii] = rng.rand()\n\n                # pick p-best\n                pbest_idx = int(rng.choice(p_pool))\n                # pick r1,r2 distinct\n                pool = [j for j in range(pop) if j not in (ii, pbest_idx)]\n                if len(pool) >= 2:\n                    r1, r2 = rng.choice(pool, size=2, replace=False)\n                elif len(pool) == 1:\n                    r1 = r2 = pool[0]\n                else:\n                    r1 = r2 = ii\n\n                xi = X[ii].copy()\n                xp = X[pbest_idx].copy()\n                xr1 = X[r1].copy()\n                xr2 = X[r2].copy()\n\n                # current-to-pbest/1 mutation (compact DE)\n                vi = xi + F[ii] * (xp - xi) + F[ii] * (xr1 - xr2)\n\n                # occasional archive-guided directional tweak to mutation (ADSS-inspired)\n                if len(archive) >= 2 and rng.rand() < 0.06:\n                    # nudge along difference between two elites scaled by diversity\n                    a, b = rng.choice(len(archive), size=2, replace=False)\n                    diff = archive[a][1] - archive[b][1]\n                    if np.linalg.norm(diff) > 0:\n                        vi += 0.2 * (diff / (np.linalg.norm(diff) + 1e-12)) * (np.mean(diversity_scale()) * rng.standard_t(self.student_df))\n\n                # crossover\n                jrand = rng.randint(self.dim)\n                mask = (rng.rand(self.dim) < CR[ii])\n                mask[jrand] = True\n                trial = np.where(mask, vi, xi)\n                trial = reflect_bounds(trial)\n\n                if evals >= self.budget:\n                    break\n                res = eval_and_record(trial)\n                if res is None:\n                    break\n                fv, trial = res\n                if fv <= f[ii]:\n                    X[ii] = trial\n                    f[ii] = fv\n                    if fv < f_best:\n                        f_best = fv\n                        x_best = trial.copy()\n                        improved_in_gen = True\n                        gens_since_improve = 0\n\n            if not improved_in_gen:\n                gens_since_improve += 1\n                no_improve_since += 1\n            else:\n                no_improve_since = 0\n\n            # adaptive global jump prob (tanh on no_improve_since)\n            p_global = min(0.9, max(0.03, self.global_base_prob * (1.0 + 0.5 * np.tanh((no_improve_since - 6) / 4.0))))\n\n            # occasional archive-guided Student-t heavy-tailed jumps\n            if rng.rand() < p_global and evals < self.budget:\n                if len(archive) > 0 and rng.rand() < 0.8:\n                    center = archive[0][1] if rng.rand() < 0.8 else archive[rng.randint(0, len(archive))][1]\n                else:\n                    center = x_best.copy() if x_best is not None else rng.uniform(lb, ub)\n                cand = studentt_jump(center, scale_factor=max(0.4, 1.0 - 0.02 * gen))\n                res = eval_and_record(cand)\n                if res is not None:\n                    f_cand, cand = res\n                    if f_cand < f_best:\n                        no_improve_since = 0\n                    else:\n                        no_improve_since += 1\n                    # promising candidate triggers small local polish\n                    threshold = archive[0][0] if len(archive) > 0 else np.inf\n                    if f_cand <= threshold * (1.06 + 0.02 * rng.rand()) and evals < self.budget:\n                        local_alloc = min(max(1, int(self.local_budget_frac * self.budget)), self.budget - evals)\n                        # be slightly random in allocation\n                        local_alloc = min(local_alloc, max(1, int(local_alloc * (0.6 + 0.8 * rng.rand()))))\n                        f_after, x_after = hooke_jeeves(cand, f_cand, local_alloc)\n                        if f_after < f_best:\n                            f_best = f_after\n                            x_best = x_after.copy()\n                            no_improve_since = 0\n\n            # occasional archive recombination injection\n            if rng.rand() < 0.08 and evals < self.budget:\n                child = recombine_archive()\n                res = eval_and_record(child)\n                if res is not None:\n                    fc, child = res\n                    if fc < f_best:\n                        f_best = fc\n                        x_best = child.copy()\n                        no_improve_since = 0\n\n            # periodic uniform injection to maintain diversity\n            if (gen % 23) == 0 and evals < self.budget:\n                xu = rng.uniform(lb, ub)\n                res = eval_and_record(xu)\n                if res is not None:\n                    fu, xu = res\n                    # replace random bad individual in population if beneficial\n                    worst_idx = int(np.argmax(f))\n                    if fu < f[worst_idx]:\n                        X[worst_idx] = xu.copy()\n                        f[worst_idx] = fu\n\n            # opportunistic Hooke-Jeeves around best if stagnating\n            if gens_since_improve >= 14 and evals < self.budget:\n                alloc = min(max(1, int(0.02 * self.budget)), self.budget - evals)\n                f_after, x_after = hooke_jeeves(x_best, f_best, alloc)\n                if f_after < f_best:\n                    f_best = f_after\n                    x_best = x_after.copy()\n                    # inject into population replacing worst\n                    worst_idx = int(np.argmax(f))\n                    X[worst_idx] = x_after.copy()\n                    f[worst_idx] = f_after\n                    gens_since_improve = 0\n                    no_improve_since = 0\n\n            # update archive from population-best\n            bi = int(np.argmin(f))\n            if f[bi] < f_best:\n                f_best = float(f[bi])\n                x_best = X[bi].copy()\n                gens_since_improve = 0\n                no_improve_since = 0\n            # ensure archive includes current best\n            if x_best is not None:\n                if len(archive) < archive_k or f_best < archive[-1][0]:\n                    archive.append((float(f_best), x_best.copy()))\n                    archive.sort(key=lambda t: t[0])\n                    if len(archive) > archive_k:\n                        archive.pop()\n\n            # mild adaptation of base global prob based on archive spread\n            if gen % 11 == 0 and len(archive) >= 2:\n                spread = np.linalg.norm(archive[0][1] - archive[-1][1])\n                if spread < 0.02 * avg_span:\n                    self.global_base_prob = min(0.85, self.global_base_prob + 0.03)\n                else:\n                    self.global_base_prob = max(0.03, self.global_base_prob * 0.995)\n\n            # ensure not to exceed budget\n            if evals >= self.budget:\n                break\n\n        # finalize\n        if x_best is None and len(archive) > 0:\n            f_best, x_best = archive[0]\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float) if x_best is not None else np.zeros(self.dim, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm DirectionalLevyjDE scored 0.470 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "7085e0ca-6bc0-45d8-b32a-44eb8685728e", "operator": null, "metadata": {"aucs": [0.11690978476985125, 0.16077017265524784, 0.9752022114536145, 0.9925671879212327, 0.21390627036047216, 0.9006810716212617, 0.2592936097145775, 0.39251096373669425, 0.5331086699272594, 0.1537264296376788]}, "task_prompt": ""}
{"id": "3fb1d17b-671f-44d8-8625-cf8b6753dc76", "fitness": "-inf", "name": "SACRA", "description": "The design centers on two spectral subspaces — U_exploit (online Oja-updated low-rank basis, default ~dim/6, oja_lr=0.05) for fast local modelling and V_explore (randomized, slowly rotating basis, default ~dim/8) for diversified directions, with an initial trust radius proportional to avg span (init_trust_rel=0.18). A lightweight low-rank quadratic surrogate (ridge-regularized, surrogate_reg=1e-6) is fitted in U (linear + per-subspace diagonal curvature) to propose a trust-limited subspace minimizer, while successful displacements are injected back into U/V via Oja and small mixing. Exploration is driven by a small operator pool (proj_surrogate, spectral_line, coord_momentum, finite_hessian, levy_escape, elite_recombine) whose selection is controlled by an EXP3-style multiplicative-weights scheme (log_w, gamma_explore≈0.07) with reward shaping that blends actual improvement and surrogate accuracy; per-dimension momentum and adaptive step_scale provide fine-grained local moves. Population/elite management, renyi-weighted batch aggregation toward a new center, spectral-entropy-based trust adaptation, and shrinkage-based anisotropic restarts (plus Lévy heavy tails) provide robustness to stagnation and preserve global diversification.", "code": "import numpy as np\n\nclass SACRA:\n    \"\"\"\n    Spectral Adaptive Covariance-Restarts Annealer (SACRA)\n\n    Key ideas / novelty:\n    - Maintain two spectral subspaces:\n        U_exploit: online low-rank basis (Oja-like) capturing recent successful displacements\n        V_explore: randomized exploratory basis that slowly rotates (to diversify exploration)\n    - Fit a lightweight low-rank quadratic surrogate in U_exploit (diagonal + low-rank correction)\n      to propose a subspace minimizer with trust-aware clipping.\n    - Maintain per-dimension momentum and adaptive step sizes (coordinate momentum) for fine local moves.\n    - Operators: subspace-surrogate minimizer, spectral line-search (along U or V vectors), coordinate-momentum step,\n                 finite-difference curvature probing (builds a cheap directional Hessian estimate), Lévy heavy escape,\n                 elite recombination (convex mix of elites + jitter).\n    - Operator allocator via EXP3-style multiplicative weights (softmax on log-weights), with reward shaped by\n      predicted vs actual improvement and normalized by recent scale.\n    - Center update blends mirror-like (logit) aggregation over batch with an annealed spectral temperature.\n    - Stagnation triggers a covariance-informed restart with anisotropic jitter and temporary exploration boost.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop=12, subspace_dim=None, explore_dim=None,\n                 init_trust=0.18, oja_lr=0.05, surrogate_reg=1e-6,\n                 q_mix=1.1, min_trust=1e-8, max_trust=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.rng = np.random.RandomState(seed)\n        self.pop = int(pop)\n        self.subspace_dim = subspace_dim if subspace_dim is not None else max(1, self.dim // 6)\n        # exploration subspace dimension (randomized basis)\n        self.explore_dim = explore_dim if explore_dim is not None else max(1, self.dim // 8)\n        self.init_trust_rel = float(init_trust)\n        self.oja_lr = float(oja_lr)\n        self.surrogate_reg = float(surrogate_reg)\n        self.q_mix = float(q_mix)\n        self.min_trust = float(min_trust)\n        self.max_trust = float(max_trust)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # handle bounds (support scalar or vector), fallback to [-5,5]\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        trust_radius = max(self.min_trust, self.init_trust_rel * avg_span)\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # small initialization sampling\n        init_samples = min(max(10, int(self.budget // 300)), max(12, self.pop * 3))\n        for _ in range(init_samples):\n            if evals >= self.budget: break\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        # ensure at least one sample\n        if len(f_arch) == 0 and evals < self.budget:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        # two centers: anchor (exploitation) and centroid (diversity/aggregation)\n        m = x_best.copy()\n        centroid = np.mean(np.asarray(X_arch), axis=0)\n\n        # initialize U_exploit (Oja) and V_explore (random rotational basis)\n        r = min(self.subspace_dim, self.dim)\n        U = rng.randn(self.dim, r)\n        try:\n            U, _ = np.linalg.qr(U)\n            U = U[:, :r]\n        except Exception:\n            U = U / (np.linalg.norm(U, axis=0, keepdims=True) + 1e-12)\n\n        s = min(self.explore_dim, self.dim)\n        V = rng.randn(self.dim, s)\n        try:\n            V, _ = np.linalg.qr(V)\n            V = V[:, :s]\n        except Exception:\n            V = V / (np.linalg.norm(V, axis=0, keepdims=True) + 1e-12)\n\n        # per-dimension momentum & adaptive step sizes\n        momentum = np.zeros(self.dim)\n        step_scale = np.full(self.dim, 0.08 * avg_span)\n        step_scale = np.clip(step_scale, 1e-8, 1.0 * avg_span)\n\n        # operator pool and exp3-style weights\n        operators = ['proj_surrogate', 'spectral_line', 'coord_momentum', 'finite_hessian', 'levy_escape', 'elite_recombine']\n        K_ops = len(operators)\n        log_w = np.zeros(K_ops)  # work in log-space for numerical stability\n        gamma_explore = 0.07  # exploration fraction for EXP3\n\n        # helpers\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch, x_best, f_best\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # keep archive manageable\n            max_arch = max(5 * (self.subspace_dim + self.explore_dim), 200)\n            if len(X_arch) > max_arch:\n                del X_arch[0:len(X_arch) - max_arch]\n                del f_arch[0:len(f_arch) - max_arch]\n            if fx < f_best:\n                x_best = x.copy(); f_best = float(fx)\n            return fx\n\n        def get_elites(k_frac=0.12):\n            n = len(X_arch)\n            if n == 0:\n                return np.empty((0, self.dim))\n            k = max(3, int(np.ceil(k_frac * max(20, n))))\n            idxs = np.argsort(f_arch)[:min(k, n)]\n            return np.asarray([X_arch[i].copy() for i in idxs])\n\n        # Robust shrinked covariance for restart/jitter\n        def shrink_cov(Xe, shrink=0.12):\n            if Xe.size == 0:\n                return np.eye(self.dim)\n            S = np.cov(Xe.T) if Xe.shape[0] > 1 else np.zeros((self.dim, self.dim))\n            F = np.trace(S) / max(1, self.dim)\n            C = (1.0 - shrink) * S + shrink * F * np.eye(self.dim)\n            C += 1e-10 * np.eye(self.dim)\n            return C\n\n        # Oja update for U_exploit using centered displacement z = x - m\n        def oja_step(Umat, z, lr):\n            if Umat.shape[1] == 0:\n                return Umat\n            zn = z / (np.linalg.norm(z) + 1e-12)\n            for j in range(Umat.shape[1]):\n                uj = Umat[:, j]\n                proj = np.dot(zn, uj)\n                uj = uj + lr * (zn * proj - uj * (proj ** 2 + 1e-12))\n                Umat[:, j] = uj\n            try:\n                Q, _ = np.linalg.qr(Umat)\n                return Q[:, :Umat.shape[1]]\n            except Exception:\n                norms = np.linalg.norm(Umat, axis=0) + 1e-12\n                return Umat / norms\n\n        # slowly rotate V_explore to avoid stale directions (random Givens-like)\n        def perturb_V(Vmat, amp=0.06):\n            if Vmat.shape[1] == 0:\n                return Vmat\n            # small gaussian rotation in subspace\n            R = np.eye(Vmat.shape[1]) + amp * (rng.randn(Vmat.shape[1], Vmat.shape[1]) * 0.5)\n            try:\n                Q = Vmat.dot(R)\n                Q, _ = np.linalg.qr(Q)\n                return Q[:, :Vmat.shape[1]]\n            except Exception:\n                return Vmat\n\n        # low-rank surrogate fit in U: model f ≈ c + g^T z + 0.5 * z^T Diag(h) z  (diagonal Hessian in subspace)\n        def fit_lowrank_quad(Umat, samples= None):\n            if Umat.shape[1] == 0 or len(X_arch) < (Umat.shape[1] + 4):\n                return None\n            if samples is None:\n                samples = min(160, max(30, Umat.shape[1] * 15))\n            K = min(samples, len(X_arch))\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(Umat)  # n x r\n            n, r = Z.shape\n            # features: [1, z1..zr, z1^2..zr^2], solve ridge\n            Phi = np.ones((n, 1 + r + r))\n            Phi[:, 1:1 + r] = Z\n            Phi[:, 1 + r:1 + r + r] = Z ** 2\n            try:\n                A = Phi.T.dot(Phi) + self.surrogate_reg * np.eye(Phi.shape[1])\n                b = Phi.T.dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1 + r]\n                Hdiag = coeff[1 + r:1 + r + r]\n                # bias toward small positive curvature but allow some negative for escape detection\n                Hdiag = np.clip(Hdiag, -1e-3, np.maximum(Hdiag, 1e-8))\n                # compute minimizer in subspace using trust-limited damped Newton for diag H\n                zstar = - g / (Hdiag + 1e-12)\n                # cap norm by trust radius projected into subspace\n                max_norm = (trust_radius / (np.linalg.norm(Umat, ord=2) + 1e-12)) * np.sqrt(max(1, r))\n                znorm = np.linalg.norm(zstar)\n                if znorm > max_norm:\n                    zstar = zstar * (max_norm / (znorm + 1e-12))\n                fpred = float(c + g.dot(zstar) + 0.5 * np.sum(Hdiag * (zstar ** 2)))\n                return (zstar, fpred, (g, Hdiag, c))\n            except Exception:\n                return None\n\n        # EXP3-like selection probabilities\n        def op_choose():\n            # softmax over log_w with exploration\n            maxlw = np.max(log_w)\n            exps = np.exp(log_w - maxlw)\n            p = (1.0 - gamma_explore) * (exps / (np.sum(exps) + 1e-12)) + gamma_explore / K_ops\n            idx = rng.choice(K_ops, p=p)\n            return operators[idx], idx, p[idx]\n\n        # mirror-like aggregation of a batch using Renyi-like weights (novel blend)\n        def renyi_weights(fs, alpha=0.9, temp=1.0):\n            # lower f higher weight. use transform w_i ∝ exp( - (f_i - fmin) / temp )^alpha\n            fmin = np.min(fs)\n            delta = (fs - fmin) / (temp + 1e-12)\n            w = np.exp(-delta) ** alpha\n            w = w / (np.sum(w) + 1e-12)\n            return w\n\n        # small auxiliary functions\n        def levy_step(scale):\n            # symmetric alpha-stable (approx Levy via Mantegna's algorithm with alpha=1.5)\n            beta = 0\n            sigma_u = (np.gamma(1 + 1.5) * np.sin(np.pi * 1.5 / 2) / (np.gamma((1 + 1.5) / 2) * 1.5 * 2 ** ((1.5 - 1) / 2))) ** (1 / 1.5)\n            u = rng.randn(self.dim) * sigma_u\n            v = rng.randn(self.dim)\n            step = u / (np.abs(v) ** (1.0 / 1.5))\n            return scale * step\n\n        # main optimization loop\n        gen = 0\n        stagn = 0\n        stagn_limit = max(10, int(0.02 * self.budget))\n\n        while evals < self.budget:\n            gen += 1\n\n            # recompute elites and diversity\n            Xe = get_elites()\n            Csh = shrink_cov(Xe)\n            # spectral entropy as diversity proxy\n            try:\n                cov_full = np.cov(np.asarray(X_arch).T) if len(X_arch) > 3 else np.eye(self.dim)\n                ev = np.linalg.eigvalsh(cov_full + 1e-12 * np.eye(self.dim))\n                ev = np.maximum(ev, 1e-16)\n                p_ev = ev / np.sum(ev)\n                diversity = -np.sum(p_ev * np.log(p_ev + 1e-12))\n            except Exception:\n                diversity = 0.0\n\n            # adjust trust slightly according to diversity and recent improvements\n            if diversity < 0.55:\n                trust_radius = min(self.max_trust, trust_radius * (1.02 + 0.004 * rng.rand()))\n            else:\n                trust_radius = max(self.min_trust, trust_radius * (0.997 - 0.001 * rng.rand()))\n\n            # candidate mini-batch this generation\n            n_batch = min(self.pop, max(1, self.budget - evals))\n            batch_X = []\n            batch_f = []\n            batch_opidx = []\n            batch_pred = []\n\n            # occasionally update exploratory basis\n            if rng.rand() < 0.3:\n                V = perturb_V(V, amp=0.045 * (1.0 + 0.5 * rng.rand()))\n\n            # fit surrogate once per generation on U\n            surrogate = fit_lowrank_quad(U)\n\n            for bi in range(n_batch):\n                if evals >= self.budget:\n                    break\n                op, idx, p_sel = op_choose()\n                x_cand = None; f_cand = None; pred = None\n\n                if op == 'proj_surrogate' and surrogate is not None:\n                    zstar, fpred, params = surrogate\n                    x_prop = m + U.dot(zstar)\n                    x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop; pred = fpred\n\n                elif op == 'spectral_line':\n                    # choose direction from U (exploit) or V (explore) with probability tuned by \"spectral temperature\"\n                    temp_spec = 0.6 * (1.0 + 0.5 * (0.6 - diversity))\n                    if U.shape[1] > 0 and rng.rand() < 0.6 + 0.3 * (1.0 - temp_spec):\n                        d = U[:, rng.randint(0, U.shape[1])]\n                    elif V.shape[1] > 0 and rng.rand() < 0.8:\n                        d = V[:, rng.randint(0, V.shape[1])]\n                    else:\n                        d = rng.randn(self.dim)\n                    d = d / (np.linalg.norm(d) + 1e-12)\n                    # perform small bracketed probes along multiple scales (log-scale)\n                    scales = np.array([0.25, 0.6, 1.2]) * trust_radius\n                    best_x = None; best_f = 1e99\n                    for s in scales:\n                        if evals >= self.budget: break\n                        for sign in (+1.0, -1.0):\n                            x_try = m + sign * s * d\n                            x_try = np.minimum(np.maximum(x_try, lb), ub)\n                            f_try = safe_eval(x_try)\n                            if f_try is None:\n                                break\n                            if f_try < best_f:\n                                best_f = f_try; best_x = x_try.copy()\n                    if best_x is not None:\n                        x_cand = best_x; f_cand = best_f\n\n                elif op == 'coord_momentum':\n                    # pick coord with largest recent movement or variance\n                    if len(X_arch) > 6:\n                        var = np.var(np.asarray(X_arch), axis=0)\n                        i = int(np.argmax(var))\n                    else:\n                        i = rng.randint(0, self.dim)\n                    # propose momentum-assisted step\n                    m_i = momentum[i]\n                    base = step_scale[i] * (0.9 + 0.4 * rng.rand()) * (trust_radius / (avg_span + 1e-12))\n                    cand = m.copy()\n                    cand[i] = np.clip(cand[i] - (0.6 * m_i + 0.4 * base), lb[i], ub[i])\n                    f_try = safe_eval(cand)\n                    if f_try is not None:\n                        x_cand = cand; f_cand = f_try\n                        # update momentum\n                        momentum[i] = 0.7 * m_i + 0.25 * (m[i] - cand[i])\n                        # adapt step scale on improvement\n                        if f_try < f_best - 1e-12:\n                            step_scale[i] = min(step_scale[i] * 1.15, avg_span)\n\n                elif op == 'finite_hessian':\n                    # probe curvature along a random spectral direction (combine a few U columns)\n                    if U.shape[1] > 0 and rng.rand() < 0.85:\n                        kdir = min(3, U.shape[1])\n                        inds = rng.choice(U.shape[1], kdir, replace=False)\n                        d = np.sum(U[:, inds], axis=1)\n                    else:\n                        d = rng.randn(self.dim)\n                    d = d / (np.linalg.norm(d) + 1e-12)\n                    eps = 0.06 * trust_radius + 1e-8\n                    x_plus = np.minimum(np.maximum(m + eps * d, lb), ub)\n                    x_minus = np.minimum(np.maximum(m - eps * d, lb), ub)\n                    f_plus = safe_eval(x_plus)\n                    if f_plus is None:\n                        break\n                    f_minus = safe_eval(x_minus)\n                    if f_minus is None:\n                        break\n                    # directional second derivative approx\n                    sec = (f_plus + f_minus - 2.0 * f_best) / ((eps ** 2) + 1e-12)\n                    # step proportional to curvature sign: if convex (sec>0) take small Newton-like step, else take larger step for escape\n                    if sec > 1e-8:\n                        step_len = min(1.2 * trust_radius, (abs((f_plus - f_minus) / (2 * eps + 1e-12)) / (sec + 1e-12)) )\n                    else:\n                        step_len = min(3.0 * trust_radius, 1.2 * trust_radius * (1.0 + rng.rand()))\n                    x_prop = np.minimum(np.maximum(m - np.sign(f_plus - f_minus) * step_len * d, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n\n                elif op == 'levy_escape':\n                    # heavy-tailed global moves centered at a random elite or centroid\n                    if Xe.size and rng.rand() < 0.7:\n                        center = Xe[rng.randint(0, Xe.shape[0])]\n                    else:\n                        center = centroid\n                    step = levy_step(2.2 * trust_radius)\n                    # clip extreme tail\n                    step = np.clip(step, -8.0 * trust_radius, 8.0 * trust_radius)\n                    x_prop = np.minimum(np.maximum(center + step, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n\n                elif op == 'elite_recombine':\n                    # convex recombination of two elites + small anisotropic jitter\n                    if Xe.size >= 2:\n                        i1, i2 = rng.choice(Xe.shape[0], size=2, replace=False)\n                        alpha = rng.beta(1.2, 1.2)\n                        child = alpha * Xe[i1] + (1.0 - alpha) * Xe[i2]\n                    else:\n                        child = m.copy()\n                    # anisotropic jitter using shrunk elite covariance\n                    C = shrink_cov(Xe)\n                    try:\n                        w, Vmat = np.linalg.eigh(C)\n                        w = np.maximum(w, 1e-12)\n                        sqrtC = Vmat.dot(np.diag(np.sqrt(w))).dot(Vmat.T)\n                        jitter = 0.9 * trust_radius * (0.5 * rng.randn(self.dim) + 0.5 * (sqrtC.dot(rng.randn(self.dim))))\n                    except Exception:\n                        jitter = 0.9 * trust_radius * rng.randn(self.dim)\n                    x_prop = np.minimum(np.maximum(child + jitter, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n\n                # record candidate and update meta components\n                if f_cand is not None:\n                    batch_X.append(x_cand.copy())\n                    batch_f.append(f_cand)\n                    batch_opidx.append(idx)\n                    batch_pred.append(pred if pred is not None else f_cand)\n\n                    # reward shaping: improvement over current best + predicted vs actual factor\n                    imp = max(0.0, f_best - f_cand)\n                    # predicted improvement if given: (pred - f_cand) normalized\n                    pred_diff = 0.0\n                    if pred is not None:\n                        pred_diff = max(-1.0, min(1.0, (pred - f_cand) / (abs(f_best) + 1e-12)))\n                    # reward combines actual improvement and surrogate accuracy, scaled\n                    reward = 0.6 * (imp / (abs(f_best) + 1e-12)) + 0.4 * pred_diff\n                    reward = max(-0.2, min(1.2, reward))\n\n                    # EXP3 multiplicative update on log_w\n                    eta = min(0.25, 1.0 / np.sqrt(1 + gen))\n                    # importance-weighted estimated reward\n                    # compute selection probability used earlier as p_sel approximation by normalizing exp(log_w)\n                    maxlw = np.max(log_w)\n                    exps_local = np.exp(log_w - maxlw)\n                    prob_local = exps_local / (np.sum(exps_local) + 1e-12)\n                    # estimated reward for chosen arm\n                    est = reward / (prob_local[idx] + 1e-12)\n                    log_w[idx] += eta * est\n\n                    # mild decay to maintain exploration (spread logs slightly)\n                    log_w = np.clip(log_w - 1e-4 * rng.rand(K_ops), -20.0, 50.0)\n\n                    # update spectral bases via Oja and small injection into V\n                    zc = x_cand - m\n                    U = oja_step(U, zc, lr=self.oja_lr * (0.5 + 0.5 * rng.rand()))\n                    # occasionally inject successful displacement into V to diversify direction pool\n                    if rng.rand() < 0.22:\n                        if V.shape[1] > 0:\n                            j = rng.randint(0, V.shape[1])\n                            newcol = zc / (np.linalg.norm(zc) + 1e-12)\n                            V[:, j] = 0.85 * V[:, j] + 0.15 * newcol\n                            try:\n                                V, _ = np.linalg.qr(V)\n                                V = V[:, :V.shape[1]]\n                            except Exception:\n                                V = V / (np.linalg.norm(V, axis=0, keepdims=True) + 1e-12)\n\n                    # trust adaptation and stagnation handling\n                    if f_cand < f_best - 1e-12:\n                        f_best = float(f_cand); x_best = x_cand.copy()\n                        trust_radius = max(self.min_trust, trust_radius * 0.8)\n                        stagn = 0\n                    else:\n                        trust_radius = min(self.max_trust, trust_radius * (1.005 + 0.002 * rng.rand()))\n                        stagn += 1\n\n                else:\n                    break  # budget exhausted\n\n            # center aggregation: mix centroid and elite-weighted mean using renyi weights and spectral temperature\n            if len(batch_X) > 0:\n                Xs = np.asarray(batch_X)\n                Fs = np.asarray(batch_f)\n                temp = max(1e-6, 0.6 * (trust_radius / (avg_span + 1e-12)) * (1.0 + 0.6 * (0.8 - diversity)))\n                weights = renyi_weights(Fs, alpha=0.92, temp=temp)\n                xr = np.sum(weights[:, None] * Xs, axis=0)\n                # compute a combined center move: mix toward xr and centroid, with geometry-aware clipping\n                mix = 0.5 if trust_radius < 0.4 * avg_span else 0.3\n                new_m = (1.0 - mix) * m + mix * xr\n                # small pull to centroid to maintain diversity\n                new_m = 0.85 * new_m + 0.15 * centroid\n                # bound the jump\n                delta = new_m - m\n                max_jump = 3.5 * trust_radius * np.sqrt(max(1, self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > max_jump:\n                    delta = delta * (max_jump / (dn + 1e-12))\n                m = np.minimum(np.maximum(m + delta, lb), ub)\n\n                # slight shrink if batch contained improvements\n                if np.any(Fs < f_best):\n                    trust_radius = max(self.min_trust, trust_radius * 0.88)\n                else:\n                    trust_radius = min(self.max_trust, trust_radius * 1.02)\n\n            # update centroid periodically from archive\n            if len(X_arch) > 4 and gen % 3 == 0:\n                centroid = np.mean(np.asarray(X_arch[-min(len(X_arch), 40):]), axis=0)\n\n            # stagnation-driven restart\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                # pick center from elite or best\n                if Xe.size:\n                    new_center = Xe[rng.randint(0, Xe.shape[0])]\n                else:\n                    new_center = x_best.copy()\n                C = shrink_cov(Xe)\n                try:\n                    w, Vc = np.linalg.eigh(C)\n                    w = np.maximum(w, 1e-12)\n                    sqrtC = Vc.dot(np.diag(np.sqrt(w))).dot(Vc.T)\n                except Exception:\n                    sqrtC = np.eye(self.dim)\n                jitter_scale = max(0.07 * avg_span, 1.6 * trust_radius)\n                m = np.minimum(np.maximum(new_center + jitter_scale * (0.6 * rng.randn(self.dim) + 0.4 * (sqrtC.dot(rng.randn(self.dim)))), lb), ub)\n                trust_radius = min(self.max_trust, trust_radius * 1.7)\n                # reseed a few local points around best\n                for _ in range(min(8, self.budget - evals)):\n                    x = np.minimum(np.maximum(x_best + 0.04 * avg_span * rng.randn(self.dim), lb), ub)\n                    f = safe_eval(x)\n                    if f is None:\n                        break\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "error": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "parent_ids": "b49a045b-62d7-481c-95dd-d06c3592f774", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "48f2b710-e0f3-41a3-8ff4-780f77f12d71", "fitness": 0.21259407299214228, "name": "EASTS", "description": "EASTS is an ensemble-driven adaptive subspace trust search that maintains a small streaming low-dimensional basis U (default ≈ dim//4) and a trust radius (trust_init_rel=0.25) to generate budget-aware, bounded proposals while keeping an archive of evaluated points. It fits a ridge-regularized quadratic surrogate in the subspace (diagonal Hessian plus one low-rank v v^T correction estimated from residuals) to propose trust-limited minimizers, and updates U with an Oja-like, QR-stabilized rule using a small streaming rate (sub_lr=0.02). Multiple complementary operators (subspace quasi-Newton, direction-polynomial line fits, coordinate-adaptive steps with per-dimension rates, finite-difference directions, heavy-tailed Lévy jumps, and Gaussian walks) are selected by exponentiated-gradient (Hedge) log-weights that decay (op_decay=0.98) and scale with 1/sqrt(gen). The algorithm aggregates successful candidates via a rank-weighted softmax centroid, adapts trust by diversity and predicted-vs-actual improvement heuristics, employs shrinkage covariance for elites, and triggers targeted restarts with local reseeding when stagnation occurs.", "code": "import numpy as np\n\nclass EASTS:\n    \"\"\"\n    Ensemble Adaptive Subspace Trust Search (EASTS)\n\n    Key differences / design notes (compared to the supplied DARTS-like algorithm):\n    - Subspace dimension default is larger (≈ dim//4) and Oja-like streaming learning rate is smaller.\n    - Surrogate in subspace: a ridge regularized quadratic with a diagonal Hessian plus a single\n      low-rank correction (v v^T) estimated from residuals (different equation form).\n    - Operator allocation uses exponentiated gradient (\"Hedge\") updates instead of simple multiplicative\n      updates; op decay is stronger to keep exploration.\n    - Center update uses a rank-weighted centroid via softmax on negative fitness (different aggregation).\n    - Trust adapts via a predicted-vs-actual improvement ratio and short-term success probability.\n    - Different default parameter values: trust_init_rel=0.25, sub_lr=0.02, op_decay=0.98, hedge_eta scaling = 1/sqrt(gen+1).\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop=14, subspace_dim=None,\n                 trust_init_rel=0.25, sub_lr=0.02, surrogate_reg=1e-5,\n                 hedge_eta_base=1.0, op_decay=0.98,\n                 min_trust=1e-8, max_trust=5.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.rng = np.random.RandomState(seed)\n        self.pop = int(pop)\n        self.subspace_dim = subspace_dim if subspace_dim is not None else max(1, self.dim // 4)\n        self.trust_init_rel = float(trust_init_rel)\n        self.sub_lr = float(sub_lr)\n        self.surrogate_reg = float(surrogate_reg)\n        self.hedge_eta_base = float(hedge_eta_base)\n        self.op_decay = float(op_decay)\n        self.min_trust = float(min_trust)\n        self.max_trust = float(max_trust)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        trust_radius = max(self.min_trust, self.trust_init_rel * avg_span)\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # initial sampling (small budget-aware)\n        seed0 = min(max(10, int(self.budget // 250)), max(16, self.pop * 4))\n        for _ in range(seed0):\n            if evals >= self.budget: break\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        if len(f_arch) == 0 and evals < self.budget:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        # center\n        m = x_best.copy()\n\n        # initialize streaming subspace basis U (columns orthonormal)\n        r = min(self.subspace_dim, self.dim)\n        if r > 0:\n            U = rng.randn(self.dim, r)\n            try:\n                U, _ = np.linalg.qr(U)\n                U = U[:, :r]\n            except Exception:\n                U = U / (np.linalg.norm(U, axis=0, keepdims=True) + 1e-12)\n        else:\n            U = np.zeros((self.dim, 0))\n\n        # per-dimension step sizes (smaller than DARTS)\n        per_dim_lr = np.full(self.dim, 0.08 * avg_span)\n        per_dim_lr = np.clip(per_dim_lr, 1e-8, 2.0 * avg_span)\n\n        # operators and hedge weights (exponentiated gradient)\n        operators = ['subspace_qn', 'dir_poly', 'coord_adapt', 'fin_dir', 'levy_jump', 'gauss_walk']\n        w_log = np.zeros(len(operators))  # log-weights for Hedge\n        op_index = {op: i for i, op in enumerate(operators)}\n\n        # safe evaluation helper\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch, x_best, f_best\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # keep archive bounded\n            max_archive = max(6 * self.subspace_dim, 4 * self.pop, 250)\n            if len(X_arch) > max_archive:\n                del X_arch[0:(len(X_arch) - max_archive)]\n                del f_arch[0:(len(f_arch) - max_archive)]\n            if fx < f_best:\n                x_best = x.copy(); f_best = float(fx)\n            return fx\n\n        # robust covariance for elites (shrink)\n        def shrink_cov(Xe, shrink=0.12):\n            if Xe.size == 0:\n                return np.eye(self.dim)\n            S = np.cov(Xe.T) if Xe.shape[0] > 1 else np.zeros((self.dim, self.dim))\n            F = np.trace(S) / max(1, self.dim)\n            C = (1.0 - shrink) * S + shrink * F * np.eye(self.dim)\n            C += 1e-10 * np.eye(self.dim)\n            return C\n\n        # streaming incremental basis update (variant of Oja but with Gram-Schmidt)\n        def subspace_update(Umat, z, lr):\n            if Umat.shape[1] == 0:\n                return Umat\n            zn = z / (np.linalg.norm(z) + 1e-12)\n            # update projection onto each basis followed by reorthogonalization\n            for j in range(Umat.shape[1]):\n                uj = Umat[:, j]\n                proj = np.dot(zn, uj)\n                uj = uj + lr * (proj * (zn - proj * uj))\n                Umat[:, j] = uj\n            # orthonormalize\n            try:\n                Q, _ = np.linalg.qr(Umat)\n                return Q[:, :Umat.shape[1]]\n            except Exception:\n                norms = np.linalg.norm(Umat, axis=0) + 1e-12\n                return Umat / norms\n\n        # subspace surrogate fit: diagonal Hessian + one low-rank correction learned from residuals\n        def fit_subspace_quadratic(Umat, K_samples=None):\n            if Umat.shape[1] == 0 or len(X_arch) < (Umat.shape[1] + 6):\n                return None\n            r = Umat.shape[1]\n            K = K_samples if K_samples is not None else min(160, max(30, r * 14))\n            K = min(K, len(X_arch))\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(Umat)  # n x r\n            n = Z.shape[0]\n            # design: [1, z_i (r), z_i^2 diag (r)]\n            Phi = np.ones((n, 1 + r + r))\n            Phi[:, 1:1 + r] = Z\n            Phi[:, 1 + r:1 + r + r] = Z ** 2\n            # ridge solve\n            try:\n                A = Phi.T.dot(Phi) + self.surrogate_reg * np.eye(Phi.shape[1])\n                b = Phi.T.dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1 + r]\n                Hdiag = coeff[1 + r:1 + r + r]\n                # regularize Hessian diag and ensure positive curvature floor\n                Hdiag = np.maximum(Hdiag, 5e-9)\n                # compute residuals and approximate a single low-rank correction direction v (in subspace)\n                preds = Phi.dot(coeff)\n                resid = Fr - preds\n                # if residual variance significant, estimate principal residual direction in subspace\n                if np.var(resid) > 1e-12 and n >= r + 2:\n                    # compute correlation of residual with z to find a rank-1 correction\n                    corr = (resid[:, None] * Z).mean(axis=0)\n                    v = corr.copy()\n                    vn = np.linalg.norm(v) + 1e-12\n                    v = v / vn\n                    alpha = (resid.dot(Z.dot(v))) / (n + 1e-12)\n                else:\n                    v = np.zeros(r)\n                    alpha = 0.0\n                # minimizer in subspace for quadratic: solve diag + rank1 correction approx by simple fixed-point:\n                # we solve (Hdiag + alpha * v v^T) z = -g  => use Sherman-Morrison to invert approximately\n                Hd = Hdiag + 1e-12\n                invHd = 1.0 / Hd\n                denom = 1.0 + alpha * (v * invHd).dot(v)\n                zstar = - invHd * g\n                if abs(denom) > 1e-12:\n                    zstar = zstar - (alpha * ((v.dot(zstar)) * (invHd * v))) / denom\n                # clamp step magnitude in subspace by trust\n                max_norm = (trust_radius / (np.linalg.norm(Umat, ord=2) + 1e-12)) * np.sqrt(max(1, r))\n                znorm = np.linalg.norm(zstar)\n                if znorm > max_norm:\n                    zstar = zstar * (max_norm / (znorm + 1e-12))\n                fpred = float(c + g.dot(zstar) + 0.5 * np.sum(Hdiag * (zstar ** 2)) + 0.5 * alpha * (v.dot(zstar)) ** 2)\n                return zstar, fpred, (g, Hdiag, c, v, alpha)\n            except Exception:\n                return None\n\n        # rank-weighted centroid: softmax on -f (lower f -> higher weight)\n        def rank_soft_centroid(Xs, Fs, temp=1.0):\n            # negative fitness because lower is better\n            vals = -np.asarray(Fs) / (temp + 1e-12)\n            # stabilize\n            vals = vals - np.max(vals)\n            w = np.exp(vals)\n            w = w / (np.sum(w) + 1e-12)\n            return np.sum(w[:, None] * Xs, axis=0), w\n\n        # choose operator by exponentiated weights probabilities\n        def choose_operator():\n            probs = np.exp(w_log - np.max(w_log))\n            probs = probs / (np.sum(probs) + 1e-12)\n            idx = rng.choice(len(operators), p=probs)\n            return operators[idx], idx\n\n        # elite set helper\n        def get_elites(k_frac=0.15):\n            n = len(X_arch)\n            if n == 0:\n                return np.empty((0, self.dim))\n            k = max(4, int(np.ceil(k_frac * max(30, n))))\n            idxs = np.argsort(f_arch)[:min(k, n)]\n            return np.asarray([X_arch[i].copy() for i in idxs])\n\n        # main loop\n        stagn = 0\n        stagn_limit = max(12, int(0.03 * self.budget))\n        gen = 0\n\n        while evals < self.budget:\n            gen += 1\n\n            Xe = get_elites()\n            Csh = shrink_cov(Xe) if Xe.size else np.eye(self.dim)\n            # diversity measure (normalized entropy of eigenspectrum)\n            try:\n                cov_all = (np.cov(np.asarray(X_arch).T) if len(X_arch) > 3 else np.eye(self.dim) * (avg_span ** 2 / 12.0))\n                ev = np.linalg.eigvalsh(cov_all + 1e-12 * np.eye(self.dim))\n                ev = np.maximum(ev, 1e-16)\n                p = ev / np.sum(ev)\n                diversity = -np.sum(p * np.log(p + 1e-12))\n            except Exception:\n                diversity = 0.0\n\n            # slight trust adaptation by diversity\n            if diversity < 0.5:\n                trust_radius = min(self.max_trust, trust_radius * (1.03 + 0.01 * rng.rand()))\n            else:\n                trust_radius = max(self.min_trust, trust_radius * (0.995 - 0.002 * rng.rand()))\n\n            # batch size\n            n_batch = min(self.pop, max(1, self.budget - evals))\n            batch_X = []\n            batch_f = []\n            batch_ops = []\n            # fit surrogate\n            surrogate = fit_subspace_quadratic(U)\n\n            for bi in range(n_batch):\n                if evals >= self.budget:\n                    break\n                op, idx = choose_operator()\n                x_cand = None\n                f_c = None\n                predicted = None\n\n                if op == 'subspace_qn' and surrogate is not None:\n                    zstar, fpred, params = surrogate\n                    x_prop = m + U.dot(zstar)\n                    x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop; predicted = fpred\n\n                elif op == 'dir_poly':\n                    # pick a principal or random direction\n                    if U.shape[1] > 0 and rng.rand() < 0.8:\n                        j = rng.randint(0, U.shape[1])\n                        d = U[:, j]\n                    else:\n                        d = rng.randn(self.dim); d /= (np.linalg.norm(d) + 1e-12)\n                    # sample three points along direction to fit a quadratic along the line and estimate minimizer\n                    scales = np.array([-1.0, 0.0, 1.0]) * trust_radius\n                    pts = []\n                    fs = []\n                    for s in scales:\n                        if evals >= self.budget: break\n                        x_try = m + s * d\n                        x_try = np.minimum(np.maximum(x_try, lb), ub)\n                        f_try = safe_eval(x_try)\n                        if f_try is None:\n                            break\n                        pts.append(x_try.copy()); fs.append(f_try)\n                    if len(fs) == 3:\n                        # fit quadratic a*s^2 + b*s + c to (s, f)\n                        svals = scales\n                        A = np.vstack([svals ** 2, svals, np.ones_like(svals)]).T\n                        try:\n                            coeff = np.linalg.lstsq(A, np.asarray(fs), rcond=None)[0]\n                            a, b, c = coeff\n                            if abs(a) > 1e-12:\n                                smin = -b / (2.0 * a)\n                                smin = np.clip(smin, -2.0 * trust_radius, 2.0 * trust_radius)\n                                x_prop = m + smin * d\n                                x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                                f_prop = safe_eval(x_prop)\n                                if f_prop is not None:\n                                    x_cand = x_prop; f_c = f_prop; predicted = float(c - (b ** 2) / (4.0 * a)) if a > 0 else None\n                            else:\n                                # fallback take best of the three\n                                best_idx = int(np.argmin(fs))\n                                x_cand = pts[best_idx]; f_c = fs[best_idx]\n                        except Exception:\n                            best_idx = int(np.argmin(fs))\n                            x_cand = pts[best_idx]; f_c = fs[best_idx]\n\n                elif op == 'coord_adapt':\n                    # choose coordinate with largest archive variance or random\n                    if len(X_arch) > 4:\n                        var = np.var(np.asarray(X_arch), axis=0)\n                        i = int(np.argmax(var))\n                    else:\n                        i = rng.randint(0, self.dim)\n                    step = per_dim_lr[i] * (trust_radius / (avg_span + 1e-12))\n                    # try also a damped 1D golden-step style: try 0.5 and 1.0\n                    tries = [step, 0.5 * step, -step]\n                    improved = False\n                    for s in tries:\n                        if evals >= self.budget: break\n                        x_try = m.copy()\n                        x_try[i] = np.clip(x_try[i] + s, lb[i], ub[i])\n                        f_try = safe_eval(x_try)\n                        if f_try is None:\n                            break\n                        if f_try < f_best - 1e-12:\n                            per_dim_lr[i] = min(per_dim_lr[i] * 1.15, 2.0 * avg_span)\n                            improved = True\n                            x_cand = x_try; f_c = f_try; break\n                    if not improved and x_cand is None:\n                        # small gaussian jitter fallback\n                        x_try = m + 0.5 * trust_radius * rng.randn(self.dim)\n                        x_try = np.minimum(np.maximum(x_try, lb), ub)\n                        f_try = safe_eval(x_try)\n                        if f_try is not None:\n                            x_cand = x_try; f_c = f_try\n                        per_dim_lr[i] = max(per_dim_lr[i] * 0.95, 1e-8)\n\n                elif op == 'fin_dir':\n                    # directional finite difference on a random linear combination of top U columns\n                    if U.shape[1] > 0 and rng.rand() < 0.85:\n                        kdir = min(3, U.shape[1])\n                        inds = rng.choice(U.shape[1], kdir, replace=False)\n                        d = np.sum(U[:, inds], axis=1)\n                    else:\n                        d = rng.randn(self.dim)\n                    d = d / (np.linalg.norm(d) + 1e-12)\n                    eps = 0.05 * trust_radius + 1e-8\n                    x_plus = np.minimum(np.maximum(m + eps * d, lb), ub)\n                    x_minus = np.minimum(np.maximum(m - eps * d, lb), ub)\n                    f_plus = safe_eval(x_plus)\n                    if f_plus is None:\n                        break\n                    f_minus = safe_eval(x_minus)\n                    if f_minus is None:\n                        break\n                    gdir = (f_plus - f_minus) / (2.0 * eps + 1e-12)\n                    # step length proportional to observed directional curvature heuristic\n                    step_len = min(1.8 * trust_radius, max(0.25 * trust_radius, abs(gdir) * 0.8 * trust_radius))\n                    x_prop = np.minimum(np.maximum(m - np.sign(gdir) * step_len * d, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                elif op == 'levy_jump':\n                    # Levy / Pareto-like heavy tail using a composition of Cauchy and Pareto scaling\n                    if Xe.size and rng.rand() < 0.7:\n                        center = Xe[rng.randint(0, Xe.shape[0])]\n                    else:\n                        center = m\n                    z = rng.standard_cauchy(size=self.dim) * (1.0 + rng.pareto(a=1.5, size=self.dim))\n                    clipv = np.percentile(np.abs(z), 90) + 1e-12\n                    z = z / clipv\n                    step = 4.5 * trust_radius * z\n                    x_prop = np.minimum(np.maximum(center + step, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                else:  # gauss_walk\n                    sigma = 0.85 * trust_radius * (0.5 + 0.9 * rng.rand())\n                    x_prop = np.minimum(np.maximum(m + sigma * rng.randn(self.dim), lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                # record candidate and adapt online\n                if f_c is not None:\n                    batch_X.append(x_cand.copy()); batch_f.append(f_c); batch_ops.append(op)\n\n                    # reward: scaled improvement relative to recent median to avoid tiny numbers\n                    baseline = np.median(f_arch[-min(len(f_arch), 25):]) if len(f_arch) >= 3 else f_best\n                    reward = max(0.0, (baseline - f_c) / (abs(baseline) + 1e-12))\n                    # Hedge exponentiated update (log-space)\n                    hedge_eta = self.hedge_eta_base / (np.sqrt(gen) + 1.0)\n                    w_log[idx] = w_log[idx] + hedge_eta * reward\n                    # decay all logs slightly to encourage exploration\n                    w_log = w_log * self.op_decay\n\n                    # update subspace\n                    zc = x_cand - m\n                    U = subspace_update(U, zc, lr=self.sub_lr * (0.4 + 0.6 * rng.rand()))\n\n                    # trust adaptation: if improved global best shrink more, else mild increase\n                    if f_c < f_best - 1e-12:\n                        trust_radius = max(self.min_trust, trust_radius * 0.78)\n                        stagn = 0\n                        f_best = float(f_c); x_best = x_cand.copy()\n                    else:\n                        trust_radius = min(self.max_trust, trust_radius * 1.015)\n                        stagn += 1\n\n                else:\n                    break  # budget exhausted\n\n            # center update via rank-weighted centroid if we have batch\n            if len(batch_X) > 0:\n                Xs = np.asarray(batch_X)\n                Fs = np.asarray(batch_f)\n                # temperature adapt: larger trust -> larger temp\n                temp = max(1e-6, 0.6 + 1.2 * (trust_radius / (avg_span + 1e-12)) + 0.4 * (0.5 - diversity))\n                x_mean, wts = rank_soft_centroid(Xs, Fs, temp=temp)\n                lr_center = 0.5 if trust_radius < 0.4 * avg_span else 0.28\n                delta = x_mean - m\n                # cap max jump\n                max_jump = 3.0 * trust_radius * np.sqrt(max(1, self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > max_jump:\n                    delta = delta * (max_jump / (dn + 1e-12))\n                m = np.minimum(np.maximum(m + lr_center * delta, lb), ub)\n\n                # predicted vs actual check if surrogate used in batch; adjust trust accordingly\n                if surrogate is not None and any([op == 'subspace_qn' for op in batch_ops]):\n                    # find first subspace candidate in batch\n                    for xi, fi, op in zip(Xs, Fs, batch_ops):\n                        if op == 'subspace_qn':\n                            # predicted was stored earlier? recompute quick projection\n                            z = (xi - m).dot(U)\n                            # crude quadratic predicted via diagonal Hessian approx from surrogate params (if available)\n                            # here we do a rough predicted improvement: old predicted baseline f_best_pred maybe unknown;\n                            # adopt simple heuristic: if actual << median then shrink, else mildly enlarge\n                            if fi < np.median(Fs):\n                                trust_radius = max(self.min_trust, trust_radius * 0.85)\n                            else:\n                                trust_radius = min(self.max_trust, trust_radius * 1.04)\n                            break\n\n                # if any improved in batch, be more aggressive shrinking\n                if np.any(Fs < f_best):\n                    trust_radius = max(self.min_trust, trust_radius * 0.88)\n                else:\n                    trust_radius = min(self.max_trust, trust_radius * 1.03)\n\n            # targeted restart if stagnation\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                if Xe.size:\n                    center = Xe[rng.randint(0, Xe.shape[0])]\n                else:\n                    center = x_best\n                C = shrink_cov(Xe)\n                try:\n                    w_e, V = np.linalg.eigh(C)\n                    w_e = np.maximum(w_e, 1e-12)\n                    S_sqrt = V.dot(np.diag(np.sqrt(w_e))).dot(V.T)\n                except Exception:\n                    S_sqrt = np.eye(self.dim)\n                jitter = max(0.06 * avg_span, 2.2 * trust_radius)\n                m = np.minimum(np.maximum(center + jitter * (0.6 * rng.randn(self.dim) + 0.4 * (S_sqrt.dot(rng.randn(self.dim)))), lb), ub)\n                trust_radius = min(self.max_trust, trust_radius * 1.8)\n                # local reseeding\n                reseed = min(8, self.budget - evals)\n                for _ in range(reseed):\n                    if evals >= self.budget: break\n                    x = np.minimum(np.maximum(x_best + 0.04 * avg_span * rng.randn(self.dim), lb), ub)\n                    f = safe_eval(x)\n                    if f is None:\n                        break\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm EASTS scored 0.213 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b49a045b-62d7-481c-95dd-d06c3592f774", "operator": null, "metadata": {"aucs": [0.13172742696182438, 0.18825844172920803, 0.25807408330643045, 0.23537403391320055, 0.2236015765987983, 0.24213350775818165, 0.22877480494975722, 0.23362433043014752, 0.2189946153966169, 0.16537790887725756]}, "task_prompt": ""}
{"id": "8c54a8ad-03a6-4535-a52c-9bd9dbc5e288", "fitness": "-inf", "name": "AMDE", "description": "AMDE maintains an evaluated archive and a mirror-centered search point m, adapting a trust radius (initialized as 0.25×avg span) and per-dimension accumulators (AdaGrad-like accum_sq and per_dim_step) to scale moves and form a mirror update. It learns a streaming low-rank subspace B via an Oja-like update (default subspace_dim ≈ dim/6) and keeps a short momentum memory to generate correlated proposals, while trimming the archive and orthonormalizing B for stability. A small ensemble of complementary operators (multiscale Gaussian, heavy‑tailed Cauchy, principal-component line probes, elite recombination, a subspace quadratic minimizer fitted with ridge regression, and a diagonal quasi‑Newton step) is selected by exponential hedge weights (hedge_eta=0.8) that are updated from observed rewards. The algorithm fits a lightweight quadratic surrogate inside B (regularized), constrains its minimizer by trust, aggregates batch evaluations with tempered softmin weighting, adaptively shrinks/expands trust from success/diversity, and performs targeted anisotropic reseeds on stagnation — all under strict budgeted safe_eval and bounds clipping.", "code": "import numpy as np\n\nclass AMDE:\n    \"\"\"\n    Adaptive Multi-scale Directional Ensemble (AMDE)\n\n    Key ideas (concise):\n    - Maintain an evaluated archive and a center m.\n    - Learn a streaming low-rank basis B from successful steps (Oja-like) and keep a small momentum memory.\n    - Maintain per-dimension adaptive scaling (accumulated squared step sizes) like AdaGrad to form a mirror update.\n    - Use a small set of complementary operators (Gaussian, Cauchy, principal-component lines, elite mixtures,\n      subspace quadratic minimizer, and diagonal quasi-Newton steps). Allocate budget with exponential hedge updates.\n    - Fit a lightweight quadratic surrogate inside the learned subspace (including a few cross terms) to propose a minimizer.\n    - Center update is a mirror aggregation using inverse-root accumulated squared steps to temper moves.\n    - Adaptive trust is multi-scale and adjusts according to recent success rate and predicted vs actual improvement.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop=14, subspace_dim=None,\n                 init_trust=0.25, oja_lr=0.05, surrogate_reg=1e-6,\n                 hedge_eta=0.8, min_trust=1e-8, max_trust=6.0,\n                 momentum_size=6):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.rng = np.random.RandomState(seed)\n        self.pop = int(pop)\n        self.subspace_dim = subspace_dim if subspace_dim is not None else max(1, self.dim // 6)\n        self.init_trust_rel = float(init_trust)\n        self.oja_lr = float(oja_lr)\n        self.surrogate_reg = float(surrogate_reg)\n        self.hedge_eta = float(hedge_eta)\n        self.min_trust = float(min_trust)\n        self.max_trust = float(max_trust)\n        self.momentum_size = int(momentum_size)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling (support scalar or vector); Many BBOB uses [-5,5]\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        trust_radius = max(self.min_trust, self.init_trust_rel * avg_span)\n\n        # archive and bookkeeping\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # small initialization: sample a bit to seed archive and basis\n        init_samples = min(max(8, int(self.budget // 300)), max(12, self.pop * 3))\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        # ensure at least one point\n        if len(f_arch) == 0 and evals < self.budget:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        # center\n        m = x_best.copy()\n\n        # initialize low-rank basis B (streaming / Oja-like)\n        r = min(self.subspace_dim, self.dim)\n        if r > 0:\n            B = rng.randn(self.dim, r)\n            try:\n                B, _ = np.linalg.qr(B)\n                B = B[:, :r]\n            except Exception:\n                B = B / (np.linalg.norm(B, axis=0, keepdims=True) + 1e-12)\n        else:\n            B = np.zeros((self.dim, 0))\n\n        # per-dimension accumulators (AdaGrad-like) for mirror scaling and quasi-diagonal curvature\n        accum_sq = np.full(self.dim, 1e-6)  # accumulate squared steps (starts small)\n        per_dim_step = np.full(self.dim, 0.06 * avg_span)  # adaptive step lengths\n\n        # momentum memory of successful normalized steps (to generate correlated proposals)\n        momentum = []\n\n        # operator set and hedge weights (exponential weights)\n        operators = ['gauss', 'cauchy', 'pc_line', 'elite_mix', 'subspace_quad', 'diag_qn']\n        w_op = np.ones(len(operators), dtype=float)\n        op_index = {op: i for i, op in enumerate(operators)}\n\n        # safe eval enforcing budget and archive trimming\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch, x_best, f_best\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # trim archive length (keep recent + elites)\n            max_archive = max(8 * self.subspace_dim, 4 * self.pop, 300)\n            if len(X_arch) > max_archive:\n                del X_arch[0:(len(X_arch) - max_archive)]\n                del f_arch[0:(len(f_arch) - max_archive)]\n            if fx < f_best:\n                x_best = x.copy(); f_best = float(fx)\n            return fx\n\n        # Oja-like update for basis B from a new step s (centered)\n        def update_basis(Bmat, step_vec, lr):\n            if Bmat.shape[1] == 0:\n                return Bmat\n            # normalize input step to avoid scale issues\n            z = step_vec / (np.linalg.norm(step_vec) + 1e-12)\n            for j in range(Bmat.shape[1]):\n                uj = Bmat[:, j]\n                # simplified Oja: u <- u + lr * (z * (z^T u)) ; then re-orthonormalize\n                proj = np.dot(z, uj)\n                uj = uj + lr * (z * proj)\n                Bmat[:, j] = uj\n            # orthonormalize\n            try:\n                Q, _ = np.linalg.qr(Bmat)\n                return Q[:, :Bmat.shape[1]]\n            except Exception:\n                norms = np.linalg.norm(Bmat, axis=0) + 1e-12\n                return Bmat / norms\n\n        # Fit lightweight quadratic surrogate in the learned subspace B.\n        # We use features: 1, z (r), z^2 (r), and limited pairwise cross-terms up to k_cross to capture curvature.\n        def fit_subspace_quadratic(Bmat, n_samples=None):\n            if Bmat.shape[1] == 0 or len(X_arch) < (Bmat.shape[1] + 6):\n                return None\n            r = Bmat.shape[1]\n            n_samples = int(min(len(X_arch), n_samples if n_samples is not None else min(120, max(40, 12 * r))))\n            Xr = np.asarray(X_arch[-n_samples:])\n            Fr = np.asarray(f_arch[-n_samples:])\n            Z = (Xr - m).dot(Bmat)  # n x r\n            # build feature matrix\n            k_cross = min(6, r)  # include some cross terms but not too many\n            # features: bias + linear (r) + quad_diag (r) + selected cross pairwise (~k_cross*(k_cross-1)/2)\n            idxs = list(range(k_cross))\n            cross_pairs = [(i, j) for i in idxs for j in range(i+1, k_cross)]\n            p = 1 + r + r + len(cross_pairs)\n            Phi = np.ones((Z.shape[0], p))\n            col = 1\n            Phi[:, col: col + r] = Z; col += r\n            Phi[:, col: col + r] = Z**2; col += r\n            for (i, j) in cross_pairs:\n                Phi[:, col] = Z[:, i] * Z[:, j]\n                col += 1\n            # ridge solve\n            try:\n                A = Phi.T.dot(Phi) + self.surrogate_reg * np.eye(Phi.shape[1])\n                b = Phi.T.dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                # reconstruct gradient and small Hessian in subspace coordinates\n                c = coeff[0]\n                g = coeff[1:1+r]\n                Hdiag = coeff[1+r:1+r+r]\n                # assemble small H matrix\n                H = np.diag(np.maximum(Hdiag, 1e-8))\n                # add cross terms to H\n                col = 1 + r + r\n                for (i, j) in cross_pairs:\n                    val = coeff[col]\n                    H[i, j] += 0.5 * val\n                    H[j, i] += 0.5 * val\n                    col += 1\n                # ensure symmetry and small positive definiteness\n                H = 0.5 * (H + H.T) + 1e-8 * np.eye(r)\n                # attempt minimizer z* = -H^{-1} g (constrain by subspace trust)\n                try:\n                    zstar = -np.linalg.solve(H, g)\n                except Exception:\n                    # fallback diagonal step\n                    zstar = - g / (np.diag(H) + 1e-12)\n                # scale zstar to stay within trust radius in original space\n                # approximate norm in original space: ||B z|| <= ||z|| * ||B||_2\n                Bnorm = np.linalg.norm(Bmat, ord=2) + 1e-12\n                max_norm = trust_radius / Bnorm * np.sqrt(max(1, r))\n                znorm = np.linalg.norm(zstar)\n                if znorm > max_norm:\n                    zstar = zstar * (max_norm / (znorm + 1e-12))\n                fpred = float(c + g.dot(zstar) + 0.5 * zstar.dot(H.dot(zstar)))\n                return (zstar, fpred, (c, g, H))\n            except Exception:\n                return None\n\n        # hedge-based operator chooser (exponential weights -> prob)\n        def choose_operator():\n            w = np.maximum(w_op, 1e-12)\n            probs = w / (np.sum(w) + 1e-12)\n            idx = rng.choice(len(operators), p=probs)\n            return operators[idx], idx\n\n        # get elites\n        def get_elites(k_frac=0.12):\n            n = len(X_arch)\n            if n == 0:\n                return np.empty((0, self.dim))\n            k = max(3, int(np.ceil(k_frac * max(20, n))))\n            idxs = np.argsort(f_arch)[:min(k, n)]\n            return np.asarray([X_arch[i].copy() for i in idxs])\n\n        # main loop\n        gen = 0\n        stagn = 0\n        stagn_limit = max(8, int(0.02 * self.budget))\n        # track a short success history for adaptive trust scaling\n        recent_success = []\n\n        while evals < self.budget:\n            gen += 1\n\n            # recompute elites and diversity\n            Xe = get_elites()\n            diversity = 0.0\n            try:\n                if len(X_arch) > 4:\n                    ev = np.linalg.eigvalsh(np.cov(np.asarray(X_arch).T) + 1e-12 * np.eye(self.dim))\n                    ev = np.maximum(ev, 1e-16)\n                    p = ev / np.sum(ev)\n                    diversity = -np.sum(p * np.log(p + 1e-12))\n                else:\n                    diversity = 0.0\n            except Exception:\n                diversity = 0.0\n\n            # adapt trust gently by success rate and diversity: more diversity -> expand a bit\n            succ_rate = np.mean(recent_success[-20:]) if recent_success else 0.0\n            if succ_rate > 0.15:\n                trust_radius = max(self.min_trust, trust_radius * (0.90 - 0.01 * rng.rand()))\n            else:\n                trust_radius = min(self.max_trust, trust_radius * (1.02 + 0.01 * rng.rand()))\n            # diversity expansion\n            if diversity > 1.1:\n                trust_radius = min(self.max_trust, trust_radius * (1.03 + 0.01 * rng.rand()))\n\n            # prepare a small batch of candidates per generation\n            batch_n = min(self.pop, max(1, self.budget - evals))\n            batch_X = []\n            batch_f = []\n            batch_ops = []\n\n            # fit surrogate in subspace once per generation\n            surrogate = fit_subspace_quadratic(B, n_samples=min(120, max(40, 10 * max(1, B.shape[1]))))\n\n            for bi in range(batch_n):\n                if evals >= self.budget:\n                    break\n                op, idx = choose_operator()\n                x_cand = None\n                f_c = None\n                pred_impr = 0.0\n\n                if op == 'gauss':\n                    # multiscale Gaussian jitter: sample sigma from mixture\n                    scales = [0.18, 0.6, 1.6]\n                    s = rng.choice(scales, p=[0.6, 0.3, 0.1])\n                    sigma = s * trust_radius * (0.5 + rng.rand() * 0.8)\n                    x_prop = m + sigma * rng.randn(self.dim)\n                    x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                elif op == 'cauchy':\n                    # heavy-tailed escape from center or random elite center\n                    if Xe.size and rng.rand() < 0.7:\n                        center = Xe[rng.randint(0, Xe.shape[0])]\n                    else:\n                        center = m\n                    z = rng.standard_cauchy(size=self.dim)\n                    # limit extreme tails\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    step = 2.8 * trust_radius * z\n                    x_prop = center + step\n                    x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                elif op == 'pc_line':\n                    # move along a principal direction from B (or random if B empty), with bracketed probing\n                    if B.shape[1] > 0 and rng.rand() < 0.8:\n                        j = rng.randint(0, B.shape[1])\n                        d = B[:, j]\n                    else:\n                        d = rng.randn(self.dim); d = d / (np.linalg.norm(d) + 1e-12)\n                    # probe several distances scaled by trust\n                    scales = [0.0, 0.4, -0.4, 1.0, -1.0]\n                    best_x = None; best_f = 1e99\n                    for s in scales:\n                        if evals >= self.budget: break\n                        x_try = m + s * trust_radius * d\n                        x_try = np.minimum(np.maximum(x_try, lb), ub)\n                        f_try = safe_eval(x_try)\n                        if f_try is None:\n                            break\n                        if f_try < best_f:\n                            best_f = f_try; best_x = x_try.copy()\n                    if best_x is not None:\n                        x_cand = best_x; f_c = best_f\n\n                elif op == 'elite_mix':\n                    # recombine two elites (weighted convex combination) and small jitter\n                    if Xe.size and Xe.shape[0] >= 2:\n                        a, b = rng.choice(Xe.shape[0], size=2, replace=False)\n                        w = rng.beta(1.2, 1.2)\n                        x_prop = Xe[a] * w + Xe[b] * (1.0 - w)\n                    elif Xe.size:\n                        x_prop = Xe[rng.randint(0, Xe.shape[0])]\n                    else:\n                        x_prop = m.copy()\n                    # add small anisotropic jitter guided by accum_sq (mirror scaling)\n                    scale = 0.7 * trust_radius\n                    jitter = rng.randn(self.dim) * scale / (np.sqrt(accum_sq) + 1e-12)\n                    x_prop = np.minimum(np.maximum(x_prop + jitter, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                elif op == 'subspace_quad' and surrogate is not None:\n                    zstar, fpred, meta = surrogate\n                    x_prop = m + B.dot(zstar)\n                    x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n                        # predicted improvement (positive if predicted better than current best)\n                        pred_impr = max(0.0, f_best - fpred)\n\n                elif op == 'diag_qn':\n                    # quasi-Newton diagonal step (approx inverse diag Hessian via accum_sq)\n                    # pick a direction from momentum or random\n                    if momentum and rng.rand() < 0.7:\n                        svec = momentum[rng.randint(0, len(momentum))]\n                        d = svec / (np.linalg.norm(svec) + 1e-12)\n                    else:\n                        d = rng.randn(self.dim); d = d / (np.linalg.norm(d) + 1e-12)\n                    # step length proportional to per_dim_step and scaled by mirror diag\n                    inv_scale = 1.0 / (np.sqrt(accum_sq) + 1e-12)\n                    step_vec = d * (0.8 * trust_radius * np.mean(inv_scale))\n                    x_prop = m + step_vec\n                    x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                # if we evaluated a candidate, update adapters\n                if f_c is not None:\n                    batch_X.append(x_cand.copy())\n                    batch_f.append(f_c)\n                    batch_ops.append(op)\n\n                    # compute reward (relative improvement)\n                    reward = max(0.0, (f_best - f_c) / (abs(f_best) + 1e-12))\n                    # also incorporate predicted improvement for surrogate\n                    reward = max(reward, 0.5 * pred_impr / (abs(f_best) + 1e-12))\n                    # update hedge weights exponentially (multiplicative in log-space)\n                    w_op[idx] = w_op[idx] * np.exp(self.hedge_eta * reward)\n                    # normalize occasionally to avoid overflow\n                    if np.max(w_op) > 1e6:\n                        w_op = w_op / np.mean(w_op)\n\n                    # update accumulators and per-dim step sizes based on move from center\n                    step = x_cand - m\n                    accum_sq += (step ** 2) * 0.5  # accumulate squared moves (tempered)\n                    # adapt per-dim step up if success, down if not\n                    if f_c < f_best - 1e-12:\n                        per_dim_step = np.minimum(per_dim_step * 1.14, 2.0 * avg_span)\n                        recent_success.append(1.0)\n                        stagn = 0\n                        # successful step contributes to momentum\n                        s_norm = step / (np.linalg.norm(step) + 1e-12)\n                        momentum.append(s_norm)\n                        if len(momentum) > self.momentum_size:\n                            momentum.pop(0)\n                    else:\n                        per_dim_step = np.maximum(per_dim_step * 0.97, 1e-8)\n                        recent_success.append(0.0)\n                        stagn += 1\n\n                    # update low-rank basis B with the step (centered)\n                    if B.shape[1] > 0:\n                        B = update_basis(B, step, lr=self.oja_lr * (0.4 + 0.6 * rng.rand()))\n\n                    # if improved global best, shrink trust (zoom in), else allow small expansion\n                    if f_c < f_best - 1e-12:\n                        f_best = float(f_c); x_best = x_cand.copy()\n                        trust_radius = max(self.min_trust, trust_radius * 0.78)\n                    else:\n                        trust_radius = min(self.max_trust, trust_radius * 1.015)\n\n                # else budget exhausted -> break\n                else:\n                    break\n\n            # Mirror-style center aggregation using inverse-root accumulated squared steps\n            if len(batch_X) > 0:\n                Xs = np.asarray(batch_X)\n                Fs = np.asarray(batch_f)\n                # compute soft weights using temperature tied to trust and diversity\n                temp = max(1e-8, 0.7 * (trust_radius / (avg_span + 1e-12)) * (1.0 + 0.3 * (1.0 - diversity)))\n                # use a tempered softmin: w_i ∝ exp(-(F_i - minF)/temp)\n                minF = np.min(Fs)\n                w = np.exp(-(Fs - minF) / (temp + 1e-12))\n                w = w / (np.sum(w) + 1e-12)\n                x_mean = np.sum(w[:, None] * Xs, axis=0)\n                # mirror update: m <- m + alpha * D^{-1} (x_mean - m), D = sqrt(accum_sq)\n                Dinv = 1.0 / (np.sqrt(accum_sq) + 1e-12)\n                lr_center = 0.45 if trust_radius < 0.5 * avg_span else 0.26\n                delta = x_mean - m\n                proposed = m + lr_center * (Dinv * delta) / (np.max(Dinv) + 1e-12) * np.sqrt(self.dim)\n                # clip move length\n                max_move = 3.5 * trust_radius * np.sqrt(max(1, self.dim))\n                if np.linalg.norm(proposed - m) > max_move:\n                    proposed = m + (proposed - m) * (max_move / (np.linalg.norm(proposed - m) + 1e-12))\n                m = np.minimum(np.maximum(proposed, lb), ub)\n\n                # trust adapt shrink if any in batch improved, else relax slightly\n                if np.any(Fs < f_best):\n                    trust_radius = max(self.min_trust, trust_radius * 0.86)\n                else:\n                    trust_radius = min(self.max_trust, trust_radius * 1.02)\n\n            # stagnation-based targeted reseed / restart (anisotropic)\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                # choose an elite center or best\n                if Xe.size:\n                    center = Xe[rng.randint(0, Xe.shape[0])]\n                else:\n                    center = x_best\n                # construct anisotropic jitter using empirical cov of elites\n                try:\n                    if Xe.size and Xe.shape[0] > 2:\n                        C = np.cov(Xe.T)\n                        w_eig, V = np.linalg.eigh(C + 1e-10 * np.eye(self.dim))\n                        w_eig = np.maximum(w_eig, 1e-12)\n                        S_sqrt = V.dot(np.diag(np.sqrt(w_eig))).dot(V.T)\n                    else:\n                        S_sqrt = np.eye(self.dim)\n                except Exception:\n                    S_sqrt = np.eye(self.dim)\n                jitter_scale = max(0.06 * avg_span, 1.4 * trust_radius)\n                perturb = jitter_scale * (0.6 * rng.randn(self.dim) + 0.4 * S_sqrt.dot(rng.randn(self.dim)))\n                m = np.minimum(np.maximum(center + perturb, lb), ub)\n                trust_radius = min(self.max_trust, trust_radius * 1.6)\n                # small local reseed around best\n                reseed = min(8, self.budget - evals)\n                for _ in range(reseed):\n                    if evals >= self.budget:\n                        break\n                    x = np.minimum(np.maximum(x_best + 0.03 * avg_span * rng.randn(self.dim), lb), ub)\n                    f = safe_eval(x)\n                    if f is None:\n                        break\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 995, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: probabilities contain NaN", "error": "In the code, line 995, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: probabilities contain NaN", "parent_ids": "b49a045b-62d7-481c-95dd-d06c3592f774", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "24702e79-8f60-4fb3-a704-187599133a70", "fitness": "-inf", "name": "LEO", "description": "LEO maintains a compact evaluated archive plus a single ensemble center m (initialized from the best of an initial random seed of ~min(budget/250, pop*6) samples) and caps the archive (≈300) to keep online updates cheap while enforcing bound handling. It learns a low-rank geometry via streaming Oja PCA (subspace_dim ≈ max(1, dim//4), oja_lr≈0.02) and fits a local weighted ridge surrogate in that subspace (bias + linear + diag-quadratic, surrogate_reg=1e-4, up to ~140 recent samples) to propose trusted steps capped by an adaptive trust radius (init ≈0.12·avg_span). Exploration is driven by a diverse ensemble of complementary operators — Lévy-like heavy-tail jumps (levy_alpha=1.4), surrogate-guided steps, axis/line probes at multiple scales, finite-difference directional search, Gaussian walks and mirror mutations — with operator allocation by exponentiated-weight updates (η≈0.8/√gen) and slight decay. Robustness and adaptation come from coordinate-wise trimmed-mean aggregation of good candidates to move the center, per-dimension scales, trust shrink on improvements (×0.78) vs mild expansion otherwise (~×1.015), and a stagnation-triggered reseed using shrunk covariance plus jitter.", "code": "import numpy as np\n\nclass LEO:\n    \"\"\"\n    LEO: Lévy-Ensemble Optimizer\n\n    Main idea (one line): Maintain a small evaluated archive and an ensemble center,\n    fit locally-weighted ridge surrogates in an online low-rank subspace, use a mix of\n    complementary operators including Lévy-style heavy tails for global escapes,\n    and allocate operators by exponentiated weight updates; centers are updated\n    by robust coordinate-wise aggregation (trimmed-mean/median) with adaptive trust.\n\n    Main parameters (accessible in __init__):\n      - budget, dim: required\n      - pop: number of candidate evaluations per generation (default 14)\n      - subspace_dim: learned subspace dimension (default max(1, dim//4))\n      - init_trust: initial trust radius relative to average span (default 0.12)\n      - oja_lr: learning rate for online subspace (default 0.02)\n      - levy_alpha: tail exponent for Lévy-like jumps (1.4)\n      - surrogate_reg: regularization for ridge surrogate (1e-4)\n      - min_trust / max_trust: trust radius bounds\n      - seed: RNG seed\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop=14, subspace_dim=None,\n                 init_trust=0.12, oja_lr=0.02,\n                 levy_alpha=1.4, surrogate_reg=1e-4,\n                 min_trust=1e-9, max_trust=6.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.rng = np.random.RandomState(seed)\n        self.pop = int(pop)\n        self.subspace_dim = subspace_dim if subspace_dim is not None else max(1, self.dim // 4)\n        self.init_trust_rel = float(init_trust)\n        self.oja_lr = float(oja_lr)\n        self.levy_alpha = float(levy_alpha)\n        self.surrogate_reg = float(surrogate_reg)\n        self.min_trust = float(min_trust)\n        self.max_trust = float(max_trust)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling (Many Affine BBOB assumed [-5,5], but respect func.bounds if present)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        trust_radius = max(self.min_trust, self.init_trust_rel * avg_span)\n\n        # archive and bookkeeping\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # initial random sampling to populate archive (small but larger than pop)\n        seed0 = min(max(12, int(self.budget // 250)), max(20, self.pop * 6))\n        for _ in range(seed0):\n            if evals >= self.budget: break\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        # ensure at least one point\n        if len(f_arch) == 0 and evals < self.budget:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        # center (ensemble single center, updated robustly)\n        m = x_best.copy()\n\n        # streaming PCA (Oja) initialize U with random orthonormal columns\n        r = min(self.subspace_dim, self.dim)\n        if r > 0:\n            U = rng.randn(self.dim, r)\n            try:\n                Q, _ = np.linalg.qr(U)\n                U = Q[:, :r]\n            except Exception:\n                U = U / (np.linalg.norm(U, axis=0, keepdims=True) + 1e-12)\n        else:\n            U = np.zeros((self.dim, 0))\n\n        # per-dimension small adaptive scales (different constants than DARTS)\n        per_dim_scale = np.full(self.dim, 0.08 * avg_span)\n        per_dim_scale = np.clip(per_dim_scale, 1e-8, 2.0 * avg_span)\n\n        # operator list and exponentiated weights (different update style)\n        operators = ['levy_jump', 'local_ridge', 'axis_line', 'fd_grad', 'gauss_walk', 'mirror_mut']\n        w_op = np.ones(len(operators), dtype=float)\n        op_index = {op: i for i, op in enumerate(operators)}\n\n        # helper: safe eval that never exceeds budget and keeps archive bounded\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch, x_best, f_best\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # keep archive recent + elites: cap size\n            max_archive = max(5 * self.subspace_dim, 4 * self.pop, 300)\n            if len(X_arch) > max_archive:\n                del X_arch[0:(len(X_arch) - max_archive)]\n                del f_arch[0:(len(f_arch) - max_archive)]\n            if fx < f_best:\n                x_best = x.copy(); f_best = float(fx)\n            return fx\n\n        # helper: small covariance shrink (slightly different constants)\n        def shrink_cov(Xe, shrink=0.12):\n            if Xe.size == 0:\n                return np.eye(self.dim)\n            S = np.cov(Xe.T) if Xe.shape[0] > 1 else np.zeros((self.dim, self.dim))\n            F = np.trace(S) / max(1, self.dim)\n            C = (1.0 - shrink) * S + shrink * F * np.eye(self.dim)\n            C += 1e-11 * np.eye(self.dim)\n            return C\n\n        # Oja update (slightly different normalization / factors)\n        def oja_update(Umat, z, lr):\n            if Umat.shape[1] == 0:\n                return Umat\n            zn = z / (np.linalg.norm(z) + 1e-12)\n            for j in range(Umat.shape[1]):\n                uj = Umat[:, j]\n                proj = np.dot(zn, uj)\n                uj = uj + lr * (zn * proj - 0.6 * uj * (proj ** 2 + 1e-12))\n                Umat[:, j] = uj\n            try:\n                Q, _ = np.linalg.qr(Umat)\n                return Q[:, :Umat.shape[1]]\n            except Exception:\n                norms = np.linalg.norm(Umat, axis=0) + 1e-12\n                return Umat / norms\n\n        # local weighted ridge surrogate in subspace U (Gaussian kernel weighting)\n        def fit_local_surrogate(Umat, samples=min(140, max(30, self.subspace_dim * 14))):\n            if Umat.shape[1] == 0 or len(X_arch) < (Umat.shape[1] + 6):\n                return None\n            K = min(samples, len(X_arch))\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(Umat)  # projections into subspace\n            # weights: Gaussian kernel on distances in original space (or subspace)\n            dists = np.linalg.norm(Xr - m, axis=1)\n            sigma = np.median(dists) + 1e-12\n            w = np.exp(-0.5 * (dists / max(1e-6, sigma))**2)\n            # construct design: bias + linear Z + diag quadratic Z^2\n            n, r = Z.shape\n            Phi = np.ones((n, 1 + r + r))\n            Phi[:, 1:1 + r] = Z\n            Phi[:, 1 + r:1 + r + r] = Z ** 2\n            W = np.diag(w + 1e-12)\n            try:\n                A = Phi.T.dot(W).dot(Phi) + self.surrogate_reg * np.eye(Phi.shape[1])\n                b = Phi.T.dot(W).dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1 + r]\n                Hdiag = coeff[1 + r:1 + r + r]\n                # enforce modest positive curvature\n                Hdiag = np.maximum(Hdiag, 5e-9)\n                zstar = - g / (Hdiag + 1e-12)\n                # cap by trust in subspace (different scaling)\n                max_norm = (trust_radius / (np.linalg.norm(Umat, ord=2) + 1e-12)) * np.sqrt(max(1, r)) * 0.9\n                znorm = np.linalg.norm(zstar)\n                if znorm > max_norm:\n                    zstar = zstar * (max_norm / (znorm + 1e-12))\n                fpred = float(c + g.dot(zstar) + 0.5 * np.sum(Hdiag * (zstar ** 2)))\n                return zstar, fpred, (g, Hdiag, c)\n            except Exception:\n                return None\n\n        # operator chooser (sample according to normalized w_op)\n        def choose_operator():\n            probs = w_op / (np.sum(w_op) + 1e-12)\n            idx = rng.choice(len(operators), p=probs)\n            return operators[idx], idx\n\n        # elite selector (top fraction)\n        def get_elites(k_frac=0.12):\n            n = len(X_arch)\n            if n == 0:\n                return np.empty((0, self.dim))\n            k = max(4, int(np.ceil(k_frac * max(30, n))))\n            idxs = np.argsort(f_arch)[:min(k, n)]\n            return np.asarray([X_arch[i].copy() for i in idxs])\n\n        # robust coordinate-wise trimmed mean (used to update center)\n        def trimmed_coordinate_mean(Xs, trim_frac=0.2):\n            # Xs: n x dim\n            if Xs.shape[0] == 0:\n                return np.zeros(self.dim)\n            n = Xs.shape[0]\n            low = int(np.floor(trim_frac * n))\n            high = n - low\n            # for each coordinate, sort and take trimmed mean\n            out = np.zeros(self.dim)\n            for j in range(self.dim):\n                col = np.sort(Xs[:, j])\n                if high <= low:\n                    out[j] = np.median(col)\n                else:\n                    out[j] = np.mean(col[low:high])\n            return out\n\n        # main loop\n        gen = 0\n        stagn = 0\n        stagn_limit = max(12, int(0.03 * self.budget))\n\n        while evals < self.budget:\n            gen += 1\n\n            # recompute elites and diversity\n            Xe = get_elites()\n            Csh = shrink_cov(Xe) if Xe.size else np.eye(self.dim)\n            # eigen-entropy as diversity proxy\n            try:\n                cov_all = np.cov(np.asarray(X_arch).T) if len(X_arch) > 3 else np.eye(self.dim)\n                ev = np.linalg.eigvalsh(cov_all + 1e-14 * np.eye(self.dim))\n                ev = np.maximum(ev, 1e-16)\n                p = ev / np.sum(ev)\n                diversity = -np.sum(p * np.log(p + 1e-12))\n            except Exception:\n                diversity = 0.0\n\n            # small trust adaptation based on diversity (different multipliers)\n            if diversity < 0.45:\n                trust_radius = min(self.max_trust, trust_radius * (1.03 + 0.003 * rng.rand()))\n            else:\n                trust_radius = max(self.min_trust, trust_radius * (0.995 - 0.002 * rng.rand()))\n\n            # prepare batch\n            n_batch = min(self.pop, max(1, self.budget - evals))\n            batch_X = []\n            batch_f = []\n            batch_ops = []\n            surrogate = fit_local_surrogate(U)\n\n            for bi in range(n_batch):\n                if evals >= self.budget:\n                    break\n                op, idx = choose_operator()\n                x_cand = None\n                f_c = None\n                predicted = None\n\n                if op == 'local_ridge' and surrogate is not None:\n                    zstar, fpred, params = surrogate\n                    x_prop = m + U.dot(zstar)\n                    x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop; predicted = fpred\n\n                elif op == 'axis_line':\n                    # choose coordinate with largest archive variance or principal direction\n                    if Xe.size and rng.rand() < 0.7:\n                        var = np.var(np.asarray(Xe), axis=0)\n                        i = int(np.argmax(var))\n                        d = np.zeros(self.dim); d[i] = 1.0\n                    elif U.shape[1] > 0 and rng.rand() < 0.6:\n                        j = rng.randint(0, U.shape[1])\n                        d = U[:, j]\n                    else:\n                        d = rng.randn(self.dim)\n                    d = d / (np.linalg.norm(d) + 1e-12)\n                    # probe multimodal bracket: small, medium, large along d\n                    scales = [0.25, -0.25, 0.7, -0.7, 1.6, -1.6]\n                    best_f = 1e99; best_x = None\n                    for s in scales:\n                        if evals >= self.budget: break\n                        step = s * trust_radius\n                        x_try = np.minimum(np.maximum(m + step * d, lb), ub)\n                        f_try = safe_eval(x_try)\n                        if f_try is None:\n                            break\n                        if f_try < best_f:\n                            best_f = f_try; best_x = x_try.copy()\n                    if best_x is not None:\n                        x_cand = best_x; f_c = best_f\n\n                elif op == 'fd_grad':\n                    # finite difference along a combined subspace vector\n                    if U.shape[1] >= 1 and rng.rand() < 0.8:\n                        kdir = min(3, U.shape[1])\n                        inds = rng.choice(U.shape[1], kdir, replace=False)\n                        d = np.sum(U[:, inds], axis=1)\n                    else:\n                        d = rng.randn(self.dim)\n                    d = d / (np.linalg.norm(d) + 1e-12)\n                    eps = 0.06 * (1.0 + rng.rand()) * trust_radius + 1e-9\n                    x_plus = np.minimum(np.maximum(m + eps * d, lb), ub)\n                    f_plus = safe_eval(x_plus)\n                    if f_plus is None:\n                        break\n                    x_minus = np.minimum(np.maximum(m - eps * d, lb), ub)\n                    f_minus = safe_eval(x_minus)\n                    if f_minus is None:\n                        break\n                    gdir = (f_plus - f_minus) / (2.0 * eps + 1e-12)\n                    # step length proportional to estimated slope but bounded\n                    step_len = np.clip(abs(gdir) * trust_radius, 0.25 * trust_radius, 1.4 * trust_radius)\n                    x_prop = np.minimum(np.maximum(m - np.sign(gdir) * step_len * d, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                elif op == 'levy_jump':\n                    # Lévy-like multivariate jump centered at random elite or center\n                    if Xe.size and rng.rand() < 0.65:\n                        center = Xe[rng.randint(0, Xe.shape[0])]\n                    else:\n                        center = m\n                    # sample heavy-tailed step sizes via alpha-stable approximation:\n                    # use scaled Cauchy, then raise magnitude by exponent to emulate alpha\n                    z = rng.standard_cauchy(size=self.dim)\n                    # reduce extreme tails gently and shape tails\n                    z = z / (np.percentile(np.abs(z), 90) + 1e-12)\n                    # shape by levy_alpha: multiply by |u|^{(2-alpha)/alpha} to get heavier tails when alpha<2\n                    shape_factor = (np.abs(rng.randn(self.dim)) + 1e-6) ** ((2.0 - self.levy_alpha) / (self.levy_alpha + 1e-12))\n                    step = (2.5 * trust_radius) * z * shape_factor\n                    x_prop = np.minimum(np.maximum(center + step, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                elif op == 'mirror_mut':\n                    # mirrored mutation: reflect worst archived point across center with jitter\n                    if len(X_arch) > 4 and rng.rand() < 0.8:\n                        worst_idx = int(np.argmax(f_arch[-min(len(f_arch), 30):]))\n                        worst = np.asarray(X_arch[-min(len(X_arch), 30):][worst_idx])\n                        refl = m + (m - worst)\n                        jitter = 0.4 * trust_radius * rng.randn(self.dim)\n                        x_prop = np.minimum(np.maximum(refl + jitter, lb), ub)\n                    else:\n                        x_prop = np.minimum(np.maximum(m + 0.9 * trust_radius * rng.randn(self.dim), lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                else:  # gauss_walk\n                    sigma = 0.9 * trust_radius * (0.5 + 0.9 * rng.rand())\n                    x_prop = np.minimum(np.maximum(m + sigma * rng.randn(self.dim), lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_c = f_prop\n\n                # if evaluated, process\n                if f_c is not None:\n                    batch_X.append(x_cand.copy())\n                    batch_f.append(f_c)\n                    batch_ops.append(op)\n\n                    # reward: relative improvement over current best (clamped)\n                    reward = max(-0.0, (f_best - f_c) / (abs(f_best) + 1e-12))\n                    # exponentiated gradient style update (different from multiplicative)\n                    eta = 0.8 / max(1.0, np.sqrt(gen))\n                    # boost chosen operator exponentially by reward\n                    w_op[idx] = w_op[idx] * np.exp(eta * reward)\n                    # small decay to keep exploration\n                    w_op = w_op * (0.997 + 0.001 * rng.rand())\n                    # numerical floor\n                    w_op = np.maximum(w_op, 1e-8)\n\n                    # update U via Oja with slightly randomized lr\n                    zc = x_cand - m\n                    U = oja_update(U, zc, lr=self.oja_lr * (0.3 + 0.7 * rng.rand()))\n\n                    # update per-dim scales if improvement happened on coordinate steps\n                    if op == 'axis_line' and f_c < f_best - 1e-12:\n                        per_dim_scale = np.minimum(per_dim_scale * 1.08, 10.0 * avg_span)\n                    if op == 'fd_grad' and f_c < f_best - 1e-12:\n                        per_dim_scale = np.maximum(per_dim_scale * 0.96, 1e-9)\n\n                    # trust adaptation: if improved global best, shrink to refine; else mild expansion\n                    if f_c < f_best - 1e-12:\n                        trust_radius = max(self.min_trust, trust_radius * 0.78)\n                        stagn = 0\n                        f_best = float(f_c); x_best = x_cand.copy()\n                    else:\n                        trust_radius = min(self.max_trust, trust_radius * 1.015)\n                        stagn += 1\n\n                else:\n                    break  # budget exhausted\n\n            # center aggregation after batch\n            if len(batch_X) > 0:\n                Xs = np.asarray(batch_X)\n                Fs = np.asarray(batch_f)\n                # pick top fraction then compute trimmed coordinate mean for robustness\n                topk = max(3, int(np.ceil(0.25 * len(Fs))))\n                idxs = np.argsort(Fs)[:topk]\n                X_top = Xs[idxs]\n                x_agg = trimmed_coordinate_mean(X_top, trim_frac=0.22)\n                # move center toward aggregate by step scaled by trust and a generation-dependent factor\n                lr_center = 0.5 if trust_radius < 0.4 * avg_span else 0.28\n                delta = x_agg - m\n                # cap max jump\n                max_jump = 3.5 * trust_radius * np.sqrt(max(1, self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > max_jump:\n                    delta = delta * (max_jump / (dn + 1e-12))\n                m = np.minimum(np.maximum(m + lr_center * delta, lb), ub)\n\n                # if any improvement in batch, prefer refinement\n                if np.any(Fs < f_best):\n                    trust_radius = max(self.min_trust, trust_radius * 0.85)\n                else:\n                    trust_radius = min(self.max_trust, trust_radius * (1.02 + 0.002 * rng.rand()))\n\n            # stagnation-driven targeted reseed (different policy)\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                # pick a random elite or best as base\n                if Xe.size:\n                    center = Xe[rng.randint(0, Xe.shape[0])]\n                else:\n                    center = x_best\n                C = shrink_cov(Xe)\n                try:\n                    w, V = np.linalg.eigh(C)\n                    w = np.maximum(w, 1e-12)\n                    S_sqrt = V.dot(np.diag(np.sqrt(w))).dot(V.T)\n                except Exception:\n                    S_sqrt = np.eye(self.dim)\n                jitter = max(0.04 * avg_span, 2.0 * trust_radius)\n                m = np.minimum(np.maximum(center + jitter * (0.6 * rng.randn(self.dim) + 0.4 * (S_sqrt.dot(rng.randn(self.dim)))), lb), ub)\n                trust_radius = min(self.max_trust, trust_radius * 1.7)\n                # small local reseed around best with a few evaluations\n                reseed = min(8, self.budget - evals)\n                for _ in range(reseed):\n                    if evals >= self.budget:\n                        break\n                    x = np.minimum(np.maximum(x_best + 0.025 * avg_span * rng.randn(self.dim), lb), ub)\n                    f = safe_eval(x)\n                    if f is None:\n                        break\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 999, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: probabilities do not sum to 1", "error": "In the code, line 999, in numpy.random.mtrand.RandomState.choice, the following error occurred:\nValueError: probabilities do not sum to 1", "parent_ids": "b49a045b-62d7-481c-95dd-d06c3592f774", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "61916f88-560c-4450-9135-0e7f9d8b6b72", "fitness": 0.19245352942634275, "name": "HSMAS", "description": "The algorithm hybridizes a low-rank learned subspace U (initialized from early samples and periodically refreshed by PCA on a buffer of successful normalized steps) with per-dimension residual noise so that each candidate step = sigma*(U·z + eps), and it maintains multiplicative per-direction energies e to softly allocate sampling mass in the subspace. It uses mirrored (antithetic) paired sampling to produce low-variance directional rewards, attributes gains to subspace axes via exponentiated reward updates (energy_lr), and tracks coordinate-wise RMS (rms_beta) to scale residual noise and form per-dimension sigma_diag. The search center m is updated by weighted recombination of elites with momentum and trust clipping, while global sigma is adapted multiplicatively from a smoothed success rate (sigma_adapt_rate) akin to a 1/5-type rule; a lightweight weighted linear surrogate (projected to the subspace) proposes targeted steps. Practical heuristics include modest initial step size (sigma0_mult=0.18), small population (pop=14) and rank ~dim/6, periodic PCA (pca_period=11), bounded clipping to [-5,5], and opportunistic restarts on stagnation.", "code": "import numpy as np\n\nclass HSMAS:\n    \"\"\"\n    Hybrid Subspace-Mirror Adaptive Search (HSMAS)\n\n    Key features:\n      - Low-rank orthonormal subspace U (learned from recent successful normalized steps) + per-dimension residual scales.\n      - Mirrored (antithetic) paired sampling to obtain directional gains and low-variance attribution for energy updates.\n      - Multiplicative direction-energies in subspace to bias sampling (soft allocation via exponentiated rewards).\n      - Per-dimension RMS (EWMA) to scale residual noise coordinate-wise.\n      - Lightweight local surrogate (weighted linear regression in full space, projected to subspace) to propose a targeted step.\n      - Momentum-based mean updates and trust clipping; sigma adapts via smoothed success rate (approx 1/5 rule).\n      - Periodic PCA refresh of U from a small buffer of successful normalized steps; opportunistic restarts on stagnation.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=14, rank=None,\n                 sigma0_mult=0.18,\n                 success_target=0.2, sigma_adapt_rate=0.24,\n                 energy_lr=0.18, rms_beta=0.92,\n                 pca_period=11, buffer_size=None,\n                 stagn_frac=0.06):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.rng = np.random.RandomState(rng_seed)\n\n        # population and subspace\n        self.pop = int(pop)\n        self.rank = int(rank) if rank is not None else max(1, self.dim // 6)\n\n        # controllers\n        self.sigma0_mult = float(sigma0_mult)\n        self.success_target = float(success_target)\n        self.sigma_adapt_rate = float(sigma_adapt_rate)\n        self.energy_lr = float(energy_lr)\n        self.rms_beta = float(rms_beta)\n        self.pca_period = int(pca_period)\n        self.buffer_size = buffer_size if buffer_size is not None else max(8 * self.rank, 60)\n        self.stagn_frac = float(stagn_frac)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds (problem statement: [-5,5], but use func.bounds if provided)\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # safe evaluator to avoid exceeding budget\n        evals = 0\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(x, lb), ub)\n            fx = float(func(x))\n            evals += 1\n            return fx\n\n        # seed initial archive with some random samples\n        init_pop = min(max(6, self.pop), max(4, self.budget // 50))\n        X_arch = []\n        f_arch = []\n        for _ in range(init_pop):\n            if evals >= self.budget:\n                break\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = safe_eval(x)\n            if f is None:\n                break\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        # ensure at least one eval\n        if len(f_arch) == 0 and evals < self.budget:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = safe_eval(x)\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        # initial best and mean\n        idx_best = int(np.argmin(f_arch))\n        f_best = float(f_arch[idx_best])\n        x_best = X_arch[idx_best].copy()\n        m = x_best.copy()\n\n        # initialize subspace U (orthonormal) from initial samples if possible\n        r = min(self.rank, self.dim)\n        if r > 0 and len(X_arch) >= r + 1:\n            try:\n                A = np.asarray(X_arch) - np.mean(X_arch, axis=0, keepdims=True)\n                _, _, Vt = np.linalg.svd(A, full_matrices=False)\n                U = Vt[:r].T.copy()\n            except Exception:\n                A = rng.randn(self.dim, r)\n                Q, _ = np.linalg.qr(A)\n                U = Q[:, :r]\n        elif r > 0:\n            A = rng.randn(self.dim, r)\n            Q, _ = np.linalg.qr(A)\n            U = Q[:, :r]\n        else:\n            U = np.zeros((self.dim, 0))\n\n        # energies for subspace directions (positive multiplicative)\n        e = np.ones(max(1, r))\n\n        # per-dimension RMS for residual scaling\n        v_rms = np.full(self.dim, 1e-6)\n        sigma_diag = np.full(self.dim, 1.0)  # will be set relative to sigma\n\n        # global sigma (step-size)\n        sigma = max(1e-12, self.sigma0_mult * avg_span)\n\n        # momentum for mean updates\n        mom = np.zeros(self.dim)\n\n        # smoothed success rate\n        p_succ = 0.2\n\n        # buffers for PCA and small surrogate regression\n        success_buffer = []  # successful normalized steps (in full space: (x - m) / sigma)\n        arch_max = max(6 * self.dim, 120)\n        stagn_limit = max(8, int(self.stagn_frac * self.budget))\n        stagn_counter = 0\n\n        gen = 0\n        # main loop: produce small batches until budget exhausted\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            lam = min(self.pop, remaining)\n            if lam <= 0:\n                break\n\n            # ensure lam even for mirrored pairs where possible\n            make_pairs = True\n            if lam % 2 == 1 and lam > 1:\n                lam -= 1  # reserve one evaluation for surrogate/probe later\n            pairs = lam // 2\n\n            batch_X = []\n            batch_f = []\n\n            # PRECOMPUTE sampling parameters\n            # transform energies to std-dev for subspace sampling\n            if r > 0:\n                e_pos = np.maximum(e, 1e-8)\n                std_sub = np.sqrt(e_pos)  # vector length r\n            else:\n                std_sub = np.array([])\n\n            # adjust sigma_diag from v_rms\n            sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-9), 1e-12, 5.0 * sigma)\n\n            # Mirrored (antithetic) sampling loop\n            for _ in range(pairs):\n                if evals + 2 > self.budget:\n                    break\n\n                # sample subspace coefficients and residual diag noise\n                if r > 0:\n                    z = rng.randn(r) * std_sub  # scaled per-direction\n                    sub_step = U.dot(z)  # dim\n                else:\n                    z = np.array([])\n                    sub_step = np.zeros(self.dim)\n\n                eps = rng.randn(self.dim) * (sigma_diag / sigma)  # normalized residual (so full step = sigma*(sub_step + eps))\n                step = sub_step + eps  # normalized (multiply by sigma later)\n\n                x_plus = m + sigma * step\n                x_minus = m - sigma * step\n\n                # clip\n                x_plus = np.minimum(np.maximum(x_plus, lb), ub)\n                x_minus = np.minimum(np.maximum(x_minus, lb), ub)\n\n                f_plus = safe_eval(x_plus)\n                if f_plus is None:\n                    break\n                f_minus = safe_eval(x_minus)\n                if f_minus is None:\n                    break\n\n                batch_X.append(x_plus.copy()); batch_f.append(f_plus)\n                batch_X.append(x_minus.copy()); batch_f.append(f_minus)\n\n                # update global best and stagnation quickly\n                improved_pair = False\n                if f_plus < f_best:\n                    f_best = f_plus; x_best = x_plus.copy(); improved_pair = True; stagn_counter = 0\n                if f_minus < f_best:\n                    f_best = f_minus; x_best = x_minus.copy(); improved_pair = True; stagn_counter = 0\n                if not improved_pair:\n                    stagn_counter += 1\n\n                # attribute directional gain to subspace components using pair difference\n                # positive delta means +step is better than -step\n                delta = f_minus - f_plus  # positive -> direction (step) favored\n                if r > 0:\n                    # projection of normalized step onto each subspace axis is z (since U^T sub_step = z)\n                    # Reward proportional to positive delta and abs(z)\n                    reward = max(0.0, delta)\n                    if reward > 0 and np.any(np.abs(z) > 0):\n                        contrib = np.abs(z) / (np.sum(np.abs(z)) + 1e-12)\n                        # multiplicative energy update (soft)\n                        e = e * np.exp(self.energy_lr * reward * contrib / (1.0 + np.linalg.norm(z)))\n                        # keep energies in sensible range\n                        e = np.clip(e, 1e-6, 1e6)\n\n                # record successful normalized steps to buffer if either improved or delta positive\n                if (f_plus <= f_best + 1e-12) or (f_minus <= f_best + 1e-12) or (delta > 0):\n                    norm_step = (sigma * step) / (sigma + 1e-20)  # essentially step normalized ~ (sub_step + eps)\n                    success_buffer.append(norm_step.copy())\n                    if len(success_buffer) > self.buffer_size:\n                        del success_buffer[0: (len(success_buffer) - self.buffer_size)]\n\n                # update RMS accumulator based on observed steps (use absolute normalized step components)\n                abs_norm = np.abs(sigma * step) / (sigma + 1e-12)\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * (abs_norm ** 2 + 1e-12)\n\n            # If we left one eval for surrogate/probe, attempt a surrogate-guided subspace minimizer\n            # Build a lightweight linear surrogate on recent archive to get a pseudo-gradient\n            # Use last N points (including batch) but not exceeding budget for extra evals\n            # Add recent batch to global archive\n            for x, f in zip(batch_X, batch_f):\n                X_arch.append(x.copy()); f_arch.append(f)\n                if len(X_arch) > arch_max:\n                    del X_arch[0]; del f_arch[0]\n\n            # selection & mean update: weighted recombination of top-half of batch (if any)\n            if len(batch_f) > 0:\n                # pick top mu from this batch\n                lam_actual = len(batch_f)\n                mu = max(1, lam_actual // 2)\n                order = np.argsort(batch_f)\n                elites = np.asarray(batch_X)[order[:mu]]\n                # weights similar to CMA logarithmic weights\n                weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n                weights = np.maximum(weights, 0.0)\n                if np.sum(weights) <= 0:\n                    weights = np.ones(mu)\n                weights = weights / (np.sum(weights) + 1e-12)\n                m_new = (weights.reshape(-1, 1) * elites).sum(axis=0)\n                # momentum update: combine with previous momentum\n                delta = m_new - m\n                # trust clip delta (avoid huge leaps)\n                max_move = max(1e-12, 6.0 * sigma * np.sqrt(self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > max_move:\n                    delta = delta * (max_move / (dn + 1e-12))\n                mom = 0.82 * mom + 0.18 * delta\n                # apply move with a damped learning rate\n                m = np.minimum(np.maximum(m + 0.5 * mom, lb), ub)\n\n            # surrogate step: fit a weighted linear model on recent archive to obtain pseudo-gradient\n            if evals < self.budget and len(X_arch) >= min(6, self.dim + 2):\n                # choose recent window\n                K = min(len(X_arch), max(12, 6 * self.rank, 30))\n                Xw = np.asarray(X_arch[-K:])\n                fw = np.asarray(f_arch[-K:])\n                # center Xw at m for linear surrogate: f ≈ a + g·(x - m)\n                Xc = Xw - m.reshape(1, -1)\n                # weighting favors near points\n                dists = np.linalg.norm(Xc / (sigma + 1e-12), axis=1)\n                w_dist = np.exp(-0.6 * dists)\n                # also favor better function values\n                fmin_local = np.min(fw)\n                w_fit = w_dist * np.exp(-0.5 * (fw - fmin_local) / (np.ptp(fw) + 1e-12))\n                W = np.sqrt(w_fit + 1e-12)\n                # design matrix for linear regression: Xc\n                try:\n                    A = (W.reshape(-1, 1) * Xc)\n                    # solve least squares for gradient g (no intercept needed since anchored at fmin_local)\n                    # minimize ||W*(Xc g - (fw - fmin_local))||\n                    y = (fw - fmin_local) * W\n                    Gmat = A.T.dot(A) + 1e-8 * np.eye(self.dim)\n                    bvec = A.T.dot((fw - fmin_local) * W)\n                    g_est = np.linalg.solve(Gmat, bvec)\n                    # project gradient into subspace to get subspace descent\n                    if r > 0:\n                        g_sub = U.T.dot(g_est)\n                        # propose a small subspace step: z = -eta * g_sub / (|g_sub| + 1e-12)\n                        # scale by local curvature proxy (use magnitude of recent projections)\n                        eta = 0.9 * sigma / (1.0 + np.linalg.norm(g_sub))\n                        z_star = -eta * g_sub\n                        # clip z_star in subspace norm\n                        max_sub_norm = 4.0 * sigma\n                        znorm = np.linalg.norm(z_star)\n                        if znorm > max_sub_norm:\n                            z_star = z_star * (max_sub_norm / (znorm + 1e-12))\n                        x_surr = m + U.dot(z_star)\n                        x_surr = np.minimum(np.maximum(x_surr, lb), ub)\n                        if evals < self.budget:\n                            f_surr = safe_eval(x_surr)\n                            if f_surr is not None:\n                                X_arch.append(x_surr.copy()); f_arch.append(f_surr)\n                                if f_surr < f_best:\n                                    f_best = f_surr; x_best = x_surr.copy(); stagn_counter = 0\n                                else:\n                                    stagn_counter += 1\n                                # if accepted (improvement or probabilistic uphill), move mean\n                                accept = False\n                                if f_surr <= np.min(f_arch) + 1e-12:\n                                    accept = True\n                                else:\n                                    # uphill acceptance probability (temperature proportional to sigma*avg_span)\n                                    T = max(1e-12, 0.6 * sigma * avg_span)\n                                    if rng.rand() < np.exp(-max(0.0, f_surr - f_best) / (T + 1e-12)):\n                                        accept = True\n                                if accept:\n                                    # move m partially towards surrogate candidate\n                                    delta = x_surr - m\n                                    max_move = max(1e-12, 8.0 * sigma * np.sqrt(self.dim))\n                                    dn = np.linalg.norm(delta)\n                                    if dn > max_move:\n                                        delta = delta * (max_move / (dn + 1e-12))\n                                    mom = 0.9 * mom + 0.1 * delta\n                                    m = np.minimum(np.maximum(m + 0.6 * mom, lb), ub)\n                                # record step into success_buffer if it improved or was promising\n                                if f_surr <= f_best + 1e-12:\n                                    step_norm = (x_surr - m) / (sigma + 1e-20)\n                                    success_buffer.append(step_norm.copy())\n                                    if len(success_buffer) > self.buffer_size:\n                                        del success_buffer[0: (len(success_buffer) - self.buffer_size)]\n                except Exception:\n                    pass\n\n            # update smoothed success and adapt sigma\n            # success indicator: any of batch improved global best\n            gen_success = float(any(np.asarray(batch_f) < (f_best + 1e-16)) if len(batch_f) > 0 else False)\n            p_succ = 0.9 * p_succ + 0.1 * gen_success\n            # multiplicative update\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            # keep sigma in reasonable bounds\n            sigma = np.clip(sigma, 1e-12, 3.0 * avg_span)\n\n            # per-dim sigma_diag re-evaluate from v_rms\n            sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-9), 1e-12, 5.0 * sigma)\n\n            # PCA refresh of U from success_buffer periodically\n            if (gen % self.pca_period == 0) and len(success_buffer) >= max(3, r):\n                try:\n                    B = np.asarray(success_buffer)\n                    Bc = B - np.mean(B, axis=0, keepdims=True)\n                    U_s, S_s, Vt = np.linalg.svd(Bc, full_matrices=False)\n                    r_eff = min(r, Vt.shape[0])\n                    if r_eff > 0:\n                        U_new = Vt[:r_eff].T\n                        # blend update to avoid abrupt change\n                        if U.shape[1] == U_new.shape[1]:\n                            U = 0.85 * U + 0.15 * U_new\n                            # re-orthonormalize\n                            Q, _ = np.linalg.qr(U)\n                            U = Q[:, :r_eff]\n                        else:\n                            U = U_new.copy()\n                            Q, _ = np.linalg.qr(U)\n                            U = Q[:, :r_eff]\n                except Exception:\n                    pass\n\n            # Opportunistic restart if stagnation high\n            if stagn_counter >= stagn_limit and evals < self.budget:\n                stagn_counter = 0\n                # re-center around best with jitter proportional to sigma and avg_span\n                jitter = max(0.05 * avg_span, 0.8 * sigma)\n                m = np.minimum(np.maximum(x_best + jitter * rng.randn(self.dim), lb), ub)\n                # reset some adaptives\n                sigma = max(sigma, 0.6 * avg_span)\n                v_rms = np.full(self.dim, 1e-6)\n                e = np.ones_like(e)\n                mom = np.zeros(self.dim)\n                success_buffer = []\n                # sample a small local reseed\n                reseed = min(6, self.budget - evals)\n                for _ in range(reseed):\n                    if evals >= self.budget: break\n                    x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                    f = safe_eval(x)\n                    if f is None: break\n                    X_arch.append(x.copy()); f_arch.append(f)\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm HSMAS scored 0.192 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b49a045b-62d7-481c-95dd-d06c3592f774", "operator": null, "metadata": {"aucs": [0.056371426065145225, 0.1509033943018192, 0.7194591919930413, 0.13620195594666873, 0.12428888238294455, 0.16299332036911018, 0.16807548450787557, 0.1652914845857365, 0.12746396856167364, 0.11348618554941259]}, "task_prompt": ""}
{"id": "e175c6a8-a42b-4bc6-8208-8f005d970c6e", "fitness": 0.06387226673379881, "name": "MomentumAntitheticOPCMA", "description": "The algorithm is a compact CMA-like optimizer that keeps a small population and a Gaussian covariance (C) updated by a weighted elite covariance (cov_lr=0.18) plus a momentum-based rank-one term (rank1=0.06, mom_beta=0.85) and per-coordinate scaling (s_diag, s_diag_beta=0.6) to bias search directions and adapt anisotropy. Sampling uses antithetic Gaussian pairs around the mean with momentum bias and coordinate-wise scaling, plus an operator-pool (DE-like differential injection, trust-local Gaussian, elite-mix, and heavy‑tailed Lévy jumps) whose operators earn credits/opportunities and influence \"trust radii\" to grow/shrink local proposal scales. Robustness mechanisms include boundary reflection+clamp, SPD stabilization of C (Cholesky/eigen fallback), success-rate driven sigma adaptation (sigma_adapt_rate=0.23 toward success_target=0.2), an archive of good points, and opportunistic periodic Hooke–Jeeves local refinement and jitter/Levy escapes to balance global exploration and fast local exploitation under tight budgets. Parameters are tuned for tight-budget, multimodal scenarios (small lam, modest initial sigma ≈0.18·mean_range, operator decay op_decay=0.9, and small local-search allocations) to favor fast, mixed global/local search behavior.", "code": "import numpy as np\n\nclass MomentumAntitheticOPCMA:\n    \"\"\"\n    Momentum-Antithetic OPCMA\n\n    One-line: Compact CMA-like core with antithetic, momentum-biased Gaussian sampling,\n    an operator pool (DE, trust-local, elite-mix, levy) with credits & trust radii, and\n    periodic Hooke-Jeeves local refinement for robust global-local balance under tight budgets.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n\n        # core CMA-like knobs\n        self.cov_lr = 0.18\n        self.rank1 = 0.06\n        self.mom_beta = 0.85\n        self.s_diag_beta = 0.6\n\n        # sigma adaptation\n        self.sigma_adapt_rate = 0.23\n        self.success_target = 0.20\n        self.sigma_min_frac = 1e-12\n\n        # population / operator settings\n        self.pop_base = None\n        self.de_inject_prob = 0.12\n        self.levy_prob = 0.18\n\n        # local search\n        self.local_period = 20\n        self.local_stagn_gen = 25\n        self.initial_step_frac = 0.16\n        self.step_shrink = 0.5\n        self.min_step_frac = 1e-5\n\n        # operator-pool settings\n        self.trust_init_frac = 0.12\n        self.trust_expand = 1.12\n        self.trust_shrink = 0.88\n        self.op_decay = 0.9\n\n        # archive\n        self.archive_capacity = max(4 * self.dim, 20)\n\n    def __call__(self, func):\n        rng = np.random.RandomState(self.seed)\n\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item(), dtype=float)\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item(), dtype=float)\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        mean_range = float(np.mean(span))\n        max_span = float(np.max(span))\n        eps = 1e-12\n\n        # population size (compact)\n        if self.pop_base is None:\n            lam = max(8, int(4 + 3 * np.log(max(2, self.dim))))\n        else:\n            lam = int(self.pop_base)\n        lam = min(lam, max(2, self.budget))\n\n        # operator pool: 0=de_diff,1=trust_local_gauss,2=elite_mix,3=levy_jump\n        n_ops = 4\n        op_credit = np.ones(n_ops, dtype=float)\n\n        # initialize mean and covariance from small uniform batch\n        evals = 0\n        init_batch = min(max(4, lam), self.budget)\n        X0 = rng.uniform(lb, ub, size=(init_batch, self.dim))\n        f0 = np.empty(init_batch, dtype=float)\n        for i in range(init_batch):\n            if evals >= self.budget:\n                f0[i] = np.inf\n                continue\n            f0[i] = float(func(X0[i]))\n            evals += 1\n\n        # best so far\n        valid_idx = np.where(np.isfinite(f0))[0]\n        if valid_idx.size > 0:\n            best_idx0 = int(np.argmin(f0[valid_idx]))\n            f_best = float(f0[valid_idx][best_idx0])\n            x_best = X0[valid_idx][best_idx0].copy()\n        else:\n            f_best = np.inf\n            x_best = 0.5 * (lb + ub)\n\n        # initialize mean from elites\n        mu0 = max(1, init_batch // 2)\n        order0 = np.argsort(f0)\n        elites0 = X0[order0[:mu0]]\n        w0 = np.log(mu0 + 0.5) - np.log(np.arange(1, mu0 + 1))\n        w0 = np.maximum(w0, 0.0)\n        if np.sum(w0) <= 0:\n            w0 = np.ones_like(w0)\n        w0 /= np.sum(w0)\n        m = (w0.reshape(-1, 1) * elites0).sum(axis=0)\n\n        # covariance and sigma\n        C = np.diag(((span / 4.0) ** 2).clip(min=1e-12))\n        sigma = max(1e-12, 0.18 * mean_range)\n\n        # momentum and per-coordinate scaling\n        v = np.zeros(self.dim, dtype=float)\n        s_diag = np.ones(self.dim, dtype=float)\n        p_succ = float(self.success_target)\n\n        # archive\n        archive_X = [X0[i].copy() for i in range(init_batch)]\n        archive_f = [float(f0[i]) for i in range(init_batch)]\n        # trim archive if needed\n        if len(archive_X) > self.archive_capacity:\n            archive_X = archive_X[-self.archive_capacity:]\n            archive_f = archive_f[-self.archive_capacity:]\n\n        # trust radii for operator-local proposals\n        pop = max(12, lam)\n        trust_radius = np.full(pop, max(1e-12, self.trust_init_frac * mean_range), dtype=float)\n        # a lightweight candidate population to map operators to base indices\n        X_pop = np.tile(m.reshape(1, -1), (pop, 1))\n\n        stagn_gens = 0\n        gen = 0\n        iter_count = 0\n\n        def chol_spd(mat):\n            eps_diag = 1e-12 * np.maximum(np.diag(mat), 1.0)\n            try:\n                A = np.linalg.cholesky(mat + np.diag(eps_diag))\n                return A\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(mat)\n                vals = np.clip(vals, 1e-12, None)\n                A = (vecs * np.sqrt(vals)).T\n                return A\n\n        def reflect_then_clamp(x):\n            xr = x.copy()\n            below = xr < lb\n            if np.any(below):\n                xr[below] = lb[below] + (lb[below] - xr[below])\n            above = xr > ub\n            if np.any(above):\n                xr[above] = ub[above] - (xr[above] - ub[above])\n            xr = np.minimum(np.maximum(xr, lb), ub)\n            return xr\n\n        def archive_add(x, fx):\n            nonlocal archive_X, archive_f\n            if len(archive_f) < self.archive_capacity:\n                archive_X.append(x.copy())\n                archive_f.append(float(fx))\n            else:\n                worst = int(np.argmax(archive_f))\n                if fx < archive_f[worst]:\n                    archive_X[worst] = x.copy()\n                    archive_f[worst] = float(fx)\n\n        def hooke_jeeves_local(x_start, f_start, local_budget):\n            nonlocal evals, f_best, x_best\n            if local_budget <= 0 or evals >= self.budget:\n                return f_start, x_start\n            step = max(1e-12, self.initial_step_frac * mean_range)\n            min_step = max(1e-12, self.min_step_frac * mean_range)\n            x_work = x_start.copy()\n            f_work = float(f_start)\n            while step >= min_step and evals < self.budget and local_budget > 0:\n                moved = False\n                for d in range(self.dim):\n                    if evals >= self.budget or local_budget <= 0:\n                        break\n                    # try plus\n                    xt = x_work.copy()\n                    xt[d] = min(ub[d], xt[d] + step)\n                    xt = reflect_then_clamp(xt)\n                    fv = float(func(xt)); evals += 1; local_budget -= 1\n                    if fv < f_work:\n                        x_work = xt.copy(); f_work = fv; moved = True\n                        if fv < f_best:\n                            f_best = fv; x_best = xt.copy(); nonlocal_stagn_reset = True\n                        # opportunistic extra probe\n                        if evals < self.budget and local_budget > 0:\n                            xt2 = x_work.copy(); xt2[d] = min(ub[d], xt2[d] + step)\n                            xt2 = reflect_then_clamp(xt2)\n                            fv2 = float(func(xt2)); evals += 1; local_budget -= 1\n                            if fv2 < f_work:\n                                x_work = xt2.copy(); f_work = fv2\n                                if fv2 < f_best:\n                                    f_best = fv2; x_best = xt2.copy()\n                    else:\n                        # try minus\n                        xt = x_work.copy()\n                        xt[d] = max(lb[d], xt[d] - step)\n                        xt = reflect_then_clamp(xt)\n                        fv = float(func(xt)); evals += 1; local_budget -= 1\n                        if fv < f_work:\n                            x_work = xt.copy(); f_work = fv; moved = True\n                            if fv < f_best:\n                                f_best = fv; x_best = xt.copy()\n                if not moved:\n                    step *= self.step_shrink\n                if evals >= self.budget or local_budget <= 0:\n                    break\n            return f_work, x_work\n\n        # main loop\n        while evals < self.budget:\n            gen += 1\n            iter_count += 1\n            remaining = self.budget - evals\n            lam_iter = min(lam, remaining)\n            # ensure antithetic pairing where possible\n            if lam_iter >= 2 and lam_iter % 2 == 1:\n                lam_iter -= 1\n            lam_iter = max(1, lam_iter)\n            mu = max(1, lam_iter // 2)\n            weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n            weights = np.maximum(weights, 0.0)\n            if np.sum(weights) <= 0:\n                weights = np.ones_like(weights)\n            weights = weights / np.sum(weights)\n            W = weights.reshape(-1, 1)\n\n            A = chol_spd(C)\n\n            # candidate pool\n            Xcand = np.empty((lam_iter, self.dim), dtype=float)\n            cand_origin = np.full(lam_iter, -1, dtype=int)  # -1 gaussian core, else op index\n            # 1) antithetic Gaussian proposals (momentum biased, per-coordinate scaled)\n            half = lam_iter // 2\n            if half > 0:\n                Zpos = rng.normal(size=(half, self.dim))\n                Z = np.vstack([Zpos, -Zpos])\n                if Z.shape[0] != lam_iter:\n                    # if odd (should not happen due to parity adjustment), add one extra\n                    extra = rng.normal(size=(1, self.dim))\n                    Z = np.vstack([Z, extra])\n                Y = Z @ A.T\n                # directional momentum bias\n                vlen = np.linalg.norm(v) + 1e-20\n                if vlen > 0:\n                    v_unit = v / vlen\n                    dir_strength = 0.9 * (vlen / (1.0 + vlen))\n                    s_scalar = rng.normal(scale=dir_strength, size=(Y.shape[0], 1))\n                    Y = Y + s_scalar * v_unit.reshape(1, -1)\n                Y = Y * s_diag.reshape(1, -1)\n                Xg = m.reshape(1, -1) + sigma * Y\n                Xg = np.minimum(np.maximum(Xg, lb), ub)\n                Xcand[:lam_iter] = Xg[:lam_iter]\n                cand_origin[:] = -1\n\n            # 2) operator-driven proposals for some slots (replace a few randomly)\n            n_ops_prop = max(0, int(0.4 * lam_iter))  # 40% operator proposals\n            if n_ops_prop > 0 and lam_iter > 0:\n                # pick distinct slots to fill with operators\n                slots = rng.choice(lam_iter, size=n_ops_prop, replace=False)\n                probs = op_credit / (np.sum(op_credit) + 1e-12)\n                for idx in slots:\n                    op = rng.choice(n_ops, p=np.maximum(probs, 1e-12) / np.sum(np.maximum(probs, 1e-12)))\n                    cand_origin[idx] = op\n                    # pick base index in X_pop\n                    base_i = rng.randint(0, pop)\n                    xi = X_pop[base_i].copy()\n                    if op == 0:\n                        # DE-like archive differential injection if possible\n                        if len(archive_X) >= 3 and rng.rand() < self.de_inject_prob:\n                            ids = rng.choice(len(archive_X), size=3, replace=False)\n                            base = archive_X[ids[0]]\n                            x1 = archive_X[ids[1]]\n                            x2 = archive_X[ids[2]]\n                            F = 0.8\n                            trial = base + F * (x1 - x2) + rng.normal(scale=0.25 * sigma, size=self.dim)\n                        else:\n                            # diff-to-mean fallback\n                            others = rng.choice(pop, size=2, replace=False)\n                            trial = xi + 0.6 * (m - xi) + 0.6 * (X_pop[others[0]] - X_pop[others[1]])\n                    elif op == 1:\n                        # trust-local gaussian\n                        scale = max(1e-12, trust_radius[base_i])\n                        trial = xi + rng.randn(self.dim) * (scale * (0.4 + 0.6 * rng.rand()))\n                    elif op == 2:\n                        # elite mix\n                        if len(archive_X) > 0:\n                            elite = archive_X[rng.randint(len(archive_X))]\n                        else:\n                            elite = m\n                        alpha = 0.3 + 0.7 * rng.rand()\n                        trial = xi + alpha * (elite - xi) + rng.randn(self.dim) * (0.12 * trust_radius[base_i])\n                    else:\n                        # heavy-tailed levy-type jump\n                        center = x_best if (x_best is not None and rng.rand() < 0.8) else xi\n                        scale = 0.6 * mean_range * (0.5 + rng.rand())\n                        # standard cauchy scaled\n                        jump = rng.standard_cauchy(self.dim) * (scale * 0.6)\n                        # clip extreme outliers for safety\n                        jump = np.clip(jump, -10.0 * mean_range, 10.0 * mean_range)\n                        trial = center + jump\n                    trial = reflect_then_clamp(trial)\n                    Xcand[idx] = trial\n\n            # evaluate candidates sequentially and credit operators based on baseline\n            f_cand = np.full(lam_iter, np.inf, dtype=float)\n            baseline_best = f_best  # baseline before this batch\n            op_try = np.zeros(n_ops, dtype=float)\n            op_succ = np.zeros(n_ops, dtype=float)\n            for i in range(lam_iter):\n                if evals >= self.budget:\n                    break\n                xi = Xcand[i]\n                fv = float(func(xi))\n                f_cand[i] = fv\n                evals += 1\n                # update immediate best\n                if fv < f_best:\n                    f_best = fv\n                    x_best = xi.copy()\n                    stagn_gens = 0\n                # archive\n                archive_add(xi, fv)\n                # crediting\n                opid = cand_origin[i]\n                if opid >= 0:\n                    op_try[opid] += 1.0\n                    # success if improved beyond baseline or beat median archive at start\n                    if fv < baseline_best:\n                        op_succ[opid] += 1.0\n\n            # trim archive if too large\n            if len(archive_X) > self.archive_capacity:\n                excess = len(archive_X) - self.archive_capacity\n                archive_X = archive_X[excess:]\n                archive_f = archive_f[excess:]\n\n            # selection: take top-mu of candidates\n            valid_mask = np.isfinite(f_cand)\n            if not np.any(valid_mask):\n                # nothing evaluated in this batch (budget exhausted)\n                break\n            order = np.argsort(f_cand)\n            X_mu = Xcand[order[:mu]]\n            f_mu = f_cand[order[:mu]]\n\n            # compute deltas and weighted covariance\n            deltas = (X_mu - m) / (sigma + 1e-20)\n            if deltas.shape[0] > 0:\n                Wd = W if W.shape[0] == deltas.shape[0] else np.ones((deltas.shape[0], 1)) / deltas.shape[0]\n                weighted_cov = (deltas * Wd).T @ deltas\n                delta_mean = (Wd * deltas).sum(axis=0)\n            else:\n                weighted_cov = np.zeros((self.dim, self.dim))\n                delta_mean = np.zeros(self.dim)\n\n            # update momentum and rank-one\n            v = self.mom_beta * v + (1.0 - self.mom_beta) * delta_mean\n            rank_one = np.outer(v, v)\n\n            # covariance update\n            other = max(0.0, 1.0 - self.cov_lr - self.rank1)\n            C = other * C + self.cov_lr * weighted_cov + self.rank1 * rank_one\n            C = 0.5 * (C + C.T) + np.diag(np.maximum(np.diag(C), 1e-18))\n\n            # per-coordinate scaling update\n            if deltas.shape[0] > 0:\n                stat = np.mean(deltas ** 2, axis=0)\n            else:\n                stat = 1e-6 * np.ones(self.dim)\n            s_diag = (self.s_diag_beta * s_diag +\n                      (1.0 - self.s_diag_beta) * np.sqrt(stat + 1e-20))\n            s_diag = np.clip(s_diag, 0.15, 6.0)\n\n            # update mean\n            if X_mu.shape[0] > 0:\n                m_new = (weights.reshape(-1, 1) * X_mu[:weights.shape[0]]).sum(axis=0)\n                m = np.minimum(np.maximum(m_new, lb), ub)\n\n            # operator credit update (decay + successes)\n            if np.sum(op_try) > 0:\n                op_credit = op_credit * self.op_decay\n                op_credit[:n_ops] += op_succ  # add raw successes\n                op_credit = np.maximum(op_credit, 1e-8)\n\n            # update trust radii (expand if some operator succeeded)\n            if np.sum(op_succ) > 0:\n                n_expand = min(pop, int(1 + np.sum(op_succ)))\n                for jj in rng.choice(pop, size=n_expand, replace=False):\n                    trust_radius[jj] = min(trust_radius[jj] * self.trust_expand, mean_range)\n            else:\n                for jj in rng.choice(pop, size=min(pop, 2), replace=False):\n                    trust_radius[jj] = max(trust_radius[jj] * self.trust_shrink, 1e-12)\n\n            # success-based sigma adaptation\n            succ_frac = np.sum(f_cand < baseline_best) / max(1, np.sum(np.isfinite(f_cand)))\n            p_succ = 0.9 * p_succ + 0.1 * succ_frac\n            sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.success_target))\n            sigma = np.clip(sigma, self.sigma_min_frac, 2.0 * max_span)\n\n            # periodic or stagnation triggered local search\n            if (gen % self.local_period == 0) or (stagn_gens >= self.local_stagn_gen):\n                remaining_loc = self.budget - evals\n                if remaining_loc > 0:\n                    local_alloc = min(int(0.02 * self.budget) + 5, remaining_loc)\n                    # prefer localizing around the current best\n                    f_after, x_after = hooke_jeeves_local(x_best.copy(), f_best, local_alloc)\n                    # inject improvement\n                    if f_after < f_best:\n                        f_best = f_after\n                        x_best = x_after.copy()\n                        # nudge mean slightly toward the found local optimum\n                        m = 0.9 * m + 0.1 * x_after\n                        # update covariance a little\n                        s = (x_after - m) / (sigma + 1e-20)\n                        C = 0.98 * C + 0.02 * np.outer(s, s)\n                        stagn_gens = 0\n                    else:\n                        # if stagnating, perform mild jitter reseed around best\n                        if stagn_gens >= self.local_stagn_gen:\n                            for k in range(min(pop, 3)):\n                                if evals >= self.budget:\n                                    break\n                                jitter = rng.randn(self.dim) * (0.06 * span)\n                                newx = reflect_then_clamp(x_best + jitter)\n                                fv = float(func(newx)); evals += 1\n                                archive_add(newx, fv)\n                                if fv < f_best:\n                                    f_best = fv; x_best = newx.copy(); stagn_gens = 0\n\n            # opportunistic levy escapes if sigma collapsed or long stagnation\n            if sigma <= 1e-10 * max_span or stagn_gens > max(5, self.local_stagn_gen * 3):\n                # jitter center around best and modestly reset covariance\n                m = reflect_then_clamp(x_best + rng.randn(self.dim) * (0.05 * span))\n                C = np.diag(((span / 6.0) ** 2).clip(min=1e-12))\n                sigma = max(sigma, 0.12 * mean_range)\n                v = np.zeros_like(v)\n                s_diag = np.ones_like(s_diag)\n                stagn_gens = 0\n\n            # increment stagn counter if no improvement in this generation (approx)\n            if np.min(f_cand) < baseline_best:\n                stagn_gens = 0\n            else:\n                stagn_gens += 1\n\n            # ensure SPD\n            try:\n                _ = np.linalg.cholesky(C + np.eye(self.dim) * 1e-16)\n            except np.linalg.LinAlgError:\n                vals, vecs = np.linalg.eigh(C)\n                vals = np.clip(vals, 1e-12, None)\n                C = (vecs * vals) @ vecs.T\n\n            # update X_pop for mapping (lightweight: sample around mean to refresh population)\n            X_pop = np.minimum(np.maximum(m.reshape(1, -1) + rng.randn(pop, self.dim) * (0.5 * sigma), lb), ub)\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm MomentumAntitheticOPCMA scored 0.064 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "b49a045b-62d7-481c-95dd-d06c3592f774", "operator": null, "metadata": {"aucs": [0.12774453346759762, 0]}, "task_prompt": ""}
{"id": "4a82f186-313f-42fe-9c06-0a292e37777a", "fitness": "-inf", "name": "MATS", "description": "The algorithm maintains a drifting low‑rank manifold U (learned by an incremental covariance sketch with moderate forgetting pca_lr) and a separate exploratory basis V around a current center m and centroid, storing a small archive to estimate diversity and centroids. It fits a ridge linear surrogate in the low‑dimensional U coordinates and uses posterior (Thompson) samples of the surrogate coefficients to generate stochastic descent proposals scaled by an adaptive trust_radius. A diverse operator pool (manifold Thompson, elite flow pulls, eigen‑aligned anisotropic sampling, coordinate‑pair probes, Lévy escapes, mirror recombination, etc.) is chosen by an optimistic softmax whose scores are updated online from improvement+novelty rewards, and batch proposals are aggregated by weighted averaging to update the center. Several adaptive mechanisms (trust_radius adjusted by spectral diversity and success, per‑dim momentum/step scales, occasional U/V refreshes, and anisotropic covariance‑informed stagnation restarts with reseeding) balance exploration and exploitation, with small subspace/explore dims, small surrogate regularization, and modest population to prioritize efficient, manifold‑focused search.", "code": "import numpy as np\n\nclass MATS:\n    \"\"\"\n    Manifold Adaptive Thompson Search (MATS)\n\n    Key ideas:\n    - Maintain a drifting low-rank manifold (U) learned via an incremental covariance sketch (lightweight PCA).\n    - Maintain a slowly-rotating exploratory basis (V).\n    - Fit a ridge-linear surrogate in the manifold coordinates and perform Thompson-style sampling of its coefficients\n      to obtain stochastic descent directions (captures uncertainty & encourages exploration).\n    - A small operator pool mixes manifold Thompson-descent, flow-field pulls from elites, anisotropic eigen-sampling,\n      coordinate pair line probes, Lévy escapes, and mirror recombination.\n    - Softmax actor with optimistic update chooses operators; per-dim momentum & adaptive step scales refine local moves.\n    - Stagnation triggers anisotropic covariance-informed restarts with temperature boosts.\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10,\n                 pop=12,\n                 subspace_dim=None,\n                 explore_dim=None,\n                 init_radius=0.18,\n                 pca_lr=0.08,\n                 surrogate_reg=1e-6,\n                 seed=None):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.pop = int(pop)\n        self.seed = seed\n        self.rng = np.random.RandomState(seed)\n        self.subspace_dim = subspace_dim if subspace_dim is not None else max(1, self.dim // 6)\n        self.explore_dim = explore_dim if explore_dim is not None else max(1, self.dim // 8)\n        self.init_radius = float(init_radius)\n        self.pca_lr = float(pca_lr)  # forgetting factor / learning rate for covariance sketch\n        self.surrogate_reg = float(surrogate_reg)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        trust_radius = max(1e-8, self.init_radius * avg_span)\n\n        # archive and counters\n        X_arch = []\n        f_arch = []\n        evals = 0\n        budget = int(self.budget)\n\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch, x_best, f_best\n            if evals >= budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # simple cap archive\n            max_arch = max(200, 6 * (self.subspace_dim + self.explore_dim))\n            if len(X_arch) > max_arch:\n                del X_arch[0:len(X_arch) - max_arch]\n                del f_arch[0:len(f_arch) - max_arch]\n            if fx < f_best:\n                x_best = x.copy(); f_best = float(fx)\n            return fx\n\n        # small initialization\n        init_samples = min(max(10, int(budget // 300)), max(12, self.pop * 3))\n        for _ in range(init_samples):\n            if evals >= budget: break\n            x = rng.uniform(lb, ub)\n            try:\n                f = float(func(x)); evals += 1\n            except Exception:\n                f = float(func(x))\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        if len(f_arch) == 0 and evals < budget:\n            x = rng.uniform(lb, ub)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        # centers\n        m = x_best.copy()\n        centroid = np.mean(np.asarray(X_arch), axis=0)\n\n        # initialize U (manifold) and V (explore)\n        r = min(self.subspace_dim, self.dim)\n        U = rng.randn(self.dim, r)\n        try:\n            U, _ = np.linalg.qr(U)\n            U = U[:, :r]\n        except Exception:\n            U = U / (np.linalg.norm(U, axis=0, keepdims=True) + 1e-12)\n\n        s = min(self.explore_dim, self.dim)\n        V = rng.randn(self.dim, s)\n        try:\n            V, _ = np.linalg.qr(V)\n            V = V[:, :s]\n        except Exception:\n            V = V / (np.linalg.norm(V, axis=0, keepdims=True) + 1e-12)\n\n        # covariance sketch for incremental PCA (we keep a running covariance estimate)\n        cov_sketch = np.eye(self.dim) * ( (avg_span ** 2) * 0.01 + 1e-9 )\n\n        # per-dim momentum & step scale\n        momentum = np.zeros(self.dim)\n        step_scale = np.full(self.dim, 0.07 * avg_span)\n        step_scale = np.clip(step_scale, 1e-8, 1.0 * avg_span)\n\n        # operator pool with optimistic-softmax selection\n        operators = ['thompson_subspace', 'flow_elite', 'eigen_sample', 'coord_pair_probe', 'levy_escape', 'mirror_recombine']\n        K_ops = len(operators)\n        op_score = np.zeros(K_ops)  # higher = better, used in softmax\n        op_count = np.ones(K_ops) * 1e-6  # counts to normalize updates\n\n        # helpers\n        def get_elites(k_frac=0.12):\n            n = len(X_arch)\n            if n == 0:\n                return np.empty((0, self.dim))\n            k = max(3, int(np.ceil(k_frac * max(20, n))))\n            idxs = np.argsort(f_arch)[:min(k, n)]\n            return np.asarray([X_arch[i].copy() for i in idxs])\n\n        def perturb_V(Vmat, amp=0.05):\n            if Vmat.shape[1] == 0:\n                return Vmat\n            R = np.eye(Vmat.shape[1]) + amp * (rng.randn(Vmat.shape[1], Vmat.shape[1]) * 0.5)\n            try:\n                Q = Vmat.dot(R)\n                Q, _ = np.linalg.qr(Q)\n                return Q[:, :Vmat.shape[1]]\n            except Exception:\n                return Vmat\n\n        # fit simple ridge linear surrogate in U coordinates: f ≈ c + g^T z\n        def fit_linear_subspace(Umat, samples=None):\n            if Umat.shape[1] == 0 or len(X_arch) < (Umat.shape[1] + 6):\n                return None\n            if samples is None:\n                samples = min(200, max(40, 12 * Umat.shape[1]))\n            K = min(samples, len(X_arch))\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(Umat)  # n x r\n            n, r = Z.shape\n            Phi = np.concatenate([np.ones((n, 1)), Z], axis=1)\n            A = Phi.T.dot(Phi) + self.surrogate_reg * np.eye(r + 1)\n            b = Phi.T.dot(Fr)\n            try:\n                theta = np.linalg.solve(A, b)  # [c; g]\n            except Exception:\n                theta = np.linalg.lstsq(A, b, rcond=None)[0]\n            # estimated noise variance (residual)\n            preds = Phi.dot(theta)\n            resid = Fr - preds\n            sigma2 = max(1e-8, np.var(resid))\n            # posterior covariance approximation: cov(theta) ≈ sigma2 * A^{-1}\n            try:\n                cov_theta = sigma2 * np.linalg.inv(A)\n            except Exception:\n                cov_theta = sigma2 * np.linalg.pinv(A)\n            return (theta, cov_theta)\n\n        # thompson sample from linear surrogate to propose descent along U\n        def thompson_propose(Umat, theta, cov_theta, scale=1.0):\n            # sample theta_tilde ~ N(theta, cov_theta * temp_scale)\n            if theta is None:\n                return None\n            temp = 1.0 + 2.0 * (trust_radius / (avg_span + 1e-12))\n            try:\n                L = np.linalg.cholesky(cov_theta * temp + 1e-12 * np.eye(cov_theta.shape[0]))\n                eps = L.dot(rng.randn(cov_theta.shape[0]))\n            except Exception:\n                eps = rng.multivariate_normal(np.zeros(cov_theta.shape[0]), cov_theta * temp + 1e-12 * np.eye(cov_theta.shape[0]))\n            theta_tilde = theta + eps\n            g = theta_tilde[1:]\n            # move: z = -alpha * g (approx Newton-free step), scale by trust\n            alpha = 0.6 * scale\n            z = -alpha * g\n            # cap by projected trust radius\n            max_norm = (trust_radius / (np.linalg.norm(Umat, ord=2) + 1e-12)) * np.sqrt(max(1, Umat.shape[1]))\n            zn = np.linalg.norm(z)\n            if zn > max_norm:\n                z = z * (max_norm / (zn + 1e-12))\n            x_prop = m + Umat.dot(z)\n            return x_prop, -np.dot(theta_tilde, np.concatenate([[1.0], np.zeros_like(g)]))  # provide a primitive pred (unused heavily)\n\n        # levy step via Mantegna (alpha ~ 1.5)\n        def levy_step(scale):\n            alpha = 1.5\n            sigma_u = (np.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) /\n                       (np.gamma((1 + alpha) / 2) * alpha * 2 ** ((alpha - 1) / 2))) ** (1 / alpha)\n            u = rng.randn(self.dim) * sigma_u\n            v = rng.randn(self.dim)\n            step = u / (np.abs(v) ** (1.0 / alpha))\n            return scale * step\n\n        # operator choose via optimistic softmax\n        def op_choose():\n            # optimistic bonus ~ 1/sqrt(count)\n            bonus = 0.2 / (np.sqrt(op_count) + 1e-12)\n            scores = op_score + bonus\n            mx = np.max(scores)\n            exps = np.exp((scores - mx) / (0.2 + 0.1 * (trust_radius / (avg_span + 1e-12))))\n            p = exps / (np.sum(exps) + 1e-12)\n            idx = rng.choice(K_ops, p=p)\n            return operators[idx], idx, p[idx]\n\n        # restart params\n        gen = 0\n        stagn = 0\n        stagn_limit = max(12, int(0.02 * budget))\n\n        # main loop\n        while evals < budget:\n            gen += 1\n\n            # compute diversity via spectral entropy of covariance\n            if len(X_arch) > 4:\n                cov_full = np.cov(np.asarray(X_arch).T)\n                ev = np.linalg.eigvalsh(cov_full + 1e-12 * np.eye(self.dim))\n                ev = np.maximum(ev, 1e-16)\n                p_ev = ev / np.sum(ev)\n                diversity = -np.sum(p_ev * np.log(p_ev + 1e-12))\n            else:\n                diversity = np.log(self.dim + 1.0)\n\n            # slight adjustment of trust with diversity\n            if diversity < 0.6:\n                trust_radius = min(5.0 * avg_span, trust_radius * (1.01 + 0.01 * rng.rand()))\n            else:\n                trust_radius = max(1e-8, trust_radius * (0.995 - 0.002 * rng.rand()))\n\n            # batch of proposals per generation\n            n_batch = min(self.pop, max(1, budget - evals))\n            batch_X = []\n            batch_f = []\n            batch_ops = []\n            batch_preds = []\n\n            # occasionally update V\n            if rng.rand() < 0.35:\n                V = perturb_V(V, amp=0.05 * (1.0 + 0.8 * rng.rand()))\n\n            # update PCA sketch with recent archive items (forgetting)\n            if len(X_arch) >= 3:\n                recent = np.asarray(X_arch[-min(len(X_arch), 30):])\n                mean_recent = np.mean(recent, axis=0)\n                S_recent = np.cov(recent.T)\n                cov_sketch = (1.0 - self.pca_lr) * cov_sketch + self.pca_lr * S_recent\n                # occasionally refresh U via top eigens\n                if gen % 6 == 0:\n                    try:\n                        w, V_ev = np.linalg.eigh(cov_sketch)\n                        idxs = np.argsort(w)[::-1][:r]\n                        U = V_ev[:, idxs]\n                    except Exception:\n                        pass\n\n            # fit surrogate once per generation\n            surrogate = fit_linear_subspace(U)\n\n            for bi in range(n_batch):\n                if evals >= budget:\n                    break\n                op, idx, p_sel = op_choose()\n                x_cand = None; f_cand = None; pred = None\n\n                if op == 'thompson_subspace' and surrogate is not None:\n                    theta, cov_theta = surrogate\n                    res = thompson_propose(U, theta, cov_theta, scale=1.0)\n                    if res is not None:\n                        x_prop, pred = res\n                        x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                        f_prop = safe_eval(x_prop)\n                        if f_prop is not None:\n                            x_cand = x_prop; f_cand = f_prop\n\n                elif op == 'flow_elite':\n                    # create a flow vector as weighted sum of elite displacements\n                    Xe = get_elites(k_frac=0.15)\n                    if Xe.size != 0:\n                        Fs_local = np.array(sorted(f_arch))[:Xe.shape[0]]\n                        fmin = np.min(Fs_local) if Fs_local.size else np.min(f_arch)\n                        temps = 0.8 + 1.6 * (trust_radius / (avg_span + 1e-12))\n                        weights = np.exp(-(Fs_local - fmin) / (temps + 1e-12))\n                        weights = weights / (np.sum(weights) + 1e-12)\n                        flow = np.sum(weights[:, None] * (Xe - m), axis=0)\n                        # apply a small damping and jitter\n                        step = 0.9 * trust_radius * (flow / (np.linalg.norm(flow) + 1e-12))\n                        x_prop = np.minimum(np.maximum(m + step + 0.06 * trust_radius * rng.randn(self.dim), lb), ub)\n                        f_prop = safe_eval(x_prop)\n                        if f_prop is not None:\n                            x_cand = x_prop; f_cand = f_prop\n\n                elif op == 'eigen_sample':\n                    # sample anisotropic gaussian aligned with top eigenvectors of cov_sketch\n                    try:\n                        w, Vc = np.linalg.eigh(cov_sketch + 1e-12 * np.eye(self.dim))\n                        idxs = np.argsort(w)[::-1][:min(self.dim, 6)]\n                        basis = Vc[:, idxs]\n                        scales = np.sqrt(np.maximum(w[idxs], 1e-12))\n                        # sample in reduced eigen-basis\n                        coeff = rng.randn(len(idxs)) * (0.7 * trust_radius * scales / (np.mean(scales) + 1e-12))\n                        delta = basis.dot(coeff) + 0.02 * trust_radius * rng.randn(self.dim)\n                        x_prop = np.minimum(np.maximum(m + delta, lb), ub)\n                        f_prop = safe_eval(x_prop)\n                        if f_prop is not None:\n                            x_cand = x_prop; f_cand = f_prop\n                    except Exception:\n                        pass\n\n                elif op == 'coord_pair_probe':\n                    # pick two coords with largest variance and do bracket probes along their plane\n                    if len(X_arch) > 6:\n                        var = np.var(np.asarray(X_arch), axis=0)\n                        idxs = np.argsort(var)[-2:]\n                        i, j = int(idxs[-1]), int(idxs[-2])\n                    else:\n                        i = rng.randint(0, self.dim); j = rng.randint(0, self.dim)\n                    d = np.zeros(self.dim); d[i] = 1.0; d[j] = 0.6 * (rng.randn() * 0.5 + 0.5)\n                    d = d / (np.linalg.norm(d) + 1e-12)\n                    scales = np.array([0.2, 0.5, 1.0]) * trust_radius\n                    best_x = None; best_f = 1e99\n                    for s in scales:\n                        if evals >= budget: break\n                        for sign in (+1.0, -1.0):\n                            x_try = m + sign * s * d\n                            x_try = np.minimum(np.maximum(x_try, lb), ub)\n                            f_try = safe_eval(x_try)\n                            if f_try is None:\n                                break\n                            if f_try < best_f:\n                                best_f = f_try; best_x = x_try.copy()\n                    if best_x is not None:\n                        x_cand = best_x; f_cand = best_f\n\n                elif op == 'levy_escape':\n                    # jump from either centroid or a random elite\n                    Xe = get_elites()\n                    if Xe.size and rng.rand() < 0.7:\n                        center = Xe[rng.randint(0, Xe.shape[0])]\n                    else:\n                        center = centroid\n                    step = levy_step(2.5 * trust_radius)\n                    step = np.clip(step, -6.0 * trust_radius, 6.0 * trust_radius)\n                    x_prop = np.minimum(np.maximum(center + step, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n\n                elif op == 'mirror_recombine':\n                    # reflect a poor elite about the best (diversifying)\n                    Xe = get_elites(k_frac=0.25)\n                    if Xe.size >= 2:\n                        worst_idx = -1\n                        candidate = Xe[rng.randint(0, Xe.shape[0])]\n                        mirror = x_best + 0.9 * (x_best - candidate) + 0.05 * trust_radius * rng.randn(self.dim)\n                    else:\n                        mirror = m + 0.6 * trust_radius * rng.randn(self.dim)\n                    x_prop = np.minimum(np.maximum(mirror, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n\n                # record and meta-updates\n                if f_cand is not None:\n                    batch_X.append(x_cand.copy())\n                    batch_f.append(f_cand)\n                    batch_ops.append(idx)\n                    batch_preds.append(pred if pred is not None else f_cand)\n\n                    # reward: improvement normalized + novelty bonus (distance from m)\n                    imp = max(0.0, f_best - f_cand)\n                    novelty = np.linalg.norm(x_cand - m) / (avg_span + 1e-12)\n                    reward = 0.7 * (imp / (abs(f_best) + 1e-12)) + 0.3 * min(1.0, novelty)\n                    reward = max(-0.2, min(1.5, reward))\n\n                    # update operator statistics (soft incremental)\n                    op_count[idx] += 1.0\n                    lr = 0.15 / np.sqrt(op_count[idx])\n                    # optimistic: add reward directly to score with small momentum\n                    op_score[idx] = (1.0 - lr) * op_score[idx] + lr * reward * (1.0 + 0.2 * rng.rand())\n\n                    # update manifold U using the displacement (incremental PCA-style)\n                    zc = (x_cand - m)\n                    # update sketch: cov_sketch = (1-lr) cov + lr * zc zc^T\n                    cov_sketch = (1.0 - self.pca_lr) * cov_sketch + self.pca_lr * np.outer(zc, zc)\n                    # occasionally refresh U columns from top eigenvectors\n                    if rng.rand() < 0.18:\n                        try:\n                            w, V_ev = np.linalg.eigh(cov_sketch + 1e-12 * np.eye(self.dim))\n                            idxs = np.argsort(w)[::-1][:r]\n                            U = V_ev[:, idxs]\n                        except Exception:\n                            pass\n\n                    # small injection into V\n                    if rng.rand() < 0.18 and V.shape[1] > 0:\n                        j = rng.randint(0, V.shape[1])\n                        newcol = zc / (np.linalg.norm(zc) + 1e-12)\n                        V[:, j] = 0.82 * V[:, j] + 0.18 * newcol\n                        try:\n                            V, _ = np.linalg.qr(V); V = V[:, :V.shape[1]]\n                        except Exception:\n                            pass\n\n                    # momentum & step adaption\n                    momentum = 0.8 * momentum + 0.2 * (m - x_cand)\n                    # if improvement, shrink trust and reset stagnation\n                    if f_cand < f_best - 1e-12:\n                        f_best = float(f_cand); x_best = x_cand.copy()\n                        trust_radius = max(1e-8, trust_radius * 0.78)\n                        stagn = 0\n                    else:\n                        trust_radius = min(5.0 * avg_span, trust_radius * (1.006 + 0.002 * rng.rand()))\n                        stagn += 1\n\n                else:\n                    break  # budget exhausted\n\n            # center aggregation: weighted mean of batch proposals (Rényi-like)\n            if len(batch_X) > 0:\n                Xs = np.asarray(batch_X)\n                Fs = np.asarray(batch_f)\n                fmin = np.min(Fs)\n                temp = max(1e-6, 0.6 * (trust_radius / (avg_span + 1e-12)) * (1.0 + 0.5 * (1.0 - diversity)))\n                weights = np.exp(-(Fs - fmin) / (temp + 1e-12))\n                weights = weights / (np.sum(weights) + 1e-12)\n                xr = np.sum(weights[:, None] * Xs, axis=0)\n                mix = 0.45 if trust_radius < 0.4 * avg_span else 0.28\n                new_m = (1.0 - mix) * m + mix * xr\n                # small pull to centroid\n                new_m = 0.84 * new_m + 0.16 * centroid\n                delta = new_m - m\n                max_jump = 3.0 * trust_radius * np.sqrt(max(1, self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > max_jump:\n                    delta = delta * (max_jump / (dn + 1e-12))\n                m = np.minimum(np.maximum(m + delta, lb), ub)\n                # if any improved, shrink trust\n                if np.any(Fs < f_best):\n                    trust_radius = max(1e-8, trust_radius * 0.86)\n                else:\n                    trust_radius = min(5.0 * avg_span, trust_radius * 1.02)\n\n            # update centroid occasionally\n            if len(X_arch) > 4 and gen % 4 == 0:\n                centroid = np.mean(np.asarray(X_arch[-min(len(X_arch), 50):]), axis=0)\n\n            # stagnation restart\n            if stagn >= stagn_limit and evals < budget:\n                stagn = 0\n                Xe = get_elites()\n                if Xe.size:\n                    new_center = Xe[rng.randint(0, Xe.shape[0])]\n                else:\n                    new_center = x_best.copy()\n                # anisotropic jitter using cov_sketch eigenbasis\n                try:\n                    w, Vc = np.linalg.eigh(cov_sketch)\n                    w = np.maximum(w, 1e-12)\n                    sqrtC = Vc.dot(np.diag(np.sqrt(w))).dot(Vc.T)\n                    jitter = 1.4 * trust_radius * (0.6 * rng.randn(self.dim) + 0.4 * (sqrtC.dot(rng.randn(self.dim))))\n                except Exception:\n                    jitter = 1.4 * trust_radius * rng.randn(self.dim)\n                m = np.minimum(np.maximum(new_center + jitter, lb), ub)\n                trust_radius = min(5.0 * avg_span, trust_radius * 1.9)\n                # reseed a few local candidates around best\n                for _ in range(min(8, budget - evals)):\n                    x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                    f = safe_eval(x)\n                    if f is None:\n                        break\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "error": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "parent_ids": "3fb1d17b-671f-44d8-8625-cf8b6753dc76", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "d129d741-221e-4e51-96a2-9786beab4204", "fitness": "-inf", "name": "SDAR", "description": "The SDAR design maintains two complementary spectral subspaces — U_exploit (a small Oja-updated low-rank basis for exploitation) and V_explore (a slowly rotating random basis for exploration) — plus an archive and two centers (current m and centroid) seeded by an initial uniform sampling (pop≈16, subspace_dim≈dim//4, explore_dim≈dim//5, init_trust≈0.1·avg_span). It fits a damped low-rank quadratic surrogate in U (ridge regularization, stronger curvature floor, Levenberg-like damping lam0≈0.12) to propose trust-limited Newton-like steps (z* capped by projected trust radius) while keeping surrogate fits conservative (surrogate_reg small, sample caps). Generation is driven by a diverse operator pool (subspace_newton, multi-scale random_subspace_probe, coordinate tweaks with per-dimension momentum/step_scale, curvature finite-difference probes, heavy-tailed Lévy jumps, and elite crossover with shrinkage-covariance jitter), chosen via a tempered softmax over log-weights that are multiplicatively updated from shaped rewards (eta schedule, gamma_explore≈0.15). Adaptation mechanisms include trust-radius adjustments based on spectral-entropy diversity, Oja_lr tuning and occasional V rotations, renyi-weighted aggregation to move the center, shrinkage covariance for robust jitter, stagnation-driven anisotropic restarts, and strict budget/bound handling via safe_eval.", "code": "import numpy as np\n\nclass SDAR:\n    \"\"\"\n    Spectral Dual-Basis Adaptive Rotations (SDAR)\n\n    Main idea (short): Maintain two spectral subspaces (U_exploit: Oja-updated low-rank; V_explore: rotating random basis),\n    fit a damped low-rank quadratic surrogate in U_exploit (diag curvature + adaptive Levenberg-like damping),\n    and drive candidate generation through a small operator pool chosen by a tempered softmax whose log-weights\n    are multiplicatively updated from shaped rewards. Trust radius, momentum, and step scales adapt differently\n    compared to the reference (different default constants, different damping and trust rules).\n\n    Key tunable parameters (defaults intentionally different from the provided algorithm):\n    - pop: population per generation (default 16)\n    - subspace_dim: exploitation subspace dimension (default max(1, dim//4))\n    - explore_dim: exploration subspace dimension (default max(1, dim//5))\n    - init_trust_rel: initial trust relative to avg span (default 0.10)\n    - oja_lr: Oja learning rate for U updates (default 0.02)\n    - surrogate_reg: ridge regularization for surrogate fit (default 1e-4)\n    - gamma_explore: exploration fraction in operator selection (default 0.15)\n    - min_trust / max_trust: trust bounds (default 1e-10, 1e1)\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop=16, subspace_dim=None, explore_dim=None,\n                 init_trust=0.10, oja_lr=0.02, surrogate_reg=1e-4,\n                 gamma_explore=0.15, min_trust=1e-10, max_trust=10.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.rng = np.random.RandomState(seed)\n        self.pop = int(pop)\n        self.subspace_dim = subspace_dim if subspace_dim is not None else max(1, self.dim // 4)\n        self.explore_dim = explore_dim if explore_dim is not None else max(1, self.dim // 5)\n        self.init_trust_rel = float(init_trust)\n        self.oja_lr = float(oja_lr)\n        self.surrogate_reg = float(surrogate_reg)\n        self.gamma_explore = float(gamma_explore)\n        self.min_trust = float(min_trust)\n        self.max_trust = float(max_trust)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # Handle bounds (support scalar or vector), default [-5,5]\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        trust_radius = max(self.min_trust, self.init_trust_rel * avg_span)\n\n        # Archive and counters\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # small initialization sampling (a few more samples than extreme minima)\n        init_samples = min(max(12, int(self.budget // 250)), max(24, self.pop * 4))\n        for _ in range(init_samples):\n            if evals >= self.budget:\n                break\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        if len(f_arch) == 0 and evals < self.budget:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        # two centers\n        m = x_best.copy()\n        centroid = np.mean(np.asarray(X_arch), axis=0)\n\n        # initialize U_exploit and V_explore (orthonormal)\n        r = min(self.subspace_dim, self.dim)\n        U = rng.randn(self.dim, r)\n        try:\n            U, _ = np.linalg.qr(U)\n            U = U[:, :r]\n        except Exception:\n            U = U / (np.linalg.norm(U, axis=0, keepdims=True) + 1e-12)\n\n        s = min(self.explore_dim, self.dim)\n        V = rng.randn(self.dim, s)\n        try:\n            V, _ = np.linalg.qr(V)\n            V = V[:, :s]\n        except Exception:\n            V = V / (np.linalg.norm(V, axis=0, keepdims=True) + 1e-12)\n\n        # per-dimension momentum and adaptive step sizes\n        momentum = np.zeros(self.dim)\n        step_scale = np.full(self.dim, 0.06 * avg_span)  # different scale than reference\n        step_scale = np.clip(step_scale, 1e-9, 1.2 * avg_span)\n\n        # operator pool and tempered softmax weights (log-space)\n        operators = ['subspace_newton', 'random_subspace_probe', 'coord_tweak',\n                     'curvature_probe', 'levy_jump', 'elite_crossover']\n        K = len(operators)\n        log_w = np.zeros(K)\n        temp_softmax = 1.2  # temperature in softmax (different equation)\n\n        # helper: safe evaluation that respects budget and maintains archive\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch, x_best, f_best\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # keep archive to reasonable size\n            max_arch = max(5 * (self.subspace_dim + self.explore_dim), 240)\n            if len(X_arch) > max_arch:\n                cut = len(X_arch) - max_arch\n                del X_arch[:cut]\n                del f_arch[:cut]\n            if fx < f_best:\n                x_best = x.copy(); f_best = float(fx)\n            return fx\n\n        # elites\n        def get_elites(k_frac=0.14):\n            n = len(X_arch)\n            if n == 0:\n                return np.empty((0, self.dim))\n            k = max(4, int(np.ceil(k_frac * max(20, n))))\n            idxs = np.argsort(f_arch)[:min(k, n)]\n            return np.asarray([X_arch[i].copy() for i in idxs])\n\n        # Shrinkage covariance estimator for jittering\n        def shrink_cov(Xe, shrink=0.10):\n            if Xe.size == 0:\n                return np.eye(self.dim)\n            S = np.cov(Xe.T) if Xe.shape[0] > 1 else np.zeros((self.dim, self.dim))\n            F = np.trace(S) / max(1, self.dim)\n            C = (1.0 - shrink) * S + shrink * F * np.eye(self.dim)\n            C += 1e-12 * np.eye(self.dim)\n            return C\n\n        # Oja step but with slightly smaller stabilization and optional normalization\n        def oja_update(Umat, z, lr):\n            if Umat.shape[1] == 0:\n                return Umat\n            zn = z / (np.linalg.norm(z) + 1e-12)\n            for j in range(Umat.shape[1]):\n                uj = Umat[:, j]\n                proj = np.dot(zn, uj)\n                # modified Oja incremental rule (different coefficients)\n                uj = uj + lr * (proj * zn - (proj**2) * uj * 0.5)\n                Umat[:, j] = uj\n            try:\n                Q, _ = np.linalg.qr(Umat)\n                return Q[:, :Umat.shape[1]]\n            except Exception:\n                norms = np.linalg.norm(Umat, axis=0) + 1e-12\n                return Umat / norms\n\n        # slowly rotate V_explore via small random orthonormal perturbation\n        def rotate_V(Vmat, amp=0.10):\n            if Vmat.shape[1] == 0:\n                return Vmat\n            # small skew-symmetric perturbation\n            A = amp * (rng.randn(Vmat.shape[1], Vmat.shape[1]) - rng.randn(Vmat.shape[1], Vmat.shape[1]).T) * 0.3\n            try:\n                R = np.eye(Vmat.shape[1]) + A\n                Q = Vmat.dot(R)\n                Q, _ = np.linalg.qr(Q)\n                return Q[:, :Vmat.shape[1]]\n            except Exception:\n                return Vmat\n\n        # Fit damped low-rank quadratic surrogate in U: c + g^T z + 0.5 * diag(h) z^2\n        # with Levenberg-like adaptive damping to compute a trust-limited subspace minimizer\n        def fit_surrogate(Umat, samples=None):\n            if Umat.shape[1] == 0 or len(X_arch) < (Umat.shape[1] + 6):\n                return None\n            if samples is None:\n                samples = min(200, max(40, Umat.shape[1] * 18))\n            Ks = min(samples, len(X_arch))\n            Xr = np.asarray(X_arch[-Ks:])\n            Fr = np.asarray(f_arch[-Ks:])\n            Z = (Xr - m).dot(Umat)  # n x r\n            n, r = Z.shape\n            # design matrix: [1, z1..zr, z1^2..zr^2] (like before) but with stronger regularization\n            Phi = np.ones((n, 1 + r + r))\n            Phi[:, 1:1 + r] = Z\n            Phi[:, 1 + r:1 + r + r] = Z ** 2\n            try:\n                A = Phi.T.dot(Phi) + self.surrogate_reg * np.eye(Phi.shape[1])\n                b = Phi.T.dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1 + r]\n                Hdiag = coeff[1 + r:1 + r + r]\n                # impose moderate curvature floor and allow moderate negativity\n                Hdiag = np.clip(Hdiag, -1e-2, np.maximum(Hdiag, 1e-6))\n                # compute LM-like damping\n                lam0 = 0.12  # different base damping\n                damping = lam0 * (1.0 + np.linalg.norm(g))\n                # compute Newton-like step with damping\n                zstar = - g / (Hdiag + damping + 1e-12)\n                # cap subspace norm by trust projected into subspace via spectral norm\n                max_norm = (trust_radius / (np.linalg.norm(Umat, ord=2) + 1e-12)) * np.sqrt(max(1, r)) * 0.9\n                znorm = np.linalg.norm(zstar)\n                if znorm > max_norm:\n                    zstar = zstar * (max_norm / (znorm + 1e-12))\n                fpred = float(c + g.dot(zstar) + 0.5 * np.sum(Hdiag * (zstar ** 2)))\n                return (zstar, fpred, (g, Hdiag, c))\n            except Exception:\n                return None\n\n        # operator chooser: tempered softmax + exploration mixing\n        def choose_op():\n            nonlocal temp_softmax\n            maxlw = np.max(log_w)\n            exps = np.exp((log_w - maxlw) / (temp_softmax + 1e-12))\n            probs = exps / (np.sum(exps) + 1e-12)\n            # mix with gamma_explore uniform\n            p = (1.0 - self.gamma_explore) * probs + self.gamma_explore / K\n            idx = rng.choice(K, p=p)\n            return operators[idx], idx, p[idx]\n\n        # Renyi-like weighting used for aggregation (slightly different alpha)\n        def renyi_weights(fs, alpha=0.88, temp=1.0):\n            fmin = np.min(fs)\n            delta = (fs - fmin) / (temp + 1e-12)\n            w = np.exp(-delta) ** alpha\n            w = w / (np.sum(w) + 1e-12)\n            return w\n\n        # Levy step variant (alpha=1.2 heavier tail than previous)\n        def levy_step(scale):\n            alpha = 1.2\n            sigma_u = (np.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) /\n                       (np.gamma((1 + alpha) / 2) * alpha * 2 ** ((alpha - 1) / 2))) ** (1 / alpha)\n            u = rng.randn(self.dim) * sigma_u\n            v = rng.randn(self.dim)\n            step = u / (np.abs(v) ** (1.0 / alpha))\n            return scale * step\n\n        # Main loop\n        gen = 0\n        stagn = 0\n        stagn_limit = max(8, int(0.015 * self.budget))\n\n        while evals < self.budget:\n            gen += 1\n\n            # elites and covariance\n            Xe = get_elites()\n            Csh = shrink_cov(Xe)\n\n            # diversity proxy via spectral entropy of recent archive covariance\n            try:\n                cov_full = np.cov(np.asarray(X_arch).T) if len(X_arch) > 5 else np.eye(self.dim)\n                ev = np.linalg.eigvalsh(cov_full + 1e-12 * np.eye(self.dim))\n                ev = np.maximum(ev, 1e-16)\n                p_ev = ev / np.sum(ev)\n                diversity = -np.sum(p_ev * np.log(p_ev + 1e-12))\n            except Exception:\n                diversity = 0.0\n\n            # trust adaptation: if diversity low, expand; if high, slowly contract (different multipliers)\n            if diversity < 0.6:\n                trust_radius = min(self.max_trust, trust_radius * (1.03 + 0.006 * rng.rand()))\n            else:\n                trust_radius = max(self.min_trust, trust_radius * (0.995 - 0.002 * rng.rand()))\n\n            # batch for this generation\n            n_batch = min(self.pop, max(1, self.budget - evals))\n            batch_X = []\n            batch_f = []\n            batch_ops = []\n            batch_preds = []\n\n            # sometimes rotate exploration basis\n            if rng.rand() < 0.35:\n                V = rotate_V(V, amp=0.08 * (1.0 + 0.5 * rng.rand()))\n\n            # fit surrogate once per generation\n            surrogate = fit_surrogate(U)\n\n            for bi in range(n_batch):\n                if evals >= self.budget:\n                    break\n                op, idx, p_sel = choose_op()\n                x_cand = None; f_cand = None; pred = None\n\n                if op == 'subspace_newton' and surrogate is not None:\n                    zstar, fpred, params = surrogate\n                    x_prop = m + U.dot(zstar)\n                    x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop; pred = fpred\n\n                elif op == 'random_subspace_probe':\n                    # build a random direction combining a few U or V columns\n                    if U.shape[1] > 0 and rng.rand() < 0.7:\n                        kdir = min(2 + rng.randint(0, 3), U.shape[1])\n                        inds = rng.choice(U.shape[1], size=kdir, replace=False)\n                        d = np.sum(U[:, inds] * (rng.randn(kdir) * 0.5 + 0.5), axis=1)\n                    else:\n                        if V.shape[1] > 0 and rng.rand() < 0.9:\n                            kdir = min(3, V.shape[1])\n                            inds = rng.choice(V.shape[1], size=kdir, replace=False)\n                            d = np.sum(V[:, inds] * (rng.randn(kdir) * 0.6 + 0.4), axis=1)\n                        else:\n                            d = rng.randn(self.dim)\n                    d = d / (np.linalg.norm(d) + 1e-12)\n                    scales = np.array([0.4, 1.0, 2.0]) * trust_radius * (0.8 + 0.4 * rng.rand())\n                    best_x = None; best_f = 1e99\n                    for s in scales:\n                        if evals >= self.budget: break\n                        x_try = np.minimum(np.maximum(m + s * d, lb), ub)\n                        f_try = safe_eval(x_try)\n                        if f_try is None:\n                            break\n                        if f_try < best_f:\n                            best_f = f_try; best_x = x_try.copy()\n                    if best_x is not None:\n                        x_cand = best_x; f_cand = best_f\n\n                elif op == 'coord_tweak':\n                    # pick coordinate proportional to variance + momentum\n                    if len(X_arch) > 8:\n                        var = np.var(np.asarray(X_arch), axis=0)\n                        i = int(np.argmax(var + 1e-12 * (np.abs(momentum))))\n                    else:\n                        i = rng.randint(0, self.dim)\n                    m_i = momentum[i]\n                    base = step_scale[i] * (0.7 + 0.6 * rng.rand()) * (trust_radius / (avg_span + 1e-12))\n                    cand = m.copy()\n                    # use a tempered momentum adjustment (different coefficients)\n                    cand[i] = np.clip(cand[i] - (0.5 * m_i + 0.5 * base), lb[i], ub[i])\n                    f_try = safe_eval(cand)\n                    if f_try is not None:\n                        x_cand = cand; f_cand = f_try\n                        momentum[i] = 0.6 * m_i + 0.3 * (m[i] - cand[i])\n                        if f_try < f_best - 1e-12:\n                            step_scale[i] = min(step_scale[i] * 1.12, 1.2 * avg_span)\n\n                elif op == 'curvature_probe':\n                    # directional finite difference around m (different eps)\n                    if U.shape[1] > 0 and rng.rand() < 0.8:\n                        kdir = min(3, U.shape[1])\n                        inds = rng.choice(U.shape[1], kdir, replace=False)\n                        d = np.sum(U[:, inds] * (1.0 + 0.2 * rng.randn(kdir)), axis=1)\n                    else:\n                        d = rng.randn(self.dim)\n                    d = d / (np.linalg.norm(d) + 1e-12)\n                    eps = 0.04 * trust_radius + 1e-9\n                    x_plus = np.minimum(np.maximum(m + eps * d, lb), ub)\n                    f_plus = safe_eval(x_plus)\n                    if f_plus is None:\n                        break\n                    x_minus = np.minimum(np.maximum(m - eps * d, lb), ub)\n                    f_minus = safe_eval(x_minus)\n                    if f_minus is None:\n                        break\n                    # directional curvature approx but anchored to local best estimate (not f_best directly)\n                    sec = (f_plus + f_minus - 2.0 * ((f_plus + f_minus) / 2.0)) / ((eps ** 2) + 1e-12)\n                    # simplified decision: step opposite sign of directional derivative average\n                    deriv = (f_plus - f_minus) / (2 * eps + 1e-12)\n                    if abs(deriv) > 1e-12:\n                        step_len = min(1.4 * trust_radius, (0.5 * abs(deriv) / (abs(sec) + 1e-12 + 1e-6)))\n                    else:\n                        step_len = 1.0 * trust_radius\n                    x_prop = np.minimum(np.maximum(m - np.sign(deriv) * step_len * d, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n\n                elif op == 'levy_jump':\n                    if Xe.size and rng.rand() < 0.75:\n                        center = Xe[rng.randint(0, Xe.shape[0])]\n                    else:\n                        center = centroid\n                    step = levy_step(2.8 * trust_radius)\n                    step = np.clip(step, -6.0 * trust_radius, 6.0 * trust_radius)\n                    x_prop = np.minimum(np.maximum(center + step, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n\n                elif op == 'elite_crossover':\n                    if Xe.size >= 2:\n                        i1, i2 = rng.choice(Xe.shape[0], size=2, replace=False)\n                        alpha = rng.beta(1.0, 1.0)\n                        child = alpha * Xe[i1] + (1.0 - alpha) * Xe[i2]\n                    else:\n                        child = m.copy()\n                    C = shrink_cov(Xe)\n                    try:\n                        wv, Vmat = np.linalg.eigh(C)\n                        wv = np.maximum(wv, 1e-12)\n                        sqrtC = Vmat.dot(np.diag(np.sqrt(wv))).dot(Vmat.T)\n                        jitter = 0.8 * trust_radius * (0.4 * rng.randn(self.dim) + 0.6 * (sqrtC.dot(rng.randn(self.dim))))\n                    except Exception:\n                        jitter = 0.9 * trust_radius * rng.randn(self.dim)\n                    x_prop = np.minimum(np.maximum(child + jitter, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n\n                if f_cand is not None:\n                    batch_X.append(x_cand.copy())\n                    batch_f.append(f_cand)\n                    batch_ops.append(idx)\n                    batch_preds.append(pred if pred is not None else f_cand)\n\n                    # reward shaping: combine normalized improvement, predicted accuracy and diversity bonus\n                    imp = max(0.0, f_best - f_cand)\n                    pred_diff = 0.0\n                    if pred is not None:\n                        pred_diff = np.clip((pred - f_cand) / (abs(f_best) + 1e-12), -1.0, 1.0)\n                    div_bonus = 0.0\n                    if diversity < 0.7 and op == 'levy_jump':\n                        div_bonus = 0.06  # reward exploration when diversity low\n                    reward = 0.55 * (imp / (abs(f_best) + 1e-12)) + 0.35 * pred_diff + 0.1 * div_bonus\n                    reward = np.clip(reward, -0.25, 1.25)\n\n                    # update log weights (different eta schedule)\n                    eta = min(0.35, 0.6 / np.sqrt(1 + gen))\n                    # compute current softmax probs for importance weighting\n                    maxlw = np.max(log_w)\n                    exps_local = np.exp((log_w - maxlw) / (temp_softmax + 1e-12))\n                    prob_local = exps_local / (np.sum(exps_local) + 1e-12)\n                    est = reward / (prob_local[idx] + 1e-12)\n                    log_w[idx] += eta * est\n                    # small decay / jitter to keep exploration\n                    log_w -= 5e-5 * rng.rand(K)\n\n                    # update spectral bases\n                    zc = x_cand - m\n                    U = oja_update(U, zc, lr=self.oja_lr * (0.4 + 0.6 * rng.rand()))\n                    if rng.rand() < 0.18:\n                        if V.shape[1] > 0:\n                            j = rng.randint(0, V.shape[1])\n                            newcol = zc / (np.linalg.norm(zc) + 1e-12)\n                            V[:, j] = 0.80 * V[:, j] + 0.20 * newcol\n                            try:\n                                V, _ = np.linalg.qr(V); V = V[:, :V.shape[1]]\n                            except Exception:\n                                V = V / (np.linalg.norm(V, axis=0, keepdims=True) + 1e-12)\n\n                    # trust adaptation\n                    if f_cand < f_best - 1e-12:\n                        f_best = float(f_cand); x_best = x_cand.copy()\n                        # successful exploitation: mildly reduce trust (different multiplier)\n                        trust_radius = max(self.min_trust, trust_radius * 0.82)\n                        stagn = 0\n                    else:\n                        trust_radius = min(self.max_trust, trust_radius * (1.006 + 0.003 * rng.rand()))\n                        stagn += 1\n                else:\n                    break  # budget exhausted\n\n            # aggregation: renyi-weighted average of batch improvements toward new center\n            if len(batch_X) > 0:\n                Xs = np.asarray(batch_X)\n                Fs = np.asarray(batch_f)\n                temp = max(1e-6, 0.7 * (trust_radius / (avg_span + 1e-12)) * (1.0 + 0.5 * (0.9 - diversity)))\n                weights = renyi_weights(Fs, alpha=0.9, temp=temp)\n                xr = np.sum(weights[:, None] * Xs, axis=0)\n                # compute combined center move (different mixing)\n                mix = 0.45 if trust_radius < 0.35 * avg_span else 0.28\n                new_m = (1.0 - mix) * m + mix * xr\n                new_m = 0.80 * new_m + 0.20 * centroid\n                delta = new_m - m\n                max_jump = 3.0 * trust_radius * np.sqrt(max(1, self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > max_jump:\n                    delta = delta * (max_jump / (dn + 1e-12))\n                m = np.minimum(np.maximum(m + delta, lb), ub)\n\n                # shrink trust if there were improvements, else slightly expand to encourage exploration\n                if np.any(Fs < f_best):\n                    trust_radius = max(self.min_trust, trust_radius * 0.86)\n                else:\n                    trust_radius = min(self.max_trust, trust_radius * 1.03)\n\n            # update centroid occasionally\n            if len(X_arch) > 6 and gen % 4 == 0:\n                centroid = np.mean(np.asarray(X_arch[-min(len(X_arch), 48):]), axis=0)\n\n            # stagnation-driven restart with anisotropic jitter (different params)\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                if Xe.size:\n                    new_center = Xe[rng.randint(0, Xe.shape[0])]\n                else:\n                    new_center = x_best.copy()\n                C = shrink_cov(Xe)\n                try:\n                    wv, Vc = np.linalg.eigh(C)\n                    wv = np.maximum(wv, 1e-12)\n                    sqrtC = Vc.dot(np.diag(np.sqrt(wv))).dot(Vc.T)\n                except Exception:\n                    sqrtC = np.eye(self.dim)\n                jitter_scale = max(0.06 * avg_span, 1.8 * trust_radius)\n                m = np.minimum(np.maximum(new_center + jitter_scale * (0.5 * rng.randn(self.dim) + 0.5 * (sqrtC.dot(rng.randn(self.dim)))), lb), ub)\n                trust_radius = min(self.max_trust, trust_radius * 1.9)\n                # reseed a few local points around best (with budget check)\n                for _ in range(min(10, self.budget - evals)):\n                    x = np.minimum(np.maximum(x_best + 0.03 * avg_span * rng.randn(self.dim), lb), ub)\n                    f = safe_eval(x)\n                    if f is None:\n                        break\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "error": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "parent_ids": "3fb1d17b-671f-44d8-8625-cf8b6753dc76", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "bf99284b-3b60-4dea-8e82-025fcb8a0da5", "fitness": "-inf", "name": "EAME", "description": "EAME maintains a small ensemble of anchors (default n_anchors=6) — each with a center, trust radius (init_trust = init_trust_rel·avg_span, default 0.18), a bounded local history (max_hist=32) and a low‑rank direction bank built from recent successful displacements, while a capped global archive/centroid collects evaluations for cross‑anchor information. A compact operator pool (scout_levy, anchor_line, subspace_polish, cov_jitter, anchor_recombine) is scheduled by a UCB‑style meta‑allocator (op UCB exploration c≈1.4 with pseudo‑counts) and anchors are chosen by an anchor‑level UCB (bonus ≈1.2), yielding optimism‑driven exploration/exploitation across basins. Local refinement uses entropy‑guided subspace construction (PCA on hist_X), a tiny surrogate (constant + linear + diagonal quadratic with surrogate_reg=1e-6) to produce damped Newton‑like steps in the subspace, plus bracketed multi‑scale line probes (scales 0.15,0.5,1.0×trust) and secant/quasi‑Newton fallbacks. Global diversification and escape are provided by Mantegna Lévy scouts (α≈1.5, scale multiplier ≈2.2), covariance‑aware anisotropic jitter (shrink toward isotropic ≈0.14), anchor recombination, adaptive trust annealing/resets and stale‑anchor replacement for robust multiscale search.", "code": "import numpy as np\n\nclass EAME:\n    \"\"\"\n    Entropic Anchor-Based Multiscale Explorer (EAME)\n\n    Key ideas:\n    - Maintain a small set of anchors (centers) each with its own trust radius, local history and\n      low-rank \"direction bank\" built from recent successful displacements.\n    - Operators chosen by a UCB-style allocator (optimism in face of uncertainty) over a small operator pool.\n    - Entropy-guided subspace construction: for each anchor build an orthonormal subspace from recent displacements\n      and choose search directions from high-variance orthogonal components.\n    - Lightweight local polynomial surrogate (linear + diagonal quadratic in the subspace) is fit per-anchor\n      from nearby archive points to propose damped quasi-Newton minimizers in the subspace.\n    - Multiscale bracketed line-searches, Lévy scouts for heavy-tailed escapes, covariance-aware jitter restarts,\n      and anisotropic recombination between anchors.\n    - Per-anchor UCB scores manage which anchor to refine next (exploitation vs exploration across basins).\n    \"\"\"\n\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 n_anchors=6, init_trust_rel=0.18, min_trust=1e-8, max_trust=5.0,\n                 surrogate_reg=1e-6, max_hist=32):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.rng = np.random.RandomState(seed)\n        self.n_anchors = max(1, int(n_anchors))\n        self.init_trust_rel = float(init_trust_rel)\n        self.min_trust = float(min_trust)\n        self.max_trust = float(max_trust)\n        self.surrogate_reg = float(surrogate_reg)\n        self.max_hist = int(max_hist)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling: Most BBOB tasks use [-5,5] by default\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        init_trust = max(self.min_trust, self.init_trust_rel * avg_span)\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # keep archive to reasonable size\n            max_arch = max(300, 8 * self.n_anchors * self.dim)\n            if len(X_arch) > max_arch:\n                del X_arch[0:len(X_arch) - max_arch]\n                del f_arch[0:len(f_arch) - max_arch]\n            return fx\n\n        # initial sampling to populate anchors and archive\n        n_init = min(max(10, int(self.budget // 300)), max(20, 6 * self.dim))\n        for _ in range(n_init):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub)\n            safe_eval(x0)\n\n        # ensure at least one sample\n        if len(f_arch) == 0 and evals < self.budget:\n            safe_eval(rng.uniform(lb, ub))\n\n        # best so far\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        # centroid\n        centroid = np.mean(np.asarray(X_arch), axis=0)\n\n        # Initialize anchors from elite points (spread by fitness)\n        def initial_anchors(k):\n            n = len(X_arch)\n            k = min(k, n)\n            idxs = np.argsort(f_arch)[:k]\n            anchors = []\n            for i in idxs:\n                anchors.append({\n                    'center': X_arch[i].copy(),\n                    'f_center': float(f_arch[i]),\n                    'trust': init_trust,\n                    'hist_X': [],   # recent successful displacements (x - center)\n                    'hist_f': [],   # function values of those displacements\n                    'visits': 1,    # how many times this anchor was selected\n                    'reward': 0.0,  # cumulative reward for UCB\n                    'age': 0,\n                })\n            # if not enough elites, fill with random samples\n            while len(anchors) < k:\n                anchors.append({\n                    'center': rng.uniform(lb, ub),\n                    'f_center': float(safe_eval(rng.uniform(lb, ub)) or np.inf),\n                    'trust': init_trust,\n                    'hist_X': [],\n                    'hist_f': [],\n                    'visits': 1,\n                    'reward': 0.0,\n                    'age': 0,\n                })\n            return anchors\n\n        anchors = initial_anchors(self.n_anchors)\n\n        # operator pool with UCB meta-allocator\n        operators = ['scout_levy', 'anchor_line', 'subspace_polish', 'cov_jitter', 'anchor_recombine']\n        K = len(operators)\n        op_counts = np.ones(K) * 1.0  # avoid zero division (initial pseudo-count)\n        op_rewards = np.zeros(K)\n        total_op_selections = 1.0\n\n        # utility: Mantegna-style Lévy step\n        def levy_step(scale, alpha=1.5):\n            # Mantegna approx for symmetric alpha-stable\n            sigma_u = (np.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) /\n                       (np.gamma((1 + alpha) / 2) * alpha * 2 ** ((alpha - 1) / 2))) ** (1 / alpha)\n            u = rng.randn(self.dim) * sigma_u\n            v = rng.randn(self.dim)\n            step = u / (np.abs(v) ** (1.0 / alpha))\n            return scale * step\n\n        # build local orthonormal basis for anchor using its hist_X (entropy-guided)\n        def anchor_basis(anchor, rmax=4):\n            H = np.asarray(anchor['hist_X'])\n            if H.size == 0:\n                # random orthonormal directions\n                B = rng.randn(self.dim, min(rmax, self.dim))\n                try:\n                    Q, _ = np.linalg.qr(B)\n                    return Q[:, :min(rmax, self.dim)]\n                except Exception:\n                    norms = np.linalg.norm(B, axis=0) + 1e-12\n                    return B / norms\n            # center H, compute covariance, take top eigenvectors (entropy/variance)\n            Hc = H - np.mean(H, axis=0)\n            if Hc.shape[0] == 1:\n                # single vector -> normalize it\n                v = Hc[0]\n                v = v / (np.linalg.norm(v) + 1e-12)\n                return v.reshape(-1, 1)\n            C = np.cov(Hc.T) + 1e-12 * np.eye(self.dim)\n            w, V = np.linalg.eigh(C)\n            idx = np.argsort(w)[::-1]\n            r = min(rmax, self.dim, V.shape[1])\n            return V[:, idx[:r]]\n\n        # fit a tiny local surrogate (constant + linear + diag quadratic in subspace) around anchor\n        def fit_local_surrogate(anchor, Usub, max_samples=120):\n            # samples from global archive near the anchor\n            if Usub.shape[1] == 0 or len(X_arch) < 6:\n                return None\n            # compute projections\n            Xarr = np.asarray(X_arch)\n            Farr = np.asarray(f_arch)\n            # distance in ambient space to anchor center\n            dists = np.linalg.norm(Xarr - anchor['center'], axis=1)\n            # select nearest points (in ambient) up to max_samples\n            idxs = np.argsort(dists)[:min(max_samples, len(Xarr))]\n            Xsel = Xarr[idxs]\n            Fsel = Farr[idxs]\n            Z = (Xsel - anchor['center']).dot(Usub)  # n x r\n            n, r = Z.shape\n            if n < (r + 4):\n                return None\n            # features: 1 + linear + squared (diag)\n            Phi = np.ones((n, 1 + r + r))\n            Phi[:, 1:1 + r] = Z\n            Phi[:, 1 + r:1 + r + r] = Z ** 2\n            try:\n                A = Phi.T.dot(Phi) + self.surrogate_reg * np.eye(Phi.shape[1])\n                b = Phi.T.dot(Fsel)\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1 + r]\n                hdiag = coeff[1 + r:1 + r + r]\n                # regularize curvature to avoid huge steps\n                hdiag = np.clip(hdiag, -1e-4, np.maximum(hdiag, 1e-8))\n                return {'c': c, 'g': g, 'hdiag': hdiag, 'U': Usub}\n            except Exception:\n                return None\n\n        # propose minimizer in subspace using local surrogate with damping\n        def surrogate_minimizer(surr, anchor):\n            Usub = surr['U']\n            g = surr['g']\n            h = surr['hdiag']\n            # damped Newton-like step on diag Hessian in subspace\n            zstar = -g / (h + 1e-12)\n            # cap by anchor trust projected into subspace (Euclidean in ambient)\n            max_norm = anchor['trust'] * np.sqrt(max(1, Usub.shape[1]))\n            znorm = np.linalg.norm(zstar)\n            if znorm > max_norm:\n                zstar = zstar * (max_norm / (znorm + 1e-12))\n            x_prop = anchor['center'] + Usub.dot(zstar)\n            x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n            return x_prop, float(surr['c'] + g.dot(zstar) + 0.5 * np.sum(h * (zstar ** 2)))\n\n        # UCB selection for operator\n        def choose_operator():\n            nonlocal total_op_selections\n            total_op_selections += 1.0\n            means = op_rewards / (op_counts + 1e-12)\n            c = 1.4  # exploration multiplier\n            ucb = means + c * np.sqrt(np.log(total_op_selections + 1.0) / (op_counts + 1e-12))\n            idx = int(np.argmax(ucb))\n            op_counts[idx] += 1.0\n            return operators[idx], idx\n\n        # UCB selection for anchor\n        def choose_anchor():\n            # anchor-level UCB: reward / visits + bonus * sqrt(log(total)/visits)\n            visits = np.array([a['visits'] for a in anchors]) + 1e-12\n            rewards = np.array([a['reward'] for a in anchors])\n            means = rewards / visits\n            bonus = 1.2 * np.sqrt(np.log(1.0 + sum(visits)) / visits)\n            scores = means + bonus\n            idx = int(np.argmax(scores))\n            anchors[idx]['visits'] += 1\n            return anchors[idx], idx\n\n        # small helper: update anchor history with a successful displacement\n        def record_anchor_success(anchor, x_new, f_new):\n            d = x_new - anchor['center']\n            anchor['hist_X'].append(d.copy())\n            anchor['hist_f'].append(f_new)\n            if len(anchor['hist_X']) > self.max_hist:\n                anchor['hist_X'].pop(0)\n                anchor['hist_f'].pop(0)\n            # move anchor center slightly toward better child (soft update)\n            if f_new < anchor['f_center'] - 1e-12:\n                anchor['center'] = 0.9 * anchor['center'] + 0.1 * x_new\n                anchor['f_center'] = float(f_new)\n            anchor['age'] = 0\n\n        # main loop:\n        gen = 0\n        stagn = 0\n        stagn_limit = max(10, int(0.02 * self.budget))\n        # global temperature for entropy weighting (annealing)\n        temp = 1.0\n\n        while evals < self.budget:\n            gen += 1\n            # recompute centroid occasionally\n            if gen % 5 == 0 and len(X_arch) > 0:\n                centroid = np.mean(np.asarray(X_arch[-min(len(X_arch), 200):]), axis=0)\n\n            # select anchor and operator\n            anchor, a_idx = choose_anchor()\n            op, op_idx = choose_operator()\n\n            anchor['age'] += 1\n\n            # build local basis and fit surrogate\n            Usub = anchor_basis(anchor, rmax=min(6, self.dim))\n            surrogate = fit_local_surrogate(anchor, Usub)\n\n            x_cand = None\n            f_cand = None\n            reward = 0.0\n\n            if op == 'scout_levy':\n                # heavy-tail exploration around centroid or anchor with some probability\n                if rng.rand() < 0.6:\n                    center = anchor['center']\n                else:\n                    center = centroid\n                scale = 2.2 * anchor['trust'] * (1.0 + 0.5 * rng.rand())\n                step = levy_step(scale)\n                x_prop = np.minimum(np.maximum(center + step, lb), ub)\n                f_prop = safe_eval(x_prop)\n                if f_prop is not None:\n                    x_cand = x_prop; f_cand = f_prop\n                    # success metric: improvement over anchor center and global best\n                    improv = max(0.0, anchor['f_center'] - f_prop)\n                    reward = improv / (abs(anchor['f_center']) + 1e-12)\n\n            elif op == 'anchor_line':\n                # bracketed multi-scale probes along a high-variance direction in the anchor basis\n                if Usub.shape[1] > 0 and rng.rand() < 0.85:\n                    d = Usub[:, rng.randint(0, Usub.shape[1])]\n                else:\n                    d = rng.randn(self.dim)\n                d = d / (np.linalg.norm(d) + 1e-12)\n                scales = np.array([0.15, 0.5, 1.0]) * anchor['trust']\n                best_x = None; best_f = 1e99\n                for s in scales:\n                    if evals >= self.budget:\n                        break\n                    for sign in (+1.0, -1.0):\n                        x_try = anchor['center'] + sign * s * d\n                        x_try = np.minimum(np.maximum(x_try, lb), ub)\n                        f_try = safe_eval(x_try)\n                        if f_try is None:\n                            break\n                        if f_try < best_f:\n                            best_f = f_try; best_x = x_try.copy()\n                if best_x is not None:\n                    x_cand = best_x; f_cand = best_f\n                    reward = max(0.0, anchor['f_center'] - f_cand) / (abs(anchor['f_center']) + 1e-12)\n\n            elif op == 'subspace_polish':\n                # use surrogate if available to get a candidate; otherwise try a small quasi-Newton in subspace by finite differences\n                if surrogate is not None:\n                    x_prop, fpred = surrogate_minimizer(surrogate, anchor)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n                        # reward blends predicted improvement and realized\n                        pred_improv = max(0.0, anchor['f_center'] - fpred)\n                        real_improv = max(0.0, anchor['f_center'] - f_prop)\n                        # shaped reward: prefer accurate surrogate and real improvement\n                        reward = 0.5 * (real_improv / (abs(anchor['f_center']) + 1e-12)) + \\\n                                 0.5 * (min(pred_improv, real_improv) / (abs(anchor['f_center']) + 1e-12))\n                else:\n                    # fallback small secant-like step: probe + and - along two principal local directions and fit linear model\n                    if Usub.shape[1] >= 1:\n                        dirs = [Usub[:, 0]]\n                    else:\n                        dirs = [rng.randn(self.dim)]\n                    # gather 2*len(dirs) samples\n                    Z = []\n                    F = []\n                    for d in dirs:\n                        d = d / (np.linalg.norm(d) + 1e-12)\n                        eps = 0.08 * anchor['trust']\n                        xp = np.minimum(np.maximum(anchor['center'] + eps * d, lb), ub)\n                        xm = np.minimum(np.maximum(anchor['center'] - eps * d, lb), ub)\n                        fp = safe_eval(xp); fm = safe_eval(xm)\n                        if fp is None or fm is None:\n                            break\n                        Z.append(eps * d); F.append(fp)\n                        Z.append(-eps * d); F.append(fm)\n                    if len(F) >= 2:\n                        # linear least squares in current small subspace to get descent direction\n                        A = np.vstack(Z)\n                        try:\n                            # estimate gradient approx as linear fit: F ~ a + g^T z\n                            A_lin = np.hstack([np.ones((A.shape[0], 1)), A])\n                            sol, *_ = np.linalg.lstsq(A_lin, np.asarray(F), rcond=None)\n                            g_est = sol[1:]\n                            # step = -gamma * g_est where gamma scaled by trust\n                            gamma = min(1.2, anchor['trust'] / (np.linalg.norm(g_est) + 1e-12))\n                            x_prop = anchor['center'] - gamma * g_est\n                            x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                            f_prop = safe_eval(x_prop)\n                            if f_prop is not None:\n                                x_cand = x_prop; f_cand = f_prop\n                                reward = max(0.0, anchor['f_center'] - f_prop) / (abs(anchor['f_center']) + 1e-12)\n                        except Exception:\n                            pass\n\n            elif op == 'cov_jitter':\n                # anisotropic jitter using local covariance of anchor history (shrinked)\n                H = np.asarray(anchor['hist_X'])\n                if H.size == 0:\n                    jitter = anchor['trust'] * rng.randn(self.dim)\n                else:\n                    if H.shape[0] == 1:\n                        C = np.eye(self.dim) * (np.var(H[0]) + 1e-8)\n                    else:\n                        C = np.cov(H.T)\n                    # shrink towards isotropic\n                    tr = np.trace(C) / max(1, self.dim)\n                    shrink = 0.14\n                    Csh = (1 - shrink) * C + shrink * tr * np.eye(self.dim) + 1e-10 * np.eye(self.dim)\n                    try:\n                        w, V = np.linalg.eigh(Csh)\n                        w = np.maximum(w, 1e-12)\n                        sqrtC = V.dot(np.diag(np.sqrt(w))).dot(V.T)\n                        jitter = anchor['trust'] * (0.6 * rng.randn(self.dim) + 0.6 * (sqrtC.dot(rng.randn(self.dim))))\n                    except Exception:\n                        jitter = anchor['trust'] * rng.randn(self.dim)\n                x_prop = np.minimum(np.maximum(anchor['center'] + jitter, lb), ub)\n                f_prop = safe_eval(x_prop)\n                if f_prop is not None:\n                    x_cand = x_prop; f_cand = f_prop\n                    reward = max(0.0, anchor['f_center'] - f_prop) / (abs(anchor['f_center']) + 1e-12)\n\n            elif op == 'anchor_recombine':\n                # convex recombination of two anchors: encourage crossing basins\n                if len(anchors) >= 2:\n                    i1 = a_idx\n                    i2 = rng.randint(0, len(anchors))\n                    if i2 == i1:\n                        i2 = (i1 + 1) % len(anchors)\n                    c2 = anchors[i2]['center']\n                    alpha = rng.beta(1.0 + 0.5 * rng.rand(), 1.0 + 0.5 * rng.rand())\n                    child = alpha * anchor['center'] + (1 - alpha) * c2\n                else:\n                    child = anchor['center'].copy()\n                # add small anisotropic jitter to child\n                jitter = anchor['trust'] * 0.6 * rng.randn(self.dim)\n                x_prop = np.minimum(np.maximum(child + jitter, lb), ub)\n                f_prop = safe_eval(x_prop)\n                if f_prop is not None:\n                    x_cand = x_prop; f_cand = f_prop\n                    reward = max(0.0, anchor['f_center'] - f_prop) / (abs(anchor['f_center']) + 1e-12)\n\n            # process candidate if any\n            if f_cand is not None:\n                # update global best\n                if f_cand < f_best - 1e-12:\n                    f_best = float(f_cand); x_best = x_cand.copy()\n                    # be more greedy: shrink anchor trust for local refinement\n                    anchor['trust'] = max(self.min_trust, anchor['trust'] * 0.7)\n                    stagn = 0\n                else:\n                    # if no improvement, slowly enlarge trust to encourage escapes\n                    anchor['trust'] = min(self.max_trust, anchor['trust'] * (1.01 + 0.01 * rng.rand()))\n                    stagn += 1\n\n                # record success into anchor history\n                record_anchor_success(anchor, x_cand, f_cand)\n\n                # shape reward by comparing to predictions and improvement\n                # op-level reward is combination of anchor-local improvement and global significance\n                local_imp = max(0.0, anchor['f_center'] - f_cand)\n                glob_imp = max(0.0, f_best - f_cand)  # improvement relative to best (non-negative)\n                # scaled reward\n                op_reward = 0.6 * (local_imp / (abs(anchor['f_center']) + 1e-12)) + 0.4 * (glob_imp / (abs(f_best) + 1e-12))\n                # clip\n                op_reward = max(-0.2, min(1.5, op_reward))\n                # update operator stats\n                op_rewards[op_idx] += op_reward\n\n                # update anchor reward and visits (for UCB)\n                anchor['reward'] += op_reward\n\n                # occasionally replace stale anchors: if anchor aged too much and not promising\n                if anchor['age'] > 35 and rng.rand() < 0.3:\n                    # replace with a recent elite\n                    elites = np.argsort(f_arch)[:max(3, min(len(f_arch), 6))]\n                    if len(elites) > 0:\n                        pick = elites[rng.randint(0, len(elites))]\n                        anchor['center'] = X_arch[pick].copy()\n                        anchor['f_center'] = f_arch[pick]\n                        anchor['trust'] = init_trust * (1.0 + 0.3 * rng.rand())\n                        anchor['hist_X'] = []\n                        anchor['hist_f'] = []\n                        anchor['reward'] = 0.0\n                        anchor['visits'] = 1\n                        anchor['age'] = 0\n\n            else:\n                # no candidate (budget exhausted)\n                break\n\n            # occasionally propagate global centroid into least performing anchor\n            if gen % 17 == 0:\n                idx_worst = int(np.argmax([a['f_center'] for a in anchors]))\n                anchors[idx_worst]['center'] = 0.6 * anchors[idx_worst]['center'] + 0.4 * centroid\n                anchors[idx_worst]['trust'] = min(self.max_trust, anchors[idx_worst]['trust'] * 1.3)\n\n            # adaptive annealing of the global temperature and occasional trust reset\n            temp *= 0.9995\n            if stagn >= stagn_limit:\n                stagn = 0\n                # pick an anchor to restart near best\n                j = np.argmin([a['f_center'] for a in anchors])\n                anchors[j]['center'] = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                anchors[j]['f_center'] = float(safe_eval(anchors[j]['center']) or anchors[j]['f_center'])\n                anchors[j]['trust'] = max(anchors[j]['trust'], 1.6 * anchors[j]['trust'])\n                anchors[j]['hist_X'] = []\n                anchors[j]['hist_f'] = []\n                anchors[j]['reward'] = 0.0\n                anchors[j]['visits'] = 1\n\n        # finalize\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "error": "In the code, line 792, in __getattr__, the following error occurred:\nAttributeError: module 'numpy' has no attribute 'gamma'", "parent_ids": "3fb1d17b-671f-44d8-8625-cf8b6753dc76", "operator": null, "metadata": {}, "task_prompt": ""}
{"id": "e8a1eb5e-13fc-45b4-91f5-d1798a96bbbf", "fitness": 0.2199214349326609, "name": "ASECA", "description": "The algorithm uses adaptive subspace exploration with covariance-annealing: it maintains an archive, centroid and a trust radius scaled to the problem span (init_trust_rel relatively large, min/max trust bounds), separates search into a dominant subspace U (sub_dim ≈ dim//4) and a smaller exploratory basis V (explore_dim ≈ dim//10) with small Oja learning rate to slowly adapt directions. It fits a ridge-regularized dense quadratic surrogate in the subspace (surrogate_reg stronger) and computes a damped Newton-like step in that subspace, capped by the trust radius to propose informed large steps. A small pool of heterogeneous operators (subspace_newton, axis_probe, random_gauss, cov_sample, mutate_elite, wide_perturb) is chosen by an UCB-style selector (ucb_c small) with rewards combining actual improvement and surrogate prediction accuracy, plus occasional epsilon exploration. Robustification is provided by shrinkage/annealing of covariance for sampling, momentum/step-scale heuristics, centroid pulls, Oja/V perturbations, trust adaptation based on spectral diversity and success, and stagnation-driven covariance-informed restarts with reseeding of nearby points.", "code": "import numpy as np\n\nclass ASECA:\n    \"\"\"\n    Adaptive Subspace Exploration with Covariance Annealing (ASECA)\n\n    Key ideas (differences vs. the provided SACRA):\n    - Different default parameterization: larger initial trust (init_trust_rel),\n      different subspace sizing (sub_dim ~ dim//4), smaller Oja LR, and stronger surrogate regularization.\n    - Surrogate: fit a dense symmetric quadratic (full Hessian in subspace) via ridge least-squares,\n      then damped-solve for a Newton step (rather than diagonal-only Hessian).\n    - Operator selection uses UCB-style scores (mean reward + exploration bonus) instead of EXP3.\n    - Covariance-annealing: archive covariance is blended with isotropic noise for sampling and restarts.\n    - Mix of operators distinct from SACRA: 'subspace_newton', 'axis_probe', 'random_gauss',\n      'cov_sample', 'mutate_elite', 'wide_perturb'.\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, seed=None,\n                 pop=14,\n                 sub_dim=None, explore_dim=None,\n                 init_trust=0.25, oja_lr=0.02, surrogate_reg=1e-5,\n                 explore_rate=0.12, ucb_c=0.12, min_trust=1e-9, max_trust=6.0):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.seed = seed\n        self.rng = np.random.RandomState(seed)\n        self.pop = int(pop)\n        self.sub_dim = sub_dim if sub_dim is not None else max(1, self.dim // 4)\n        self.explore_dim = explore_dim if explore_dim is not None else max(1, self.dim // 10)\n        self.init_trust_rel = float(init_trust)\n        self.oja_lr = float(oja_lr)\n        self.surrogate_reg = float(surrogate_reg)\n        self.explore_rate = float(explore_rate)\n        self.ucb_c = float(ucb_c)\n        self.min_trust = float(min_trust)\n        self.max_trust = float(max_trust)\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds, default [-5,5]\n        try:\n            lb = np.asarray(func.bounds.lb, dtype=float)\n            ub = np.asarray(func.bounds.ub, dtype=float)\n        except Exception:\n            lb = np.full(self.dim, -5.0)\n            ub = np.full(self.dim, 5.0)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n        trust_radius = max(self.min_trust, self.init_trust_rel * avg_span)\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # small Latin-hypercube-like initialization (simple stratified random)\n        init_samples = min(max(12, int(self.budget // 250)), max(20, self.pop * 4))\n        for i in range(init_samples):\n            if evals >= self.budget: break\n            # stratify each coordinate by segmenting [-1,1]\n            u = rng.rand(self.dim)\n            x = lb + (ub - lb) * u\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        # ensure at least one sample\n        if len(f_arch) == 0 and evals < self.budget:\n            x = rng.uniform(lb, ub, size=self.dim)\n            f = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(f)\n\n        idx_best = int(np.argmin(f_arch))\n        x_best = X_arch[idx_best].copy()\n        f_best = float(f_arch[idx_best])\n\n        # centers\n        m = x_best.copy()\n        centroid = np.mean(np.asarray(X_arch), axis=0)\n\n        # initialize spectral bases\n        r = min(self.sub_dim, self.dim)\n        U = rng.randn(self.dim, r)\n        try:\n            U, _ = np.linalg.qr(U)\n            U = U[:, :r]\n        except Exception:\n            U = U / (np.linalg.norm(U, axis=0, keepdims=True) + 1e-12)\n\n        s = min(self.explore_dim, self.dim)\n        V = rng.randn(self.dim, s)\n        try:\n            V, _ = np.linalg.qr(V)\n            V = V[:, :s]\n        except Exception:\n            V = V / (np.linalg.norm(V, axis=0, keepdims=True) + 1e-12)\n\n        # momentum / step scales per-dim (different scaling)\n        momentum = np.zeros(self.dim)\n        step_scale = np.full(self.dim, 0.06 * avg_span)\n        step_scale = np.clip(step_scale, 1e-9, 1.5 * avg_span)\n\n        # operator pool (distinct names)\n        operators = ['subspace_newton', 'axis_probe', 'random_gauss', 'cov_sample', 'mutate_elite', 'wide_perturb']\n        K_ops = len(operators)\n        op_counts = np.zeros(K_ops, dtype=int)\n        op_rewards = np.zeros(K_ops, dtype=float)\n        total_selections = 0\n        epsilon_explore = 0.08  # small randomization\n\n        # helpers\n        def safe_eval(x):\n            nonlocal evals, X_arch, f_arch, x_best, f_best\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x)); evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # maintain archive size\n            max_arch = max(300, 6 * (self.sub_dim + self.explore_dim))\n            if len(X_arch) > max_arch:\n                # drop oldest\n                remove = len(X_arch) - max_arch\n                del X_arch[:remove]; del f_arch[:remove]\n            if fx < f_best:\n                x_best = x.copy(); f_best = float(fx)\n            return fx\n\n        def get_elites(k_frac=0.14):\n            n = len(X_arch)\n            if n == 0:\n                return np.empty((0, self.dim))\n            k = max(3, int(np.ceil(k_frac * max(20, n))))\n            idxs = np.argsort(f_arch)[:min(k, n)]\n            return np.asarray([X_arch[i].copy() for i in idxs])\n\n        def shrink_cov_anneal(Xe, shrink=0.18, anneal=0.9):\n            if Xe.size == 0:\n                return np.eye(self.dim)\n            S = np.cov(Xe.T) if Xe.shape[0] > 1 else np.zeros((self.dim, self.dim))\n            F = np.trace(S) / max(1, self.dim)\n            C = (1.0 - shrink) * S + shrink * F * np.eye(self.dim)\n            # anneal towards isotropic to encourage exploration early\n            C = anneal * C + (1.0 - anneal) * (F * np.eye(self.dim))\n            C += 1e-12 * np.eye(self.dim)\n            return C\n\n        # Oja-style update with cosine-annealed lr multiplier\n        def oja_update(Umat, z, base_lr):\n            if Umat.shape[1] == 0:\n                return Umat\n            zn = z / (np.linalg.norm(z) + 1e-12)\n            for j in range(Umat.shape[1]):\n                uj = Umat[:, j]\n                proj = np.dot(zn, uj)\n                # slightly different rule: projective growth with damping\n                uj = uj + base_lr * (proj * zn - 0.5 * proj**2 * uj)\n                Umat[:, j] = uj\n            try:\n                Q, _ = np.linalg.qr(Umat)\n                return Q[:, :Umat.shape[1]]\n            except Exception:\n                norms = np.linalg.norm(Umat, axis=0) + 1e-12\n                return Umat / norms\n\n        def perturb_explore(Vmat, scale=0.08):\n            if Vmat.shape[1] == 0:\n                return Vmat\n            rot = np.eye(Vmat.shape[1]) + scale * (rng.randn(Vmat.shape[1], Vmat.shape[1]) * 0.4)\n            try:\n                Q = Vmat.dot(rot)\n                Q, _ = np.linalg.qr(Q)\n                return Q[:, :Vmat.shape[1]]\n            except Exception:\n                return Vmat\n\n        # Surrogate: full symmetric quadratic in subspace z: f ≈ c + g^T z + 0.5 z^T H z\n        def fit_quadratic_dense(Umat, samples=None):\n            # require enough samples: p = 1 + r + r*(r+1)/2\n            if Umat.shape[1] == 0:\n                return None\n            r = Umat.shape[1]\n            p = 1 + r + (r * (r + 1)) // 2\n            if len(X_arch) < max(p + 4, 20):\n                return None\n            if samples is None:\n                samples = min(len(X_arch), max(40, 6 * r))\n            Xr = np.asarray(X_arch[-samples:])\n            Fr = np.asarray(f_arch[-samples:])\n            Z = (Xr - m).dot(Umat)  # n x r\n            n = Z.shape[0]\n            # build design matrix\n            Phi = np.ones((n, p))\n            Phi[:, 1:1 + r] = Z\n            # upper-triangular index for quadratic terms\n            idx = 1 + r\n            for i in range(r):\n                for j in range(i, r):\n                    Phi[:, idx] = Z[:, i] * Z[:, j]\n                    idx += 1\n            # ridge solve\n            try:\n                A = Phi.T.dot(Phi) + self.surrogate_reg * np.eye(p)\n                b = Phi.T.dot(Fr)\n                coeff = np.linalg.solve(A, b)\n                c = coeff[0]\n                g = coeff[1:1 + r]\n                H = np.zeros((r, r))\n                idx = 1 + r\n                for i in range(r):\n                    for j in range(i, r):\n                        H[i, j] = coeff[idx]\n                        H[j, i] = coeff[idx]\n                        idx += 1\n                # regularize H mildly: make SPD by shifting eigenvalues if necessary\n                try:\n                    w, Qh = np.linalg.eigh(H)\n                    minw = np.min(w)\n                    if minw < 1e-6:\n                        w = np.maximum(w, 1e-6)\n                        H = Qh.dot(np.diag(w)).dot(Qh.T)\n                except Exception:\n                    H += 1e-6 * np.eye(r)\n                # compute Newton-like step: solve (H + lambda I) z = -g\n                lam = 1e-6 + 1e-2 * np.linalg.norm(g) / (1.0 + np.linalg.norm(H))\n                try:\n                    zstar = -np.linalg.solve(H + lam * np.eye(r), g)\n                except Exception:\n                    zstar = -g / (np.diag(H + lam * np.eye(r)) + 1e-12)\n                # cap norm by trust radius (projected)\n                max_norm = (trust_radius / (np.linalg.norm(Umat, ord=2) + 1e-12)) * np.sqrt(max(1, r))\n                znorm = np.linalg.norm(zstar)\n                if znorm > max_norm:\n                    zstar = zstar * (max_norm / (znorm + 1e-12))\n                # predicted f\n                fpred = float(c + g.dot(zstar) + 0.5 * zstar.dot(H).dot(zstar))\n                return (zstar, fpred, (c, g, H))\n            except Exception:\n                return None\n\n        # UCB operator selector\n        def choose_op():\n            nonlocal total_selections\n            total_selections += 1\n            scores = np.zeros(K_ops)\n            for k in range(K_ops):\n                if op_counts[k] == 0:\n                    # encourage trying each operator at least once\n                    scores[k] = 1e6 * (rng.rand() * 0.01 + 0.001)  # small randomness to break ties\n                else:\n                    mean_r = op_rewards[k] / (op_counts[k] + 1e-12)\n                    bonus = self.ucb_c * np.sqrt(np.log(1 + total_selections) / (op_counts[k] + 1e-12))\n                    scores[k] = mean_r + bonus + 0.001 * rng.rand()\n            # epsilon explore occasionally\n            if rng.rand() < epsilon_explore:\n                idx = rng.randint(0, K_ops)\n            else:\n                idx = int(np.argmax(scores))\n            op_counts[idx] += 1\n            return operators[idx], idx\n\n        # main loop\n        gen = 0\n        stagn = 0\n        stagn_limit = max(8, int(0.015 * self.budget))\n\n        while evals < self.budget:\n            gen += 1\n\n            # update elites and covariance for perturbations\n            Xe = get_elites()\n            Csh = shrink_cov_anneal(Xe, shrink=0.16, anneal=0.92)\n\n            # diversity metric (spectral entropy)\n            try:\n                cov_full = np.cov(np.asarray(X_arch).T) if len(X_arch) > 4 else np.eye(self.dim)\n                ev = np.linalg.eigvalsh(cov_full + 1e-12 * np.eye(self.dim))\n                ev = np.maximum(ev, 1e-16)\n                p_ev = ev / np.sum(ev)\n                diversity = -np.sum(p_ev * np.log(p_ev + 1e-12))\n            except Exception:\n                diversity = 0.0\n\n            # trust adaptation: anneal toward larger trust when diversity is high, shrink otherwise\n            if diversity > 0.9:\n                trust_radius = min(self.max_trust, trust_radius * (1.03 + 0.006 * rng.rand()))\n            else:\n                trust_radius = max(self.min_trust, trust_radius * (0.995 - 0.001 * rng.rand()))\n\n            # occasionally perturb exploratory basis\n            if rng.rand() < 0.28:\n                V = perturb_explore(V, scale=0.06 * (1.0 + 0.5 * rng.rand()))\n\n            # fit surrogate (dense) in U\n            surrogate = fit_quadratic_dense(U)\n\n            # batch of candidates this generation\n            n_batch = min(self.pop, max(1, self.budget - evals))\n            batch_X = []\n            batch_f = []\n            batch_opidx = []\n            batch_pred = []\n\n            for bi in range(n_batch):\n                if evals >= self.budget:\n                    break\n                op, idx = choose_op()\n                x_cand = None; f_cand = None; pred = None\n\n                if op == 'subspace_newton' and surrogate is not None:\n                    zstar, fpred, params = surrogate\n                    x_prop = m + U.dot(zstar)\n                    x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop; pred = fpred\n\n                elif op == 'axis_probe':\n                    # probe along coordinate directions with adaptive scaling\n                    # choose a few coords with highest variance\n                    if len(X_arch) > 8:\n                        var = np.var(np.asarray(X_arch), axis=0)\n                        idxs = np.argsort(-var)[:min(3, self.dim)]\n                        i = int(idxs[rng.randint(0, len(idxs))])\n                    else:\n                        i = rng.randint(0, self.dim)\n                    scale = step_scale[i] * (0.8 + 0.6 * rng.rand()) * (trust_radius / (avg_span + 1e-12))\n                    cand = m.copy()\n                    # try positive and negative\n                    best_local_x = None; best_local_f = 1e99\n                    for sign in (+1.0, -1.0):\n                        cand[i] = np.clip(m[i] + sign * scale, lb[i], ub[i])\n                        f_try = safe_eval(cand)\n                        if f_try is None:\n                            break\n                        if f_try < best_local_f:\n                            best_local_f = f_try; best_local_x = cand.copy()\n                    if best_local_x is not None:\n                        x_cand = best_local_x; f_cand = best_local_f\n                        # update momentum and step_scale heuristic\n                        momentum[i] = 0.6 * momentum[i] + 0.35 * (m[i] - best_local_x[i])\n                        if f_cand < f_best - 1e-12:\n                            step_scale[i] = min(step_scale[i] * 1.12, avg_span)\n\n                elif op == 'random_gauss':\n                    # local Gaussian around centroid with radius proportional to trust\n                    center = centroid if rng.rand() < 0.6 else m\n                    sigma = 0.9 * trust_radius * (0.8 + 0.6 * rng.rand())\n                    x_prop = np.minimum(np.maximum(center + sigma * rng.randn(self.dim), lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n\n                elif op == 'cov_sample':\n                    # sample from archive covariance blended with isotropic noise\n                    try:\n                        w, Vc = np.linalg.eigh(Csh)\n                        w = np.maximum(w, 1e-12)\n                        sqrtC = Vc.dot(np.diag(np.sqrt(w))).dot(Vc.T)\n                        step = sqrtC.dot(rng.randn(self.dim))\n                    except Exception:\n                        step = rng.randn(self.dim)\n                    scale = 1.1 * trust_radius * (0.9 + rng.rand())\n                    center = m if rng.rand() < 0.5 else centroid\n                    x_prop = np.minimum(np.maximum(center + scale * step, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n\n                elif op == 'mutate_elite':\n                    Xe_local = Xe\n                    if Xe_local.size >= 2:\n                        i1, i2 = rng.choice(Xe_local.shape[0], size=2, replace=False)\n                        alpha = rng.beta(1.5, 1.5)\n                        child = alpha * Xe_local[i1] + (1.0 - alpha) * Xe_local[i2]\n                    elif Xe_local.size == 1:\n                        child = Xe_local[0].copy()\n                    else:\n                        child = m.copy()\n                    # jitter along a random combination of U and V\n                    mixdir = 0.6 * U.dot(rng.randn(U.shape[1])) if U.shape[1] > 0 else rng.randn(self.dim)\n                    mixdir += 0.4 * (V.dot(rng.randn(V.shape[1])) if V.shape[1] > 0 else 0.0)\n                    mixdir = mixdir / (np.linalg.norm(mixdir) + 1e-12)\n                    x_prop = np.minimum(np.maximum(child + 0.7 * trust_radius * mixdir + 0.12 * avg_span * rng.randn(self.dim), lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n\n                elif op == 'wide_perturb':\n                    # occasionally wide exploratory jump (Gaussian + uniform)\n                    base = x_best if rng.rand() < 0.6 else centroid\n                    wide = 2.4 * trust_radius * rng.randn(self.dim) + (ub - lb) * (rng.rand(self.dim) - 0.5) * 0.12\n                    x_prop = np.minimum(np.maximum(base + wide, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is not None:\n                        x_cand = x_prop; f_cand = f_prop\n\n                # record candidate and update meta-components\n                if f_cand is not None:\n                    batch_X.append(x_cand.copy())\n                    batch_f.append(f_cand)\n                    batch_opidx.append(idx)\n                    batch_pred.append(pred if pred is not None else f_cand)\n\n                    # reward: scaled improvement plus predicted accuracy if available\n                    imp = max(0.0, f_best - f_cand)\n                    pred_diff = 0.0\n                    if pred is not None:\n                        pred_diff = max(-1.0, min(1.0, (pred - f_cand) / (abs(f_best) + 1e-12)))\n                    reward = 0.75 * (imp / (abs(f_best) + 1e-12)) + 0.25 * pred_diff\n                    reward = max(-0.3, min(1.5, reward))\n\n                    # update operator statistics (UCB accumulators)\n                    op_rewards[idx] += reward\n\n                    # gentle decay to avoid stale operators dominating\n                    if total_selections % 50 == 0:\n                        op_rewards *= 0.995\n\n                    # update spectral basis U via Oja-like\n                    zc = x_cand - m\n                    # cosine annealed lr factor per generation for variety\n                    lr_mult = 0.5 * (1.0 + np.cos(np.pi * min(1.0, gen / max(1, 200))))\n                    U = oja_update(U, zc, base_lr=self.oja_lr * (0.6 + 0.8 * lr_mult))\n\n                    # occasionally inject direction into V\n                    if rng.rand() < 0.18:\n                        if V.shape[1] > 0:\n                            j = rng.randint(0, V.shape[1])\n                            newcol = zc / (np.linalg.norm(zc) + 1e-12)\n                            V[:, j] = 0.78 * V[:, j] + 0.22 * newcol\n                            try:\n                                V, _ = np.linalg.qr(V)\n                                V = V[:, :V.shape[1]]\n                            except Exception:\n                                V = V / (np.linalg.norm(V, axis=0, keepdims=True) + 1e-12)\n\n                    # trust adaptation & stagnation\n                    if f_cand < f_best - 1e-12:\n                        f_best = float(f_cand); x_best = x_cand.copy()\n                        # shrink trust gently on success\n                        trust_radius = max(self.min_trust, trust_radius * 0.82)\n                        stagn = 0\n                    else:\n                        # small expansion to encourage escape\n                        trust_radius = min(self.max_trust, trust_radius * (1.004 + 0.0015 * rng.rand()))\n                        stagn += 1\n\n                else:\n                    # budget exhausted inside safe_eval\n                    break\n\n            # aggregate batch into center m: use weighted mean emphasizing better-than-center results\n            if len(batch_X) > 0:\n                Xs = np.asarray(batch_X)\n                Fs = np.asarray(batch_f)\n                # temperature scaled by trust and diversity\n                temp = max(1e-6, 0.5 * (trust_radius / (avg_span + 1e-12)) * (1.0 + 0.8 * (diversity - 0.6)))\n                # weights: exponential on negative cost\n                w = np.exp(-(Fs - np.min(Fs)) / (temp + 1e-12))\n                w = w / (np.sum(w) + 1e-12)\n                xr = np.sum(w[:, None] * Xs, axis=0)\n                # move toward xr with a trust-aware step clipping\n                mix = 0.4 if trust_radius < 0.45 * avg_span else 0.25\n                new_m = (1.0 - mix) * m + mix * xr\n                # slight centroid pull\n                new_m = 0.82 * new_m + 0.18 * centroid\n                delta = new_m - m\n                max_jump = 3.2 * trust_radius * np.sqrt(max(1, self.dim))\n                dn = np.linalg.norm(delta)\n                if dn > max_jump:\n                    delta = delta * (max_jump / (dn + 1e-12))\n                m = np.minimum(np.maximum(m + delta, lb), ub)\n\n                # shrink trust when improvements occurred in batch, else gentle grow\n                if np.any(Fs < f_best):\n                    trust_radius = max(self.min_trust, trust_radius * 0.86)\n                else:\n                    trust_radius = min(self.max_trust, trust_radius * 1.025)\n\n            # update centroid from archive occasionally\n            if len(X_arch) > 6 and gen % 4 == 0:\n                centroid = np.mean(np.asarray(X_arch[-min(len(X_arch), 60):]), axis=0)\n\n            # stagnation-driven covariance-informed restart\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                # pick random elite or best\n                if Xe.size:\n                    new_center = Xe[rng.randint(0, Xe.shape[0])]\n                else:\n                    new_center = x_best.copy()\n                C = shrink_cov_anneal(Xe, shrink=0.16, anneal=0.85)\n                try:\n                    wv, Vm = np.linalg.eigh(C)\n                    wv = np.maximum(wv, 1e-12)\n                    sqrtC = Vm.dot(np.diag(np.sqrt(wv))).dot(Vm.T)\n                except Exception:\n                    sqrtC = np.eye(self.dim)\n                jitter_scale = max(0.08 * avg_span, 2.0 * trust_radius)\n                m = np.minimum(np.maximum(new_center + jitter_scale * (0.5 * rng.randn(self.dim) + 0.5 * (sqrtC.dot(rng.randn(self.dim)))), lb), ub)\n                trust_radius = min(self.max_trust, trust_radius * 1.9)\n                # reseed some points near best and elites to refresh surrogate data\n                for _ in range(min(7, self.budget - evals)):\n                    x = np.minimum(np.maximum(x_best + 0.03 * avg_span * rng.randn(self.dim), lb), ub)\n                    f = safe_eval(x)\n                    if f is None:\n                        break\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm ASECA scored 0.220 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "3fb1d17b-671f-44d8-8625-cf8b6753dc76", "operator": null, "metadata": {"aucs": [0.12335602944809065, 0.16350762301946054, 0.2926974419205758, 0.2769539892511558, 0.2106655742664384, 0.28632959129081104, 0.2271439791561949, 0.23977399829002988, 0.220095218402656, 0.15869090428119625]}, "task_prompt": ""}
{"id": "700f2812-e418-467c-9e68-d83b26c068ef", "fitness": 0.16371082905827775, "name": "SYNERGIA", "description": "SYNERGIA mixes complementary heuristics: it learns a low-dimensional PCA subspace (subrank ≈ dim/6) and fits a cheap diagonal quadratic surrogate there to propose predictive minimizers, while also sampling with low-rank + per-dimension diagonal jitter, mirrored/antithetic pairs, multiscale probes, occasional Cauchy (Levy-like) jumps and recombination to cover local and global moves. Adaptation is lightweight and per-dimension — RMS accumulation (rms_beta=0.93) sets sigma_diag, momentum (momentum_beta=0.86) smooths accepted moves, trust-region clipping bounds updates, and a smoothed success rate (succ_target=0.2, succ_ema_beta=0.9, sigma_adapt_rate=0.27) multiplicatively adapts global sigma (sigma0_mult=0.18 initial scale). An EXP3-like operator allocator (log_w, op_eta=0.12, gamma_explore=0.06) biases evaluations to productive operators, while safe_eval enforces bounds and the evaluation budget and an opportunistic restart on stagnation (stagn_frac=0.05) re-centers and inflates sigma to escape traps. Implementation details include small initial seeding, archive-limited SVD for subspace refresh, importance-weighted operator updates, simple 1D line/bracket probes and budget-aware mirrored/paired evaluations to efficiently use limited function calls.", "code": "import numpy as np\n\nclass SYNERGIA:\n    \"\"\"\n    SYNERGIA - SYnergistic NEtwork of Rank-guided Gaussian & Informed Actions\n\n    Combines:\n      - periodic subspace PCA + small quadratic surrogate in subspace for predictive minimizers\n      - low-rank+diag sampling, mirrored pairs, multiscale probes and rare Levy jumps\n      - per-dim RMS scaling, momentum, trust-region clipping, adaptive sigma via smoothed success\n      - lightweight EXP3-like operator weighting to allocate evaluations efficiently\n      - opportunistic restarts on stagnation\n    \"\"\"\n    def __init__(self, budget=10000, dim=10, rng_seed=None,\n                 pop=12, subrank=None, dir_refresh=12, pca_min=12):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.rng_seed = rng_seed\n        self.rng = np.random.RandomState(rng_seed)\n        self.pop = int(pop)\n        self.subrank = subrank if subrank is not None else max(1, self.dim // 6)\n        self.dir_refresh = int(dir_refresh)\n        self.pca_min = int(pca_min)\n\n        # adaptation knobs\n        self.sigma0_mult = 0.18\n        self.rms_beta = 0.93\n        self.momentum_beta = 0.86\n        self.succ_ema_beta = 0.9\n        self.succ_target = 0.2\n        self.sigma_adapt_rate = 0.27\n        self.op_eta = 0.12  # operator multiplicative learning rate\n        self.gamma_explore = 0.06  # exploration floor for operator sampling\n        self.stagn_frac = 0.05\n\n    def __call__(self, func):\n        rng = self.rng\n\n        # bounds handling (support scalar or per-dim)\n        lb = np.asarray(func.bounds.lb, dtype=float)\n        ub = np.asarray(func.bounds.ub, dtype=float)\n        if lb.size == 1:\n            lb = np.full(self.dim, lb.item())\n        if ub.size == 1:\n            ub = np.full(self.dim, ub.item())\n        assert lb.shape[0] == self.dim and ub.shape[0] == self.dim\n\n        span = ub - lb\n        avg_span = float(np.mean(span))\n\n        # initialize state\n        sigma0 = max(1e-12, self.sigma0_mult * avg_span)\n        sigma = float(sigma0)\n        v_rms = np.full(self.dim, 1e-6)      # per-dim RMS accumulator\n        sigma_diag = np.full(self.dim, sigma)  # diagonal jitter scales\n        momentum = np.zeros(self.dim)\n\n        # subspace basis (learned via PCA on archive periodically)\n        k = min(self.subrank, self.dim)\n        U = np.zeros((self.dim, 0)) if k == 0 else np.eye(self.dim)[:, :k].copy()\n        sub_scale = np.full(k, sigma / np.sqrt(max(1, k))) if k > 0 else np.array([])\n\n        # operator pool\n        operators = ['surrogate', 'lowrank', 'mirror', 'line', 'levy', 'recomb']\n        K_ops = len(operators)\n        # log-weights for EXP3-like soft selection\n        log_w = np.zeros(K_ops)\n\n        # archive\n        X_arch = []\n        f_arch = []\n        evals = 0\n\n        # Safe evaluation wrapper (respects budget)\n        def safe_eval(x):\n            nonlocal evals\n            if evals >= self.budget:\n                return None\n            x = np.minimum(np.maximum(np.asarray(x, dtype=float), lb), ub)\n            fx = float(func(x))\n            evals += 1\n            X_arch.append(x.copy()); f_arch.append(fx)\n            # keep archive bounded\n            max_arch = max(200, 6 * self.dim)\n            if len(X_arch) > max_arch:\n                del X_arch[0: len(X_arch) - max_arch]\n                del f_arch[0: len(f_arch) - max_arch]\n            return fx\n\n        # initial seeding: small diverse batch\n        seed0 = min(max(12, self.pop * 2), self.budget // 5)\n        for _ in range(seed0):\n            if evals >= self.budget:\n                break\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            fx0 = safe_eval(x0)\n            if fx0 is None:\n                break\n\n        # fallback ensure at least one sample\n        if len(f_arch) == 0 and evals < self.budget:\n            x0 = rng.uniform(lb, ub, size=self.dim)\n            safe_eval(x0)\n\n        # best so far\n        best_idx = int(np.argmin(f_arch))\n        x_best = X_arch[best_idx].copy()\n        f_best = float(f_arch[best_idx])\n\n        # smoothed success probability\n        p_succ = 0.2\n\n        gen = 0\n        stagn_limit = max(6, int(self.stagn_frac * self.budget))\n        stagn = 0\n\n        # helper: refresh subspace U via SVD of recent archive\n        def refresh_subspace():\n            nonlocal U, sub_scale, k\n            if k == 0 or len(X_arch) < max(self.pca_min, k + 4):\n                return\n            K = min(len(X_arch), max(self.pca_min, 6 * k))\n            Xr = np.asarray(X_arch[-K:])\n            M = Xr.mean(axis=0)\n            S = Xr - M\n            try:\n                _, svals, Vt = np.linalg.svd(S, full_matrices=False)\n                r_eff = min(k, Vt.shape[0])\n                if r_eff <= 0:\n                    return\n                U_new = Vt[:r_eff].T.copy()\n                # blend softly to avoid abrupt jumps\n                if U.shape[1] == r_eff:\n                    U[:] = 0.85 * U + 0.15 * U_new\n                else:\n                    U = U_new\n                # orthonormalize\n                try:\n                    Q, _ = np.linalg.qr(U)\n                    U = Q[:, :r_eff]\n                except Exception:\n                    pass\n                # update subspace scales from singular values\n                svals = np.maximum(svals[:r_eff], 1e-8)\n                sub_scale = 0.9 * sub_scale[:r_eff] + 0.1 * (svals / (np.sqrt(max(1, K)) + 1e-12))\n            except Exception:\n                pass\n\n        # helper: fit diagonal quadratic surrogate in subspace U (ridge), returns z_star or None\n        def fit_subspace_diagonal_quad():\n            if k == 0 or len(X_arch) < (k + 6):\n                return None\n            K = min(len(X_arch), 6 * k + 20)\n            Xr = np.asarray(X_arch[-K:])\n            Fr = np.asarray(f_arch[-K:])\n            Z = (Xr - m).dot(U)  # coords relative to m (m is current center; defined below)\n            n = Z.shape[0]\n            # design: [1, z_i..., 0.5*z_i^2...]\n            Phi = np.ones((n, 1 + k + k))\n            Phi[:, 1:1 + k] = Z\n            Phi[:, 1 + k:1 + k + k] = 0.5 * (Z ** 2)\n            reg = 1e-6 * (1.0 + np.var(Fr))\n            try:\n                A = Phi.T.dot(Phi) + reg * np.eye(Phi.shape[1])\n                b = Phi.T.dot(Fr)\n                theta = np.linalg.solve(A, b)\n                g = theta[1:1 + k]\n                hdiag = theta[1 + k:1 + k + k]\n                # ensure some positive curvature (regularize)\n                hdiag = np.sign(hdiag) * np.maximum(np.abs(hdiag), 1e-6)\n                z_star = - g / (hdiag + 1e-12)\n                # trust clip in subspace\n                z_norm = np.linalg.norm(z_star)\n                max_sub = 6.0 * sigma\n                if z_norm > max_sub:\n                    z_star = z_star * (max_sub / (z_norm + 1e-12))\n                return z_star\n            except Exception:\n                return None\n\n        # helper: draw index by EXP3-like probability from log_w\n        def op_sample():\n            maxlw = np.max(log_w)\n            exps = np.exp(log_w - maxlw)\n            probs = (1.0 - self.gamma_explore) * (exps / (np.sum(exps) + 1e-12)) + self.gamma_explore / K_ops\n            idx = rng.choice(K_ops, p=probs)\n            return idx, probs[idx]\n\n        # current center m (start at best)\n        m = x_best.copy()\n\n        # main loop: produce small batches until budget exhausted\n        while evals < self.budget:\n            gen += 1\n            remaining = self.budget - evals\n            batch_size = min(self.pop, max(1, remaining))\n            # refresh subspace periodically\n            if (gen % max(1, self.dir_refresh)) == 0:\n                refresh_subspace()\n\n            # fit surrogate once per generation\n            zstar_surrogate = None\n            if k > 0:\n                zstar_surrogate = fit_subspace_diagonal_quad()\n\n            # collect generation results for adaptation\n            batch_candidates = []\n            batch_results = []\n            batch_ops = []\n            gen_improved = False\n\n            for _b in range(batch_size):\n                if evals >= self.budget:\n                    break\n\n                # choose operator\n                op_idx, op_p = op_sample()\n                op = operators[op_idx]\n\n                # default candidate None\n                x_cand = None\n                step = None\n\n                if op == 'surrogate' and zstar_surrogate is not None:\n                    # propose subspace minimizer\n                    x_prop = m + U.dot(zstar_surrogate)\n                    x_prop = np.minimum(np.maximum(x_prop, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is None:\n                        break\n                    x_cand = x_prop\n                    step = x_cand - m\n\n                elif op == 'lowrank':\n                    # low-rank correlated gaussian + diag jitter, multiscale\n                    scales = [0.4, 1.0, 2.5]\n                    scale = scales[rng.randint(0, len(scales))]\n                    if k > 0 and U.shape[1] > 0:\n                        z = rng.randn(U.shape[1]) * sub_scale\n                        low = U.dot(z)\n                    else:\n                        low = np.zeros(self.dim)\n                    eps = rng.randn(self.dim) * sigma_diag\n                    step = scale * (low + eps)\n                    x_try = m + step\n                    x_try = np.minimum(np.maximum(x_try, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try\n\n                elif op == 'mirror':\n                    # mirrored/antithetic pair: generate a step and evaluate both sides if budget allows\n                    # generate step from lowrank+diag\n                    if k > 0 and U.shape[1] > 0:\n                        z = rng.randn(U.shape[1]) * sub_scale\n                        low = U.dot(z)\n                    else:\n                        low = np.zeros(self.dim)\n                    eps = rng.randn(self.dim) * sigma_diag\n                    step_vec = sigma * (low + 0.6 * eps)\n                    x_plus = m + step_vec\n                    x_minus = m - step_vec\n                    x_plus = np.minimum(np.maximum(x_plus, lb), ub)\n                    x_minus = np.minimum(np.maximum(x_minus, lb), ub)\n                    # try evaluate both, but if budget only allows one, pick better heuristic (evaluate plus)\n                    if evals + 2 <= self.budget:\n                        f_plus = safe_eval(x_plus)\n                        if f_plus is None: break\n                        f_minus = safe_eval(x_minus)\n                        if f_minus is None: break\n                        # pick better of pair\n                        if f_plus <= f_minus:\n                            x_cand = x_plus; f_cand = f_plus\n                        else:\n                            x_cand = x_minus; f_cand = f_minus\n                        # we'll record both into archive already by safe_eval\n                        # we don't double-count evals here\n                        batch_candidates.append(None)  # placeholder consumed above\n                        batch_results.append(None)\n                        batch_ops.append(op_idx)\n                        # update best immediately\n                        if f_plus < f_best:\n                            f_best = f_plus; x_best = x_plus.copy()\n                        if f_minus < f_best:\n                            f_best = f_minus; x_best = x_minus.copy()\n                        # mark that generation improved if either improved\n                        if (f_plus < f_best) or (f_minus < f_best):\n                            gen_improved = True\n                        # continue to next candidate (we already consumed two evals)\n                        continue\n                    else:\n                        # only one eval left: evaluate x_plus\n                        f_plus = safe_eval(x_plus)\n                        if f_plus is None:\n                            break\n                        x_cand = x_plus\n                        step = x_cand - m\n\n                elif op == 'line':\n                    # cheap 1D bracket along direction (best-m or top subspace vector)\n                    if rng.rand() < 0.6 and np.linalg.norm(x_best - m) > 1e-12:\n                        d = x_best - m\n                        d = d / (np.linalg.norm(d) + 1e-12)\n                    elif k > 0 and U.shape[1] > 0:\n                        j = rng.randint(0, U.shape[1])\n                        d = U[:, j]\n                        d = d / (np.linalg.norm(d) + 1e-12)\n                    else:\n                        d = rng.randn(self.dim)\n                        d = d / (np.linalg.norm(d) + 1e-12)\n                    a = 0.7 * sigma\n                    x1 = np.minimum(np.maximum(m + a * d, lb), ub)\n                    x2 = np.minimum(np.maximum(m - a * d, lb), ub)\n                    # evaluate both if budget allows (prefer both)\n                    if evals + 2 <= self.budget:\n                        f1 = safe_eval(x1)\n                        if f1 is None: break\n                        f2 = safe_eval(x2)\n                        if f2 is None: break\n                        # parabola vertex estimate symmetric => alpha_star formula\n                        denom = (f1 + f2 - 2.0 * f_best)\n                        if abs(denom) > 1e-12:\n                            alpha = 0.5 * a * (f2 - f1) / denom\n                            alpha = np.clip(alpha, -2.0 * a, 2.0 * a)\n                            x_star = np.minimum(np.maximum(m + alpha * d, lb), ub)\n                            f_star = safe_eval(x_star)\n                            if f_star is None: break\n                            x_cand = x_star\n                        else:\n                            # pick best among f1,f2,m\n                            cand_list = [(f1, x1), (f2, x2), (f_best, m)]\n                            fsel, xsel = min(cand_list, key=lambda t: t[0])\n                            x_cand = xsel.copy()\n                    else:\n                        # only one eval possible: test x1\n                        f1 = safe_eval(x1)\n                        if f1 is None: break\n                        x_cand = x1\n\n                elif op == 'levy':\n                    # heavy-tailed jump centered at best or m\n                    center = x_best if rng.rand() < 0.6 else m\n                    # simple Cauchy as heavy-tail (scaled)\n                    z = rng.standard_cauchy(size=self.dim)\n                    clipv = np.percentile(np.abs(z), 92) + 1e-12\n                    z = z / clipv\n                    step = 2.8 * sigma * z\n                    x_prop = np.minimum(np.maximum(center + step, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is None:\n                        break\n                    x_cand = x_prop\n\n                elif op == 'recomb':\n                    # convex recombination of two elites with jitter\n                    if len(X_arch) >= 3:\n                        # choose two elites biased by fitness\n                        idxs = np.argsort(f_arch)[:max(3, min(len(f_arch), 10))]\n                        i1 = idxs[rng.randint(0, len(idxs))]\n                        i2 = idxs[rng.randint(0, len(idxs))]\n                        alpha = rng.rand()\n                        child = alpha * X_arch[i1] + (1.0 - alpha) * X_arch[i2]\n                    else:\n                        child = rng.uniform(lb, ub, size=self.dim)\n                    jitter = 0.6 * sigma * rng.randn(self.dim)\n                    x_prop = np.minimum(np.maximum(child + jitter, lb), ub)\n                    f_prop = safe_eval(x_prop)\n                    if f_prop is None:\n                        break\n                    x_cand = x_prop\n\n                else:\n                    # fallback gaussian jitter\n                    step = sigma_diag * rng.randn(self.dim)\n                    x_try = m + step\n                    x_try = np.minimum(np.maximum(x_try, lb), ub)\n                    f_try = safe_eval(x_try)\n                    if f_try is None:\n                        break\n                    x_cand = x_try\n\n                # if x_cand was produced AND not already processed, get its function (safe_eval already used)\n                if x_cand is None:\n                    continue\n\n                # we assume safe_eval already placed candidate in archive and f_arch updated; retrieve last\n                if len(f_arch) == 0:\n                    continue\n                # f_cand is last appended if safe_eval used\n                f_cand = f_arch[-1]\n                batch_candidates.append(x_cand.copy())\n                batch_results.append(f_cand)\n                batch_ops.append(op_idx)\n\n                # immediate best update\n                improved = False\n                if f_cand < f_best - 1e-15:\n                    f_best = float(f_cand)\n                    x_best = x_cand.copy()\n                    improved = True\n                    gen_improved = True\n                    stagn = 0\n                else:\n                    stagn += 1\n\n                # reward shaping for operator: combine actual improvement and surrogate plausibility\n                # improvement relative to median\n                baseline = np.median(f_arch) if len(f_arch) > 0 else f_best\n                imp = max(0.0, baseline - f_cand)\n                # surrogate accuracy signal: if surrogate proposed similar point, small bonus (we approximate)\n                pred_bonus = 0.0\n                # normalized reward in [0,1]\n                reward = imp / (abs(baseline) + 1e-12)\n                reward = float(np.clip(reward, 0.0, 1.0))\n\n                # multiplicative update to log_w (EXP3 style via estimated reward)\n                # estimate selection probability for current op (approx from log_w)\n                maxlw = np.max(log_w)\n                exps = np.exp(log_w - maxlw)\n                probs = (1.0 - self.gamma_explore) * (exps / (np.sum(exps) + 1e-12)) + self.gamma_explore / K_ops\n                est_reward = reward / (probs[op_idx] + 1e-12)\n                # additive update on log_w (importance-weighted)\n                log_w[op_idx] += self.op_eta * est_reward\n                # mild decay to avoid runaway\n                log_w *= (1.0 - 1e-4)\n                # clip logs\n                log_w = np.clip(log_w, -20.0, 50.0)\n\n                # update per-dim RMS and sigma_diag\n                if step is None:\n                    step = x_cand - m\n                sq = (step / (sigma + 1e-12)) ** 2\n                v_rms = self.rms_beta * v_rms + (1.0 - self.rms_beta) * sq\n                sigma_diag = np.clip(sigma / (np.sqrt(v_rms) + 1e-8), 1e-12, 5.0 * avg_span)\n\n                # update momentum\n                if improved:\n                    momentum = self.momentum_beta * momentum + (1.0 - self.momentum_beta) * (x_cand - m)\n\n                # mean update: accept improvements and some uphill moves probabilistically\n                accept = False\n                if improved:\n                    accept = True\n                else:\n                    # uphill acceptance temperature proportional to sigma * avg_span\n                    T = max(1e-12, 0.9 * sigma * avg_span)\n                    delta = f_cand - f_best\n                    if delta <= 0 or rng.rand() < np.exp(-max(0.0, delta) / (T + 1e-12)):\n                        accept = True\n\n                if accept:\n                    # strategy-dependent lr: stronger for surrogate/recomb, gentler for levy/lowrank\n                    if operators[op_idx] == 'surrogate':\n                        lr = 0.7\n                    elif operators[op_idx] in ('recomb',):\n                        lr = 0.45\n                    elif operators[op_idx] in ('line', 'mirror'):\n                        lr = 0.55\n                    elif operators[op_idx] == 'levy':\n                        lr = 0.25\n                    else:\n                        lr = 0.32\n                    delta = x_cand - m\n                    # trust clipping\n                    trust = max(1e-12, 6.0 * sigma * np.sqrt(self.dim))\n                    dn = np.linalg.norm(delta)\n                    if dn > trust:\n                        delta = delta * (trust / (dn + 1e-12))\n                    m = np.minimum(np.maximum(m + lr * delta, lb), ub)\n                    # on accept, slightly shrink sigma if improved, else mild grow\n                    if improved:\n                        sigma = max(1e-12, sigma * np.exp(self.sigma_adapt_rate * (1.0 - self.succ_target) * -0.5))\n                    else:\n                        sigma = min(5.0 * avg_span, sigma * np.exp(self.sigma_adapt_rate * (0.5 * (self.succ_target))))\n                else:\n                    # rejection: small jitter and mild sigma inflation\n                    m = np.minimum(np.maximum(m + 0.01 * avg_span * rng.randn(self.dim), lb), ub)\n                    sigma = min(5.0 * avg_span, sigma * 1.01)\n                    momentum *= 0.98\n\n                # update smoothed success probability\n                p_succ = self.succ_ema_beta * p_succ + (1.0 - self.succ_ema_beta) * float(improved)\n                # multiplicative control for sigma (global)\n                sigma *= np.exp(self.sigma_adapt_rate * (p_succ - self.succ_target))\n                sigma = np.clip(sigma, 1e-12, 5.0 * avg_span)\n\n            # end batch\n\n            # opportunistic restart on stagnation long enough\n            if stagn >= stagn_limit and evals < self.budget:\n                stagn = 0\n                # re-center near best with anisotropic jitter from elite cov\n                if len(X_arch) >= 4:\n                    Xe_idx = np.argsort(f_arch)[:min(8, len(f_arch))]\n                    Xe = np.asarray([X_arch[i] for i in Xe_idx])\n                    try:\n                        C = np.cov(Xe.T) + 1e-8 * np.eye(self.dim)\n                        wv, V = np.linalg.eigh(C)\n                        wv = np.maximum(wv, 1e-12)\n                        sqrtC = V.dot(np.diag(np.sqrt(wv))).dot(V.T)\n                        jitter = 0.9 * sigma * (0.6 * rng.randn(self.dim) + 0.4 * (sqrtC.dot(rng.randn(self.dim))))\n                    except Exception:\n                        jitter = 1.2 * sigma * rng.randn(self.dim)\n                else:\n                    jitter = 1.2 * sigma * rng.randn(self.dim)\n                m = np.minimum(np.maximum(x_best + jitter, lb), ub)\n                # reset subspace and scales mildly\n                if k > 0:\n                    A = rng.randn(self.dim, k)\n                    try:\n                        Q, _ = np.linalg.qr(A)\n                        U = Q[:, :k]\n                        sub_scale = np.full(k, sigma / np.sqrt(max(1, k)))\n                    except Exception:\n                        pass\n                # inflate sigma to promote exploration\n                sigma = min(5.0 * avg_span, sigma * 1.8)\n                # small reseed around best to refresh archive\n                for _ in range(min(6, self.budget - evals)):\n                    x = np.minimum(np.maximum(x_best + 0.06 * avg_span * rng.randn(self.dim), lb), ub)\n                    f = safe_eval(x)\n                    if f is None:\n                        break\n                    if f < f_best:\n                        f_best = f; x_best = x.copy()\n\n        # finished budget\n        self.f_opt = float(f_best)\n        self.x_opt = np.asarray(x_best, dtype=float)\n        return self.f_opt, self.x_opt", "configspace": "", "generation": 0, "feedback": "The algorithm SYNERGIA scored 0.164 on AOCC (higher is better, 1.0 is the best).", "error": "", "parent_ids": "3fb1d17b-671f-44d8-8625-cf8b6753dc76", "operator": null, "metadata": {"aucs": [0.08765673410269259, 0.1508668333144474, 0.26432282170690147, 0.16858078357330553, 0.11477121677482593, 0.2142518626529316, 0.17393292241080893, 0.17183112954398994, 0.16866385229922642, 0.12223013420364781]}, "task_prompt": ""}
